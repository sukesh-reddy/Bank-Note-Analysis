<!DOCTYPE html>
<html>
<head><meta charset="utf-8" />

<title>BankNoteAnalysisProject</title>

<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.1.10/require.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>



<style type="text/css">
    /*!
*
* Twitter Bootstrap
*
*/
/*!
 * Bootstrap v3.3.7 (http://getbootstrap.com)
 * Copyright 2011-2016 Twitter, Inc.
 * Licensed under MIT (https://github.com/twbs/bootstrap/blob/master/LICENSE)
 */
/*! normalize.css v3.0.3 | MIT License | github.com/necolas/normalize.css */
html {
  font-family: sans-serif;
  -ms-text-size-adjust: 100%;
  -webkit-text-size-adjust: 100%;
}
body {
  margin: 0;
}
article,
aside,
details,
figcaption,
figure,
footer,
header,
hgroup,
main,
menu,
nav,
section,
summary {
  display: block;
}
audio,
canvas,
progress,
video {
  display: inline-block;
  vertical-align: baseline;
}
audio:not([controls]) {
  display: none;
  height: 0;
}
[hidden],
template {
  display: none;
}
a {
  background-color: transparent;
}
a:active,
a:hover {
  outline: 0;
}
abbr[title] {
  border-bottom: 1px dotted;
}
b,
strong {
  font-weight: bold;
}
dfn {
  font-style: italic;
}
h1 {
  font-size: 2em;
  margin: 0.67em 0;
}
mark {
  background: #ff0;
  color: #000;
}
small {
  font-size: 80%;
}
sub,
sup {
  font-size: 75%;
  line-height: 0;
  position: relative;
  vertical-align: baseline;
}
sup {
  top: -0.5em;
}
sub {
  bottom: -0.25em;
}
img {
  border: 0;
}
svg:not(:root) {
  overflow: hidden;
}
figure {
  margin: 1em 40px;
}
hr {
  box-sizing: content-box;
  height: 0;
}
pre {
  overflow: auto;
}
code,
kbd,
pre,
samp {
  font-family: monospace, monospace;
  font-size: 1em;
}
button,
input,
optgroup,
select,
textarea {
  color: inherit;
  font: inherit;
  margin: 0;
}
button {
  overflow: visible;
}
button,
select {
  text-transform: none;
}
button,
html input[type="button"],
input[type="reset"],
input[type="submit"] {
  -webkit-appearance: button;
  cursor: pointer;
}
button[disabled],
html input[disabled] {
  cursor: default;
}
button::-moz-focus-inner,
input::-moz-focus-inner {
  border: 0;
  padding: 0;
}
input {
  line-height: normal;
}
input[type="checkbox"],
input[type="radio"] {
  box-sizing: border-box;
  padding: 0;
}
input[type="number"]::-webkit-inner-spin-button,
input[type="number"]::-webkit-outer-spin-button {
  height: auto;
}
input[type="search"] {
  -webkit-appearance: textfield;
  box-sizing: content-box;
}
input[type="search"]::-webkit-search-cancel-button,
input[type="search"]::-webkit-search-decoration {
  -webkit-appearance: none;
}
fieldset {
  border: 1px solid #c0c0c0;
  margin: 0 2px;
  padding: 0.35em 0.625em 0.75em;
}
legend {
  border: 0;
  padding: 0;
}
textarea {
  overflow: auto;
}
optgroup {
  font-weight: bold;
}
table {
  border-collapse: collapse;
  border-spacing: 0;
}
td,
th {
  padding: 0;
}
/*! Source: https://github.com/h5bp/html5-boilerplate/blob/master/src/css/main.css */
@media print {
  *,
  *:before,
  *:after {
    background: transparent !important;
    box-shadow: none !important;
    text-shadow: none !important;
  }
  a,
  a:visited {
    text-decoration: underline;
  }
  a[href]:after {
    content: " (" attr(href) ")";
  }
  abbr[title]:after {
    content: " (" attr(title) ")";
  }
  a[href^="#"]:after,
  a[href^="javascript:"]:after {
    content: "";
  }
  pre,
  blockquote {
    border: 1px solid #999;
    page-break-inside: avoid;
  }
  thead {
    display: table-header-group;
  }
  tr,
  img {
    page-break-inside: avoid;
  }
  img {
    max-width: 100% !important;
  }
  p,
  h2,
  h3 {
    orphans: 3;
    widows: 3;
  }
  h2,
  h3 {
    page-break-after: avoid;
  }
  .navbar {
    display: none;
  }
  .btn > .caret,
  .dropup > .btn > .caret {
    border-top-color: #000 !important;
  }
  .label {
    border: 1px solid #000;
  }
  .table {
    border-collapse: collapse !important;
  }
  .table td,
  .table th {
    background-color: #fff !important;
  }
  .table-bordered th,
  .table-bordered td {
    border: 1px solid #ddd !important;
  }
}
@font-face {
  font-family: 'Glyphicons Halflings';
  src: url('../components/bootstrap/fonts/glyphicons-halflings-regular.eot');
  src: url('../components/bootstrap/fonts/glyphicons-halflings-regular.eot?#iefix') format('embedded-opentype'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.woff2') format('woff2'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.woff') format('woff'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.ttf') format('truetype'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.svg#glyphicons_halflingsregular') format('svg');
}
.glyphicon {
  position: relative;
  top: 1px;
  display: inline-block;
  font-family: 'Glyphicons Halflings';
  font-style: normal;
  font-weight: normal;
  line-height: 1;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
}
.glyphicon-asterisk:before {
  content: "\002a";
}
.glyphicon-plus:before {
  content: "\002b";
}
.glyphicon-euro:before,
.glyphicon-eur:before {
  content: "\20ac";
}
.glyphicon-minus:before {
  content: "\2212";
}
.glyphicon-cloud:before {
  content: "\2601";
}
.glyphicon-envelope:before {
  content: "\2709";
}
.glyphicon-pencil:before {
  content: "\270f";
}
.glyphicon-glass:before {
  content: "\e001";
}
.glyphicon-music:before {
  content: "\e002";
}
.glyphicon-search:before {
  content: "\e003";
}
.glyphicon-heart:before {
  content: "\e005";
}
.glyphicon-star:before {
  content: "\e006";
}
.glyphicon-star-empty:before {
  content: "\e007";
}
.glyphicon-user:before {
  content: "\e008";
}
.glyphicon-film:before {
  content: "\e009";
}
.glyphicon-th-large:before {
  content: "\e010";
}
.glyphicon-th:before {
  content: "\e011";
}
.glyphicon-th-list:before {
  content: "\e012";
}
.glyphicon-ok:before {
  content: "\e013";
}
.glyphicon-remove:before {
  content: "\e014";
}
.glyphicon-zoom-in:before {
  content: "\e015";
}
.glyphicon-zoom-out:before {
  content: "\e016";
}
.glyphicon-off:before {
  content: "\e017";
}
.glyphicon-signal:before {
  content: "\e018";
}
.glyphicon-cog:before {
  content: "\e019";
}
.glyphicon-trash:before {
  content: "\e020";
}
.glyphicon-home:before {
  content: "\e021";
}
.glyphicon-file:before {
  content: "\e022";
}
.glyphicon-time:before {
  content: "\e023";
}
.glyphicon-road:before {
  content: "\e024";
}
.glyphicon-download-alt:before {
  content: "\e025";
}
.glyphicon-download:before {
  content: "\e026";
}
.glyphicon-upload:before {
  content: "\e027";
}
.glyphicon-inbox:before {
  content: "\e028";
}
.glyphicon-play-circle:before {
  content: "\e029";
}
.glyphicon-repeat:before {
  content: "\e030";
}
.glyphicon-refresh:before {
  content: "\e031";
}
.glyphicon-list-alt:before {
  content: "\e032";
}
.glyphicon-lock:before {
  content: "\e033";
}
.glyphicon-flag:before {
  content: "\e034";
}
.glyphicon-headphones:before {
  content: "\e035";
}
.glyphicon-volume-off:before {
  content: "\e036";
}
.glyphicon-volume-down:before {
  content: "\e037";
}
.glyphicon-volume-up:before {
  content: "\e038";
}
.glyphicon-qrcode:before {
  content: "\e039";
}
.glyphicon-barcode:before {
  content: "\e040";
}
.glyphicon-tag:before {
  content: "\e041";
}
.glyphicon-tags:before {
  content: "\e042";
}
.glyphicon-book:before {
  content: "\e043";
}
.glyphicon-bookmark:before {
  content: "\e044";
}
.glyphicon-print:before {
  content: "\e045";
}
.glyphicon-camera:before {
  content: "\e046";
}
.glyphicon-font:before {
  content: "\e047";
}
.glyphicon-bold:before {
  content: "\e048";
}
.glyphicon-italic:before {
  content: "\e049";
}
.glyphicon-text-height:before {
  content: "\e050";
}
.glyphicon-text-width:before {
  content: "\e051";
}
.glyphicon-align-left:before {
  content: "\e052";
}
.glyphicon-align-center:before {
  content: "\e053";
}
.glyphicon-align-right:before {
  content: "\e054";
}
.glyphicon-align-justify:before {
  content: "\e055";
}
.glyphicon-list:before {
  content: "\e056";
}
.glyphicon-indent-left:before {
  content: "\e057";
}
.glyphicon-indent-right:before {
  content: "\e058";
}
.glyphicon-facetime-video:before {
  content: "\e059";
}
.glyphicon-picture:before {
  content: "\e060";
}
.glyphicon-map-marker:before {
  content: "\e062";
}
.glyphicon-adjust:before {
  content: "\e063";
}
.glyphicon-tint:before {
  content: "\e064";
}
.glyphicon-edit:before {
  content: "\e065";
}
.glyphicon-share:before {
  content: "\e066";
}
.glyphicon-check:before {
  content: "\e067";
}
.glyphicon-move:before {
  content: "\e068";
}
.glyphicon-step-backward:before {
  content: "\e069";
}
.glyphicon-fast-backward:before {
  content: "\e070";
}
.glyphicon-backward:before {
  content: "\e071";
}
.glyphicon-play:before {
  content: "\e072";
}
.glyphicon-pause:before {
  content: "\e073";
}
.glyphicon-stop:before {
  content: "\e074";
}
.glyphicon-forward:before {
  content: "\e075";
}
.glyphicon-fast-forward:before {
  content: "\e076";
}
.glyphicon-step-forward:before {
  content: "\e077";
}
.glyphicon-eject:before {
  content: "\e078";
}
.glyphicon-chevron-left:before {
  content: "\e079";
}
.glyphicon-chevron-right:before {
  content: "\e080";
}
.glyphicon-plus-sign:before {
  content: "\e081";
}
.glyphicon-minus-sign:before {
  content: "\e082";
}
.glyphicon-remove-sign:before {
  content: "\e083";
}
.glyphicon-ok-sign:before {
  content: "\e084";
}
.glyphicon-question-sign:before {
  content: "\e085";
}
.glyphicon-info-sign:before {
  content: "\e086";
}
.glyphicon-screenshot:before {
  content: "\e087";
}
.glyphicon-remove-circle:before {
  content: "\e088";
}
.glyphicon-ok-circle:before {
  content: "\e089";
}
.glyphicon-ban-circle:before {
  content: "\e090";
}
.glyphicon-arrow-left:before {
  content: "\e091";
}
.glyphicon-arrow-right:before {
  content: "\e092";
}
.glyphicon-arrow-up:before {
  content: "\e093";
}
.glyphicon-arrow-down:before {
  content: "\e094";
}
.glyphicon-share-alt:before {
  content: "\e095";
}
.glyphicon-resize-full:before {
  content: "\e096";
}
.glyphicon-resize-small:before {
  content: "\e097";
}
.glyphicon-exclamation-sign:before {
  content: "\e101";
}
.glyphicon-gift:before {
  content: "\e102";
}
.glyphicon-leaf:before {
  content: "\e103";
}
.glyphicon-fire:before {
  content: "\e104";
}
.glyphicon-eye-open:before {
  content: "\e105";
}
.glyphicon-eye-close:before {
  content: "\e106";
}
.glyphicon-warning-sign:before {
  content: "\e107";
}
.glyphicon-plane:before {
  content: "\e108";
}
.glyphicon-calendar:before {
  content: "\e109";
}
.glyphicon-random:before {
  content: "\e110";
}
.glyphicon-comment:before {
  content: "\e111";
}
.glyphicon-magnet:before {
  content: "\e112";
}
.glyphicon-chevron-up:before {
  content: "\e113";
}
.glyphicon-chevron-down:before {
  content: "\e114";
}
.glyphicon-retweet:before {
  content: "\e115";
}
.glyphicon-shopping-cart:before {
  content: "\e116";
}
.glyphicon-folder-close:before {
  content: "\e117";
}
.glyphicon-folder-open:before {
  content: "\e118";
}
.glyphicon-resize-vertical:before {
  content: "\e119";
}
.glyphicon-resize-horizontal:before {
  content: "\e120";
}
.glyphicon-hdd:before {
  content: "\e121";
}
.glyphicon-bullhorn:before {
  content: "\e122";
}
.glyphicon-bell:before {
  content: "\e123";
}
.glyphicon-certificate:before {
  content: "\e124";
}
.glyphicon-thumbs-up:before {
  content: "\e125";
}
.glyphicon-thumbs-down:before {
  content: "\e126";
}
.glyphicon-hand-right:before {
  content: "\e127";
}
.glyphicon-hand-left:before {
  content: "\e128";
}
.glyphicon-hand-up:before {
  content: "\e129";
}
.glyphicon-hand-down:before {
  content: "\e130";
}
.glyphicon-circle-arrow-right:before {
  content: "\e131";
}
.glyphicon-circle-arrow-left:before {
  content: "\e132";
}
.glyphicon-circle-arrow-up:before {
  content: "\e133";
}
.glyphicon-circle-arrow-down:before {
  content: "\e134";
}
.glyphicon-globe:before {
  content: "\e135";
}
.glyphicon-wrench:before {
  content: "\e136";
}
.glyphicon-tasks:before {
  content: "\e137";
}
.glyphicon-filter:before {
  content: "\e138";
}
.glyphicon-briefcase:before {
  content: "\e139";
}
.glyphicon-fullscreen:before {
  content: "\e140";
}
.glyphicon-dashboard:before {
  content: "\e141";
}
.glyphicon-paperclip:before {
  content: "\e142";
}
.glyphicon-heart-empty:before {
  content: "\e143";
}
.glyphicon-link:before {
  content: "\e144";
}
.glyphicon-phone:before {
  content: "\e145";
}
.glyphicon-pushpin:before {
  content: "\e146";
}
.glyphicon-usd:before {
  content: "\e148";
}
.glyphicon-gbp:before {
  content: "\e149";
}
.glyphicon-sort:before {
  content: "\e150";
}
.glyphicon-sort-by-alphabet:before {
  content: "\e151";
}
.glyphicon-sort-by-alphabet-alt:before {
  content: "\e152";
}
.glyphicon-sort-by-order:before {
  content: "\e153";
}
.glyphicon-sort-by-order-alt:before {
  content: "\e154";
}
.glyphicon-sort-by-attributes:before {
  content: "\e155";
}
.glyphicon-sort-by-attributes-alt:before {
  content: "\e156";
}
.glyphicon-unchecked:before {
  content: "\e157";
}
.glyphicon-expand:before {
  content: "\e158";
}
.glyphicon-collapse-down:before {
  content: "\e159";
}
.glyphicon-collapse-up:before {
  content: "\e160";
}
.glyphicon-log-in:before {
  content: "\e161";
}
.glyphicon-flash:before {
  content: "\e162";
}
.glyphicon-log-out:before {
  content: "\e163";
}
.glyphicon-new-window:before {
  content: "\e164";
}
.glyphicon-record:before {
  content: "\e165";
}
.glyphicon-save:before {
  content: "\e166";
}
.glyphicon-open:before {
  content: "\e167";
}
.glyphicon-saved:before {
  content: "\e168";
}
.glyphicon-import:before {
  content: "\e169";
}
.glyphicon-export:before {
  content: "\e170";
}
.glyphicon-send:before {
  content: "\e171";
}
.glyphicon-floppy-disk:before {
  content: "\e172";
}
.glyphicon-floppy-saved:before {
  content: "\e173";
}
.glyphicon-floppy-remove:before {
  content: "\e174";
}
.glyphicon-floppy-save:before {
  content: "\e175";
}
.glyphicon-floppy-open:before {
  content: "\e176";
}
.glyphicon-credit-card:before {
  content: "\e177";
}
.glyphicon-transfer:before {
  content: "\e178";
}
.glyphicon-cutlery:before {
  content: "\e179";
}
.glyphicon-header:before {
  content: "\e180";
}
.glyphicon-compressed:before {
  content: "\e181";
}
.glyphicon-earphone:before {
  content: "\e182";
}
.glyphicon-phone-alt:before {
  content: "\e183";
}
.glyphicon-tower:before {
  content: "\e184";
}
.glyphicon-stats:before {
  content: "\e185";
}
.glyphicon-sd-video:before {
  content: "\e186";
}
.glyphicon-hd-video:before {
  content: "\e187";
}
.glyphicon-subtitles:before {
  content: "\e188";
}
.glyphicon-sound-stereo:before {
  content: "\e189";
}
.glyphicon-sound-dolby:before {
  content: "\e190";
}
.glyphicon-sound-5-1:before {
  content: "\e191";
}
.glyphicon-sound-6-1:before {
  content: "\e192";
}
.glyphicon-sound-7-1:before {
  content: "\e193";
}
.glyphicon-copyright-mark:before {
  content: "\e194";
}
.glyphicon-registration-mark:before {
  content: "\e195";
}
.glyphicon-cloud-download:before {
  content: "\e197";
}
.glyphicon-cloud-upload:before {
  content: "\e198";
}
.glyphicon-tree-conifer:before {
  content: "\e199";
}
.glyphicon-tree-deciduous:before {
  content: "\e200";
}
.glyphicon-cd:before {
  content: "\e201";
}
.glyphicon-save-file:before {
  content: "\e202";
}
.glyphicon-open-file:before {
  content: "\e203";
}
.glyphicon-level-up:before {
  content: "\e204";
}
.glyphicon-copy:before {
  content: "\e205";
}
.glyphicon-paste:before {
  content: "\e206";
}
.glyphicon-alert:before {
  content: "\e209";
}
.glyphicon-equalizer:before {
  content: "\e210";
}
.glyphicon-king:before {
  content: "\e211";
}
.glyphicon-queen:before {
  content: "\e212";
}
.glyphicon-pawn:before {
  content: "\e213";
}
.glyphicon-bishop:before {
  content: "\e214";
}
.glyphicon-knight:before {
  content: "\e215";
}
.glyphicon-baby-formula:before {
  content: "\e216";
}
.glyphicon-tent:before {
  content: "\26fa";
}
.glyphicon-blackboard:before {
  content: "\e218";
}
.glyphicon-bed:before {
  content: "\e219";
}
.glyphicon-apple:before {
  content: "\f8ff";
}
.glyphicon-erase:before {
  content: "\e221";
}
.glyphicon-hourglass:before {
  content: "\231b";
}
.glyphicon-lamp:before {
  content: "\e223";
}
.glyphicon-duplicate:before {
  content: "\e224";
}
.glyphicon-piggy-bank:before {
  content: "\e225";
}
.glyphicon-scissors:before {
  content: "\e226";
}
.glyphicon-bitcoin:before {
  content: "\e227";
}
.glyphicon-btc:before {
  content: "\e227";
}
.glyphicon-xbt:before {
  content: "\e227";
}
.glyphicon-yen:before {
  content: "\00a5";
}
.glyphicon-jpy:before {
  content: "\00a5";
}
.glyphicon-ruble:before {
  content: "\20bd";
}
.glyphicon-rub:before {
  content: "\20bd";
}
.glyphicon-scale:before {
  content: "\e230";
}
.glyphicon-ice-lolly:before {
  content: "\e231";
}
.glyphicon-ice-lolly-tasted:before {
  content: "\e232";
}
.glyphicon-education:before {
  content: "\e233";
}
.glyphicon-option-horizontal:before {
  content: "\e234";
}
.glyphicon-option-vertical:before {
  content: "\e235";
}
.glyphicon-menu-hamburger:before {
  content: "\e236";
}
.glyphicon-modal-window:before {
  content: "\e237";
}
.glyphicon-oil:before {
  content: "\e238";
}
.glyphicon-grain:before {
  content: "\e239";
}
.glyphicon-sunglasses:before {
  content: "\e240";
}
.glyphicon-text-size:before {
  content: "\e241";
}
.glyphicon-text-color:before {
  content: "\e242";
}
.glyphicon-text-background:before {
  content: "\e243";
}
.glyphicon-object-align-top:before {
  content: "\e244";
}
.glyphicon-object-align-bottom:before {
  content: "\e245";
}
.glyphicon-object-align-horizontal:before {
  content: "\e246";
}
.glyphicon-object-align-left:before {
  content: "\e247";
}
.glyphicon-object-align-vertical:before {
  content: "\e248";
}
.glyphicon-object-align-right:before {
  content: "\e249";
}
.glyphicon-triangle-right:before {
  content: "\e250";
}
.glyphicon-triangle-left:before {
  content: "\e251";
}
.glyphicon-triangle-bottom:before {
  content: "\e252";
}
.glyphicon-triangle-top:before {
  content: "\e253";
}
.glyphicon-console:before {
  content: "\e254";
}
.glyphicon-superscript:before {
  content: "\e255";
}
.glyphicon-subscript:before {
  content: "\e256";
}
.glyphicon-menu-left:before {
  content: "\e257";
}
.glyphicon-menu-right:before {
  content: "\e258";
}
.glyphicon-menu-down:before {
  content: "\e259";
}
.glyphicon-menu-up:before {
  content: "\e260";
}
* {
  -webkit-box-sizing: border-box;
  -moz-box-sizing: border-box;
  box-sizing: border-box;
}
*:before,
*:after {
  -webkit-box-sizing: border-box;
  -moz-box-sizing: border-box;
  box-sizing: border-box;
}
html {
  font-size: 10px;
  -webkit-tap-highlight-color: rgba(0, 0, 0, 0);
}
body {
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
  font-size: 13px;
  line-height: 1.42857143;
  color: #000;
  background-color: #fff;
}
input,
button,
select,
textarea {
  font-family: inherit;
  font-size: inherit;
  line-height: inherit;
}
a {
  color: #337ab7;
  text-decoration: none;
}
a:hover,
a:focus {
  color: #23527c;
  text-decoration: underline;
}
a:focus {
  outline: 5px auto -webkit-focus-ring-color;
  outline-offset: -2px;
}
figure {
  margin: 0;
}
img {
  vertical-align: middle;
}
.img-responsive,
.thumbnail > img,
.thumbnail a > img,
.carousel-inner > .item > img,
.carousel-inner > .item > a > img {
  display: block;
  max-width: 100%;
  height: auto;
}
.img-rounded {
  border-radius: 3px;
}
.img-thumbnail {
  padding: 4px;
  line-height: 1.42857143;
  background-color: #fff;
  border: 1px solid #ddd;
  border-radius: 2px;
  -webkit-transition: all 0.2s ease-in-out;
  -o-transition: all 0.2s ease-in-out;
  transition: all 0.2s ease-in-out;
  display: inline-block;
  max-width: 100%;
  height: auto;
}
.img-circle {
  border-radius: 50%;
}
hr {
  margin-top: 18px;
  margin-bottom: 18px;
  border: 0;
  border-top: 1px solid #eeeeee;
}
.sr-only {
  position: absolute;
  width: 1px;
  height: 1px;
  margin: -1px;
  padding: 0;
  overflow: hidden;
  clip: rect(0, 0, 0, 0);
  border: 0;
}
.sr-only-focusable:active,
.sr-only-focusable:focus {
  position: static;
  width: auto;
  height: auto;
  margin: 0;
  overflow: visible;
  clip: auto;
}
[role="button"] {
  cursor: pointer;
}
h1,
h2,
h3,
h4,
h5,
h6,
.h1,
.h2,
.h3,
.h4,
.h5,
.h6 {
  font-family: inherit;
  font-weight: 500;
  line-height: 1.1;
  color: inherit;
}
h1 small,
h2 small,
h3 small,
h4 small,
h5 small,
h6 small,
.h1 small,
.h2 small,
.h3 small,
.h4 small,
.h5 small,
.h6 small,
h1 .small,
h2 .small,
h3 .small,
h4 .small,
h5 .small,
h6 .small,
.h1 .small,
.h2 .small,
.h3 .small,
.h4 .small,
.h5 .small,
.h6 .small {
  font-weight: normal;
  line-height: 1;
  color: #777777;
}
h1,
.h1,
h2,
.h2,
h3,
.h3 {
  margin-top: 18px;
  margin-bottom: 9px;
}
h1 small,
.h1 small,
h2 small,
.h2 small,
h3 small,
.h3 small,
h1 .small,
.h1 .small,
h2 .small,
.h2 .small,
h3 .small,
.h3 .small {
  font-size: 65%;
}
h4,
.h4,
h5,
.h5,
h6,
.h6 {
  margin-top: 9px;
  margin-bottom: 9px;
}
h4 small,
.h4 small,
h5 small,
.h5 small,
h6 small,
.h6 small,
h4 .small,
.h4 .small,
h5 .small,
.h5 .small,
h6 .small,
.h6 .small {
  font-size: 75%;
}
h1,
.h1 {
  font-size: 33px;
}
h2,
.h2 {
  font-size: 27px;
}
h3,
.h3 {
  font-size: 23px;
}
h4,
.h4 {
  font-size: 17px;
}
h5,
.h5 {
  font-size: 13px;
}
h6,
.h6 {
  font-size: 12px;
}
p {
  margin: 0 0 9px;
}
.lead {
  margin-bottom: 18px;
  font-size: 14px;
  font-weight: 300;
  line-height: 1.4;
}
@media (min-width: 768px) {
  .lead {
    font-size: 19.5px;
  }
}
small,
.small {
  font-size: 92%;
}
mark,
.mark {
  background-color: #fcf8e3;
  padding: .2em;
}
.text-left {
  text-align: left;
}
.text-right {
  text-align: right;
}
.text-center {
  text-align: center;
}
.text-justify {
  text-align: justify;
}
.text-nowrap {
  white-space: nowrap;
}
.text-lowercase {
  text-transform: lowercase;
}
.text-uppercase {
  text-transform: uppercase;
}
.text-capitalize {
  text-transform: capitalize;
}
.text-muted {
  color: #777777;
}
.text-primary {
  color: #337ab7;
}
a.text-primary:hover,
a.text-primary:focus {
  color: #286090;
}
.text-success {
  color: #3c763d;
}
a.text-success:hover,
a.text-success:focus {
  color: #2b542c;
}
.text-info {
  color: #31708f;
}
a.text-info:hover,
a.text-info:focus {
  color: #245269;
}
.text-warning {
  color: #8a6d3b;
}
a.text-warning:hover,
a.text-warning:focus {
  color: #66512c;
}
.text-danger {
  color: #a94442;
}
a.text-danger:hover,
a.text-danger:focus {
  color: #843534;
}
.bg-primary {
  color: #fff;
  background-color: #337ab7;
}
a.bg-primary:hover,
a.bg-primary:focus {
  background-color: #286090;
}
.bg-success {
  background-color: #dff0d8;
}
a.bg-success:hover,
a.bg-success:focus {
  background-color: #c1e2b3;
}
.bg-info {
  background-color: #d9edf7;
}
a.bg-info:hover,
a.bg-info:focus {
  background-color: #afd9ee;
}
.bg-warning {
  background-color: #fcf8e3;
}
a.bg-warning:hover,
a.bg-warning:focus {
  background-color: #f7ecb5;
}
.bg-danger {
  background-color: #f2dede;
}
a.bg-danger:hover,
a.bg-danger:focus {
  background-color: #e4b9b9;
}
.page-header {
  padding-bottom: 8px;
  margin: 36px 0 18px;
  border-bottom: 1px solid #eeeeee;
}
ul,
ol {
  margin-top: 0;
  margin-bottom: 9px;
}
ul ul,
ol ul,
ul ol,
ol ol {
  margin-bottom: 0;
}
.list-unstyled {
  padding-left: 0;
  list-style: none;
}
.list-inline {
  padding-left: 0;
  list-style: none;
  margin-left: -5px;
}
.list-inline > li {
  display: inline-block;
  padding-left: 5px;
  padding-right: 5px;
}
dl {
  margin-top: 0;
  margin-bottom: 18px;
}
dt,
dd {
  line-height: 1.42857143;
}
dt {
  font-weight: bold;
}
dd {
  margin-left: 0;
}
@media (min-width: 541px) {
  .dl-horizontal dt {
    float: left;
    width: 160px;
    clear: left;
    text-align: right;
    overflow: hidden;
    text-overflow: ellipsis;
    white-space: nowrap;
  }
  .dl-horizontal dd {
    margin-left: 180px;
  }
}
abbr[title],
abbr[data-original-title] {
  cursor: help;
  border-bottom: 1px dotted #777777;
}
.initialism {
  font-size: 90%;
  text-transform: uppercase;
}
blockquote {
  padding: 9px 18px;
  margin: 0 0 18px;
  font-size: inherit;
  border-left: 5px solid #eeeeee;
}
blockquote p:last-child,
blockquote ul:last-child,
blockquote ol:last-child {
  margin-bottom: 0;
}
blockquote footer,
blockquote small,
blockquote .small {
  display: block;
  font-size: 80%;
  line-height: 1.42857143;
  color: #777777;
}
blockquote footer:before,
blockquote small:before,
blockquote .small:before {
  content: '\2014 \00A0';
}
.blockquote-reverse,
blockquote.pull-right {
  padding-right: 15px;
  padding-left: 0;
  border-right: 5px solid #eeeeee;
  border-left: 0;
  text-align: right;
}
.blockquote-reverse footer:before,
blockquote.pull-right footer:before,
.blockquote-reverse small:before,
blockquote.pull-right small:before,
.blockquote-reverse .small:before,
blockquote.pull-right .small:before {
  content: '';
}
.blockquote-reverse footer:after,
blockquote.pull-right footer:after,
.blockquote-reverse small:after,
blockquote.pull-right small:after,
.blockquote-reverse .small:after,
blockquote.pull-right .small:after {
  content: '\00A0 \2014';
}
address {
  margin-bottom: 18px;
  font-style: normal;
  line-height: 1.42857143;
}
code,
kbd,
pre,
samp {
  font-family: monospace;
}
code {
  padding: 2px 4px;
  font-size: 90%;
  color: #c7254e;
  background-color: #f9f2f4;
  border-radius: 2px;
}
kbd {
  padding: 2px 4px;
  font-size: 90%;
  color: #888;
  background-color: transparent;
  border-radius: 1px;
  box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.25);
}
kbd kbd {
  padding: 0;
  font-size: 100%;
  font-weight: bold;
  box-shadow: none;
}
pre {
  display: block;
  padding: 8.5px;
  margin: 0 0 9px;
  font-size: 12px;
  line-height: 1.42857143;
  word-break: break-all;
  word-wrap: break-word;
  color: #333333;
  background-color: #f5f5f5;
  border: 1px solid #ccc;
  border-radius: 2px;
}
pre code {
  padding: 0;
  font-size: inherit;
  color: inherit;
  white-space: pre-wrap;
  background-color: transparent;
  border-radius: 0;
}
.pre-scrollable {
  max-height: 340px;
  overflow-y: scroll;
}
.container {
  margin-right: auto;
  margin-left: auto;
  padding-left: 0px;
  padding-right: 0px;
}
@media (min-width: 768px) {
  .container {
    width: 768px;
  }
}
@media (min-width: 992px) {
  .container {
    width: 940px;
  }
}
@media (min-width: 1200px) {
  .container {
    width: 1140px;
  }
}
.container-fluid {
  margin-right: auto;
  margin-left: auto;
  padding-left: 0px;
  padding-right: 0px;
}
.row {
  margin-left: 0px;
  margin-right: 0px;
}
.col-xs-1, .col-sm-1, .col-md-1, .col-lg-1, .col-xs-2, .col-sm-2, .col-md-2, .col-lg-2, .col-xs-3, .col-sm-3, .col-md-3, .col-lg-3, .col-xs-4, .col-sm-4, .col-md-4, .col-lg-4, .col-xs-5, .col-sm-5, .col-md-5, .col-lg-5, .col-xs-6, .col-sm-6, .col-md-6, .col-lg-6, .col-xs-7, .col-sm-7, .col-md-7, .col-lg-7, .col-xs-8, .col-sm-8, .col-md-8, .col-lg-8, .col-xs-9, .col-sm-9, .col-md-9, .col-lg-9, .col-xs-10, .col-sm-10, .col-md-10, .col-lg-10, .col-xs-11, .col-sm-11, .col-md-11, .col-lg-11, .col-xs-12, .col-sm-12, .col-md-12, .col-lg-12 {
  position: relative;
  min-height: 1px;
  padding-left: 0px;
  padding-right: 0px;
}
.col-xs-1, .col-xs-2, .col-xs-3, .col-xs-4, .col-xs-5, .col-xs-6, .col-xs-7, .col-xs-8, .col-xs-9, .col-xs-10, .col-xs-11, .col-xs-12 {
  float: left;
}
.col-xs-12 {
  width: 100%;
}
.col-xs-11 {
  width: 91.66666667%;
}
.col-xs-10 {
  width: 83.33333333%;
}
.col-xs-9 {
  width: 75%;
}
.col-xs-8 {
  width: 66.66666667%;
}
.col-xs-7 {
  width: 58.33333333%;
}
.col-xs-6 {
  width: 50%;
}
.col-xs-5 {
  width: 41.66666667%;
}
.col-xs-4 {
  width: 33.33333333%;
}
.col-xs-3 {
  width: 25%;
}
.col-xs-2 {
  width: 16.66666667%;
}
.col-xs-1 {
  width: 8.33333333%;
}
.col-xs-pull-12 {
  right: 100%;
}
.col-xs-pull-11 {
  right: 91.66666667%;
}
.col-xs-pull-10 {
  right: 83.33333333%;
}
.col-xs-pull-9 {
  right: 75%;
}
.col-xs-pull-8 {
  right: 66.66666667%;
}
.col-xs-pull-7 {
  right: 58.33333333%;
}
.col-xs-pull-6 {
  right: 50%;
}
.col-xs-pull-5 {
  right: 41.66666667%;
}
.col-xs-pull-4 {
  right: 33.33333333%;
}
.col-xs-pull-3 {
  right: 25%;
}
.col-xs-pull-2 {
  right: 16.66666667%;
}
.col-xs-pull-1 {
  right: 8.33333333%;
}
.col-xs-pull-0 {
  right: auto;
}
.col-xs-push-12 {
  left: 100%;
}
.col-xs-push-11 {
  left: 91.66666667%;
}
.col-xs-push-10 {
  left: 83.33333333%;
}
.col-xs-push-9 {
  left: 75%;
}
.col-xs-push-8 {
  left: 66.66666667%;
}
.col-xs-push-7 {
  left: 58.33333333%;
}
.col-xs-push-6 {
  left: 50%;
}
.col-xs-push-5 {
  left: 41.66666667%;
}
.col-xs-push-4 {
  left: 33.33333333%;
}
.col-xs-push-3 {
  left: 25%;
}
.col-xs-push-2 {
  left: 16.66666667%;
}
.col-xs-push-1 {
  left: 8.33333333%;
}
.col-xs-push-0 {
  left: auto;
}
.col-xs-offset-12 {
  margin-left: 100%;
}
.col-xs-offset-11 {
  margin-left: 91.66666667%;
}
.col-xs-offset-10 {
  margin-left: 83.33333333%;
}
.col-xs-offset-9 {
  margin-left: 75%;
}
.col-xs-offset-8 {
  margin-left: 66.66666667%;
}
.col-xs-offset-7 {
  margin-left: 58.33333333%;
}
.col-xs-offset-6 {
  margin-left: 50%;
}
.col-xs-offset-5 {
  margin-left: 41.66666667%;
}
.col-xs-offset-4 {
  margin-left: 33.33333333%;
}
.col-xs-offset-3 {
  margin-left: 25%;
}
.col-xs-offset-2 {
  margin-left: 16.66666667%;
}
.col-xs-offset-1 {
  margin-left: 8.33333333%;
}
.col-xs-offset-0 {
  margin-left: 0%;
}
@media (min-width: 768px) {
  .col-sm-1, .col-sm-2, .col-sm-3, .col-sm-4, .col-sm-5, .col-sm-6, .col-sm-7, .col-sm-8, .col-sm-9, .col-sm-10, .col-sm-11, .col-sm-12 {
    float: left;
  }
  .col-sm-12 {
    width: 100%;
  }
  .col-sm-11 {
    width: 91.66666667%;
  }
  .col-sm-10 {
    width: 83.33333333%;
  }
  .col-sm-9 {
    width: 75%;
  }
  .col-sm-8 {
    width: 66.66666667%;
  }
  .col-sm-7 {
    width: 58.33333333%;
  }
  .col-sm-6 {
    width: 50%;
  }
  .col-sm-5 {
    width: 41.66666667%;
  }
  .col-sm-4 {
    width: 33.33333333%;
  }
  .col-sm-3 {
    width: 25%;
  }
  .col-sm-2 {
    width: 16.66666667%;
  }
  .col-sm-1 {
    width: 8.33333333%;
  }
  .col-sm-pull-12 {
    right: 100%;
  }
  .col-sm-pull-11 {
    right: 91.66666667%;
  }
  .col-sm-pull-10 {
    right: 83.33333333%;
  }
  .col-sm-pull-9 {
    right: 75%;
  }
  .col-sm-pull-8 {
    right: 66.66666667%;
  }
  .col-sm-pull-7 {
    right: 58.33333333%;
  }
  .col-sm-pull-6 {
    right: 50%;
  }
  .col-sm-pull-5 {
    right: 41.66666667%;
  }
  .col-sm-pull-4 {
    right: 33.33333333%;
  }
  .col-sm-pull-3 {
    right: 25%;
  }
  .col-sm-pull-2 {
    right: 16.66666667%;
  }
  .col-sm-pull-1 {
    right: 8.33333333%;
  }
  .col-sm-pull-0 {
    right: auto;
  }
  .col-sm-push-12 {
    left: 100%;
  }
  .col-sm-push-11 {
    left: 91.66666667%;
  }
  .col-sm-push-10 {
    left: 83.33333333%;
  }
  .col-sm-push-9 {
    left: 75%;
  }
  .col-sm-push-8 {
    left: 66.66666667%;
  }
  .col-sm-push-7 {
    left: 58.33333333%;
  }
  .col-sm-push-6 {
    left: 50%;
  }
  .col-sm-push-5 {
    left: 41.66666667%;
  }
  .col-sm-push-4 {
    left: 33.33333333%;
  }
  .col-sm-push-3 {
    left: 25%;
  }
  .col-sm-push-2 {
    left: 16.66666667%;
  }
  .col-sm-push-1 {
    left: 8.33333333%;
  }
  .col-sm-push-0 {
    left: auto;
  }
  .col-sm-offset-12 {
    margin-left: 100%;
  }
  .col-sm-offset-11 {
    margin-left: 91.66666667%;
  }
  .col-sm-offset-10 {
    margin-left: 83.33333333%;
  }
  .col-sm-offset-9 {
    margin-left: 75%;
  }
  .col-sm-offset-8 {
    margin-left: 66.66666667%;
  }
  .col-sm-offset-7 {
    margin-left: 58.33333333%;
  }
  .col-sm-offset-6 {
    margin-left: 50%;
  }
  .col-sm-offset-5 {
    margin-left: 41.66666667%;
  }
  .col-sm-offset-4 {
    margin-left: 33.33333333%;
  }
  .col-sm-offset-3 {
    margin-left: 25%;
  }
  .col-sm-offset-2 {
    margin-left: 16.66666667%;
  }
  .col-sm-offset-1 {
    margin-left: 8.33333333%;
  }
  .col-sm-offset-0 {
    margin-left: 0%;
  }
}
@media (min-width: 992px) {
  .col-md-1, .col-md-2, .col-md-3, .col-md-4, .col-md-5, .col-md-6, .col-md-7, .col-md-8, .col-md-9, .col-md-10, .col-md-11, .col-md-12 {
    float: left;
  }
  .col-md-12 {
    width: 100%;
  }
  .col-md-11 {
    width: 91.66666667%;
  }
  .col-md-10 {
    width: 83.33333333%;
  }
  .col-md-9 {
    width: 75%;
  }
  .col-md-8 {
    width: 66.66666667%;
  }
  .col-md-7 {
    width: 58.33333333%;
  }
  .col-md-6 {
    width: 50%;
  }
  .col-md-5 {
    width: 41.66666667%;
  }
  .col-md-4 {
    width: 33.33333333%;
  }
  .col-md-3 {
    width: 25%;
  }
  .col-md-2 {
    width: 16.66666667%;
  }
  .col-md-1 {
    width: 8.33333333%;
  }
  .col-md-pull-12 {
    right: 100%;
  }
  .col-md-pull-11 {
    right: 91.66666667%;
  }
  .col-md-pull-10 {
    right: 83.33333333%;
  }
  .col-md-pull-9 {
    right: 75%;
  }
  .col-md-pull-8 {
    right: 66.66666667%;
  }
  .col-md-pull-7 {
    right: 58.33333333%;
  }
  .col-md-pull-6 {
    right: 50%;
  }
  .col-md-pull-5 {
    right: 41.66666667%;
  }
  .col-md-pull-4 {
    right: 33.33333333%;
  }
  .col-md-pull-3 {
    right: 25%;
  }
  .col-md-pull-2 {
    right: 16.66666667%;
  }
  .col-md-pull-1 {
    right: 8.33333333%;
  }
  .col-md-pull-0 {
    right: auto;
  }
  .col-md-push-12 {
    left: 100%;
  }
  .col-md-push-11 {
    left: 91.66666667%;
  }
  .col-md-push-10 {
    left: 83.33333333%;
  }
  .col-md-push-9 {
    left: 75%;
  }
  .col-md-push-8 {
    left: 66.66666667%;
  }
  .col-md-push-7 {
    left: 58.33333333%;
  }
  .col-md-push-6 {
    left: 50%;
  }
  .col-md-push-5 {
    left: 41.66666667%;
  }
  .col-md-push-4 {
    left: 33.33333333%;
  }
  .col-md-push-3 {
    left: 25%;
  }
  .col-md-push-2 {
    left: 16.66666667%;
  }
  .col-md-push-1 {
    left: 8.33333333%;
  }
  .col-md-push-0 {
    left: auto;
  }
  .col-md-offset-12 {
    margin-left: 100%;
  }
  .col-md-offset-11 {
    margin-left: 91.66666667%;
  }
  .col-md-offset-10 {
    margin-left: 83.33333333%;
  }
  .col-md-offset-9 {
    margin-left: 75%;
  }
  .col-md-offset-8 {
    margin-left: 66.66666667%;
  }
  .col-md-offset-7 {
    margin-left: 58.33333333%;
  }
  .col-md-offset-6 {
    margin-left: 50%;
  }
  .col-md-offset-5 {
    margin-left: 41.66666667%;
  }
  .col-md-offset-4 {
    margin-left: 33.33333333%;
  }
  .col-md-offset-3 {
    margin-left: 25%;
  }
  .col-md-offset-2 {
    margin-left: 16.66666667%;
  }
  .col-md-offset-1 {
    margin-left: 8.33333333%;
  }
  .col-md-offset-0 {
    margin-left: 0%;
  }
}
@media (min-width: 1200px) {
  .col-lg-1, .col-lg-2, .col-lg-3, .col-lg-4, .col-lg-5, .col-lg-6, .col-lg-7, .col-lg-8, .col-lg-9, .col-lg-10, .col-lg-11, .col-lg-12 {
    float: left;
  }
  .col-lg-12 {
    width: 100%;
  }
  .col-lg-11 {
    width: 91.66666667%;
  }
  .col-lg-10 {
    width: 83.33333333%;
  }
  .col-lg-9 {
    width: 75%;
  }
  .col-lg-8 {
    width: 66.66666667%;
  }
  .col-lg-7 {
    width: 58.33333333%;
  }
  .col-lg-6 {
    width: 50%;
  }
  .col-lg-5 {
    width: 41.66666667%;
  }
  .col-lg-4 {
    width: 33.33333333%;
  }
  .col-lg-3 {
    width: 25%;
  }
  .col-lg-2 {
    width: 16.66666667%;
  }
  .col-lg-1 {
    width: 8.33333333%;
  }
  .col-lg-pull-12 {
    right: 100%;
  }
  .col-lg-pull-11 {
    right: 91.66666667%;
  }
  .col-lg-pull-10 {
    right: 83.33333333%;
  }
  .col-lg-pull-9 {
    right: 75%;
  }
  .col-lg-pull-8 {
    right: 66.66666667%;
  }
  .col-lg-pull-7 {
    right: 58.33333333%;
  }
  .col-lg-pull-6 {
    right: 50%;
  }
  .col-lg-pull-5 {
    right: 41.66666667%;
  }
  .col-lg-pull-4 {
    right: 33.33333333%;
  }
  .col-lg-pull-3 {
    right: 25%;
  }
  .col-lg-pull-2 {
    right: 16.66666667%;
  }
  .col-lg-pull-1 {
    right: 8.33333333%;
  }
  .col-lg-pull-0 {
    right: auto;
  }
  .col-lg-push-12 {
    left: 100%;
  }
  .col-lg-push-11 {
    left: 91.66666667%;
  }
  .col-lg-push-10 {
    left: 83.33333333%;
  }
  .col-lg-push-9 {
    left: 75%;
  }
  .col-lg-push-8 {
    left: 66.66666667%;
  }
  .col-lg-push-7 {
    left: 58.33333333%;
  }
  .col-lg-push-6 {
    left: 50%;
  }
  .col-lg-push-5 {
    left: 41.66666667%;
  }
  .col-lg-push-4 {
    left: 33.33333333%;
  }
  .col-lg-push-3 {
    left: 25%;
  }
  .col-lg-push-2 {
    left: 16.66666667%;
  }
  .col-lg-push-1 {
    left: 8.33333333%;
  }
  .col-lg-push-0 {
    left: auto;
  }
  .col-lg-offset-12 {
    margin-left: 100%;
  }
  .col-lg-offset-11 {
    margin-left: 91.66666667%;
  }
  .col-lg-offset-10 {
    margin-left: 83.33333333%;
  }
  .col-lg-offset-9 {
    margin-left: 75%;
  }
  .col-lg-offset-8 {
    margin-left: 66.66666667%;
  }
  .col-lg-offset-7 {
    margin-left: 58.33333333%;
  }
  .col-lg-offset-6 {
    margin-left: 50%;
  }
  .col-lg-offset-5 {
    margin-left: 41.66666667%;
  }
  .col-lg-offset-4 {
    margin-left: 33.33333333%;
  }
  .col-lg-offset-3 {
    margin-left: 25%;
  }
  .col-lg-offset-2 {
    margin-left: 16.66666667%;
  }
  .col-lg-offset-1 {
    margin-left: 8.33333333%;
  }
  .col-lg-offset-0 {
    margin-left: 0%;
  }
}
table {
  background-color: transparent;
}
caption {
  padding-top: 8px;
  padding-bottom: 8px;
  color: #777777;
  text-align: left;
}
th {
  text-align: left;
}
.table {
  width: 100%;
  max-width: 100%;
  margin-bottom: 18px;
}
.table > thead > tr > th,
.table > tbody > tr > th,
.table > tfoot > tr > th,
.table > thead > tr > td,
.table > tbody > tr > td,
.table > tfoot > tr > td {
  padding: 8px;
  line-height: 1.42857143;
  vertical-align: top;
  border-top: 1px solid #ddd;
}
.table > thead > tr > th {
  vertical-align: bottom;
  border-bottom: 2px solid #ddd;
}
.table > caption + thead > tr:first-child > th,
.table > colgroup + thead > tr:first-child > th,
.table > thead:first-child > tr:first-child > th,
.table > caption + thead > tr:first-child > td,
.table > colgroup + thead > tr:first-child > td,
.table > thead:first-child > tr:first-child > td {
  border-top: 0;
}
.table > tbody + tbody {
  border-top: 2px solid #ddd;
}
.table .table {
  background-color: #fff;
}
.table-condensed > thead > tr > th,
.table-condensed > tbody > tr > th,
.table-condensed > tfoot > tr > th,
.table-condensed > thead > tr > td,
.table-condensed > tbody > tr > td,
.table-condensed > tfoot > tr > td {
  padding: 5px;
}
.table-bordered {
  border: 1px solid #ddd;
}
.table-bordered > thead > tr > th,
.table-bordered > tbody > tr > th,
.table-bordered > tfoot > tr > th,
.table-bordered > thead > tr > td,
.table-bordered > tbody > tr > td,
.table-bordered > tfoot > tr > td {
  border: 1px solid #ddd;
}
.table-bordered > thead > tr > th,
.table-bordered > thead > tr > td {
  border-bottom-width: 2px;
}
.table-striped > tbody > tr:nth-of-type(odd) {
  background-color: #f9f9f9;
}
.table-hover > tbody > tr:hover {
  background-color: #f5f5f5;
}
table col[class*="col-"] {
  position: static;
  float: none;
  display: table-column;
}
table td[class*="col-"],
table th[class*="col-"] {
  position: static;
  float: none;
  display: table-cell;
}
.table > thead > tr > td.active,
.table > tbody > tr > td.active,
.table > tfoot > tr > td.active,
.table > thead > tr > th.active,
.table > tbody > tr > th.active,
.table > tfoot > tr > th.active,
.table > thead > tr.active > td,
.table > tbody > tr.active > td,
.table > tfoot > tr.active > td,
.table > thead > tr.active > th,
.table > tbody > tr.active > th,
.table > tfoot > tr.active > th {
  background-color: #f5f5f5;
}
.table-hover > tbody > tr > td.active:hover,
.table-hover > tbody > tr > th.active:hover,
.table-hover > tbody > tr.active:hover > td,
.table-hover > tbody > tr:hover > .active,
.table-hover > tbody > tr.active:hover > th {
  background-color: #e8e8e8;
}
.table > thead > tr > td.success,
.table > tbody > tr > td.success,
.table > tfoot > tr > td.success,
.table > thead > tr > th.success,
.table > tbody > tr > th.success,
.table > tfoot > tr > th.success,
.table > thead > tr.success > td,
.table > tbody > tr.success > td,
.table > tfoot > tr.success > td,
.table > thead > tr.success > th,
.table > tbody > tr.success > th,
.table > tfoot > tr.success > th {
  background-color: #dff0d8;
}
.table-hover > tbody > tr > td.success:hover,
.table-hover > tbody > tr > th.success:hover,
.table-hover > tbody > tr.success:hover > td,
.table-hover > tbody > tr:hover > .success,
.table-hover > tbody > tr.success:hover > th {
  background-color: #d0e9c6;
}
.table > thead > tr > td.info,
.table > tbody > tr > td.info,
.table > tfoot > tr > td.info,
.table > thead > tr > th.info,
.table > tbody > tr > th.info,
.table > tfoot > tr > th.info,
.table > thead > tr.info > td,
.table > tbody > tr.info > td,
.table > tfoot > tr.info > td,
.table > thead > tr.info > th,
.table > tbody > tr.info > th,
.table > tfoot > tr.info > th {
  background-color: #d9edf7;
}
.table-hover > tbody > tr > td.info:hover,
.table-hover > tbody > tr > th.info:hover,
.table-hover > tbody > tr.info:hover > td,
.table-hover > tbody > tr:hover > .info,
.table-hover > tbody > tr.info:hover > th {
  background-color: #c4e3f3;
}
.table > thead > tr > td.warning,
.table > tbody > tr > td.warning,
.table > tfoot > tr > td.warning,
.table > thead > tr > th.warning,
.table > tbody > tr > th.warning,
.table > tfoot > tr > th.warning,
.table > thead > tr.warning > td,
.table > tbody > tr.warning > td,
.table > tfoot > tr.warning > td,
.table > thead > tr.warning > th,
.table > tbody > tr.warning > th,
.table > tfoot > tr.warning > th {
  background-color: #fcf8e3;
}
.table-hover > tbody > tr > td.warning:hover,
.table-hover > tbody > tr > th.warning:hover,
.table-hover > tbody > tr.warning:hover > td,
.table-hover > tbody > tr:hover > .warning,
.table-hover > tbody > tr.warning:hover > th {
  background-color: #faf2cc;
}
.table > thead > tr > td.danger,
.table > tbody > tr > td.danger,
.table > tfoot > tr > td.danger,
.table > thead > tr > th.danger,
.table > tbody > tr > th.danger,
.table > tfoot > tr > th.danger,
.table > thead > tr.danger > td,
.table > tbody > tr.danger > td,
.table > tfoot > tr.danger > td,
.table > thead > tr.danger > th,
.table > tbody > tr.danger > th,
.table > tfoot > tr.danger > th {
  background-color: #f2dede;
}
.table-hover > tbody > tr > td.danger:hover,
.table-hover > tbody > tr > th.danger:hover,
.table-hover > tbody > tr.danger:hover > td,
.table-hover > tbody > tr:hover > .danger,
.table-hover > tbody > tr.danger:hover > th {
  background-color: #ebcccc;
}
.table-responsive {
  overflow-x: auto;
  min-height: 0.01%;
}
@media screen and (max-width: 767px) {
  .table-responsive {
    width: 100%;
    margin-bottom: 13.5px;
    overflow-y: hidden;
    -ms-overflow-style: -ms-autohiding-scrollbar;
    border: 1px solid #ddd;
  }
  .table-responsive > .table {
    margin-bottom: 0;
  }
  .table-responsive > .table > thead > tr > th,
  .table-responsive > .table > tbody > tr > th,
  .table-responsive > .table > tfoot > tr > th,
  .table-responsive > .table > thead > tr > td,
  .table-responsive > .table > tbody > tr > td,
  .table-responsive > .table > tfoot > tr > td {
    white-space: nowrap;
  }
  .table-responsive > .table-bordered {
    border: 0;
  }
  .table-responsive > .table-bordered > thead > tr > th:first-child,
  .table-responsive > .table-bordered > tbody > tr > th:first-child,
  .table-responsive > .table-bordered > tfoot > tr > th:first-child,
  .table-responsive > .table-bordered > thead > tr > td:first-child,
  .table-responsive > .table-bordered > tbody > tr > td:first-child,
  .table-responsive > .table-bordered > tfoot > tr > td:first-child {
    border-left: 0;
  }
  .table-responsive > .table-bordered > thead > tr > th:last-child,
  .table-responsive > .table-bordered > tbody > tr > th:last-child,
  .table-responsive > .table-bordered > tfoot > tr > th:last-child,
  .table-responsive > .table-bordered > thead > tr > td:last-child,
  .table-responsive > .table-bordered > tbody > tr > td:last-child,
  .table-responsive > .table-bordered > tfoot > tr > td:last-child {
    border-right: 0;
  }
  .table-responsive > .table-bordered > tbody > tr:last-child > th,
  .table-responsive > .table-bordered > tfoot > tr:last-child > th,
  .table-responsive > .table-bordered > tbody > tr:last-child > td,
  .table-responsive > .table-bordered > tfoot > tr:last-child > td {
    border-bottom: 0;
  }
}
fieldset {
  padding: 0;
  margin: 0;
  border: 0;
  min-width: 0;
}
legend {
  display: block;
  width: 100%;
  padding: 0;
  margin-bottom: 18px;
  font-size: 19.5px;
  line-height: inherit;
  color: #333333;
  border: 0;
  border-bottom: 1px solid #e5e5e5;
}
label {
  display: inline-block;
  max-width: 100%;
  margin-bottom: 5px;
  font-weight: bold;
}
input[type="search"] {
  -webkit-box-sizing: border-box;
  -moz-box-sizing: border-box;
  box-sizing: border-box;
}
input[type="radio"],
input[type="checkbox"] {
  margin: 4px 0 0;
  margin-top: 1px \9;
  line-height: normal;
}
input[type="file"] {
  display: block;
}
input[type="range"] {
  display: block;
  width: 100%;
}
select[multiple],
select[size] {
  height: auto;
}
input[type="file"]:focus,
input[type="radio"]:focus,
input[type="checkbox"]:focus {
  outline: 5px auto -webkit-focus-ring-color;
  outline-offset: -2px;
}
output {
  display: block;
  padding-top: 7px;
  font-size: 13px;
  line-height: 1.42857143;
  color: #555555;
}
.form-control {
  display: block;
  width: 100%;
  height: 32px;
  padding: 6px 12px;
  font-size: 13px;
  line-height: 1.42857143;
  color: #555555;
  background-color: #fff;
  background-image: none;
  border: 1px solid #ccc;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  -webkit-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  -o-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
}
.form-control:focus {
  border-color: #66afe9;
  outline: 0;
  -webkit-box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
  box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
}
.form-control::-moz-placeholder {
  color: #999;
  opacity: 1;
}
.form-control:-ms-input-placeholder {
  color: #999;
}
.form-control::-webkit-input-placeholder {
  color: #999;
}
.form-control::-ms-expand {
  border: 0;
  background-color: transparent;
}
.form-control[disabled],
.form-control[readonly],
fieldset[disabled] .form-control {
  background-color: #eeeeee;
  opacity: 1;
}
.form-control[disabled],
fieldset[disabled] .form-control {
  cursor: not-allowed;
}
textarea.form-control {
  height: auto;
}
input[type="search"] {
  -webkit-appearance: none;
}
@media screen and (-webkit-min-device-pixel-ratio: 0) {
  input[type="date"].form-control,
  input[type="time"].form-control,
  input[type="datetime-local"].form-control,
  input[type="month"].form-control {
    line-height: 32px;
  }
  input[type="date"].input-sm,
  input[type="time"].input-sm,
  input[type="datetime-local"].input-sm,
  input[type="month"].input-sm,
  .input-group-sm input[type="date"],
  .input-group-sm input[type="time"],
  .input-group-sm input[type="datetime-local"],
  .input-group-sm input[type="month"] {
    line-height: 30px;
  }
  input[type="date"].input-lg,
  input[type="time"].input-lg,
  input[type="datetime-local"].input-lg,
  input[type="month"].input-lg,
  .input-group-lg input[type="date"],
  .input-group-lg input[type="time"],
  .input-group-lg input[type="datetime-local"],
  .input-group-lg input[type="month"] {
    line-height: 45px;
  }
}
.form-group {
  margin-bottom: 15px;
}
.radio,
.checkbox {
  position: relative;
  display: block;
  margin-top: 10px;
  margin-bottom: 10px;
}
.radio label,
.checkbox label {
  min-height: 18px;
  padding-left: 20px;
  margin-bottom: 0;
  font-weight: normal;
  cursor: pointer;
}
.radio input[type="radio"],
.radio-inline input[type="radio"],
.checkbox input[type="checkbox"],
.checkbox-inline input[type="checkbox"] {
  position: absolute;
  margin-left: -20px;
  margin-top: 4px \9;
}
.radio + .radio,
.checkbox + .checkbox {
  margin-top: -5px;
}
.radio-inline,
.checkbox-inline {
  position: relative;
  display: inline-block;
  padding-left: 20px;
  margin-bottom: 0;
  vertical-align: middle;
  font-weight: normal;
  cursor: pointer;
}
.radio-inline + .radio-inline,
.checkbox-inline + .checkbox-inline {
  margin-top: 0;
  margin-left: 10px;
}
input[type="radio"][disabled],
input[type="checkbox"][disabled],
input[type="radio"].disabled,
input[type="checkbox"].disabled,
fieldset[disabled] input[type="radio"],
fieldset[disabled] input[type="checkbox"] {
  cursor: not-allowed;
}
.radio-inline.disabled,
.checkbox-inline.disabled,
fieldset[disabled] .radio-inline,
fieldset[disabled] .checkbox-inline {
  cursor: not-allowed;
}
.radio.disabled label,
.checkbox.disabled label,
fieldset[disabled] .radio label,
fieldset[disabled] .checkbox label {
  cursor: not-allowed;
}
.form-control-static {
  padding-top: 7px;
  padding-bottom: 7px;
  margin-bottom: 0;
  min-height: 31px;
}
.form-control-static.input-lg,
.form-control-static.input-sm {
  padding-left: 0;
  padding-right: 0;
}
.input-sm {
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
select.input-sm {
  height: 30px;
  line-height: 30px;
}
textarea.input-sm,
select[multiple].input-sm {
  height: auto;
}
.form-group-sm .form-control {
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
.form-group-sm select.form-control {
  height: 30px;
  line-height: 30px;
}
.form-group-sm textarea.form-control,
.form-group-sm select[multiple].form-control {
  height: auto;
}
.form-group-sm .form-control-static {
  height: 30px;
  min-height: 30px;
  padding: 6px 10px;
  font-size: 12px;
  line-height: 1.5;
}
.input-lg {
  height: 45px;
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
select.input-lg {
  height: 45px;
  line-height: 45px;
}
textarea.input-lg,
select[multiple].input-lg {
  height: auto;
}
.form-group-lg .form-control {
  height: 45px;
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
.form-group-lg select.form-control {
  height: 45px;
  line-height: 45px;
}
.form-group-lg textarea.form-control,
.form-group-lg select[multiple].form-control {
  height: auto;
}
.form-group-lg .form-control-static {
  height: 45px;
  min-height: 35px;
  padding: 11px 16px;
  font-size: 17px;
  line-height: 1.3333333;
}
.has-feedback {
  position: relative;
}
.has-feedback .form-control {
  padding-right: 40px;
}
.form-control-feedback {
  position: absolute;
  top: 0;
  right: 0;
  z-index: 2;
  display: block;
  width: 32px;
  height: 32px;
  line-height: 32px;
  text-align: center;
  pointer-events: none;
}
.input-lg + .form-control-feedback,
.input-group-lg + .form-control-feedback,
.form-group-lg .form-control + .form-control-feedback {
  width: 45px;
  height: 45px;
  line-height: 45px;
}
.input-sm + .form-control-feedback,
.input-group-sm + .form-control-feedback,
.form-group-sm .form-control + .form-control-feedback {
  width: 30px;
  height: 30px;
  line-height: 30px;
}
.has-success .help-block,
.has-success .control-label,
.has-success .radio,
.has-success .checkbox,
.has-success .radio-inline,
.has-success .checkbox-inline,
.has-success.radio label,
.has-success.checkbox label,
.has-success.radio-inline label,
.has-success.checkbox-inline label {
  color: #3c763d;
}
.has-success .form-control {
  border-color: #3c763d;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
}
.has-success .form-control:focus {
  border-color: #2b542c;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #67b168;
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #67b168;
}
.has-success .input-group-addon {
  color: #3c763d;
  border-color: #3c763d;
  background-color: #dff0d8;
}
.has-success .form-control-feedback {
  color: #3c763d;
}
.has-warning .help-block,
.has-warning .control-label,
.has-warning .radio,
.has-warning .checkbox,
.has-warning .radio-inline,
.has-warning .checkbox-inline,
.has-warning.radio label,
.has-warning.checkbox label,
.has-warning.radio-inline label,
.has-warning.checkbox-inline label {
  color: #8a6d3b;
}
.has-warning .form-control {
  border-color: #8a6d3b;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
}
.has-warning .form-control:focus {
  border-color: #66512c;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #c0a16b;
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #c0a16b;
}
.has-warning .input-group-addon {
  color: #8a6d3b;
  border-color: #8a6d3b;
  background-color: #fcf8e3;
}
.has-warning .form-control-feedback {
  color: #8a6d3b;
}
.has-error .help-block,
.has-error .control-label,
.has-error .radio,
.has-error .checkbox,
.has-error .radio-inline,
.has-error .checkbox-inline,
.has-error.radio label,
.has-error.checkbox label,
.has-error.radio-inline label,
.has-error.checkbox-inline label {
  color: #a94442;
}
.has-error .form-control {
  border-color: #a94442;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
}
.has-error .form-control:focus {
  border-color: #843534;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #ce8483;
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #ce8483;
}
.has-error .input-group-addon {
  color: #a94442;
  border-color: #a94442;
  background-color: #f2dede;
}
.has-error .form-control-feedback {
  color: #a94442;
}
.has-feedback label ~ .form-control-feedback {
  top: 23px;
}
.has-feedback label.sr-only ~ .form-control-feedback {
  top: 0;
}
.help-block {
  display: block;
  margin-top: 5px;
  margin-bottom: 10px;
  color: #404040;
}
@media (min-width: 768px) {
  .form-inline .form-group {
    display: inline-block;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .form-inline .form-control {
    display: inline-block;
    width: auto;
    vertical-align: middle;
  }
  .form-inline .form-control-static {
    display: inline-block;
  }
  .form-inline .input-group {
    display: inline-table;
    vertical-align: middle;
  }
  .form-inline .input-group .input-group-addon,
  .form-inline .input-group .input-group-btn,
  .form-inline .input-group .form-control {
    width: auto;
  }
  .form-inline .input-group > .form-control {
    width: 100%;
  }
  .form-inline .control-label {
    margin-bottom: 0;
    vertical-align: middle;
  }
  .form-inline .radio,
  .form-inline .checkbox {
    display: inline-block;
    margin-top: 0;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .form-inline .radio label,
  .form-inline .checkbox label {
    padding-left: 0;
  }
  .form-inline .radio input[type="radio"],
  .form-inline .checkbox input[type="checkbox"] {
    position: relative;
    margin-left: 0;
  }
  .form-inline .has-feedback .form-control-feedback {
    top: 0;
  }
}
.form-horizontal .radio,
.form-horizontal .checkbox,
.form-horizontal .radio-inline,
.form-horizontal .checkbox-inline {
  margin-top: 0;
  margin-bottom: 0;
  padding-top: 7px;
}
.form-horizontal .radio,
.form-horizontal .checkbox {
  min-height: 25px;
}
.form-horizontal .form-group {
  margin-left: 0px;
  margin-right: 0px;
}
@media (min-width: 768px) {
  .form-horizontal .control-label {
    text-align: right;
    margin-bottom: 0;
    padding-top: 7px;
  }
}
.form-horizontal .has-feedback .form-control-feedback {
  right: 0px;
}
@media (min-width: 768px) {
  .form-horizontal .form-group-lg .control-label {
    padding-top: 11px;
    font-size: 17px;
  }
}
@media (min-width: 768px) {
  .form-horizontal .form-group-sm .control-label {
    padding-top: 6px;
    font-size: 12px;
  }
}
.btn {
  display: inline-block;
  margin-bottom: 0;
  font-weight: normal;
  text-align: center;
  vertical-align: middle;
  touch-action: manipulation;
  cursor: pointer;
  background-image: none;
  border: 1px solid transparent;
  white-space: nowrap;
  padding: 6px 12px;
  font-size: 13px;
  line-height: 1.42857143;
  border-radius: 2px;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}
.btn:focus,
.btn:active:focus,
.btn.active:focus,
.btn.focus,
.btn:active.focus,
.btn.active.focus {
  outline: 5px auto -webkit-focus-ring-color;
  outline-offset: -2px;
}
.btn:hover,
.btn:focus,
.btn.focus {
  color: #333;
  text-decoration: none;
}
.btn:active,
.btn.active {
  outline: 0;
  background-image: none;
  -webkit-box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
  box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
}
.btn.disabled,
.btn[disabled],
fieldset[disabled] .btn {
  cursor: not-allowed;
  opacity: 0.65;
  filter: alpha(opacity=65);
  -webkit-box-shadow: none;
  box-shadow: none;
}
a.btn.disabled,
fieldset[disabled] a.btn {
  pointer-events: none;
}
.btn-default {
  color: #333;
  background-color: #fff;
  border-color: #ccc;
}
.btn-default:focus,
.btn-default.focus {
  color: #333;
  background-color: #e6e6e6;
  border-color: #8c8c8c;
}
.btn-default:hover {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.btn-default:active,
.btn-default.active,
.open > .dropdown-toggle.btn-default {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.btn-default:active:hover,
.btn-default.active:hover,
.open > .dropdown-toggle.btn-default:hover,
.btn-default:active:focus,
.btn-default.active:focus,
.open > .dropdown-toggle.btn-default:focus,
.btn-default:active.focus,
.btn-default.active.focus,
.open > .dropdown-toggle.btn-default.focus {
  color: #333;
  background-color: #d4d4d4;
  border-color: #8c8c8c;
}
.btn-default:active,
.btn-default.active,
.open > .dropdown-toggle.btn-default {
  background-image: none;
}
.btn-default.disabled:hover,
.btn-default[disabled]:hover,
fieldset[disabled] .btn-default:hover,
.btn-default.disabled:focus,
.btn-default[disabled]:focus,
fieldset[disabled] .btn-default:focus,
.btn-default.disabled.focus,
.btn-default[disabled].focus,
fieldset[disabled] .btn-default.focus {
  background-color: #fff;
  border-color: #ccc;
}
.btn-default .badge {
  color: #fff;
  background-color: #333;
}
.btn-primary {
  color: #fff;
  background-color: #337ab7;
  border-color: #2e6da4;
}
.btn-primary:focus,
.btn-primary.focus {
  color: #fff;
  background-color: #286090;
  border-color: #122b40;
}
.btn-primary:hover {
  color: #fff;
  background-color: #286090;
  border-color: #204d74;
}
.btn-primary:active,
.btn-primary.active,
.open > .dropdown-toggle.btn-primary {
  color: #fff;
  background-color: #286090;
  border-color: #204d74;
}
.btn-primary:active:hover,
.btn-primary.active:hover,
.open > .dropdown-toggle.btn-primary:hover,
.btn-primary:active:focus,
.btn-primary.active:focus,
.open > .dropdown-toggle.btn-primary:focus,
.btn-primary:active.focus,
.btn-primary.active.focus,
.open > .dropdown-toggle.btn-primary.focus {
  color: #fff;
  background-color: #204d74;
  border-color: #122b40;
}
.btn-primary:active,
.btn-primary.active,
.open > .dropdown-toggle.btn-primary {
  background-image: none;
}
.btn-primary.disabled:hover,
.btn-primary[disabled]:hover,
fieldset[disabled] .btn-primary:hover,
.btn-primary.disabled:focus,
.btn-primary[disabled]:focus,
fieldset[disabled] .btn-primary:focus,
.btn-primary.disabled.focus,
.btn-primary[disabled].focus,
fieldset[disabled] .btn-primary.focus {
  background-color: #337ab7;
  border-color: #2e6da4;
}
.btn-primary .badge {
  color: #337ab7;
  background-color: #fff;
}
.btn-success {
  color: #fff;
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.btn-success:focus,
.btn-success.focus {
  color: #fff;
  background-color: #449d44;
  border-color: #255625;
}
.btn-success:hover {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.btn-success:active,
.btn-success.active,
.open > .dropdown-toggle.btn-success {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.btn-success:active:hover,
.btn-success.active:hover,
.open > .dropdown-toggle.btn-success:hover,
.btn-success:active:focus,
.btn-success.active:focus,
.open > .dropdown-toggle.btn-success:focus,
.btn-success:active.focus,
.btn-success.active.focus,
.open > .dropdown-toggle.btn-success.focus {
  color: #fff;
  background-color: #398439;
  border-color: #255625;
}
.btn-success:active,
.btn-success.active,
.open > .dropdown-toggle.btn-success {
  background-image: none;
}
.btn-success.disabled:hover,
.btn-success[disabled]:hover,
fieldset[disabled] .btn-success:hover,
.btn-success.disabled:focus,
.btn-success[disabled]:focus,
fieldset[disabled] .btn-success:focus,
.btn-success.disabled.focus,
.btn-success[disabled].focus,
fieldset[disabled] .btn-success.focus {
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.btn-success .badge {
  color: #5cb85c;
  background-color: #fff;
}
.btn-info {
  color: #fff;
  background-color: #5bc0de;
  border-color: #46b8da;
}
.btn-info:focus,
.btn-info.focus {
  color: #fff;
  background-color: #31b0d5;
  border-color: #1b6d85;
}
.btn-info:hover {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.btn-info:active,
.btn-info.active,
.open > .dropdown-toggle.btn-info {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.btn-info:active:hover,
.btn-info.active:hover,
.open > .dropdown-toggle.btn-info:hover,
.btn-info:active:focus,
.btn-info.active:focus,
.open > .dropdown-toggle.btn-info:focus,
.btn-info:active.focus,
.btn-info.active.focus,
.open > .dropdown-toggle.btn-info.focus {
  color: #fff;
  background-color: #269abc;
  border-color: #1b6d85;
}
.btn-info:active,
.btn-info.active,
.open > .dropdown-toggle.btn-info {
  background-image: none;
}
.btn-info.disabled:hover,
.btn-info[disabled]:hover,
fieldset[disabled] .btn-info:hover,
.btn-info.disabled:focus,
.btn-info[disabled]:focus,
fieldset[disabled] .btn-info:focus,
.btn-info.disabled.focus,
.btn-info[disabled].focus,
fieldset[disabled] .btn-info.focus {
  background-color: #5bc0de;
  border-color: #46b8da;
}
.btn-info .badge {
  color: #5bc0de;
  background-color: #fff;
}
.btn-warning {
  color: #fff;
  background-color: #f0ad4e;
  border-color: #eea236;
}
.btn-warning:focus,
.btn-warning.focus {
  color: #fff;
  background-color: #ec971f;
  border-color: #985f0d;
}
.btn-warning:hover {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.btn-warning:active,
.btn-warning.active,
.open > .dropdown-toggle.btn-warning {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.btn-warning:active:hover,
.btn-warning.active:hover,
.open > .dropdown-toggle.btn-warning:hover,
.btn-warning:active:focus,
.btn-warning.active:focus,
.open > .dropdown-toggle.btn-warning:focus,
.btn-warning:active.focus,
.btn-warning.active.focus,
.open > .dropdown-toggle.btn-warning.focus {
  color: #fff;
  background-color: #d58512;
  border-color: #985f0d;
}
.btn-warning:active,
.btn-warning.active,
.open > .dropdown-toggle.btn-warning {
  background-image: none;
}
.btn-warning.disabled:hover,
.btn-warning[disabled]:hover,
fieldset[disabled] .btn-warning:hover,
.btn-warning.disabled:focus,
.btn-warning[disabled]:focus,
fieldset[disabled] .btn-warning:focus,
.btn-warning.disabled.focus,
.btn-warning[disabled].focus,
fieldset[disabled] .btn-warning.focus {
  background-color: #f0ad4e;
  border-color: #eea236;
}
.btn-warning .badge {
  color: #f0ad4e;
  background-color: #fff;
}
.btn-danger {
  color: #fff;
  background-color: #d9534f;
  border-color: #d43f3a;
}
.btn-danger:focus,
.btn-danger.focus {
  color: #fff;
  background-color: #c9302c;
  border-color: #761c19;
}
.btn-danger:hover {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.btn-danger:active,
.btn-danger.active,
.open > .dropdown-toggle.btn-danger {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.btn-danger:active:hover,
.btn-danger.active:hover,
.open > .dropdown-toggle.btn-danger:hover,
.btn-danger:active:focus,
.btn-danger.active:focus,
.open > .dropdown-toggle.btn-danger:focus,
.btn-danger:active.focus,
.btn-danger.active.focus,
.open > .dropdown-toggle.btn-danger.focus {
  color: #fff;
  background-color: #ac2925;
  border-color: #761c19;
}
.btn-danger:active,
.btn-danger.active,
.open > .dropdown-toggle.btn-danger {
  background-image: none;
}
.btn-danger.disabled:hover,
.btn-danger[disabled]:hover,
fieldset[disabled] .btn-danger:hover,
.btn-danger.disabled:focus,
.btn-danger[disabled]:focus,
fieldset[disabled] .btn-danger:focus,
.btn-danger.disabled.focus,
.btn-danger[disabled].focus,
fieldset[disabled] .btn-danger.focus {
  background-color: #d9534f;
  border-color: #d43f3a;
}
.btn-danger .badge {
  color: #d9534f;
  background-color: #fff;
}
.btn-link {
  color: #337ab7;
  font-weight: normal;
  border-radius: 0;
}
.btn-link,
.btn-link:active,
.btn-link.active,
.btn-link[disabled],
fieldset[disabled] .btn-link {
  background-color: transparent;
  -webkit-box-shadow: none;
  box-shadow: none;
}
.btn-link,
.btn-link:hover,
.btn-link:focus,
.btn-link:active {
  border-color: transparent;
}
.btn-link:hover,
.btn-link:focus {
  color: #23527c;
  text-decoration: underline;
  background-color: transparent;
}
.btn-link[disabled]:hover,
fieldset[disabled] .btn-link:hover,
.btn-link[disabled]:focus,
fieldset[disabled] .btn-link:focus {
  color: #777777;
  text-decoration: none;
}
.btn-lg,
.btn-group-lg > .btn {
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
.btn-sm,
.btn-group-sm > .btn {
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
.btn-xs,
.btn-group-xs > .btn {
  padding: 1px 5px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
.btn-block {
  display: block;
  width: 100%;
}
.btn-block + .btn-block {
  margin-top: 5px;
}
input[type="submit"].btn-block,
input[type="reset"].btn-block,
input[type="button"].btn-block {
  width: 100%;
}
.fade {
  opacity: 0;
  -webkit-transition: opacity 0.15s linear;
  -o-transition: opacity 0.15s linear;
  transition: opacity 0.15s linear;
}
.fade.in {
  opacity: 1;
}
.collapse {
  display: none;
}
.collapse.in {
  display: block;
}
tr.collapse.in {
  display: table-row;
}
tbody.collapse.in {
  display: table-row-group;
}
.collapsing {
  position: relative;
  height: 0;
  overflow: hidden;
  -webkit-transition-property: height, visibility;
  transition-property: height, visibility;
  -webkit-transition-duration: 0.35s;
  transition-duration: 0.35s;
  -webkit-transition-timing-function: ease;
  transition-timing-function: ease;
}
.caret {
  display: inline-block;
  width: 0;
  height: 0;
  margin-left: 2px;
  vertical-align: middle;
  border-top: 4px dashed;
  border-top: 4px solid \9;
  border-right: 4px solid transparent;
  border-left: 4px solid transparent;
}
.dropup,
.dropdown {
  position: relative;
}
.dropdown-toggle:focus {
  outline: 0;
}
.dropdown-menu {
  position: absolute;
  top: 100%;
  left: 0;
  z-index: 1000;
  display: none;
  float: left;
  min-width: 160px;
  padding: 5px 0;
  margin: 2px 0 0;
  list-style: none;
  font-size: 13px;
  text-align: left;
  background-color: #fff;
  border: 1px solid #ccc;
  border: 1px solid rgba(0, 0, 0, 0.15);
  border-radius: 2px;
  -webkit-box-shadow: 0 6px 12px rgba(0, 0, 0, 0.175);
  box-shadow: 0 6px 12px rgba(0, 0, 0, 0.175);
  background-clip: padding-box;
}
.dropdown-menu.pull-right {
  right: 0;
  left: auto;
}
.dropdown-menu .divider {
  height: 1px;
  margin: 8px 0;
  overflow: hidden;
  background-color: #e5e5e5;
}
.dropdown-menu > li > a {
  display: block;
  padding: 3px 20px;
  clear: both;
  font-weight: normal;
  line-height: 1.42857143;
  color: #333333;
  white-space: nowrap;
}
.dropdown-menu > li > a:hover,
.dropdown-menu > li > a:focus {
  text-decoration: none;
  color: #262626;
  background-color: #f5f5f5;
}
.dropdown-menu > .active > a,
.dropdown-menu > .active > a:hover,
.dropdown-menu > .active > a:focus {
  color: #fff;
  text-decoration: none;
  outline: 0;
  background-color: #337ab7;
}
.dropdown-menu > .disabled > a,
.dropdown-menu > .disabled > a:hover,
.dropdown-menu > .disabled > a:focus {
  color: #777777;
}
.dropdown-menu > .disabled > a:hover,
.dropdown-menu > .disabled > a:focus {
  text-decoration: none;
  background-color: transparent;
  background-image: none;
  filter: progid:DXImageTransform.Microsoft.gradient(enabled = false);
  cursor: not-allowed;
}
.open > .dropdown-menu {
  display: block;
}
.open > a {
  outline: 0;
}
.dropdown-menu-right {
  left: auto;
  right: 0;
}
.dropdown-menu-left {
  left: 0;
  right: auto;
}
.dropdown-header {
  display: block;
  padding: 3px 20px;
  font-size: 12px;
  line-height: 1.42857143;
  color: #777777;
  white-space: nowrap;
}
.dropdown-backdrop {
  position: fixed;
  left: 0;
  right: 0;
  bottom: 0;
  top: 0;
  z-index: 990;
}
.pull-right > .dropdown-menu {
  right: 0;
  left: auto;
}
.dropup .caret,
.navbar-fixed-bottom .dropdown .caret {
  border-top: 0;
  border-bottom: 4px dashed;
  border-bottom: 4px solid \9;
  content: "";
}
.dropup .dropdown-menu,
.navbar-fixed-bottom .dropdown .dropdown-menu {
  top: auto;
  bottom: 100%;
  margin-bottom: 2px;
}
@media (min-width: 541px) {
  .navbar-right .dropdown-menu {
    left: auto;
    right: 0;
  }
  .navbar-right .dropdown-menu-left {
    left: 0;
    right: auto;
  }
}
.btn-group,
.btn-group-vertical {
  position: relative;
  display: inline-block;
  vertical-align: middle;
}
.btn-group > .btn,
.btn-group-vertical > .btn {
  position: relative;
  float: left;
}
.btn-group > .btn:hover,
.btn-group-vertical > .btn:hover,
.btn-group > .btn:focus,
.btn-group-vertical > .btn:focus,
.btn-group > .btn:active,
.btn-group-vertical > .btn:active,
.btn-group > .btn.active,
.btn-group-vertical > .btn.active {
  z-index: 2;
}
.btn-group .btn + .btn,
.btn-group .btn + .btn-group,
.btn-group .btn-group + .btn,
.btn-group .btn-group + .btn-group {
  margin-left: -1px;
}
.btn-toolbar {
  margin-left: -5px;
}
.btn-toolbar .btn,
.btn-toolbar .btn-group,
.btn-toolbar .input-group {
  float: left;
}
.btn-toolbar > .btn,
.btn-toolbar > .btn-group,
.btn-toolbar > .input-group {
  margin-left: 5px;
}
.btn-group > .btn:not(:first-child):not(:last-child):not(.dropdown-toggle) {
  border-radius: 0;
}
.btn-group > .btn:first-child {
  margin-left: 0;
}
.btn-group > .btn:first-child:not(:last-child):not(.dropdown-toggle) {
  border-bottom-right-radius: 0;
  border-top-right-radius: 0;
}
.btn-group > .btn:last-child:not(:first-child),
.btn-group > .dropdown-toggle:not(:first-child) {
  border-bottom-left-radius: 0;
  border-top-left-radius: 0;
}
.btn-group > .btn-group {
  float: left;
}
.btn-group > .btn-group:not(:first-child):not(:last-child) > .btn {
  border-radius: 0;
}
.btn-group > .btn-group:first-child:not(:last-child) > .btn:last-child,
.btn-group > .btn-group:first-child:not(:last-child) > .dropdown-toggle {
  border-bottom-right-radius: 0;
  border-top-right-radius: 0;
}
.btn-group > .btn-group:last-child:not(:first-child) > .btn:first-child {
  border-bottom-left-radius: 0;
  border-top-left-radius: 0;
}
.btn-group .dropdown-toggle:active,
.btn-group.open .dropdown-toggle {
  outline: 0;
}
.btn-group > .btn + .dropdown-toggle {
  padding-left: 8px;
  padding-right: 8px;
}
.btn-group > .btn-lg + .dropdown-toggle {
  padding-left: 12px;
  padding-right: 12px;
}
.btn-group.open .dropdown-toggle {
  -webkit-box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
  box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
}
.btn-group.open .dropdown-toggle.btn-link {
  -webkit-box-shadow: none;
  box-shadow: none;
}
.btn .caret {
  margin-left: 0;
}
.btn-lg .caret {
  border-width: 5px 5px 0;
  border-bottom-width: 0;
}
.dropup .btn-lg .caret {
  border-width: 0 5px 5px;
}
.btn-group-vertical > .btn,
.btn-group-vertical > .btn-group,
.btn-group-vertical > .btn-group > .btn {
  display: block;
  float: none;
  width: 100%;
  max-width: 100%;
}
.btn-group-vertical > .btn-group > .btn {
  float: none;
}
.btn-group-vertical > .btn + .btn,
.btn-group-vertical > .btn + .btn-group,
.btn-group-vertical > .btn-group + .btn,
.btn-group-vertical > .btn-group + .btn-group {
  margin-top: -1px;
  margin-left: 0;
}
.btn-group-vertical > .btn:not(:first-child):not(:last-child) {
  border-radius: 0;
}
.btn-group-vertical > .btn:first-child:not(:last-child) {
  border-top-right-radius: 2px;
  border-top-left-radius: 2px;
  border-bottom-right-radius: 0;
  border-bottom-left-radius: 0;
}
.btn-group-vertical > .btn:last-child:not(:first-child) {
  border-top-right-radius: 0;
  border-top-left-radius: 0;
  border-bottom-right-radius: 2px;
  border-bottom-left-radius: 2px;
}
.btn-group-vertical > .btn-group:not(:first-child):not(:last-child) > .btn {
  border-radius: 0;
}
.btn-group-vertical > .btn-group:first-child:not(:last-child) > .btn:last-child,
.btn-group-vertical > .btn-group:first-child:not(:last-child) > .dropdown-toggle {
  border-bottom-right-radius: 0;
  border-bottom-left-radius: 0;
}
.btn-group-vertical > .btn-group:last-child:not(:first-child) > .btn:first-child {
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.btn-group-justified {
  display: table;
  width: 100%;
  table-layout: fixed;
  border-collapse: separate;
}
.btn-group-justified > .btn,
.btn-group-justified > .btn-group {
  float: none;
  display: table-cell;
  width: 1%;
}
.btn-group-justified > .btn-group .btn {
  width: 100%;
}
.btn-group-justified > .btn-group .dropdown-menu {
  left: auto;
}
[data-toggle="buttons"] > .btn input[type="radio"],
[data-toggle="buttons"] > .btn-group > .btn input[type="radio"],
[data-toggle="buttons"] > .btn input[type="checkbox"],
[data-toggle="buttons"] > .btn-group > .btn input[type="checkbox"] {
  position: absolute;
  clip: rect(0, 0, 0, 0);
  pointer-events: none;
}
.input-group {
  position: relative;
  display: table;
  border-collapse: separate;
}
.input-group[class*="col-"] {
  float: none;
  padding-left: 0;
  padding-right: 0;
}
.input-group .form-control {
  position: relative;
  z-index: 2;
  float: left;
  width: 100%;
  margin-bottom: 0;
}
.input-group .form-control:focus {
  z-index: 3;
}
.input-group-lg > .form-control,
.input-group-lg > .input-group-addon,
.input-group-lg > .input-group-btn > .btn {
  height: 45px;
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
select.input-group-lg > .form-control,
select.input-group-lg > .input-group-addon,
select.input-group-lg > .input-group-btn > .btn {
  height: 45px;
  line-height: 45px;
}
textarea.input-group-lg > .form-control,
textarea.input-group-lg > .input-group-addon,
textarea.input-group-lg > .input-group-btn > .btn,
select[multiple].input-group-lg > .form-control,
select[multiple].input-group-lg > .input-group-addon,
select[multiple].input-group-lg > .input-group-btn > .btn {
  height: auto;
}
.input-group-sm > .form-control,
.input-group-sm > .input-group-addon,
.input-group-sm > .input-group-btn > .btn {
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
select.input-group-sm > .form-control,
select.input-group-sm > .input-group-addon,
select.input-group-sm > .input-group-btn > .btn {
  height: 30px;
  line-height: 30px;
}
textarea.input-group-sm > .form-control,
textarea.input-group-sm > .input-group-addon,
textarea.input-group-sm > .input-group-btn > .btn,
select[multiple].input-group-sm > .form-control,
select[multiple].input-group-sm > .input-group-addon,
select[multiple].input-group-sm > .input-group-btn > .btn {
  height: auto;
}
.input-group-addon,
.input-group-btn,
.input-group .form-control {
  display: table-cell;
}
.input-group-addon:not(:first-child):not(:last-child),
.input-group-btn:not(:first-child):not(:last-child),
.input-group .form-control:not(:first-child):not(:last-child) {
  border-radius: 0;
}
.input-group-addon,
.input-group-btn {
  width: 1%;
  white-space: nowrap;
  vertical-align: middle;
}
.input-group-addon {
  padding: 6px 12px;
  font-size: 13px;
  font-weight: normal;
  line-height: 1;
  color: #555555;
  text-align: center;
  background-color: #eeeeee;
  border: 1px solid #ccc;
  border-radius: 2px;
}
.input-group-addon.input-sm {
  padding: 5px 10px;
  font-size: 12px;
  border-radius: 1px;
}
.input-group-addon.input-lg {
  padding: 10px 16px;
  font-size: 17px;
  border-radius: 3px;
}
.input-group-addon input[type="radio"],
.input-group-addon input[type="checkbox"] {
  margin-top: 0;
}
.input-group .form-control:first-child,
.input-group-addon:first-child,
.input-group-btn:first-child > .btn,
.input-group-btn:first-child > .btn-group > .btn,
.input-group-btn:first-child > .dropdown-toggle,
.input-group-btn:last-child > .btn:not(:last-child):not(.dropdown-toggle),
.input-group-btn:last-child > .btn-group:not(:last-child) > .btn {
  border-bottom-right-radius: 0;
  border-top-right-radius: 0;
}
.input-group-addon:first-child {
  border-right: 0;
}
.input-group .form-control:last-child,
.input-group-addon:last-child,
.input-group-btn:last-child > .btn,
.input-group-btn:last-child > .btn-group > .btn,
.input-group-btn:last-child > .dropdown-toggle,
.input-group-btn:first-child > .btn:not(:first-child),
.input-group-btn:first-child > .btn-group:not(:first-child) > .btn {
  border-bottom-left-radius: 0;
  border-top-left-radius: 0;
}
.input-group-addon:last-child {
  border-left: 0;
}
.input-group-btn {
  position: relative;
  font-size: 0;
  white-space: nowrap;
}
.input-group-btn > .btn {
  position: relative;
}
.input-group-btn > .btn + .btn {
  margin-left: -1px;
}
.input-group-btn > .btn:hover,
.input-group-btn > .btn:focus,
.input-group-btn > .btn:active {
  z-index: 2;
}
.input-group-btn:first-child > .btn,
.input-group-btn:first-child > .btn-group {
  margin-right: -1px;
}
.input-group-btn:last-child > .btn,
.input-group-btn:last-child > .btn-group {
  z-index: 2;
  margin-left: -1px;
}
.nav {
  margin-bottom: 0;
  padding-left: 0;
  list-style: none;
}
.nav > li {
  position: relative;
  display: block;
}
.nav > li > a {
  position: relative;
  display: block;
  padding: 10px 15px;
}
.nav > li > a:hover,
.nav > li > a:focus {
  text-decoration: none;
  background-color: #eeeeee;
}
.nav > li.disabled > a {
  color: #777777;
}
.nav > li.disabled > a:hover,
.nav > li.disabled > a:focus {
  color: #777777;
  text-decoration: none;
  background-color: transparent;
  cursor: not-allowed;
}
.nav .open > a,
.nav .open > a:hover,
.nav .open > a:focus {
  background-color: #eeeeee;
  border-color: #337ab7;
}
.nav .nav-divider {
  height: 1px;
  margin: 8px 0;
  overflow: hidden;
  background-color: #e5e5e5;
}
.nav > li > a > img {
  max-width: none;
}
.nav-tabs {
  border-bottom: 1px solid #ddd;
}
.nav-tabs > li {
  float: left;
  margin-bottom: -1px;
}
.nav-tabs > li > a {
  margin-right: 2px;
  line-height: 1.42857143;
  border: 1px solid transparent;
  border-radius: 2px 2px 0 0;
}
.nav-tabs > li > a:hover {
  border-color: #eeeeee #eeeeee #ddd;
}
.nav-tabs > li.active > a,
.nav-tabs > li.active > a:hover,
.nav-tabs > li.active > a:focus {
  color: #555555;
  background-color: #fff;
  border: 1px solid #ddd;
  border-bottom-color: transparent;
  cursor: default;
}
.nav-tabs.nav-justified {
  width: 100%;
  border-bottom: 0;
}
.nav-tabs.nav-justified > li {
  float: none;
}
.nav-tabs.nav-justified > li > a {
  text-align: center;
  margin-bottom: 5px;
}
.nav-tabs.nav-justified > .dropdown .dropdown-menu {
  top: auto;
  left: auto;
}
@media (min-width: 768px) {
  .nav-tabs.nav-justified > li {
    display: table-cell;
    width: 1%;
  }
  .nav-tabs.nav-justified > li > a {
    margin-bottom: 0;
  }
}
.nav-tabs.nav-justified > li > a {
  margin-right: 0;
  border-radius: 2px;
}
.nav-tabs.nav-justified > .active > a,
.nav-tabs.nav-justified > .active > a:hover,
.nav-tabs.nav-justified > .active > a:focus {
  border: 1px solid #ddd;
}
@media (min-width: 768px) {
  .nav-tabs.nav-justified > li > a {
    border-bottom: 1px solid #ddd;
    border-radius: 2px 2px 0 0;
  }
  .nav-tabs.nav-justified > .active > a,
  .nav-tabs.nav-justified > .active > a:hover,
  .nav-tabs.nav-justified > .active > a:focus {
    border-bottom-color: #fff;
  }
}
.nav-pills > li {
  float: left;
}
.nav-pills > li > a {
  border-radius: 2px;
}
.nav-pills > li + li {
  margin-left: 2px;
}
.nav-pills > li.active > a,
.nav-pills > li.active > a:hover,
.nav-pills > li.active > a:focus {
  color: #fff;
  background-color: #337ab7;
}
.nav-stacked > li {
  float: none;
}
.nav-stacked > li + li {
  margin-top: 2px;
  margin-left: 0;
}
.nav-justified {
  width: 100%;
}
.nav-justified > li {
  float: none;
}
.nav-justified > li > a {
  text-align: center;
  margin-bottom: 5px;
}
.nav-justified > .dropdown .dropdown-menu {
  top: auto;
  left: auto;
}
@media (min-width: 768px) {
  .nav-justified > li {
    display: table-cell;
    width: 1%;
  }
  .nav-justified > li > a {
    margin-bottom: 0;
  }
}
.nav-tabs-justified {
  border-bottom: 0;
}
.nav-tabs-justified > li > a {
  margin-right: 0;
  border-radius: 2px;
}
.nav-tabs-justified > .active > a,
.nav-tabs-justified > .active > a:hover,
.nav-tabs-justified > .active > a:focus {
  border: 1px solid #ddd;
}
@media (min-width: 768px) {
  .nav-tabs-justified > li > a {
    border-bottom: 1px solid #ddd;
    border-radius: 2px 2px 0 0;
  }
  .nav-tabs-justified > .active > a,
  .nav-tabs-justified > .active > a:hover,
  .nav-tabs-justified > .active > a:focus {
    border-bottom-color: #fff;
  }
}
.tab-content > .tab-pane {
  display: none;
}
.tab-content > .active {
  display: block;
}
.nav-tabs .dropdown-menu {
  margin-top: -1px;
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.navbar {
  position: relative;
  min-height: 30px;
  margin-bottom: 18px;
  border: 1px solid transparent;
}
@media (min-width: 541px) {
  .navbar {
    border-radius: 2px;
  }
}
@media (min-width: 541px) {
  .navbar-header {
    float: left;
  }
}
.navbar-collapse {
  overflow-x: visible;
  padding-right: 0px;
  padding-left: 0px;
  border-top: 1px solid transparent;
  box-shadow: inset 0 1px 0 rgba(255, 255, 255, 0.1);
  -webkit-overflow-scrolling: touch;
}
.navbar-collapse.in {
  overflow-y: auto;
}
@media (min-width: 541px) {
  .navbar-collapse {
    width: auto;
    border-top: 0;
    box-shadow: none;
  }
  .navbar-collapse.collapse {
    display: block !important;
    height: auto !important;
    padding-bottom: 0;
    overflow: visible !important;
  }
  .navbar-collapse.in {
    overflow-y: visible;
  }
  .navbar-fixed-top .navbar-collapse,
  .navbar-static-top .navbar-collapse,
  .navbar-fixed-bottom .navbar-collapse {
    padding-left: 0;
    padding-right: 0;
  }
}
.navbar-fixed-top .navbar-collapse,
.navbar-fixed-bottom .navbar-collapse {
  max-height: 340px;
}
@media (max-device-width: 540px) and (orientation: landscape) {
  .navbar-fixed-top .navbar-collapse,
  .navbar-fixed-bottom .navbar-collapse {
    max-height: 200px;
  }
}
.container > .navbar-header,
.container-fluid > .navbar-header,
.container > .navbar-collapse,
.container-fluid > .navbar-collapse {
  margin-right: 0px;
  margin-left: 0px;
}
@media (min-width: 541px) {
  .container > .navbar-header,
  .container-fluid > .navbar-header,
  .container > .navbar-collapse,
  .container-fluid > .navbar-collapse {
    margin-right: 0;
    margin-left: 0;
  }
}
.navbar-static-top {
  z-index: 1000;
  border-width: 0 0 1px;
}
@media (min-width: 541px) {
  .navbar-static-top {
    border-radius: 0;
  }
}
.navbar-fixed-top,
.navbar-fixed-bottom {
  position: fixed;
  right: 0;
  left: 0;
  z-index: 1030;
}
@media (min-width: 541px) {
  .navbar-fixed-top,
  .navbar-fixed-bottom {
    border-radius: 0;
  }
}
.navbar-fixed-top {
  top: 0;
  border-width: 0 0 1px;
}
.navbar-fixed-bottom {
  bottom: 0;
  margin-bottom: 0;
  border-width: 1px 0 0;
}
.navbar-brand {
  float: left;
  padding: 6px 0px;
  font-size: 17px;
  line-height: 18px;
  height: 30px;
}
.navbar-brand:hover,
.navbar-brand:focus {
  text-decoration: none;
}
.navbar-brand > img {
  display: block;
}
@media (min-width: 541px) {
  .navbar > .container .navbar-brand,
  .navbar > .container-fluid .navbar-brand {
    margin-left: 0px;
  }
}
.navbar-toggle {
  position: relative;
  float: right;
  margin-right: 0px;
  padding: 9px 10px;
  margin-top: -2px;
  margin-bottom: -2px;
  background-color: transparent;
  background-image: none;
  border: 1px solid transparent;
  border-radius: 2px;
}
.navbar-toggle:focus {
  outline: 0;
}
.navbar-toggle .icon-bar {
  display: block;
  width: 22px;
  height: 2px;
  border-radius: 1px;
}
.navbar-toggle .icon-bar + .icon-bar {
  margin-top: 4px;
}
@media (min-width: 541px) {
  .navbar-toggle {
    display: none;
  }
}
.navbar-nav {
  margin: 3px 0px;
}
.navbar-nav > li > a {
  padding-top: 10px;
  padding-bottom: 10px;
  line-height: 18px;
}
@media (max-width: 540px) {
  .navbar-nav .open .dropdown-menu {
    position: static;
    float: none;
    width: auto;
    margin-top: 0;
    background-color: transparent;
    border: 0;
    box-shadow: none;
  }
  .navbar-nav .open .dropdown-menu > li > a,
  .navbar-nav .open .dropdown-menu .dropdown-header {
    padding: 5px 15px 5px 25px;
  }
  .navbar-nav .open .dropdown-menu > li > a {
    line-height: 18px;
  }
  .navbar-nav .open .dropdown-menu > li > a:hover,
  .navbar-nav .open .dropdown-menu > li > a:focus {
    background-image: none;
  }
}
@media (min-width: 541px) {
  .navbar-nav {
    float: left;
    margin: 0;
  }
  .navbar-nav > li {
    float: left;
  }
  .navbar-nav > li > a {
    padding-top: 6px;
    padding-bottom: 6px;
  }
}
.navbar-form {
  margin-left: 0px;
  margin-right: 0px;
  padding: 10px 0px;
  border-top: 1px solid transparent;
  border-bottom: 1px solid transparent;
  -webkit-box-shadow: inset 0 1px 0 rgba(255, 255, 255, 0.1), 0 1px 0 rgba(255, 255, 255, 0.1);
  box-shadow: inset 0 1px 0 rgba(255, 255, 255, 0.1), 0 1px 0 rgba(255, 255, 255, 0.1);
  margin-top: -1px;
  margin-bottom: -1px;
}
@media (min-width: 768px) {
  .navbar-form .form-group {
    display: inline-block;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .navbar-form .form-control {
    display: inline-block;
    width: auto;
    vertical-align: middle;
  }
  .navbar-form .form-control-static {
    display: inline-block;
  }
  .navbar-form .input-group {
    display: inline-table;
    vertical-align: middle;
  }
  .navbar-form .input-group .input-group-addon,
  .navbar-form .input-group .input-group-btn,
  .navbar-form .input-group .form-control {
    width: auto;
  }
  .navbar-form .input-group > .form-control {
    width: 100%;
  }
  .navbar-form .control-label {
    margin-bottom: 0;
    vertical-align: middle;
  }
  .navbar-form .radio,
  .navbar-form .checkbox {
    display: inline-block;
    margin-top: 0;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .navbar-form .radio label,
  .navbar-form .checkbox label {
    padding-left: 0;
  }
  .navbar-form .radio input[type="radio"],
  .navbar-form .checkbox input[type="checkbox"] {
    position: relative;
    margin-left: 0;
  }
  .navbar-form .has-feedback .form-control-feedback {
    top: 0;
  }
}
@media (max-width: 540px) {
  .navbar-form .form-group {
    margin-bottom: 5px;
  }
  .navbar-form .form-group:last-child {
    margin-bottom: 0;
  }
}
@media (min-width: 541px) {
  .navbar-form {
    width: auto;
    border: 0;
    margin-left: 0;
    margin-right: 0;
    padding-top: 0;
    padding-bottom: 0;
    -webkit-box-shadow: none;
    box-shadow: none;
  }
}
.navbar-nav > li > .dropdown-menu {
  margin-top: 0;
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.navbar-fixed-bottom .navbar-nav > li > .dropdown-menu {
  margin-bottom: 0;
  border-top-right-radius: 2px;
  border-top-left-radius: 2px;
  border-bottom-right-radius: 0;
  border-bottom-left-radius: 0;
}
.navbar-btn {
  margin-top: -1px;
  margin-bottom: -1px;
}
.navbar-btn.btn-sm {
  margin-top: 0px;
  margin-bottom: 0px;
}
.navbar-btn.btn-xs {
  margin-top: 4px;
  margin-bottom: 4px;
}
.navbar-text {
  margin-top: 6px;
  margin-bottom: 6px;
}
@media (min-width: 541px) {
  .navbar-text {
    float: left;
    margin-left: 0px;
    margin-right: 0px;
  }
}
@media (min-width: 541px) {
  .navbar-left {
    float: left !important;
    float: left;
  }
  .navbar-right {
    float: right !important;
    float: right;
    margin-right: 0px;
  }
  .navbar-right ~ .navbar-right {
    margin-right: 0;
  }
}
.navbar-default {
  background-color: #f8f8f8;
  border-color: #e7e7e7;
}
.navbar-default .navbar-brand {
  color: #777;
}
.navbar-default .navbar-brand:hover,
.navbar-default .navbar-brand:focus {
  color: #5e5e5e;
  background-color: transparent;
}
.navbar-default .navbar-text {
  color: #777;
}
.navbar-default .navbar-nav > li > a {
  color: #777;
}
.navbar-default .navbar-nav > li > a:hover,
.navbar-default .navbar-nav > li > a:focus {
  color: #333;
  background-color: transparent;
}
.navbar-default .navbar-nav > .active > a,
.navbar-default .navbar-nav > .active > a:hover,
.navbar-default .navbar-nav > .active > a:focus {
  color: #555;
  background-color: #e7e7e7;
}
.navbar-default .navbar-nav > .disabled > a,
.navbar-default .navbar-nav > .disabled > a:hover,
.navbar-default .navbar-nav > .disabled > a:focus {
  color: #ccc;
  background-color: transparent;
}
.navbar-default .navbar-toggle {
  border-color: #ddd;
}
.navbar-default .navbar-toggle:hover,
.navbar-default .navbar-toggle:focus {
  background-color: #ddd;
}
.navbar-default .navbar-toggle .icon-bar {
  background-color: #888;
}
.navbar-default .navbar-collapse,
.navbar-default .navbar-form {
  border-color: #e7e7e7;
}
.navbar-default .navbar-nav > .open > a,
.navbar-default .navbar-nav > .open > a:hover,
.navbar-default .navbar-nav > .open > a:focus {
  background-color: #e7e7e7;
  color: #555;
}
@media (max-width: 540px) {
  .navbar-default .navbar-nav .open .dropdown-menu > li > a {
    color: #777;
  }
  .navbar-default .navbar-nav .open .dropdown-menu > li > a:hover,
  .navbar-default .navbar-nav .open .dropdown-menu > li > a:focus {
    color: #333;
    background-color: transparent;
  }
  .navbar-default .navbar-nav .open .dropdown-menu > .active > a,
  .navbar-default .navbar-nav .open .dropdown-menu > .active > a:hover,
  .navbar-default .navbar-nav .open .dropdown-menu > .active > a:focus {
    color: #555;
    background-color: #e7e7e7;
  }
  .navbar-default .navbar-nav .open .dropdown-menu > .disabled > a,
  .navbar-default .navbar-nav .open .dropdown-menu > .disabled > a:hover,
  .navbar-default .navbar-nav .open .dropdown-menu > .disabled > a:focus {
    color: #ccc;
    background-color: transparent;
  }
}
.navbar-default .navbar-link {
  color: #777;
}
.navbar-default .navbar-link:hover {
  color: #333;
}
.navbar-default .btn-link {
  color: #777;
}
.navbar-default .btn-link:hover,
.navbar-default .btn-link:focus {
  color: #333;
}
.navbar-default .btn-link[disabled]:hover,
fieldset[disabled] .navbar-default .btn-link:hover,
.navbar-default .btn-link[disabled]:focus,
fieldset[disabled] .navbar-default .btn-link:focus {
  color: #ccc;
}
.navbar-inverse {
  background-color: #222;
  border-color: #080808;
}
.navbar-inverse .navbar-brand {
  color: #9d9d9d;
}
.navbar-inverse .navbar-brand:hover,
.navbar-inverse .navbar-brand:focus {
  color: #fff;
  background-color: transparent;
}
.navbar-inverse .navbar-text {
  color: #9d9d9d;
}
.navbar-inverse .navbar-nav > li > a {
  color: #9d9d9d;
}
.navbar-inverse .navbar-nav > li > a:hover,
.navbar-inverse .navbar-nav > li > a:focus {
  color: #fff;
  background-color: transparent;
}
.navbar-inverse .navbar-nav > .active > a,
.navbar-inverse .navbar-nav > .active > a:hover,
.navbar-inverse .navbar-nav > .active > a:focus {
  color: #fff;
  background-color: #080808;
}
.navbar-inverse .navbar-nav > .disabled > a,
.navbar-inverse .navbar-nav > .disabled > a:hover,
.navbar-inverse .navbar-nav > .disabled > a:focus {
  color: #444;
  background-color: transparent;
}
.navbar-inverse .navbar-toggle {
  border-color: #333;
}
.navbar-inverse .navbar-toggle:hover,
.navbar-inverse .navbar-toggle:focus {
  background-color: #333;
}
.navbar-inverse .navbar-toggle .icon-bar {
  background-color: #fff;
}
.navbar-inverse .navbar-collapse,
.navbar-inverse .navbar-form {
  border-color: #101010;
}
.navbar-inverse .navbar-nav > .open > a,
.navbar-inverse .navbar-nav > .open > a:hover,
.navbar-inverse .navbar-nav > .open > a:focus {
  background-color: #080808;
  color: #fff;
}
@media (max-width: 540px) {
  .navbar-inverse .navbar-nav .open .dropdown-menu > .dropdown-header {
    border-color: #080808;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu .divider {
    background-color: #080808;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > li > a {
    color: #9d9d9d;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > li > a:hover,
  .navbar-inverse .navbar-nav .open .dropdown-menu > li > a:focus {
    color: #fff;
    background-color: transparent;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > .active > a,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .active > a:hover,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .active > a:focus {
    color: #fff;
    background-color: #080808;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > .disabled > a,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .disabled > a:hover,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .disabled > a:focus {
    color: #444;
    background-color: transparent;
  }
}
.navbar-inverse .navbar-link {
  color: #9d9d9d;
}
.navbar-inverse .navbar-link:hover {
  color: #fff;
}
.navbar-inverse .btn-link {
  color: #9d9d9d;
}
.navbar-inverse .btn-link:hover,
.navbar-inverse .btn-link:focus {
  color: #fff;
}
.navbar-inverse .btn-link[disabled]:hover,
fieldset[disabled] .navbar-inverse .btn-link:hover,
.navbar-inverse .btn-link[disabled]:focus,
fieldset[disabled] .navbar-inverse .btn-link:focus {
  color: #444;
}
.breadcrumb {
  padding: 8px 15px;
  margin-bottom: 18px;
  list-style: none;
  background-color: #f5f5f5;
  border-radius: 2px;
}
.breadcrumb > li {
  display: inline-block;
}
.breadcrumb > li + li:before {
  content: "/\00a0";
  padding: 0 5px;
  color: #5e5e5e;
}
.breadcrumb > .active {
  color: #777777;
}
.pagination {
  display: inline-block;
  padding-left: 0;
  margin: 18px 0;
  border-radius: 2px;
}
.pagination > li {
  display: inline;
}
.pagination > li > a,
.pagination > li > span {
  position: relative;
  float: left;
  padding: 6px 12px;
  line-height: 1.42857143;
  text-decoration: none;
  color: #337ab7;
  background-color: #fff;
  border: 1px solid #ddd;
  margin-left: -1px;
}
.pagination > li:first-child > a,
.pagination > li:first-child > span {
  margin-left: 0;
  border-bottom-left-radius: 2px;
  border-top-left-radius: 2px;
}
.pagination > li:last-child > a,
.pagination > li:last-child > span {
  border-bottom-right-radius: 2px;
  border-top-right-radius: 2px;
}
.pagination > li > a:hover,
.pagination > li > span:hover,
.pagination > li > a:focus,
.pagination > li > span:focus {
  z-index: 2;
  color: #23527c;
  background-color: #eeeeee;
  border-color: #ddd;
}
.pagination > .active > a,
.pagination > .active > span,
.pagination > .active > a:hover,
.pagination > .active > span:hover,
.pagination > .active > a:focus,
.pagination > .active > span:focus {
  z-index: 3;
  color: #fff;
  background-color: #337ab7;
  border-color: #337ab7;
  cursor: default;
}
.pagination > .disabled > span,
.pagination > .disabled > span:hover,
.pagination > .disabled > span:focus,
.pagination > .disabled > a,
.pagination > .disabled > a:hover,
.pagination > .disabled > a:focus {
  color: #777777;
  background-color: #fff;
  border-color: #ddd;
  cursor: not-allowed;
}
.pagination-lg > li > a,
.pagination-lg > li > span {
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
}
.pagination-lg > li:first-child > a,
.pagination-lg > li:first-child > span {
  border-bottom-left-radius: 3px;
  border-top-left-radius: 3px;
}
.pagination-lg > li:last-child > a,
.pagination-lg > li:last-child > span {
  border-bottom-right-radius: 3px;
  border-top-right-radius: 3px;
}
.pagination-sm > li > a,
.pagination-sm > li > span {
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
}
.pagination-sm > li:first-child > a,
.pagination-sm > li:first-child > span {
  border-bottom-left-radius: 1px;
  border-top-left-radius: 1px;
}
.pagination-sm > li:last-child > a,
.pagination-sm > li:last-child > span {
  border-bottom-right-radius: 1px;
  border-top-right-radius: 1px;
}
.pager {
  padding-left: 0;
  margin: 18px 0;
  list-style: none;
  text-align: center;
}
.pager li {
  display: inline;
}
.pager li > a,
.pager li > span {
  display: inline-block;
  padding: 5px 14px;
  background-color: #fff;
  border: 1px solid #ddd;
  border-radius: 15px;
}
.pager li > a:hover,
.pager li > a:focus {
  text-decoration: none;
  background-color: #eeeeee;
}
.pager .next > a,
.pager .next > span {
  float: right;
}
.pager .previous > a,
.pager .previous > span {
  float: left;
}
.pager .disabled > a,
.pager .disabled > a:hover,
.pager .disabled > a:focus,
.pager .disabled > span {
  color: #777777;
  background-color: #fff;
  cursor: not-allowed;
}
.label {
  display: inline;
  padding: .2em .6em .3em;
  font-size: 75%;
  font-weight: bold;
  line-height: 1;
  color: #fff;
  text-align: center;
  white-space: nowrap;
  vertical-align: baseline;
  border-radius: .25em;
}
a.label:hover,
a.label:focus {
  color: #fff;
  text-decoration: none;
  cursor: pointer;
}
.label:empty {
  display: none;
}
.btn .label {
  position: relative;
  top: -1px;
}
.label-default {
  background-color: #777777;
}
.label-default[href]:hover,
.label-default[href]:focus {
  background-color: #5e5e5e;
}
.label-primary {
  background-color: #337ab7;
}
.label-primary[href]:hover,
.label-primary[href]:focus {
  background-color: #286090;
}
.label-success {
  background-color: #5cb85c;
}
.label-success[href]:hover,
.label-success[href]:focus {
  background-color: #449d44;
}
.label-info {
  background-color: #5bc0de;
}
.label-info[href]:hover,
.label-info[href]:focus {
  background-color: #31b0d5;
}
.label-warning {
  background-color: #f0ad4e;
}
.label-warning[href]:hover,
.label-warning[href]:focus {
  background-color: #ec971f;
}
.label-danger {
  background-color: #d9534f;
}
.label-danger[href]:hover,
.label-danger[href]:focus {
  background-color: #c9302c;
}
.badge {
  display: inline-block;
  min-width: 10px;
  padding: 3px 7px;
  font-size: 12px;
  font-weight: bold;
  color: #fff;
  line-height: 1;
  vertical-align: middle;
  white-space: nowrap;
  text-align: center;
  background-color: #777777;
  border-radius: 10px;
}
.badge:empty {
  display: none;
}
.btn .badge {
  position: relative;
  top: -1px;
}
.btn-xs .badge,
.btn-group-xs > .btn .badge {
  top: 0;
  padding: 1px 5px;
}
a.badge:hover,
a.badge:focus {
  color: #fff;
  text-decoration: none;
  cursor: pointer;
}
.list-group-item.active > .badge,
.nav-pills > .active > a > .badge {
  color: #337ab7;
  background-color: #fff;
}
.list-group-item > .badge {
  float: right;
}
.list-group-item > .badge + .badge {
  margin-right: 5px;
}
.nav-pills > li > a > .badge {
  margin-left: 3px;
}
.jumbotron {
  padding-top: 30px;
  padding-bottom: 30px;
  margin-bottom: 30px;
  color: inherit;
  background-color: #eeeeee;
}
.jumbotron h1,
.jumbotron .h1 {
  color: inherit;
}
.jumbotron p {
  margin-bottom: 15px;
  font-size: 20px;
  font-weight: 200;
}
.jumbotron > hr {
  border-top-color: #d5d5d5;
}
.container .jumbotron,
.container-fluid .jumbotron {
  border-radius: 3px;
  padding-left: 0px;
  padding-right: 0px;
}
.jumbotron .container {
  max-width: 100%;
}
@media screen and (min-width: 768px) {
  .jumbotron {
    padding-top: 48px;
    padding-bottom: 48px;
  }
  .container .jumbotron,
  .container-fluid .jumbotron {
    padding-left: 60px;
    padding-right: 60px;
  }
  .jumbotron h1,
  .jumbotron .h1 {
    font-size: 59px;
  }
}
.thumbnail {
  display: block;
  padding: 4px;
  margin-bottom: 18px;
  line-height: 1.42857143;
  background-color: #fff;
  border: 1px solid #ddd;
  border-radius: 2px;
  -webkit-transition: border 0.2s ease-in-out;
  -o-transition: border 0.2s ease-in-out;
  transition: border 0.2s ease-in-out;
}
.thumbnail > img,
.thumbnail a > img {
  margin-left: auto;
  margin-right: auto;
}
a.thumbnail:hover,
a.thumbnail:focus,
a.thumbnail.active {
  border-color: #337ab7;
}
.thumbnail .caption {
  padding: 9px;
  color: #000;
}
.alert {
  padding: 15px;
  margin-bottom: 18px;
  border: 1px solid transparent;
  border-radius: 2px;
}
.alert h4 {
  margin-top: 0;
  color: inherit;
}
.alert .alert-link {
  font-weight: bold;
}
.alert > p,
.alert > ul {
  margin-bottom: 0;
}
.alert > p + p {
  margin-top: 5px;
}
.alert-dismissable,
.alert-dismissible {
  padding-right: 35px;
}
.alert-dismissable .close,
.alert-dismissible .close {
  position: relative;
  top: -2px;
  right: -21px;
  color: inherit;
}
.alert-success {
  background-color: #dff0d8;
  border-color: #d6e9c6;
  color: #3c763d;
}
.alert-success hr {
  border-top-color: #c9e2b3;
}
.alert-success .alert-link {
  color: #2b542c;
}
.alert-info {
  background-color: #d9edf7;
  border-color: #bce8f1;
  color: #31708f;
}
.alert-info hr {
  border-top-color: #a6e1ec;
}
.alert-info .alert-link {
  color: #245269;
}
.alert-warning {
  background-color: #fcf8e3;
  border-color: #faebcc;
  color: #8a6d3b;
}
.alert-warning hr {
  border-top-color: #f7e1b5;
}
.alert-warning .alert-link {
  color: #66512c;
}
.alert-danger {
  background-color: #f2dede;
  border-color: #ebccd1;
  color: #a94442;
}
.alert-danger hr {
  border-top-color: #e4b9c0;
}
.alert-danger .alert-link {
  color: #843534;
}
@-webkit-keyframes progress-bar-stripes {
  from {
    background-position: 40px 0;
  }
  to {
    background-position: 0 0;
  }
}
@keyframes progress-bar-stripes {
  from {
    background-position: 40px 0;
  }
  to {
    background-position: 0 0;
  }
}
.progress {
  overflow: hidden;
  height: 18px;
  margin-bottom: 18px;
  background-color: #f5f5f5;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 2px rgba(0, 0, 0, 0.1);
  box-shadow: inset 0 1px 2px rgba(0, 0, 0, 0.1);
}
.progress-bar {
  float: left;
  width: 0%;
  height: 100%;
  font-size: 12px;
  line-height: 18px;
  color: #fff;
  text-align: center;
  background-color: #337ab7;
  -webkit-box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.15);
  box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.15);
  -webkit-transition: width 0.6s ease;
  -o-transition: width 0.6s ease;
  transition: width 0.6s ease;
}
.progress-striped .progress-bar,
.progress-bar-striped {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-size: 40px 40px;
}
.progress.active .progress-bar,
.progress-bar.active {
  -webkit-animation: progress-bar-stripes 2s linear infinite;
  -o-animation: progress-bar-stripes 2s linear infinite;
  animation: progress-bar-stripes 2s linear infinite;
}
.progress-bar-success {
  background-color: #5cb85c;
}
.progress-striped .progress-bar-success {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.progress-bar-info {
  background-color: #5bc0de;
}
.progress-striped .progress-bar-info {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.progress-bar-warning {
  background-color: #f0ad4e;
}
.progress-striped .progress-bar-warning {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.progress-bar-danger {
  background-color: #d9534f;
}
.progress-striped .progress-bar-danger {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.media {
  margin-top: 15px;
}
.media:first-child {
  margin-top: 0;
}
.media,
.media-body {
  zoom: 1;
  overflow: hidden;
}
.media-body {
  width: 10000px;
}
.media-object {
  display: block;
}
.media-object.img-thumbnail {
  max-width: none;
}
.media-right,
.media > .pull-right {
  padding-left: 10px;
}
.media-left,
.media > .pull-left {
  padding-right: 10px;
}
.media-left,
.media-right,
.media-body {
  display: table-cell;
  vertical-align: top;
}
.media-middle {
  vertical-align: middle;
}
.media-bottom {
  vertical-align: bottom;
}
.media-heading {
  margin-top: 0;
  margin-bottom: 5px;
}
.media-list {
  padding-left: 0;
  list-style: none;
}
.list-group {
  margin-bottom: 20px;
  padding-left: 0;
}
.list-group-item {
  position: relative;
  display: block;
  padding: 10px 15px;
  margin-bottom: -1px;
  background-color: #fff;
  border: 1px solid #ddd;
}
.list-group-item:first-child {
  border-top-right-radius: 2px;
  border-top-left-radius: 2px;
}
.list-group-item:last-child {
  margin-bottom: 0;
  border-bottom-right-radius: 2px;
  border-bottom-left-radius: 2px;
}
a.list-group-item,
button.list-group-item {
  color: #555;
}
a.list-group-item .list-group-item-heading,
button.list-group-item .list-group-item-heading {
  color: #333;
}
a.list-group-item:hover,
button.list-group-item:hover,
a.list-group-item:focus,
button.list-group-item:focus {
  text-decoration: none;
  color: #555;
  background-color: #f5f5f5;
}
button.list-group-item {
  width: 100%;
  text-align: left;
}
.list-group-item.disabled,
.list-group-item.disabled:hover,
.list-group-item.disabled:focus {
  background-color: #eeeeee;
  color: #777777;
  cursor: not-allowed;
}
.list-group-item.disabled .list-group-item-heading,
.list-group-item.disabled:hover .list-group-item-heading,
.list-group-item.disabled:focus .list-group-item-heading {
  color: inherit;
}
.list-group-item.disabled .list-group-item-text,
.list-group-item.disabled:hover .list-group-item-text,
.list-group-item.disabled:focus .list-group-item-text {
  color: #777777;
}
.list-group-item.active,
.list-group-item.active:hover,
.list-group-item.active:focus {
  z-index: 2;
  color: #fff;
  background-color: #337ab7;
  border-color: #337ab7;
}
.list-group-item.active .list-group-item-heading,
.list-group-item.active:hover .list-group-item-heading,
.list-group-item.active:focus .list-group-item-heading,
.list-group-item.active .list-group-item-heading > small,
.list-group-item.active:hover .list-group-item-heading > small,
.list-group-item.active:focus .list-group-item-heading > small,
.list-group-item.active .list-group-item-heading > .small,
.list-group-item.active:hover .list-group-item-heading > .small,
.list-group-item.active:focus .list-group-item-heading > .small {
  color: inherit;
}
.list-group-item.active .list-group-item-text,
.list-group-item.active:hover .list-group-item-text,
.list-group-item.active:focus .list-group-item-text {
  color: #c7ddef;
}
.list-group-item-success {
  color: #3c763d;
  background-color: #dff0d8;
}
a.list-group-item-success,
button.list-group-item-success {
  color: #3c763d;
}
a.list-group-item-success .list-group-item-heading,
button.list-group-item-success .list-group-item-heading {
  color: inherit;
}
a.list-group-item-success:hover,
button.list-group-item-success:hover,
a.list-group-item-success:focus,
button.list-group-item-success:focus {
  color: #3c763d;
  background-color: #d0e9c6;
}
a.list-group-item-success.active,
button.list-group-item-success.active,
a.list-group-item-success.active:hover,
button.list-group-item-success.active:hover,
a.list-group-item-success.active:focus,
button.list-group-item-success.active:focus {
  color: #fff;
  background-color: #3c763d;
  border-color: #3c763d;
}
.list-group-item-info {
  color: #31708f;
  background-color: #d9edf7;
}
a.list-group-item-info,
button.list-group-item-info {
  color: #31708f;
}
a.list-group-item-info .list-group-item-heading,
button.list-group-item-info .list-group-item-heading {
  color: inherit;
}
a.list-group-item-info:hover,
button.list-group-item-info:hover,
a.list-group-item-info:focus,
button.list-group-item-info:focus {
  color: #31708f;
  background-color: #c4e3f3;
}
a.list-group-item-info.active,
button.list-group-item-info.active,
a.list-group-item-info.active:hover,
button.list-group-item-info.active:hover,
a.list-group-item-info.active:focus,
button.list-group-item-info.active:focus {
  color: #fff;
  background-color: #31708f;
  border-color: #31708f;
}
.list-group-item-warning {
  color: #8a6d3b;
  background-color: #fcf8e3;
}
a.list-group-item-warning,
button.list-group-item-warning {
  color: #8a6d3b;
}
a.list-group-item-warning .list-group-item-heading,
button.list-group-item-warning .list-group-item-heading {
  color: inherit;
}
a.list-group-item-warning:hover,
button.list-group-item-warning:hover,
a.list-group-item-warning:focus,
button.list-group-item-warning:focus {
  color: #8a6d3b;
  background-color: #faf2cc;
}
a.list-group-item-warning.active,
button.list-group-item-warning.active,
a.list-group-item-warning.active:hover,
button.list-group-item-warning.active:hover,
a.list-group-item-warning.active:focus,
button.list-group-item-warning.active:focus {
  color: #fff;
  background-color: #8a6d3b;
  border-color: #8a6d3b;
}
.list-group-item-danger {
  color: #a94442;
  background-color: #f2dede;
}
a.list-group-item-danger,
button.list-group-item-danger {
  color: #a94442;
}
a.list-group-item-danger .list-group-item-heading,
button.list-group-item-danger .list-group-item-heading {
  color: inherit;
}
a.list-group-item-danger:hover,
button.list-group-item-danger:hover,
a.list-group-item-danger:focus,
button.list-group-item-danger:focus {
  color: #a94442;
  background-color: #ebcccc;
}
a.list-group-item-danger.active,
button.list-group-item-danger.active,
a.list-group-item-danger.active:hover,
button.list-group-item-danger.active:hover,
a.list-group-item-danger.active:focus,
button.list-group-item-danger.active:focus {
  color: #fff;
  background-color: #a94442;
  border-color: #a94442;
}
.list-group-item-heading {
  margin-top: 0;
  margin-bottom: 5px;
}
.list-group-item-text {
  margin-bottom: 0;
  line-height: 1.3;
}
.panel {
  margin-bottom: 18px;
  background-color: #fff;
  border: 1px solid transparent;
  border-radius: 2px;
  -webkit-box-shadow: 0 1px 1px rgba(0, 0, 0, 0.05);
  box-shadow: 0 1px 1px rgba(0, 0, 0, 0.05);
}
.panel-body {
  padding: 15px;
}
.panel-heading {
  padding: 10px 15px;
  border-bottom: 1px solid transparent;
  border-top-right-radius: 1px;
  border-top-left-radius: 1px;
}
.panel-heading > .dropdown .dropdown-toggle {
  color: inherit;
}
.panel-title {
  margin-top: 0;
  margin-bottom: 0;
  font-size: 15px;
  color: inherit;
}
.panel-title > a,
.panel-title > small,
.panel-title > .small,
.panel-title > small > a,
.panel-title > .small > a {
  color: inherit;
}
.panel-footer {
  padding: 10px 15px;
  background-color: #f5f5f5;
  border-top: 1px solid #ddd;
  border-bottom-right-radius: 1px;
  border-bottom-left-radius: 1px;
}
.panel > .list-group,
.panel > .panel-collapse > .list-group {
  margin-bottom: 0;
}
.panel > .list-group .list-group-item,
.panel > .panel-collapse > .list-group .list-group-item {
  border-width: 1px 0;
  border-radius: 0;
}
.panel > .list-group:first-child .list-group-item:first-child,
.panel > .panel-collapse > .list-group:first-child .list-group-item:first-child {
  border-top: 0;
  border-top-right-radius: 1px;
  border-top-left-radius: 1px;
}
.panel > .list-group:last-child .list-group-item:last-child,
.panel > .panel-collapse > .list-group:last-child .list-group-item:last-child {
  border-bottom: 0;
  border-bottom-right-radius: 1px;
  border-bottom-left-radius: 1px;
}
.panel > .panel-heading + .panel-collapse > .list-group .list-group-item:first-child {
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.panel-heading + .list-group .list-group-item:first-child {
  border-top-width: 0;
}
.list-group + .panel-footer {
  border-top-width: 0;
}
.panel > .table,
.panel > .table-responsive > .table,
.panel > .panel-collapse > .table {
  margin-bottom: 0;
}
.panel > .table caption,
.panel > .table-responsive > .table caption,
.panel > .panel-collapse > .table caption {
  padding-left: 15px;
  padding-right: 15px;
}
.panel > .table:first-child,
.panel > .table-responsive:first-child > .table:first-child {
  border-top-right-radius: 1px;
  border-top-left-radius: 1px;
}
.panel > .table:first-child > thead:first-child > tr:first-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child,
.panel > .table:first-child > tbody:first-child > tr:first-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child {
  border-top-left-radius: 1px;
  border-top-right-radius: 1px;
}
.panel > .table:first-child > thead:first-child > tr:first-child td:first-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child td:first-child,
.panel > .table:first-child > tbody:first-child > tr:first-child td:first-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child td:first-child,
.panel > .table:first-child > thead:first-child > tr:first-child th:first-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child th:first-child,
.panel > .table:first-child > tbody:first-child > tr:first-child th:first-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child th:first-child {
  border-top-left-radius: 1px;
}
.panel > .table:first-child > thead:first-child > tr:first-child td:last-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child td:last-child,
.panel > .table:first-child > tbody:first-child > tr:first-child td:last-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child td:last-child,
.panel > .table:first-child > thead:first-child > tr:first-child th:last-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child th:last-child,
.panel > .table:first-child > tbody:first-child > tr:first-child th:last-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child th:last-child {
  border-top-right-radius: 1px;
}
.panel > .table:last-child,
.panel > .table-responsive:last-child > .table:last-child {
  border-bottom-right-radius: 1px;
  border-bottom-left-radius: 1px;
}
.panel > .table:last-child > tbody:last-child > tr:last-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child {
  border-bottom-left-radius: 1px;
  border-bottom-right-radius: 1px;
}
.panel > .table:last-child > tbody:last-child > tr:last-child td:first-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child td:first-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child td:first-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child td:first-child,
.panel > .table:last-child > tbody:last-child > tr:last-child th:first-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child th:first-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child th:first-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child th:first-child {
  border-bottom-left-radius: 1px;
}
.panel > .table:last-child > tbody:last-child > tr:last-child td:last-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child td:last-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child td:last-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child td:last-child,
.panel > .table:last-child > tbody:last-child > tr:last-child th:last-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child th:last-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child th:last-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child th:last-child {
  border-bottom-right-radius: 1px;
}
.panel > .panel-body + .table,
.panel > .panel-body + .table-responsive,
.panel > .table + .panel-body,
.panel > .table-responsive + .panel-body {
  border-top: 1px solid #ddd;
}
.panel > .table > tbody:first-child > tr:first-child th,
.panel > .table > tbody:first-child > tr:first-child td {
  border-top: 0;
}
.panel > .table-bordered,
.panel > .table-responsive > .table-bordered {
  border: 0;
}
.panel > .table-bordered > thead > tr > th:first-child,
.panel > .table-responsive > .table-bordered > thead > tr > th:first-child,
.panel > .table-bordered > tbody > tr > th:first-child,
.panel > .table-responsive > .table-bordered > tbody > tr > th:first-child,
.panel > .table-bordered > tfoot > tr > th:first-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > th:first-child,
.panel > .table-bordered > thead > tr > td:first-child,
.panel > .table-responsive > .table-bordered > thead > tr > td:first-child,
.panel > .table-bordered > tbody > tr > td:first-child,
.panel > .table-responsive > .table-bordered > tbody > tr > td:first-child,
.panel > .table-bordered > tfoot > tr > td:first-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > td:first-child {
  border-left: 0;
}
.panel > .table-bordered > thead > tr > th:last-child,
.panel > .table-responsive > .table-bordered > thead > tr > th:last-child,
.panel > .table-bordered > tbody > tr > th:last-child,
.panel > .table-responsive > .table-bordered > tbody > tr > th:last-child,
.panel > .table-bordered > tfoot > tr > th:last-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > th:last-child,
.panel > .table-bordered > thead > tr > td:last-child,
.panel > .table-responsive > .table-bordered > thead > tr > td:last-child,
.panel > .table-bordered > tbody > tr > td:last-child,
.panel > .table-responsive > .table-bordered > tbody > tr > td:last-child,
.panel > .table-bordered > tfoot > tr > td:last-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > td:last-child {
  border-right: 0;
}
.panel > .table-bordered > thead > tr:first-child > td,
.panel > .table-responsive > .table-bordered > thead > tr:first-child > td,
.panel > .table-bordered > tbody > tr:first-child > td,
.panel > .table-responsive > .table-bordered > tbody > tr:first-child > td,
.panel > .table-bordered > thead > tr:first-child > th,
.panel > .table-responsive > .table-bordered > thead > tr:first-child > th,
.panel > .table-bordered > tbody > tr:first-child > th,
.panel > .table-responsive > .table-bordered > tbody > tr:first-child > th {
  border-bottom: 0;
}
.panel > .table-bordered > tbody > tr:last-child > td,
.panel > .table-responsive > .table-bordered > tbody > tr:last-child > td,
.panel > .table-bordered > tfoot > tr:last-child > td,
.panel > .table-responsive > .table-bordered > tfoot > tr:last-child > td,
.panel > .table-bordered > tbody > tr:last-child > th,
.panel > .table-responsive > .table-bordered > tbody > tr:last-child > th,
.panel > .table-bordered > tfoot > tr:last-child > th,
.panel > .table-responsive > .table-bordered > tfoot > tr:last-child > th {
  border-bottom: 0;
}
.panel > .table-responsive {
  border: 0;
  margin-bottom: 0;
}
.panel-group {
  margin-bottom: 18px;
}
.panel-group .panel {
  margin-bottom: 0;
  border-radius: 2px;
}
.panel-group .panel + .panel {
  margin-top: 5px;
}
.panel-group .panel-heading {
  border-bottom: 0;
}
.panel-group .panel-heading + .panel-collapse > .panel-body,
.panel-group .panel-heading + .panel-collapse > .list-group {
  border-top: 1px solid #ddd;
}
.panel-group .panel-footer {
  border-top: 0;
}
.panel-group .panel-footer + .panel-collapse .panel-body {
  border-bottom: 1px solid #ddd;
}
.panel-default {
  border-color: #ddd;
}
.panel-default > .panel-heading {
  color: #333333;
  background-color: #f5f5f5;
  border-color: #ddd;
}
.panel-default > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #ddd;
}
.panel-default > .panel-heading .badge {
  color: #f5f5f5;
  background-color: #333333;
}
.panel-default > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #ddd;
}
.panel-primary {
  border-color: #337ab7;
}
.panel-primary > .panel-heading {
  color: #fff;
  background-color: #337ab7;
  border-color: #337ab7;
}
.panel-primary > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #337ab7;
}
.panel-primary > .panel-heading .badge {
  color: #337ab7;
  background-color: #fff;
}
.panel-primary > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #337ab7;
}
.panel-success {
  border-color: #d6e9c6;
}
.panel-success > .panel-heading {
  color: #3c763d;
  background-color: #dff0d8;
  border-color: #d6e9c6;
}
.panel-success > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #d6e9c6;
}
.panel-success > .panel-heading .badge {
  color: #dff0d8;
  background-color: #3c763d;
}
.panel-success > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #d6e9c6;
}
.panel-info {
  border-color: #bce8f1;
}
.panel-info > .panel-heading {
  color: #31708f;
  background-color: #d9edf7;
  border-color: #bce8f1;
}
.panel-info > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #bce8f1;
}
.panel-info > .panel-heading .badge {
  color: #d9edf7;
  background-color: #31708f;
}
.panel-info > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #bce8f1;
}
.panel-warning {
  border-color: #faebcc;
}
.panel-warning > .panel-heading {
  color: #8a6d3b;
  background-color: #fcf8e3;
  border-color: #faebcc;
}
.panel-warning > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #faebcc;
}
.panel-warning > .panel-heading .badge {
  color: #fcf8e3;
  background-color: #8a6d3b;
}
.panel-warning > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #faebcc;
}
.panel-danger {
  border-color: #ebccd1;
}
.panel-danger > .panel-heading {
  color: #a94442;
  background-color: #f2dede;
  border-color: #ebccd1;
}
.panel-danger > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #ebccd1;
}
.panel-danger > .panel-heading .badge {
  color: #f2dede;
  background-color: #a94442;
}
.panel-danger > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #ebccd1;
}
.embed-responsive {
  position: relative;
  display: block;
  height: 0;
  padding: 0;
  overflow: hidden;
}
.embed-responsive .embed-responsive-item,
.embed-responsive iframe,
.embed-responsive embed,
.embed-responsive object,
.embed-responsive video {
  position: absolute;
  top: 0;
  left: 0;
  bottom: 0;
  height: 100%;
  width: 100%;
  border: 0;
}
.embed-responsive-16by9 {
  padding-bottom: 56.25%;
}
.embed-responsive-4by3 {
  padding-bottom: 75%;
}
.well {
  min-height: 20px;
  padding: 19px;
  margin-bottom: 20px;
  background-color: #f5f5f5;
  border: 1px solid #e3e3e3;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.05);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.05);
}
.well blockquote {
  border-color: #ddd;
  border-color: rgba(0, 0, 0, 0.15);
}
.well-lg {
  padding: 24px;
  border-radius: 3px;
}
.well-sm {
  padding: 9px;
  border-radius: 1px;
}
.close {
  float: right;
  font-size: 19.5px;
  font-weight: bold;
  line-height: 1;
  color: #000;
  text-shadow: 0 1px 0 #fff;
  opacity: 0.2;
  filter: alpha(opacity=20);
}
.close:hover,
.close:focus {
  color: #000;
  text-decoration: none;
  cursor: pointer;
  opacity: 0.5;
  filter: alpha(opacity=50);
}
button.close {
  padding: 0;
  cursor: pointer;
  background: transparent;
  border: 0;
  -webkit-appearance: none;
}
.modal-open {
  overflow: hidden;
}
.modal {
  display: none;
  overflow: hidden;
  position: fixed;
  top: 0;
  right: 0;
  bottom: 0;
  left: 0;
  z-index: 1050;
  -webkit-overflow-scrolling: touch;
  outline: 0;
}
.modal.fade .modal-dialog {
  -webkit-transform: translate(0, -25%);
  -ms-transform: translate(0, -25%);
  -o-transform: translate(0, -25%);
  transform: translate(0, -25%);
  -webkit-transition: -webkit-transform 0.3s ease-out;
  -moz-transition: -moz-transform 0.3s ease-out;
  -o-transition: -o-transform 0.3s ease-out;
  transition: transform 0.3s ease-out;
}
.modal.in .modal-dialog {
  -webkit-transform: translate(0, 0);
  -ms-transform: translate(0, 0);
  -o-transform: translate(0, 0);
  transform: translate(0, 0);
}
.modal-open .modal {
  overflow-x: hidden;
  overflow-y: auto;
}
.modal-dialog {
  position: relative;
  width: auto;
  margin: 10px;
}
.modal-content {
  position: relative;
  background-color: #fff;
  border: 1px solid #999;
  border: 1px solid rgba(0, 0, 0, 0.2);
  border-radius: 3px;
  -webkit-box-shadow: 0 3px 9px rgba(0, 0, 0, 0.5);
  box-shadow: 0 3px 9px rgba(0, 0, 0, 0.5);
  background-clip: padding-box;
  outline: 0;
}
.modal-backdrop {
  position: fixed;
  top: 0;
  right: 0;
  bottom: 0;
  left: 0;
  z-index: 1040;
  background-color: #000;
}
.modal-backdrop.fade {
  opacity: 0;
  filter: alpha(opacity=0);
}
.modal-backdrop.in {
  opacity: 0.5;
  filter: alpha(opacity=50);
}
.modal-header {
  padding: 15px;
  border-bottom: 1px solid #e5e5e5;
}
.modal-header .close {
  margin-top: -2px;
}
.modal-title {
  margin: 0;
  line-height: 1.42857143;
}
.modal-body {
  position: relative;
  padding: 15px;
}
.modal-footer {
  padding: 15px;
  text-align: right;
  border-top: 1px solid #e5e5e5;
}
.modal-footer .btn + .btn {
  margin-left: 5px;
  margin-bottom: 0;
}
.modal-footer .btn-group .btn + .btn {
  margin-left: -1px;
}
.modal-footer .btn-block + .btn-block {
  margin-left: 0;
}
.modal-scrollbar-measure {
  position: absolute;
  top: -9999px;
  width: 50px;
  height: 50px;
  overflow: scroll;
}
@media (min-width: 768px) {
  .modal-dialog {
    width: 600px;
    margin: 30px auto;
  }
  .modal-content {
    -webkit-box-shadow: 0 5px 15px rgba(0, 0, 0, 0.5);
    box-shadow: 0 5px 15px rgba(0, 0, 0, 0.5);
  }
  .modal-sm {
    width: 300px;
  }
}
@media (min-width: 992px) {
  .modal-lg {
    width: 900px;
  }
}
.tooltip {
  position: absolute;
  z-index: 1070;
  display: block;
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
  font-style: normal;
  font-weight: normal;
  letter-spacing: normal;
  line-break: auto;
  line-height: 1.42857143;
  text-align: left;
  text-align: start;
  text-decoration: none;
  text-shadow: none;
  text-transform: none;
  white-space: normal;
  word-break: normal;
  word-spacing: normal;
  word-wrap: normal;
  font-size: 12px;
  opacity: 0;
  filter: alpha(opacity=0);
}
.tooltip.in {
  opacity: 0.9;
  filter: alpha(opacity=90);
}
.tooltip.top {
  margin-top: -3px;
  padding: 5px 0;
}
.tooltip.right {
  margin-left: 3px;
  padding: 0 5px;
}
.tooltip.bottom {
  margin-top: 3px;
  padding: 5px 0;
}
.tooltip.left {
  margin-left: -3px;
  padding: 0 5px;
}
.tooltip-inner {
  max-width: 200px;
  padding: 3px 8px;
  color: #fff;
  text-align: center;
  background-color: #000;
  border-radius: 2px;
}
.tooltip-arrow {
  position: absolute;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
}
.tooltip.top .tooltip-arrow {
  bottom: 0;
  left: 50%;
  margin-left: -5px;
  border-width: 5px 5px 0;
  border-top-color: #000;
}
.tooltip.top-left .tooltip-arrow {
  bottom: 0;
  right: 5px;
  margin-bottom: -5px;
  border-width: 5px 5px 0;
  border-top-color: #000;
}
.tooltip.top-right .tooltip-arrow {
  bottom: 0;
  left: 5px;
  margin-bottom: -5px;
  border-width: 5px 5px 0;
  border-top-color: #000;
}
.tooltip.right .tooltip-arrow {
  top: 50%;
  left: 0;
  margin-top: -5px;
  border-width: 5px 5px 5px 0;
  border-right-color: #000;
}
.tooltip.left .tooltip-arrow {
  top: 50%;
  right: 0;
  margin-top: -5px;
  border-width: 5px 0 5px 5px;
  border-left-color: #000;
}
.tooltip.bottom .tooltip-arrow {
  top: 0;
  left: 50%;
  margin-left: -5px;
  border-width: 0 5px 5px;
  border-bottom-color: #000;
}
.tooltip.bottom-left .tooltip-arrow {
  top: 0;
  right: 5px;
  margin-top: -5px;
  border-width: 0 5px 5px;
  border-bottom-color: #000;
}
.tooltip.bottom-right .tooltip-arrow {
  top: 0;
  left: 5px;
  margin-top: -5px;
  border-width: 0 5px 5px;
  border-bottom-color: #000;
}
.popover {
  position: absolute;
  top: 0;
  left: 0;
  z-index: 1060;
  display: none;
  max-width: 276px;
  padding: 1px;
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
  font-style: normal;
  font-weight: normal;
  letter-spacing: normal;
  line-break: auto;
  line-height: 1.42857143;
  text-align: left;
  text-align: start;
  text-decoration: none;
  text-shadow: none;
  text-transform: none;
  white-space: normal;
  word-break: normal;
  word-spacing: normal;
  word-wrap: normal;
  font-size: 13px;
  background-color: #fff;
  background-clip: padding-box;
  border: 1px solid #ccc;
  border: 1px solid rgba(0, 0, 0, 0.2);
  border-radius: 3px;
  -webkit-box-shadow: 0 5px 10px rgba(0, 0, 0, 0.2);
  box-shadow: 0 5px 10px rgba(0, 0, 0, 0.2);
}
.popover.top {
  margin-top: -10px;
}
.popover.right {
  margin-left: 10px;
}
.popover.bottom {
  margin-top: 10px;
}
.popover.left {
  margin-left: -10px;
}
.popover-title {
  margin: 0;
  padding: 8px 14px;
  font-size: 13px;
  background-color: #f7f7f7;
  border-bottom: 1px solid #ebebeb;
  border-radius: 2px 2px 0 0;
}
.popover-content {
  padding: 9px 14px;
}
.popover > .arrow,
.popover > .arrow:after {
  position: absolute;
  display: block;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
}
.popover > .arrow {
  border-width: 11px;
}
.popover > .arrow:after {
  border-width: 10px;
  content: "";
}
.popover.top > .arrow {
  left: 50%;
  margin-left: -11px;
  border-bottom-width: 0;
  border-top-color: #999999;
  border-top-color: rgba(0, 0, 0, 0.25);
  bottom: -11px;
}
.popover.top > .arrow:after {
  content: " ";
  bottom: 1px;
  margin-left: -10px;
  border-bottom-width: 0;
  border-top-color: #fff;
}
.popover.right > .arrow {
  top: 50%;
  left: -11px;
  margin-top: -11px;
  border-left-width: 0;
  border-right-color: #999999;
  border-right-color: rgba(0, 0, 0, 0.25);
}
.popover.right > .arrow:after {
  content: " ";
  left: 1px;
  bottom: -10px;
  border-left-width: 0;
  border-right-color: #fff;
}
.popover.bottom > .arrow {
  left: 50%;
  margin-left: -11px;
  border-top-width: 0;
  border-bottom-color: #999999;
  border-bottom-color: rgba(0, 0, 0, 0.25);
  top: -11px;
}
.popover.bottom > .arrow:after {
  content: " ";
  top: 1px;
  margin-left: -10px;
  border-top-width: 0;
  border-bottom-color: #fff;
}
.popover.left > .arrow {
  top: 50%;
  right: -11px;
  margin-top: -11px;
  border-right-width: 0;
  border-left-color: #999999;
  border-left-color: rgba(0, 0, 0, 0.25);
}
.popover.left > .arrow:after {
  content: " ";
  right: 1px;
  border-right-width: 0;
  border-left-color: #fff;
  bottom: -10px;
}
.carousel {
  position: relative;
}
.carousel-inner {
  position: relative;
  overflow: hidden;
  width: 100%;
}
.carousel-inner > .item {
  display: none;
  position: relative;
  -webkit-transition: 0.6s ease-in-out left;
  -o-transition: 0.6s ease-in-out left;
  transition: 0.6s ease-in-out left;
}
.carousel-inner > .item > img,
.carousel-inner > .item > a > img {
  line-height: 1;
}
@media all and (transform-3d), (-webkit-transform-3d) {
  .carousel-inner > .item {
    -webkit-transition: -webkit-transform 0.6s ease-in-out;
    -moz-transition: -moz-transform 0.6s ease-in-out;
    -o-transition: -o-transform 0.6s ease-in-out;
    transition: transform 0.6s ease-in-out;
    -webkit-backface-visibility: hidden;
    -moz-backface-visibility: hidden;
    backface-visibility: hidden;
    -webkit-perspective: 1000px;
    -moz-perspective: 1000px;
    perspective: 1000px;
  }
  .carousel-inner > .item.next,
  .carousel-inner > .item.active.right {
    -webkit-transform: translate3d(100%, 0, 0);
    transform: translate3d(100%, 0, 0);
    left: 0;
  }
  .carousel-inner > .item.prev,
  .carousel-inner > .item.active.left {
    -webkit-transform: translate3d(-100%, 0, 0);
    transform: translate3d(-100%, 0, 0);
    left: 0;
  }
  .carousel-inner > .item.next.left,
  .carousel-inner > .item.prev.right,
  .carousel-inner > .item.active {
    -webkit-transform: translate3d(0, 0, 0);
    transform: translate3d(0, 0, 0);
    left: 0;
  }
}
.carousel-inner > .active,
.carousel-inner > .next,
.carousel-inner > .prev {
  display: block;
}
.carousel-inner > .active {
  left: 0;
}
.carousel-inner > .next,
.carousel-inner > .prev {
  position: absolute;
  top: 0;
  width: 100%;
}
.carousel-inner > .next {
  left: 100%;
}
.carousel-inner > .prev {
  left: -100%;
}
.carousel-inner > .next.left,
.carousel-inner > .prev.right {
  left: 0;
}
.carousel-inner > .active.left {
  left: -100%;
}
.carousel-inner > .active.right {
  left: 100%;
}
.carousel-control {
  position: absolute;
  top: 0;
  left: 0;
  bottom: 0;
  width: 15%;
  opacity: 0.5;
  filter: alpha(opacity=50);
  font-size: 20px;
  color: #fff;
  text-align: center;
  text-shadow: 0 1px 2px rgba(0, 0, 0, 0.6);
  background-color: rgba(0, 0, 0, 0);
}
.carousel-control.left {
  background-image: -webkit-linear-gradient(left, rgba(0, 0, 0, 0.5) 0%, rgba(0, 0, 0, 0.0001) 100%);
  background-image: -o-linear-gradient(left, rgba(0, 0, 0, 0.5) 0%, rgba(0, 0, 0, 0.0001) 100%);
  background-image: linear-gradient(to right, rgba(0, 0, 0, 0.5) 0%, rgba(0, 0, 0, 0.0001) 100%);
  background-repeat: repeat-x;
  filter: progid:DXImageTransform.Microsoft.gradient(startColorstr='#80000000', endColorstr='#00000000', GradientType=1);
}
.carousel-control.right {
  left: auto;
  right: 0;
  background-image: -webkit-linear-gradient(left, rgba(0, 0, 0, 0.0001) 0%, rgba(0, 0, 0, 0.5) 100%);
  background-image: -o-linear-gradient(left, rgba(0, 0, 0, 0.0001) 0%, rgba(0, 0, 0, 0.5) 100%);
  background-image: linear-gradient(to right, rgba(0, 0, 0, 0.0001) 0%, rgba(0, 0, 0, 0.5) 100%);
  background-repeat: repeat-x;
  filter: progid:DXImageTransform.Microsoft.gradient(startColorstr='#00000000', endColorstr='#80000000', GradientType=1);
}
.carousel-control:hover,
.carousel-control:focus {
  outline: 0;
  color: #fff;
  text-decoration: none;
  opacity: 0.9;
  filter: alpha(opacity=90);
}
.carousel-control .icon-prev,
.carousel-control .icon-next,
.carousel-control .glyphicon-chevron-left,
.carousel-control .glyphicon-chevron-right {
  position: absolute;
  top: 50%;
  margin-top: -10px;
  z-index: 5;
  display: inline-block;
}
.carousel-control .icon-prev,
.carousel-control .glyphicon-chevron-left {
  left: 50%;
  margin-left: -10px;
}
.carousel-control .icon-next,
.carousel-control .glyphicon-chevron-right {
  right: 50%;
  margin-right: -10px;
}
.carousel-control .icon-prev,
.carousel-control .icon-next {
  width: 20px;
  height: 20px;
  line-height: 1;
  font-family: serif;
}
.carousel-control .icon-prev:before {
  content: '\2039';
}
.carousel-control .icon-next:before {
  content: '\203a';
}
.carousel-indicators {
  position: absolute;
  bottom: 10px;
  left: 50%;
  z-index: 15;
  width: 60%;
  margin-left: -30%;
  padding-left: 0;
  list-style: none;
  text-align: center;
}
.carousel-indicators li {
  display: inline-block;
  width: 10px;
  height: 10px;
  margin: 1px;
  text-indent: -999px;
  border: 1px solid #fff;
  border-radius: 10px;
  cursor: pointer;
  background-color: #000 \9;
  background-color: rgba(0, 0, 0, 0);
}
.carousel-indicators .active {
  margin: 0;
  width: 12px;
  height: 12px;
  background-color: #fff;
}
.carousel-caption {
  position: absolute;
  left: 15%;
  right: 15%;
  bottom: 20px;
  z-index: 10;
  padding-top: 20px;
  padding-bottom: 20px;
  color: #fff;
  text-align: center;
  text-shadow: 0 1px 2px rgba(0, 0, 0, 0.6);
}
.carousel-caption .btn {
  text-shadow: none;
}
@media screen and (min-width: 768px) {
  .carousel-control .glyphicon-chevron-left,
  .carousel-control .glyphicon-chevron-right,
  .carousel-control .icon-prev,
  .carousel-control .icon-next {
    width: 30px;
    height: 30px;
    margin-top: -10px;
    font-size: 30px;
  }
  .carousel-control .glyphicon-chevron-left,
  .carousel-control .icon-prev {
    margin-left: -10px;
  }
  .carousel-control .glyphicon-chevron-right,
  .carousel-control .icon-next {
    margin-right: -10px;
  }
  .carousel-caption {
    left: 20%;
    right: 20%;
    padding-bottom: 30px;
  }
  .carousel-indicators {
    bottom: 20px;
  }
}
.clearfix:before,
.clearfix:after,
.dl-horizontal dd:before,
.dl-horizontal dd:after,
.container:before,
.container:after,
.container-fluid:before,
.container-fluid:after,
.row:before,
.row:after,
.form-horizontal .form-group:before,
.form-horizontal .form-group:after,
.btn-toolbar:before,
.btn-toolbar:after,
.btn-group-vertical > .btn-group:before,
.btn-group-vertical > .btn-group:after,
.nav:before,
.nav:after,
.navbar:before,
.navbar:after,
.navbar-header:before,
.navbar-header:after,
.navbar-collapse:before,
.navbar-collapse:after,
.pager:before,
.pager:after,
.panel-body:before,
.panel-body:after,
.modal-header:before,
.modal-header:after,
.modal-footer:before,
.modal-footer:after,
.item_buttons:before,
.item_buttons:after {
  content: " ";
  display: table;
}
.clearfix:after,
.dl-horizontal dd:after,
.container:after,
.container-fluid:after,
.row:after,
.form-horizontal .form-group:after,
.btn-toolbar:after,
.btn-group-vertical > .btn-group:after,
.nav:after,
.navbar:after,
.navbar-header:after,
.navbar-collapse:after,
.pager:after,
.panel-body:after,
.modal-header:after,
.modal-footer:after,
.item_buttons:after {
  clear: both;
}
.center-block {
  display: block;
  margin-left: auto;
  margin-right: auto;
}
.pull-right {
  float: right !important;
}
.pull-left {
  float: left !important;
}
.hide {
  display: none !important;
}
.show {
  display: block !important;
}
.invisible {
  visibility: hidden;
}
.text-hide {
  font: 0/0 a;
  color: transparent;
  text-shadow: none;
  background-color: transparent;
  border: 0;
}
.hidden {
  display: none !important;
}
.affix {
  position: fixed;
}
@-ms-viewport {
  width: device-width;
}
.visible-xs,
.visible-sm,
.visible-md,
.visible-lg {
  display: none !important;
}
.visible-xs-block,
.visible-xs-inline,
.visible-xs-inline-block,
.visible-sm-block,
.visible-sm-inline,
.visible-sm-inline-block,
.visible-md-block,
.visible-md-inline,
.visible-md-inline-block,
.visible-lg-block,
.visible-lg-inline,
.visible-lg-inline-block {
  display: none !important;
}
@media (max-width: 767px) {
  .visible-xs {
    display: block !important;
  }
  table.visible-xs {
    display: table !important;
  }
  tr.visible-xs {
    display: table-row !important;
  }
  th.visible-xs,
  td.visible-xs {
    display: table-cell !important;
  }
}
@media (max-width: 767px) {
  .visible-xs-block {
    display: block !important;
  }
}
@media (max-width: 767px) {
  .visible-xs-inline {
    display: inline !important;
  }
}
@media (max-width: 767px) {
  .visible-xs-inline-block {
    display: inline-block !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm {
    display: block !important;
  }
  table.visible-sm {
    display: table !important;
  }
  tr.visible-sm {
    display: table-row !important;
  }
  th.visible-sm,
  td.visible-sm {
    display: table-cell !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm-block {
    display: block !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm-inline {
    display: inline !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm-inline-block {
    display: inline-block !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md {
    display: block !important;
  }
  table.visible-md {
    display: table !important;
  }
  tr.visible-md {
    display: table-row !important;
  }
  th.visible-md,
  td.visible-md {
    display: table-cell !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md-block {
    display: block !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md-inline {
    display: inline !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md-inline-block {
    display: inline-block !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg {
    display: block !important;
  }
  table.visible-lg {
    display: table !important;
  }
  tr.visible-lg {
    display: table-row !important;
  }
  th.visible-lg,
  td.visible-lg {
    display: table-cell !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg-block {
    display: block !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg-inline {
    display: inline !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg-inline-block {
    display: inline-block !important;
  }
}
@media (max-width: 767px) {
  .hidden-xs {
    display: none !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .hidden-sm {
    display: none !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .hidden-md {
    display: none !important;
  }
}
@media (min-width: 1200px) {
  .hidden-lg {
    display: none !important;
  }
}
.visible-print {
  display: none !important;
}
@media print {
  .visible-print {
    display: block !important;
  }
  table.visible-print {
    display: table !important;
  }
  tr.visible-print {
    display: table-row !important;
  }
  th.visible-print,
  td.visible-print {
    display: table-cell !important;
  }
}
.visible-print-block {
  display: none !important;
}
@media print {
  .visible-print-block {
    display: block !important;
  }
}
.visible-print-inline {
  display: none !important;
}
@media print {
  .visible-print-inline {
    display: inline !important;
  }
}
.visible-print-inline-block {
  display: none !important;
}
@media print {
  .visible-print-inline-block {
    display: inline-block !important;
  }
}
@media print {
  .hidden-print {
    display: none !important;
  }
}
/*!
*
* Font Awesome
*
*/
/*!
 *  Font Awesome 4.7.0 by @davegandy - http://fontawesome.io - @fontawesome
 *  License - http://fontawesome.io/license (Font: SIL OFL 1.1, CSS: MIT License)
 */
/* FONT PATH
 * -------------------------- */
@font-face {
  font-family: 'FontAwesome';
  src: url('../components/font-awesome/fonts/fontawesome-webfont.eot?v=4.7.0');
  src: url('../components/font-awesome/fonts/fontawesome-webfont.eot?#iefix&v=4.7.0') format('embedded-opentype'), url('../components/font-awesome/fonts/fontawesome-webfont.woff2?v=4.7.0') format('woff2'), url('../components/font-awesome/fonts/fontawesome-webfont.woff?v=4.7.0') format('woff'), url('../components/font-awesome/fonts/fontawesome-webfont.ttf?v=4.7.0') format('truetype'), url('../components/font-awesome/fonts/fontawesome-webfont.svg?v=4.7.0#fontawesomeregular') format('svg');
  font-weight: normal;
  font-style: normal;
}
.fa {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
}
/* makes the font 33% larger relative to the icon container */
.fa-lg {
  font-size: 1.33333333em;
  line-height: 0.75em;
  vertical-align: -15%;
}
.fa-2x {
  font-size: 2em;
}
.fa-3x {
  font-size: 3em;
}
.fa-4x {
  font-size: 4em;
}
.fa-5x {
  font-size: 5em;
}
.fa-fw {
  width: 1.28571429em;
  text-align: center;
}
.fa-ul {
  padding-left: 0;
  margin-left: 2.14285714em;
  list-style-type: none;
}
.fa-ul > li {
  position: relative;
}
.fa-li {
  position: absolute;
  left: -2.14285714em;
  width: 2.14285714em;
  top: 0.14285714em;
  text-align: center;
}
.fa-li.fa-lg {
  left: -1.85714286em;
}
.fa-border {
  padding: .2em .25em .15em;
  border: solid 0.08em #eee;
  border-radius: .1em;
}
.fa-pull-left {
  float: left;
}
.fa-pull-right {
  float: right;
}
.fa.fa-pull-left {
  margin-right: .3em;
}
.fa.fa-pull-right {
  margin-left: .3em;
}
/* Deprecated as of 4.4.0 */
.pull-right {
  float: right;
}
.pull-left {
  float: left;
}
.fa.pull-left {
  margin-right: .3em;
}
.fa.pull-right {
  margin-left: .3em;
}
.fa-spin {
  -webkit-animation: fa-spin 2s infinite linear;
  animation: fa-spin 2s infinite linear;
}
.fa-pulse {
  -webkit-animation: fa-spin 1s infinite steps(8);
  animation: fa-spin 1s infinite steps(8);
}
@-webkit-keyframes fa-spin {
  0% {
    -webkit-transform: rotate(0deg);
    transform: rotate(0deg);
  }
  100% {
    -webkit-transform: rotate(359deg);
    transform: rotate(359deg);
  }
}
@keyframes fa-spin {
  0% {
    -webkit-transform: rotate(0deg);
    transform: rotate(0deg);
  }
  100% {
    -webkit-transform: rotate(359deg);
    transform: rotate(359deg);
  }
}
.fa-rotate-90 {
  -ms-filter: "progid:DXImageTransform.Microsoft.BasicImage(rotation=1)";
  -webkit-transform: rotate(90deg);
  -ms-transform: rotate(90deg);
  transform: rotate(90deg);
}
.fa-rotate-180 {
  -ms-filter: "progid:DXImageTransform.Microsoft.BasicImage(rotation=2)";
  -webkit-transform: rotate(180deg);
  -ms-transform: rotate(180deg);
  transform: rotate(180deg);
}
.fa-rotate-270 {
  -ms-filter: "progid:DXImageTransform.Microsoft.BasicImage(rotation=3)";
  -webkit-transform: rotate(270deg);
  -ms-transform: rotate(270deg);
  transform: rotate(270deg);
}
.fa-flip-horizontal {
  -ms-filter: "progid:DXImageTransform.Microsoft.BasicImage(rotation=0, mirror=1)";
  -webkit-transform: scale(-1, 1);
  -ms-transform: scale(-1, 1);
  transform: scale(-1, 1);
}
.fa-flip-vertical {
  -ms-filter: "progid:DXImageTransform.Microsoft.BasicImage(rotation=2, mirror=1)";
  -webkit-transform: scale(1, -1);
  -ms-transform: scale(1, -1);
  transform: scale(1, -1);
}
:root .fa-rotate-90,
:root .fa-rotate-180,
:root .fa-rotate-270,
:root .fa-flip-horizontal,
:root .fa-flip-vertical {
  filter: none;
}
.fa-stack {
  position: relative;
  display: inline-block;
  width: 2em;
  height: 2em;
  line-height: 2em;
  vertical-align: middle;
}
.fa-stack-1x,
.fa-stack-2x {
  position: absolute;
  left: 0;
  width: 100%;
  text-align: center;
}
.fa-stack-1x {
  line-height: inherit;
}
.fa-stack-2x {
  font-size: 2em;
}
.fa-inverse {
  color: #fff;
}
/* Font Awesome uses the Unicode Private Use Area (PUA) to ensure screen
   readers do not read off random characters that represent icons */
.fa-glass:before {
  content: "\f000";
}
.fa-music:before {
  content: "\f001";
}
.fa-search:before {
  content: "\f002";
}
.fa-envelope-o:before {
  content: "\f003";
}
.fa-heart:before {
  content: "\f004";
}
.fa-star:before {
  content: "\f005";
}
.fa-star-o:before {
  content: "\f006";
}
.fa-user:before {
  content: "\f007";
}
.fa-film:before {
  content: "\f008";
}
.fa-th-large:before {
  content: "\f009";
}
.fa-th:before {
  content: "\f00a";
}
.fa-th-list:before {
  content: "\f00b";
}
.fa-check:before {
  content: "\f00c";
}
.fa-remove:before,
.fa-close:before,
.fa-times:before {
  content: "\f00d";
}
.fa-search-plus:before {
  content: "\f00e";
}
.fa-search-minus:before {
  content: "\f010";
}
.fa-power-off:before {
  content: "\f011";
}
.fa-signal:before {
  content: "\f012";
}
.fa-gear:before,
.fa-cog:before {
  content: "\f013";
}
.fa-trash-o:before {
  content: "\f014";
}
.fa-home:before {
  content: "\f015";
}
.fa-file-o:before {
  content: "\f016";
}
.fa-clock-o:before {
  content: "\f017";
}
.fa-road:before {
  content: "\f018";
}
.fa-download:before {
  content: "\f019";
}
.fa-arrow-circle-o-down:before {
  content: "\f01a";
}
.fa-arrow-circle-o-up:before {
  content: "\f01b";
}
.fa-inbox:before {
  content: "\f01c";
}
.fa-play-circle-o:before {
  content: "\f01d";
}
.fa-rotate-right:before,
.fa-repeat:before {
  content: "\f01e";
}
.fa-refresh:before {
  content: "\f021";
}
.fa-list-alt:before {
  content: "\f022";
}
.fa-lock:before {
  content: "\f023";
}
.fa-flag:before {
  content: "\f024";
}
.fa-headphones:before {
  content: "\f025";
}
.fa-volume-off:before {
  content: "\f026";
}
.fa-volume-down:before {
  content: "\f027";
}
.fa-volume-up:before {
  content: "\f028";
}
.fa-qrcode:before {
  content: "\f029";
}
.fa-barcode:before {
  content: "\f02a";
}
.fa-tag:before {
  content: "\f02b";
}
.fa-tags:before {
  content: "\f02c";
}
.fa-book:before {
  content: "\f02d";
}
.fa-bookmark:before {
  content: "\f02e";
}
.fa-print:before {
  content: "\f02f";
}
.fa-camera:before {
  content: "\f030";
}
.fa-font:before {
  content: "\f031";
}
.fa-bold:before {
  content: "\f032";
}
.fa-italic:before {
  content: "\f033";
}
.fa-text-height:before {
  content: "\f034";
}
.fa-text-width:before {
  content: "\f035";
}
.fa-align-left:before {
  content: "\f036";
}
.fa-align-center:before {
  content: "\f037";
}
.fa-align-right:before {
  content: "\f038";
}
.fa-align-justify:before {
  content: "\f039";
}
.fa-list:before {
  content: "\f03a";
}
.fa-dedent:before,
.fa-outdent:before {
  content: "\f03b";
}
.fa-indent:before {
  content: "\f03c";
}
.fa-video-camera:before {
  content: "\f03d";
}
.fa-photo:before,
.fa-image:before,
.fa-picture-o:before {
  content: "\f03e";
}
.fa-pencil:before {
  content: "\f040";
}
.fa-map-marker:before {
  content: "\f041";
}
.fa-adjust:before {
  content: "\f042";
}
.fa-tint:before {
  content: "\f043";
}
.fa-edit:before,
.fa-pencil-square-o:before {
  content: "\f044";
}
.fa-share-square-o:before {
  content: "\f045";
}
.fa-check-square-o:before {
  content: "\f046";
}
.fa-arrows:before {
  content: "\f047";
}
.fa-step-backward:before {
  content: "\f048";
}
.fa-fast-backward:before {
  content: "\f049";
}
.fa-backward:before {
  content: "\f04a";
}
.fa-play:before {
  content: "\f04b";
}
.fa-pause:before {
  content: "\f04c";
}
.fa-stop:before {
  content: "\f04d";
}
.fa-forward:before {
  content: "\f04e";
}
.fa-fast-forward:before {
  content: "\f050";
}
.fa-step-forward:before {
  content: "\f051";
}
.fa-eject:before {
  content: "\f052";
}
.fa-chevron-left:before {
  content: "\f053";
}
.fa-chevron-right:before {
  content: "\f054";
}
.fa-plus-circle:before {
  content: "\f055";
}
.fa-minus-circle:before {
  content: "\f056";
}
.fa-times-circle:before {
  content: "\f057";
}
.fa-check-circle:before {
  content: "\f058";
}
.fa-question-circle:before {
  content: "\f059";
}
.fa-info-circle:before {
  content: "\f05a";
}
.fa-crosshairs:before {
  content: "\f05b";
}
.fa-times-circle-o:before {
  content: "\f05c";
}
.fa-check-circle-o:before {
  content: "\f05d";
}
.fa-ban:before {
  content: "\f05e";
}
.fa-arrow-left:before {
  content: "\f060";
}
.fa-arrow-right:before {
  content: "\f061";
}
.fa-arrow-up:before {
  content: "\f062";
}
.fa-arrow-down:before {
  content: "\f063";
}
.fa-mail-forward:before,
.fa-share:before {
  content: "\f064";
}
.fa-expand:before {
  content: "\f065";
}
.fa-compress:before {
  content: "\f066";
}
.fa-plus:before {
  content: "\f067";
}
.fa-minus:before {
  content: "\f068";
}
.fa-asterisk:before {
  content: "\f069";
}
.fa-exclamation-circle:before {
  content: "\f06a";
}
.fa-gift:before {
  content: "\f06b";
}
.fa-leaf:before {
  content: "\f06c";
}
.fa-fire:before {
  content: "\f06d";
}
.fa-eye:before {
  content: "\f06e";
}
.fa-eye-slash:before {
  content: "\f070";
}
.fa-warning:before,
.fa-exclamation-triangle:before {
  content: "\f071";
}
.fa-plane:before {
  content: "\f072";
}
.fa-calendar:before {
  content: "\f073";
}
.fa-random:before {
  content: "\f074";
}
.fa-comment:before {
  content: "\f075";
}
.fa-magnet:before {
  content: "\f076";
}
.fa-chevron-up:before {
  content: "\f077";
}
.fa-chevron-down:before {
  content: "\f078";
}
.fa-retweet:before {
  content: "\f079";
}
.fa-shopping-cart:before {
  content: "\f07a";
}
.fa-folder:before {
  content: "\f07b";
}
.fa-folder-open:before {
  content: "\f07c";
}
.fa-arrows-v:before {
  content: "\f07d";
}
.fa-arrows-h:before {
  content: "\f07e";
}
.fa-bar-chart-o:before,
.fa-bar-chart:before {
  content: "\f080";
}
.fa-twitter-square:before {
  content: "\f081";
}
.fa-facebook-square:before {
  content: "\f082";
}
.fa-camera-retro:before {
  content: "\f083";
}
.fa-key:before {
  content: "\f084";
}
.fa-gears:before,
.fa-cogs:before {
  content: "\f085";
}
.fa-comments:before {
  content: "\f086";
}
.fa-thumbs-o-up:before {
  content: "\f087";
}
.fa-thumbs-o-down:before {
  content: "\f088";
}
.fa-star-half:before {
  content: "\f089";
}
.fa-heart-o:before {
  content: "\f08a";
}
.fa-sign-out:before {
  content: "\f08b";
}
.fa-linkedin-square:before {
  content: "\f08c";
}
.fa-thumb-tack:before {
  content: "\f08d";
}
.fa-external-link:before {
  content: "\f08e";
}
.fa-sign-in:before {
  content: "\f090";
}
.fa-trophy:before {
  content: "\f091";
}
.fa-github-square:before {
  content: "\f092";
}
.fa-upload:before {
  content: "\f093";
}
.fa-lemon-o:before {
  content: "\f094";
}
.fa-phone:before {
  content: "\f095";
}
.fa-square-o:before {
  content: "\f096";
}
.fa-bookmark-o:before {
  content: "\f097";
}
.fa-phone-square:before {
  content: "\f098";
}
.fa-twitter:before {
  content: "\f099";
}
.fa-facebook-f:before,
.fa-facebook:before {
  content: "\f09a";
}
.fa-github:before {
  content: "\f09b";
}
.fa-unlock:before {
  content: "\f09c";
}
.fa-credit-card:before {
  content: "\f09d";
}
.fa-feed:before,
.fa-rss:before {
  content: "\f09e";
}
.fa-hdd-o:before {
  content: "\f0a0";
}
.fa-bullhorn:before {
  content: "\f0a1";
}
.fa-bell:before {
  content: "\f0f3";
}
.fa-certificate:before {
  content: "\f0a3";
}
.fa-hand-o-right:before {
  content: "\f0a4";
}
.fa-hand-o-left:before {
  content: "\f0a5";
}
.fa-hand-o-up:before {
  content: "\f0a6";
}
.fa-hand-o-down:before {
  content: "\f0a7";
}
.fa-arrow-circle-left:before {
  content: "\f0a8";
}
.fa-arrow-circle-right:before {
  content: "\f0a9";
}
.fa-arrow-circle-up:before {
  content: "\f0aa";
}
.fa-arrow-circle-down:before {
  content: "\f0ab";
}
.fa-globe:before {
  content: "\f0ac";
}
.fa-wrench:before {
  content: "\f0ad";
}
.fa-tasks:before {
  content: "\f0ae";
}
.fa-filter:before {
  content: "\f0b0";
}
.fa-briefcase:before {
  content: "\f0b1";
}
.fa-arrows-alt:before {
  content: "\f0b2";
}
.fa-group:before,
.fa-users:before {
  content: "\f0c0";
}
.fa-chain:before,
.fa-link:before {
  content: "\f0c1";
}
.fa-cloud:before {
  content: "\f0c2";
}
.fa-flask:before {
  content: "\f0c3";
}
.fa-cut:before,
.fa-scissors:before {
  content: "\f0c4";
}
.fa-copy:before,
.fa-files-o:before {
  content: "\f0c5";
}
.fa-paperclip:before {
  content: "\f0c6";
}
.fa-save:before,
.fa-floppy-o:before {
  content: "\f0c7";
}
.fa-square:before {
  content: "\f0c8";
}
.fa-navicon:before,
.fa-reorder:before,
.fa-bars:before {
  content: "\f0c9";
}
.fa-list-ul:before {
  content: "\f0ca";
}
.fa-list-ol:before {
  content: "\f0cb";
}
.fa-strikethrough:before {
  content: "\f0cc";
}
.fa-underline:before {
  content: "\f0cd";
}
.fa-table:before {
  content: "\f0ce";
}
.fa-magic:before {
  content: "\f0d0";
}
.fa-truck:before {
  content: "\f0d1";
}
.fa-pinterest:before {
  content: "\f0d2";
}
.fa-pinterest-square:before {
  content: "\f0d3";
}
.fa-google-plus-square:before {
  content: "\f0d4";
}
.fa-google-plus:before {
  content: "\f0d5";
}
.fa-money:before {
  content: "\f0d6";
}
.fa-caret-down:before {
  content: "\f0d7";
}
.fa-caret-up:before {
  content: "\f0d8";
}
.fa-caret-left:before {
  content: "\f0d9";
}
.fa-caret-right:before {
  content: "\f0da";
}
.fa-columns:before {
  content: "\f0db";
}
.fa-unsorted:before,
.fa-sort:before {
  content: "\f0dc";
}
.fa-sort-down:before,
.fa-sort-desc:before {
  content: "\f0dd";
}
.fa-sort-up:before,
.fa-sort-asc:before {
  content: "\f0de";
}
.fa-envelope:before {
  content: "\f0e0";
}
.fa-linkedin:before {
  content: "\f0e1";
}
.fa-rotate-left:before,
.fa-undo:before {
  content: "\f0e2";
}
.fa-legal:before,
.fa-gavel:before {
  content: "\f0e3";
}
.fa-dashboard:before,
.fa-tachometer:before {
  content: "\f0e4";
}
.fa-comment-o:before {
  content: "\f0e5";
}
.fa-comments-o:before {
  content: "\f0e6";
}
.fa-flash:before,
.fa-bolt:before {
  content: "\f0e7";
}
.fa-sitemap:before {
  content: "\f0e8";
}
.fa-umbrella:before {
  content: "\f0e9";
}
.fa-paste:before,
.fa-clipboard:before {
  content: "\f0ea";
}
.fa-lightbulb-o:before {
  content: "\f0eb";
}
.fa-exchange:before {
  content: "\f0ec";
}
.fa-cloud-download:before {
  content: "\f0ed";
}
.fa-cloud-upload:before {
  content: "\f0ee";
}
.fa-user-md:before {
  content: "\f0f0";
}
.fa-stethoscope:before {
  content: "\f0f1";
}
.fa-suitcase:before {
  content: "\f0f2";
}
.fa-bell-o:before {
  content: "\f0a2";
}
.fa-coffee:before {
  content: "\f0f4";
}
.fa-cutlery:before {
  content: "\f0f5";
}
.fa-file-text-o:before {
  content: "\f0f6";
}
.fa-building-o:before {
  content: "\f0f7";
}
.fa-hospital-o:before {
  content: "\f0f8";
}
.fa-ambulance:before {
  content: "\f0f9";
}
.fa-medkit:before {
  content: "\f0fa";
}
.fa-fighter-jet:before {
  content: "\f0fb";
}
.fa-beer:before {
  content: "\f0fc";
}
.fa-h-square:before {
  content: "\f0fd";
}
.fa-plus-square:before {
  content: "\f0fe";
}
.fa-angle-double-left:before {
  content: "\f100";
}
.fa-angle-double-right:before {
  content: "\f101";
}
.fa-angle-double-up:before {
  content: "\f102";
}
.fa-angle-double-down:before {
  content: "\f103";
}
.fa-angle-left:before {
  content: "\f104";
}
.fa-angle-right:before {
  content: "\f105";
}
.fa-angle-up:before {
  content: "\f106";
}
.fa-angle-down:before {
  content: "\f107";
}
.fa-desktop:before {
  content: "\f108";
}
.fa-laptop:before {
  content: "\f109";
}
.fa-tablet:before {
  content: "\f10a";
}
.fa-mobile-phone:before,
.fa-mobile:before {
  content: "\f10b";
}
.fa-circle-o:before {
  content: "\f10c";
}
.fa-quote-left:before {
  content: "\f10d";
}
.fa-quote-right:before {
  content: "\f10e";
}
.fa-spinner:before {
  content: "\f110";
}
.fa-circle:before {
  content: "\f111";
}
.fa-mail-reply:before,
.fa-reply:before {
  content: "\f112";
}
.fa-github-alt:before {
  content: "\f113";
}
.fa-folder-o:before {
  content: "\f114";
}
.fa-folder-open-o:before {
  content: "\f115";
}
.fa-smile-o:before {
  content: "\f118";
}
.fa-frown-o:before {
  content: "\f119";
}
.fa-meh-o:before {
  content: "\f11a";
}
.fa-gamepad:before {
  content: "\f11b";
}
.fa-keyboard-o:before {
  content: "\f11c";
}
.fa-flag-o:before {
  content: "\f11d";
}
.fa-flag-checkered:before {
  content: "\f11e";
}
.fa-terminal:before {
  content: "\f120";
}
.fa-code:before {
  content: "\f121";
}
.fa-mail-reply-all:before,
.fa-reply-all:before {
  content: "\f122";
}
.fa-star-half-empty:before,
.fa-star-half-full:before,
.fa-star-half-o:before {
  content: "\f123";
}
.fa-location-arrow:before {
  content: "\f124";
}
.fa-crop:before {
  content: "\f125";
}
.fa-code-fork:before {
  content: "\f126";
}
.fa-unlink:before,
.fa-chain-broken:before {
  content: "\f127";
}
.fa-question:before {
  content: "\f128";
}
.fa-info:before {
  content: "\f129";
}
.fa-exclamation:before {
  content: "\f12a";
}
.fa-superscript:before {
  content: "\f12b";
}
.fa-subscript:before {
  content: "\f12c";
}
.fa-eraser:before {
  content: "\f12d";
}
.fa-puzzle-piece:before {
  content: "\f12e";
}
.fa-microphone:before {
  content: "\f130";
}
.fa-microphone-slash:before {
  content: "\f131";
}
.fa-shield:before {
  content: "\f132";
}
.fa-calendar-o:before {
  content: "\f133";
}
.fa-fire-extinguisher:before {
  content: "\f134";
}
.fa-rocket:before {
  content: "\f135";
}
.fa-maxcdn:before {
  content: "\f136";
}
.fa-chevron-circle-left:before {
  content: "\f137";
}
.fa-chevron-circle-right:before {
  content: "\f138";
}
.fa-chevron-circle-up:before {
  content: "\f139";
}
.fa-chevron-circle-down:before {
  content: "\f13a";
}
.fa-html5:before {
  content: "\f13b";
}
.fa-css3:before {
  content: "\f13c";
}
.fa-anchor:before {
  content: "\f13d";
}
.fa-unlock-alt:before {
  content: "\f13e";
}
.fa-bullseye:before {
  content: "\f140";
}
.fa-ellipsis-h:before {
  content: "\f141";
}
.fa-ellipsis-v:before {
  content: "\f142";
}
.fa-rss-square:before {
  content: "\f143";
}
.fa-play-circle:before {
  content: "\f144";
}
.fa-ticket:before {
  content: "\f145";
}
.fa-minus-square:before {
  content: "\f146";
}
.fa-minus-square-o:before {
  content: "\f147";
}
.fa-level-up:before {
  content: "\f148";
}
.fa-level-down:before {
  content: "\f149";
}
.fa-check-square:before {
  content: "\f14a";
}
.fa-pencil-square:before {
  content: "\f14b";
}
.fa-external-link-square:before {
  content: "\f14c";
}
.fa-share-square:before {
  content: "\f14d";
}
.fa-compass:before {
  content: "\f14e";
}
.fa-toggle-down:before,
.fa-caret-square-o-down:before {
  content: "\f150";
}
.fa-toggle-up:before,
.fa-caret-square-o-up:before {
  content: "\f151";
}
.fa-toggle-right:before,
.fa-caret-square-o-right:before {
  content: "\f152";
}
.fa-euro:before,
.fa-eur:before {
  content: "\f153";
}
.fa-gbp:before {
  content: "\f154";
}
.fa-dollar:before,
.fa-usd:before {
  content: "\f155";
}
.fa-rupee:before,
.fa-inr:before {
  content: "\f156";
}
.fa-cny:before,
.fa-rmb:before,
.fa-yen:before,
.fa-jpy:before {
  content: "\f157";
}
.fa-ruble:before,
.fa-rouble:before,
.fa-rub:before {
  content: "\f158";
}
.fa-won:before,
.fa-krw:before {
  content: "\f159";
}
.fa-bitcoin:before,
.fa-btc:before {
  content: "\f15a";
}
.fa-file:before {
  content: "\f15b";
}
.fa-file-text:before {
  content: "\f15c";
}
.fa-sort-alpha-asc:before {
  content: "\f15d";
}
.fa-sort-alpha-desc:before {
  content: "\f15e";
}
.fa-sort-amount-asc:before {
  content: "\f160";
}
.fa-sort-amount-desc:before {
  content: "\f161";
}
.fa-sort-numeric-asc:before {
  content: "\f162";
}
.fa-sort-numeric-desc:before {
  content: "\f163";
}
.fa-thumbs-up:before {
  content: "\f164";
}
.fa-thumbs-down:before {
  content: "\f165";
}
.fa-youtube-square:before {
  content: "\f166";
}
.fa-youtube:before {
  content: "\f167";
}
.fa-xing:before {
  content: "\f168";
}
.fa-xing-square:before {
  content: "\f169";
}
.fa-youtube-play:before {
  content: "\f16a";
}
.fa-dropbox:before {
  content: "\f16b";
}
.fa-stack-overflow:before {
  content: "\f16c";
}
.fa-instagram:before {
  content: "\f16d";
}
.fa-flickr:before {
  content: "\f16e";
}
.fa-adn:before {
  content: "\f170";
}
.fa-bitbucket:before {
  content: "\f171";
}
.fa-bitbucket-square:before {
  content: "\f172";
}
.fa-tumblr:before {
  content: "\f173";
}
.fa-tumblr-square:before {
  content: "\f174";
}
.fa-long-arrow-down:before {
  content: "\f175";
}
.fa-long-arrow-up:before {
  content: "\f176";
}
.fa-long-arrow-left:before {
  content: "\f177";
}
.fa-long-arrow-right:before {
  content: "\f178";
}
.fa-apple:before {
  content: "\f179";
}
.fa-windows:before {
  content: "\f17a";
}
.fa-android:before {
  content: "\f17b";
}
.fa-linux:before {
  content: "\f17c";
}
.fa-dribbble:before {
  content: "\f17d";
}
.fa-skype:before {
  content: "\f17e";
}
.fa-foursquare:before {
  content: "\f180";
}
.fa-trello:before {
  content: "\f181";
}
.fa-female:before {
  content: "\f182";
}
.fa-male:before {
  content: "\f183";
}
.fa-gittip:before,
.fa-gratipay:before {
  content: "\f184";
}
.fa-sun-o:before {
  content: "\f185";
}
.fa-moon-o:before {
  content: "\f186";
}
.fa-archive:before {
  content: "\f187";
}
.fa-bug:before {
  content: "\f188";
}
.fa-vk:before {
  content: "\f189";
}
.fa-weibo:before {
  content: "\f18a";
}
.fa-renren:before {
  content: "\f18b";
}
.fa-pagelines:before {
  content: "\f18c";
}
.fa-stack-exchange:before {
  content: "\f18d";
}
.fa-arrow-circle-o-right:before {
  content: "\f18e";
}
.fa-arrow-circle-o-left:before {
  content: "\f190";
}
.fa-toggle-left:before,
.fa-caret-square-o-left:before {
  content: "\f191";
}
.fa-dot-circle-o:before {
  content: "\f192";
}
.fa-wheelchair:before {
  content: "\f193";
}
.fa-vimeo-square:before {
  content: "\f194";
}
.fa-turkish-lira:before,
.fa-try:before {
  content: "\f195";
}
.fa-plus-square-o:before {
  content: "\f196";
}
.fa-space-shuttle:before {
  content: "\f197";
}
.fa-slack:before {
  content: "\f198";
}
.fa-envelope-square:before {
  content: "\f199";
}
.fa-wordpress:before {
  content: "\f19a";
}
.fa-openid:before {
  content: "\f19b";
}
.fa-institution:before,
.fa-bank:before,
.fa-university:before {
  content: "\f19c";
}
.fa-mortar-board:before,
.fa-graduation-cap:before {
  content: "\f19d";
}
.fa-yahoo:before {
  content: "\f19e";
}
.fa-google:before {
  content: "\f1a0";
}
.fa-reddit:before {
  content: "\f1a1";
}
.fa-reddit-square:before {
  content: "\f1a2";
}
.fa-stumbleupon-circle:before {
  content: "\f1a3";
}
.fa-stumbleupon:before {
  content: "\f1a4";
}
.fa-delicious:before {
  content: "\f1a5";
}
.fa-digg:before {
  content: "\f1a6";
}
.fa-pied-piper-pp:before {
  content: "\f1a7";
}
.fa-pied-piper-alt:before {
  content: "\f1a8";
}
.fa-drupal:before {
  content: "\f1a9";
}
.fa-joomla:before {
  content: "\f1aa";
}
.fa-language:before {
  content: "\f1ab";
}
.fa-fax:before {
  content: "\f1ac";
}
.fa-building:before {
  content: "\f1ad";
}
.fa-child:before {
  content: "\f1ae";
}
.fa-paw:before {
  content: "\f1b0";
}
.fa-spoon:before {
  content: "\f1b1";
}
.fa-cube:before {
  content: "\f1b2";
}
.fa-cubes:before {
  content: "\f1b3";
}
.fa-behance:before {
  content: "\f1b4";
}
.fa-behance-square:before {
  content: "\f1b5";
}
.fa-steam:before {
  content: "\f1b6";
}
.fa-steam-square:before {
  content: "\f1b7";
}
.fa-recycle:before {
  content: "\f1b8";
}
.fa-automobile:before,
.fa-car:before {
  content: "\f1b9";
}
.fa-cab:before,
.fa-taxi:before {
  content: "\f1ba";
}
.fa-tree:before {
  content: "\f1bb";
}
.fa-spotify:before {
  content: "\f1bc";
}
.fa-deviantart:before {
  content: "\f1bd";
}
.fa-soundcloud:before {
  content: "\f1be";
}
.fa-database:before {
  content: "\f1c0";
}
.fa-file-pdf-o:before {
  content: "\f1c1";
}
.fa-file-word-o:before {
  content: "\f1c2";
}
.fa-file-excel-o:before {
  content: "\f1c3";
}
.fa-file-powerpoint-o:before {
  content: "\f1c4";
}
.fa-file-photo-o:before,
.fa-file-picture-o:before,
.fa-file-image-o:before {
  content: "\f1c5";
}
.fa-file-zip-o:before,
.fa-file-archive-o:before {
  content: "\f1c6";
}
.fa-file-sound-o:before,
.fa-file-audio-o:before {
  content: "\f1c7";
}
.fa-file-movie-o:before,
.fa-file-video-o:before {
  content: "\f1c8";
}
.fa-file-code-o:before {
  content: "\f1c9";
}
.fa-vine:before {
  content: "\f1ca";
}
.fa-codepen:before {
  content: "\f1cb";
}
.fa-jsfiddle:before {
  content: "\f1cc";
}
.fa-life-bouy:before,
.fa-life-buoy:before,
.fa-life-saver:before,
.fa-support:before,
.fa-life-ring:before {
  content: "\f1cd";
}
.fa-circle-o-notch:before {
  content: "\f1ce";
}
.fa-ra:before,
.fa-resistance:before,
.fa-rebel:before {
  content: "\f1d0";
}
.fa-ge:before,
.fa-empire:before {
  content: "\f1d1";
}
.fa-git-square:before {
  content: "\f1d2";
}
.fa-git:before {
  content: "\f1d3";
}
.fa-y-combinator-square:before,
.fa-yc-square:before,
.fa-hacker-news:before {
  content: "\f1d4";
}
.fa-tencent-weibo:before {
  content: "\f1d5";
}
.fa-qq:before {
  content: "\f1d6";
}
.fa-wechat:before,
.fa-weixin:before {
  content: "\f1d7";
}
.fa-send:before,
.fa-paper-plane:before {
  content: "\f1d8";
}
.fa-send-o:before,
.fa-paper-plane-o:before {
  content: "\f1d9";
}
.fa-history:before {
  content: "\f1da";
}
.fa-circle-thin:before {
  content: "\f1db";
}
.fa-header:before {
  content: "\f1dc";
}
.fa-paragraph:before {
  content: "\f1dd";
}
.fa-sliders:before {
  content: "\f1de";
}
.fa-share-alt:before {
  content: "\f1e0";
}
.fa-share-alt-square:before {
  content: "\f1e1";
}
.fa-bomb:before {
  content: "\f1e2";
}
.fa-soccer-ball-o:before,
.fa-futbol-o:before {
  content: "\f1e3";
}
.fa-tty:before {
  content: "\f1e4";
}
.fa-binoculars:before {
  content: "\f1e5";
}
.fa-plug:before {
  content: "\f1e6";
}
.fa-slideshare:before {
  content: "\f1e7";
}
.fa-twitch:before {
  content: "\f1e8";
}
.fa-yelp:before {
  content: "\f1e9";
}
.fa-newspaper-o:before {
  content: "\f1ea";
}
.fa-wifi:before {
  content: "\f1eb";
}
.fa-calculator:before {
  content: "\f1ec";
}
.fa-paypal:before {
  content: "\f1ed";
}
.fa-google-wallet:before {
  content: "\f1ee";
}
.fa-cc-visa:before {
  content: "\f1f0";
}
.fa-cc-mastercard:before {
  content: "\f1f1";
}
.fa-cc-discover:before {
  content: "\f1f2";
}
.fa-cc-amex:before {
  content: "\f1f3";
}
.fa-cc-paypal:before {
  content: "\f1f4";
}
.fa-cc-stripe:before {
  content: "\f1f5";
}
.fa-bell-slash:before {
  content: "\f1f6";
}
.fa-bell-slash-o:before {
  content: "\f1f7";
}
.fa-trash:before {
  content: "\f1f8";
}
.fa-copyright:before {
  content: "\f1f9";
}
.fa-at:before {
  content: "\f1fa";
}
.fa-eyedropper:before {
  content: "\f1fb";
}
.fa-paint-brush:before {
  content: "\f1fc";
}
.fa-birthday-cake:before {
  content: "\f1fd";
}
.fa-area-chart:before {
  content: "\f1fe";
}
.fa-pie-chart:before {
  content: "\f200";
}
.fa-line-chart:before {
  content: "\f201";
}
.fa-lastfm:before {
  content: "\f202";
}
.fa-lastfm-square:before {
  content: "\f203";
}
.fa-toggle-off:before {
  content: "\f204";
}
.fa-toggle-on:before {
  content: "\f205";
}
.fa-bicycle:before {
  content: "\f206";
}
.fa-bus:before {
  content: "\f207";
}
.fa-ioxhost:before {
  content: "\f208";
}
.fa-angellist:before {
  content: "\f209";
}
.fa-cc:before {
  content: "\f20a";
}
.fa-shekel:before,
.fa-sheqel:before,
.fa-ils:before {
  content: "\f20b";
}
.fa-meanpath:before {
  content: "\f20c";
}
.fa-buysellads:before {
  content: "\f20d";
}
.fa-connectdevelop:before {
  content: "\f20e";
}
.fa-dashcube:before {
  content: "\f210";
}
.fa-forumbee:before {
  content: "\f211";
}
.fa-leanpub:before {
  content: "\f212";
}
.fa-sellsy:before {
  content: "\f213";
}
.fa-shirtsinbulk:before {
  content: "\f214";
}
.fa-simplybuilt:before {
  content: "\f215";
}
.fa-skyatlas:before {
  content: "\f216";
}
.fa-cart-plus:before {
  content: "\f217";
}
.fa-cart-arrow-down:before {
  content: "\f218";
}
.fa-diamond:before {
  content: "\f219";
}
.fa-ship:before {
  content: "\f21a";
}
.fa-user-secret:before {
  content: "\f21b";
}
.fa-motorcycle:before {
  content: "\f21c";
}
.fa-street-view:before {
  content: "\f21d";
}
.fa-heartbeat:before {
  content: "\f21e";
}
.fa-venus:before {
  content: "\f221";
}
.fa-mars:before {
  content: "\f222";
}
.fa-mercury:before {
  content: "\f223";
}
.fa-intersex:before,
.fa-transgender:before {
  content: "\f224";
}
.fa-transgender-alt:before {
  content: "\f225";
}
.fa-venus-double:before {
  content: "\f226";
}
.fa-mars-double:before {
  content: "\f227";
}
.fa-venus-mars:before {
  content: "\f228";
}
.fa-mars-stroke:before {
  content: "\f229";
}
.fa-mars-stroke-v:before {
  content: "\f22a";
}
.fa-mars-stroke-h:before {
  content: "\f22b";
}
.fa-neuter:before {
  content: "\f22c";
}
.fa-genderless:before {
  content: "\f22d";
}
.fa-facebook-official:before {
  content: "\f230";
}
.fa-pinterest-p:before {
  content: "\f231";
}
.fa-whatsapp:before {
  content: "\f232";
}
.fa-server:before {
  content: "\f233";
}
.fa-user-plus:before {
  content: "\f234";
}
.fa-user-times:before {
  content: "\f235";
}
.fa-hotel:before,
.fa-bed:before {
  content: "\f236";
}
.fa-viacoin:before {
  content: "\f237";
}
.fa-train:before {
  content: "\f238";
}
.fa-subway:before {
  content: "\f239";
}
.fa-medium:before {
  content: "\f23a";
}
.fa-yc:before,
.fa-y-combinator:before {
  content: "\f23b";
}
.fa-optin-monster:before {
  content: "\f23c";
}
.fa-opencart:before {
  content: "\f23d";
}
.fa-expeditedssl:before {
  content: "\f23e";
}
.fa-battery-4:before,
.fa-battery:before,
.fa-battery-full:before {
  content: "\f240";
}
.fa-battery-3:before,
.fa-battery-three-quarters:before {
  content: "\f241";
}
.fa-battery-2:before,
.fa-battery-half:before {
  content: "\f242";
}
.fa-battery-1:before,
.fa-battery-quarter:before {
  content: "\f243";
}
.fa-battery-0:before,
.fa-battery-empty:before {
  content: "\f244";
}
.fa-mouse-pointer:before {
  content: "\f245";
}
.fa-i-cursor:before {
  content: "\f246";
}
.fa-object-group:before {
  content: "\f247";
}
.fa-object-ungroup:before {
  content: "\f248";
}
.fa-sticky-note:before {
  content: "\f249";
}
.fa-sticky-note-o:before {
  content: "\f24a";
}
.fa-cc-jcb:before {
  content: "\f24b";
}
.fa-cc-diners-club:before {
  content: "\f24c";
}
.fa-clone:before {
  content: "\f24d";
}
.fa-balance-scale:before {
  content: "\f24e";
}
.fa-hourglass-o:before {
  content: "\f250";
}
.fa-hourglass-1:before,
.fa-hourglass-start:before {
  content: "\f251";
}
.fa-hourglass-2:before,
.fa-hourglass-half:before {
  content: "\f252";
}
.fa-hourglass-3:before,
.fa-hourglass-end:before {
  content: "\f253";
}
.fa-hourglass:before {
  content: "\f254";
}
.fa-hand-grab-o:before,
.fa-hand-rock-o:before {
  content: "\f255";
}
.fa-hand-stop-o:before,
.fa-hand-paper-o:before {
  content: "\f256";
}
.fa-hand-scissors-o:before {
  content: "\f257";
}
.fa-hand-lizard-o:before {
  content: "\f258";
}
.fa-hand-spock-o:before {
  content: "\f259";
}
.fa-hand-pointer-o:before {
  content: "\f25a";
}
.fa-hand-peace-o:before {
  content: "\f25b";
}
.fa-trademark:before {
  content: "\f25c";
}
.fa-registered:before {
  content: "\f25d";
}
.fa-creative-commons:before {
  content: "\f25e";
}
.fa-gg:before {
  content: "\f260";
}
.fa-gg-circle:before {
  content: "\f261";
}
.fa-tripadvisor:before {
  content: "\f262";
}
.fa-odnoklassniki:before {
  content: "\f263";
}
.fa-odnoklassniki-square:before {
  content: "\f264";
}
.fa-get-pocket:before {
  content: "\f265";
}
.fa-wikipedia-w:before {
  content: "\f266";
}
.fa-safari:before {
  content: "\f267";
}
.fa-chrome:before {
  content: "\f268";
}
.fa-firefox:before {
  content: "\f269";
}
.fa-opera:before {
  content: "\f26a";
}
.fa-internet-explorer:before {
  content: "\f26b";
}
.fa-tv:before,
.fa-television:before {
  content: "\f26c";
}
.fa-contao:before {
  content: "\f26d";
}
.fa-500px:before {
  content: "\f26e";
}
.fa-amazon:before {
  content: "\f270";
}
.fa-calendar-plus-o:before {
  content: "\f271";
}
.fa-calendar-minus-o:before {
  content: "\f272";
}
.fa-calendar-times-o:before {
  content: "\f273";
}
.fa-calendar-check-o:before {
  content: "\f274";
}
.fa-industry:before {
  content: "\f275";
}
.fa-map-pin:before {
  content: "\f276";
}
.fa-map-signs:before {
  content: "\f277";
}
.fa-map-o:before {
  content: "\f278";
}
.fa-map:before {
  content: "\f279";
}
.fa-commenting:before {
  content: "\f27a";
}
.fa-commenting-o:before {
  content: "\f27b";
}
.fa-houzz:before {
  content: "\f27c";
}
.fa-vimeo:before {
  content: "\f27d";
}
.fa-black-tie:before {
  content: "\f27e";
}
.fa-fonticons:before {
  content: "\f280";
}
.fa-reddit-alien:before {
  content: "\f281";
}
.fa-edge:before {
  content: "\f282";
}
.fa-credit-card-alt:before {
  content: "\f283";
}
.fa-codiepie:before {
  content: "\f284";
}
.fa-modx:before {
  content: "\f285";
}
.fa-fort-awesome:before {
  content: "\f286";
}
.fa-usb:before {
  content: "\f287";
}
.fa-product-hunt:before {
  content: "\f288";
}
.fa-mixcloud:before {
  content: "\f289";
}
.fa-scribd:before {
  content: "\f28a";
}
.fa-pause-circle:before {
  content: "\f28b";
}
.fa-pause-circle-o:before {
  content: "\f28c";
}
.fa-stop-circle:before {
  content: "\f28d";
}
.fa-stop-circle-o:before {
  content: "\f28e";
}
.fa-shopping-bag:before {
  content: "\f290";
}
.fa-shopping-basket:before {
  content: "\f291";
}
.fa-hashtag:before {
  content: "\f292";
}
.fa-bluetooth:before {
  content: "\f293";
}
.fa-bluetooth-b:before {
  content: "\f294";
}
.fa-percent:before {
  content: "\f295";
}
.fa-gitlab:before {
  content: "\f296";
}
.fa-wpbeginner:before {
  content: "\f297";
}
.fa-wpforms:before {
  content: "\f298";
}
.fa-envira:before {
  content: "\f299";
}
.fa-universal-access:before {
  content: "\f29a";
}
.fa-wheelchair-alt:before {
  content: "\f29b";
}
.fa-question-circle-o:before {
  content: "\f29c";
}
.fa-blind:before {
  content: "\f29d";
}
.fa-audio-description:before {
  content: "\f29e";
}
.fa-volume-control-phone:before {
  content: "\f2a0";
}
.fa-braille:before {
  content: "\f2a1";
}
.fa-assistive-listening-systems:before {
  content: "\f2a2";
}
.fa-asl-interpreting:before,
.fa-american-sign-language-interpreting:before {
  content: "\f2a3";
}
.fa-deafness:before,
.fa-hard-of-hearing:before,
.fa-deaf:before {
  content: "\f2a4";
}
.fa-glide:before {
  content: "\f2a5";
}
.fa-glide-g:before {
  content: "\f2a6";
}
.fa-signing:before,
.fa-sign-language:before {
  content: "\f2a7";
}
.fa-low-vision:before {
  content: "\f2a8";
}
.fa-viadeo:before {
  content: "\f2a9";
}
.fa-viadeo-square:before {
  content: "\f2aa";
}
.fa-snapchat:before {
  content: "\f2ab";
}
.fa-snapchat-ghost:before {
  content: "\f2ac";
}
.fa-snapchat-square:before {
  content: "\f2ad";
}
.fa-pied-piper:before {
  content: "\f2ae";
}
.fa-first-order:before {
  content: "\f2b0";
}
.fa-yoast:before {
  content: "\f2b1";
}
.fa-themeisle:before {
  content: "\f2b2";
}
.fa-google-plus-circle:before,
.fa-google-plus-official:before {
  content: "\f2b3";
}
.fa-fa:before,
.fa-font-awesome:before {
  content: "\f2b4";
}
.fa-handshake-o:before {
  content: "\f2b5";
}
.fa-envelope-open:before {
  content: "\f2b6";
}
.fa-envelope-open-o:before {
  content: "\f2b7";
}
.fa-linode:before {
  content: "\f2b8";
}
.fa-address-book:before {
  content: "\f2b9";
}
.fa-address-book-o:before {
  content: "\f2ba";
}
.fa-vcard:before,
.fa-address-card:before {
  content: "\f2bb";
}
.fa-vcard-o:before,
.fa-address-card-o:before {
  content: "\f2bc";
}
.fa-user-circle:before {
  content: "\f2bd";
}
.fa-user-circle-o:before {
  content: "\f2be";
}
.fa-user-o:before {
  content: "\f2c0";
}
.fa-id-badge:before {
  content: "\f2c1";
}
.fa-drivers-license:before,
.fa-id-card:before {
  content: "\f2c2";
}
.fa-drivers-license-o:before,
.fa-id-card-o:before {
  content: "\f2c3";
}
.fa-quora:before {
  content: "\f2c4";
}
.fa-free-code-camp:before {
  content: "\f2c5";
}
.fa-telegram:before {
  content: "\f2c6";
}
.fa-thermometer-4:before,
.fa-thermometer:before,
.fa-thermometer-full:before {
  content: "\f2c7";
}
.fa-thermometer-3:before,
.fa-thermometer-three-quarters:before {
  content: "\f2c8";
}
.fa-thermometer-2:before,
.fa-thermometer-half:before {
  content: "\f2c9";
}
.fa-thermometer-1:before,
.fa-thermometer-quarter:before {
  content: "\f2ca";
}
.fa-thermometer-0:before,
.fa-thermometer-empty:before {
  content: "\f2cb";
}
.fa-shower:before {
  content: "\f2cc";
}
.fa-bathtub:before,
.fa-s15:before,
.fa-bath:before {
  content: "\f2cd";
}
.fa-podcast:before {
  content: "\f2ce";
}
.fa-window-maximize:before {
  content: "\f2d0";
}
.fa-window-minimize:before {
  content: "\f2d1";
}
.fa-window-restore:before {
  content: "\f2d2";
}
.fa-times-rectangle:before,
.fa-window-close:before {
  content: "\f2d3";
}
.fa-times-rectangle-o:before,
.fa-window-close-o:before {
  content: "\f2d4";
}
.fa-bandcamp:before {
  content: "\f2d5";
}
.fa-grav:before {
  content: "\f2d6";
}
.fa-etsy:before {
  content: "\f2d7";
}
.fa-imdb:before {
  content: "\f2d8";
}
.fa-ravelry:before {
  content: "\f2d9";
}
.fa-eercast:before {
  content: "\f2da";
}
.fa-microchip:before {
  content: "\f2db";
}
.fa-snowflake-o:before {
  content: "\f2dc";
}
.fa-superpowers:before {
  content: "\f2dd";
}
.fa-wpexplorer:before {
  content: "\f2de";
}
.fa-meetup:before {
  content: "\f2e0";
}
.sr-only {
  position: absolute;
  width: 1px;
  height: 1px;
  padding: 0;
  margin: -1px;
  overflow: hidden;
  clip: rect(0, 0, 0, 0);
  border: 0;
}
.sr-only-focusable:active,
.sr-only-focusable:focus {
  position: static;
  width: auto;
  height: auto;
  margin: 0;
  overflow: visible;
  clip: auto;
}
.sr-only-focusable:active,
.sr-only-focusable:focus {
  position: static;
  width: auto;
  height: auto;
  margin: 0;
  overflow: visible;
  clip: auto;
}
/*!
*
* IPython base
*
*/
.modal.fade .modal-dialog {
  -webkit-transform: translate(0, 0);
  -ms-transform: translate(0, 0);
  -o-transform: translate(0, 0);
  transform: translate(0, 0);
}
code {
  color: #000;
}
pre {
  font-size: inherit;
  line-height: inherit;
}
label {
  font-weight: normal;
}
/* Make the page background atleast 100% the height of the view port */
/* Make the page itself atleast 70% the height of the view port */
.border-box-sizing {
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
.corner-all {
  border-radius: 2px;
}
.no-padding {
  padding: 0px;
}
/* Flexible box model classes */
/* Taken from Alex Russell http://infrequently.org/2009/08/css-3-progress/ */
/* This file is a compatability layer.  It allows the usage of flexible box 
model layouts accross multiple browsers, including older browsers.  The newest,
universal implementation of the flexible box model is used when available (see
`Modern browsers` comments below).  Browsers that are known to implement this 
new spec completely include:

    Firefox 28.0+
    Chrome 29.0+
    Internet Explorer 11+ 
    Opera 17.0+

Browsers not listed, including Safari, are supported via the styling under the
`Old browsers` comments below.
*/
.hbox {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
.hbox > * {
  /* Old browsers */
  -webkit-box-flex: 0;
  -moz-box-flex: 0;
  box-flex: 0;
  /* Modern browsers */
  flex: none;
}
.vbox {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
.vbox > * {
  /* Old browsers */
  -webkit-box-flex: 0;
  -moz-box-flex: 0;
  box-flex: 0;
  /* Modern browsers */
  flex: none;
}
.hbox.reverse,
.vbox.reverse,
.reverse {
  /* Old browsers */
  -webkit-box-direction: reverse;
  -moz-box-direction: reverse;
  box-direction: reverse;
  /* Modern browsers */
  flex-direction: row-reverse;
}
.hbox.box-flex0,
.vbox.box-flex0,
.box-flex0 {
  /* Old browsers */
  -webkit-box-flex: 0;
  -moz-box-flex: 0;
  box-flex: 0;
  /* Modern browsers */
  flex: none;
  width: auto;
}
.hbox.box-flex1,
.vbox.box-flex1,
.box-flex1 {
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
.hbox.box-flex,
.vbox.box-flex,
.box-flex {
  /* Old browsers */
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
.hbox.box-flex2,
.vbox.box-flex2,
.box-flex2 {
  /* Old browsers */
  -webkit-box-flex: 2;
  -moz-box-flex: 2;
  box-flex: 2;
  /* Modern browsers */
  flex: 2;
}
.box-group1 {
  /*  Deprecated */
  -webkit-box-flex-group: 1;
  -moz-box-flex-group: 1;
  box-flex-group: 1;
}
.box-group2 {
  /* Deprecated */
  -webkit-box-flex-group: 2;
  -moz-box-flex-group: 2;
  box-flex-group: 2;
}
.hbox.start,
.vbox.start,
.start {
  /* Old browsers */
  -webkit-box-pack: start;
  -moz-box-pack: start;
  box-pack: start;
  /* Modern browsers */
  justify-content: flex-start;
}
.hbox.end,
.vbox.end,
.end {
  /* Old browsers */
  -webkit-box-pack: end;
  -moz-box-pack: end;
  box-pack: end;
  /* Modern browsers */
  justify-content: flex-end;
}
.hbox.center,
.vbox.center,
.center {
  /* Old browsers */
  -webkit-box-pack: center;
  -moz-box-pack: center;
  box-pack: center;
  /* Modern browsers */
  justify-content: center;
}
.hbox.baseline,
.vbox.baseline,
.baseline {
  /* Old browsers */
  -webkit-box-pack: baseline;
  -moz-box-pack: baseline;
  box-pack: baseline;
  /* Modern browsers */
  justify-content: baseline;
}
.hbox.stretch,
.vbox.stretch,
.stretch {
  /* Old browsers */
  -webkit-box-pack: stretch;
  -moz-box-pack: stretch;
  box-pack: stretch;
  /* Modern browsers */
  justify-content: stretch;
}
.hbox.align-start,
.vbox.align-start,
.align-start {
  /* Old browsers */
  -webkit-box-align: start;
  -moz-box-align: start;
  box-align: start;
  /* Modern browsers */
  align-items: flex-start;
}
.hbox.align-end,
.vbox.align-end,
.align-end {
  /* Old browsers */
  -webkit-box-align: end;
  -moz-box-align: end;
  box-align: end;
  /* Modern browsers */
  align-items: flex-end;
}
.hbox.align-center,
.vbox.align-center,
.align-center {
  /* Old browsers */
  -webkit-box-align: center;
  -moz-box-align: center;
  box-align: center;
  /* Modern browsers */
  align-items: center;
}
.hbox.align-baseline,
.vbox.align-baseline,
.align-baseline {
  /* Old browsers */
  -webkit-box-align: baseline;
  -moz-box-align: baseline;
  box-align: baseline;
  /* Modern browsers */
  align-items: baseline;
}
.hbox.align-stretch,
.vbox.align-stretch,
.align-stretch {
  /* Old browsers */
  -webkit-box-align: stretch;
  -moz-box-align: stretch;
  box-align: stretch;
  /* Modern browsers */
  align-items: stretch;
}
div.error {
  margin: 2em;
  text-align: center;
}
div.error > h1 {
  font-size: 500%;
  line-height: normal;
}
div.error > p {
  font-size: 200%;
  line-height: normal;
}
div.traceback-wrapper {
  text-align: left;
  max-width: 800px;
  margin: auto;
}
div.traceback-wrapper pre.traceback {
  max-height: 600px;
  overflow: auto;
}
/**
 * Primary styles
 *
 * Author: Jupyter Development Team
 */
body {
  background-color: #fff;
  /* This makes sure that the body covers the entire window and needs to
       be in a different element than the display: box in wrapper below */
  position: absolute;
  left: 0px;
  right: 0px;
  top: 0px;
  bottom: 0px;
  overflow: visible;
}
body > #header {
  /* Initially hidden to prevent FLOUC */
  display: none;
  background-color: #fff;
  /* Display over codemirror */
  position: relative;
  z-index: 100;
}
body > #header #header-container {
  display: flex;
  flex-direction: row;
  justify-content: space-between;
  padding: 5px;
  padding-bottom: 5px;
  padding-top: 5px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
body > #header .header-bar {
  width: 100%;
  height: 1px;
  background: #e7e7e7;
  margin-bottom: -1px;
}
@media print {
  body > #header {
    display: none !important;
  }
}
#header-spacer {
  width: 100%;
  visibility: hidden;
}
@media print {
  #header-spacer {
    display: none;
  }
}
#ipython_notebook {
  padding-left: 0px;
  padding-top: 1px;
  padding-bottom: 1px;
}
[dir="rtl"] #ipython_notebook {
  margin-right: 10px;
  margin-left: 0;
}
[dir="rtl"] #ipython_notebook.pull-left {
  float: right !important;
  float: right;
}
.flex-spacer {
  flex: 1;
}
#noscript {
  width: auto;
  padding-top: 16px;
  padding-bottom: 16px;
  text-align: center;
  font-size: 22px;
  color: red;
  font-weight: bold;
}
#ipython_notebook img {
  height: 28px;
}
#site {
  width: 100%;
  display: none;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  overflow: auto;
}
@media print {
  #site {
    height: auto !important;
  }
}
/* Smaller buttons */
.ui-button .ui-button-text {
  padding: 0.2em 0.8em;
  font-size: 77%;
}
input.ui-button {
  padding: 0.3em 0.9em;
}
span#kernel_logo_widget {
  margin: 0 10px;
}
span#login_widget {
  float: right;
}
[dir="rtl"] span#login_widget {
  float: left;
}
span#login_widget > .button,
#logout {
  color: #333;
  background-color: #fff;
  border-color: #ccc;
}
span#login_widget > .button:focus,
#logout:focus,
span#login_widget > .button.focus,
#logout.focus {
  color: #333;
  background-color: #e6e6e6;
  border-color: #8c8c8c;
}
span#login_widget > .button:hover,
#logout:hover {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
span#login_widget > .button:active,
#logout:active,
span#login_widget > .button.active,
#logout.active,
.open > .dropdown-togglespan#login_widget > .button,
.open > .dropdown-toggle#logout {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
span#login_widget > .button:active:hover,
#logout:active:hover,
span#login_widget > .button.active:hover,
#logout.active:hover,
.open > .dropdown-togglespan#login_widget > .button:hover,
.open > .dropdown-toggle#logout:hover,
span#login_widget > .button:active:focus,
#logout:active:focus,
span#login_widget > .button.active:focus,
#logout.active:focus,
.open > .dropdown-togglespan#login_widget > .button:focus,
.open > .dropdown-toggle#logout:focus,
span#login_widget > .button:active.focus,
#logout:active.focus,
span#login_widget > .button.active.focus,
#logout.active.focus,
.open > .dropdown-togglespan#login_widget > .button.focus,
.open > .dropdown-toggle#logout.focus {
  color: #333;
  background-color: #d4d4d4;
  border-color: #8c8c8c;
}
span#login_widget > .button:active,
#logout:active,
span#login_widget > .button.active,
#logout.active,
.open > .dropdown-togglespan#login_widget > .button,
.open > .dropdown-toggle#logout {
  background-image: none;
}
span#login_widget > .button.disabled:hover,
#logout.disabled:hover,
span#login_widget > .button[disabled]:hover,
#logout[disabled]:hover,
fieldset[disabled] span#login_widget > .button:hover,
fieldset[disabled] #logout:hover,
span#login_widget > .button.disabled:focus,
#logout.disabled:focus,
span#login_widget > .button[disabled]:focus,
#logout[disabled]:focus,
fieldset[disabled] span#login_widget > .button:focus,
fieldset[disabled] #logout:focus,
span#login_widget > .button.disabled.focus,
#logout.disabled.focus,
span#login_widget > .button[disabled].focus,
#logout[disabled].focus,
fieldset[disabled] span#login_widget > .button.focus,
fieldset[disabled] #logout.focus {
  background-color: #fff;
  border-color: #ccc;
}
span#login_widget > .button .badge,
#logout .badge {
  color: #fff;
  background-color: #333;
}
.nav-header {
  text-transform: none;
}
#header > span {
  margin-top: 10px;
}
.modal_stretch .modal-dialog {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  min-height: 80vh;
}
.modal_stretch .modal-dialog .modal-body {
  max-height: calc(100vh - 200px);
  overflow: auto;
  flex: 1;
}
.modal-header {
  cursor: move;
}
@media (min-width: 768px) {
  .modal .modal-dialog {
    width: 700px;
  }
}
@media (min-width: 768px) {
  select.form-control {
    margin-left: 12px;
    margin-right: 12px;
  }
}
/*!
*
* IPython auth
*
*/
.center-nav {
  display: inline-block;
  margin-bottom: -4px;
}
[dir="rtl"] .center-nav form.pull-left {
  float: right !important;
  float: right;
}
[dir="rtl"] .center-nav .navbar-text {
  float: right;
}
[dir="rtl"] .navbar-inner {
  text-align: right;
}
[dir="rtl"] div.text-left {
  text-align: right;
}
/*!
*
* IPython tree view
*
*/
/* We need an invisible input field on top of the sentense*/
/* "Drag file onto the list ..." */
.alternate_upload {
  background-color: none;
  display: inline;
}
.alternate_upload.form {
  padding: 0;
  margin: 0;
}
.alternate_upload input.fileinput {
  position: absolute;
  display: block;
  width: 100%;
  height: 100%;
  overflow: hidden;
  cursor: pointer;
  opacity: 0;
  z-index: 2;
}
.alternate_upload .btn-xs > input.fileinput {
  margin: -1px -5px;
}
.alternate_upload .btn-upload {
  position: relative;
  height: 22px;
}
::-webkit-file-upload-button {
  cursor: pointer;
}
/**
 * Primary styles
 *
 * Author: Jupyter Development Team
 */
ul#tabs {
  margin-bottom: 4px;
}
ul#tabs a {
  padding-top: 6px;
  padding-bottom: 4px;
}
[dir="rtl"] ul#tabs.nav-tabs > li {
  float: right;
}
[dir="rtl"] ul#tabs.nav.nav-tabs {
  padding-right: 0;
}
ul.breadcrumb a:focus,
ul.breadcrumb a:hover {
  text-decoration: none;
}
ul.breadcrumb i.icon-home {
  font-size: 16px;
  margin-right: 4px;
}
ul.breadcrumb span {
  color: #5e5e5e;
}
.list_toolbar {
  padding: 4px 0 4px 0;
  vertical-align: middle;
}
.list_toolbar .tree-buttons {
  padding-top: 1px;
}
[dir="rtl"] .list_toolbar .tree-buttons .pull-right {
  float: left !important;
  float: left;
}
[dir="rtl"] .list_toolbar .col-sm-4,
[dir="rtl"] .list_toolbar .col-sm-8 {
  float: right;
}
.dynamic-buttons {
  padding-top: 3px;
  display: inline-block;
}
.list_toolbar [class*="span"] {
  min-height: 24px;
}
.list_header {
  font-weight: bold;
  background-color: #EEE;
}
.list_placeholder {
  font-weight: bold;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 7px;
  padding-right: 7px;
}
.list_container {
  margin-top: 4px;
  margin-bottom: 20px;
  border: 1px solid #ddd;
  border-radius: 2px;
}
.list_container > div {
  border-bottom: 1px solid #ddd;
}
.list_container > div:hover .list-item {
  background-color: red;
}
.list_container > div:last-child {
  border: none;
}
.list_item:hover .list_item {
  background-color: #ddd;
}
.list_item a {
  text-decoration: none;
}
.list_item:hover {
  background-color: #fafafa;
}
.list_header > div,
.list_item > div {
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 7px;
  padding-right: 7px;
  line-height: 22px;
}
.list_header > div input,
.list_item > div input {
  margin-right: 7px;
  margin-left: 14px;
  vertical-align: text-bottom;
  line-height: 22px;
  position: relative;
  top: -1px;
}
.list_header > div .item_link,
.list_item > div .item_link {
  margin-left: -1px;
  vertical-align: baseline;
  line-height: 22px;
}
[dir="rtl"] .list_item > div input {
  margin-right: 0;
}
.new-file input[type=checkbox] {
  visibility: hidden;
}
.item_name {
  line-height: 22px;
  height: 24px;
}
.item_icon {
  font-size: 14px;
  color: #5e5e5e;
  margin-right: 7px;
  margin-left: 7px;
  line-height: 22px;
  vertical-align: baseline;
}
.item_modified {
  margin-right: 7px;
  margin-left: 7px;
}
[dir="rtl"] .item_modified.pull-right {
  float: left !important;
  float: left;
}
.item_buttons {
  line-height: 1em;
  margin-left: -5px;
}
.item_buttons .btn,
.item_buttons .btn-group,
.item_buttons .input-group {
  float: left;
}
.item_buttons > .btn,
.item_buttons > .btn-group,
.item_buttons > .input-group {
  margin-left: 5px;
}
.item_buttons .btn {
  min-width: 13ex;
}
.item_buttons .running-indicator {
  padding-top: 4px;
  color: #5cb85c;
}
.item_buttons .kernel-name {
  padding-top: 4px;
  color: #5bc0de;
  margin-right: 7px;
  float: left;
}
[dir="rtl"] .item_buttons.pull-right {
  float: left !important;
  float: left;
}
[dir="rtl"] .item_buttons .kernel-name {
  margin-left: 7px;
  float: right;
}
.toolbar_info {
  height: 24px;
  line-height: 24px;
}
.list_item input:not([type=checkbox]) {
  padding-top: 3px;
  padding-bottom: 3px;
  height: 22px;
  line-height: 14px;
  margin: 0px;
}
.highlight_text {
  color: blue;
}
#project_name {
  display: inline-block;
  padding-left: 7px;
  margin-left: -2px;
}
#project_name > .breadcrumb {
  padding: 0px;
  margin-bottom: 0px;
  background-color: transparent;
  font-weight: bold;
}
.sort_button {
  display: inline-block;
  padding-left: 7px;
}
[dir="rtl"] .sort_button.pull-right {
  float: left !important;
  float: left;
}
#tree-selector {
  padding-right: 0px;
}
#button-select-all {
  min-width: 50px;
}
[dir="rtl"] #button-select-all.btn {
  float: right ;
}
#select-all {
  margin-left: 7px;
  margin-right: 2px;
  margin-top: 2px;
  height: 16px;
}
[dir="rtl"] #select-all.pull-left {
  float: right !important;
  float: right;
}
.menu_icon {
  margin-right: 2px;
}
.tab-content .row {
  margin-left: 0px;
  margin-right: 0px;
}
.folder_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f114";
}
.folder_icon:before.fa-pull-left {
  margin-right: .3em;
}
.folder_icon:before.fa-pull-right {
  margin-left: .3em;
}
.folder_icon:before.pull-left {
  margin-right: .3em;
}
.folder_icon:before.pull-right {
  margin-left: .3em;
}
.notebook_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f02d";
  position: relative;
  top: -1px;
}
.notebook_icon:before.fa-pull-left {
  margin-right: .3em;
}
.notebook_icon:before.fa-pull-right {
  margin-left: .3em;
}
.notebook_icon:before.pull-left {
  margin-right: .3em;
}
.notebook_icon:before.pull-right {
  margin-left: .3em;
}
.running_notebook_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f02d";
  position: relative;
  top: -1px;
  color: #5cb85c;
}
.running_notebook_icon:before.fa-pull-left {
  margin-right: .3em;
}
.running_notebook_icon:before.fa-pull-right {
  margin-left: .3em;
}
.running_notebook_icon:before.pull-left {
  margin-right: .3em;
}
.running_notebook_icon:before.pull-right {
  margin-left: .3em;
}
.file_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f016";
  position: relative;
  top: -2px;
}
.file_icon:before.fa-pull-left {
  margin-right: .3em;
}
.file_icon:before.fa-pull-right {
  margin-left: .3em;
}
.file_icon:before.pull-left {
  margin-right: .3em;
}
.file_icon:before.pull-right {
  margin-left: .3em;
}
#notebook_toolbar .pull-right {
  padding-top: 0px;
  margin-right: -1px;
}
ul#new-menu {
  left: auto;
  right: 0;
}
#new-menu .dropdown-header {
  font-size: 10px;
  border-bottom: 1px solid #e5e5e5;
  padding: 0 0 3px;
  margin: -3px 20px 0;
}
.kernel-menu-icon {
  padding-right: 12px;
  width: 24px;
  content: "\f096";
}
.kernel-menu-icon:before {
  content: "\f096";
}
.kernel-menu-icon-current:before {
  content: "\f00c";
}
#tab_content {
  padding-top: 20px;
}
#running .panel-group .panel {
  margin-top: 3px;
  margin-bottom: 1em;
}
#running .panel-group .panel .panel-heading {
  background-color: #EEE;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 7px;
  padding-right: 7px;
  line-height: 22px;
}
#running .panel-group .panel .panel-heading a:focus,
#running .panel-group .panel .panel-heading a:hover {
  text-decoration: none;
}
#running .panel-group .panel .panel-body {
  padding: 0px;
}
#running .panel-group .panel .panel-body .list_container {
  margin-top: 0px;
  margin-bottom: 0px;
  border: 0px;
  border-radius: 0px;
}
#running .panel-group .panel .panel-body .list_container .list_item {
  border-bottom: 1px solid #ddd;
}
#running .panel-group .panel .panel-body .list_container .list_item:last-child {
  border-bottom: 0px;
}
.delete-button {
  display: none;
}
.duplicate-button {
  display: none;
}
.rename-button {
  display: none;
}
.move-button {
  display: none;
}
.download-button {
  display: none;
}
.shutdown-button {
  display: none;
}
.dynamic-instructions {
  display: inline-block;
  padding-top: 4px;
}
/*!
*
* IPython text editor webapp
*
*/
.selected-keymap i.fa {
  padding: 0px 5px;
}
.selected-keymap i.fa:before {
  content: "\f00c";
}
#mode-menu {
  overflow: auto;
  max-height: 20em;
}
.edit_app #header {
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
}
.edit_app #menubar .navbar {
  /* Use a negative 1 bottom margin, so the border overlaps the border of the
    header */
  margin-bottom: -1px;
}
.dirty-indicator {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  width: 20px;
}
.dirty-indicator.fa-pull-left {
  margin-right: .3em;
}
.dirty-indicator.fa-pull-right {
  margin-left: .3em;
}
.dirty-indicator.pull-left {
  margin-right: .3em;
}
.dirty-indicator.pull-right {
  margin-left: .3em;
}
.dirty-indicator-dirty {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  width: 20px;
}
.dirty-indicator-dirty.fa-pull-left {
  margin-right: .3em;
}
.dirty-indicator-dirty.fa-pull-right {
  margin-left: .3em;
}
.dirty-indicator-dirty.pull-left {
  margin-right: .3em;
}
.dirty-indicator-dirty.pull-right {
  margin-left: .3em;
}
.dirty-indicator-clean {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  width: 20px;
}
.dirty-indicator-clean.fa-pull-left {
  margin-right: .3em;
}
.dirty-indicator-clean.fa-pull-right {
  margin-left: .3em;
}
.dirty-indicator-clean.pull-left {
  margin-right: .3em;
}
.dirty-indicator-clean.pull-right {
  margin-left: .3em;
}
.dirty-indicator-clean:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f00c";
}
.dirty-indicator-clean:before.fa-pull-left {
  margin-right: .3em;
}
.dirty-indicator-clean:before.fa-pull-right {
  margin-left: .3em;
}
.dirty-indicator-clean:before.pull-left {
  margin-right: .3em;
}
.dirty-indicator-clean:before.pull-right {
  margin-left: .3em;
}
#filename {
  font-size: 16pt;
  display: table;
  padding: 0px 5px;
}
#current-mode {
  padding-left: 5px;
  padding-right: 5px;
}
#texteditor-backdrop {
  padding-top: 20px;
  padding-bottom: 20px;
}
@media not print {
  #texteditor-backdrop {
    background-color: #EEE;
  }
}
@media print {
  #texteditor-backdrop #texteditor-container .CodeMirror-gutter,
  #texteditor-backdrop #texteditor-container .CodeMirror-gutters {
    background-color: #fff;
  }
}
@media not print {
  #texteditor-backdrop #texteditor-container .CodeMirror-gutter,
  #texteditor-backdrop #texteditor-container .CodeMirror-gutters {
    background-color: #fff;
  }
}
@media not print {
  #texteditor-backdrop #texteditor-container {
    padding: 0px;
    background-color: #fff;
    -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
    box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  }
}
.CodeMirror-dialog {
  background-color: #fff;
}
/*!
*
* IPython notebook
*
*/
/* CSS font colors for translated ANSI escape sequences */
/* The color values are a mix of
   http://www.xcolors.net/dl/baskerville-ivorylight and
   http://www.xcolors.net/dl/euphrasia */
.ansi-black-fg {
  color: #3E424D;
}
.ansi-black-bg {
  background-color: #3E424D;
}
.ansi-black-intense-fg {
  color: #282C36;
}
.ansi-black-intense-bg {
  background-color: #282C36;
}
.ansi-red-fg {
  color: #E75C58;
}
.ansi-red-bg {
  background-color: #E75C58;
}
.ansi-red-intense-fg {
  color: #B22B31;
}
.ansi-red-intense-bg {
  background-color: #B22B31;
}
.ansi-green-fg {
  color: #00A250;
}
.ansi-green-bg {
  background-color: #00A250;
}
.ansi-green-intense-fg {
  color: #007427;
}
.ansi-green-intense-bg {
  background-color: #007427;
}
.ansi-yellow-fg {
  color: #DDB62B;
}
.ansi-yellow-bg {
  background-color: #DDB62B;
}
.ansi-yellow-intense-fg {
  color: #B27D12;
}
.ansi-yellow-intense-bg {
  background-color: #B27D12;
}
.ansi-blue-fg {
  color: #208FFB;
}
.ansi-blue-bg {
  background-color: #208FFB;
}
.ansi-blue-intense-fg {
  color: #0065CA;
}
.ansi-blue-intense-bg {
  background-color: #0065CA;
}
.ansi-magenta-fg {
  color: #D160C4;
}
.ansi-magenta-bg {
  background-color: #D160C4;
}
.ansi-magenta-intense-fg {
  color: #A03196;
}
.ansi-magenta-intense-bg {
  background-color: #A03196;
}
.ansi-cyan-fg {
  color: #60C6C8;
}
.ansi-cyan-bg {
  background-color: #60C6C8;
}
.ansi-cyan-intense-fg {
  color: #258F8F;
}
.ansi-cyan-intense-bg {
  background-color: #258F8F;
}
.ansi-white-fg {
  color: #C5C1B4;
}
.ansi-white-bg {
  background-color: #C5C1B4;
}
.ansi-white-intense-fg {
  color: #A1A6B2;
}
.ansi-white-intense-bg {
  background-color: #A1A6B2;
}
.ansi-default-inverse-fg {
  color: #FFFFFF;
}
.ansi-default-inverse-bg {
  background-color: #000000;
}
.ansi-bold {
  font-weight: bold;
}
.ansi-underline {
  text-decoration: underline;
}
/* The following styles are deprecated an will be removed in a future version */
.ansibold {
  font-weight: bold;
}
.ansi-inverse {
  outline: 0.5px dotted;
}
/* use dark versions for foreground, to improve visibility */
.ansiblack {
  color: black;
}
.ansired {
  color: darkred;
}
.ansigreen {
  color: darkgreen;
}
.ansiyellow {
  color: #c4a000;
}
.ansiblue {
  color: darkblue;
}
.ansipurple {
  color: darkviolet;
}
.ansicyan {
  color: steelblue;
}
.ansigray {
  color: gray;
}
/* and light for background, for the same reason */
.ansibgblack {
  background-color: black;
}
.ansibgred {
  background-color: red;
}
.ansibggreen {
  background-color: green;
}
.ansibgyellow {
  background-color: yellow;
}
.ansibgblue {
  background-color: blue;
}
.ansibgpurple {
  background-color: magenta;
}
.ansibgcyan {
  background-color: cyan;
}
.ansibggray {
  background-color: gray;
}
div.cell {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  border-radius: 2px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  border-width: 1px;
  border-style: solid;
  border-color: transparent;
  width: 100%;
  padding: 5px;
  /* This acts as a spacer between cells, that is outside the border */
  margin: 0px;
  outline: none;
  position: relative;
  overflow: visible;
}
div.cell:before {
  position: absolute;
  display: block;
  top: -1px;
  left: -1px;
  width: 5px;
  height: calc(100% +  2px);
  content: '';
  background: transparent;
}
div.cell.jupyter-soft-selected {
  border-left-color: #E3F2FD;
  border-left-width: 1px;
  padding-left: 5px;
  border-right-color: #E3F2FD;
  border-right-width: 1px;
  background: #E3F2FD;
}
@media print {
  div.cell.jupyter-soft-selected {
    border-color: transparent;
  }
}
div.cell.selected,
div.cell.selected.jupyter-soft-selected {
  border-color: #ababab;
}
div.cell.selected:before,
div.cell.selected.jupyter-soft-selected:before {
  position: absolute;
  display: block;
  top: -1px;
  left: -1px;
  width: 5px;
  height: calc(100% +  2px);
  content: '';
  background: #42A5F5;
}
@media print {
  div.cell.selected,
  div.cell.selected.jupyter-soft-selected {
    border-color: transparent;
  }
}
.edit_mode div.cell.selected {
  border-color: #66BB6A;
}
.edit_mode div.cell.selected:before {
  position: absolute;
  display: block;
  top: -1px;
  left: -1px;
  width: 5px;
  height: calc(100% +  2px);
  content: '';
  background: #66BB6A;
}
@media print {
  .edit_mode div.cell.selected {
    border-color: transparent;
  }
}
.prompt {
  /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */
  min-width: 14ex;
  /* This padding is tuned to match the padding on the CodeMirror editor. */
  padding: 0.4em;
  margin: 0px;
  font-family: monospace;
  text-align: right;
  /* This has to match that of the the CodeMirror class line-height below */
  line-height: 1.21429em;
  /* Don't highlight prompt number selection */
  -webkit-touch-callout: none;
  -webkit-user-select: none;
  -khtml-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
  /* Use default cursor */
  cursor: default;
}
@media (max-width: 540px) {
  .prompt {
    text-align: left;
  }
}
div.inner_cell {
  min-width: 0;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
/* input_area and input_prompt must match in top border and margin for alignment */
div.input_area {
  border: 1px solid #cfcfcf;
  border-radius: 2px;
  background: #f7f7f7;
  line-height: 1.21429em;
}
/* This is needed so that empty prompt areas can collapse to zero height when there
   is no content in the output_subarea and the prompt. The main purpose of this is
   to make sure that empty JavaScript output_subareas have no height. */
div.prompt:empty {
  padding-top: 0;
  padding-bottom: 0;
}
div.unrecognized_cell {
  padding: 5px 5px 5px 0px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
div.unrecognized_cell .inner_cell {
  border-radius: 2px;
  padding: 5px;
  font-weight: bold;
  color: red;
  border: 1px solid #cfcfcf;
  background: #eaeaea;
}
div.unrecognized_cell .inner_cell a {
  color: inherit;
  text-decoration: none;
}
div.unrecognized_cell .inner_cell a:hover {
  color: inherit;
  text-decoration: none;
}
@media (max-width: 540px) {
  div.unrecognized_cell > div.prompt {
    display: none;
  }
}
div.code_cell {
  /* avoid page breaking on code cells when printing */
}
@media print {
  div.code_cell {
    page-break-inside: avoid;
  }
}
/* any special styling for code cells that are currently running goes here */
div.input {
  page-break-inside: avoid;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.input {
    /* Old browsers */
    display: -webkit-box;
    -webkit-box-orient: vertical;
    -webkit-box-align: stretch;
    display: -moz-box;
    -moz-box-orient: vertical;
    -moz-box-align: stretch;
    display: box;
    box-orient: vertical;
    box-align: stretch;
    /* Modern browsers */
    display: flex;
    flex-direction: column;
    align-items: stretch;
  }
}
/* input_area and input_prompt must match in top border and margin for alignment */
div.input_prompt {
  color: #303F9F;
  border-top: 1px solid transparent;
}
div.input_area > div.highlight {
  margin: 0.4em;
  border: none;
  padding: 0px;
  background-color: transparent;
}
div.input_area > div.highlight > pre {
  margin: 0px;
  border: none;
  padding: 0px;
  background-color: transparent;
}
/* The following gets added to the <head> if it is detected that the user has a
 * monospace font with inconsistent normal/bold/italic height.  See
 * notebookmain.js.  Such fonts will have keywords vertically offset with
 * respect to the rest of the text.  The user should select a better font.
 * See: https://github.com/ipython/ipython/issues/1503
 *
 * .CodeMirror span {
 *      vertical-align: bottom;
 * }
 */
.CodeMirror {
  line-height: 1.21429em;
  /* Changed from 1em to our global default */
  font-size: 14px;
  height: auto;
  /* Changed to auto to autogrow */
  background: none;
  /* Changed from white to allow our bg to show through */
}
.CodeMirror-scroll {
  /*  The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/
  /*  We have found that if it is visible, vertical scrollbars appear with font size changes.*/
  overflow-y: hidden;
  overflow-x: auto;
}
.CodeMirror-lines {
  /* In CM2, this used to be 0.4em, but in CM3 it went to 4px. We need the em value because */
  /* we have set a different line-height and want this to scale with that. */
  /* Note that this should set vertical padding only, since CodeMirror assumes
       that horizontal padding will be set on CodeMirror pre */
  padding: 0.4em 0;
}
.CodeMirror-linenumber {
  padding: 0 8px 0 4px;
}
.CodeMirror-gutters {
  border-bottom-left-radius: 2px;
  border-top-left-radius: 2px;
}
.CodeMirror pre {
  /* In CM3 this went to 4px from 0 in CM2. This sets horizontal padding only,
    use .CodeMirror-lines for vertical */
  padding: 0 0.4em;
  border: 0;
  border-radius: 0;
}
.CodeMirror-cursor {
  border-left: 1.4px solid black;
}
@media screen and (min-width: 2138px) and (max-width: 4319px) {
  .CodeMirror-cursor {
    border-left: 2px solid black;
  }
}
@media screen and (min-width: 4320px) {
  .CodeMirror-cursor {
    border-left: 4px solid black;
  }
}
/*

Original style from softwaremaniacs.org (c) Ivan Sagalaev <Maniac@SoftwareManiacs.Org>
Adapted from GitHub theme

*/
.highlight-base {
  color: #000;
}
.highlight-variable {
  color: #000;
}
.highlight-variable-2 {
  color: #1a1a1a;
}
.highlight-variable-3 {
  color: #333333;
}
.highlight-string {
  color: #BA2121;
}
.highlight-comment {
  color: #408080;
  font-style: italic;
}
.highlight-number {
  color: #080;
}
.highlight-atom {
  color: #88F;
}
.highlight-keyword {
  color: #008000;
  font-weight: bold;
}
.highlight-builtin {
  color: #008000;
}
.highlight-error {
  color: #f00;
}
.highlight-operator {
  color: #AA22FF;
  font-weight: bold;
}
.highlight-meta {
  color: #AA22FF;
}
/* previously not defined, copying from default codemirror */
.highlight-def {
  color: #00f;
}
.highlight-string-2 {
  color: #f50;
}
.highlight-qualifier {
  color: #555;
}
.highlight-bracket {
  color: #997;
}
.highlight-tag {
  color: #170;
}
.highlight-attribute {
  color: #00c;
}
.highlight-header {
  color: blue;
}
.highlight-quote {
  color: #090;
}
.highlight-link {
  color: #00c;
}
/* apply the same style to codemirror */
.cm-s-ipython span.cm-keyword {
  color: #008000;
  font-weight: bold;
}
.cm-s-ipython span.cm-atom {
  color: #88F;
}
.cm-s-ipython span.cm-number {
  color: #080;
}
.cm-s-ipython span.cm-def {
  color: #00f;
}
.cm-s-ipython span.cm-variable {
  color: #000;
}
.cm-s-ipython span.cm-operator {
  color: #AA22FF;
  font-weight: bold;
}
.cm-s-ipython span.cm-variable-2 {
  color: #1a1a1a;
}
.cm-s-ipython span.cm-variable-3 {
  color: #333333;
}
.cm-s-ipython span.cm-comment {
  color: #408080;
  font-style: italic;
}
.cm-s-ipython span.cm-string {
  color: #BA2121;
}
.cm-s-ipython span.cm-string-2 {
  color: #f50;
}
.cm-s-ipython span.cm-meta {
  color: #AA22FF;
}
.cm-s-ipython span.cm-qualifier {
  color: #555;
}
.cm-s-ipython span.cm-builtin {
  color: #008000;
}
.cm-s-ipython span.cm-bracket {
  color: #997;
}
.cm-s-ipython span.cm-tag {
  color: #170;
}
.cm-s-ipython span.cm-attribute {
  color: #00c;
}
.cm-s-ipython span.cm-header {
  color: blue;
}
.cm-s-ipython span.cm-quote {
  color: #090;
}
.cm-s-ipython span.cm-link {
  color: #00c;
}
.cm-s-ipython span.cm-error {
  color: #f00;
}
.cm-s-ipython span.cm-tab {
  background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=);
  background-position: right;
  background-repeat: no-repeat;
}
div.output_wrapper {
  /* this position must be relative to enable descendents to be absolute within it */
  position: relative;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  z-index: 1;
}
/* class for the output area when it should be height-limited */
div.output_scroll {
  /* ideally, this would be max-height, but FF barfs all over that */
  height: 24em;
  /* FF needs this *and the wrapper* to specify full width, or it will shrinkwrap */
  width: 100%;
  overflow: auto;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8);
  box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8);
  display: block;
}
/* output div while it is collapsed */
div.output_collapsed {
  margin: 0px;
  padding: 0px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
div.out_prompt_overlay {
  height: 100%;
  padding: 0px 0.4em;
  position: absolute;
  border-radius: 2px;
}
div.out_prompt_overlay:hover {
  /* use inner shadow to get border that is computed the same on WebKit/FF */
  -webkit-box-shadow: inset 0 0 1px #000;
  box-shadow: inset 0 0 1px #000;
  background: rgba(240, 240, 240, 0.5);
}
div.output_prompt {
  color: #D84315;
}
/* This class is the outer container of all output sections. */
div.output_area {
  padding: 0px;
  page-break-inside: avoid;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
div.output_area .MathJax_Display {
  text-align: left !important;
}
div.output_area .rendered_html table {
  margin-left: 0;
  margin-right: 0;
}
div.output_area .rendered_html img {
  margin-left: 0;
  margin-right: 0;
}
div.output_area img,
div.output_area svg {
  max-width: 100%;
  height: auto;
}
div.output_area img.unconfined,
div.output_area svg.unconfined {
  max-width: none;
}
div.output_area .mglyph > img {
  max-width: none;
}
/* This is needed to protect the pre formating from global settings such
   as that of bootstrap */
.output {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.output_area {
    /* Old browsers */
    display: -webkit-box;
    -webkit-box-orient: vertical;
    -webkit-box-align: stretch;
    display: -moz-box;
    -moz-box-orient: vertical;
    -moz-box-align: stretch;
    display: box;
    box-orient: vertical;
    box-align: stretch;
    /* Modern browsers */
    display: flex;
    flex-direction: column;
    align-items: stretch;
  }
}
div.output_area pre {
  margin: 0;
  padding: 1px 0 1px 0;
  border: 0;
  vertical-align: baseline;
  color: black;
  background-color: transparent;
  border-radius: 0;
}
/* This class is for the output subarea inside the output_area and after
   the prompt div. */
div.output_subarea {
  overflow-x: auto;
  padding: 0.4em;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
  max-width: calc(100% - 14ex);
}
div.output_scroll div.output_subarea {
  overflow-x: visible;
}
/* The rest of the output_* classes are for special styling of the different
   output types */
/* all text output has this class: */
div.output_text {
  text-align: left;
  color: #000;
  /* This has to match that of the the CodeMirror class line-height below */
  line-height: 1.21429em;
}
/* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */
div.output_stderr {
  background: #fdd;
  /* very light red background for stderr */
}
div.output_latex {
  text-align: left;
}
/* Empty output_javascript divs should have no height */
div.output_javascript:empty {
  padding: 0;
}
.js-error {
  color: darkred;
}
/* raw_input styles */
div.raw_input_container {
  line-height: 1.21429em;
  padding-top: 5px;
}
pre.raw_input_prompt {
  /* nothing needed here. */
}
input.raw_input {
  font-family: monospace;
  font-size: inherit;
  color: inherit;
  width: auto;
  /* make sure input baseline aligns with prompt */
  vertical-align: baseline;
  /* padding + margin = 0.5em between prompt and cursor */
  padding: 0em 0.25em;
  margin: 0em 0.25em;
}
input.raw_input:focus {
  box-shadow: none;
}
p.p-space {
  margin-bottom: 10px;
}
div.output_unrecognized {
  padding: 5px;
  font-weight: bold;
  color: red;
}
div.output_unrecognized a {
  color: inherit;
  text-decoration: none;
}
div.output_unrecognized a:hover {
  color: inherit;
  text-decoration: none;
}
.rendered_html {
  color: #000;
  /* any extras will just be numbers: */
}
.rendered_html em {
  font-style: italic;
}
.rendered_html strong {
  font-weight: bold;
}
.rendered_html u {
  text-decoration: underline;
}
.rendered_html :link {
  text-decoration: underline;
}
.rendered_html :visited {
  text-decoration: underline;
}
.rendered_html h1 {
  font-size: 185.7%;
  margin: 1.08em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h2 {
  font-size: 157.1%;
  margin: 1.27em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h3 {
  font-size: 128.6%;
  margin: 1.55em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h4 {
  font-size: 100%;
  margin: 2em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h5 {
  font-size: 100%;
  margin: 2em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
  font-style: italic;
}
.rendered_html h6 {
  font-size: 100%;
  margin: 2em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
  font-style: italic;
}
.rendered_html h1:first-child {
  margin-top: 0.538em;
}
.rendered_html h2:first-child {
  margin-top: 0.636em;
}
.rendered_html h3:first-child {
  margin-top: 0.777em;
}
.rendered_html h4:first-child {
  margin-top: 1em;
}
.rendered_html h5:first-child {
  margin-top: 1em;
}
.rendered_html h6:first-child {
  margin-top: 1em;
}
.rendered_html ul:not(.list-inline),
.rendered_html ol:not(.list-inline) {
  padding-left: 2em;
}
.rendered_html ul {
  list-style: disc;
}
.rendered_html ul ul {
  list-style: square;
  margin-top: 0;
}
.rendered_html ul ul ul {
  list-style: circle;
}
.rendered_html ol {
  list-style: decimal;
}
.rendered_html ol ol {
  list-style: upper-alpha;
  margin-top: 0;
}
.rendered_html ol ol ol {
  list-style: lower-alpha;
}
.rendered_html ol ol ol ol {
  list-style: lower-roman;
}
.rendered_html ol ol ol ol ol {
  list-style: decimal;
}
.rendered_html * + ul {
  margin-top: 1em;
}
.rendered_html * + ol {
  margin-top: 1em;
}
.rendered_html hr {
  color: black;
  background-color: black;
}
.rendered_html pre {
  margin: 1em 2em;
  padding: 0px;
  background-color: #fff;
}
.rendered_html code {
  background-color: #eff0f1;
}
.rendered_html p code {
  padding: 1px 5px;
}
.rendered_html pre code {
  background-color: #fff;
}
.rendered_html pre,
.rendered_html code {
  border: 0;
  color: #000;
  font-size: 100%;
}
.rendered_html blockquote {
  margin: 1em 2em;
}
.rendered_html table {
  margin-left: auto;
  margin-right: auto;
  border: none;
  border-collapse: collapse;
  border-spacing: 0;
  color: black;
  font-size: 12px;
  table-layout: fixed;
}
.rendered_html thead {
  border-bottom: 1px solid black;
  vertical-align: bottom;
}
.rendered_html tr,
.rendered_html th,
.rendered_html td {
  text-align: right;
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}
.rendered_html th {
  font-weight: bold;
}
.rendered_html tbody tr:nth-child(odd) {
  background: #f5f5f5;
}
.rendered_html tbody tr:hover {
  background: rgba(66, 165, 245, 0.2);
}
.rendered_html * + table {
  margin-top: 1em;
}
.rendered_html p {
  text-align: left;
}
.rendered_html * + p {
  margin-top: 1em;
}
.rendered_html img {
  display: block;
  margin-left: auto;
  margin-right: auto;
}
.rendered_html * + img {
  margin-top: 1em;
}
.rendered_html img,
.rendered_html svg {
  max-width: 100%;
  height: auto;
}
.rendered_html img.unconfined,
.rendered_html svg.unconfined {
  max-width: none;
}
.rendered_html .alert {
  margin-bottom: initial;
}
.rendered_html * + .alert {
  margin-top: 1em;
}
[dir="rtl"] .rendered_html p {
  text-align: right;
}
div.text_cell {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.text_cell > div.prompt {
    display: none;
  }
}
div.text_cell_render {
  /*font-family: "Helvetica Neue", Arial, Helvetica, Geneva, sans-serif;*/
  outline: none;
  resize: none;
  width: inherit;
  border-style: none;
  padding: 0.5em 0.5em 0.5em 0.4em;
  color: #000;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
a.anchor-link:link {
  text-decoration: none;
  padding: 0px 20px;
  visibility: hidden;
}
h1:hover .anchor-link,
h2:hover .anchor-link,
h3:hover .anchor-link,
h4:hover .anchor-link,
h5:hover .anchor-link,
h6:hover .anchor-link {
  visibility: visible;
}
.text_cell.rendered .input_area {
  display: none;
}
.text_cell.rendered .rendered_html {
  overflow-x: auto;
  overflow-y: hidden;
}
.text_cell.rendered .rendered_html tr,
.text_cell.rendered .rendered_html th,
.text_cell.rendered .rendered_html td {
  max-width: none;
}
.text_cell.unrendered .text_cell_render {
  display: none;
}
.text_cell .dropzone .input_area {
  border: 2px dashed #bababa;
  margin: -1px;
}
.cm-header-1,
.cm-header-2,
.cm-header-3,
.cm-header-4,
.cm-header-5,
.cm-header-6 {
  font-weight: bold;
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
}
.cm-header-1 {
  font-size: 185.7%;
}
.cm-header-2 {
  font-size: 157.1%;
}
.cm-header-3 {
  font-size: 128.6%;
}
.cm-header-4 {
  font-size: 110%;
}
.cm-header-5 {
  font-size: 100%;
  font-style: italic;
}
.cm-header-6 {
  font-size: 100%;
  font-style: italic;
}
/*!
*
* IPython notebook webapp
*
*/
@media (max-width: 767px) {
  .notebook_app {
    padding-left: 0px;
    padding-right: 0px;
  }
}
#ipython-main-app {
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  height: 100%;
}
div#notebook_panel {
  margin: 0px;
  padding: 0px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  height: 100%;
}
div#notebook {
  font-size: 14px;
  line-height: 20px;
  overflow-y: hidden;
  overflow-x: auto;
  width: 100%;
  /* This spaces the page away from the edge of the notebook area */
  padding-top: 20px;
  margin: 0px;
  outline: none;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  min-height: 100%;
}
@media not print {
  #notebook-container {
    padding: 15px;
    background-color: #fff;
    min-height: 0;
    -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
    box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  }
}
@media print {
  #notebook-container {
    width: 100%;
  }
}
div.ui-widget-content {
  border: 1px solid #ababab;
  outline: none;
}
pre.dialog {
  background-color: #f7f7f7;
  border: 1px solid #ddd;
  border-radius: 2px;
  padding: 0.4em;
  padding-left: 2em;
}
p.dialog {
  padding: 0.2em;
}
/* Word-wrap output correctly.  This is the CSS3 spelling, though Firefox seems
   to not honor it correctly.  Webkit browsers (Chrome, rekonq, Safari) do.
 */
pre,
code,
kbd,
samp {
  white-space: pre-wrap;
}
#fonttest {
  font-family: monospace;
}
p {
  margin-bottom: 0;
}
.end_space {
  min-height: 100px;
  transition: height .2s ease;
}
.notebook_app > #header {
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
}
@media not print {
  .notebook_app {
    background-color: #EEE;
  }
}
kbd {
  border-style: solid;
  border-width: 1px;
  box-shadow: none;
  margin: 2px;
  padding-left: 2px;
  padding-right: 2px;
  padding-top: 1px;
  padding-bottom: 1px;
}
.jupyter-keybindings {
  padding: 1px;
  line-height: 24px;
  border-bottom: 1px solid gray;
}
.jupyter-keybindings input {
  margin: 0;
  padding: 0;
  border: none;
}
.jupyter-keybindings i {
  padding: 6px;
}
.well code {
  background-color: #ffffff;
  border-color: #ababab;
  border-width: 1px;
  border-style: solid;
  padding: 2px;
  padding-top: 1px;
  padding-bottom: 1px;
}
/* CSS for the cell toolbar */
.celltoolbar {
  border: thin solid #CFCFCF;
  border-bottom: none;
  background: #EEE;
  border-radius: 2px 2px 0px 0px;
  width: 100%;
  height: 29px;
  padding-right: 4px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
  /* Old browsers */
  -webkit-box-pack: end;
  -moz-box-pack: end;
  box-pack: end;
  /* Modern browsers */
  justify-content: flex-end;
  display: -webkit-flex;
}
@media print {
  .celltoolbar {
    display: none;
  }
}
.ctb_hideshow {
  display: none;
  vertical-align: bottom;
}
/* ctb_show is added to the ctb_hideshow div to show the cell toolbar.
   Cell toolbars are only shown when the ctb_global_show class is also set.
*/
.ctb_global_show .ctb_show.ctb_hideshow {
  display: block;
}
.ctb_global_show .ctb_show + .input_area,
.ctb_global_show .ctb_show + div.text_cell_input,
.ctb_global_show .ctb_show ~ div.text_cell_render {
  border-top-right-radius: 0px;
  border-top-left-radius: 0px;
}
.ctb_global_show .ctb_show ~ div.text_cell_render {
  border: 1px solid #cfcfcf;
}
.celltoolbar {
  font-size: 87%;
  padding-top: 3px;
}
.celltoolbar select {
  display: block;
  width: 100%;
  height: 32px;
  padding: 6px 12px;
  font-size: 13px;
  line-height: 1.42857143;
  color: #555555;
  background-color: #fff;
  background-image: none;
  border: 1px solid #ccc;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  -webkit-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  -o-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
  width: inherit;
  font-size: inherit;
  height: 22px;
  padding: 0px;
  display: inline-block;
}
.celltoolbar select:focus {
  border-color: #66afe9;
  outline: 0;
  -webkit-box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
  box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
}
.celltoolbar select::-moz-placeholder {
  color: #999;
  opacity: 1;
}
.celltoolbar select:-ms-input-placeholder {
  color: #999;
}
.celltoolbar select::-webkit-input-placeholder {
  color: #999;
}
.celltoolbar select::-ms-expand {
  border: 0;
  background-color: transparent;
}
.celltoolbar select[disabled],
.celltoolbar select[readonly],
fieldset[disabled] .celltoolbar select {
  background-color: #eeeeee;
  opacity: 1;
}
.celltoolbar select[disabled],
fieldset[disabled] .celltoolbar select {
  cursor: not-allowed;
}
textarea.celltoolbar select {
  height: auto;
}
select.celltoolbar select {
  height: 30px;
  line-height: 30px;
}
textarea.celltoolbar select,
select[multiple].celltoolbar select {
  height: auto;
}
.celltoolbar label {
  margin-left: 5px;
  margin-right: 5px;
}
.tags_button_container {
  width: 100%;
  display: flex;
}
.tag-container {
  display: flex;
  flex-direction: row;
  flex-grow: 1;
  overflow: hidden;
  position: relative;
}
.tag-container > * {
  margin: 0 4px;
}
.remove-tag-btn {
  margin-left: 4px;
}
.tags-input {
  display: flex;
}
.cell-tag:last-child:after {
  content: "";
  position: absolute;
  right: 0;
  width: 40px;
  height: 100%;
  /* Fade to background color of cell toolbar */
  background: linear-gradient(to right, rgba(0, 0, 0, 0), #EEE);
}
.tags-input > * {
  margin-left: 4px;
}
.cell-tag,
.tags-input input,
.tags-input button {
  display: block;
  width: 100%;
  height: 32px;
  padding: 6px 12px;
  font-size: 13px;
  line-height: 1.42857143;
  color: #555555;
  background-color: #fff;
  background-image: none;
  border: 1px solid #ccc;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  -webkit-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  -o-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
  box-shadow: none;
  width: inherit;
  font-size: inherit;
  height: 22px;
  line-height: 22px;
  padding: 0px 4px;
  display: inline-block;
}
.cell-tag:focus,
.tags-input input:focus,
.tags-input button:focus {
  border-color: #66afe9;
  outline: 0;
  -webkit-box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
  box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
}
.cell-tag::-moz-placeholder,
.tags-input input::-moz-placeholder,
.tags-input button::-moz-placeholder {
  color: #999;
  opacity: 1;
}
.cell-tag:-ms-input-placeholder,
.tags-input input:-ms-input-placeholder,
.tags-input button:-ms-input-placeholder {
  color: #999;
}
.cell-tag::-webkit-input-placeholder,
.tags-input input::-webkit-input-placeholder,
.tags-input button::-webkit-input-placeholder {
  color: #999;
}
.cell-tag::-ms-expand,
.tags-input input::-ms-expand,
.tags-input button::-ms-expand {
  border: 0;
  background-color: transparent;
}
.cell-tag[disabled],
.tags-input input[disabled],
.tags-input button[disabled],
.cell-tag[readonly],
.tags-input input[readonly],
.tags-input button[readonly],
fieldset[disabled] .cell-tag,
fieldset[disabled] .tags-input input,
fieldset[disabled] .tags-input button {
  background-color: #eeeeee;
  opacity: 1;
}
.cell-tag[disabled],
.tags-input input[disabled],
.tags-input button[disabled],
fieldset[disabled] .cell-tag,
fieldset[disabled] .tags-input input,
fieldset[disabled] .tags-input button {
  cursor: not-allowed;
}
textarea.cell-tag,
textarea.tags-input input,
textarea.tags-input button {
  height: auto;
}
select.cell-tag,
select.tags-input input,
select.tags-input button {
  height: 30px;
  line-height: 30px;
}
textarea.cell-tag,
textarea.tags-input input,
textarea.tags-input button,
select[multiple].cell-tag,
select[multiple].tags-input input,
select[multiple].tags-input button {
  height: auto;
}
.cell-tag,
.tags-input button {
  padding: 0px 4px;
}
.cell-tag {
  background-color: #fff;
  white-space: nowrap;
}
.tags-input input[type=text]:focus {
  outline: none;
  box-shadow: none;
  border-color: #ccc;
}
.completions {
  position: absolute;
  z-index: 110;
  overflow: hidden;
  border: 1px solid #ababab;
  border-radius: 2px;
  -webkit-box-shadow: 0px 6px 10px -1px #adadad;
  box-shadow: 0px 6px 10px -1px #adadad;
  line-height: 1;
}
.completions select {
  background: white;
  outline: none;
  border: none;
  padding: 0px;
  margin: 0px;
  overflow: auto;
  font-family: monospace;
  font-size: 110%;
  color: #000;
  width: auto;
}
.completions select option.context {
  color: #286090;
}
#kernel_logo_widget .current_kernel_logo {
  display: none;
  margin-top: -1px;
  margin-bottom: -1px;
  width: 32px;
  height: 32px;
}
[dir="rtl"] #kernel_logo_widget {
  float: left !important;
  float: left;
}
.modal .modal-body .move-path {
  display: flex;
  flex-direction: row;
  justify-content: space;
  align-items: center;
}
.modal .modal-body .move-path .server-root {
  padding-right: 20px;
}
.modal .modal-body .move-path .path-input {
  flex: 1;
}
#menubar {
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  margin-top: 1px;
}
#menubar .navbar {
  border-top: 1px;
  border-radius: 0px 0px 2px 2px;
  margin-bottom: 0px;
}
#menubar .navbar-toggle {
  float: left;
  padding-top: 7px;
  padding-bottom: 7px;
  border: none;
}
#menubar .navbar-collapse {
  clear: left;
}
[dir="rtl"] #menubar .navbar-toggle {
  float: right;
}
[dir="rtl"] #menubar .navbar-collapse {
  clear: right;
}
[dir="rtl"] #menubar .navbar-nav {
  float: right;
}
[dir="rtl"] #menubar .nav {
  padding-right: 0px;
}
[dir="rtl"] #menubar .navbar-nav > li {
  float: right;
}
[dir="rtl"] #menubar .navbar-right {
  float: left !important;
}
[dir="rtl"] ul.dropdown-menu {
  text-align: right;
  left: auto;
}
[dir="rtl"] ul#new-menu.dropdown-menu {
  right: auto;
  left: 0;
}
.nav-wrapper {
  border-bottom: 1px solid #e7e7e7;
}
i.menu-icon {
  padding-top: 4px;
}
[dir="rtl"] i.menu-icon.pull-right {
  float: left !important;
  float: left;
}
ul#help_menu li a {
  overflow: hidden;
  padding-right: 2.2em;
}
ul#help_menu li a i {
  margin-right: -1.2em;
}
[dir="rtl"] ul#help_menu li a {
  padding-left: 2.2em;
}
[dir="rtl"] ul#help_menu li a i {
  margin-right: 0;
  margin-left: -1.2em;
}
[dir="rtl"] ul#help_menu li a i.pull-right {
  float: left !important;
  float: left;
}
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu > .dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
}
[dir="rtl"] .dropdown-submenu > .dropdown-menu {
  right: 100%;
  margin-right: -1px;
}
.dropdown-submenu:hover > .dropdown-menu {
  display: block;
}
.dropdown-submenu > a:after {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  display: block;
  content: "\f0da";
  float: right;
  color: #333333;
  margin-top: 2px;
  margin-right: -10px;
}
.dropdown-submenu > a:after.fa-pull-left {
  margin-right: .3em;
}
.dropdown-submenu > a:after.fa-pull-right {
  margin-left: .3em;
}
.dropdown-submenu > a:after.pull-left {
  margin-right: .3em;
}
.dropdown-submenu > a:after.pull-right {
  margin-left: .3em;
}
[dir="rtl"] .dropdown-submenu > a:after {
  float: left;
  content: "\f0d9";
  margin-right: 0;
  margin-left: -10px;
}
.dropdown-submenu:hover > a:after {
  color: #262626;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left > .dropdown-menu {
  left: -100%;
  margin-left: 10px;
}
#notification_area {
  float: right !important;
  float: right;
  z-index: 10;
}
[dir="rtl"] #notification_area {
  float: left !important;
  float: left;
}
.indicator_area {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
}
[dir="rtl"] .indicator_area {
  float: left !important;
  float: left;
}
#kernel_indicator {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
  border-left: 1px solid;
}
#kernel_indicator .kernel_indicator_name {
  padding-left: 5px;
  padding-right: 5px;
}
[dir="rtl"] #kernel_indicator {
  float: left !important;
  float: left;
  border-left: 0;
  border-right: 1px solid;
}
#modal_indicator {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
}
[dir="rtl"] #modal_indicator {
  float: left !important;
  float: left;
}
#readonly-indicator {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
  margin-top: 2px;
  margin-bottom: 0px;
  margin-left: 0px;
  margin-right: 0px;
  display: none;
}
.modal_indicator:before {
  width: 1.28571429em;
  text-align: center;
}
.edit_mode .modal_indicator:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f040";
}
.edit_mode .modal_indicator:before.fa-pull-left {
  margin-right: .3em;
}
.edit_mode .modal_indicator:before.fa-pull-right {
  margin-left: .3em;
}
.edit_mode .modal_indicator:before.pull-left {
  margin-right: .3em;
}
.edit_mode .modal_indicator:before.pull-right {
  margin-left: .3em;
}
.command_mode .modal_indicator:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: ' ';
}
.command_mode .modal_indicator:before.fa-pull-left {
  margin-right: .3em;
}
.command_mode .modal_indicator:before.fa-pull-right {
  margin-left: .3em;
}
.command_mode .modal_indicator:before.pull-left {
  margin-right: .3em;
}
.command_mode .modal_indicator:before.pull-right {
  margin-left: .3em;
}
.kernel_idle_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f10c";
}
.kernel_idle_icon:before.fa-pull-left {
  margin-right: .3em;
}
.kernel_idle_icon:before.fa-pull-right {
  margin-left: .3em;
}
.kernel_idle_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_idle_icon:before.pull-right {
  margin-left: .3em;
}
.kernel_busy_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f111";
}
.kernel_busy_icon:before.fa-pull-left {
  margin-right: .3em;
}
.kernel_busy_icon:before.fa-pull-right {
  margin-left: .3em;
}
.kernel_busy_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_busy_icon:before.pull-right {
  margin-left: .3em;
}
.kernel_dead_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f1e2";
}
.kernel_dead_icon:before.fa-pull-left {
  margin-right: .3em;
}
.kernel_dead_icon:before.fa-pull-right {
  margin-left: .3em;
}
.kernel_dead_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_dead_icon:before.pull-right {
  margin-left: .3em;
}
.kernel_disconnected_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f127";
}
.kernel_disconnected_icon:before.fa-pull-left {
  margin-right: .3em;
}
.kernel_disconnected_icon:before.fa-pull-right {
  margin-left: .3em;
}
.kernel_disconnected_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_disconnected_icon:before.pull-right {
  margin-left: .3em;
}
.notification_widget {
  color: #777;
  z-index: 10;
  background: rgba(240, 240, 240, 0.5);
  margin-right: 4px;
  color: #333;
  background-color: #fff;
  border-color: #ccc;
}
.notification_widget:focus,
.notification_widget.focus {
  color: #333;
  background-color: #e6e6e6;
  border-color: #8c8c8c;
}
.notification_widget:hover {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.notification_widget:active,
.notification_widget.active,
.open > .dropdown-toggle.notification_widget {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.notification_widget:active:hover,
.notification_widget.active:hover,
.open > .dropdown-toggle.notification_widget:hover,
.notification_widget:active:focus,
.notification_widget.active:focus,
.open > .dropdown-toggle.notification_widget:focus,
.notification_widget:active.focus,
.notification_widget.active.focus,
.open > .dropdown-toggle.notification_widget.focus {
  color: #333;
  background-color: #d4d4d4;
  border-color: #8c8c8c;
}
.notification_widget:active,
.notification_widget.active,
.open > .dropdown-toggle.notification_widget {
  background-image: none;
}
.notification_widget.disabled:hover,
.notification_widget[disabled]:hover,
fieldset[disabled] .notification_widget:hover,
.notification_widget.disabled:focus,
.notification_widget[disabled]:focus,
fieldset[disabled] .notification_widget:focus,
.notification_widget.disabled.focus,
.notification_widget[disabled].focus,
fieldset[disabled] .notification_widget.focus {
  background-color: #fff;
  border-color: #ccc;
}
.notification_widget .badge {
  color: #fff;
  background-color: #333;
}
.notification_widget.warning {
  color: #fff;
  background-color: #f0ad4e;
  border-color: #eea236;
}
.notification_widget.warning:focus,
.notification_widget.warning.focus {
  color: #fff;
  background-color: #ec971f;
  border-color: #985f0d;
}
.notification_widget.warning:hover {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.notification_widget.warning:active,
.notification_widget.warning.active,
.open > .dropdown-toggle.notification_widget.warning {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.notification_widget.warning:active:hover,
.notification_widget.warning.active:hover,
.open > .dropdown-toggle.notification_widget.warning:hover,
.notification_widget.warning:active:focus,
.notification_widget.warning.active:focus,
.open > .dropdown-toggle.notification_widget.warning:focus,
.notification_widget.warning:active.focus,
.notification_widget.warning.active.focus,
.open > .dropdown-toggle.notification_widget.warning.focus {
  color: #fff;
  background-color: #d58512;
  border-color: #985f0d;
}
.notification_widget.warning:active,
.notification_widget.warning.active,
.open > .dropdown-toggle.notification_widget.warning {
  background-image: none;
}
.notification_widget.warning.disabled:hover,
.notification_widget.warning[disabled]:hover,
fieldset[disabled] .notification_widget.warning:hover,
.notification_widget.warning.disabled:focus,
.notification_widget.warning[disabled]:focus,
fieldset[disabled] .notification_widget.warning:focus,
.notification_widget.warning.disabled.focus,
.notification_widget.warning[disabled].focus,
fieldset[disabled] .notification_widget.warning.focus {
  background-color: #f0ad4e;
  border-color: #eea236;
}
.notification_widget.warning .badge {
  color: #f0ad4e;
  background-color: #fff;
}
.notification_widget.success {
  color: #fff;
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.notification_widget.success:focus,
.notification_widget.success.focus {
  color: #fff;
  background-color: #449d44;
  border-color: #255625;
}
.notification_widget.success:hover {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.notification_widget.success:active,
.notification_widget.success.active,
.open > .dropdown-toggle.notification_widget.success {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.notification_widget.success:active:hover,
.notification_widget.success.active:hover,
.open > .dropdown-toggle.notification_widget.success:hover,
.notification_widget.success:active:focus,
.notification_widget.success.active:focus,
.open > .dropdown-toggle.notification_widget.success:focus,
.notification_widget.success:active.focus,
.notification_widget.success.active.focus,
.open > .dropdown-toggle.notification_widget.success.focus {
  color: #fff;
  background-color: #398439;
  border-color: #255625;
}
.notification_widget.success:active,
.notification_widget.success.active,
.open > .dropdown-toggle.notification_widget.success {
  background-image: none;
}
.notification_widget.success.disabled:hover,
.notification_widget.success[disabled]:hover,
fieldset[disabled] .notification_widget.success:hover,
.notification_widget.success.disabled:focus,
.notification_widget.success[disabled]:focus,
fieldset[disabled] .notification_widget.success:focus,
.notification_widget.success.disabled.focus,
.notification_widget.success[disabled].focus,
fieldset[disabled] .notification_widget.success.focus {
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.notification_widget.success .badge {
  color: #5cb85c;
  background-color: #fff;
}
.notification_widget.info {
  color: #fff;
  background-color: #5bc0de;
  border-color: #46b8da;
}
.notification_widget.info:focus,
.notification_widget.info.focus {
  color: #fff;
  background-color: #31b0d5;
  border-color: #1b6d85;
}
.notification_widget.info:hover {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.notification_widget.info:active,
.notification_widget.info.active,
.open > .dropdown-toggle.notification_widget.info {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.notification_widget.info:active:hover,
.notification_widget.info.active:hover,
.open > .dropdown-toggle.notification_widget.info:hover,
.notification_widget.info:active:focus,
.notification_widget.info.active:focus,
.open > .dropdown-toggle.notification_widget.info:focus,
.notification_widget.info:active.focus,
.notification_widget.info.active.focus,
.open > .dropdown-toggle.notification_widget.info.focus {
  color: #fff;
  background-color: #269abc;
  border-color: #1b6d85;
}
.notification_widget.info:active,
.notification_widget.info.active,
.open > .dropdown-toggle.notification_widget.info {
  background-image: none;
}
.notification_widget.info.disabled:hover,
.notification_widget.info[disabled]:hover,
fieldset[disabled] .notification_widget.info:hover,
.notification_widget.info.disabled:focus,
.notification_widget.info[disabled]:focus,
fieldset[disabled] .notification_widget.info:focus,
.notification_widget.info.disabled.focus,
.notification_widget.info[disabled].focus,
fieldset[disabled] .notification_widget.info.focus {
  background-color: #5bc0de;
  border-color: #46b8da;
}
.notification_widget.info .badge {
  color: #5bc0de;
  background-color: #fff;
}
.notification_widget.danger {
  color: #fff;
  background-color: #d9534f;
  border-color: #d43f3a;
}
.notification_widget.danger:focus,
.notification_widget.danger.focus {
  color: #fff;
  background-color: #c9302c;
  border-color: #761c19;
}
.notification_widget.danger:hover {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.notification_widget.danger:active,
.notification_widget.danger.active,
.open > .dropdown-toggle.notification_widget.danger {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.notification_widget.danger:active:hover,
.notification_widget.danger.active:hover,
.open > .dropdown-toggle.notification_widget.danger:hover,
.notification_widget.danger:active:focus,
.notification_widget.danger.active:focus,
.open > .dropdown-toggle.notification_widget.danger:focus,
.notification_widget.danger:active.focus,
.notification_widget.danger.active.focus,
.open > .dropdown-toggle.notification_widget.danger.focus {
  color: #fff;
  background-color: #ac2925;
  border-color: #761c19;
}
.notification_widget.danger:active,
.notification_widget.danger.active,
.open > .dropdown-toggle.notification_widget.danger {
  background-image: none;
}
.notification_widget.danger.disabled:hover,
.notification_widget.danger[disabled]:hover,
fieldset[disabled] .notification_widget.danger:hover,
.notification_widget.danger.disabled:focus,
.notification_widget.danger[disabled]:focus,
fieldset[disabled] .notification_widget.danger:focus,
.notification_widget.danger.disabled.focus,
.notification_widget.danger[disabled].focus,
fieldset[disabled] .notification_widget.danger.focus {
  background-color: #d9534f;
  border-color: #d43f3a;
}
.notification_widget.danger .badge {
  color: #d9534f;
  background-color: #fff;
}
div#pager {
  background-color: #fff;
  font-size: 14px;
  line-height: 20px;
  overflow: hidden;
  display: none;
  position: fixed;
  bottom: 0px;
  width: 100%;
  max-height: 50%;
  padding-top: 8px;
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  /* Display over codemirror */
  z-index: 100;
  /* Hack which prevents jquery ui resizable from changing top. */
  top: auto !important;
}
div#pager pre {
  line-height: 1.21429em;
  color: #000;
  background-color: #f7f7f7;
  padding: 0.4em;
}
div#pager #pager-button-area {
  position: absolute;
  top: 8px;
  right: 20px;
}
div#pager #pager-contents {
  position: relative;
  overflow: auto;
  width: 100%;
  height: 100%;
}
div#pager #pager-contents #pager-container {
  position: relative;
  padding: 15px 0px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
div#pager .ui-resizable-handle {
  top: 0px;
  height: 8px;
  background: #f7f7f7;
  border-top: 1px solid #cfcfcf;
  border-bottom: 1px solid #cfcfcf;
  /* This injects handle bars (a short, wide = symbol) for 
        the resize handle. */
}
div#pager .ui-resizable-handle::after {
  content: '';
  top: 2px;
  left: 50%;
  height: 3px;
  width: 30px;
  margin-left: -15px;
  position: absolute;
  border-top: 1px solid #cfcfcf;
}
.quickhelp {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
  line-height: 1.8em;
}
.shortcut_key {
  display: inline-block;
  width: 21ex;
  text-align: right;
  font-family: monospace;
}
.shortcut_descr {
  display: inline-block;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
span.save_widget {
  height: 30px;
  margin-top: 4px;
  display: flex;
  justify-content: flex-start;
  align-items: baseline;
  width: 50%;
  flex: 1;
}
span.save_widget span.filename {
  height: 100%;
  line-height: 1em;
  margin-left: 16px;
  border: none;
  font-size: 146.5%;
  text-overflow: ellipsis;
  overflow: hidden;
  white-space: nowrap;
  border-radius: 2px;
}
span.save_widget span.filename:hover {
  background-color: #e6e6e6;
}
[dir="rtl"] span.save_widget.pull-left {
  float: right !important;
  float: right;
}
[dir="rtl"] span.save_widget span.filename {
  margin-left: 0;
  margin-right: 16px;
}
span.checkpoint_status,
span.autosave_status {
  font-size: small;
  white-space: nowrap;
  padding: 0 5px;
}
@media (max-width: 767px) {
  span.save_widget {
    font-size: small;
    padding: 0 0 0 5px;
  }
  span.checkpoint_status,
  span.autosave_status {
    display: none;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  span.checkpoint_status {
    display: none;
  }
  span.autosave_status {
    font-size: x-small;
  }
}
.toolbar {
  padding: 0px;
  margin-left: -5px;
  margin-top: 2px;
  margin-bottom: 5px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
.toolbar select,
.toolbar label {
  width: auto;
  vertical-align: middle;
  margin-right: 2px;
  margin-bottom: 0px;
  display: inline;
  font-size: 92%;
  margin-left: 0.3em;
  margin-right: 0.3em;
  padding: 0px;
  padding-top: 3px;
}
.toolbar .btn {
  padding: 2px 8px;
}
.toolbar .btn-group {
  margin-top: 0px;
  margin-left: 5px;
}
.toolbar-btn-label {
  margin-left: 6px;
}
#maintoolbar {
  margin-bottom: -3px;
  margin-top: -8px;
  border: 0px;
  min-height: 27px;
  margin-left: 0px;
  padding-top: 11px;
  padding-bottom: 3px;
}
#maintoolbar .navbar-text {
  float: none;
  vertical-align: middle;
  text-align: right;
  margin-left: 5px;
  margin-right: 0px;
  margin-top: 0px;
}
.select-xs {
  height: 24px;
}
[dir="rtl"] .btn-group > .btn,
.btn-group-vertical > .btn {
  float: right;
}
.pulse,
.dropdown-menu > li > a.pulse,
li.pulse > a.dropdown-toggle,
li.pulse.open > a.dropdown-toggle {
  background-color: #F37626;
  color: white;
}
/**
 * Primary styles
 *
 * Author: Jupyter Development Team
 */
/** WARNING IF YOU ARE EDITTING THIS FILE, if this is a .css file, It has a lot
 * of chance of beeing generated from the ../less/[samename].less file, you can
 * try to get back the less file by reverting somme commit in history
 **/
/*
 * We'll try to get something pretty, so we
 * have some strange css to have the scroll bar on
 * the left with fix button on the top right of the tooltip
 */
@-moz-keyframes fadeOut {
  from {
    opacity: 1;
  }
  to {
    opacity: 0;
  }
}
@-webkit-keyframes fadeOut {
  from {
    opacity: 1;
  }
  to {
    opacity: 0;
  }
}
@-moz-keyframes fadeIn {
  from {
    opacity: 0;
  }
  to {
    opacity: 1;
  }
}
@-webkit-keyframes fadeIn {
  from {
    opacity: 0;
  }
  to {
    opacity: 1;
  }
}
/*properties of tooltip after "expand"*/
.bigtooltip {
  overflow: auto;
  height: 200px;
  -webkit-transition-property: height;
  -webkit-transition-duration: 500ms;
  -moz-transition-property: height;
  -moz-transition-duration: 500ms;
  transition-property: height;
  transition-duration: 500ms;
}
/*properties of tooltip before "expand"*/
.smalltooltip {
  -webkit-transition-property: height;
  -webkit-transition-duration: 500ms;
  -moz-transition-property: height;
  -moz-transition-duration: 500ms;
  transition-property: height;
  transition-duration: 500ms;
  text-overflow: ellipsis;
  overflow: hidden;
  height: 80px;
}
.tooltipbuttons {
  position: absolute;
  padding-right: 15px;
  top: 0px;
  right: 0px;
}
.tooltiptext {
  /*avoid the button to overlap on some docstring*/
  padding-right: 30px;
}
.ipython_tooltip {
  max-width: 700px;
  /*fade-in animation when inserted*/
  -webkit-animation: fadeOut 400ms;
  -moz-animation: fadeOut 400ms;
  animation: fadeOut 400ms;
  -webkit-animation: fadeIn 400ms;
  -moz-animation: fadeIn 400ms;
  animation: fadeIn 400ms;
  vertical-align: middle;
  background-color: #f7f7f7;
  overflow: visible;
  border: #ababab 1px solid;
  outline: none;
  padding: 3px;
  margin: 0px;
  padding-left: 7px;
  font-family: monospace;
  min-height: 50px;
  -moz-box-shadow: 0px 6px 10px -1px #adadad;
  -webkit-box-shadow: 0px 6px 10px -1px #adadad;
  box-shadow: 0px 6px 10px -1px #adadad;
  border-radius: 2px;
  position: absolute;
  z-index: 1000;
}
.ipython_tooltip a {
  float: right;
}
.ipython_tooltip .tooltiptext pre {
  border: 0;
  border-radius: 0;
  font-size: 100%;
  background-color: #f7f7f7;
}
.pretooltiparrow {
  left: 0px;
  margin: 0px;
  top: -16px;
  width: 40px;
  height: 16px;
  overflow: hidden;
  position: absolute;
}
.pretooltiparrow:before {
  background-color: #f7f7f7;
  border: 1px #ababab solid;
  z-index: 11;
  content: "";
  position: absolute;
  left: 15px;
  top: 10px;
  width: 25px;
  height: 25px;
  -webkit-transform: rotate(45deg);
  -moz-transform: rotate(45deg);
  -ms-transform: rotate(45deg);
  -o-transform: rotate(45deg);
}
ul.typeahead-list i {
  margin-left: -10px;
  width: 18px;
}
[dir="rtl"] ul.typeahead-list i {
  margin-left: 0;
  margin-right: -10px;
}
ul.typeahead-list {
  max-height: 80vh;
  overflow: auto;
}
ul.typeahead-list > li > a {
  /** Firefox bug **/
  /* see https://github.com/jupyter/notebook/issues/559 */
  white-space: normal;
}
ul.typeahead-list  > li > a.pull-right {
  float: left !important;
  float: left;
}
[dir="rtl"] .typeahead-list {
  text-align: right;
}
.cmd-palette .modal-body {
  padding: 7px;
}
.cmd-palette form {
  background: white;
}
.cmd-palette input {
  outline: none;
}
.no-shortcut {
  min-width: 20px;
  color: transparent;
}
[dir="rtl"] .no-shortcut.pull-right {
  float: left !important;
  float: left;
}
[dir="rtl"] .command-shortcut.pull-right {
  float: left !important;
  float: left;
}
.command-shortcut:before {
  content: "(command mode)";
  padding-right: 3px;
  color: #777777;
}
.edit-shortcut:before {
  content: "(edit)";
  padding-right: 3px;
  color: #777777;
}
[dir="rtl"] .edit-shortcut.pull-right {
  float: left !important;
  float: left;
}
#find-and-replace #replace-preview .match,
#find-and-replace #replace-preview .insert {
  background-color: #BBDEFB;
  border-color: #90CAF9;
  border-style: solid;
  border-width: 1px;
  border-radius: 0px;
}
[dir="ltr"] #find-and-replace .input-group-btn + .form-control {
  border-left: none;
}
[dir="rtl"] #find-and-replace .input-group-btn + .form-control {
  border-right: none;
}
#find-and-replace #replace-preview .replace .match {
  background-color: #FFCDD2;
  border-color: #EF9A9A;
  border-radius: 0px;
}
#find-and-replace #replace-preview .replace .insert {
  background-color: #C8E6C9;
  border-color: #A5D6A7;
  border-radius: 0px;
}
#find-and-replace #replace-preview {
  max-height: 60vh;
  overflow: auto;
}
#find-and-replace #replace-preview pre {
  padding: 5px 10px;
}
.terminal-app {
  background: #EEE;
}
.terminal-app #header {
  background: #fff;
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
}
.terminal-app .terminal {
  width: 100%;
  float: left;
  font-family: monospace;
  color: white;
  background: black;
  padding: 0.4em;
  border-radius: 2px;
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.4);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.4);
}
.terminal-app .terminal,
.terminal-app .terminal dummy-screen {
  line-height: 1em;
  font-size: 14px;
}
.terminal-app .terminal .xterm-rows {
  padding: 10px;
}
.terminal-app .terminal-cursor {
  color: black;
  background: white;
}
.terminal-app #terminado-container {
  margin-top: 20px;
}
/*# sourceMappingURL=style.min.css.map */
    </style>
<style type="text/css">
    .highlight .hll { background-color: #ffffcc }
.highlight  { background: #f8f8f8; }
.highlight .c { color: #408080; font-style: italic } /* Comment */
.highlight .err { border: 1px solid #FF0000 } /* Error */
.highlight .k { color: #008000; font-weight: bold } /* Keyword */
.highlight .o { color: #666666 } /* Operator */
.highlight .ch { color: #408080; font-style: italic } /* Comment.Hashbang */
.highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */
.highlight .cp { color: #BC7A00 } /* Comment.Preproc */
.highlight .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */
.highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */
.highlight .cs { color: #408080; font-style: italic } /* Comment.Special */
.highlight .gd { color: #A00000 } /* Generic.Deleted */
.highlight .ge { font-style: italic } /* Generic.Emph */
.highlight .gr { color: #FF0000 } /* Generic.Error */
.highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */
.highlight .gi { color: #00A000 } /* Generic.Inserted */
.highlight .go { color: #888888 } /* Generic.Output */
.highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */
.highlight .gs { font-weight: bold } /* Generic.Strong */
.highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */
.highlight .gt { color: #0044DD } /* Generic.Traceback */
.highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */
.highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */
.highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */
.highlight .kp { color: #008000 } /* Keyword.Pseudo */
.highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */
.highlight .kt { color: #B00040 } /* Keyword.Type */
.highlight .m { color: #666666 } /* Literal.Number */
.highlight .s { color: #BA2121 } /* Literal.String */
.highlight .na { color: #7D9029 } /* Name.Attribute */
.highlight .nb { color: #008000 } /* Name.Builtin */
.highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */
.highlight .no { color: #880000 } /* Name.Constant */
.highlight .nd { color: #AA22FF } /* Name.Decorator */
.highlight .ni { color: #999999; font-weight: bold } /* Name.Entity */
.highlight .ne { color: #D2413A; font-weight: bold } /* Name.Exception */
.highlight .nf { color: #0000FF } /* Name.Function */
.highlight .nl { color: #A0A000 } /* Name.Label */
.highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */
.highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */
.highlight .nv { color: #19177C } /* Name.Variable */
.highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */
.highlight .w { color: #bbbbbb } /* Text.Whitespace */
.highlight .mb { color: #666666 } /* Literal.Number.Bin */
.highlight .mf { color: #666666 } /* Literal.Number.Float */
.highlight .mh { color: #666666 } /* Literal.Number.Hex */
.highlight .mi { color: #666666 } /* Literal.Number.Integer */
.highlight .mo { color: #666666 } /* Literal.Number.Oct */
.highlight .sa { color: #BA2121 } /* Literal.String.Affix */
.highlight .sb { color: #BA2121 } /* Literal.String.Backtick */
.highlight .sc { color: #BA2121 } /* Literal.String.Char */
.highlight .dl { color: #BA2121 } /* Literal.String.Delimiter */
.highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */
.highlight .s2 { color: #BA2121 } /* Literal.String.Double */
.highlight .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */
.highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */
.highlight .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */
.highlight .sx { color: #008000 } /* Literal.String.Other */
.highlight .sr { color: #BB6688 } /* Literal.String.Regex */
.highlight .s1 { color: #BA2121 } /* Literal.String.Single */
.highlight .ss { color: #19177C } /* Literal.String.Symbol */
.highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */
.highlight .fm { color: #0000FF } /* Name.Function.Magic */
.highlight .vc { color: #19177C } /* Name.Variable.Class */
.highlight .vg { color: #19177C } /* Name.Variable.Global */
.highlight .vi { color: #19177C } /* Name.Variable.Instance */
.highlight .vm { color: #19177C } /* Name.Variable.Magic */
.highlight .il { color: #666666 } /* Literal.Number.Integer.Long */
    </style>
<style type="text/css">
    
/* Temporary definitions which will become obsolete with Notebook release 5.0 */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-bold { font-weight: bold; }

    </style>


<style type="text/css">
/* Overrides of notebook CSS for static HTML export */
body {
  overflow: visible;
  padding: 8px;
}

div#notebook {
  overflow: visible;
  border-top: none;
}@media print {
  div.cell {
    display: block;
    page-break-inside: avoid;
  } 
  div.output_wrapper { 
    display: block;
    page-break-inside: avoid; 
  }
  div.output { 
    display: block;
    page-break-inside: avoid; 
  }
}
</style>

<!-- Custom stylesheet, it must be in the same directory as the html file -->
<link rel="stylesheet" href="custom.css">

<!-- Loading mathjax macro -->
<!-- Load mathjax -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS_HTML"></script>
    <!-- MathJax configuration -->
    <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ['$','$'], ["\\(","\\)"] ],
            displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
            processEscapes: true,
            processEnvironments: true
        },
        // Center justify equations in code and markdown cells. Elsewhere
        // we use CSS to left justify single line equations in code cells.
        displayAlign: 'center',
        "HTML-CSS": {
            styles: {'.MathJax_Display': {"margin": 0}},
            linebreaks: { automatic: true }
        }
    });
    </script>
    <!-- End of mathjax configuration --></head>
<body>
  <div tabindex="-1" id="notebook" class="border-box-sizing">
    <div class="container" id="notebook-container">

<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><img src="data:image/jpeg;base64,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"/></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Bank-Note-Analysis"><strong>Bank Note Analysis</strong><a class="anchor-link" href="#Bank-Note-Analysis">&#182;</a></h1>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><br></p>
<p><strong>Data Set Information:</strong></p>
<p>Data were extracted from images that were taken from genuine and forged banknote-like specimens. For digitization, an industrial camera usually used for print inspection was used. The final images have 400x 400 pixels. Due to the object lens and distance to the investigated object gray-scale pictures with a resolution of about 660 dpi were gained. Wavelet Transform tool were used to extract features from images.</p>
<p><strong>Attribute Information:</strong></p>
<ol>
<li>variance of Wavelet Transformed image (continuous)</li>
<li>skewness of Wavelet Transformed image (continuous)</li>
<li>curtosis of Wavelet Transformed image (continuous)</li>
<li>entropy of image (continuous)</li>
<li>class (integer)</li>
</ol>
<p><strong>Dataset:</strong> <a href="https://www.kaggle.com/ritesaluja/bank-note-authentication-uci-data">https://www.kaggle.com/ritesaluja/bank-note-authentication-uci-data</a></p>
<p><strong>UCI:</strong> <a href="http://archive.ics.uci.edu/ml/datasets/banknote+authentication">http://archive.ics.uci.edu/ml/datasets/banknote+authentication</a></p>
<p><br></p>
<h3 id="Can-we-classify-banknote-as-fake-or-genuine?"><strong>Can we classify banknote as fake or genuine?</strong><a class="anchor-link" href="#Can-we-classify-banknote-as-fake-or-genuine?">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[65]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">pyforest</span> <span class="k">import</span><span class="o">*</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[66]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">lazy_imports</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[66]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>[&#39;import os&#39;,
 &#39;import plotly.express as px&#39;,
 &#39;import altair as alt&#39;,
 &#39;import plotly.graph_objs as go&#39;,
 &#39;import keras&#39;,
 &#39;import bokeh&#39;,
 &#39;import datetime as dt&#39;,
 &#39;from sklearn.preprocessing import OneHotEncoder&#39;,
 &#39;from pathlib import Path&#39;,
 &#39;import sklearn&#39;,
 &#39;import numpy as np&#39;,
 &#39;from sklearn.manifold import TSNE&#39;,
 &#39;from sklearn.ensemble import GradientBoostingRegressor&#39;,
 &#39;import re&#39;,
 &#39;import plotly as py&#39;,
 &#39;from sklearn.model_selection import train_test_split&#39;,
 &#39;import statistics&#39;,
 &#39;from sklearn.ensemble import RandomForestClassifier&#39;,
 &#39;import nltk&#39;,
 &#39;from sklearn.ensemble import RandomForestRegressor&#39;,
 &#39;import tensorflow as tf&#39;,
 &#39;from sklearn import svm&#39;,
 &#39;import pickle&#39;,
 &#39;import dash&#39;,
 &#39;import matplotlib as mpl&#39;,
 &#39;from dask import dataframe as dd&#39;,
 &#39;from sklearn.feature_extraction.text import TfidfVectorizer&#39;,
 &#39;import tqdm&#39;,
 &#39;from pyspark import SparkContext&#39;,
 &#39;from sklearn.ensemble import GradientBoostingClassifier&#39;,
 &#39;import spacy&#39;,
 &#39;import gensim&#39;,
 &#39;import pydot&#39;,
 &#39;from openpyxl import load_workbook&#39;,
 &#39;import glob&#39;,
 &#39;import sys&#39;]</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[67]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df</span><span class="o">=</span><span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;BankNote_Authentication.csv&#39;</span><span class="p">)</span>   
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>





<div id="acb09d96-3ec2-4717-9137-a0cf5b121ec5"></div>
<div class="output_subarea output_javascript ">
<script type="text/javascript">
var element = $('#acb09d96-3ec2-4717-9137-a0cf5b121ec5');

        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns'); }
    
</script>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[68]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[68]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>variance</th>
      <th>skewness</th>
      <th>curtosis</th>
      <th>entropy</th>
      <th>class</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>3.62160</td>
      <td>8.6661</td>
      <td>-2.8073</td>
      <td>-0.44699</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>4.54590</td>
      <td>8.1674</td>
      <td>-2.4586</td>
      <td>-1.46210</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3.86600</td>
      <td>-2.6383</td>
      <td>1.9242</td>
      <td>0.10645</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>3.45660</td>
      <td>9.5228</td>
      <td>-4.0112</td>
      <td>-3.59440</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.32924</td>
      <td>-4.4552</td>
      <td>4.5718</td>
      <td>-0.98880</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[69]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[69]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>(1372, 5)</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[70]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;class&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[70]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>0    762
1    610
Name: class, dtype: int64</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[71]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df</span><span class="o">.</span><span class="n">isna</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[71]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>variance    0
skewness    0
curtosis    0
entropy     0
class       0
dtype: int64</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[72]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df</span><span class="o">.</span><span class="n">dtypes</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[72]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>variance    float64
skewness    float64
curtosis    float64
entropy     float64
class         int64
dtype: object</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><br></p>
<h2 id="Visualizations">Visualizations<a class="anchor-link" href="#Visualizations">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Univariate-Data-Analysis">Univariate Data Analysis<a class="anchor-link" href="#Univariate-Data-Analysis">&#182;</a></h4>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[73]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">7</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Distribution of &quot;Class&quot; Attribute&#39;</span><span class="p">)</span>

<span class="n">sns</span><span class="o">.</span><span class="n">distplot</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;class&#39;</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>





<div id="43948640-2004-4524-ba68-1e639b2e47f0"></div>
<div class="output_subarea output_javascript ">
<script type="text/javascript">
var element = $('#43948640-2004-4524-ba68-1e639b2e47f0');

        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns'); }
    
</script>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>





<div id="a91b0896-859d-4348-90f4-d7d74ff3ec95"></div>
<div class="output_subarea output_javascript ">
<script type="text/javascript">
var element = $('#a91b0896-859d-4348-90f4-d7d74ff3ec95');

        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns'); }
    
</script>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>





<div id="4bb4152b-fa64-43d9-bb70-78b7de9f21f0"></div>
<div class="output_subarea output_javascript ">
<script type="text/javascript">
var element = $('#4bb4152b-fa64-43d9-bb70-78b7de9f21f0');

        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns'); }
    
</script>
</div>

</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[73]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&lt;matplotlib.axes._subplots.AxesSubplot at 0x125c39358&gt;</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>




<div class="output_png output_subarea ">
<img src="data:image/png;base64,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
"
>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Multivariate-Data-Analysis">Multivariate Data Analysis<a class="anchor-link" href="#Multivariate-Data-Analysis">&#182;</a></h4>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[74]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">bins</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span><span class="mi">8</span><span class="p">),</span><span class="n">layout</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">));</span> <span class="c1">#Histogram of all the attributes</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>




<div class="output_png output_subarea ">
<img src="data:image/png;base64,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
"
>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[75]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># col_names = df.drop(&#39;class&#39;, axis = 1).columns.tolist()</span>

<span class="c1"># plt.figure(figsize = (10,3))</span>
<span class="c1"># i = 0</span>
<span class="c1"># for col in col_names:</span>
<span class="c1">#     plt.subplot(1,4,i+1)</span>
<span class="c1">#     plt.grid(True, alpha =0.5)</span>
<span class="c1">#     sns.kdeplot(df[col][df[&#39;class&#39;] ==0], label = &#39;Fake note&#39;)</span>
<span class="c1">#     sns.kdeplot(df[col][df[&#39;class&#39;] ==1], label = &#39;Original note&#39;)</span>
<span class="c1">#     plt.title(&#39;Class vs &#39; + col)</span>
<span class="c1">#     plt.tight_layout()</span>
<span class="c1">#     i+=1</span>
<span class="c1"># plt.show()</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[76]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">warnings</span>

<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s1">&#39;ignore&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[77]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">sns</span><span class="o">.</span><span class="n">pairplot</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">hue</span><span class="o">=</span><span class="s2">&quot;class&quot;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>





<div id="34c854df-eac0-44d6-b00d-b188cd6b62cd"></div>
<div class="output_subarea output_javascript ">
<script type="text/javascript">
var element = $('#34c854df-eac0-44d6-b00d-b188cd6b62cd');

        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns'); }
    
</script>
</div>

</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[77]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&lt;seaborn.axisgrid.PairGrid at 0x125e077b8&gt;</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>




<div class="output_png output_subarea ">
<img src="data:image/png;base64,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
"
>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><br></p>
<h3 id="Preparing-Our-Data-To-Build-Our-Model"><strong>Preparing Our Data To Build Our Model</strong><a class="anchor-link" href="#Preparing-Our-Data-To-Build-Our-Model">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[78]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[78]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>variance</th>
      <th>skewness</th>
      <th>curtosis</th>
      <th>entropy</th>
      <th>class</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>3.62160</td>
      <td>8.6661</td>
      <td>-2.8073</td>
      <td>-0.44699</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>4.54590</td>
      <td>8.1674</td>
      <td>-2.4586</td>
      <td>-1.46210</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3.86600</td>
      <td>-2.6383</td>
      <td>1.9242</td>
      <td>0.10645</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>3.45660</td>
      <td>9.5228</td>
      <td>-4.0112</td>
      <td>-3.59440</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.32924</td>
      <td>-4.4552</td>
      <td>4.5718</td>
      <td>-0.98880</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[79]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#defining features and target variable</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">drop</span><span class="p">([</span><span class="s1">&#39;class&#39;</span><span class="p">],</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> 
<span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;class&#39;</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[80]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="k">import</span> <span class="n">train_test_split</span>

<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.20</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><br></p>
<p><strong>Scaling Our Data</strong></p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[81]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="k">import</span> <span class="n">StandardScaler</span>

<span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">X_train</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">X_test</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[82]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">X_train</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[82]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>array([[-1.58438248,  0.1072115 , -0.14276339,  0.03334576],
       [-1.08829139, -2.53123321,  2.67783284, -0.35092979],
       [ 1.13672843, -0.15348755, -0.16820608,  0.86368769],
       ...,
       [-1.6900361 ,  0.72314447, -0.19588896, -2.05114485],
       [ 0.57766241,  0.02698182,  0.1851622 ,  0.52080477],
       [-0.9644631 ,  0.30908695, -0.49734797, -0.03521515]])</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[83]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">y_train</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[83]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>1226    1
1085    1
148     0
1178    1
478     0
Name: class, dtype: int64</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><br></p>
<h3 id="Logistic-Regression"><strong>Logistic Regression</strong><a class="anchor-link" href="#Logistic-Regression">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[84]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="k">import</span> <span class="n">LogisticRegression</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="k">import</span> <span class="n">cross_val_score</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="k">import</span> <span class="n">accuracy_score</span>

<span class="n">classifier</span><span class="o">=</span><span class="n">LogisticRegression</span><span class="p">(</span><span class="n">solver</span><span class="o">=</span><span class="s1">&#39;liblinear&#39;</span><span class="p">,</span><span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">classifier</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span>

<span class="n">accuracies</span><span class="o">=</span><span class="n">cross_val_score</span><span class="p">(</span><span class="n">estimator</span><span class="o">=</span><span class="n">classifier</span><span class="p">,</span><span class="n">X</span><span class="o">=</span><span class="n">X_train</span><span class="p">,</span><span class="n">y</span><span class="o">=</span><span class="n">y_train</span><span class="p">,</span><span class="n">cv</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span> <span class="c1"># CV: Determines the cross-validation splitting strategy (How many folds, default is 5-folds) Evaluate a score by cross-validation. estimator: object to use to fit the data.</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Accuracies:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span><span class="n">accuracies</span><span class="p">)</span>

<span class="n">y_test_pred</span><span class="o">=</span><span class="n">classifier</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>


<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Mean Accuracy: &quot;</span><span class="p">,</span><span class="n">accuracies</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Accuracies:
 [0.98181818 0.99090909 0.98181818 0.99090909 0.99090909 0.99090909
 0.96363636 0.99082569 0.97247706 0.98165138]
Mean Accuracy:  0.9835863219349459
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[85]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span><span class="n">y_test_pred</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[85]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>0.9745454545454545</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[86]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn</span> <span class="k">import</span> <span class="n">metrics</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Confusion Matrix For Logistic Regression&quot;</span><span class="p">)</span>
<span class="n">cm</span><span class="o">=</span><span class="n">metrics</span><span class="o">.</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_test_pred</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>

<span class="n">df_cm</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">cm</span><span class="p">,</span> <span class="n">index</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">]],</span>
                  <span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;Predict 0&quot;</span><span class="p">,</span><span class="s2">&quot;Predict 1&quot;</span><span class="p">]])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">7</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">df_cm</span><span class="p">,</span> <span class="n">annot</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Confusion Matrix For Logistic Regression
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>





<div id="eb23a27e-b783-4164-a286-68c904812429"></div>
<div class="output_subarea output_javascript ">
<script type="text/javascript">
var element = $('#eb23a27e-b783-4164-a286-68c904812429');

        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns'); }
    
</script>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>





<div id="b9bd362e-c767-41df-b5a7-4cee9c6493c2"></div>
<div class="output_subarea output_javascript ">
<script type="text/javascript">
var element = $('#b9bd362e-c767-41df-b5a7-4cee9c6493c2');

        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns'); }
    
</script>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>





<div id="1add249e-09ea-40a6-8a89-be2d5a4bfec9"></div>
<div class="output_subarea output_javascript ">
<script type="text/javascript">
var element = $('#1add249e-09ea-40a6-8a89-be2d5a4bfec9');

        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns'); }
    
</script>
</div>

</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[86]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&lt;matplotlib.axes._subplots.AxesSubplot at 0x125f5f320&gt;</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>




<div class="output_png output_subarea ">
<img src="data:image/png;base64,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
"
>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><br></p>
<h3 id="Support-Vector-Machine"><strong>Support Vector Machine</strong><a class="anchor-link" href="#Support-Vector-Machine">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[87]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.svm</span> <span class="k">import</span> <span class="n">SVC</span>

<span class="n">svm_classifier</span><span class="o">=</span><span class="n">SVC</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="s1">&#39;linear&#39;</span><span class="p">)</span>
<span class="n">svm_classifier</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span>

<span class="n">svm_accuracies</span><span class="o">=</span><span class="n">cross_val_score</span><span class="p">(</span><span class="n">estimator</span><span class="o">=</span><span class="n">svm_classifier</span><span class="p">,</span><span class="n">X</span><span class="o">=</span><span class="n">X_train</span><span class="p">,</span><span class="n">y</span><span class="o">=</span><span class="n">y_train</span><span class="p">,</span><span class="n">cv</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Accuracies:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span><span class="n">svm_accuracies</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Accuracies:
 [0.99090909 0.99090909 0.99090909 0.99090909 0.99090909 0.99090909
 0.96363636 0.99082569 0.97247706 0.98165138]
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[88]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">svm_pred</span><span class="o">=</span><span class="n">svm_classifier</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Mean Accuracy: &quot;</span><span class="p">,</span><span class="n">svm_accuracies</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Mean Accuracy:  0.9854045037531277
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[89]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span><span class="n">svm_pred</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[89]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>0.9818181818181818</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[90]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Confusion Matrix For svm_pred&quot;</span><span class="p">)</span>
<span class="n">cm</span><span class="o">=</span><span class="n">metrics</span><span class="o">.</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span><span class="n">svm_pred</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>

<span class="n">df_cm</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">cm</span><span class="p">,</span> <span class="n">index</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">]],</span>
                  <span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;Predict 0&quot;</span><span class="p">,</span><span class="s2">&quot;Predict 1&quot;</span><span class="p">]])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">7</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">df_cm</span><span class="p">,</span> <span class="n">annot</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Confusion Matrix For svm_pred
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>





<div id="5d955e62-c00c-42bf-a2a3-6b2b3bdb0a03"></div>
<div class="output_subarea output_javascript ">
<script type="text/javascript">
var element = $('#5d955e62-c00c-42bf-a2a3-6b2b3bdb0a03');

        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns'); }
    
</script>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>





<div id="cf49c625-9d65-4644-a4f3-c49ea0b98068"></div>
<div class="output_subarea output_javascript ">
<script type="text/javascript">
var element = $('#cf49c625-9d65-4644-a4f3-c49ea0b98068');

        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns'); }
    
</script>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>





<div id="f3c2de75-960e-41b8-95fb-4822bdfcdbba"></div>
<div class="output_subarea output_javascript ">
<script type="text/javascript">
var element = $('#f3c2de75-960e-41b8-95fb-4822bdfcdbba');

        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns'); }
    
</script>
</div>

</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[90]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&lt;matplotlib.axes._subplots.AxesSubplot at 0x125c80c18&gt;</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>




<div class="output_png output_subarea ">
<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAZMAAAEvCAYAAACAFCxvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAWwUlEQVR4nO3de5xdVX338c8vM5kESEICkRASpMj9UglIIfqARUAJmHJ9bOGpEk1qqoBCtVbyYMUg+IBcVB5BXmMJBLCBVEBTqJQQReQaESImXEqIAjGBcAvXJDOZs/rHOaRjMpmZnDVnZp/M581rv+acffbZex1eJ/Od31pr7x0pJSRJyjGgrxsgSap/hokkKZthIknKZphIkrIZJpKkbIaJJClbY60P0PryEuceq9cM2/Ejfd0E9TOrVj0bPbWvan9fDhz5vh5rQ7WsTCRJ2QwTSSqKUlt1SxciYkZErIiIhe3WfSMi/hgRCyrLMe1emxYRiyPiqYg4qjtNr3k3lySpm1KpVnu+Fvg+cN1667+TUrqk/YqI2Bs4GdgH2AG4KyJ2Tyl1mlpWJpJUFKVSdUsXUkr3AK92sxXHATemlNaklH4PLAYO6upNhokkFURKpaqWiJgaEQ+3W6Z285BnRMRjlW6wEZV1Y4Dn222ztLKuU4aJJBVFlZVJSqk5pXRgu6W5G0f7AbALMA5YDlxaWd/RzLAuZ5k5ZiJJRVG7MZMND5XSi+8+jogfArdVni4Fdmy36VhgWVf7szKRpKKo0WyujkTE6HZPTwDenek1Bzg5IgZFxM7AbsD8rvZnZSJJRVGjyiQiZgGHASMjYilwLnBYRIyj3IX1B+DvAVJKiyJiNvA4sBY4vauZXABR65tjeQa8epNnwKu39eQZ8C1L5lf1+7LpfQf1+RnwViaSVBCpF8dMepphIklF0Y1zRorKMJGkorAykSRlq3JmVhEYJpJUFFYmkqRsjplIkrLVcWXiGfCSpGxWJpJUFHZzSZJydeOqJYVlmEhSUdTxmIlhIklFYTeXJCmblYkkKZtnwEuSslmZSJKyOWYiScpmZSJJymZlIknKZphIknJ5BrwkKZ+ViSQpmwPwkqRsViaSpGx1XJl4cyxJUjYrE0kqCru5JEnZ6ribyzCRpKKwMpEkZTNMJEnZ7OaSJGWzMpEkZbMykSRlszKRJGWzMpEkZbMykSRlM0wkSdlS6usWVM0wkaSisDKRJGUzTCRJ2ZzNJUnKVseViTfHkiRlszKRpKJwNpckKZvdXJKkbKVSdUsXImJGRKyIiIXt1l0cEU9GxGMRcWtEDG/32rSIWBwRT0XEUd1pumEiSUWRStUtXbsWmLDeurnAviml9wP/BUwDiIi9gZOBfSrvuTIiGro6gGEiSQWRSqmqpcv9pnQP8Op66+5MKa2tPH0QGFt5fBxwY0ppTUrp98Bi4KCujuGYiSQVRd+NmUwGbqo8HkM5XN61tLKuU1YmklQUVXZzRcTUiHi43TK1u4eMiHOAtcCP3l3VUcu62o+ViSQVRTe6rDqSUmoGmjf1fRExCZgIHJHSunnJS4Ed2202FljW1b6sTCSpKGo0m6sjETEB+CpwbErpnXYvzQFOjohBEbEzsBswv6v9WZlIUlHUaMwkImYBhwEjI2IpcC7l2VuDgLkRAfBgSulzKaVFETEbeJxy99fpKaW2ro5hmPSQr33rMu65bz7bjBjOT264aoPX5z/yGF88ezpjRm8PwJF/+SE+P/lvs47Z0tLCtG9eyuNPPc3wrYdxyXnTGDN6FPfPf4TvXnUNra1rGTiwkS+fPoWDPzAu61javA0YMID77ruNZcte4KSTJvd1c/qvGp0Bn1I6pYPVV3ey/QXABZtyDLu5esjxx3yUqy47v9NtDthvX26eeQU3z7xik4Lkj8tf5NNn/NMG62+57U6GDR3Cz2bP4FN/czyXXTkDgBHDh/H9i77Brdf/gAu+9mWmnXfJpn0Y9TtnnDGZp55a3NfNUC92c/W0LsMkIvaMiK9GxOUR8b3K4716o3H15MBxf87Ww4ZW9d5//8+fc/LfnclJk05n+rcvp62ty4oSgJ//6gGOO+ZIAD522KE89JsFpJTYa/dd2e492wKw6847saalhZaWlqraps3fmDHbM2HC4VxzzY193RSVUnVLAXQaJhHxVeBGylPF5gO/rjyeFRFn1755m5ffLnyCEyedxue+/M8sXvIsAM/84TnumPdLrr/qUm6eeQUDBgzgtjt/0a39rXjpFbbfbiQAjY0NDNlqS1a+/safbDP37nvZa/ddaGpq6tkPo83GxRefyznnfItSQf7C7ddqdwZ8zXU1ZjIF2Cel1Np+ZURcBiwCLqxVwzY3e++xC3NvnsmWW27BPffP54vTzuM/brqahx5ewONPLubkKWcCsGbNGrYZUb5Ezhennccfl71I69pWlr/4EidNOh2AT/71cZzw8Y+ROuhfrQykAbB4ybNcduUMmr+zSV2f6keOPvpwVqx4hUcfXcihh47v6+aoIFVGNboKkxKwA/DseutHV17rUOWEmakAV156Pn93akdjP/3LkK22Wvf4wx86iPMvvYLXVr5OSoljjz6Sf/j8ZzZ4z+X/7+tAeczknAsu5drvf/tPXh+13UheWPEy22/3HtaubeOtt99Z19X2woqXOPP/fpNv/fM/8t6xO9Twk6meffCDBzJx4pFMmHAYgwYNYtiwocyY8V0mTz6rr5vWL6U6rg67GjM5C5gXET+LiObKcgcwDzhzY29KKTWnlA5MKR1okJS9/Mqr6yqJ3z3+FKWUGL71MMYfOI65d9/LK6+tBOD1N95k2QsvdmufHzlkPD/9j7sAuPPuX3HwB/YjInjjzbc47Svnctbff5oD3r9PbT6QNgtf//q32XXX8ey55yGceuoXuPvu+w0SVaXTyiSldEdE7E75Il9jKI+XLAV+3Z15x/3JV869kF8/+hgrV77BEcd/ktOmfIq1a8vXUPubEz7Onb+4l5tuvZ2GxgYGNzVx8fSziQh22XknvvDZU5l61jmUUomBjY2c86XT2GH7UV0e88SJRzHtmxdz9F9PZuthQ7l4enkYa9bN/87zS5dx1bWzuOraWQA0f/cCth0xvLPdSeprddzNFR31u/ek1peX1O//HdWdYTt+pK+boH5m1apnO7qWVVXePv+TVf2+3OprN/RYG6rlSYuSVBR1XJkYJpJUFHU8AG+YSFJRWJlIkrIV5ATEahgmklQUViaSpFz1fNKiYSJJRWFlIknKZphIkrI5AC9JymZlIknKlQwTSVI2w0SSlM2pwZKkbFYmkqRsdRwmXd1pUZKkLlmZSFJB1PpmhbVkmEhSUdRxN5dhIklFYZhIknJ50qIkKZ9hIknKVr/nLBomklQUdnNJkvIZJpKkbHZzSZJy2c0lScpnZSJJymVlIknKZ2UiScqVDBNJUjbDRJKUq54rE2+OJUnKZmUiSUVRx5WJYSJJBVHP3VyGiSQVhGEiScpWz2HiALwkFUWK6pYuRMSZEbEwIhZFxFmVddtExNyIeLryc0RO0w0TSSqIVKpu6UxE7At8FjgI2A+YGBG7AWcD81JKuwHzKs+rZphIUkGkUlS1dGEv4MGU0jsppbXAL4ETgOOAmZVtZgLH57TdMJGkgqhFZQIsBD4cEdtGxJbAMcCOwKiU0nKAys/tctruALwkFUTqxvhHRyJiKjC13armlFJzeZ/piYi4CJgLvAX8Flib2dQNGCaSVBDVzuaqBEdzJ69fDVwNEBHfApYCL0bE6JTS8ogYDayo7uhldnNJUkHUaMyEiNiu8vO9wInALGAOMKmyySTgpzlttzKRpIJItbs31s0RsS3QCpyeUnotIi4EZkfEFOA54BM5BzBMJKkgulNlVLXflA7tYN0rwBE9dQzDRJIKolZh0hsME0kqiBp2c9WcYSJJBVHPlYmzuSRJ2axMJKkgqj1psQgME0kqiHq+BL1hIkkFUbIykSTlsptLkpStnmdzGSaSVBCeZyJJymZlIknK5gC8JCmbA/CSpGyOmUiSstnNJUnKZjeXJCmb3Vyd2GKHDW7wJdXMGxce09dNkKpmN5ckKZvdXJKkbPVcmXhzLElSNisTSSqIOh5/N0wkqSjquZvLMJGkgnAAXpKUrY7v2muYSFJRJKxMJEmZSnU8Am+YSFJBlKxMJEm57OaSJGVzAF6SlM3KRJKUzcpEkpTNMJEkZbObS5KUrVS/WWKYSFJReJ6JJClbHZ8A782xJEn5rEwkqSCczSVJylYKx0wkSZnqeczEMJGkgrCbS5KUzfNMJEnZ6vk8E6cGS1JBpCqX7oiI4RHx44h4MiKeiIgPRsQ2ETE3Ip6u/BxRbdsNE0kqiFJUt3TT94A7Ukp7AvsBTwBnA/NSSrsB8yrPq2KYSFJBlKpcuhIRw4APA1cDpJRaUkorgeOAmZXNZgLHV9t2w0SSCqKG3VzvA14CromIRyPiXyJiK2BUSmk5QOXndtW23TCRpIKotpsrIqZGxMPtlqnr7boROAD4QUppf+BtMrq0OuJsLkkqiGrPM0kpNQPNnWyyFFiaUnqo8vzHlMPkxYgYnVJaHhGjgRVVNsHKRJKKolZjJimlF4DnI2KPyqojgMeBOcCkyrpJwE+rbbuViSQVRKrtaSZfAH4UEU3AEuAzlAuK2RExBXgO+ES1OzdMJKkgank5lZTSAuDADl46oif2b5hIUkF4bS5JUrZ6vmqwA/CSpGxWJpJUEF41WJKUzTETSVI2w0SSlK2eB+ANE0kqCMdMJEnZ7OaSJGWzm0uSlK1Ux3FimEhSQdjNJUnKVr91iWEiSYVhZSJJyubUYElSNgfgJUnZ6jdKDBNJKgzHTCRJ2eq5m8ubY0mSslmZSFJB1G9dYphIUmE4ZiJJylbPYyaGiSQVRP1GiWEiSYVhN5ckKVuq49rEMJGkgrAykSRlcwBePeaHzZfy8WOOZMVLLzNu/yP6ujkqqKaPTaLhfe8nvfMmq6/7xgavN+x5MAP/YgIAqXU1LXf9iPTy0ryDNjTSNGEyA0btRFr1Fi23N5PeeIUB792LpkNPgoYGaGuj5Z4fU3r+ybxj9VP1GyWeAV841103m49P/Nu+boYKbu2i+1l9y/c2+np6/WVWz76Y1ddPp/XB22n66Ke6ve8Yti2DPvGPG6xv3PcQ0up3WD3jHNY+chcDDz2pfKxVb7HmJ/+f1ddNZ80dM2g6evKmfyAB5cqkmqUIrEwK5lf3PsROO43t62ao4Ep/fJoYtu3GX1/+TLvHS4ihI9Y9b9jrYBr3P4IY0EjbC0tonfcjSF3/QmrYZRytD8wBoO2/fkPT4acAkF56ft026ZVlRMNAaGiEtrWb/Ln6u3oeM6m6MomIz/RkQyTVRuO+h1D6/UIAYpvtadz9L1hz40WsvuE8KJVo2HN8t/YTQ4aT3nyt/CSVSGtWweAhf7JNw24HUFrxnEFSpVTlf0WQU5lMB67pqYZI6nkDdtyDxn0PYfVNFwHQ8N69iFE7Mfj/nFPeoHEgrHqTNqDp2NMYMGwkNDQQQ7dh8Ce/DkDro3fRtuh+oKPbAP7PL7LYdgcGHnoSa27+bm0/1GasniuTTsMkIh7b2EvAqE7eNxWYChANWzNgwFZVN1BSdWLkGJo+eiprbrkcVr/97lraHr+f1ntv3WD7ljlXlrcYti1NR32GNf92yZ+8nt56jRg6gvTWaxADiEFbrNtvDBnBoGNPo+WOGaTXX6rp59qcFaXKqEZXlcko4CjgtfXWB3D/xt6UUmoGmgEam8bU7/8dqU7F0G3Kv9x/NoO08sV169uee4JBx51O62/uglVvwuAtiYGDSW++2uU+255ZQMPeH6K0fAkNu3+AtueeKr8waAsGnfAFWu+9hdKyZzrfiTq12VYmwG3AkJTSgvVfiIi7a9Kifu6G66/gLz/8QUaO3IY/LHmY6eddwjXX3tjXzVLBNB3zWRrG7g5bDGHwZ79N6wNziAENAKx97JcMHD+RGLwVTUeUZwamUhtr/vUC0qvLab3vJww+6R8gAkpttPz8X7sVJmsX3kvT0VMYPPkC0uq3abm9GYDGcYcTw7dj4METGXjwRABW3/ydclhpk5S6MRGiqCLVuPFWJupNb1x4TF83Qf3Mll/6YUeDSVX51E4nVvX78vpnb+mxNlTLqcGSVBD1/Je3YSJJBVGUExCrYZhIUkFszrO5JEm9ZHOezSVJ6iV2c0mSstnNJUnKZjeXJClbrc/7qyXvZyJJBVGr+5lExOCImB8Rv42IRRExvbJ+54h4KCKejoibIqKp2rYbJpJUEKUql25YAxyeUtoPGAdMiIjxwEXAd1JKu1G+BuOUattumEhSQdTqfiap7K3K04GVJQGHAz+urJ8JHF9t2w0TSSqIWt62NyIaImIBsAKYCzwDrEwpvXsns6XAmGrbbphIUkGklKpaImJqRDzcbpnawb7bUkrjgLHAQcBeHTWh2rY7m0uSCqLaqcHt7yHVjW1XVm4hMh4YHhGNlepkLLCsyiZYmUhSUdRqzCQi3hMRwyuPtwCOBJ4AfgH878pmk4CfVtt2KxNJKogaXk5lNDAzIhooFxGzU0q3RcTjwI0RcT7wKHB1tQcwTCRpM5dSegzYv4P1SyiPn2QzTCSpIOr5DHjDRJIKwqsGS5KyedVgSVK2kt1ckqRc9RslhokkFYZjJpKkbIaJJCmbU4MlSdmsTCRJ2ZwaLEnKZjeXJCmb3VySpGxWJpKkbFYmkqRsDsBLkrLV87W5vG2vJCmblYkkFYTdXJKkbPXczWWYSFJBWJlIkrJZmUiSslmZSJKyWZlIkrJZmUiSsqVU6usmVM0wkaSC8NpckqRsXjVYkpTNykSSlM3KRJKUzanBkqRsTg2WJGWzm0uSlM0BeElStnquTLzToiQpm5WJJBWEs7kkSdnquZvLMJGkgnAAXpKUzcpEkpTNMRNJUjbPgJckZbMykSRlc8xEkpTNbi5JUjYrE0lSNsNEkpStfqMEop6TcHMWEVNTSs193Q71H37nlMOrBhfX1L5ugPodv3OqmmEiScpmmEiSshkmxWXftXqb3zlVzQF4SVI2KxNJUjbDpAdERFtELIiIhRHxbxGxZca+DouI2yqPj42IszvZdnhEnNbJ6xMi4qmIWNzZflRfCvx9mxERKyJiYbXtUf0yTHrGqpTSuJTSvkAL8Ln2L0bZJv+/TinNSSld2Mkmw4EO/3FHRANwBXA0sDdwSkTsvaltUCEV7vtWcS0wYVOPq82DYdLzfgXsGhF/FhFPRMSVwCPAjhHxsYh4ICIeqfxFOQTWVRBPRsS9wInv7igiPh0R3688HhURt0bEbyvLh4ALgV0qf6VevF47DgIWp5SWpJRagBuB42r/8dXLivJ9I6V0D/BqL3xmFZBh0oMiopFyJfC7yqo9gOtSSvsDbwNfA45MKR0APAx8KSIGAz8E/go4FNh+I7u/HPhlSmk/4ABgEXA28Ezlr9SvrLf9GOD5ds+XVtZpM1Gw75v6OcOkZ2wREQso/4N9Dri6sv7ZlNKDlcfjKXc33VfZdhKwE7An8PuU0tOpPLXuho0c43DgBwAppbaU0utdtCk6WOfUvc1DEb9v6ue80GPPWJVSGtd+RURA+a/DdauAuSmlU9bbbhy1+SW/FNix3fOxwLIaHEe9r4jfN/VzVia950Hgf0XErgARsWVE7A48CewcEbtUtjtlI++fB3y+8t6GiBgGvAkM3cj2vwZ2i4idI6IJOBmY0zMfRXWgt79v6ucMk16SUnoJ+DQwKyIeo/yPfc+U0mrKF9i7vTIg+uxGdnEm8JGI+B3wG2CflNIrlLsxFq4/IJpSWgucAfwn8AQwO6W0qAYfTQXU2983gIiYBTwA7BERSyNiSo9/MBWWZ8BLkrJZmUiSshkmkqRshokkKZthIknKZphIkrIZJpKkbIaJJCmbYSJJyvbfrGtkzKSwwbQAAAAASUVORK5CYII=
"
>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><br></p>
<h3 id="Support-Vector-Machine-(rbf)"><strong>Support Vector Machine</strong> (rbf)<a class="anchor-link" href="#Support-Vector-Machine-(rbf)">&#182;</a></h3><p>Kernels in SVM classification refer to the function that is responsible for defining the decision boundaries between the classes. Apart from the classic linear kernel which assumes that the different classes are separated by a straight line, a RBF (radial basis function) kernel is used when the boundaries are hypothesized to be curve-shaped.</p>
<p>RBF kernel uses two main parameters, gamma and C that are related to:</p>
<ol>
<li>the decision region (how spread the region is), and</li>
<li>the penalty for misclassifying a data point</li>
</ol>
<p>respectively</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[91]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.svm</span> <span class="k">import</span> <span class="n">SVC</span>

<span class="n">svm_rbf_classifier</span><span class="o">=</span><span class="n">SVC</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="s1">&#39;rbf&#39;</span><span class="p">,</span><span class="n">gamma</span><span class="o">=</span><span class="s1">&#39;auto&#39;</span><span class="p">)</span>
<span class="n">svm_rbf_classifier</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span>

<span class="n">svm_rbf_accuracies</span><span class="o">=</span><span class="n">cross_val_score</span><span class="p">(</span><span class="n">estimator</span><span class="o">=</span><span class="n">svm_rbf_classifier</span><span class="p">,</span><span class="n">X</span><span class="o">=</span><span class="n">X_test</span><span class="p">,</span><span class="n">y</span><span class="o">=</span><span class="n">y_test</span><span class="p">,</span><span class="n">cv</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Accuracies:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span><span class="n">svm_rbf_accuracies</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Mean Accuracy: &quot;</span><span class="p">,</span><span class="n">svm_rbf_accuracies</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Accuracies:
 [1.         0.96428571 1.         1.         1.         1.
 0.96296296 1.         1.         1.        ]
Mean Accuracy:  0.9927248677248677
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[92]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">svm_rbf_pred</span><span class="o">=</span><span class="n">svm_rbf_classifier</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span><span class="n">svm_rbf_pred</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[92]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>1.0</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[93]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Confusion Matrix For svm_rbf&quot;</span><span class="p">)</span>
<span class="n">cm</span><span class="o">=</span><span class="n">metrics</span><span class="o">.</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span><span class="n">svm_rbf_pred</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>

<span class="n">df_cm</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">cm</span><span class="p">,</span> <span class="n">index</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">]],</span>
                  <span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;Predict 0&quot;</span><span class="p">,</span><span class="s2">&quot;Predict 1&quot;</span><span class="p">]])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">7</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">df_cm</span><span class="p">,</span> <span class="n">annot</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Confusion Matrix For svm_rbf
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>





<div id="4e34781d-cfb8-48e3-a066-300e2dd08bb1"></div>
<div class="output_subarea output_javascript ">
<script type="text/javascript">
var element = $('#4e34781d-cfb8-48e3-a066-300e2dd08bb1');

        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns'); }
    
</script>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>





<div id="524ff63e-6ed6-430c-8ae0-75ddc0c14509"></div>
<div class="output_subarea output_javascript ">
<script type="text/javascript">
var element = $('#524ff63e-6ed6-430c-8ae0-75ddc0c14509');

        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns'); }
    
</script>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>





<div id="4079de86-dd2f-4d95-89cb-2bc2d4cf3542"></div>
<div class="output_subarea output_javascript ">
<script type="text/javascript">
var element = $('#4079de86-dd2f-4d95-89cb-2bc2d4cf3542');

        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns'); }
    
</script>
</div>

</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[93]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&lt;matplotlib.axes._subplots.AxesSubplot at 0x126c31cc0&gt;</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>




<div class="output_png output_subarea ">
<img src="data:image/png;base64,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
"
>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span> 
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><br></p>
<h3 id="RandomForestClassifier">RandomForestClassifier<a class="anchor-link" href="#RandomForestClassifier">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[94]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="k">import</span> <span class="n">RandomForestClassifier</span>

<span class="n">rdf_classifier</span><span class="o">=</span><span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span><span class="n">criterion</span><span class="o">=</span><span class="s1">&#39;entropy&#39;</span><span class="p">,</span><span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">rdf_classifier</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span>
<span class="n">rdf_accuracies</span><span class="o">=</span><span class="n">cross_val_score</span><span class="p">(</span><span class="n">estimator</span><span class="o">=</span><span class="n">rdf_classifier</span><span class="p">,</span><span class="n">X</span><span class="o">=</span><span class="n">X_test</span><span class="p">,</span><span class="n">y</span><span class="o">=</span><span class="n">y_test</span><span class="p">,</span><span class="n">cv</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
 
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Accuracies:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span><span class="n">rdf_accuracies</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Mean Accuracy: &quot;</span><span class="p">,</span><span class="n">rdf_accuracies</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Accuracies:
 [0.96428571 1.         0.89285714 0.96428571 1.         0.96296296
 1.         0.96296296 1.         1.        ]
Mean Accuracy:  0.9747354497354497
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[95]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">rdf_pred</span><span class="o">=</span><span class="n">rdf_classifier</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span><span class="n">rdf_pred</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[95]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>0.9963636363636363</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[96]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Confusion Matrix For Random Forest&quot;</span><span class="p">)</span>
<span class="n">cm</span><span class="o">=</span><span class="n">metrics</span><span class="o">.</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span><span class="n">rdf_pred</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>

<span class="n">df_cm</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">cm</span><span class="p">,</span> <span class="n">index</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">]],</span>
                  <span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;Predict 0&quot;</span><span class="p">,</span><span class="s2">&quot;Predict 1&quot;</span><span class="p">]])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">7</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">df_cm</span><span class="p">,</span> <span class="n">annot</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Confusion Matrix For Random Forest
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>





<div id="82501afd-084d-4756-954b-691fea08644e"></div>
<div class="output_subarea output_javascript ">
<script type="text/javascript">
var element = $('#82501afd-084d-4756-954b-691fea08644e');

        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns'); }
    
</script>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>





<div id="9262d79c-a95d-4d43-882a-19f14914bde0"></div>
<div class="output_subarea output_javascript ">
<script type="text/javascript">
var element = $('#9262d79c-a95d-4d43-882a-19f14914bde0');

        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns'); }
    
</script>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>





<div id="5199b038-b852-4842-89b6-7ad42bfcd353"></div>
<div class="output_subarea output_javascript ">
<script type="text/javascript">
var element = $('#5199b038-b852-4842-89b6-7ad42bfcd353');

        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns'); }
    
</script>
</div>

</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[96]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&lt;matplotlib.axes._subplots.AxesSubplot at 0x126f4d160&gt;</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>




<div class="output_png output_subarea ">
<img src="data:image/png;base64,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
"
>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><br></p>
<h2 id="KNeighborsClassifier">KNeighborsClassifier<a class="anchor-link" href="#KNeighborsClassifier">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[97]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="k">import</span> <span class="n">KNeighborsClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="k">import</span> <span class="n">KFold</span><span class="p">,</span> <span class="n">GridSearchCV</span>

<span class="n">param_grid</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;leaf_size&#39;</span> <span class="p">:</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">7</span><span class="p">,</span><span class="mi">9</span><span class="p">,</span><span class="mi">11</span><span class="p">],</span>
    <span class="s1">&#39;n_neighbors&#39;</span> <span class="p">:</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">7</span><span class="p">,</span><span class="mi">9</span><span class="p">,</span><span class="mi">11</span><span class="p">],</span>
    <span class="s1">&#39;p&#39;</span> <span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">]</span>    
<span class="p">}</span>

<span class="n">grid</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">KNeighborsClassifier</span><span class="p">(),</span> <span class="n">param_grid</span> <span class="o">=</span> <span class="n">param_grid</span><span class="p">)</span>
<span class="n">grid</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[97]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>GridSearchCV(cv=None, error_score=nan,
             estimator=KNeighborsClassifier(algorithm=&#39;auto&#39;, leaf_size=30,
                                            metric=&#39;minkowski&#39;,
                                            metric_params=None, n_jobs=None,
                                            n_neighbors=5, p=2,
                                            weights=&#39;uniform&#39;),
             iid=&#39;deprecated&#39;, n_jobs=None,
             param_grid={&#39;leaf_size&#39;: [2, 5, 7, 9, 11],
                         &#39;n_neighbors&#39;: [2, 5, 7, 9, 11], &#39;p&#39;: [1, 2]},
             pre_dispatch=&#39;2*n_jobs&#39;, refit=True, return_train_score=False,
             scoring=None, verbose=0)</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[98]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">grid</span><span class="o">.</span><span class="n">best_params_</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[98]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>{&#39;leaf_size&#39;: 2, &#39;n_neighbors&#39;: 2, &#39;p&#39;: 1}</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[99]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">final_KNN_Model</span> <span class="o">=</span> <span class="n">grid</span><span class="o">.</span><span class="n">best_estimator_</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[100]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">KNN</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span><span class="n">p</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">leaf_size</span><span class="o">=</span><span class="mi">2</span> <span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[101]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Call Nearest Neighbour algorithm</span>

<span class="n">KNN</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[101]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>KNeighborsClassifier(algorithm=&#39;auto&#39;, leaf_size=2, metric=&#39;minkowski&#39;,
                     metric_params=None, n_jobs=None, n_neighbors=2, p=1,
                     weights=&#39;uniform&#39;)</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[102]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">KNN_predicted</span> <span class="o">=</span> <span class="n">KNN</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span><span class="n">KNN_predicted</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[102]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>1.0</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[103]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Confusion Matrix For KNN&quot;</span><span class="p">)</span>
<span class="n">cm</span><span class="o">=</span><span class="n">metrics</span><span class="o">.</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span><span class="n">KNN_predicted</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>

<span class="n">df_cm</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">cm</span><span class="p">,</span> <span class="n">index</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">]],</span>
                  <span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;Predict 0&quot;</span><span class="p">,</span><span class="s2">&quot;Predict 1&quot;</span><span class="p">]])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">7</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">df_cm</span><span class="p">,</span> <span class="n">annot</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Confusion Matrix For KNN
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>





<div id="c1b597e2-2945-44fb-ac5d-be27ee9e3b8f"></div>
<div class="output_subarea output_javascript ">
<script type="text/javascript">
var element = $('#c1b597e2-2945-44fb-ac5d-be27ee9e3b8f');

        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns'); }
    
</script>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>





<div id="1cd0dac1-d874-4f86-aeb0-86afdf63ced4"></div>
<div class="output_subarea output_javascript ">
<script type="text/javascript">
var element = $('#1cd0dac1-d874-4f86-aeb0-86afdf63ced4');

        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns'); }
    
</script>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>





<div id="8fb1f57b-3ebb-4abb-8a51-07d0967478a1"></div>
<div class="output_subarea output_javascript ">
<script type="text/javascript">
var element = $('#8fb1f57b-3ebb-4abb-8a51-07d0967478a1');

        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns'); }
    
</script>
</div>

</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[103]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&lt;matplotlib.axes._subplots.AxesSubplot at 0x12706aac8&gt;</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>




<div class="output_png output_subarea ">
<img src="data:image/png;base64,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
"
>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><br></p>
<h2 id="Multilayer-Perceptron">Multilayer Perceptron<a class="anchor-link" href="#Multilayer-Perceptron">&#182;</a></h2><p><a href="https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html">https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html</a></p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[104]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.neural_network</span> <span class="k">import</span> <span class="n">MLPClassifier</span>
<span class="n">multi_classifier</span><span class="o">=</span><span class="n">MLPClassifier</span><span class="p">(</span><span class="n">hidden_layer_sizes</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span><span class="mi">4</span><span class="p">),</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">8000</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.0001</span><span class="p">,</span> <span class="n">solver</span><span class="o">=</span><span class="s1">&#39;sgd&#39;</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>  <span class="n">random_state</span><span class="o">=</span><span class="mi">21</span><span class="p">,</span><span class="n">tol</span><span class="o">=</span><span class="mf">0.000000001</span><span class="p">)</span>
<span class="n">multi_classifier</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span>
<span class="n">multi_accuracies</span><span class="o">=</span><span class="n">cross_val_score</span><span class="p">(</span><span class="n">estimator</span><span class="o">=</span><span class="n">multi_classifier</span><span class="p">,</span><span class="n">X</span><span class="o">=</span><span class="n">X_test</span><span class="p">,</span><span class="n">y</span><span class="o">=</span><span class="n">y_test</span><span class="p">,</span><span class="n">cv</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Iteration 1, loss = 1.02065261
Iteration 2, loss = 1.00232763
Iteration 3, loss = 0.97715486
Iteration 4, loss = 0.94973488
Iteration 5, loss = 0.92231418
Iteration 6, loss = 0.89651964
Iteration 7, loss = 0.87283524
Iteration 8, loss = 0.85051410
Iteration 9, loss = 0.83056223
Iteration 10, loss = 0.81132826
Iteration 11, loss = 0.79467501
Iteration 12, loss = 0.77862224
Iteration 13, loss = 0.76455037
Iteration 14, loss = 0.75105250
Iteration 15, loss = 0.73882781
Iteration 16, loss = 0.72727541
Iteration 17, loss = 0.71657090
Iteration 18, loss = 0.70615519
Iteration 19, loss = 0.69650376
Iteration 20, loss = 0.68705241
Iteration 21, loss = 0.67795411
Iteration 22, loss = 0.66915932
Iteration 23, loss = 0.66056959
Iteration 24, loss = 0.65225336
Iteration 25, loss = 0.64391579
Iteration 26, loss = 0.63595619
Iteration 27, loss = 0.62803230
Iteration 28, loss = 0.62041858
Iteration 29, loss = 0.61270498
Iteration 30, loss = 0.60516212
Iteration 31, loss = 0.59779594
Iteration 32, loss = 0.59035692
Iteration 33, loss = 0.58320321
Iteration 34, loss = 0.57595144
Iteration 35, loss = 0.56900180
Iteration 36, loss = 0.56205103
Iteration 37, loss = 0.55529365
Iteration 38, loss = 0.54845094
Iteration 39, loss = 0.54178612
Iteration 40, loss = 0.53513160
Iteration 41, loss = 0.52864501
Iteration 42, loss = 0.52224032
Iteration 43, loss = 0.51578667
Iteration 44, loss = 0.50946421
Iteration 45, loss = 0.50308509
Iteration 46, loss = 0.49676730
Iteration 47, loss = 0.49048927
Iteration 48, loss = 0.48424447
Iteration 49, loss = 0.47795603
Iteration 50, loss = 0.47168591
Iteration 51, loss = 0.46554127
Iteration 52, loss = 0.45931321
Iteration 53, loss = 0.45311487
Iteration 54, loss = 0.44700208
Iteration 55, loss = 0.44078905
Iteration 56, loss = 0.43458773
Iteration 57, loss = 0.42855313
Iteration 58, loss = 0.42237734
Iteration 59, loss = 0.41626065
Iteration 60, loss = 0.41010472
Iteration 61, loss = 0.40404071
Iteration 62, loss = 0.39796998
Iteration 63, loss = 0.39184843
Iteration 64, loss = 0.38582899
Iteration 65, loss = 0.37982684
Iteration 66, loss = 0.37377680
Iteration 67, loss = 0.36774698
Iteration 68, loss = 0.36184120
Iteration 69, loss = 0.35589148
Iteration 70, loss = 0.34996399
Iteration 71, loss = 0.34405863
Iteration 72, loss = 0.33821501
Iteration 73, loss = 0.33238220
Iteration 74, loss = 0.32657664
Iteration 75, loss = 0.32080032
Iteration 76, loss = 0.31512534
Iteration 77, loss = 0.30945453
Iteration 78, loss = 0.30387061
Iteration 79, loss = 0.29833487
Iteration 80, loss = 0.29282992
Iteration 81, loss = 0.28743817
Iteration 82, loss = 0.28206505
Iteration 83, loss = 0.27679398
Iteration 84, loss = 0.27160790
Iteration 85, loss = 0.26648198
Iteration 86, loss = 0.26147567
Iteration 87, loss = 0.25648488
Iteration 88, loss = 0.25167142
Iteration 89, loss = 0.24685406
Iteration 90, loss = 0.24220478
Iteration 91, loss = 0.23763726
Iteration 92, loss = 0.23315116
Iteration 93, loss = 0.22880331
Iteration 94, loss = 0.22447856
Iteration 95, loss = 0.22029372
Iteration 96, loss = 0.21615029
Iteration 97, loss = 0.21213816
Iteration 98, loss = 0.20817922
Iteration 99, loss = 0.20428405
Iteration 100, loss = 0.20048594
Iteration 101, loss = 0.19679086
Iteration 102, loss = 0.19318859
Iteration 103, loss = 0.18964047
Iteration 104, loss = 0.18621313
Iteration 105, loss = 0.18281696
Iteration 106, loss = 0.17952817
Iteration 107, loss = 0.17630263
Iteration 108, loss = 0.17318159
Iteration 109, loss = 0.17011360
Iteration 110, loss = 0.16712502
Iteration 111, loss = 0.16421313
Iteration 112, loss = 0.16136983
Iteration 113, loss = 0.15859124
Iteration 114, loss = 0.15589711
Iteration 115, loss = 0.15325848
Iteration 116, loss = 0.15070201
Iteration 117, loss = 0.14820547
Iteration 118, loss = 0.14576031
Iteration 119, loss = 0.14339203
Iteration 120, loss = 0.14106500
Iteration 121, loss = 0.13881946
Iteration 122, loss = 0.13660643
Iteration 123, loss = 0.13446933
Iteration 124, loss = 0.13237608
Iteration 125, loss = 0.13033827
Iteration 126, loss = 0.12836027
Iteration 127, loss = 0.12642249
Iteration 128, loss = 0.12454009
Iteration 129, loss = 0.12268435
Iteration 130, loss = 0.12088455
Iteration 131, loss = 0.11915212
Iteration 132, loss = 0.11741655
Iteration 133, loss = 0.11574596
Iteration 134, loss = 0.11412071
Iteration 135, loss = 0.11252615
Iteration 136, loss = 0.11098422
Iteration 137, loss = 0.10946150
Iteration 138, loss = 0.10798531
Iteration 139, loss = 0.10653809
Iteration 140, loss = 0.10513015
Iteration 141, loss = 0.10375451
Iteration 142, loss = 0.10241026
Iteration 143, loss = 0.10109661
Iteration 144, loss = 0.09980897
Iteration 145, loss = 0.09855872
Iteration 146, loss = 0.09732385
Iteration 147, loss = 0.09614793
Iteration 148, loss = 0.09496971
Iteration 149, loss = 0.09384161
Iteration 150, loss = 0.09272834
Iteration 151, loss = 0.09161685
Iteration 152, loss = 0.09057096
Iteration 153, loss = 0.08952995
Iteration 154, loss = 0.08850073
Iteration 155, loss = 0.08750489
Iteration 156, loss = 0.08653097
Iteration 157, loss = 0.08557633
Iteration 158, loss = 0.08464328
Iteration 159, loss = 0.08373069
Iteration 160, loss = 0.08283452
Iteration 161, loss = 0.08196166
Iteration 162, loss = 0.08111051
Iteration 163, loss = 0.08026085
Iteration 164, loss = 0.07944789
Iteration 165, loss = 0.07864239
Iteration 166, loss = 0.07785417
Iteration 167, loss = 0.07708332
Iteration 168, loss = 0.07633191
Iteration 169, loss = 0.07559835
Iteration 170, loss = 0.07488046
Iteration 171, loss = 0.07417128
Iteration 172, loss = 0.07347539
Iteration 173, loss = 0.07279578
Iteration 174, loss = 0.07212676
Iteration 175, loss = 0.07147993
Iteration 176, loss = 0.07082708
Iteration 177, loss = 0.07019272
Iteration 178, loss = 0.06957363
Iteration 179, loss = 0.06896190
Iteration 180, loss = 0.06836536
Iteration 181, loss = 0.06778055
Iteration 182, loss = 0.06720160
Iteration 183, loss = 0.06663578
Iteration 184, loss = 0.06607506
Iteration 185, loss = 0.06554014
Iteration 186, loss = 0.06500435
Iteration 187, loss = 0.06447534
Iteration 188, loss = 0.06395695
Iteration 189, loss = 0.06344526
Iteration 190, loss = 0.06294495
Iteration 191, loss = 0.06245129
Iteration 192, loss = 0.06197639
Iteration 193, loss = 0.06149206
Iteration 194, loss = 0.06102840
Iteration 195, loss = 0.06057314
Iteration 196, loss = 0.06013086
Iteration 197, loss = 0.05968988
Iteration 198, loss = 0.05925400
Iteration 199, loss = 0.05883593
Iteration 200, loss = 0.05841735
Iteration 201, loss = 0.05800045
Iteration 202, loss = 0.05759967
Iteration 203, loss = 0.05720536
Iteration 204, loss = 0.05680791
Iteration 205, loss = 0.05642613
Iteration 206, loss = 0.05603566
Iteration 207, loss = 0.05566237
Iteration 208, loss = 0.05529067
Iteration 209, loss = 0.05493253
Iteration 210, loss = 0.05457438
Iteration 211, loss = 0.05421724
Iteration 212, loss = 0.05386587
Iteration 213, loss = 0.05352801
Iteration 214, loss = 0.05319007
Iteration 215, loss = 0.05285737
Iteration 216, loss = 0.05252950
Iteration 217, loss = 0.05220530
Iteration 218, loss = 0.05188605
Iteration 219, loss = 0.05157180
Iteration 220, loss = 0.05126418
Iteration 221, loss = 0.05096363
Iteration 222, loss = 0.05065958
Iteration 223, loss = 0.05036744
Iteration 224, loss = 0.05006724
Iteration 225, loss = 0.04977752
Iteration 226, loss = 0.04950245
Iteration 227, loss = 0.04921081
Iteration 228, loss = 0.04893026
Iteration 229, loss = 0.04866155
Iteration 230, loss = 0.04839043
Iteration 231, loss = 0.04812989
Iteration 232, loss = 0.04786760
Iteration 233, loss = 0.04760596
Iteration 234, loss = 0.04735202
Iteration 235, loss = 0.04710676
Iteration 236, loss = 0.04685101
Iteration 237, loss = 0.04660956
Iteration 238, loss = 0.04636803
Iteration 239, loss = 0.04612591
Iteration 240, loss = 0.04588605
Iteration 241, loss = 0.04564952
Iteration 242, loss = 0.04541974
Iteration 243, loss = 0.04519042
Iteration 244, loss = 0.04496640
Iteration 245, loss = 0.04474029
Iteration 246, loss = 0.04451830
Iteration 247, loss = 0.04429805
Iteration 248, loss = 0.04408530
Iteration 249, loss = 0.04387552
Iteration 250, loss = 0.04366131
Iteration 251, loss = 0.04345422
Iteration 252, loss = 0.04325435
Iteration 253, loss = 0.04305007
Iteration 254, loss = 0.04285108
Iteration 255, loss = 0.04265372
Iteration 256, loss = 0.04245935
Iteration 257, loss = 0.04226632
Iteration 258, loss = 0.04207579
Iteration 259, loss = 0.04188603
Iteration 260, loss = 0.04169793
Iteration 261, loss = 0.04151085
Iteration 262, loss = 0.04133371
Iteration 263, loss = 0.04114986
Iteration 264, loss = 0.04096914
Iteration 265, loss = 0.04078835
Iteration 266, loss = 0.04061609
Iteration 267, loss = 0.04044067
Iteration 268, loss = 0.04026434
Iteration 269, loss = 0.04009450
Iteration 270, loss = 0.03992535
Iteration 271, loss = 0.03976054
Iteration 272, loss = 0.03959222
Iteration 273, loss = 0.03942884
Iteration 274, loss = 0.03926568
Iteration 275, loss = 0.03910304
Iteration 276, loss = 0.03893744
Iteration 277, loss = 0.03878404
Iteration 278, loss = 0.03861920
Iteration 279, loss = 0.03846199
Iteration 280, loss = 0.03830598
Iteration 281, loss = 0.03815187
Iteration 282, loss = 0.03800226
Iteration 283, loss = 0.03785460
Iteration 284, loss = 0.03770229
Iteration 285, loss = 0.03756117
Iteration 286, loss = 0.03741211
Iteration 287, loss = 0.03726985
Iteration 288, loss = 0.03711690
Iteration 289, loss = 0.03697685
Iteration 290, loss = 0.03683561
Iteration 291, loss = 0.03670088
Iteration 292, loss = 0.03655956
Iteration 293, loss = 0.03642230
Iteration 294, loss = 0.03628931
Iteration 295, loss = 0.03615684
Iteration 296, loss = 0.03602420
Iteration 297, loss = 0.03589386
Iteration 298, loss = 0.03576305
Iteration 299, loss = 0.03563450
Iteration 300, loss = 0.03550705
Iteration 301, loss = 0.03537878
Iteration 302, loss = 0.03525408
Iteration 303, loss = 0.03513394
Iteration 304, loss = 0.03500536
Iteration 305, loss = 0.03488854
Iteration 306, loss = 0.03476340
Iteration 307, loss = 0.03464008
Iteration 308, loss = 0.03451699
Iteration 309, loss = 0.03439868
Iteration 310, loss = 0.03427191
Iteration 311, loss = 0.03415465
Iteration 312, loss = 0.03403997
Iteration 313, loss = 0.03392635
Iteration 314, loss = 0.03380769
Iteration 315, loss = 0.03369144
Iteration 316, loss = 0.03358002
Iteration 317, loss = 0.03347190
Iteration 318, loss = 0.03335779
Iteration 319, loss = 0.03324726
Iteration 320, loss = 0.03313638
Iteration 321, loss = 0.03302853
Iteration 322, loss = 0.03292591
Iteration 323, loss = 0.03282288
Iteration 324, loss = 0.03270784
Iteration 325, loss = 0.03260314
Iteration 326, loss = 0.03250024
Iteration 327, loss = 0.03239892
Iteration 328, loss = 0.03229020
Iteration 329, loss = 0.03219337
Iteration 330, loss = 0.03209161
Iteration 331, loss = 0.03199029
Iteration 332, loss = 0.03189282
Iteration 333, loss = 0.03179243
Iteration 334, loss = 0.03169092
Iteration 335, loss = 0.03159594
Iteration 336, loss = 0.03149929
Iteration 337, loss = 0.03139925
Iteration 338, loss = 0.03130220
Iteration 339, loss = 0.03121069
Iteration 340, loss = 0.03111529
Iteration 341, loss = 0.03101899
Iteration 342, loss = 0.03093213
Iteration 343, loss = 0.03083161
Iteration 344, loss = 0.03074001
Iteration 345, loss = 0.03064432
Iteration 346, loss = 0.03055385
Iteration 347, loss = 0.03046132
Iteration 348, loss = 0.03037244
Iteration 349, loss = 0.03027953
Iteration 350, loss = 0.03018879
Iteration 351, loss = 0.03010367
Iteration 352, loss = 0.03001329
Iteration 353, loss = 0.02992703
Iteration 354, loss = 0.02984057
Iteration 355, loss = 0.02975310
Iteration 356, loss = 0.02967029
Iteration 357, loss = 0.02958348
Iteration 358, loss = 0.02949713
Iteration 359, loss = 0.02941618
Iteration 360, loss = 0.02933012
Iteration 361, loss = 0.02924767
Iteration 362, loss = 0.02916463
Iteration 363, loss = 0.02908144
Iteration 364, loss = 0.02900216
Iteration 365, loss = 0.02892134
Iteration 366, loss = 0.02883725
Iteration 367, loss = 0.02875631
Iteration 368, loss = 0.02867269
Iteration 369, loss = 0.02859141
Iteration 370, loss = 0.02851483
Iteration 371, loss = 0.02843606
Iteration 372, loss = 0.02835714
Iteration 373, loss = 0.02828141
Iteration 374, loss = 0.02820224
Iteration 375, loss = 0.02812744
Iteration 376, loss = 0.02805597
Iteration 377, loss = 0.02797507
Iteration 378, loss = 0.02790247
Iteration 379, loss = 0.02782623
Iteration 380, loss = 0.02775717
Iteration 381, loss = 0.02767890
Iteration 382, loss = 0.02760291
Iteration 383, loss = 0.02753070
Iteration 384, loss = 0.02745955
Iteration 385, loss = 0.02738867
Iteration 386, loss = 0.02731334
Iteration 387, loss = 0.02724541
Iteration 388, loss = 0.02717366
Iteration 389, loss = 0.02710331
Iteration 390, loss = 0.02703439
Iteration 391, loss = 0.02696779
Iteration 392, loss = 0.02689249
Iteration 393, loss = 0.02682609
Iteration 394, loss = 0.02675574
Iteration 395, loss = 0.02668877
Iteration 396, loss = 0.02661835
Iteration 397, loss = 0.02655102
Iteration 398, loss = 0.02648696
Iteration 399, loss = 0.02641770
Iteration 400, loss = 0.02634867
Iteration 401, loss = 0.02627981
Iteration 402, loss = 0.02621258
Iteration 403, loss = 0.02615064
Iteration 404, loss = 0.02607949
Iteration 405, loss = 0.02601324
Iteration 406, loss = 0.02594869
Iteration 407, loss = 0.02588515
Iteration 408, loss = 0.02582360
Iteration 409, loss = 0.02575424
Iteration 410, loss = 0.02569097
Iteration 411, loss = 0.02562500
Iteration 412, loss = 0.02556431
Iteration 413, loss = 0.02549846
Iteration 414, loss = 0.02543672
Iteration 415, loss = 0.02537581
Iteration 416, loss = 0.02531503
Iteration 417, loss = 0.02525303
Iteration 418, loss = 0.02519494
Iteration 419, loss = 0.02513219
Iteration 420, loss = 0.02507011
Iteration 421, loss = 0.02500978
Iteration 422, loss = 0.02495129
Iteration 423, loss = 0.02489218
Iteration 424, loss = 0.02483195
Iteration 425, loss = 0.02477423
Iteration 426, loss = 0.02471502
Iteration 427, loss = 0.02465381
Iteration 428, loss = 0.02459555
Iteration 429, loss = 0.02453734
Iteration 430, loss = 0.02447791
Iteration 431, loss = 0.02442238
Iteration 432, loss = 0.02436120
Iteration 433, loss = 0.02430425
Iteration 434, loss = 0.02425174
Iteration 435, loss = 0.02419019
Iteration 436, loss = 0.02414233
Iteration 437, loss = 0.02408197
Iteration 438, loss = 0.02402108
Iteration 439, loss = 0.02396917
Iteration 440, loss = 0.02391141
Iteration 441, loss = 0.02385725
Iteration 442, loss = 0.02380309
Iteration 443, loss = 0.02374842
Iteration 444, loss = 0.02369450
Iteration 445, loss = 0.02364541
Iteration 446, loss = 0.02358837
Iteration 447, loss = 0.02353468
Iteration 448, loss = 0.02348492
Iteration 449, loss = 0.02343072
Iteration 450, loss = 0.02337773
Iteration 451, loss = 0.02332516
Iteration 452, loss = 0.02327478
Iteration 453, loss = 0.02322088
Iteration 454, loss = 0.02316796
Iteration 455, loss = 0.02311889
Iteration 456, loss = 0.02306737
Iteration 457, loss = 0.02301649
Iteration 458, loss = 0.02296386
Iteration 459, loss = 0.02291658
Iteration 460, loss = 0.02286528
Iteration 461, loss = 0.02281090
Iteration 462, loss = 0.02276053
Iteration 463, loss = 0.02270952
Iteration 464, loss = 0.02265984
Iteration 465, loss = 0.02260995
Iteration 466, loss = 0.02256140
Iteration 467, loss = 0.02251271
Iteration 468, loss = 0.02246010
Iteration 469, loss = 0.02241299
Iteration 470, loss = 0.02236544
Iteration 471, loss = 0.02231238
Iteration 472, loss = 0.02226811
Iteration 473, loss = 0.02221668
Iteration 474, loss = 0.02216943
Iteration 475, loss = 0.02212048
Iteration 476, loss = 0.02207214
Iteration 477, loss = 0.02202501
Iteration 478, loss = 0.02197736
Iteration 479, loss = 0.02193087
Iteration 480, loss = 0.02188917
Iteration 481, loss = 0.02183691
Iteration 482, loss = 0.02179185
Iteration 483, loss = 0.02174751
Iteration 484, loss = 0.02169894
Iteration 485, loss = 0.02165651
Iteration 486, loss = 0.02160784
Iteration 487, loss = 0.02155897
Iteration 488, loss = 0.02151358
Iteration 489, loss = 0.02146891
Iteration 490, loss = 0.02142413
Iteration 491, loss = 0.02138302
Iteration 492, loss = 0.02133110
Iteration 493, loss = 0.02128776
Iteration 494, loss = 0.02123930
Iteration 495, loss = 0.02119442
Iteration 496, loss = 0.02115463
Iteration 497, loss = 0.02110546
Iteration 498, loss = 0.02105994
Iteration 499, loss = 0.02101768
Iteration 500, loss = 0.02097409
Iteration 501, loss = 0.02092993
Iteration 502, loss = 0.02088780
Iteration 503, loss = 0.02084385
Iteration 504, loss = 0.02080190
Iteration 505, loss = 0.02076130
Iteration 506, loss = 0.02071933
Iteration 507, loss = 0.02067522
Iteration 508, loss = 0.02063738
Iteration 509, loss = 0.02059326
Iteration 510, loss = 0.02055442
Iteration 511, loss = 0.02050804
Iteration 512, loss = 0.02046894
Iteration 513, loss = 0.02042701
Iteration 514, loss = 0.02038257
Iteration 515, loss = 0.02034252
Iteration 516, loss = 0.02030666
Iteration 517, loss = 0.02026330
Iteration 518, loss = 0.02022178
Iteration 519, loss = 0.02018039
Iteration 520, loss = 0.02014305
Iteration 521, loss = 0.02010340
Iteration 522, loss = 0.02006458
Iteration 523, loss = 0.02002217
Iteration 524, loss = 0.01998025
Iteration 525, loss = 0.01994146
Iteration 526, loss = 0.01990187
Iteration 527, loss = 0.01986395
Iteration 528, loss = 0.01982180
Iteration 529, loss = 0.01978371
Iteration 530, loss = 0.01974482
Iteration 531, loss = 0.01970654
Iteration 532, loss = 0.01966994
Iteration 533, loss = 0.01962822
Iteration 534, loss = 0.01959167
Iteration 535, loss = 0.01955600
Iteration 536, loss = 0.01951895
Iteration 537, loss = 0.01947656
Iteration 538, loss = 0.01943905
Iteration 539, loss = 0.01940010
Iteration 540, loss = 0.01936248
Iteration 541, loss = 0.01932282
Iteration 542, loss = 0.01928521
Iteration 543, loss = 0.01924830
Iteration 544, loss = 0.01921152
Iteration 545, loss = 0.01917545
Iteration 546, loss = 0.01913794
Iteration 547, loss = 0.01910061
Iteration 548, loss = 0.01906512
Iteration 549, loss = 0.01902648
Iteration 550, loss = 0.01898773
Iteration 551, loss = 0.01895389
Iteration 552, loss = 0.01891872
Iteration 553, loss = 0.01887788
Iteration 554, loss = 0.01884507
Iteration 555, loss = 0.01880825
Iteration 556, loss = 0.01877205
Iteration 557, loss = 0.01873509
Iteration 558, loss = 0.01870421
Iteration 559, loss = 0.01866518
Iteration 560, loss = 0.01862787
Iteration 561, loss = 0.01859535
Iteration 562, loss = 0.01855807
Iteration 563, loss = 0.01852122
Iteration 564, loss = 0.01848908
Iteration 565, loss = 0.01845371
Iteration 566, loss = 0.01841829
Iteration 567, loss = 0.01838373
Iteration 568, loss = 0.01834905
Iteration 569, loss = 0.01831402
Iteration 570, loss = 0.01828295
Iteration 571, loss = 0.01824622
Iteration 572, loss = 0.01821089
Iteration 573, loss = 0.01817810
Iteration 574, loss = 0.01814379
Iteration 575, loss = 0.01810960
Iteration 576, loss = 0.01807762
Iteration 577, loss = 0.01804404
Iteration 578, loss = 0.01800892
Iteration 579, loss = 0.01797557
Iteration 580, loss = 0.01794376
Iteration 581, loss = 0.01790856
Iteration 582, loss = 0.01788002
Iteration 583, loss = 0.01784143
Iteration 584, loss = 0.01781075
Iteration 585, loss = 0.01777684
Iteration 586, loss = 0.01774634
Iteration 587, loss = 0.01771389
Iteration 588, loss = 0.01767803
Iteration 589, loss = 0.01764657
Iteration 590, loss = 0.01761433
Iteration 591, loss = 0.01758391
Iteration 592, loss = 0.01754953
Iteration 593, loss = 0.01751858
Iteration 594, loss = 0.01748727
Iteration 595, loss = 0.01745831
Iteration 596, loss = 0.01742434
Iteration 597, loss = 0.01739413
Iteration 598, loss = 0.01736417
Iteration 599, loss = 0.01733121
Iteration 600, loss = 0.01729865
Iteration 601, loss = 0.01726958
Iteration 602, loss = 0.01723837
Iteration 603, loss = 0.01720527
Iteration 604, loss = 0.01717424
Iteration 605, loss = 0.01714486
Iteration 606, loss = 0.01711229
Iteration 607, loss = 0.01708218
Iteration 608, loss = 0.01705083
Iteration 609, loss = 0.01702263
Iteration 610, loss = 0.01699120
Iteration 611, loss = 0.01695992
Iteration 612, loss = 0.01693077
Iteration 613, loss = 0.01690197
Iteration 614, loss = 0.01686854
Iteration 615, loss = 0.01684227
Iteration 616, loss = 0.01681052
Iteration 617, loss = 0.01678012
Iteration 618, loss = 0.01674931
Iteration 619, loss = 0.01671939
Iteration 620, loss = 0.01668852
Iteration 621, loss = 0.01666139
Iteration 622, loss = 0.01663030
Iteration 623, loss = 0.01660329
Iteration 624, loss = 0.01657410
Iteration 625, loss = 0.01654497
Iteration 626, loss = 0.01651699
Iteration 627, loss = 0.01648729
Iteration 628, loss = 0.01646009
Iteration 629, loss = 0.01643024
Iteration 630, loss = 0.01640097
Iteration 631, loss = 0.01637167
Iteration 632, loss = 0.01634456
Iteration 633, loss = 0.01631195
Iteration 634, loss = 0.01628316
Iteration 635, loss = 0.01625721
Iteration 636, loss = 0.01622543
Iteration 637, loss = 0.01619735
Iteration 638, loss = 0.01617116
Iteration 639, loss = 0.01614210
Iteration 640, loss = 0.01611345
Iteration 641, loss = 0.01608580
Iteration 642, loss = 0.01605801
Iteration 643, loss = 0.01602950
Iteration 644, loss = 0.01600354
Iteration 645, loss = 0.01597674
Iteration 646, loss = 0.01594932
Iteration 647, loss = 0.01592178
Iteration 648, loss = 0.01589315
Iteration 649, loss = 0.01586652
Iteration 650, loss = 0.01583877
Iteration 651, loss = 0.01581262
Iteration 652, loss = 0.01578694
Iteration 653, loss = 0.01576161
Iteration 654, loss = 0.01573023
Iteration 655, loss = 0.01570433
Iteration 656, loss = 0.01567717
Iteration 657, loss = 0.01565040
Iteration 658, loss = 0.01562226
Iteration 659, loss = 0.01559702
Iteration 660, loss = 0.01557104
Iteration 661, loss = 0.01554200
Iteration 662, loss = 0.01551516
Iteration 663, loss = 0.01548992
Iteration 664, loss = 0.01546133
Iteration 665, loss = 0.01543707
Iteration 666, loss = 0.01540976
Iteration 667, loss = 0.01538570
Iteration 668, loss = 0.01535985
Iteration 669, loss = 0.01533222
Iteration 670, loss = 0.01530739
Iteration 671, loss = 0.01528007
Iteration 672, loss = 0.01525462
Iteration 673, loss = 0.01522887
Iteration 674, loss = 0.01520386
Iteration 675, loss = 0.01517804
Iteration 676, loss = 0.01515329
Iteration 677, loss = 0.01512611
Iteration 678, loss = 0.01510208
Iteration 679, loss = 0.01507806
Iteration 680, loss = 0.01505464
Iteration 681, loss = 0.01502899
Iteration 682, loss = 0.01500480
Iteration 683, loss = 0.01497864
Iteration 684, loss = 0.01495387
Iteration 685, loss = 0.01492939
Iteration 686, loss = 0.01490458
Iteration 687, loss = 0.01488052
Iteration 688, loss = 0.01485956
Iteration 689, loss = 0.01483118
Iteration 690, loss = 0.01480749
Iteration 691, loss = 0.01478175
Iteration 692, loss = 0.01475882
Iteration 693, loss = 0.01473623
Iteration 694, loss = 0.01471082
Iteration 695, loss = 0.01468760
Iteration 696, loss = 0.01466429
Iteration 697, loss = 0.01463982
Iteration 698, loss = 0.01461328
Iteration 699, loss = 0.01458854
Iteration 700, loss = 0.01456517
Iteration 701, loss = 0.01454229
Iteration 702, loss = 0.01451752
Iteration 703, loss = 0.01449820
Iteration 704, loss = 0.01447287
Iteration 705, loss = 0.01444632
Iteration 706, loss = 0.01442533
Iteration 707, loss = 0.01439892
Iteration 708, loss = 0.01437543
Iteration 709, loss = 0.01435134
Iteration 710, loss = 0.01432780
Iteration 711, loss = 0.01430442
Iteration 712, loss = 0.01428422
Iteration 713, loss = 0.01425807
Iteration 714, loss = 0.01423515
Iteration 715, loss = 0.01421247
Iteration 716, loss = 0.01418877
Iteration 717, loss = 0.01416404
Iteration 718, loss = 0.01414503
Iteration 719, loss = 0.01412004
Iteration 720, loss = 0.01409679
Iteration 721, loss = 0.01407506
Iteration 722, loss = 0.01405529
Iteration 723, loss = 0.01402947
Iteration 724, loss = 0.01400703
Iteration 725, loss = 0.01398613
Iteration 726, loss = 0.01396285
Iteration 727, loss = 0.01394115
Iteration 728, loss = 0.01391975
Iteration 729, loss = 0.01389623
Iteration 730, loss = 0.01387614
Iteration 731, loss = 0.01385566
Iteration 732, loss = 0.01383468
Iteration 733, loss = 0.01380983
Iteration 734, loss = 0.01378964
Iteration 735, loss = 0.01376605
Iteration 736, loss = 0.01374643
Iteration 737, loss = 0.01372207
Iteration 738, loss = 0.01370039
Iteration 739, loss = 0.01367876
Iteration 740, loss = 0.01365916
Iteration 741, loss = 0.01363544
Iteration 742, loss = 0.01361512
Iteration 743, loss = 0.01359079
Iteration 744, loss = 0.01357247
Iteration 745, loss = 0.01354885
Iteration 746, loss = 0.01352703
Iteration 747, loss = 0.01350602
Iteration 748, loss = 0.01348531
Iteration 749, loss = 0.01346421
Iteration 750, loss = 0.01344317
Iteration 751, loss = 0.01342191
Iteration 752, loss = 0.01339863
Iteration 753, loss = 0.01337974
Iteration 754, loss = 0.01335865
Iteration 755, loss = 0.01333797
Iteration 756, loss = 0.01331596
Iteration 757, loss = 0.01329480
Iteration 758, loss = 0.01327532
Iteration 759, loss = 0.01325540
Iteration 760, loss = 0.01323595
Iteration 761, loss = 0.01321497
Iteration 762, loss = 0.01319441
Iteration 763, loss = 0.01317384
Iteration 764, loss = 0.01315458
Iteration 765, loss = 0.01313402
Iteration 766, loss = 0.01311253
Iteration 767, loss = 0.01309444
Iteration 768, loss = 0.01307296
Iteration 769, loss = 0.01305290
Iteration 770, loss = 0.01303363
Iteration 771, loss = 0.01301368
Iteration 772, loss = 0.01299605
Iteration 773, loss = 0.01297456
Iteration 774, loss = 0.01295658
Iteration 775, loss = 0.01293456
Iteration 776, loss = 0.01291551
Iteration 777, loss = 0.01289509
Iteration 778, loss = 0.01287550
Iteration 779, loss = 0.01285695
Iteration 780, loss = 0.01283688
Iteration 781, loss = 0.01281723
Iteration 782, loss = 0.01279683
Iteration 783, loss = 0.01277941
Iteration 784, loss = 0.01275880
Iteration 785, loss = 0.01273747
Iteration 786, loss = 0.01271964
Iteration 787, loss = 0.01269907
Iteration 788, loss = 0.01267944
Iteration 789, loss = 0.01266000
Iteration 790, loss = 0.01264274
Iteration 791, loss = 0.01262378
Iteration 792, loss = 0.01260185
Iteration 793, loss = 0.01258401
Iteration 794, loss = 0.01256597
Iteration 795, loss = 0.01254452
Iteration 796, loss = 0.01252558
Iteration 797, loss = 0.01251147
Iteration 798, loss = 0.01248660
Iteration 799, loss = 0.01246858
Iteration 800, loss = 0.01244879
Iteration 801, loss = 0.01243131
Iteration 802, loss = 0.01241337
Iteration 803, loss = 0.01239353
Iteration 804, loss = 0.01237527
Iteration 805, loss = 0.01235588
Iteration 806, loss = 0.01233859
Iteration 807, loss = 0.01232026
Iteration 808, loss = 0.01230247
Iteration 809, loss = 0.01228254
Iteration 810, loss = 0.01226561
Iteration 811, loss = 0.01224681
Iteration 812, loss = 0.01222709
Iteration 813, loss = 0.01220834
Iteration 814, loss = 0.01219005
Iteration 815, loss = 0.01217365
Iteration 816, loss = 0.01215432
Iteration 817, loss = 0.01213687
Iteration 818, loss = 0.01212102
Iteration 819, loss = 0.01210201
Iteration 820, loss = 0.01208252
Iteration 821, loss = 0.01206462
Iteration 822, loss = 0.01204643
Iteration 823, loss = 0.01202861
Iteration 824, loss = 0.01201228
Iteration 825, loss = 0.01199393
Iteration 826, loss = 0.01197706
Iteration 827, loss = 0.01195997
Iteration 828, loss = 0.01194296
Iteration 829, loss = 0.01192521
Iteration 830, loss = 0.01190763
Iteration 831, loss = 0.01188891
Iteration 832, loss = 0.01187188
Iteration 833, loss = 0.01185340
Iteration 834, loss = 0.01183852
Iteration 835, loss = 0.01182019
Iteration 836, loss = 0.01180310
Iteration 837, loss = 0.01178716
Iteration 838, loss = 0.01176767
Iteration 839, loss = 0.01175148
Iteration 840, loss = 0.01173402
Iteration 841, loss = 0.01171731
Iteration 842, loss = 0.01169920
Iteration 843, loss = 0.01168309
Iteration 844, loss = 0.01166709
Iteration 845, loss = 0.01164918
Iteration 846, loss = 0.01163261
Iteration 847, loss = 0.01161716
Iteration 848, loss = 0.01160041
Iteration 849, loss = 0.01158401
Iteration 850, loss = 0.01156899
Iteration 851, loss = 0.01155027
Iteration 852, loss = 0.01153354
Iteration 853, loss = 0.01152006
Iteration 854, loss = 0.01150046
Iteration 855, loss = 0.01148492
Iteration 856, loss = 0.01146729
Iteration 857, loss = 0.01145094
Iteration 858, loss = 0.01143427
Iteration 859, loss = 0.01141891
Iteration 860, loss = 0.01140181
Iteration 861, loss = 0.01138655
Iteration 862, loss = 0.01137042
Iteration 863, loss = 0.01135512
Iteration 864, loss = 0.01133880
Iteration 865, loss = 0.01132327
Iteration 866, loss = 0.01130722
Iteration 867, loss = 0.01129266
Iteration 868, loss = 0.01127582
Iteration 869, loss = 0.01125958
Iteration 870, loss = 0.01124374
Iteration 871, loss = 0.01122876
Iteration 872, loss = 0.01121267
Iteration 873, loss = 0.01119623
Iteration 874, loss = 0.01118026
Iteration 875, loss = 0.01116548
Iteration 876, loss = 0.01114772
Iteration 877, loss = 0.01113357
Iteration 878, loss = 0.01111710
Iteration 879, loss = 0.01110136
Iteration 880, loss = 0.01108546
Iteration 881, loss = 0.01106938
Iteration 882, loss = 0.01105404
Iteration 883, loss = 0.01103946
Iteration 884, loss = 0.01102424
Iteration 885, loss = 0.01100624
Iteration 886, loss = 0.01099227
Iteration 887, loss = 0.01097600
Iteration 888, loss = 0.01095971
Iteration 889, loss = 0.01094605
Iteration 890, loss = 0.01092985
Iteration 891, loss = 0.01091609
Iteration 892, loss = 0.01089828
Iteration 893, loss = 0.01088419
Iteration 894, loss = 0.01086808
Iteration 895, loss = 0.01085441
Iteration 896, loss = 0.01083869
Iteration 897, loss = 0.01082742
Iteration 898, loss = 0.01081021
Iteration 899, loss = 0.01079145
Iteration 900, loss = 0.01077719
Iteration 901, loss = 0.01076244
Iteration 902, loss = 0.01074727
Iteration 903, loss = 0.01073429
Iteration 904, loss = 0.01071811
Iteration 905, loss = 0.01070468
Iteration 906, loss = 0.01069110
Iteration 907, loss = 0.01067713
Iteration 908, loss = 0.01066029
Iteration 909, loss = 0.01064490
Iteration 910, loss = 0.01063090
Iteration 911, loss = 0.01061697
Iteration 912, loss = 0.01060024
Iteration 913, loss = 0.01058720
Iteration 914, loss = 0.01057165
Iteration 915, loss = 0.01055633
Iteration 916, loss = 0.01054332
Iteration 917, loss = 0.01052675
Iteration 918, loss = 0.01051340
Iteration 919, loss = 0.01049923
Iteration 920, loss = 0.01048576
Iteration 921, loss = 0.01046993
Iteration 922, loss = 0.01045526
Iteration 923, loss = 0.01044206
Iteration 924, loss = 0.01042735
Iteration 925, loss = 0.01041306
Iteration 926, loss = 0.01039832
Iteration 927, loss = 0.01038421
Iteration 928, loss = 0.01037095
Iteration 929, loss = 0.01035600
Iteration 930, loss = 0.01034218
Iteration 931, loss = 0.01033052
Iteration 932, loss = 0.01031491
Iteration 933, loss = 0.01030148
Iteration 934, loss = 0.01028853
Iteration 935, loss = 0.01027430
Iteration 936, loss = 0.01025981
Iteration 937, loss = 0.01024670
Iteration 938, loss = 0.01023424
Iteration 939, loss = 0.01021899
Iteration 940, loss = 0.01020503
Iteration 941, loss = 0.01019219
Iteration 942, loss = 0.01017684
Iteration 943, loss = 0.01016425
Iteration 944, loss = 0.01015125
Iteration 945, loss = 0.01013787
Iteration 946, loss = 0.01012512
Iteration 947, loss = 0.01011067
Iteration 948, loss = 0.01009759
Iteration 949, loss = 0.01008358
Iteration 950, loss = 0.01006995
Iteration 951, loss = 0.01005762
Iteration 952, loss = 0.01004360
Iteration 953, loss = 0.01003079
Iteration 954, loss = 0.01001939
Iteration 955, loss = 0.01000319
Iteration 956, loss = 0.00999071
Iteration 957, loss = 0.00997854
Iteration 958, loss = 0.00996397
Iteration 959, loss = 0.00994990
Iteration 960, loss = 0.00993795
Iteration 961, loss = 0.00992223
Iteration 962, loss = 0.00990823
Iteration 963, loss = 0.00989599
Iteration 964, loss = 0.00988288
Iteration 965, loss = 0.00986919
Iteration 966, loss = 0.00985739
Iteration 967, loss = 0.00984456
Iteration 968, loss = 0.00983043
Iteration 969, loss = 0.00982026
Iteration 970, loss = 0.00980461
Iteration 971, loss = 0.00979106
Iteration 972, loss = 0.00977725
Iteration 973, loss = 0.00976442
Iteration 974, loss = 0.00975143
Iteration 975, loss = 0.00973852
Iteration 976, loss = 0.00972452
Iteration 977, loss = 0.00971246
Iteration 978, loss = 0.00969875
Iteration 979, loss = 0.00968524
Iteration 980, loss = 0.00967277
Iteration 981, loss = 0.00966009
Iteration 982, loss = 0.00964682
Iteration 983, loss = 0.00963419
Iteration 984, loss = 0.00962291
Iteration 985, loss = 0.00960851
Iteration 986, loss = 0.00959576
Iteration 987, loss = 0.00958348
Iteration 988, loss = 0.00957011
Iteration 989, loss = 0.00955756
Iteration 990, loss = 0.00954586
Iteration 991, loss = 0.00953264
Iteration 992, loss = 0.00951990
Iteration 993, loss = 0.00950688
Iteration 994, loss = 0.00949515
Iteration 995, loss = 0.00948236
Iteration 996, loss = 0.00947194
Iteration 997, loss = 0.00945656
Iteration 998, loss = 0.00944444
Iteration 999, loss = 0.00943159
Iteration 1000, loss = 0.00941938
Iteration 1001, loss = 0.00940684
Iteration 1002, loss = 0.00939565
Iteration 1003, loss = 0.00938275
Iteration 1004, loss = 0.00936938
Iteration 1005, loss = 0.00935684
Iteration 1006, loss = 0.00934449
Iteration 1007, loss = 0.00933232
Iteration 1008, loss = 0.00931933
Iteration 1009, loss = 0.00930685
Iteration 1010, loss = 0.00929688
Iteration 1011, loss = 0.00928169
Iteration 1012, loss = 0.00926959
Iteration 1013, loss = 0.00925851
Iteration 1014, loss = 0.00924635
Iteration 1015, loss = 0.00923368
Iteration 1016, loss = 0.00922008
Iteration 1017, loss = 0.00920843
Iteration 1018, loss = 0.00919620
Iteration 1019, loss = 0.00918476
Iteration 1020, loss = 0.00917194
Iteration 1021, loss = 0.00916159
Iteration 1022, loss = 0.00914870
Iteration 1023, loss = 0.00913813
Iteration 1024, loss = 0.00912483
Iteration 1025, loss = 0.00911369
Iteration 1026, loss = 0.00910150
Iteration 1027, loss = 0.00909101
Iteration 1028, loss = 0.00907898
Iteration 1029, loss = 0.00906788
Iteration 1030, loss = 0.00905671
Iteration 1031, loss = 0.00904542
Iteration 1032, loss = 0.00903270
Iteration 1033, loss = 0.00902153
Iteration 1034, loss = 0.00901042
Iteration 1035, loss = 0.00899831
Iteration 1036, loss = 0.00898697
Iteration 1037, loss = 0.00897446
Iteration 1038, loss = 0.00896410
Iteration 1039, loss = 0.00895298
Iteration 1040, loss = 0.00893981
Iteration 1041, loss = 0.00892919
Iteration 1042, loss = 0.00891751
Iteration 1043, loss = 0.00890515
Iteration 1044, loss = 0.00889374
Iteration 1045, loss = 0.00888264
Iteration 1046, loss = 0.00887118
Iteration 1047, loss = 0.00885946
Iteration 1048, loss = 0.00884788
Iteration 1049, loss = 0.00883802
Iteration 1050, loss = 0.00882612
Iteration 1051, loss = 0.00881532
Iteration 1052, loss = 0.00880394
Iteration 1053, loss = 0.00879326
Iteration 1054, loss = 0.00878198
Iteration 1055, loss = 0.00877177
Iteration 1056, loss = 0.00876227
Iteration 1057, loss = 0.00874942
Iteration 1058, loss = 0.00873823
Iteration 1059, loss = 0.00872624
Iteration 1060, loss = 0.00871575
Iteration 1061, loss = 0.00870453
Iteration 1062, loss = 0.00869407
Iteration 1063, loss = 0.00868274
Iteration 1064, loss = 0.00867285
Iteration 1065, loss = 0.00866130
Iteration 1066, loss = 0.00865100
Iteration 1067, loss = 0.00864025
Iteration 1068, loss = 0.00863028
Iteration 1069, loss = 0.00861950
Iteration 1070, loss = 0.00860898
Iteration 1071, loss = 0.00859741
Iteration 1072, loss = 0.00858985
Iteration 1073, loss = 0.00857677
Iteration 1074, loss = 0.00856511
Iteration 1075, loss = 0.00855438
Iteration 1076, loss = 0.00854569
Iteration 1077, loss = 0.00853412
Iteration 1078, loss = 0.00852391
Iteration 1079, loss = 0.00851207
Iteration 1080, loss = 0.00850090
Iteration 1081, loss = 0.00849143
Iteration 1082, loss = 0.00848061
Iteration 1083, loss = 0.00847094
Iteration 1084, loss = 0.00845987
Iteration 1085, loss = 0.00844865
Iteration 1086, loss = 0.00843898
Iteration 1087, loss = 0.00842867
Iteration 1088, loss = 0.00841726
Iteration 1089, loss = 0.00840729
Iteration 1090, loss = 0.00839670
Iteration 1091, loss = 0.00838600
Iteration 1092, loss = 0.00837630
Iteration 1093, loss = 0.00836575
Iteration 1094, loss = 0.00835526
Iteration 1095, loss = 0.00834570
Iteration 1096, loss = 0.00833597
Iteration 1097, loss = 0.00832550
Iteration 1098, loss = 0.00831643
Iteration 1099, loss = 0.00830580
Iteration 1100, loss = 0.00829507
Iteration 1101, loss = 0.00828544
Iteration 1102, loss = 0.00827512
Iteration 1103, loss = 0.00826499
Iteration 1104, loss = 0.00825397
Iteration 1105, loss = 0.00824384
Iteration 1106, loss = 0.00823478
Iteration 1107, loss = 0.00822237
Iteration 1108, loss = 0.00821295
Iteration 1109, loss = 0.00820224
Iteration 1110, loss = 0.00819225
Iteration 1111, loss = 0.00818256
Iteration 1112, loss = 0.00817304
Iteration 1113, loss = 0.00816183
Iteration 1114, loss = 0.00815232
Iteration 1115, loss = 0.00814226
Iteration 1116, loss = 0.00813231
Iteration 1117, loss = 0.00812201
Iteration 1118, loss = 0.00811225
Iteration 1119, loss = 0.00810168
Iteration 1120, loss = 0.00809255
Iteration 1121, loss = 0.00808235
Iteration 1122, loss = 0.00807332
Iteration 1123, loss = 0.00806372
Iteration 1124, loss = 0.00805375
Iteration 1125, loss = 0.00804597
Iteration 1126, loss = 0.00803500
Iteration 1127, loss = 0.00802409
Iteration 1128, loss = 0.00801534
Iteration 1129, loss = 0.00800672
Iteration 1130, loss = 0.00799550
Iteration 1131, loss = 0.00798627
Iteration 1132, loss = 0.00797773
Iteration 1133, loss = 0.00796721
Iteration 1134, loss = 0.00795763
Iteration 1135, loss = 0.00794846
Iteration 1136, loss = 0.00794020
Iteration 1137, loss = 0.00793093
Iteration 1138, loss = 0.00791993
Iteration 1139, loss = 0.00791131
Iteration 1140, loss = 0.00790067
Iteration 1141, loss = 0.00789180
Iteration 1142, loss = 0.00788189
Iteration 1143, loss = 0.00787288
Iteration 1144, loss = 0.00786309
Iteration 1145, loss = 0.00785338
Iteration 1146, loss = 0.00784472
Iteration 1147, loss = 0.00783608
Iteration 1148, loss = 0.00782631
Iteration 1149, loss = 0.00781754
Iteration 1150, loss = 0.00780702
Iteration 1151, loss = 0.00779780
Iteration 1152, loss = 0.00778913
Iteration 1153, loss = 0.00778073
Iteration 1154, loss = 0.00777062
Iteration 1155, loss = 0.00776114
Iteration 1156, loss = 0.00775104
Iteration 1157, loss = 0.00774176
Iteration 1158, loss = 0.00773322
Iteration 1159, loss = 0.00772364
Iteration 1160, loss = 0.00771461
Iteration 1161, loss = 0.00770533
Iteration 1162, loss = 0.00769680
Iteration 1163, loss = 0.00768760
Iteration 1164, loss = 0.00767855
Iteration 1165, loss = 0.00766883
Iteration 1166, loss = 0.00766055
Iteration 1167, loss = 0.00765100
Iteration 1168, loss = 0.00764173
Iteration 1169, loss = 0.00763298
Iteration 1170, loss = 0.00762472
Iteration 1171, loss = 0.00761460
Iteration 1172, loss = 0.00760638
Iteration 1173, loss = 0.00759738
Iteration 1174, loss = 0.00758892
Iteration 1175, loss = 0.00757905
Iteration 1176, loss = 0.00757159
Iteration 1177, loss = 0.00756249
Iteration 1178, loss = 0.00755315
Iteration 1179, loss = 0.00754454
Iteration 1180, loss = 0.00753645
Iteration 1181, loss = 0.00752607
Iteration 1182, loss = 0.00751756
Iteration 1183, loss = 0.00750877
Iteration 1184, loss = 0.00750019
Iteration 1185, loss = 0.00749152
Iteration 1186, loss = 0.00748479
Iteration 1187, loss = 0.00747314
Iteration 1188, loss = 0.00746783
Iteration 1189, loss = 0.00745719
Iteration 1190, loss = 0.00744859
Iteration 1191, loss = 0.00743920
Iteration 1192, loss = 0.00743161
Iteration 1193, loss = 0.00742264
Iteration 1194, loss = 0.00741411
Iteration 1195, loss = 0.00740540
Iteration 1196, loss = 0.00739731
Iteration 1197, loss = 0.00738750
Iteration 1198, loss = 0.00737993
Iteration 1199, loss = 0.00737064
Iteration 1200, loss = 0.00736294
Iteration 1201, loss = 0.00735381
Iteration 1202, loss = 0.00734567
Iteration 1203, loss = 0.00733773
Iteration 1204, loss = 0.00732710
Iteration 1205, loss = 0.00732008
Iteration 1206, loss = 0.00731213
Iteration 1207, loss = 0.00730206
Iteration 1208, loss = 0.00729446
Iteration 1209, loss = 0.00728540
Iteration 1210, loss = 0.00727755
Iteration 1211, loss = 0.00726954
Iteration 1212, loss = 0.00726017
Iteration 1213, loss = 0.00725268
Iteration 1214, loss = 0.00724548
Iteration 1215, loss = 0.00723663
Iteration 1216, loss = 0.00722869
Iteration 1217, loss = 0.00722059
Iteration 1218, loss = 0.00721216
Iteration 1219, loss = 0.00720480
Iteration 1220, loss = 0.00719600
Iteration 1221, loss = 0.00718850
Iteration 1222, loss = 0.00717979
Iteration 1223, loss = 0.00717191
Iteration 1224, loss = 0.00716334
Iteration 1225, loss = 0.00715566
Iteration 1226, loss = 0.00714736
Iteration 1227, loss = 0.00713993
Iteration 1228, loss = 0.00713200
Iteration 1229, loss = 0.00712412
Iteration 1230, loss = 0.00711566
Iteration 1231, loss = 0.00710787
Iteration 1232, loss = 0.00710083
Iteration 1233, loss = 0.00709206
Iteration 1234, loss = 0.00708507
Iteration 1235, loss = 0.00707759
Iteration 1236, loss = 0.00706905
Iteration 1237, loss = 0.00706163
Iteration 1238, loss = 0.00705278
Iteration 1239, loss = 0.00704482
Iteration 1240, loss = 0.00703753
Iteration 1241, loss = 0.00702957
Iteration 1242, loss = 0.00702152
Iteration 1243, loss = 0.00701388
Iteration 1244, loss = 0.00700680
Iteration 1245, loss = 0.00699875
Iteration 1246, loss = 0.00699173
Iteration 1247, loss = 0.00698312
Iteration 1248, loss = 0.00697504
Iteration 1249, loss = 0.00696842
Iteration 1250, loss = 0.00695938
Iteration 1251, loss = 0.00695167
Iteration 1252, loss = 0.00694503
Iteration 1253, loss = 0.00693659
Iteration 1254, loss = 0.00692957
Iteration 1255, loss = 0.00692094
Iteration 1256, loss = 0.00691305
Iteration 1257, loss = 0.00690595
Iteration 1258, loss = 0.00689832
Iteration 1259, loss = 0.00689112
Iteration 1260, loss = 0.00688330
Iteration 1261, loss = 0.00687756
Iteration 1262, loss = 0.00686796
Iteration 1263, loss = 0.00686145
Iteration 1264, loss = 0.00685443
Iteration 1265, loss = 0.00684661
Iteration 1266, loss = 0.00683858
Iteration 1267, loss = 0.00683208
Iteration 1268, loss = 0.00682468
Iteration 1269, loss = 0.00681661
Iteration 1270, loss = 0.00680929
Iteration 1271, loss = 0.00680149
Iteration 1272, loss = 0.00679341
Iteration 1273, loss = 0.00678622
Iteration 1274, loss = 0.00677854
Iteration 1275, loss = 0.00677357
Iteration 1276, loss = 0.00676377
Iteration 1277, loss = 0.00675591
Iteration 1278, loss = 0.00674906
Iteration 1279, loss = 0.00674204
Iteration 1280, loss = 0.00673405
Iteration 1281, loss = 0.00672649
Iteration 1282, loss = 0.00672045
Iteration 1283, loss = 0.00671206
Iteration 1284, loss = 0.00670529
Iteration 1285, loss = 0.00669845
Iteration 1286, loss = 0.00669099
Iteration 1287, loss = 0.00668342
Iteration 1288, loss = 0.00667742
Iteration 1289, loss = 0.00667044
Iteration 1290, loss = 0.00666239
Iteration 1291, loss = 0.00665489
Iteration 1292, loss = 0.00664811
Iteration 1293, loss = 0.00664004
Iteration 1294, loss = 0.00663309
Iteration 1295, loss = 0.00662696
Iteration 1296, loss = 0.00661874
Iteration 1297, loss = 0.00661343
Iteration 1298, loss = 0.00660475
Iteration 1299, loss = 0.00659870
Iteration 1300, loss = 0.00659054
Iteration 1301, loss = 0.00658407
Iteration 1302, loss = 0.00657651
Iteration 1303, loss = 0.00656963
Iteration 1304, loss = 0.00656319
Iteration 1305, loss = 0.00655526
Iteration 1306, loss = 0.00654930
Iteration 1307, loss = 0.00654094
Iteration 1308, loss = 0.00653391
Iteration 1309, loss = 0.00652705
Iteration 1310, loss = 0.00652040
Iteration 1311, loss = 0.00651297
Iteration 1312, loss = 0.00650560
Iteration 1313, loss = 0.00649912
Iteration 1314, loss = 0.00649265
Iteration 1315, loss = 0.00648556
Iteration 1316, loss = 0.00647924
Iteration 1317, loss = 0.00647255
Iteration 1318, loss = 0.00646488
Iteration 1319, loss = 0.00645832
Iteration 1320, loss = 0.00645139
Iteration 1321, loss = 0.00644479
Iteration 1322, loss = 0.00643720
Iteration 1323, loss = 0.00643101
Iteration 1324, loss = 0.00642397
Iteration 1325, loss = 0.00641655
Iteration 1326, loss = 0.00641045
Iteration 1327, loss = 0.00640309
Iteration 1328, loss = 0.00639641
Iteration 1329, loss = 0.00638980
Iteration 1330, loss = 0.00638271
Iteration 1331, loss = 0.00637562
Iteration 1332, loss = 0.00636921
Iteration 1333, loss = 0.00636205
Iteration 1334, loss = 0.00635589
Iteration 1335, loss = 0.00634934
Iteration 1336, loss = 0.00634234
Iteration 1337, loss = 0.00633588
Iteration 1338, loss = 0.00632877
Iteration 1339, loss = 0.00632301
Iteration 1340, loss = 0.00631623
Iteration 1341, loss = 0.00630895
Iteration 1342, loss = 0.00630252
Iteration 1343, loss = 0.00629663
Iteration 1344, loss = 0.00628980
Iteration 1345, loss = 0.00628429
Iteration 1346, loss = 0.00627589
Iteration 1347, loss = 0.00626975
Iteration 1348, loss = 0.00626445
Iteration 1349, loss = 0.00625694
Iteration 1350, loss = 0.00625016
Iteration 1351, loss = 0.00624395
Iteration 1352, loss = 0.00623759
Iteration 1353, loss = 0.00623133
Iteration 1354, loss = 0.00622424
Iteration 1355, loss = 0.00621864
Iteration 1356, loss = 0.00621162
Iteration 1357, loss = 0.00620527
Iteration 1358, loss = 0.00619842
Iteration 1359, loss = 0.00619179
Iteration 1360, loss = 0.00618501
Iteration 1361, loss = 0.00617914
Iteration 1362, loss = 0.00617178
Iteration 1363, loss = 0.00616580
Iteration 1364, loss = 0.00615909
Iteration 1365, loss = 0.00615311
Iteration 1366, loss = 0.00614660
Iteration 1367, loss = 0.00614009
Iteration 1368, loss = 0.00613397
Iteration 1369, loss = 0.00612738
Iteration 1370, loss = 0.00612138
Iteration 1371, loss = 0.00611619
Iteration 1372, loss = 0.00610945
Iteration 1373, loss = 0.00610321
Iteration 1374, loss = 0.00609692
Iteration 1375, loss = 0.00609103
Iteration 1376, loss = 0.00608443
Iteration 1377, loss = 0.00607827
Iteration 1378, loss = 0.00607298
Iteration 1379, loss = 0.00606716
Iteration 1380, loss = 0.00605998
Iteration 1381, loss = 0.00605413
Iteration 1382, loss = 0.00604817
Iteration 1383, loss = 0.00604165
Iteration 1384, loss = 0.00603505
Iteration 1385, loss = 0.00602911
Iteration 1386, loss = 0.00602344
Iteration 1387, loss = 0.00601679
Iteration 1388, loss = 0.00601072
Iteration 1389, loss = 0.00600435
Iteration 1390, loss = 0.00599918
Iteration 1391, loss = 0.00599284
Iteration 1392, loss = 0.00598714
Iteration 1393, loss = 0.00598115
Iteration 1394, loss = 0.00597500
Iteration 1395, loss = 0.00596903
Iteration 1396, loss = 0.00596267
Iteration 1397, loss = 0.00595680
Iteration 1398, loss = 0.00595021
Iteration 1399, loss = 0.00594577
Iteration 1400, loss = 0.00593956
Iteration 1401, loss = 0.00593365
Iteration 1402, loss = 0.00592789
Iteration 1403, loss = 0.00592205
Iteration 1404, loss = 0.00591623
Iteration 1405, loss = 0.00591022
Iteration 1406, loss = 0.00590474
Iteration 1407, loss = 0.00589913
Iteration 1408, loss = 0.00589387
Iteration 1409, loss = 0.00588741
Iteration 1410, loss = 0.00588122
Iteration 1411, loss = 0.00587566
Iteration 1412, loss = 0.00586993
Iteration 1413, loss = 0.00586458
Iteration 1414, loss = 0.00585843
Iteration 1415, loss = 0.00585370
Iteration 1416, loss = 0.00584683
Iteration 1417, loss = 0.00584140
Iteration 1418, loss = 0.00583568
Iteration 1419, loss = 0.00582957
Iteration 1420, loss = 0.00582431
Iteration 1421, loss = 0.00581864
Iteration 1422, loss = 0.00581320
Iteration 1423, loss = 0.00580811
Iteration 1424, loss = 0.00580204
Iteration 1425, loss = 0.00579641
Iteration 1426, loss = 0.00579123
Iteration 1427, loss = 0.00578539
Iteration 1428, loss = 0.00578030
Iteration 1429, loss = 0.00577473
Iteration 1430, loss = 0.00576904
Iteration 1431, loss = 0.00576378
Iteration 1432, loss = 0.00575723
Iteration 1433, loss = 0.00575163
Iteration 1434, loss = 0.00574579
Iteration 1435, loss = 0.00574050
Iteration 1436, loss = 0.00573590
Iteration 1437, loss = 0.00572922
Iteration 1438, loss = 0.00572375
Iteration 1439, loss = 0.00571840
Iteration 1440, loss = 0.00571297
Iteration 1441, loss = 0.00570762
Iteration 1442, loss = 0.00570202
Iteration 1443, loss = 0.00569697
Iteration 1444, loss = 0.00569210
Iteration 1445, loss = 0.00568633
Iteration 1446, loss = 0.00568137
Iteration 1447, loss = 0.00567600
Iteration 1448, loss = 0.00567077
Iteration 1449, loss = 0.00566550
Iteration 1450, loss = 0.00566022
Iteration 1451, loss = 0.00565532
Iteration 1452, loss = 0.00564980
Iteration 1453, loss = 0.00564568
Iteration 1454, loss = 0.00563999
Iteration 1455, loss = 0.00563386
Iteration 1456, loss = 0.00562860
Iteration 1457, loss = 0.00562346
Iteration 1458, loss = 0.00561776
Iteration 1459, loss = 0.00561266
Iteration 1460, loss = 0.00560708
Iteration 1461, loss = 0.00560257
Iteration 1462, loss = 0.00559622
Iteration 1463, loss = 0.00559113
Iteration 1464, loss = 0.00558570
Iteration 1465, loss = 0.00557992
Iteration 1466, loss = 0.00557479
Iteration 1467, loss = 0.00557032
Iteration 1468, loss = 0.00556432
Iteration 1469, loss = 0.00555897
Iteration 1470, loss = 0.00555375
Iteration 1471, loss = 0.00554849
Iteration 1472, loss = 0.00554328
Iteration 1473, loss = 0.00553819
Iteration 1474, loss = 0.00553304
Iteration 1475, loss = 0.00552756
Iteration 1476, loss = 0.00552434
Iteration 1477, loss = 0.00551758
Iteration 1478, loss = 0.00551235
Iteration 1479, loss = 0.00550672
Iteration 1480, loss = 0.00550213
Iteration 1481, loss = 0.00549674
Iteration 1482, loss = 0.00549267
Iteration 1483, loss = 0.00548697
Iteration 1484, loss = 0.00548141
Iteration 1485, loss = 0.00547638
Iteration 1486, loss = 0.00547179
Iteration 1487, loss = 0.00546692
Iteration 1488, loss = 0.00546180
Iteration 1489, loss = 0.00545643
Iteration 1490, loss = 0.00545157
Iteration 1491, loss = 0.00544659
Iteration 1492, loss = 0.00544136
Iteration 1493, loss = 0.00543659
Iteration 1494, loss = 0.00543156
Iteration 1495, loss = 0.00542646
Iteration 1496, loss = 0.00542145
Iteration 1497, loss = 0.00541655
Iteration 1498, loss = 0.00541122
Iteration 1499, loss = 0.00540613
Iteration 1500, loss = 0.00540151
Iteration 1501, loss = 0.00539579
Iteration 1502, loss = 0.00539103
Iteration 1503, loss = 0.00538602
Iteration 1504, loss = 0.00538141
Iteration 1505, loss = 0.00537660
Iteration 1506, loss = 0.00537166
Iteration 1507, loss = 0.00536608
Iteration 1508, loss = 0.00536153
Iteration 1509, loss = 0.00535630
Iteration 1510, loss = 0.00535163
Iteration 1511, loss = 0.00534637
Iteration 1512, loss = 0.00534163
Iteration 1513, loss = 0.00533700
Iteration 1514, loss = 0.00533271
Iteration 1515, loss = 0.00532778
Iteration 1516, loss = 0.00532246
Iteration 1517, loss = 0.00531779
Iteration 1518, loss = 0.00531397
Iteration 1519, loss = 0.00530837
Iteration 1520, loss = 0.00530417
Iteration 1521, loss = 0.00529916
Iteration 1522, loss = 0.00529435
Iteration 1523, loss = 0.00528967
Iteration 1524, loss = 0.00528488
Iteration 1525, loss = 0.00527983
Iteration 1526, loss = 0.00527508
Iteration 1527, loss = 0.00527055
Iteration 1528, loss = 0.00526663
Iteration 1529, loss = 0.00526143
Iteration 1530, loss = 0.00525602
Iteration 1531, loss = 0.00525163
Iteration 1532, loss = 0.00524760
Iteration 1533, loss = 0.00524223
Iteration 1534, loss = 0.00523713
Iteration 1535, loss = 0.00523264
Iteration 1536, loss = 0.00522786
Iteration 1537, loss = 0.00522296
Iteration 1538, loss = 0.00521873
Iteration 1539, loss = 0.00521357
Iteration 1540, loss = 0.00520894
Iteration 1541, loss = 0.00520427
Iteration 1542, loss = 0.00519972
Iteration 1543, loss = 0.00519523
Iteration 1544, loss = 0.00519008
Iteration 1545, loss = 0.00518531
Iteration 1546, loss = 0.00518086
Iteration 1547, loss = 0.00517589
Iteration 1548, loss = 0.00517123
Iteration 1549, loss = 0.00516697
Iteration 1550, loss = 0.00516257
Iteration 1551, loss = 0.00515795
Iteration 1552, loss = 0.00515303
Iteration 1553, loss = 0.00514894
Iteration 1554, loss = 0.00514408
Iteration 1555, loss = 0.00513963
Iteration 1556, loss = 0.00513566
Iteration 1557, loss = 0.00513077
Iteration 1558, loss = 0.00512671
Iteration 1559, loss = 0.00512159
Iteration 1560, loss = 0.00511727
Iteration 1561, loss = 0.00511322
Iteration 1562, loss = 0.00510816
Iteration 1563, loss = 0.00510303
Iteration 1564, loss = 0.00509898
Iteration 1565, loss = 0.00509416
Iteration 1566, loss = 0.00508982
Iteration 1567, loss = 0.00508516
Iteration 1568, loss = 0.00508053
Iteration 1569, loss = 0.00507617
Iteration 1570, loss = 0.00507124
Iteration 1571, loss = 0.00506662
Iteration 1572, loss = 0.00506276
Iteration 1573, loss = 0.00505793
Iteration 1574, loss = 0.00505317
Iteration 1575, loss = 0.00504895
Iteration 1576, loss = 0.00504449
Iteration 1577, loss = 0.00504063
Iteration 1578, loss = 0.00503570
Iteration 1579, loss = 0.00503066
Iteration 1580, loss = 0.00502786
Iteration 1581, loss = 0.00502258
Iteration 1582, loss = 0.00501735
Iteration 1583, loss = 0.00501366
Iteration 1584, loss = 0.00500851
Iteration 1585, loss = 0.00500474
Iteration 1586, loss = 0.00500046
Iteration 1587, loss = 0.00499572
Iteration 1588, loss = 0.00499163
Iteration 1589, loss = 0.00498755
Iteration 1590, loss = 0.00498299
Iteration 1591, loss = 0.00497815
Iteration 1592, loss = 0.00497371
Iteration 1593, loss = 0.00497008
Iteration 1594, loss = 0.00496557
Iteration 1595, loss = 0.00496126
Iteration 1596, loss = 0.00495671
Iteration 1597, loss = 0.00495250
Iteration 1598, loss = 0.00494796
Iteration 1599, loss = 0.00494429
Iteration 1600, loss = 0.00493995
Iteration 1601, loss = 0.00493528
Iteration 1602, loss = 0.00493086
Iteration 1603, loss = 0.00492679
Iteration 1604, loss = 0.00492265
Iteration 1605, loss = 0.00491839
Iteration 1606, loss = 0.00491400
Iteration 1607, loss = 0.00490976
Iteration 1608, loss = 0.00490570
Iteration 1609, loss = 0.00490167
Iteration 1610, loss = 0.00489707
Iteration 1611, loss = 0.00489300
Iteration 1612, loss = 0.00488905
Iteration 1613, loss = 0.00488481
Iteration 1614, loss = 0.00488096
Iteration 1615, loss = 0.00487671
Iteration 1616, loss = 0.00487215
Iteration 1617, loss = 0.00486853
Iteration 1618, loss = 0.00486380
Iteration 1619, loss = 0.00486006
Iteration 1620, loss = 0.00485555
Iteration 1621, loss = 0.00485132
Iteration 1622, loss = 0.00484753
Iteration 1623, loss = 0.00484329
Iteration 1624, loss = 0.00483892
Iteration 1625, loss = 0.00483492
Iteration 1626, loss = 0.00483086
Iteration 1627, loss = 0.00482717
Iteration 1628, loss = 0.00482298
Iteration 1629, loss = 0.00481898
Iteration 1630, loss = 0.00481486
Iteration 1631, loss = 0.00481096
Iteration 1632, loss = 0.00480681
Iteration 1633, loss = 0.00480266
Iteration 1634, loss = 0.00479943
Iteration 1635, loss = 0.00479481
Iteration 1636, loss = 0.00479096
Iteration 1637, loss = 0.00478771
Iteration 1638, loss = 0.00478327
Iteration 1639, loss = 0.00477848
Iteration 1640, loss = 0.00477442
Iteration 1641, loss = 0.00477021
Iteration 1642, loss = 0.00476623
Iteration 1643, loss = 0.00476264
Iteration 1644, loss = 0.00475864
Iteration 1645, loss = 0.00475389
Iteration 1646, loss = 0.00475031
Iteration 1647, loss = 0.00474604
Iteration 1648, loss = 0.00474275
Iteration 1649, loss = 0.00473785
Iteration 1650, loss = 0.00473421
Iteration 1651, loss = 0.00473043
Iteration 1652, loss = 0.00472668
Iteration 1653, loss = 0.00472204
Iteration 1654, loss = 0.00471793
Iteration 1655, loss = 0.00471416
Iteration 1656, loss = 0.00471031
Iteration 1657, loss = 0.00470688
Iteration 1658, loss = 0.00470250
Iteration 1659, loss = 0.00469837
Iteration 1660, loss = 0.00469453
Iteration 1661, loss = 0.00469062
Iteration 1662, loss = 0.00468686
Iteration 1663, loss = 0.00468276
Iteration 1664, loss = 0.00467897
Iteration 1665, loss = 0.00467480
Iteration 1666, loss = 0.00467092
Iteration 1667, loss = 0.00466714
Iteration 1668, loss = 0.00466324
Iteration 1669, loss = 0.00465932
Iteration 1670, loss = 0.00465538
Iteration 1671, loss = 0.00465162
Iteration 1672, loss = 0.00464796
Iteration 1673, loss = 0.00464416
Iteration 1674, loss = 0.00464001
Iteration 1675, loss = 0.00463629
Iteration 1676, loss = 0.00463277
Iteration 1677, loss = 0.00462894
Iteration 1678, loss = 0.00462474
Iteration 1679, loss = 0.00462118
Iteration 1680, loss = 0.00461748
Iteration 1681, loss = 0.00461324
Iteration 1682, loss = 0.00460991
Iteration 1683, loss = 0.00460639
Iteration 1684, loss = 0.00460245
Iteration 1685, loss = 0.00459816
Iteration 1686, loss = 0.00459451
Iteration 1687, loss = 0.00459105
Iteration 1688, loss = 0.00458702
Iteration 1689, loss = 0.00458354
Iteration 1690, loss = 0.00457979
Iteration 1691, loss = 0.00457593
Iteration 1692, loss = 0.00457208
Iteration 1693, loss = 0.00456836
Iteration 1694, loss = 0.00456488
Iteration 1695, loss = 0.00456138
Iteration 1696, loss = 0.00455789
Iteration 1697, loss = 0.00455357
Iteration 1698, loss = 0.00454965
Iteration 1699, loss = 0.00454593
Iteration 1700, loss = 0.00454276
Iteration 1701, loss = 0.00453882
Iteration 1702, loss = 0.00453536
Iteration 1703, loss = 0.00453146
Iteration 1704, loss = 0.00452786
Iteration 1705, loss = 0.00452418
Iteration 1706, loss = 0.00452048
Iteration 1707, loss = 0.00451685
Iteration 1708, loss = 0.00451307
Iteration 1709, loss = 0.00450979
Iteration 1710, loss = 0.00450610
Iteration 1711, loss = 0.00450244
Iteration 1712, loss = 0.00449870
Iteration 1713, loss = 0.00449501
Iteration 1714, loss = 0.00449173
Iteration 1715, loss = 0.00448771
Iteration 1716, loss = 0.00448406
Iteration 1717, loss = 0.00448069
Iteration 1718, loss = 0.00447685
Iteration 1719, loss = 0.00447339
Iteration 1720, loss = 0.00446952
Iteration 1721, loss = 0.00446611
Iteration 1722, loss = 0.00446256
Iteration 1723, loss = 0.00445890
Iteration 1724, loss = 0.00445513
Iteration 1725, loss = 0.00445220
Iteration 1726, loss = 0.00444825
Iteration 1727, loss = 0.00444455
Iteration 1728, loss = 0.00444125
Iteration 1729, loss = 0.00443736
Iteration 1730, loss = 0.00443450
Iteration 1731, loss = 0.00443009
Iteration 1732, loss = 0.00442657
Iteration 1733, loss = 0.00442347
Iteration 1734, loss = 0.00441923
Iteration 1735, loss = 0.00441607
Iteration 1736, loss = 0.00441261
Iteration 1737, loss = 0.00440923
Iteration 1738, loss = 0.00440583
Iteration 1739, loss = 0.00440201
Iteration 1740, loss = 0.00439877
Iteration 1741, loss = 0.00439530
Iteration 1742, loss = 0.00439170
Iteration 1743, loss = 0.00438811
Iteration 1744, loss = 0.00438467
Iteration 1745, loss = 0.00438106
Iteration 1746, loss = 0.00437786
Iteration 1747, loss = 0.00437461
Iteration 1748, loss = 0.00437121
Iteration 1749, loss = 0.00436739
Iteration 1750, loss = 0.00436412
Iteration 1751, loss = 0.00436055
Iteration 1752, loss = 0.00435746
Iteration 1753, loss = 0.00435396
Iteration 1754, loss = 0.00435039
Iteration 1755, loss = 0.00434710
Iteration 1756, loss = 0.00434320
Iteration 1757, loss = 0.00433999
Iteration 1758, loss = 0.00433669
Iteration 1759, loss = 0.00433443
Iteration 1760, loss = 0.00433011
Iteration 1761, loss = 0.00432648
Iteration 1762, loss = 0.00432370
Iteration 1763, loss = 0.00431978
Iteration 1764, loss = 0.00431650
Iteration 1765, loss = 0.00431304
Iteration 1766, loss = 0.00430980
Iteration 1767, loss = 0.00430677
Iteration 1768, loss = 0.00430366
Iteration 1769, loss = 0.00429995
Iteration 1770, loss = 0.00429679
Iteration 1771, loss = 0.00429358
Iteration 1772, loss = 0.00429037
Iteration 1773, loss = 0.00428672
Iteration 1774, loss = 0.00428392
Iteration 1775, loss = 0.00428009
Iteration 1776, loss = 0.00427690
Iteration 1777, loss = 0.00427344
Iteration 1778, loss = 0.00427019
Iteration 1779, loss = 0.00426678
Iteration 1780, loss = 0.00426361
Iteration 1781, loss = 0.00426022
Iteration 1782, loss = 0.00425691
Iteration 1783, loss = 0.00425367
Iteration 1784, loss = 0.00425025
Iteration 1785, loss = 0.00424691
Iteration 1786, loss = 0.00424346
Iteration 1787, loss = 0.00424029
Iteration 1788, loss = 0.00423694
Iteration 1789, loss = 0.00423368
Iteration 1790, loss = 0.00423014
Iteration 1791, loss = 0.00422666
Iteration 1792, loss = 0.00422322
Iteration 1793, loss = 0.00422008
Iteration 1794, loss = 0.00421672
Iteration 1795, loss = 0.00421357
Iteration 1796, loss = 0.00421057
Iteration 1797, loss = 0.00420703
Iteration 1798, loss = 0.00420352
Iteration 1799, loss = 0.00420048
Iteration 1800, loss = 0.00419769
Iteration 1801, loss = 0.00419472
Iteration 1802, loss = 0.00419086
Iteration 1803, loss = 0.00418766
Iteration 1804, loss = 0.00418484
Iteration 1805, loss = 0.00418160
Iteration 1806, loss = 0.00417858
Iteration 1807, loss = 0.00417503
Iteration 1808, loss = 0.00417187
Iteration 1809, loss = 0.00416970
Iteration 1810, loss = 0.00416565
Iteration 1811, loss = 0.00416241
Iteration 1812, loss = 0.00415962
Iteration 1813, loss = 0.00415628
Iteration 1814, loss = 0.00415320
Iteration 1815, loss = 0.00415010
Iteration 1816, loss = 0.00414694
Iteration 1817, loss = 0.00414397
Iteration 1818, loss = 0.00414070
Iteration 1819, loss = 0.00413752
Iteration 1820, loss = 0.00413448
Iteration 1821, loss = 0.00413183
Iteration 1822, loss = 0.00412836
Iteration 1823, loss = 0.00412518
Iteration 1824, loss = 0.00412218
Iteration 1825, loss = 0.00411870
Iteration 1826, loss = 0.00411579
Iteration 1827, loss = 0.00411262
Iteration 1828, loss = 0.00410958
Iteration 1829, loss = 0.00410673
Iteration 1830, loss = 0.00410347
Iteration 1831, loss = 0.00410071
Iteration 1832, loss = 0.00409719
Iteration 1833, loss = 0.00409408
Iteration 1834, loss = 0.00409121
Iteration 1835, loss = 0.00408796
Iteration 1836, loss = 0.00408482
Iteration 1837, loss = 0.00408194
Iteration 1838, loss = 0.00407864
Iteration 1839, loss = 0.00407581
Iteration 1840, loss = 0.00407245
Iteration 1841, loss = 0.00406983
Iteration 1842, loss = 0.00406628
Iteration 1843, loss = 0.00406366
Iteration 1844, loss = 0.00406050
Iteration 1845, loss = 0.00405753
Iteration 1846, loss = 0.00405429
Iteration 1847, loss = 0.00405142
Iteration 1848, loss = 0.00404890
Iteration 1849, loss = 0.00404528
Iteration 1850, loss = 0.00404284
Iteration 1851, loss = 0.00403978
Iteration 1852, loss = 0.00403654
Iteration 1853, loss = 0.00403347
Iteration 1854, loss = 0.00403069
Iteration 1855, loss = 0.00402772
Iteration 1856, loss = 0.00402475
Iteration 1857, loss = 0.00402204
Iteration 1858, loss = 0.00401884
Iteration 1859, loss = 0.00401602
Iteration 1860, loss = 0.00401313
Iteration 1861, loss = 0.00400996
Iteration 1862, loss = 0.00400724
Iteration 1863, loss = 0.00400466
Iteration 1864, loss = 0.00400119
Iteration 1865, loss = 0.00399832
Iteration 1866, loss = 0.00399572
Iteration 1867, loss = 0.00399236
Iteration 1868, loss = 0.00398942
Iteration 1869, loss = 0.00398682
Iteration 1870, loss = 0.00398342
Iteration 1871, loss = 0.00398080
Iteration 1872, loss = 0.00397852
Iteration 1873, loss = 0.00397493
Iteration 1874, loss = 0.00397227
Iteration 1875, loss = 0.00396891
Iteration 1876, loss = 0.00396609
Iteration 1877, loss = 0.00396362
Iteration 1878, loss = 0.00396019
Iteration 1879, loss = 0.00395762
Iteration 1880, loss = 0.00395452
Iteration 1881, loss = 0.00395205
Iteration 1882, loss = 0.00394907
Iteration 1883, loss = 0.00394607
Iteration 1884, loss = 0.00394344
Iteration 1885, loss = 0.00394036
Iteration 1886, loss = 0.00393736
Iteration 1887, loss = 0.00393460
Iteration 1888, loss = 0.00393178
Iteration 1889, loss = 0.00392897
Iteration 1890, loss = 0.00392565
Iteration 1891, loss = 0.00392335
Iteration 1892, loss = 0.00392025
Iteration 1893, loss = 0.00391782
Iteration 1894, loss = 0.00391447
Iteration 1895, loss = 0.00391165
Iteration 1896, loss = 0.00390885
Iteration 1897, loss = 0.00390630
Iteration 1898, loss = 0.00390312
Iteration 1899, loss = 0.00390024
Iteration 1900, loss = 0.00389765
Iteration 1901, loss = 0.00389498
Iteration 1902, loss = 0.00389172
Iteration 1903, loss = 0.00388898
Iteration 1904, loss = 0.00388618
Iteration 1905, loss = 0.00388348
Iteration 1906, loss = 0.00388075
Iteration 1907, loss = 0.00387811
Iteration 1908, loss = 0.00387549
Iteration 1909, loss = 0.00387245
Iteration 1910, loss = 0.00386984
Iteration 1911, loss = 0.00386730
Iteration 1912, loss = 0.00386425
Iteration 1913, loss = 0.00386119
Iteration 1914, loss = 0.00385846
Iteration 1915, loss = 0.00385568
Iteration 1916, loss = 0.00385303
Iteration 1917, loss = 0.00384998
Iteration 1918, loss = 0.00384750
Iteration 1919, loss = 0.00384459
Iteration 1920, loss = 0.00384218
Iteration 1921, loss = 0.00383894
Iteration 1922, loss = 0.00383619
Iteration 1923, loss = 0.00383359
Iteration 1924, loss = 0.00383080
Iteration 1925, loss = 0.00382819
Iteration 1926, loss = 0.00382574
Iteration 1927, loss = 0.00382258
Iteration 1928, loss = 0.00381966
Iteration 1929, loss = 0.00381700
Iteration 1930, loss = 0.00381421
Iteration 1931, loss = 0.00381183
Iteration 1932, loss = 0.00380891
Iteration 1933, loss = 0.00380626
Iteration 1934, loss = 0.00380354
Iteration 1935, loss = 0.00380091
Iteration 1936, loss = 0.00379825
Iteration 1937, loss = 0.00379579
Iteration 1938, loss = 0.00379292
Iteration 1939, loss = 0.00379048
Iteration 1940, loss = 0.00378758
Iteration 1941, loss = 0.00378493
Iteration 1942, loss = 0.00378214
Iteration 1943, loss = 0.00377985
Iteration 1944, loss = 0.00377676
Iteration 1945, loss = 0.00377414
Iteration 1946, loss = 0.00377114
Iteration 1947, loss = 0.00376869
Iteration 1948, loss = 0.00376593
Iteration 1949, loss = 0.00376374
Iteration 1950, loss = 0.00376085
Iteration 1951, loss = 0.00375814
Iteration 1952, loss = 0.00375555
Iteration 1953, loss = 0.00375286
Iteration 1954, loss = 0.00375026
Iteration 1955, loss = 0.00374764
Iteration 1956, loss = 0.00374533
Iteration 1957, loss = 0.00374252
Iteration 1958, loss = 0.00373992
Iteration 1959, loss = 0.00373733
Iteration 1960, loss = 0.00373462
Iteration 1961, loss = 0.00373199
Iteration 1962, loss = 0.00372929
Iteration 1963, loss = 0.00372692
Iteration 1964, loss = 0.00372422
Iteration 1965, loss = 0.00372156
Iteration 1966, loss = 0.00371908
Iteration 1967, loss = 0.00371657
Iteration 1968, loss = 0.00371405
Iteration 1969, loss = 0.00371170
Iteration 1970, loss = 0.00370938
Iteration 1971, loss = 0.00370671
Iteration 1972, loss = 0.00370388
Iteration 1973, loss = 0.00370187
Iteration 1974, loss = 0.00369902
Iteration 1975, loss = 0.00369630
Iteration 1976, loss = 0.00369354
Iteration 1977, loss = 0.00369109
Iteration 1978, loss = 0.00368853
Iteration 1979, loss = 0.00368592
Iteration 1980, loss = 0.00368307
Iteration 1981, loss = 0.00368052
Iteration 1982, loss = 0.00367823
Iteration 1983, loss = 0.00367562
Iteration 1984, loss = 0.00367307
Iteration 1985, loss = 0.00367088
Iteration 1986, loss = 0.00366789
Iteration 1987, loss = 0.00366538
Iteration 1988, loss = 0.00366265
Iteration 1989, loss = 0.00366014
Iteration 1990, loss = 0.00365785
Iteration 1991, loss = 0.00365529
Iteration 1992, loss = 0.00365258
Iteration 1993, loss = 0.00365009
Iteration 1994, loss = 0.00364750
Iteration 1995, loss = 0.00364538
Iteration 1996, loss = 0.00364269
Iteration 1997, loss = 0.00364016
Iteration 1998, loss = 0.00363758
Iteration 1999, loss = 0.00363517
Iteration 2000, loss = 0.00363303
Iteration 2001, loss = 0.00363060
Iteration 2002, loss = 0.00362794
Iteration 2003, loss = 0.00362555
Iteration 2004, loss = 0.00362256
Iteration 2005, loss = 0.00362031
Iteration 2006, loss = 0.00361806
Iteration 2007, loss = 0.00361501
Iteration 2008, loss = 0.00361275
Iteration 2009, loss = 0.00361006
Iteration 2010, loss = 0.00360746
Iteration 2011, loss = 0.00360520
Iteration 2012, loss = 0.00360276
Iteration 2013, loss = 0.00360010
Iteration 2014, loss = 0.00359807
Iteration 2015, loss = 0.00359508
Iteration 2016, loss = 0.00359234
Iteration 2017, loss = 0.00359017
Iteration 2018, loss = 0.00358771
Iteration 2019, loss = 0.00358524
Iteration 2020, loss = 0.00358296
Iteration 2021, loss = 0.00358018
Iteration 2022, loss = 0.00357787
Iteration 2023, loss = 0.00357524
Iteration 2024, loss = 0.00357298
Iteration 2025, loss = 0.00357058
Iteration 2026, loss = 0.00356838
Iteration 2027, loss = 0.00356551
Iteration 2028, loss = 0.00356326
Iteration 2029, loss = 0.00356056
Iteration 2030, loss = 0.00355859
Iteration 2031, loss = 0.00355578
Iteration 2032, loss = 0.00355354
Iteration 2033, loss = 0.00355117
Iteration 2034, loss = 0.00354869
Iteration 2035, loss = 0.00354676
Iteration 2036, loss = 0.00354408
Iteration 2037, loss = 0.00354252
Iteration 2038, loss = 0.00353919
Iteration 2039, loss = 0.00353677
Iteration 2040, loss = 0.00353486
Iteration 2041, loss = 0.00353250
Iteration 2042, loss = 0.00352992
Iteration 2043, loss = 0.00352766
Iteration 2044, loss = 0.00352540
Iteration 2045, loss = 0.00352281
Iteration 2046, loss = 0.00352024
Iteration 2047, loss = 0.00351782
Iteration 2048, loss = 0.00351554
Iteration 2049, loss = 0.00351303
Iteration 2050, loss = 0.00351072
Iteration 2051, loss = 0.00350852
Iteration 2052, loss = 0.00350584
Iteration 2053, loss = 0.00350381
Iteration 2054, loss = 0.00350133
Iteration 2055, loss = 0.00349876
Iteration 2056, loss = 0.00349678
Iteration 2057, loss = 0.00349427
Iteration 2058, loss = 0.00349186
Iteration 2059, loss = 0.00348959
Iteration 2060, loss = 0.00348734
Iteration 2061, loss = 0.00348483
Iteration 2062, loss = 0.00348247
Iteration 2063, loss = 0.00348052
Iteration 2064, loss = 0.00347806
Iteration 2065, loss = 0.00347565
Iteration 2066, loss = 0.00347351
Iteration 2067, loss = 0.00347097
Iteration 2068, loss = 0.00346859
Iteration 2069, loss = 0.00346619
Iteration 2070, loss = 0.00346413
Iteration 2071, loss = 0.00346196
Iteration 2072, loss = 0.00345958
Iteration 2073, loss = 0.00345732
Iteration 2074, loss = 0.00345508
Iteration 2075, loss = 0.00345305
Iteration 2076, loss = 0.00345069
Iteration 2077, loss = 0.00344821
Iteration 2078, loss = 0.00344585
Iteration 2079, loss = 0.00344394
Iteration 2080, loss = 0.00344150
Iteration 2081, loss = 0.00343911
Iteration 2082, loss = 0.00343683
Iteration 2083, loss = 0.00343481
Iteration 2084, loss = 0.00343254
Iteration 2085, loss = 0.00343002
Iteration 2086, loss = 0.00342779
Iteration 2087, loss = 0.00342546
Iteration 2088, loss = 0.00342347
Iteration 2089, loss = 0.00342100
Iteration 2090, loss = 0.00341865
Iteration 2091, loss = 0.00341669
Iteration 2092, loss = 0.00341437
Iteration 2093, loss = 0.00341173
Iteration 2094, loss = 0.00340963
Iteration 2095, loss = 0.00340756
Iteration 2096, loss = 0.00340516
Iteration 2097, loss = 0.00340305
Iteration 2098, loss = 0.00340078
Iteration 2099, loss = 0.00339841
Iteration 2100, loss = 0.00339639
Iteration 2101, loss = 0.00339415
Iteration 2102, loss = 0.00339193
Iteration 2103, loss = 0.00338969
Iteration 2104, loss = 0.00338737
Iteration 2105, loss = 0.00338515
Iteration 2106, loss = 0.00338290
Iteration 2107, loss = 0.00338083
Iteration 2108, loss = 0.00337872
Iteration 2109, loss = 0.00337641
Iteration 2110, loss = 0.00337437
Iteration 2111, loss = 0.00337221
Iteration 2112, loss = 0.00337010
Iteration 2113, loss = 0.00336779
Iteration 2114, loss = 0.00336587
Iteration 2115, loss = 0.00336367
Iteration 2116, loss = 0.00336151
Iteration 2117, loss = 0.00335891
Iteration 2118, loss = 0.00335728
Iteration 2119, loss = 0.00335492
Iteration 2120, loss = 0.00335239
Iteration 2121, loss = 0.00335037
Iteration 2122, loss = 0.00334821
Iteration 2123, loss = 0.00334612
Iteration 2124, loss = 0.00334397
Iteration 2125, loss = 0.00334165
Iteration 2126, loss = 0.00333941
Iteration 2127, loss = 0.00333728
Iteration 2128, loss = 0.00333515
Iteration 2129, loss = 0.00333322
Iteration 2130, loss = 0.00333084
Iteration 2131, loss = 0.00332920
Iteration 2132, loss = 0.00332650
Iteration 2133, loss = 0.00332442
Iteration 2134, loss = 0.00332233
Iteration 2135, loss = 0.00332021
Iteration 2136, loss = 0.00331791
Iteration 2137, loss = 0.00331610
Iteration 2138, loss = 0.00331361
Iteration 2139, loss = 0.00331130
Iteration 2140, loss = 0.00330910
Iteration 2141, loss = 0.00330700
Iteration 2142, loss = 0.00330471
Iteration 2143, loss = 0.00330263
Iteration 2144, loss = 0.00330105
Iteration 2145, loss = 0.00329837
Iteration 2146, loss = 0.00329601
Iteration 2147, loss = 0.00329437
Iteration 2148, loss = 0.00329197
Iteration 2149, loss = 0.00329025
Iteration 2150, loss = 0.00328774
Iteration 2151, loss = 0.00328571
Iteration 2152, loss = 0.00328362
Iteration 2153, loss = 0.00328168
Iteration 2154, loss = 0.00327951
Iteration 2155, loss = 0.00327735
Iteration 2156, loss = 0.00327542
Iteration 2157, loss = 0.00327297
Iteration 2158, loss = 0.00327093
Iteration 2159, loss = 0.00326895
Iteration 2160, loss = 0.00326688
Iteration 2161, loss = 0.00326486
Iteration 2162, loss = 0.00326286
Iteration 2163, loss = 0.00326071
Iteration 2164, loss = 0.00325867
Iteration 2165, loss = 0.00325667
Iteration 2166, loss = 0.00325477
Iteration 2167, loss = 0.00325253
Iteration 2168, loss = 0.00325045
Iteration 2169, loss = 0.00324853
Iteration 2170, loss = 0.00324665
Iteration 2171, loss = 0.00324453
Iteration 2172, loss = 0.00324245
Iteration 2173, loss = 0.00324040
Iteration 2174, loss = 0.00323846
Iteration 2175, loss = 0.00323607
Iteration 2176, loss = 0.00323434
Iteration 2177, loss = 0.00323232
Iteration 2178, loss = 0.00323033
Iteration 2179, loss = 0.00322824
Iteration 2180, loss = 0.00322610
Iteration 2181, loss = 0.00322408
Iteration 2182, loss = 0.00322236
Iteration 2183, loss = 0.00322004
Iteration 2184, loss = 0.00321819
Iteration 2185, loss = 0.00321614
Iteration 2186, loss = 0.00321422
Iteration 2187, loss = 0.00321200
Iteration 2188, loss = 0.00321000
Iteration 2189, loss = 0.00320804
Iteration 2190, loss = 0.00320604
Iteration 2191, loss = 0.00320394
Iteration 2192, loss = 0.00320232
Iteration 2193, loss = 0.00320014
Iteration 2194, loss = 0.00319784
Iteration 2195, loss = 0.00319603
Iteration 2196, loss = 0.00319396
Iteration 2197, loss = 0.00319211
Iteration 2198, loss = 0.00318998
Iteration 2199, loss = 0.00318820
Iteration 2200, loss = 0.00318643
Iteration 2201, loss = 0.00318408
Iteration 2202, loss = 0.00318232
Iteration 2203, loss = 0.00318006
Iteration 2204, loss = 0.00317791
Iteration 2205, loss = 0.00317584
Iteration 2206, loss = 0.00317398
Iteration 2207, loss = 0.00317197
Iteration 2208, loss = 0.00316978
Iteration 2209, loss = 0.00316817
Iteration 2210, loss = 0.00316599
Iteration 2211, loss = 0.00316371
Iteration 2212, loss = 0.00316179
Iteration 2213, loss = 0.00315986
Iteration 2214, loss = 0.00315807
Iteration 2215, loss = 0.00315611
Iteration 2216, loss = 0.00315400
Iteration 2217, loss = 0.00315184
Iteration 2218, loss = 0.00314998
Iteration 2219, loss = 0.00314805
Iteration 2220, loss = 0.00314597
Iteration 2221, loss = 0.00314398
Iteration 2222, loss = 0.00314217
Iteration 2223, loss = 0.00314001
Iteration 2224, loss = 0.00313811
Iteration 2225, loss = 0.00313625
Iteration 2226, loss = 0.00313404
Iteration 2227, loss = 0.00313245
Iteration 2228, loss = 0.00313029
Iteration 2229, loss = 0.00312868
Iteration 2230, loss = 0.00312604
Iteration 2231, loss = 0.00312416
Iteration 2232, loss = 0.00312241
Iteration 2233, loss = 0.00312037
Iteration 2234, loss = 0.00311830
Iteration 2235, loss = 0.00311637
Iteration 2236, loss = 0.00311442
Iteration 2237, loss = 0.00311286
Iteration 2238, loss = 0.00311061
Iteration 2239, loss = 0.00310873
Iteration 2240, loss = 0.00310674
Iteration 2241, loss = 0.00310470
Iteration 2242, loss = 0.00310268
Iteration 2243, loss = 0.00310101
Iteration 2244, loss = 0.00309896
Iteration 2245, loss = 0.00309717
Iteration 2246, loss = 0.00309526
Iteration 2247, loss = 0.00309317
Iteration 2248, loss = 0.00309121
Iteration 2249, loss = 0.00308940
Iteration 2250, loss = 0.00308779
Iteration 2251, loss = 0.00308570
Iteration 2252, loss = 0.00308383
Iteration 2253, loss = 0.00308194
Iteration 2254, loss = 0.00308013
Iteration 2255, loss = 0.00307831
Iteration 2256, loss = 0.00307636
Iteration 2257, loss = 0.00307447
Iteration 2258, loss = 0.00307254
Iteration 2259, loss = 0.00307059
Iteration 2260, loss = 0.00306879
Iteration 2261, loss = 0.00306687
Iteration 2262, loss = 0.00306515
Iteration 2263, loss = 0.00306324
Iteration 2264, loss = 0.00306134
Iteration 2265, loss = 0.00305960
Iteration 2266, loss = 0.00305743
Iteration 2267, loss = 0.00305585
Iteration 2268, loss = 0.00305385
Iteration 2269, loss = 0.00305186
Iteration 2270, loss = 0.00305004
Iteration 2271, loss = 0.00304809
Iteration 2272, loss = 0.00304622
Iteration 2273, loss = 0.00304440
Iteration 2274, loss = 0.00304242
Iteration 2275, loss = 0.00304080
Iteration 2276, loss = 0.00303920
Iteration 2277, loss = 0.00303703
Iteration 2278, loss = 0.00303535
Iteration 2279, loss = 0.00303361
Iteration 2280, loss = 0.00303176
Iteration 2281, loss = 0.00302981
Iteration 2282, loss = 0.00302804
Iteration 2283, loss = 0.00302598
Iteration 2284, loss = 0.00302441
Iteration 2285, loss = 0.00302249
Iteration 2286, loss = 0.00302063
Iteration 2287, loss = 0.00301901
Iteration 2288, loss = 0.00301726
Iteration 2289, loss = 0.00301520
Iteration 2290, loss = 0.00301332
Iteration 2291, loss = 0.00301191
Iteration 2292, loss = 0.00300974
Iteration 2293, loss = 0.00300801
Iteration 2294, loss = 0.00300633
Iteration 2295, loss = 0.00300455
Iteration 2296, loss = 0.00300263
Iteration 2297, loss = 0.00300098
Iteration 2298, loss = 0.00299920
Iteration 2299, loss = 0.00299725
Iteration 2300, loss = 0.00299561
Iteration 2301, loss = 0.00299394
Iteration 2302, loss = 0.00299187
Iteration 2303, loss = 0.00299059
Iteration 2304, loss = 0.00298833
Iteration 2305, loss = 0.00298632
Iteration 2306, loss = 0.00298474
Iteration 2307, loss = 0.00298315
Iteration 2308, loss = 0.00298122
Iteration 2309, loss = 0.00297958
Iteration 2310, loss = 0.00297762
Iteration 2311, loss = 0.00297630
Iteration 2312, loss = 0.00297419
Iteration 2313, loss = 0.00297228
Iteration 2314, loss = 0.00297041
Iteration 2315, loss = 0.00296872
Iteration 2316, loss = 0.00296702
Iteration 2317, loss = 0.00296534
Iteration 2318, loss = 0.00296359
Iteration 2319, loss = 0.00296180
Iteration 2320, loss = 0.00296004
Iteration 2321, loss = 0.00295862
Iteration 2322, loss = 0.00295656
Iteration 2323, loss = 0.00295488
Iteration 2324, loss = 0.00295325
Iteration 2325, loss = 0.00295133
Iteration 2326, loss = 0.00294956
Iteration 2327, loss = 0.00294823
Iteration 2328, loss = 0.00294612
Iteration 2329, loss = 0.00294460
Iteration 2330, loss = 0.00294269
Iteration 2331, loss = 0.00294095
Iteration 2332, loss = 0.00293937
Iteration 2333, loss = 0.00293762
Iteration 2334, loss = 0.00293600
Iteration 2335, loss = 0.00293419
Iteration 2336, loss = 0.00293246
Iteration 2337, loss = 0.00293072
Iteration 2338, loss = 0.00292932
Iteration 2339, loss = 0.00292704
Iteration 2340, loss = 0.00292549
Iteration 2341, loss = 0.00292405
Iteration 2342, loss = 0.00292211
Iteration 2343, loss = 0.00292047
Iteration 2344, loss = 0.00291879
Iteration 2345, loss = 0.00291714
Iteration 2346, loss = 0.00291563
Iteration 2347, loss = 0.00291373
Iteration 2348, loss = 0.00291188
Iteration 2349, loss = 0.00291043
Iteration 2350, loss = 0.00290874
Iteration 2351, loss = 0.00290690
Iteration 2352, loss = 0.00290524
Iteration 2353, loss = 0.00290350
Iteration 2354, loss = 0.00290181
Iteration 2355, loss = 0.00290008
Iteration 2356, loss = 0.00289838
Iteration 2357, loss = 0.00289674
Iteration 2358, loss = 0.00289542
Iteration 2359, loss = 0.00289348
Iteration 2360, loss = 0.00289204
Iteration 2361, loss = 0.00289035
Iteration 2362, loss = 0.00288857
Iteration 2363, loss = 0.00288695
Iteration 2364, loss = 0.00288528
Iteration 2365, loss = 0.00288343
Iteration 2366, loss = 0.00288189
Iteration 2367, loss = 0.00288043
Iteration 2368, loss = 0.00287901
Iteration 2369, loss = 0.00287689
Iteration 2370, loss = 0.00287533
Iteration 2371, loss = 0.00287349
Iteration 2372, loss = 0.00287177
Iteration 2373, loss = 0.00287063
Iteration 2374, loss = 0.00286872
Iteration 2375, loss = 0.00286712
Iteration 2376, loss = 0.00286532
Iteration 2377, loss = 0.00286360
Iteration 2378, loss = 0.00286202
Iteration 2379, loss = 0.00286045
Iteration 2380, loss = 0.00285880
Iteration 2381, loss = 0.00285698
Iteration 2382, loss = 0.00285556
Iteration 2383, loss = 0.00285412
Iteration 2384, loss = 0.00285216
Iteration 2385, loss = 0.00285060
Iteration 2386, loss = 0.00284897
Iteration 2387, loss = 0.00284733
Iteration 2388, loss = 0.00284579
Iteration 2389, loss = 0.00284399
Iteration 2390, loss = 0.00284241
Iteration 2391, loss = 0.00284086
Iteration 2392, loss = 0.00283947
Iteration 2393, loss = 0.00283781
Iteration 2394, loss = 0.00283618
Iteration 2395, loss = 0.00283461
Iteration 2396, loss = 0.00283314
Iteration 2397, loss = 0.00283156
Iteration 2398, loss = 0.00283000
Iteration 2399, loss = 0.00282848
Iteration 2400, loss = 0.00282683
Iteration 2401, loss = 0.00282541
Iteration 2402, loss = 0.00282378
Iteration 2403, loss = 0.00282229
Iteration 2404, loss = 0.00282088
Iteration 2405, loss = 0.00281914
Iteration 2406, loss = 0.00281746
Iteration 2407, loss = 0.00281590
Iteration 2408, loss = 0.00281465
Iteration 2409, loss = 0.00281373
Iteration 2410, loss = 0.00281130
Iteration 2411, loss = 0.00280972
Iteration 2412, loss = 0.00280837
Iteration 2413, loss = 0.00280673
Iteration 2414, loss = 0.00280500
Iteration 2415, loss = 0.00280357
Iteration 2416, loss = 0.00280185
Iteration 2417, loss = 0.00280044
Iteration 2418, loss = 0.00279876
Iteration 2419, loss = 0.00279731
Iteration 2420, loss = 0.00279587
Iteration 2421, loss = 0.00279421
Iteration 2422, loss = 0.00279262
Iteration 2423, loss = 0.00279117
Iteration 2424, loss = 0.00278963
Iteration 2425, loss = 0.00278802
Iteration 2426, loss = 0.00278670
Iteration 2427, loss = 0.00278518
Iteration 2428, loss = 0.00278358
Iteration 2429, loss = 0.00278212
Iteration 2430, loss = 0.00278064
Iteration 2431, loss = 0.00277895
Iteration 2432, loss = 0.00277753
Iteration 2433, loss = 0.00277607
Iteration 2434, loss = 0.00277446
Iteration 2435, loss = 0.00277306
Iteration 2436, loss = 0.00277142
Iteration 2437, loss = 0.00277009
Iteration 2438, loss = 0.00276837
Iteration 2439, loss = 0.00276684
Iteration 2440, loss = 0.00276567
Iteration 2441, loss = 0.00276402
Iteration 2442, loss = 0.00276236
Iteration 2443, loss = 0.00276076
Iteration 2444, loss = 0.00275930
Iteration 2445, loss = 0.00275782
Iteration 2446, loss = 0.00275623
Iteration 2447, loss = 0.00275489
Iteration 2448, loss = 0.00275320
Iteration 2449, loss = 0.00275170
Iteration 2450, loss = 0.00275032
Iteration 2451, loss = 0.00274901
Iteration 2452, loss = 0.00274734
Iteration 2453, loss = 0.00274566
Iteration 2454, loss = 0.00274424
Iteration 2455, loss = 0.00274270
Iteration 2456, loss = 0.00274138
Iteration 2457, loss = 0.00274019
Iteration 2458, loss = 0.00273849
Iteration 2459, loss = 0.00273691
Iteration 2460, loss = 0.00273552
Iteration 2461, loss = 0.00273381
Iteration 2462, loss = 0.00273269
Iteration 2463, loss = 0.00273127
Iteration 2464, loss = 0.00272936
Iteration 2465, loss = 0.00272802
Iteration 2466, loss = 0.00272660
Iteration 2467, loss = 0.00272551
Iteration 2468, loss = 0.00272352
Iteration 2469, loss = 0.00272201
Iteration 2470, loss = 0.00272065
Iteration 2471, loss = 0.00271910
Iteration 2472, loss = 0.00271767
Iteration 2473, loss = 0.00271637
Iteration 2474, loss = 0.00271476
Iteration 2475, loss = 0.00271357
Iteration 2476, loss = 0.00271180
Iteration 2477, loss = 0.00271038
Iteration 2478, loss = 0.00270905
Iteration 2479, loss = 0.00270797
Iteration 2480, loss = 0.00270605
Iteration 2481, loss = 0.00270473
Iteration 2482, loss = 0.00270332
Iteration 2483, loss = 0.00270168
Iteration 2484, loss = 0.00270059
Iteration 2485, loss = 0.00269871
Iteration 2486, loss = 0.00269725
Iteration 2487, loss = 0.00269568
Iteration 2488, loss = 0.00269442
Iteration 2489, loss = 0.00269297
Iteration 2490, loss = 0.00269149
Iteration 2491, loss = 0.00269019
Iteration 2492, loss = 0.00268887
Iteration 2493, loss = 0.00268735
Iteration 2494, loss = 0.00268587
Iteration 2495, loss = 0.00268445
Iteration 2496, loss = 0.00268313
Iteration 2497, loss = 0.00268199
Iteration 2498, loss = 0.00268040
Iteration 2499, loss = 0.00267884
Iteration 2500, loss = 0.00267750
Iteration 2501, loss = 0.00267612
Iteration 2502, loss = 0.00267468
Iteration 2503, loss = 0.00267331
Iteration 2504, loss = 0.00267212
Iteration 2505, loss = 0.00267038
Iteration 2506, loss = 0.00266895
Iteration 2507, loss = 0.00266769
Iteration 2508, loss = 0.00266628
Iteration 2509, loss = 0.00266499
Iteration 2510, loss = 0.00266374
Iteration 2511, loss = 0.00266222
Iteration 2512, loss = 0.00266109
Iteration 2513, loss = 0.00265934
Iteration 2514, loss = 0.00265799
Iteration 2515, loss = 0.00265658
Iteration 2516, loss = 0.00265563
Iteration 2517, loss = 0.00265373
Iteration 2518, loss = 0.00265242
Iteration 2519, loss = 0.00265094
Iteration 2520, loss = 0.00264980
Iteration 2521, loss = 0.00264851
Iteration 2522, loss = 0.00264687
Iteration 2523, loss = 0.00264575
Iteration 2524, loss = 0.00264412
Iteration 2525, loss = 0.00264315
Iteration 2526, loss = 0.00264128
Iteration 2527, loss = 0.00263997
Iteration 2528, loss = 0.00263881
Iteration 2529, loss = 0.00263726
Iteration 2530, loss = 0.00263604
Iteration 2531, loss = 0.00263475
Iteration 2532, loss = 0.00263333
Iteration 2533, loss = 0.00263201
Iteration 2534, loss = 0.00263043
Iteration 2535, loss = 0.00262912
Iteration 2536, loss = 0.00262777
Iteration 2537, loss = 0.00262626
Iteration 2538, loss = 0.00262513
Iteration 2539, loss = 0.00262354
Iteration 2540, loss = 0.00262204
Iteration 2541, loss = 0.00262077
Iteration 2542, loss = 0.00261949
Iteration 2543, loss = 0.00261788
Iteration 2544, loss = 0.00261678
Iteration 2545, loss = 0.00261544
Iteration 2546, loss = 0.00261404
Iteration 2547, loss = 0.00261275
Iteration 2548, loss = 0.00261141
Iteration 2549, loss = 0.00261014
Iteration 2550, loss = 0.00260887
Iteration 2551, loss = 0.00260763
Iteration 2552, loss = 0.00260622
Iteration 2553, loss = 0.00260492
Iteration 2554, loss = 0.00260371
Iteration 2555, loss = 0.00260242
Iteration 2556, loss = 0.00260110
Iteration 2557, loss = 0.00259959
Iteration 2558, loss = 0.00259834
Iteration 2559, loss = 0.00259707
Iteration 2560, loss = 0.00259566
Iteration 2561, loss = 0.00259451
Iteration 2562, loss = 0.00259304
Iteration 2563, loss = 0.00259174
Iteration 2564, loss = 0.00259055
Iteration 2565, loss = 0.00258908
Iteration 2566, loss = 0.00258788
Iteration 2567, loss = 0.00258650
Iteration 2568, loss = 0.00258528
Iteration 2569, loss = 0.00258403
Iteration 2570, loss = 0.00258278
Iteration 2571, loss = 0.00258141
Iteration 2572, loss = 0.00258008
Iteration 2573, loss = 0.00257864
Iteration 2574, loss = 0.00257735
Iteration 2575, loss = 0.00257612
Iteration 2576, loss = 0.00257506
Iteration 2577, loss = 0.00257340
Iteration 2578, loss = 0.00257208
Iteration 2579, loss = 0.00257068
Iteration 2580, loss = 0.00256946
Iteration 2581, loss = 0.00256813
Iteration 2582, loss = 0.00256673
Iteration 2583, loss = 0.00256548
Iteration 2584, loss = 0.00256437
Iteration 2585, loss = 0.00256267
Iteration 2586, loss = 0.00256150
Iteration 2587, loss = 0.00256019
Iteration 2588, loss = 0.00255898
Iteration 2589, loss = 0.00255765
Iteration 2590, loss = 0.00255641
Iteration 2591, loss = 0.00255520
Iteration 2592, loss = 0.00255391
Iteration 2593, loss = 0.00255258
Iteration 2594, loss = 0.00255120
Iteration 2595, loss = 0.00254988
Iteration 2596, loss = 0.00254869
Iteration 2597, loss = 0.00254744
Iteration 2598, loss = 0.00254607
Iteration 2599, loss = 0.00254471
Iteration 2600, loss = 0.00254356
Iteration 2601, loss = 0.00254211
Iteration 2602, loss = 0.00254078
Iteration 2603, loss = 0.00253982
Iteration 2604, loss = 0.00253829
Iteration 2605, loss = 0.00253707
Iteration 2606, loss = 0.00253581
Iteration 2607, loss = 0.00253456
Iteration 2608, loss = 0.00253334
Iteration 2609, loss = 0.00253194
Iteration 2610, loss = 0.00253068
Iteration 2611, loss = 0.00252945
Iteration 2612, loss = 0.00252831
Iteration 2613, loss = 0.00252684
Iteration 2614, loss = 0.00252577
Iteration 2615, loss = 0.00252429
Iteration 2616, loss = 0.00252298
Iteration 2617, loss = 0.00252180
Iteration 2618, loss = 0.00252051
Iteration 2619, loss = 0.00251909
Iteration 2620, loss = 0.00251806
Iteration 2621, loss = 0.00251662
Iteration 2622, loss = 0.00251545
Iteration 2623, loss = 0.00251412
Iteration 2624, loss = 0.00251286
Iteration 2625, loss = 0.00251164
Iteration 2626, loss = 0.00251054
Iteration 2627, loss = 0.00250892
Iteration 2628, loss = 0.00250765
Iteration 2629, loss = 0.00250656
Iteration 2630, loss = 0.00250524
Iteration 2631, loss = 0.00250388
Iteration 2632, loss = 0.00250284
Iteration 2633, loss = 0.00250145
Iteration 2634, loss = 0.00250015
Iteration 2635, loss = 0.00249892
Iteration 2636, loss = 0.00249766
Iteration 2637, loss = 0.00249634
Iteration 2638, loss = 0.00249511
Iteration 2639, loss = 0.00249391
Iteration 2640, loss = 0.00249256
Iteration 2641, loss = 0.00249123
Iteration 2642, loss = 0.00249012
Iteration 2643, loss = 0.00248889
Iteration 2644, loss = 0.00248757
Iteration 2645, loss = 0.00248642
Iteration 2646, loss = 0.00248523
Iteration 2647, loss = 0.00248394
Iteration 2648, loss = 0.00248298
Iteration 2649, loss = 0.00248165
Iteration 2650, loss = 0.00248047
Iteration 2651, loss = 0.00247940
Iteration 2652, loss = 0.00247837
Iteration 2653, loss = 0.00247698
Iteration 2654, loss = 0.00247555
Iteration 2655, loss = 0.00247424
Iteration 2656, loss = 0.00247296
Iteration 2657, loss = 0.00247168
Iteration 2658, loss = 0.00247058
Iteration 2659, loss = 0.00246927
Iteration 2660, loss = 0.00246808
Iteration 2661, loss = 0.00246685
Iteration 2662, loss = 0.00246580
Iteration 2663, loss = 0.00246457
Iteration 2664, loss = 0.00246337
Iteration 2665, loss = 0.00246213
Iteration 2666, loss = 0.00246088
Iteration 2667, loss = 0.00245981
Iteration 2668, loss = 0.00245845
Iteration 2669, loss = 0.00245755
Iteration 2670, loss = 0.00245605
Iteration 2671, loss = 0.00245516
Iteration 2672, loss = 0.00245392
Iteration 2673, loss = 0.00245265
Iteration 2674, loss = 0.00245143
Iteration 2675, loss = 0.00245011
Iteration 2676, loss = 0.00244883
Iteration 2677, loss = 0.00244761
Iteration 2678, loss = 0.00244676
Iteration 2679, loss = 0.00244518
Iteration 2680, loss = 0.00244402
Iteration 2681, loss = 0.00244274
Iteration 2682, loss = 0.00244146
Iteration 2683, loss = 0.00244042
Iteration 2684, loss = 0.00243912
Iteration 2685, loss = 0.00243807
Iteration 2686, loss = 0.00243675
Iteration 2687, loss = 0.00243559
Iteration 2688, loss = 0.00243438
Iteration 2689, loss = 0.00243326
Iteration 2690, loss = 0.00243203
Iteration 2691, loss = 0.00243077
Iteration 2692, loss = 0.00242945
Iteration 2693, loss = 0.00242854
Iteration 2694, loss = 0.00242715
Iteration 2695, loss = 0.00242615
Iteration 2696, loss = 0.00242472
Iteration 2697, loss = 0.00242356
Iteration 2698, loss = 0.00242247
Iteration 2699, loss = 0.00242116
Iteration 2700, loss = 0.00242025
Iteration 2701, loss = 0.00241868
Iteration 2702, loss = 0.00241772
Iteration 2703, loss = 0.00241636
Iteration 2704, loss = 0.00241529
Iteration 2705, loss = 0.00241398
Iteration 2706, loss = 0.00241289
Iteration 2707, loss = 0.00241174
Iteration 2708, loss = 0.00241052
Iteration 2709, loss = 0.00240952
Iteration 2710, loss = 0.00240827
Iteration 2711, loss = 0.00240691
Iteration 2712, loss = 0.00240567
Iteration 2713, loss = 0.00240463
Iteration 2714, loss = 0.00240338
Iteration 2715, loss = 0.00240235
Iteration 2716, loss = 0.00240113
Iteration 2717, loss = 0.00239991
Iteration 2718, loss = 0.00239872
Iteration 2719, loss = 0.00239760
Iteration 2720, loss = 0.00239646
Iteration 2721, loss = 0.00239515
Iteration 2722, loss = 0.00239418
Iteration 2723, loss = 0.00239308
Iteration 2724, loss = 0.00239176
Iteration 2725, loss = 0.00239077
Iteration 2726, loss = 0.00238948
Iteration 2727, loss = 0.00238828
Iteration 2728, loss = 0.00238718
Iteration 2729, loss = 0.00238614
Iteration 2730, loss = 0.00238485
Iteration 2731, loss = 0.00238382
Iteration 2732, loss = 0.00238284
Iteration 2733, loss = 0.00238155
Iteration 2734, loss = 0.00238045
Iteration 2735, loss = 0.00237924
Iteration 2736, loss = 0.00237815
Iteration 2737, loss = 0.00237695
Iteration 2738, loss = 0.00237581
Iteration 2739, loss = 0.00237481
Iteration 2740, loss = 0.00237370
Iteration 2741, loss = 0.00237252
Iteration 2742, loss = 0.00237129
Iteration 2743, loss = 0.00237031
Iteration 2744, loss = 0.00236927
Iteration 2745, loss = 0.00236803
Iteration 2746, loss = 0.00236701
Iteration 2747, loss = 0.00236579
Iteration 2748, loss = 0.00236466
Iteration 2749, loss = 0.00236375
Iteration 2750, loss = 0.00236242
Iteration 2751, loss = 0.00236133
Iteration 2752, loss = 0.00236024
Iteration 2753, loss = 0.00235906
Iteration 2754, loss = 0.00235801
Iteration 2755, loss = 0.00235702
Iteration 2756, loss = 0.00235577
Iteration 2757, loss = 0.00235443
Iteration 2758, loss = 0.00235318
Iteration 2759, loss = 0.00235256
Iteration 2760, loss = 0.00235109
Iteration 2761, loss = 0.00234987
Iteration 2762, loss = 0.00234905
Iteration 2763, loss = 0.00234774
Iteration 2764, loss = 0.00234657
Iteration 2765, loss = 0.00234553
Iteration 2766, loss = 0.00234461
Iteration 2767, loss = 0.00234330
Iteration 2768, loss = 0.00234205
Iteration 2769, loss = 0.00234105
Iteration 2770, loss = 0.00233988
Iteration 2771, loss = 0.00233879
Iteration 2772, loss = 0.00233770
Iteration 2773, loss = 0.00233659
Iteration 2774, loss = 0.00233552
Iteration 2775, loss = 0.00233434
Iteration 2776, loss = 0.00233320
Iteration 2777, loss = 0.00233206
Iteration 2778, loss = 0.00233093
Iteration 2779, loss = 0.00233006
Iteration 2780, loss = 0.00232889
Iteration 2781, loss = 0.00232770
Iteration 2782, loss = 0.00232672
Iteration 2783, loss = 0.00232543
Iteration 2784, loss = 0.00232434
Iteration 2785, loss = 0.00232320
Iteration 2786, loss = 0.00232215
Iteration 2787, loss = 0.00232095
Iteration 2788, loss = 0.00232000
Iteration 2789, loss = 0.00231875
Iteration 2790, loss = 0.00231778
Iteration 2791, loss = 0.00231666
Iteration 2792, loss = 0.00231545
Iteration 2793, loss = 0.00231453
Iteration 2794, loss = 0.00231329
Iteration 2795, loss = 0.00231241
Iteration 2796, loss = 0.00231102
Iteration 2797, loss = 0.00231008
Iteration 2798, loss = 0.00230899
Iteration 2799, loss = 0.00230801
Iteration 2800, loss = 0.00230686
Iteration 2801, loss = 0.00230570
Iteration 2802, loss = 0.00230463
Iteration 2803, loss = 0.00230350
Iteration 2804, loss = 0.00230244
Iteration 2805, loss = 0.00230150
Iteration 2806, loss = 0.00230023
Iteration 2807, loss = 0.00229916
Iteration 2808, loss = 0.00229810
Iteration 2809, loss = 0.00229700
Iteration 2810, loss = 0.00229596
Iteration 2811, loss = 0.00229478
Iteration 2812, loss = 0.00229372
Iteration 2813, loss = 0.00229269
Iteration 2814, loss = 0.00229159
Iteration 2815, loss = 0.00229038
Iteration 2816, loss = 0.00228951
Iteration 2817, loss = 0.00228828
Iteration 2818, loss = 0.00228716
Iteration 2819, loss = 0.00228600
Iteration 2820, loss = 0.00228491
Iteration 2821, loss = 0.00228386
Iteration 2822, loss = 0.00228287
Iteration 2823, loss = 0.00228167
Iteration 2824, loss = 0.00228062
Iteration 2825, loss = 0.00227951
Iteration 2826, loss = 0.00227844
Iteration 2827, loss = 0.00227744
Iteration 2828, loss = 0.00227630
Iteration 2829, loss = 0.00227527
Iteration 2830, loss = 0.00227411
Iteration 2831, loss = 0.00227307
Iteration 2832, loss = 0.00227221
Iteration 2833, loss = 0.00227107
Iteration 2834, loss = 0.00226996
Iteration 2835, loss = 0.00226890
Iteration 2836, loss = 0.00226795
Iteration 2837, loss = 0.00226676
Iteration 2838, loss = 0.00226562
Iteration 2839, loss = 0.00226463
Iteration 2840, loss = 0.00226387
Iteration 2841, loss = 0.00226257
Iteration 2842, loss = 0.00226153
Iteration 2843, loss = 0.00226058
Iteration 2844, loss = 0.00225957
Iteration 2845, loss = 0.00225836
Iteration 2846, loss = 0.00225725
Iteration 2847, loss = 0.00225621
Iteration 2848, loss = 0.00225526
Iteration 2849, loss = 0.00225411
Iteration 2850, loss = 0.00225329
Iteration 2851, loss = 0.00225210
Iteration 2852, loss = 0.00225113
Iteration 2853, loss = 0.00224995
Iteration 2854, loss = 0.00224911
Iteration 2855, loss = 0.00224783
Iteration 2856, loss = 0.00224692
Iteration 2857, loss = 0.00224583
Iteration 2858, loss = 0.00224489
Iteration 2859, loss = 0.00224400
Iteration 2860, loss = 0.00224303
Iteration 2861, loss = 0.00224214
Iteration 2862, loss = 0.00224093
Iteration 2863, loss = 0.00223972
Iteration 2864, loss = 0.00223870
Iteration 2865, loss = 0.00223762
Iteration 2866, loss = 0.00223668
Iteration 2867, loss = 0.00223559
Iteration 2868, loss = 0.00223448
Iteration 2869, loss = 0.00223363
Iteration 2870, loss = 0.00223260
Iteration 2871, loss = 0.00223147
Iteration 2872, loss = 0.00223039
Iteration 2873, loss = 0.00222933
Iteration 2874, loss = 0.00222850
Iteration 2875, loss = 0.00222727
Iteration 2876, loss = 0.00222634
Iteration 2877, loss = 0.00222552
Iteration 2878, loss = 0.00222422
Iteration 2879, loss = 0.00222334
Iteration 2880, loss = 0.00222226
Iteration 2881, loss = 0.00222117
Iteration 2882, loss = 0.00222018
Iteration 2883, loss = 0.00221916
Iteration 2884, loss = 0.00221808
Iteration 2885, loss = 0.00221723
Iteration 2886, loss = 0.00221602
Iteration 2887, loss = 0.00221508
Iteration 2888, loss = 0.00221406
Iteration 2889, loss = 0.00221285
Iteration 2890, loss = 0.00221198
Iteration 2891, loss = 0.00221080
Iteration 2892, loss = 0.00220992
Iteration 2893, loss = 0.00220873
Iteration 2894, loss = 0.00220788
Iteration 2895, loss = 0.00220671
Iteration 2896, loss = 0.00220566
Iteration 2897, loss = 0.00220492
Iteration 2898, loss = 0.00220359
Iteration 2899, loss = 0.00220257
Iteration 2900, loss = 0.00220168
Iteration 2901, loss = 0.00220071
Iteration 2902, loss = 0.00219968
Iteration 2903, loss = 0.00219872
Iteration 2904, loss = 0.00219760
Iteration 2905, loss = 0.00219647
Iteration 2906, loss = 0.00219553
Iteration 2907, loss = 0.00219460
Iteration 2908, loss = 0.00219352
Iteration 2909, loss = 0.00219267
Iteration 2910, loss = 0.00219158
Iteration 2911, loss = 0.00219077
Iteration 2912, loss = 0.00218959
Iteration 2913, loss = 0.00218863
Iteration 2914, loss = 0.00218748
Iteration 2915, loss = 0.00218664
Iteration 2916, loss = 0.00218570
Iteration 2917, loss = 0.00218491
Iteration 2918, loss = 0.00218378
Iteration 2919, loss = 0.00218272
Iteration 2920, loss = 0.00218167
Iteration 2921, loss = 0.00218085
Iteration 2922, loss = 0.00217975
Iteration 2923, loss = 0.00217879
Iteration 2924, loss = 0.00217785
Iteration 2925, loss = 0.00217693
Iteration 2926, loss = 0.00217596
Iteration 2927, loss = 0.00217536
Iteration 2928, loss = 0.00217391
Iteration 2929, loss = 0.00217291
Iteration 2930, loss = 0.00217201
Iteration 2931, loss = 0.00217108
Iteration 2932, loss = 0.00216999
Iteration 2933, loss = 0.00216913
Iteration 2934, loss = 0.00216818
Iteration 2935, loss = 0.00216718
Iteration 2936, loss = 0.00216615
Iteration 2937, loss = 0.00216512
Iteration 2938, loss = 0.00216415
Iteration 2939, loss = 0.00216331
Iteration 2940, loss = 0.00216216
Iteration 2941, loss = 0.00216130
Iteration 2942, loss = 0.00216017
Iteration 2943, loss = 0.00215920
Iteration 2944, loss = 0.00215821
Iteration 2945, loss = 0.00215732
Iteration 2946, loss = 0.00215632
Iteration 2947, loss = 0.00215539
Iteration 2948, loss = 0.00215448
Iteration 2949, loss = 0.00215348
Iteration 2950, loss = 0.00215253
Iteration 2951, loss = 0.00215169
Iteration 2952, loss = 0.00215064
Iteration 2953, loss = 0.00214977
Iteration 2954, loss = 0.00214868
Iteration 2955, loss = 0.00214783
Iteration 2956, loss = 0.00214689
Iteration 2957, loss = 0.00214578
Iteration 2958, loss = 0.00214495
Iteration 2959, loss = 0.00214397
Iteration 2960, loss = 0.00214291
Iteration 2961, loss = 0.00214208
Iteration 2962, loss = 0.00214122
Iteration 2963, loss = 0.00214032
Iteration 2964, loss = 0.00213929
Iteration 2965, loss = 0.00213809
Iteration 2966, loss = 0.00213722
Iteration 2967, loss = 0.00213628
Iteration 2968, loss = 0.00213527
Iteration 2969, loss = 0.00213437
Iteration 2970, loss = 0.00213358
Iteration 2971, loss = 0.00213246
Iteration 2972, loss = 0.00213153
Iteration 2973, loss = 0.00213037
Iteration 2974, loss = 0.00212952
Iteration 2975, loss = 0.00212847
Iteration 2976, loss = 0.00212764
Iteration 2977, loss = 0.00212682
Iteration 2978, loss = 0.00212564
Iteration 2979, loss = 0.00212473
Iteration 2980, loss = 0.00212391
Iteration 2981, loss = 0.00212287
Iteration 2982, loss = 0.00212186
Iteration 2983, loss = 0.00212111
Iteration 2984, loss = 0.00212001
Iteration 2985, loss = 0.00211923
Iteration 2986, loss = 0.00211822
Iteration 2987, loss = 0.00211726
Iteration 2988, loss = 0.00211639
Iteration 2989, loss = 0.00211551
Iteration 2990, loss = 0.00211460
Iteration 2991, loss = 0.00211360
Iteration 2992, loss = 0.00211271
Iteration 2993, loss = 0.00211181
Iteration 2994, loss = 0.00211077
Iteration 2995, loss = 0.00210981
Iteration 2996, loss = 0.00210888
Iteration 2997, loss = 0.00210822
Iteration 2998, loss = 0.00210711
Iteration 2999, loss = 0.00210614
Iteration 3000, loss = 0.00210523
Iteration 3001, loss = 0.00210422
Iteration 3002, loss = 0.00210327
Iteration 3003, loss = 0.00210249
Iteration 3004, loss = 0.00210162
Iteration 3005, loss = 0.00210064
Iteration 3006, loss = 0.00209983
Iteration 3007, loss = 0.00209866
Iteration 3008, loss = 0.00209775
Iteration 3009, loss = 0.00209693
Iteration 3010, loss = 0.00209610
Iteration 3011, loss = 0.00209507
Iteration 3012, loss = 0.00209421
Iteration 3013, loss = 0.00209323
Iteration 3014, loss = 0.00209230
Iteration 3015, loss = 0.00209141
Iteration 3016, loss = 0.00209054
Iteration 3017, loss = 0.00208984
Iteration 3018, loss = 0.00208863
Iteration 3019, loss = 0.00208777
Iteration 3020, loss = 0.00208675
Iteration 3021, loss = 0.00208586
Iteration 3022, loss = 0.00208514
Iteration 3023, loss = 0.00208415
Iteration 3024, loss = 0.00208311
Iteration 3025, loss = 0.00208239
Iteration 3026, loss = 0.00208135
Iteration 3027, loss = 0.00208042
Iteration 3028, loss = 0.00207952
Iteration 3029, loss = 0.00207862
Iteration 3030, loss = 0.00207755
Iteration 3031, loss = 0.00207675
Iteration 3032, loss = 0.00207590
Iteration 3033, loss = 0.00207496
Iteration 3034, loss = 0.00207425
Iteration 3035, loss = 0.00207298
Iteration 3036, loss = 0.00207211
Iteration 3037, loss = 0.00207122
Iteration 3038, loss = 0.00207040
Iteration 3039, loss = 0.00206942
Iteration 3040, loss = 0.00206858
Iteration 3041, loss = 0.00206772
Iteration 3042, loss = 0.00206685
Iteration 3043, loss = 0.00206586
Iteration 3044, loss = 0.00206493
Iteration 3045, loss = 0.00206404
Iteration 3046, loss = 0.00206308
Iteration 3047, loss = 0.00206219
Iteration 3048, loss = 0.00206132
Iteration 3049, loss = 0.00206052
Iteration 3050, loss = 0.00205949
Iteration 3051, loss = 0.00205868
Iteration 3052, loss = 0.00205767
Iteration 3053, loss = 0.00205690
Iteration 3054, loss = 0.00205615
Iteration 3055, loss = 0.00205506
Iteration 3056, loss = 0.00205423
Iteration 3057, loss = 0.00205362
Iteration 3058, loss = 0.00205255
Iteration 3059, loss = 0.00205161
Iteration 3060, loss = 0.00205077
Iteration 3061, loss = 0.00204981
Iteration 3062, loss = 0.00204904
Iteration 3063, loss = 0.00204800
Iteration 3064, loss = 0.00204712
Iteration 3065, loss = 0.00204638
Iteration 3066, loss = 0.00204544
Iteration 3067, loss = 0.00204429
Iteration 3068, loss = 0.00204354
Iteration 3069, loss = 0.00204261
Iteration 3070, loss = 0.00204174
Iteration 3071, loss = 0.00204080
Iteration 3072, loss = 0.00203988
Iteration 3073, loss = 0.00203906
Iteration 3074, loss = 0.00203811
Iteration 3075, loss = 0.00203731
Iteration 3076, loss = 0.00203638
Iteration 3077, loss = 0.00203539
Iteration 3078, loss = 0.00203459
Iteration 3079, loss = 0.00203375
Iteration 3080, loss = 0.00203286
Iteration 3081, loss = 0.00203196
Iteration 3082, loss = 0.00203110
Iteration 3083, loss = 0.00203019
Iteration 3084, loss = 0.00202943
Iteration 3085, loss = 0.00202851
Iteration 3086, loss = 0.00202760
Iteration 3087, loss = 0.00202658
Iteration 3088, loss = 0.00202600
Iteration 3089, loss = 0.00202484
Iteration 3090, loss = 0.00202416
Iteration 3091, loss = 0.00202324
Iteration 3092, loss = 0.00202225
Iteration 3093, loss = 0.00202151
Iteration 3094, loss = 0.00202055
Iteration 3095, loss = 0.00201965
Iteration 3096, loss = 0.00201883
Iteration 3097, loss = 0.00201812
Iteration 3098, loss = 0.00201717
Iteration 3099, loss = 0.00201629
Iteration 3100, loss = 0.00201553
Iteration 3101, loss = 0.00201455
Iteration 3102, loss = 0.00201379
Iteration 3103, loss = 0.00201306
Iteration 3104, loss = 0.00201205
Iteration 3105, loss = 0.00201130
Iteration 3106, loss = 0.00201045
Iteration 3107, loss = 0.00200962
Iteration 3108, loss = 0.00200867
Iteration 3109, loss = 0.00200790
Iteration 3110, loss = 0.00200719
Iteration 3111, loss = 0.00200616
Iteration 3112, loss = 0.00200545
Iteration 3113, loss = 0.00200451
Iteration 3114, loss = 0.00200366
Iteration 3115, loss = 0.00200293
Iteration 3116, loss = 0.00200202
Iteration 3117, loss = 0.00200124
Iteration 3118, loss = 0.00200041
Iteration 3119, loss = 0.00199951
Iteration 3120, loss = 0.00199873
Iteration 3121, loss = 0.00199790
Iteration 3122, loss = 0.00199696
Iteration 3123, loss = 0.00199620
Iteration 3124, loss = 0.00199549
Iteration 3125, loss = 0.00199451
Iteration 3126, loss = 0.00199372
Iteration 3127, loss = 0.00199288
Iteration 3128, loss = 0.00199204
Iteration 3129, loss = 0.00199120
Iteration 3130, loss = 0.00199043
Iteration 3131, loss = 0.00198958
Iteration 3132, loss = 0.00198882
Iteration 3133, loss = 0.00198803
Iteration 3134, loss = 0.00198708
Iteration 3135, loss = 0.00198617
Iteration 3136, loss = 0.00198535
Iteration 3137, loss = 0.00198459
Iteration 3138, loss = 0.00198372
Iteration 3139, loss = 0.00198287
Iteration 3140, loss = 0.00198198
Iteration 3141, loss = 0.00198125
Iteration 3142, loss = 0.00198032
Iteration 3143, loss = 0.00197955
Iteration 3144, loss = 0.00197862
Iteration 3145, loss = 0.00197785
Iteration 3146, loss = 0.00197697
Iteration 3147, loss = 0.00197606
Iteration 3148, loss = 0.00197523
Iteration 3149, loss = 0.00197446
Iteration 3150, loss = 0.00197356
Iteration 3151, loss = 0.00197276
Iteration 3152, loss = 0.00197185
Iteration 3153, loss = 0.00197107
Iteration 3154, loss = 0.00197031
Iteration 3155, loss = 0.00196961
Iteration 3156, loss = 0.00196881
Iteration 3157, loss = 0.00196789
Iteration 3158, loss = 0.00196694
Iteration 3159, loss = 0.00196618
Iteration 3160, loss = 0.00196536
Iteration 3161, loss = 0.00196464
Iteration 3162, loss = 0.00196375
Iteration 3163, loss = 0.00196305
Iteration 3164, loss = 0.00196222
Iteration 3165, loss = 0.00196135
Iteration 3166, loss = 0.00196066
Iteration 3167, loss = 0.00195970
Iteration 3168, loss = 0.00195899
Iteration 3169, loss = 0.00195808
Iteration 3170, loss = 0.00195739
Iteration 3171, loss = 0.00195654
Iteration 3172, loss = 0.00195571
Iteration 3173, loss = 0.00195495
Iteration 3174, loss = 0.00195407
Iteration 3175, loss = 0.00195324
Iteration 3176, loss = 0.00195240
Iteration 3177, loss = 0.00195156
Iteration 3178, loss = 0.00195079
Iteration 3179, loss = 0.00194989
Iteration 3180, loss = 0.00194911
Iteration 3181, loss = 0.00194823
Iteration 3182, loss = 0.00194744
Iteration 3183, loss = 0.00194676
Iteration 3184, loss = 0.00194587
Iteration 3185, loss = 0.00194514
Iteration 3186, loss = 0.00194438
Iteration 3187, loss = 0.00194355
Iteration 3188, loss = 0.00194275
Iteration 3189, loss = 0.00194190
Iteration 3190, loss = 0.00194113
Iteration 3191, loss = 0.00194025
Iteration 3192, loss = 0.00193950
Iteration 3193, loss = 0.00193866
Iteration 3194, loss = 0.00193790
Iteration 3195, loss = 0.00193720
Iteration 3196, loss = 0.00193631
Iteration 3197, loss = 0.00193552
Iteration 3198, loss = 0.00193468
Iteration 3199, loss = 0.00193389
Iteration 3200, loss = 0.00193321
Iteration 3201, loss = 0.00193235
Iteration 3202, loss = 0.00193144
Iteration 3203, loss = 0.00193076
Iteration 3204, loss = 0.00192985
Iteration 3205, loss = 0.00192904
Iteration 3206, loss = 0.00192844
Iteration 3207, loss = 0.00192754
Iteration 3208, loss = 0.00192663
Iteration 3209, loss = 0.00192589
Iteration 3210, loss = 0.00192513
Iteration 3211, loss = 0.00192440
Iteration 3212, loss = 0.00192354
Iteration 3213, loss = 0.00192296
Iteration 3214, loss = 0.00192189
Iteration 3215, loss = 0.00192120
Iteration 3216, loss = 0.00192031
Iteration 3217, loss = 0.00191956
Iteration 3218, loss = 0.00191884
Iteration 3219, loss = 0.00191796
Iteration 3220, loss = 0.00191724
Iteration 3221, loss = 0.00191635
Iteration 3222, loss = 0.00191568
Iteration 3223, loss = 0.00191490
Iteration 3224, loss = 0.00191400
Iteration 3225, loss = 0.00191342
Iteration 3226, loss = 0.00191236
Iteration 3227, loss = 0.00191165
Iteration 3228, loss = 0.00191084
Iteration 3229, loss = 0.00191000
Iteration 3230, loss = 0.00190939
Iteration 3231, loss = 0.00190860
Iteration 3232, loss = 0.00190764
Iteration 3233, loss = 0.00190687
Iteration 3234, loss = 0.00190616
Iteration 3235, loss = 0.00190538
Iteration 3236, loss = 0.00190461
Iteration 3237, loss = 0.00190380
Iteration 3238, loss = 0.00190324
Iteration 3239, loss = 0.00190226
Iteration 3240, loss = 0.00190145
Iteration 3241, loss = 0.00190073
Iteration 3242, loss = 0.00190007
Iteration 3243, loss = 0.00189920
Iteration 3244, loss = 0.00189857
Iteration 3245, loss = 0.00189767
Iteration 3246, loss = 0.00189689
Iteration 3247, loss = 0.00189611
Iteration 3248, loss = 0.00189533
Iteration 3249, loss = 0.00189469
Iteration 3250, loss = 0.00189391
Iteration 3251, loss = 0.00189313
Iteration 3252, loss = 0.00189261
Iteration 3253, loss = 0.00189167
Iteration 3254, loss = 0.00189099
Iteration 3255, loss = 0.00189007
Iteration 3256, loss = 0.00188936
Iteration 3257, loss = 0.00188863
Iteration 3258, loss = 0.00188797
Iteration 3259, loss = 0.00188704
Iteration 3260, loss = 0.00188636
Iteration 3261, loss = 0.00188562
Iteration 3262, loss = 0.00188497
Iteration 3263, loss = 0.00188398
Iteration 3264, loss = 0.00188327
Iteration 3265, loss = 0.00188242
Iteration 3266, loss = 0.00188166
Iteration 3267, loss = 0.00188094
Iteration 3268, loss = 0.00188032
Iteration 3269, loss = 0.00187959
Iteration 3270, loss = 0.00187892
Iteration 3271, loss = 0.00187799
Iteration 3272, loss = 0.00187717
Iteration 3273, loss = 0.00187657
Iteration 3274, loss = 0.00187580
Iteration 3275, loss = 0.00187501
Iteration 3276, loss = 0.00187419
Iteration 3277, loss = 0.00187361
Iteration 3278, loss = 0.00187279
Iteration 3279, loss = 0.00187198
Iteration 3280, loss = 0.00187121
Iteration 3281, loss = 0.00187049
Iteration 3282, loss = 0.00186977
Iteration 3283, loss = 0.00186895
Iteration 3284, loss = 0.00186823
Iteration 3285, loss = 0.00186760
Iteration 3286, loss = 0.00186680
Iteration 3287, loss = 0.00186601
Iteration 3288, loss = 0.00186523
Iteration 3289, loss = 0.00186468
Iteration 3290, loss = 0.00186377
Iteration 3291, loss = 0.00186289
Iteration 3292, loss = 0.00186221
Iteration 3293, loss = 0.00186140
Iteration 3294, loss = 0.00186074
Iteration 3295, loss = 0.00186007
Iteration 3296, loss = 0.00185917
Iteration 3297, loss = 0.00185851
Iteration 3298, loss = 0.00185774
Iteration 3299, loss = 0.00185705
Iteration 3300, loss = 0.00185630
Iteration 3301, loss = 0.00185573
Iteration 3302, loss = 0.00185472
Iteration 3303, loss = 0.00185403
Iteration 3304, loss = 0.00185337
Iteration 3305, loss = 0.00185254
Iteration 3306, loss = 0.00185193
Iteration 3307, loss = 0.00185118
Iteration 3308, loss = 0.00185039
Iteration 3309, loss = 0.00184986
Iteration 3310, loss = 0.00184892
Iteration 3311, loss = 0.00184821
Iteration 3312, loss = 0.00184753
Iteration 3313, loss = 0.00184693
Iteration 3314, loss = 0.00184601
Iteration 3315, loss = 0.00184529
Iteration 3316, loss = 0.00184452
Iteration 3317, loss = 0.00184393
Iteration 3318, loss = 0.00184310
Iteration 3319, loss = 0.00184239
Iteration 3320, loss = 0.00184151
Iteration 3321, loss = 0.00184094
Iteration 3322, loss = 0.00184021
Iteration 3323, loss = 0.00183956
Iteration 3324, loss = 0.00183871
Iteration 3325, loss = 0.00183806
Iteration 3326, loss = 0.00183729
Iteration 3327, loss = 0.00183651
Iteration 3328, loss = 0.00183577
Iteration 3329, loss = 0.00183501
Iteration 3330, loss = 0.00183432
Iteration 3331, loss = 0.00183361
Iteration 3332, loss = 0.00183297
Iteration 3333, loss = 0.00183222
Iteration 3334, loss = 0.00183167
Iteration 3335, loss = 0.00183071
Iteration 3336, loss = 0.00183013
Iteration 3337, loss = 0.00182923
Iteration 3338, loss = 0.00182853
Iteration 3339, loss = 0.00182782
Iteration 3340, loss = 0.00182709
Iteration 3341, loss = 0.00182632
Iteration 3342, loss = 0.00182566
Iteration 3343, loss = 0.00182493
Iteration 3344, loss = 0.00182441
Iteration 3345, loss = 0.00182350
Iteration 3346, loss = 0.00182277
Iteration 3347, loss = 0.00182207
Iteration 3348, loss = 0.00182129
Iteration 3349, loss = 0.00182063
Iteration 3350, loss = 0.00182001
Iteration 3351, loss = 0.00181923
Iteration 3352, loss = 0.00181842
Iteration 3353, loss = 0.00181774
Iteration 3354, loss = 0.00181714
Iteration 3355, loss = 0.00181637
Iteration 3356, loss = 0.00181575
Iteration 3357, loss = 0.00181498
Iteration 3358, loss = 0.00181423
Iteration 3359, loss = 0.00181359
Iteration 3360, loss = 0.00181280
Iteration 3361, loss = 0.00181207
Iteration 3362, loss = 0.00181140
Iteration 3363, loss = 0.00181064
Iteration 3364, loss = 0.00180998
Iteration 3365, loss = 0.00180917
Iteration 3366, loss = 0.00180858
Iteration 3367, loss = 0.00180777
Iteration 3368, loss = 0.00180714
Iteration 3369, loss = 0.00180639
Iteration 3370, loss = 0.00180567
Iteration 3371, loss = 0.00180494
Iteration 3372, loss = 0.00180430
Iteration 3373, loss = 0.00180358
Iteration 3374, loss = 0.00180289
Iteration 3375, loss = 0.00180220
Iteration 3376, loss = 0.00180165
Iteration 3377, loss = 0.00180078
Iteration 3378, loss = 0.00180002
Iteration 3379, loss = 0.00179934
Iteration 3380, loss = 0.00179873
Iteration 3381, loss = 0.00179809
Iteration 3382, loss = 0.00179730
Iteration 3383, loss = 0.00179651
Iteration 3384, loss = 0.00179598
Iteration 3385, loss = 0.00179511
Iteration 3386, loss = 0.00179447
Iteration 3387, loss = 0.00179378
Iteration 3388, loss = 0.00179297
Iteration 3389, loss = 0.00179233
Iteration 3390, loss = 0.00179173
Iteration 3391, loss = 0.00179104
Iteration 3392, loss = 0.00179023
Iteration 3393, loss = 0.00178958
Iteration 3394, loss = 0.00178890
Iteration 3395, loss = 0.00178818
Iteration 3396, loss = 0.00178754
Iteration 3397, loss = 0.00178682
Iteration 3398, loss = 0.00178609
Iteration 3399, loss = 0.00178543
Iteration 3400, loss = 0.00178470
Iteration 3401, loss = 0.00178408
Iteration 3402, loss = 0.00178334
Iteration 3403, loss = 0.00178269
Iteration 3404, loss = 0.00178198
Iteration 3405, loss = 0.00178139
Iteration 3406, loss = 0.00178067
Iteration 3407, loss = 0.00178000
Iteration 3408, loss = 0.00177929
Iteration 3409, loss = 0.00177862
Iteration 3410, loss = 0.00177796
Iteration 3411, loss = 0.00177747
Iteration 3412, loss = 0.00177655
Iteration 3413, loss = 0.00177580
Iteration 3414, loss = 0.00177513
Iteration 3415, loss = 0.00177448
Iteration 3416, loss = 0.00177377
Iteration 3417, loss = 0.00177305
Iteration 3418, loss = 0.00177243
Iteration 3419, loss = 0.00177165
Iteration 3420, loss = 0.00177099
Iteration 3421, loss = 0.00177029
Iteration 3422, loss = 0.00176961
Iteration 3423, loss = 0.00176903
Iteration 3424, loss = 0.00176829
Iteration 3425, loss = 0.00176756
Iteration 3426, loss = 0.00176699
Iteration 3427, loss = 0.00176630
Iteration 3428, loss = 0.00176575
Iteration 3429, loss = 0.00176494
Iteration 3430, loss = 0.00176425
Iteration 3431, loss = 0.00176357
Iteration 3432, loss = 0.00176292
Iteration 3433, loss = 0.00176211
Iteration 3434, loss = 0.00176153
Iteration 3435, loss = 0.00176083
Iteration 3436, loss = 0.00176021
Iteration 3437, loss = 0.00175953
Iteration 3438, loss = 0.00175885
Iteration 3439, loss = 0.00175817
Iteration 3440, loss = 0.00175761
Iteration 3441, loss = 0.00175690
Iteration 3442, loss = 0.00175621
Iteration 3443, loss = 0.00175553
Iteration 3444, loss = 0.00175508
Iteration 3445, loss = 0.00175417
Iteration 3446, loss = 0.00175349
Iteration 3447, loss = 0.00175282
Iteration 3448, loss = 0.00175214
Iteration 3449, loss = 0.00175156
Iteration 3450, loss = 0.00175085
Iteration 3451, loss = 0.00175022
Iteration 3452, loss = 0.00174961
Iteration 3453, loss = 0.00174881
Iteration 3454, loss = 0.00174813
Iteration 3455, loss = 0.00174751
Iteration 3456, loss = 0.00174684
Iteration 3457, loss = 0.00174618
Iteration 3458, loss = 0.00174566
Iteration 3459, loss = 0.00174486
Iteration 3460, loss = 0.00174426
Iteration 3461, loss = 0.00174355
Iteration 3462, loss = 0.00174290
Iteration 3463, loss = 0.00174227
Iteration 3464, loss = 0.00174155
Iteration 3465, loss = 0.00174092
Iteration 3466, loss = 0.00174030
Iteration 3467, loss = 0.00173967
Iteration 3468, loss = 0.00173896
Iteration 3469, loss = 0.00173835
Iteration 3470, loss = 0.00173764
Iteration 3471, loss = 0.00173712
Iteration 3472, loss = 0.00173633
Iteration 3473, loss = 0.00173558
Iteration 3474, loss = 0.00173496
Iteration 3475, loss = 0.00173430
Iteration 3476, loss = 0.00173359
Iteration 3477, loss = 0.00173310
Iteration 3478, loss = 0.00173231
Iteration 3479, loss = 0.00173171
Iteration 3480, loss = 0.00173109
Iteration 3481, loss = 0.00173033
Iteration 3482, loss = 0.00172978
Iteration 3483, loss = 0.00172908
Iteration 3484, loss = 0.00172842
Iteration 3485, loss = 0.00172763
Iteration 3486, loss = 0.00172704
Iteration 3487, loss = 0.00172638
Iteration 3488, loss = 0.00172579
Iteration 3489, loss = 0.00172505
Iteration 3490, loss = 0.00172452
Iteration 3491, loss = 0.00172375
Iteration 3492, loss = 0.00172320
Iteration 3493, loss = 0.00172249
Iteration 3494, loss = 0.00172179
Iteration 3495, loss = 0.00172122
Iteration 3496, loss = 0.00172055
Iteration 3497, loss = 0.00171995
Iteration 3498, loss = 0.00171930
Iteration 3499, loss = 0.00171860
Iteration 3500, loss = 0.00171802
Iteration 3501, loss = 0.00171734
Iteration 3502, loss = 0.00171668
Iteration 3503, loss = 0.00171616
Iteration 3504, loss = 0.00171540
Iteration 3505, loss = 0.00171478
Iteration 3506, loss = 0.00171413
Iteration 3507, loss = 0.00171351
Iteration 3508, loss = 0.00171282
Iteration 3509, loss = 0.00171222
Iteration 3510, loss = 0.00171158
Iteration 3511, loss = 0.00171087
Iteration 3512, loss = 0.00171040
Iteration 3513, loss = 0.00170968
Iteration 3514, loss = 0.00170904
Iteration 3515, loss = 0.00170840
Iteration 3516, loss = 0.00170776
Iteration 3517, loss = 0.00170720
Iteration 3518, loss = 0.00170652
Iteration 3519, loss = 0.00170601
Iteration 3520, loss = 0.00170519
Iteration 3521, loss = 0.00170469
Iteration 3522, loss = 0.00170404
Iteration 3523, loss = 0.00170354
Iteration 3524, loss = 0.00170271
Iteration 3525, loss = 0.00170215
Iteration 3526, loss = 0.00170156
Iteration 3527, loss = 0.00170101
Iteration 3528, loss = 0.00170025
Iteration 3529, loss = 0.00169964
Iteration 3530, loss = 0.00169897
Iteration 3531, loss = 0.00169836
Iteration 3532, loss = 0.00169782
Iteration 3533, loss = 0.00169709
Iteration 3534, loss = 0.00169640
Iteration 3535, loss = 0.00169582
Iteration 3536, loss = 0.00169521
Iteration 3537, loss = 0.00169453
Iteration 3538, loss = 0.00169391
Iteration 3539, loss = 0.00169329
Iteration 3540, loss = 0.00169264
Iteration 3541, loss = 0.00169201
Iteration 3542, loss = 0.00169139
Iteration 3543, loss = 0.00169075
Iteration 3544, loss = 0.00169014
Iteration 3545, loss = 0.00168959
Iteration 3546, loss = 0.00168898
Iteration 3547, loss = 0.00168825
Iteration 3548, loss = 0.00168808
Iteration 3549, loss = 0.00168710
Iteration 3550, loss = 0.00168639
Iteration 3551, loss = 0.00168583
Iteration 3552, loss = 0.00168524
Iteration 3553, loss = 0.00168455
Iteration 3554, loss = 0.00168401
Iteration 3555, loss = 0.00168350
Iteration 3556, loss = 0.00168274
Iteration 3557, loss = 0.00168211
Iteration 3558, loss = 0.00168147
Iteration 3559, loss = 0.00168087
Iteration 3560, loss = 0.00168025
Iteration 3561, loss = 0.00167970
Iteration 3562, loss = 0.00167897
Iteration 3563, loss = 0.00167840
Iteration 3564, loss = 0.00167786
Iteration 3565, loss = 0.00167731
Iteration 3566, loss = 0.00167651
Iteration 3567, loss = 0.00167594
Iteration 3568, loss = 0.00167529
Iteration 3569, loss = 0.00167465
Iteration 3570, loss = 0.00167405
Iteration 3571, loss = 0.00167351
Iteration 3572, loss = 0.00167277
Iteration 3573, loss = 0.00167217
Iteration 3574, loss = 0.00167167
Iteration 3575, loss = 0.00167095
Iteration 3576, loss = 0.00167037
Iteration 3577, loss = 0.00166974
Iteration 3578, loss = 0.00166931
Iteration 3579, loss = 0.00166853
Iteration 3580, loss = 0.00166799
Iteration 3581, loss = 0.00166734
Iteration 3582, loss = 0.00166672
Iteration 3583, loss = 0.00166616
Iteration 3584, loss = 0.00166571
Iteration 3585, loss = 0.00166498
Iteration 3586, loss = 0.00166441
Iteration 3587, loss = 0.00166367
Iteration 3588, loss = 0.00166300
Iteration 3589, loss = 0.00166250
Iteration 3590, loss = 0.00166190
Iteration 3591, loss = 0.00166110
Iteration 3592, loss = 0.00166068
Iteration 3593, loss = 0.00165992
Iteration 3594, loss = 0.00165931
Iteration 3595, loss = 0.00165870
Iteration 3596, loss = 0.00165806
Iteration 3597, loss = 0.00165745
Iteration 3598, loss = 0.00165685
Iteration 3599, loss = 0.00165619
Iteration 3600, loss = 0.00165568
Iteration 3601, loss = 0.00165505
Iteration 3602, loss = 0.00165443
Iteration 3603, loss = 0.00165391
Iteration 3604, loss = 0.00165325
Iteration 3605, loss = 0.00165265
Iteration 3606, loss = 0.00165203
Iteration 3607, loss = 0.00165170
Iteration 3608, loss = 0.00165084
Iteration 3609, loss = 0.00165030
Iteration 3610, loss = 0.00164965
Iteration 3611, loss = 0.00164908
Iteration 3612, loss = 0.00164854
Iteration 3613, loss = 0.00164786
Iteration 3614, loss = 0.00164733
Iteration 3615, loss = 0.00164669
Iteration 3616, loss = 0.00164609
Iteration 3617, loss = 0.00164548
Iteration 3618, loss = 0.00164506
Iteration 3619, loss = 0.00164430
Iteration 3620, loss = 0.00164371
Iteration 3621, loss = 0.00164313
Iteration 3622, loss = 0.00164245
Iteration 3623, loss = 0.00164197
Iteration 3624, loss = 0.00164134
Iteration 3625, loss = 0.00164074
Iteration 3626, loss = 0.00164012
Iteration 3627, loss = 0.00163957
Iteration 3628, loss = 0.00163906
Iteration 3629, loss = 0.00163844
Iteration 3630, loss = 0.00163800
Iteration 3631, loss = 0.00163730
Iteration 3632, loss = 0.00163665
Iteration 3633, loss = 0.00163609
Iteration 3634, loss = 0.00163544
Iteration 3635, loss = 0.00163492
Iteration 3636, loss = 0.00163425
Iteration 3637, loss = 0.00163369
Iteration 3638, loss = 0.00163307
Iteration 3639, loss = 0.00163250
Iteration 3640, loss = 0.00163189
Iteration 3641, loss = 0.00163138
Iteration 3642, loss = 0.00163074
Iteration 3643, loss = 0.00163018
Iteration 3644, loss = 0.00162952
Iteration 3645, loss = 0.00162896
Iteration 3646, loss = 0.00162837
Iteration 3647, loss = 0.00162783
Iteration 3648, loss = 0.00162732
Iteration 3649, loss = 0.00162673
Iteration 3650, loss = 0.00162613
Iteration 3651, loss = 0.00162560
Iteration 3652, loss = 0.00162496
Iteration 3653, loss = 0.00162440
Iteration 3654, loss = 0.00162371
Iteration 3655, loss = 0.00162318
Iteration 3656, loss = 0.00162262
Iteration 3657, loss = 0.00162206
Iteration 3658, loss = 0.00162144
Iteration 3659, loss = 0.00162085
Iteration 3660, loss = 0.00162027
Iteration 3661, loss = 0.00161972
Iteration 3662, loss = 0.00161906
Iteration 3663, loss = 0.00161850
Iteration 3664, loss = 0.00161799
Iteration 3665, loss = 0.00161739
Iteration 3666, loss = 0.00161679
Iteration 3667, loss = 0.00161627
Iteration 3668, loss = 0.00161564
Iteration 3669, loss = 0.00161504
Iteration 3670, loss = 0.00161443
Iteration 3671, loss = 0.00161383
Iteration 3672, loss = 0.00161321
Iteration 3673, loss = 0.00161271
Iteration 3674, loss = 0.00161223
Iteration 3675, loss = 0.00161156
Iteration 3676, loss = 0.00161103
Iteration 3677, loss = 0.00161050
Iteration 3678, loss = 0.00160979
Iteration 3679, loss = 0.00160929
Iteration 3680, loss = 0.00160868
Iteration 3681, loss = 0.00160809
Iteration 3682, loss = 0.00160757
Iteration 3683, loss = 0.00160692
Iteration 3684, loss = 0.00160636
Iteration 3685, loss = 0.00160587
Iteration 3686, loss = 0.00160523
Iteration 3687, loss = 0.00160461
Iteration 3688, loss = 0.00160411
Iteration 3689, loss = 0.00160351
Iteration 3690, loss = 0.00160292
Iteration 3691, loss = 0.00160245
Iteration 3692, loss = 0.00160175
Iteration 3693, loss = 0.00160114
Iteration 3694, loss = 0.00160074
Iteration 3695, loss = 0.00160003
Iteration 3696, loss = 0.00159952
Iteration 3697, loss = 0.00159897
Iteration 3698, loss = 0.00159830
Iteration 3699, loss = 0.00159780
Iteration 3700, loss = 0.00159721
Iteration 3701, loss = 0.00159667
Iteration 3702, loss = 0.00159617
Iteration 3703, loss = 0.00159557
Iteration 3704, loss = 0.00159495
Iteration 3705, loss = 0.00159450
Iteration 3706, loss = 0.00159382
Iteration 3707, loss = 0.00159333
Iteration 3708, loss = 0.00159272
Iteration 3709, loss = 0.00159218
Iteration 3710, loss = 0.00159157
Iteration 3711, loss = 0.00159100
Iteration 3712, loss = 0.00159044
Iteration 3713, loss = 0.00158988
Iteration 3714, loss = 0.00158932
Iteration 3715, loss = 0.00158877
Iteration 3716, loss = 0.00158857
Iteration 3717, loss = 0.00158767
Iteration 3718, loss = 0.00158710
Iteration 3719, loss = 0.00158656
Iteration 3720, loss = 0.00158599
Iteration 3721, loss = 0.00158551
Iteration 3722, loss = 0.00158481
Iteration 3723, loss = 0.00158453
Iteration 3724, loss = 0.00158372
Iteration 3725, loss = 0.00158312
Iteration 3726, loss = 0.00158254
Iteration 3727, loss = 0.00158194
Iteration 3728, loss = 0.00158147
Iteration 3729, loss = 0.00158087
Iteration 3730, loss = 0.00158037
Iteration 3731, loss = 0.00157980
Iteration 3732, loss = 0.00157920
Iteration 3733, loss = 0.00157877
Iteration 3734, loss = 0.00157815
Iteration 3735, loss = 0.00157758
Iteration 3736, loss = 0.00157710
Iteration 3737, loss = 0.00157653
Iteration 3738, loss = 0.00157603
Iteration 3739, loss = 0.00157534
Iteration 3740, loss = 0.00157492
Iteration 3741, loss = 0.00157431
Iteration 3742, loss = 0.00157372
Iteration 3743, loss = 0.00157317
Iteration 3744, loss = 0.00157265
Iteration 3745, loss = 0.00157203
Iteration 3746, loss = 0.00157155
Iteration 3747, loss = 0.00157103
Iteration 3748, loss = 0.00157058
Iteration 3749, loss = 0.00156988
Iteration 3750, loss = 0.00156940
Iteration 3751, loss = 0.00156882
Iteration 3752, loss = 0.00156825
Iteration 3753, loss = 0.00156774
Iteration 3754, loss = 0.00156724
Iteration 3755, loss = 0.00156668
Iteration 3756, loss = 0.00156620
Iteration 3757, loss = 0.00156563
Iteration 3758, loss = 0.00156508
Iteration 3759, loss = 0.00156440
Iteration 3760, loss = 0.00156393
Iteration 3761, loss = 0.00156338
Iteration 3762, loss = 0.00156283
Iteration 3763, loss = 0.00156230
Iteration 3764, loss = 0.00156173
Iteration 3765, loss = 0.00156125
Iteration 3766, loss = 0.00156071
Iteration 3767, loss = 0.00156020
Iteration 3768, loss = 0.00155966
Iteration 3769, loss = 0.00155910
Iteration 3770, loss = 0.00155854
Iteration 3771, loss = 0.00155804
Iteration 3772, loss = 0.00155745
Iteration 3773, loss = 0.00155699
Iteration 3774, loss = 0.00155639
Iteration 3775, loss = 0.00155589
Iteration 3776, loss = 0.00155534
Iteration 3777, loss = 0.00155479
Iteration 3778, loss = 0.00155433
Iteration 3779, loss = 0.00155379
Iteration 3780, loss = 0.00155329
Iteration 3781, loss = 0.00155291
Iteration 3782, loss = 0.00155216
Iteration 3783, loss = 0.00155170
Iteration 3784, loss = 0.00155120
Iteration 3785, loss = 0.00155055
Iteration 3786, loss = 0.00155004
Iteration 3787, loss = 0.00154945
Iteration 3788, loss = 0.00154899
Iteration 3789, loss = 0.00154842
Iteration 3790, loss = 0.00154783
Iteration 3791, loss = 0.00154727
Iteration 3792, loss = 0.00154684
Iteration 3793, loss = 0.00154626
Iteration 3794, loss = 0.00154568
Iteration 3795, loss = 0.00154512
Iteration 3796, loss = 0.00154457
Iteration 3797, loss = 0.00154409
Iteration 3798, loss = 0.00154358
Iteration 3799, loss = 0.00154299
Iteration 3800, loss = 0.00154252
Iteration 3801, loss = 0.00154208
Iteration 3802, loss = 0.00154147
Iteration 3803, loss = 0.00154100
Iteration 3804, loss = 0.00154041
Iteration 3805, loss = 0.00153996
Iteration 3806, loss = 0.00153935
Iteration 3807, loss = 0.00153891
Iteration 3808, loss = 0.00153837
Iteration 3809, loss = 0.00153779
Iteration 3810, loss = 0.00153732
Iteration 3811, loss = 0.00153675
Iteration 3812, loss = 0.00153621
Iteration 3813, loss = 0.00153589
Iteration 3814, loss = 0.00153517
Iteration 3815, loss = 0.00153466
Iteration 3816, loss = 0.00153420
Iteration 3817, loss = 0.00153359
Iteration 3818, loss = 0.00153308
Iteration 3819, loss = 0.00153256
Iteration 3820, loss = 0.00153201
Iteration 3821, loss = 0.00153150
Iteration 3822, loss = 0.00153103
Iteration 3823, loss = 0.00153044
Iteration 3824, loss = 0.00152997
Iteration 3825, loss = 0.00152940
Iteration 3826, loss = 0.00152890
Iteration 3827, loss = 0.00152837
Iteration 3828, loss = 0.00152783
Iteration 3829, loss = 0.00152725
Iteration 3830, loss = 0.00152677
Iteration 3831, loss = 0.00152623
Iteration 3832, loss = 0.00152572
Iteration 3833, loss = 0.00152520
Iteration 3834, loss = 0.00152463
Iteration 3835, loss = 0.00152417
Iteration 3836, loss = 0.00152359
Iteration 3837, loss = 0.00152306
Iteration 3838, loss = 0.00152254
Iteration 3839, loss = 0.00152200
Iteration 3840, loss = 0.00152156
Iteration 3841, loss = 0.00152093
Iteration 3842, loss = 0.00152050
Iteration 3843, loss = 0.00151989
Iteration 3844, loss = 0.00151942
Iteration 3845, loss = 0.00151889
Iteration 3846, loss = 0.00151833
Iteration 3847, loss = 0.00151777
Iteration 3848, loss = 0.00151725
Iteration 3849, loss = 0.00151677
Iteration 3850, loss = 0.00151631
Iteration 3851, loss = 0.00151570
Iteration 3852, loss = 0.00151523
Iteration 3853, loss = 0.00151465
Iteration 3854, loss = 0.00151412
Iteration 3855, loss = 0.00151364
Iteration 3856, loss = 0.00151309
Iteration 3857, loss = 0.00151261
Iteration 3858, loss = 0.00151215
Iteration 3859, loss = 0.00151159
Iteration 3860, loss = 0.00151106
Iteration 3861, loss = 0.00151059
Iteration 3862, loss = 0.00151014
Iteration 3863, loss = 0.00150958
Iteration 3864, loss = 0.00150902
Iteration 3865, loss = 0.00150853
Iteration 3866, loss = 0.00150803
Iteration 3867, loss = 0.00150754
Iteration 3868, loss = 0.00150700
Iteration 3869, loss = 0.00150651
Iteration 3870, loss = 0.00150595
Iteration 3871, loss = 0.00150546
Iteration 3872, loss = 0.00150503
Iteration 3873, loss = 0.00150445
Iteration 3874, loss = 0.00150393
Iteration 3875, loss = 0.00150340
Iteration 3876, loss = 0.00150292
Iteration 3877, loss = 0.00150244
Iteration 3878, loss = 0.00150185
Iteration 3879, loss = 0.00150147
Iteration 3880, loss = 0.00150097
Iteration 3881, loss = 0.00150043
Iteration 3882, loss = 0.00149991
Iteration 3883, loss = 0.00149940
Iteration 3884, loss = 0.00149895
Iteration 3885, loss = 0.00149840
Iteration 3886, loss = 0.00149797
Iteration 3887, loss = 0.00149743
Iteration 3888, loss = 0.00149690
Iteration 3889, loss = 0.00149642
Iteration 3890, loss = 0.00149591
Iteration 3891, loss = 0.00149540
Iteration 3892, loss = 0.00149494
Iteration 3893, loss = 0.00149443
Iteration 3894, loss = 0.00149390
Iteration 3895, loss = 0.00149342
Iteration 3896, loss = 0.00149290
Iteration 3897, loss = 0.00149243
Iteration 3898, loss = 0.00149190
Iteration 3899, loss = 0.00149139
Iteration 3900, loss = 0.00149087
Iteration 3901, loss = 0.00149045
Iteration 3902, loss = 0.00149003
Iteration 3903, loss = 0.00148946
Iteration 3904, loss = 0.00148896
Iteration 3905, loss = 0.00148840
Iteration 3906, loss = 0.00148798
Iteration 3907, loss = 0.00148735
Iteration 3908, loss = 0.00148696
Iteration 3909, loss = 0.00148643
Iteration 3910, loss = 0.00148588
Iteration 3911, loss = 0.00148546
Iteration 3912, loss = 0.00148490
Iteration 3913, loss = 0.00148446
Iteration 3914, loss = 0.00148392
Iteration 3915, loss = 0.00148340
Iteration 3916, loss = 0.00148289
Iteration 3917, loss = 0.00148239
Iteration 3918, loss = 0.00148184
Iteration 3919, loss = 0.00148138
Iteration 3920, loss = 0.00148085
Iteration 3921, loss = 0.00148038
Iteration 3922, loss = 0.00147982
Iteration 3923, loss = 0.00147938
Iteration 3924, loss = 0.00147888
Iteration 3925, loss = 0.00147840
Iteration 3926, loss = 0.00147784
Iteration 3927, loss = 0.00147736
Iteration 3928, loss = 0.00147687
Iteration 3929, loss = 0.00147642
Iteration 3930, loss = 0.00147592
Iteration 3931, loss = 0.00147540
Iteration 3932, loss = 0.00147498
Iteration 3933, loss = 0.00147442
Iteration 3934, loss = 0.00147401
Iteration 3935, loss = 0.00147348
Iteration 3936, loss = 0.00147308
Iteration 3937, loss = 0.00147262
Iteration 3938, loss = 0.00147208
Iteration 3939, loss = 0.00147162
Iteration 3940, loss = 0.00147108
Iteration 3941, loss = 0.00147061
Iteration 3942, loss = 0.00147009
Iteration 3943, loss = 0.00146962
Iteration 3944, loss = 0.00146917
Iteration 3945, loss = 0.00146865
Iteration 3946, loss = 0.00146817
Iteration 3947, loss = 0.00146773
Iteration 3948, loss = 0.00146715
Iteration 3949, loss = 0.00146670
Iteration 3950, loss = 0.00146610
Iteration 3951, loss = 0.00146567
Iteration 3952, loss = 0.00146516
Iteration 3953, loss = 0.00146465
Iteration 3954, loss = 0.00146419
Iteration 3955, loss = 0.00146368
Iteration 3956, loss = 0.00146321
Iteration 3957, loss = 0.00146272
Iteration 3958, loss = 0.00146232
Iteration 3959, loss = 0.00146179
Iteration 3960, loss = 0.00146125
Iteration 3961, loss = 0.00146083
Iteration 3962, loss = 0.00146050
Iteration 3963, loss = 0.00145979
Iteration 3964, loss = 0.00145936
Iteration 3965, loss = 0.00145888
Iteration 3966, loss = 0.00145840
Iteration 3967, loss = 0.00145799
Iteration 3968, loss = 0.00145757
Iteration 3969, loss = 0.00145696
Iteration 3970, loss = 0.00145649
Iteration 3971, loss = 0.00145606
Iteration 3972, loss = 0.00145559
Iteration 3973, loss = 0.00145506
Iteration 3974, loss = 0.00145455
Iteration 3975, loss = 0.00145402
Iteration 3976, loss = 0.00145369
Iteration 3977, loss = 0.00145316
Iteration 3978, loss = 0.00145269
Iteration 3979, loss = 0.00145219
Iteration 3980, loss = 0.00145163
Iteration 3981, loss = 0.00145120
Iteration 3982, loss = 0.00145068
Iteration 3983, loss = 0.00145032
Iteration 3984, loss = 0.00144979
Iteration 3985, loss = 0.00144929
Iteration 3986, loss = 0.00144882
Iteration 3987, loss = 0.00144835
Iteration 3988, loss = 0.00144781
Iteration 3989, loss = 0.00144742
Iteration 3990, loss = 0.00144692
Iteration 3991, loss = 0.00144642
Iteration 3992, loss = 0.00144590
Iteration 3993, loss = 0.00144541
Iteration 3994, loss = 0.00144495
Iteration 3995, loss = 0.00144447
Iteration 3996, loss = 0.00144402
Iteration 3997, loss = 0.00144354
Iteration 3998, loss = 0.00144307
Iteration 3999, loss = 0.00144256
Iteration 4000, loss = 0.00144211
Iteration 4001, loss = 0.00144174
Iteration 4002, loss = 0.00144114
Iteration 4003, loss = 0.00144068
Iteration 4004, loss = 0.00144017
Iteration 4005, loss = 0.00143971
Iteration 4006, loss = 0.00143925
Iteration 4007, loss = 0.00143882
Iteration 4008, loss = 0.00143829
Iteration 4009, loss = 0.00143779
Iteration 4010, loss = 0.00143738
Iteration 4011, loss = 0.00143690
Iteration 4012, loss = 0.00143650
Iteration 4013, loss = 0.00143597
Iteration 4014, loss = 0.00143553
Iteration 4015, loss = 0.00143506
Iteration 4016, loss = 0.00143465
Iteration 4017, loss = 0.00143414
Iteration 4018, loss = 0.00143365
Iteration 4019, loss = 0.00143312
Iteration 4020, loss = 0.00143269
Iteration 4021, loss = 0.00143226
Iteration 4022, loss = 0.00143175
Iteration 4023, loss = 0.00143142
Iteration 4024, loss = 0.00143087
Iteration 4025, loss = 0.00143036
Iteration 4026, loss = 0.00142996
Iteration 4027, loss = 0.00142949
Iteration 4028, loss = 0.00142900
Iteration 4029, loss = 0.00142858
Iteration 4030, loss = 0.00142812
Iteration 4031, loss = 0.00142769
Iteration 4032, loss = 0.00142720
Iteration 4033, loss = 0.00142677
Iteration 4034, loss = 0.00142623
Iteration 4035, loss = 0.00142581
Iteration 4036, loss = 0.00142531
Iteration 4037, loss = 0.00142481
Iteration 4038, loss = 0.00142446
Iteration 4039, loss = 0.00142391
Iteration 4040, loss = 0.00142349
Iteration 4041, loss = 0.00142305
Iteration 4042, loss = 0.00142262
Iteration 4043, loss = 0.00142207
Iteration 4044, loss = 0.00142159
Iteration 4045, loss = 0.00142123
Iteration 4046, loss = 0.00142081
Iteration 4047, loss = 0.00142023
Iteration 4048, loss = 0.00141979
Iteration 4049, loss = 0.00141938
Iteration 4050, loss = 0.00141885
Iteration 4051, loss = 0.00141837
Iteration 4052, loss = 0.00141795
Iteration 4053, loss = 0.00141753
Iteration 4054, loss = 0.00141705
Iteration 4055, loss = 0.00141658
Iteration 4056, loss = 0.00141620
Iteration 4057, loss = 0.00141574
Iteration 4058, loss = 0.00141521
Iteration 4059, loss = 0.00141477
Iteration 4060, loss = 0.00141434
Iteration 4061, loss = 0.00141386
Iteration 4062, loss = 0.00141360
Iteration 4063, loss = 0.00141295
Iteration 4064, loss = 0.00141246
Iteration 4065, loss = 0.00141204
Iteration 4066, loss = 0.00141159
Iteration 4067, loss = 0.00141112
Iteration 4068, loss = 0.00141060
Iteration 4069, loss = 0.00141018
Iteration 4070, loss = 0.00140979
Iteration 4071, loss = 0.00140933
Iteration 4072, loss = 0.00140879
Iteration 4073, loss = 0.00140838
Iteration 4074, loss = 0.00140797
Iteration 4075, loss = 0.00140748
Iteration 4076, loss = 0.00140701
Iteration 4077, loss = 0.00140657
Iteration 4078, loss = 0.00140606
Iteration 4079, loss = 0.00140577
Iteration 4080, loss = 0.00140521
Iteration 4081, loss = 0.00140474
Iteration 4082, loss = 0.00140433
Iteration 4083, loss = 0.00140385
Iteration 4084, loss = 0.00140338
Iteration 4085, loss = 0.00140289
Iteration 4086, loss = 0.00140251
Iteration 4087, loss = 0.00140202
Iteration 4088, loss = 0.00140160
Iteration 4089, loss = 0.00140116
Iteration 4090, loss = 0.00140071
Iteration 4091, loss = 0.00140025
Iteration 4092, loss = 0.00139977
Iteration 4093, loss = 0.00139936
Iteration 4094, loss = 0.00139891
Iteration 4095, loss = 0.00139851
Iteration 4096, loss = 0.00139809
Iteration 4097, loss = 0.00139760
Iteration 4098, loss = 0.00139726
Iteration 4099, loss = 0.00139677
Iteration 4100, loss = 0.00139629
Iteration 4101, loss = 0.00139579
Iteration 4102, loss = 0.00139533
Iteration 4103, loss = 0.00139491
Iteration 4104, loss = 0.00139442
Iteration 4105, loss = 0.00139405
Iteration 4106, loss = 0.00139363
Iteration 4107, loss = 0.00139318
Iteration 4108, loss = 0.00139257
Iteration 4109, loss = 0.00139217
Iteration 4110, loss = 0.00139178
Iteration 4111, loss = 0.00139135
Iteration 4112, loss = 0.00139086
Iteration 4113, loss = 0.00139048
Iteration 4114, loss = 0.00138994
Iteration 4115, loss = 0.00138943
Iteration 4116, loss = 0.00138908
Iteration 4117, loss = 0.00138857
Iteration 4118, loss = 0.00138815
Iteration 4119, loss = 0.00138771
Iteration 4120, loss = 0.00138738
Iteration 4121, loss = 0.00138704
Iteration 4122, loss = 0.00138640
Iteration 4123, loss = 0.00138598
Iteration 4124, loss = 0.00138558
Iteration 4125, loss = 0.00138517
Iteration 4126, loss = 0.00138466
Iteration 4127, loss = 0.00138426
Iteration 4128, loss = 0.00138387
Iteration 4129, loss = 0.00138339
Iteration 4130, loss = 0.00138296
Iteration 4131, loss = 0.00138252
Iteration 4132, loss = 0.00138229
Iteration 4133, loss = 0.00138161
Iteration 4134, loss = 0.00138123
Iteration 4135, loss = 0.00138082
Iteration 4136, loss = 0.00138032
Iteration 4137, loss = 0.00137992
Iteration 4138, loss = 0.00137950
Iteration 4139, loss = 0.00137911
Iteration 4140, loss = 0.00137863
Iteration 4141, loss = 0.00137824
Iteration 4142, loss = 0.00137781
Iteration 4143, loss = 0.00137729
Iteration 4144, loss = 0.00137687
Iteration 4145, loss = 0.00137639
Iteration 4146, loss = 0.00137601
Iteration 4147, loss = 0.00137559
Iteration 4148, loss = 0.00137514
Iteration 4149, loss = 0.00137471
Iteration 4150, loss = 0.00137427
Iteration 4151, loss = 0.00137395
Iteration 4152, loss = 0.00137334
Iteration 4153, loss = 0.00137296
Iteration 4154, loss = 0.00137253
Iteration 4155, loss = 0.00137202
Iteration 4156, loss = 0.00137162
Iteration 4157, loss = 0.00137137
Iteration 4158, loss = 0.00137096
Iteration 4159, loss = 0.00137036
Iteration 4160, loss = 0.00136992
Iteration 4161, loss = 0.00136954
Iteration 4162, loss = 0.00136913
Iteration 4163, loss = 0.00136864
Iteration 4164, loss = 0.00136822
Iteration 4165, loss = 0.00136771
Iteration 4166, loss = 0.00136732
Iteration 4167, loss = 0.00136682
Iteration 4168, loss = 0.00136639
Iteration 4169, loss = 0.00136601
Iteration 4170, loss = 0.00136565
Iteration 4171, loss = 0.00136510
Iteration 4172, loss = 0.00136468
Iteration 4173, loss = 0.00136427
Iteration 4174, loss = 0.00136378
Iteration 4175, loss = 0.00136350
Iteration 4176, loss = 0.00136293
Iteration 4177, loss = 0.00136249
Iteration 4178, loss = 0.00136207
Iteration 4179, loss = 0.00136166
Iteration 4180, loss = 0.00136119
Iteration 4181, loss = 0.00136079
Iteration 4182, loss = 0.00136041
Iteration 4183, loss = 0.00135990
Iteration 4184, loss = 0.00135948
Iteration 4185, loss = 0.00135915
Iteration 4186, loss = 0.00135871
Iteration 4187, loss = 0.00135827
Iteration 4188, loss = 0.00135776
Iteration 4189, loss = 0.00135734
Iteration 4190, loss = 0.00135692
Iteration 4191, loss = 0.00135649
Iteration 4192, loss = 0.00135605
Iteration 4193, loss = 0.00135569
Iteration 4194, loss = 0.00135528
Iteration 4195, loss = 0.00135491
Iteration 4196, loss = 0.00135448
Iteration 4197, loss = 0.00135401
Iteration 4198, loss = 0.00135361
Iteration 4199, loss = 0.00135315
Iteration 4200, loss = 0.00135283
Iteration 4201, loss = 0.00135232
Iteration 4202, loss = 0.00135190
Iteration 4203, loss = 0.00135147
Iteration 4204, loss = 0.00135115
Iteration 4205, loss = 0.00135067
Iteration 4206, loss = 0.00135035
Iteration 4207, loss = 0.00134976
Iteration 4208, loss = 0.00134956
Iteration 4209, loss = 0.00134897
Iteration 4210, loss = 0.00134851
Iteration 4211, loss = 0.00134811
Iteration 4212, loss = 0.00134771
Iteration 4213, loss = 0.00134727
Iteration 4214, loss = 0.00134683
Iteration 4215, loss = 0.00134641
Iteration 4216, loss = 0.00134602
Iteration 4217, loss = 0.00134558
Iteration 4218, loss = 0.00134520
Iteration 4219, loss = 0.00134483
Iteration 4220, loss = 0.00134437
Iteration 4221, loss = 0.00134394
Iteration 4222, loss = 0.00134355
Iteration 4223, loss = 0.00134313
Iteration 4224, loss = 0.00134275
Iteration 4225, loss = 0.00134226
Iteration 4226, loss = 0.00134188
Iteration 4227, loss = 0.00134145
Iteration 4228, loss = 0.00134102
Iteration 4229, loss = 0.00134064
Iteration 4230, loss = 0.00134020
Iteration 4231, loss = 0.00133978
Iteration 4232, loss = 0.00133934
Iteration 4233, loss = 0.00133910
Iteration 4234, loss = 0.00133851
Iteration 4235, loss = 0.00133822
Iteration 4236, loss = 0.00133775
Iteration 4237, loss = 0.00133740
Iteration 4238, loss = 0.00133692
Iteration 4239, loss = 0.00133652
Iteration 4240, loss = 0.00133608
Iteration 4241, loss = 0.00133572
Iteration 4242, loss = 0.00133551
Iteration 4243, loss = 0.00133490
Iteration 4244, loss = 0.00133449
Iteration 4245, loss = 0.00133415
Iteration 4246, loss = 0.00133368
Iteration 4247, loss = 0.00133335
Iteration 4248, loss = 0.00133290
Iteration 4249, loss = 0.00133248
Iteration 4250, loss = 0.00133213
Iteration 4251, loss = 0.00133168
Iteration 4252, loss = 0.00133129
Iteration 4253, loss = 0.00133087
Iteration 4254, loss = 0.00133045
Iteration 4255, loss = 0.00133004
Iteration 4256, loss = 0.00132969
Iteration 4257, loss = 0.00132923
Iteration 4258, loss = 0.00132884
Iteration 4259, loss = 0.00132847
Iteration 4260, loss = 0.00132797
Iteration 4261, loss = 0.00132767
Iteration 4262, loss = 0.00132721
Iteration 4263, loss = 0.00132677
Iteration 4264, loss = 0.00132637
Iteration 4265, loss = 0.00132607
Iteration 4266, loss = 0.00132556
Iteration 4267, loss = 0.00132513
Iteration 4268, loss = 0.00132473
Iteration 4269, loss = 0.00132433
Iteration 4270, loss = 0.00132395
Iteration 4271, loss = 0.00132358
Iteration 4272, loss = 0.00132316
Iteration 4273, loss = 0.00132273
Iteration 4274, loss = 0.00132235
Iteration 4275, loss = 0.00132195
Iteration 4276, loss = 0.00132161
Iteration 4277, loss = 0.00132114
Iteration 4278, loss = 0.00132073
Iteration 4279, loss = 0.00132027
Iteration 4280, loss = 0.00131990
Iteration 4281, loss = 0.00131948
Iteration 4282, loss = 0.00131909
Iteration 4283, loss = 0.00131876
Iteration 4284, loss = 0.00131826
Iteration 4285, loss = 0.00131789
Iteration 4286, loss = 0.00131740
Iteration 4287, loss = 0.00131706
Iteration 4288, loss = 0.00131666
Iteration 4289, loss = 0.00131630
Iteration 4290, loss = 0.00131586
Iteration 4291, loss = 0.00131546
Iteration 4292, loss = 0.00131508
Iteration 4293, loss = 0.00131476
Iteration 4294, loss = 0.00131431
Iteration 4295, loss = 0.00131388
Iteration 4296, loss = 0.00131348
Iteration 4297, loss = 0.00131311
Iteration 4298, loss = 0.00131270
Iteration 4299, loss = 0.00131230
Iteration 4300, loss = 0.00131190
Iteration 4301, loss = 0.00131165
Iteration 4302, loss = 0.00131111
Iteration 4303, loss = 0.00131069
Iteration 4304, loss = 0.00131043
Iteration 4305, loss = 0.00130992
Iteration 4306, loss = 0.00130952
Iteration 4307, loss = 0.00130916
Iteration 4308, loss = 0.00130863
Iteration 4309, loss = 0.00130827
Iteration 4310, loss = 0.00130789
Iteration 4311, loss = 0.00130750
Iteration 4312, loss = 0.00130704
Iteration 4313, loss = 0.00130666
Iteration 4314, loss = 0.00130629
Iteration 4315, loss = 0.00130589
Iteration 4316, loss = 0.00130559
Iteration 4317, loss = 0.00130511
Iteration 4318, loss = 0.00130474
Iteration 4319, loss = 0.00130431
Iteration 4320, loss = 0.00130386
Iteration 4321, loss = 0.00130346
Iteration 4322, loss = 0.00130309
Iteration 4323, loss = 0.00130273
Iteration 4324, loss = 0.00130233
Iteration 4325, loss = 0.00130190
Iteration 4326, loss = 0.00130148
Iteration 4327, loss = 0.00130116
Iteration 4328, loss = 0.00130073
Iteration 4329, loss = 0.00130037
Iteration 4330, loss = 0.00129996
Iteration 4331, loss = 0.00129966
Iteration 4332, loss = 0.00129918
Iteration 4333, loss = 0.00129879
Iteration 4334, loss = 0.00129852
Iteration 4335, loss = 0.00129804
Iteration 4336, loss = 0.00129768
Iteration 4337, loss = 0.00129728
Iteration 4338, loss = 0.00129694
Iteration 4339, loss = 0.00129652
Iteration 4340, loss = 0.00129616
Iteration 4341, loss = 0.00129570
Iteration 4342, loss = 0.00129538
Iteration 4343, loss = 0.00129506
Iteration 4344, loss = 0.00129456
Iteration 4345, loss = 0.00129417
Iteration 4346, loss = 0.00129380
Iteration 4347, loss = 0.00129343
Iteration 4348, loss = 0.00129301
Iteration 4349, loss = 0.00129265
Iteration 4350, loss = 0.00129225
Iteration 4351, loss = 0.00129185
Iteration 4352, loss = 0.00129150
Iteration 4353, loss = 0.00129110
Iteration 4354, loss = 0.00129076
Iteration 4355, loss = 0.00129027
Iteration 4356, loss = 0.00128994
Iteration 4357, loss = 0.00128953
Iteration 4358, loss = 0.00128916
Iteration 4359, loss = 0.00128876
Iteration 4360, loss = 0.00128833
Iteration 4361, loss = 0.00128794
Iteration 4362, loss = 0.00128760
Iteration 4363, loss = 0.00128719
Iteration 4364, loss = 0.00128684
Iteration 4365, loss = 0.00128642
Iteration 4366, loss = 0.00128606
Iteration 4367, loss = 0.00128563
Iteration 4368, loss = 0.00128528
Iteration 4369, loss = 0.00128486
Iteration 4370, loss = 0.00128454
Iteration 4371, loss = 0.00128408
Iteration 4372, loss = 0.00128381
Iteration 4373, loss = 0.00128337
Iteration 4374, loss = 0.00128301
Iteration 4375, loss = 0.00128256
Iteration 4376, loss = 0.00128213
Iteration 4377, loss = 0.00128174
Iteration 4378, loss = 0.00128138
Iteration 4379, loss = 0.00128096
Iteration 4380, loss = 0.00128059
Iteration 4381, loss = 0.00128018
Iteration 4382, loss = 0.00127975
Iteration 4383, loss = 0.00127942
Iteration 4384, loss = 0.00127900
Iteration 4385, loss = 0.00127862
Iteration 4386, loss = 0.00127828
Iteration 4387, loss = 0.00127785
Iteration 4388, loss = 0.00127751
Iteration 4389, loss = 0.00127709
Iteration 4390, loss = 0.00127676
Iteration 4391, loss = 0.00127633
Iteration 4392, loss = 0.00127597
Iteration 4393, loss = 0.00127571
Iteration 4394, loss = 0.00127522
Iteration 4395, loss = 0.00127478
Iteration 4396, loss = 0.00127445
Iteration 4397, loss = 0.00127407
Iteration 4398, loss = 0.00127368
Iteration 4399, loss = 0.00127333
Iteration 4400, loss = 0.00127292
Iteration 4401, loss = 0.00127252
Iteration 4402, loss = 0.00127215
Iteration 4403, loss = 0.00127187
Iteration 4404, loss = 0.00127153
Iteration 4405, loss = 0.00127099
Iteration 4406, loss = 0.00127065
Iteration 4407, loss = 0.00127032
Iteration 4408, loss = 0.00126986
Iteration 4409, loss = 0.00126951
Iteration 4410, loss = 0.00126912
Iteration 4411, loss = 0.00126879
Iteration 4412, loss = 0.00126833
Iteration 4413, loss = 0.00126809
Iteration 4414, loss = 0.00126758
Iteration 4415, loss = 0.00126720
Iteration 4416, loss = 0.00126684
Iteration 4417, loss = 0.00126648
Iteration 4418, loss = 0.00126611
Iteration 4419, loss = 0.00126577
Iteration 4420, loss = 0.00126525
Iteration 4421, loss = 0.00126492
Iteration 4422, loss = 0.00126449
Iteration 4423, loss = 0.00126428
Iteration 4424, loss = 0.00126385
Iteration 4425, loss = 0.00126333
Iteration 4426, loss = 0.00126298
Iteration 4427, loss = 0.00126270
Iteration 4428, loss = 0.00126222
Iteration 4429, loss = 0.00126184
Iteration 4430, loss = 0.00126147
Iteration 4431, loss = 0.00126111
Iteration 4432, loss = 0.00126067
Iteration 4433, loss = 0.00126040
Iteration 4434, loss = 0.00125995
Iteration 4435, loss = 0.00125957
Iteration 4436, loss = 0.00125922
Iteration 4437, loss = 0.00125879
Iteration 4438, loss = 0.00125845
Iteration 4439, loss = 0.00125809
Iteration 4440, loss = 0.00125778
Iteration 4441, loss = 0.00125741
Iteration 4442, loss = 0.00125694
Iteration 4443, loss = 0.00125680
Iteration 4444, loss = 0.00125621
Iteration 4445, loss = 0.00125583
Iteration 4446, loss = 0.00125554
Iteration 4447, loss = 0.00125507
Iteration 4448, loss = 0.00125469
Iteration 4449, loss = 0.00125436
Iteration 4450, loss = 0.00125401
Iteration 4451, loss = 0.00125361
Iteration 4452, loss = 0.00125321
Iteration 4453, loss = 0.00125286
Iteration 4454, loss = 0.00125253
Iteration 4455, loss = 0.00125211
Iteration 4456, loss = 0.00125175
Iteration 4457, loss = 0.00125138
Iteration 4458, loss = 0.00125102
Iteration 4459, loss = 0.00125074
Iteration 4460, loss = 0.00125027
Iteration 4461, loss = 0.00124989
Iteration 4462, loss = 0.00124958
Iteration 4463, loss = 0.00124921
Iteration 4464, loss = 0.00124891
Iteration 4465, loss = 0.00124843
Iteration 4466, loss = 0.00124813
Iteration 4467, loss = 0.00124772
Iteration 4468, loss = 0.00124739
Iteration 4469, loss = 0.00124702
Iteration 4470, loss = 0.00124662
Iteration 4471, loss = 0.00124628
Iteration 4472, loss = 0.00124594
Iteration 4473, loss = 0.00124558
Iteration 4474, loss = 0.00124527
Iteration 4475, loss = 0.00124485
Iteration 4476, loss = 0.00124449
Iteration 4477, loss = 0.00124412
Iteration 4478, loss = 0.00124374
Iteration 4479, loss = 0.00124342
Iteration 4480, loss = 0.00124302
Iteration 4481, loss = 0.00124265
Iteration 4482, loss = 0.00124229
Iteration 4483, loss = 0.00124201
Iteration 4484, loss = 0.00124156
Iteration 4485, loss = 0.00124121
Iteration 4486, loss = 0.00124085
Iteration 4487, loss = 0.00124051
Iteration 4488, loss = 0.00124017
Iteration 4489, loss = 0.00123980
Iteration 4490, loss = 0.00123942
Iteration 4491, loss = 0.00123911
Iteration 4492, loss = 0.00123874
Iteration 4493, loss = 0.00123831
Iteration 4494, loss = 0.00123797
Iteration 4495, loss = 0.00123757
Iteration 4496, loss = 0.00123721
Iteration 4497, loss = 0.00123689
Iteration 4498, loss = 0.00123651
Iteration 4499, loss = 0.00123615
Iteration 4500, loss = 0.00123580
Iteration 4501, loss = 0.00123551
Iteration 4502, loss = 0.00123508
Iteration 4503, loss = 0.00123471
Iteration 4504, loss = 0.00123435
Iteration 4505, loss = 0.00123402
Iteration 4506, loss = 0.00123365
Iteration 4507, loss = 0.00123326
Iteration 4508, loss = 0.00123295
Iteration 4509, loss = 0.00123257
Iteration 4510, loss = 0.00123220
Iteration 4511, loss = 0.00123185
Iteration 4512, loss = 0.00123147
Iteration 4513, loss = 0.00123111
Iteration 4514, loss = 0.00123074
Iteration 4515, loss = 0.00123043
Iteration 4516, loss = 0.00123005
Iteration 4517, loss = 0.00122972
Iteration 4518, loss = 0.00122934
Iteration 4519, loss = 0.00122898
Iteration 4520, loss = 0.00122865
Iteration 4521, loss = 0.00122831
Iteration 4522, loss = 0.00122801
Iteration 4523, loss = 0.00122757
Iteration 4524, loss = 0.00122731
Iteration 4525, loss = 0.00122695
Iteration 4526, loss = 0.00122652
Iteration 4527, loss = 0.00122618
Iteration 4528, loss = 0.00122584
Iteration 4529, loss = 0.00122545
Iteration 4530, loss = 0.00122515
Iteration 4531, loss = 0.00122472
Iteration 4532, loss = 0.00122435
Iteration 4533, loss = 0.00122417
Iteration 4534, loss = 0.00122362
Iteration 4535, loss = 0.00122330
Iteration 4536, loss = 0.00122289
Iteration 4537, loss = 0.00122258
Iteration 4538, loss = 0.00122221
Iteration 4539, loss = 0.00122183
Iteration 4540, loss = 0.00122153
Iteration 4541, loss = 0.00122109
Iteration 4542, loss = 0.00122079
Iteration 4543, loss = 0.00122048
Iteration 4544, loss = 0.00122009
Iteration 4545, loss = 0.00121982
Iteration 4546, loss = 0.00121947
Iteration 4547, loss = 0.00121904
Iteration 4548, loss = 0.00121867
Iteration 4549, loss = 0.00121840
Iteration 4550, loss = 0.00121804
Iteration 4551, loss = 0.00121760
Iteration 4552, loss = 0.00121729
Iteration 4553, loss = 0.00121693
Iteration 4554, loss = 0.00121658
Iteration 4555, loss = 0.00121624
Iteration 4556, loss = 0.00121591
Iteration 4557, loss = 0.00121558
Iteration 4558, loss = 0.00121515
Iteration 4559, loss = 0.00121488
Iteration 4560, loss = 0.00121448
Iteration 4561, loss = 0.00121407
Iteration 4562, loss = 0.00121375
Iteration 4563, loss = 0.00121338
Iteration 4564, loss = 0.00121304
Iteration 4565, loss = 0.00121267
Iteration 4566, loss = 0.00121230
Iteration 4567, loss = 0.00121205
Iteration 4568, loss = 0.00121159
Iteration 4569, loss = 0.00121127
Iteration 4570, loss = 0.00121094
Iteration 4571, loss = 0.00121059
Iteration 4572, loss = 0.00121030
Iteration 4573, loss = 0.00120988
Iteration 4574, loss = 0.00120956
Iteration 4575, loss = 0.00120923
Iteration 4576, loss = 0.00120894
Iteration 4577, loss = 0.00120852
Iteration 4578, loss = 0.00120816
Iteration 4579, loss = 0.00120781
Iteration 4580, loss = 0.00120748
Iteration 4581, loss = 0.00120715
Iteration 4582, loss = 0.00120678
Iteration 4583, loss = 0.00120649
Iteration 4584, loss = 0.00120609
Iteration 4585, loss = 0.00120579
Iteration 4586, loss = 0.00120540
Iteration 4587, loss = 0.00120508
Iteration 4588, loss = 0.00120476
Iteration 4589, loss = 0.00120441
Iteration 4590, loss = 0.00120408
Iteration 4591, loss = 0.00120375
Iteration 4592, loss = 0.00120338
Iteration 4593, loss = 0.00120311
Iteration 4594, loss = 0.00120274
Iteration 4595, loss = 0.00120234
Iteration 4596, loss = 0.00120203
Iteration 4597, loss = 0.00120169
Iteration 4598, loss = 0.00120132
Iteration 4599, loss = 0.00120099
Iteration 4600, loss = 0.00120063
Iteration 4601, loss = 0.00120037
Iteration 4602, loss = 0.00119996
Iteration 4603, loss = 0.00119964
Iteration 4604, loss = 0.00119935
Iteration 4605, loss = 0.00119905
Iteration 4606, loss = 0.00119864
Iteration 4607, loss = 0.00119831
Iteration 4608, loss = 0.00119798
Iteration 4609, loss = 0.00119765
Iteration 4610, loss = 0.00119733
Iteration 4611, loss = 0.00119696
Iteration 4612, loss = 0.00119659
Iteration 4613, loss = 0.00119631
Iteration 4614, loss = 0.00119596
Iteration 4615, loss = 0.00119560
Iteration 4616, loss = 0.00119522
Iteration 4617, loss = 0.00119492
Iteration 4618, loss = 0.00119462
Iteration 4619, loss = 0.00119428
Iteration 4620, loss = 0.00119386
Iteration 4621, loss = 0.00119361
Iteration 4622, loss = 0.00119330
Iteration 4623, loss = 0.00119289
Iteration 4624, loss = 0.00119257
Iteration 4625, loss = 0.00119228
Iteration 4626, loss = 0.00119185
Iteration 4627, loss = 0.00119161
Iteration 4628, loss = 0.00119123
Iteration 4629, loss = 0.00119100
Iteration 4630, loss = 0.00119053
Iteration 4631, loss = 0.00119023
Iteration 4632, loss = 0.00118986
Iteration 4633, loss = 0.00118958
Iteration 4634, loss = 0.00118922
Iteration 4635, loss = 0.00118890
Iteration 4636, loss = 0.00118855
Iteration 4637, loss = 0.00118828
Iteration 4638, loss = 0.00118793
Iteration 4639, loss = 0.00118753
Iteration 4640, loss = 0.00118725
Iteration 4641, loss = 0.00118691
Iteration 4642, loss = 0.00118660
Iteration 4643, loss = 0.00118624
Iteration 4644, loss = 0.00118590
Iteration 4645, loss = 0.00118557
Iteration 4646, loss = 0.00118529
Iteration 4647, loss = 0.00118496
Iteration 4648, loss = 0.00118459
Iteration 4649, loss = 0.00118427
Iteration 4650, loss = 0.00118398
Iteration 4651, loss = 0.00118354
Iteration 4652, loss = 0.00118325
Iteration 4653, loss = 0.00118289
Iteration 4654, loss = 0.00118263
Iteration 4655, loss = 0.00118241
Iteration 4656, loss = 0.00118189
Iteration 4657, loss = 0.00118167
Iteration 4658, loss = 0.00118123
Iteration 4659, loss = 0.00118095
Iteration 4660, loss = 0.00118057
Iteration 4661, loss = 0.00118026
Iteration 4662, loss = 0.00117991
Iteration 4663, loss = 0.00117966
Iteration 4664, loss = 0.00117926
Iteration 4665, loss = 0.00117891
Iteration 4666, loss = 0.00117859
Iteration 4667, loss = 0.00117832
Iteration 4668, loss = 0.00117802
Iteration 4669, loss = 0.00117759
Iteration 4670, loss = 0.00117735
Iteration 4671, loss = 0.00117698
Iteration 4672, loss = 0.00117668
Iteration 4673, loss = 0.00117628
Iteration 4674, loss = 0.00117599
Iteration 4675, loss = 0.00117571
Iteration 4676, loss = 0.00117532
Iteration 4677, loss = 0.00117502
Iteration 4678, loss = 0.00117474
Iteration 4679, loss = 0.00117432
Iteration 4680, loss = 0.00117399
Iteration 4681, loss = 0.00117364
Iteration 4682, loss = 0.00117337
Iteration 4683, loss = 0.00117297
Iteration 4684, loss = 0.00117272
Iteration 4685, loss = 0.00117238
Iteration 4686, loss = 0.00117199
Iteration 4687, loss = 0.00117167
Iteration 4688, loss = 0.00117143
Iteration 4689, loss = 0.00117106
Iteration 4690, loss = 0.00117072
Iteration 4691, loss = 0.00117045
Iteration 4692, loss = 0.00117008
Iteration 4693, loss = 0.00116977
Iteration 4694, loss = 0.00116942
Iteration 4695, loss = 0.00116917
Iteration 4696, loss = 0.00116883
Iteration 4697, loss = 0.00116848
Iteration 4698, loss = 0.00116819
Iteration 4699, loss = 0.00116788
Iteration 4700, loss = 0.00116755
Iteration 4701, loss = 0.00116719
Iteration 4702, loss = 0.00116689
Iteration 4703, loss = 0.00116654
Iteration 4704, loss = 0.00116623
Iteration 4705, loss = 0.00116588
Iteration 4706, loss = 0.00116565
Iteration 4707, loss = 0.00116528
Iteration 4708, loss = 0.00116496
Iteration 4709, loss = 0.00116464
Iteration 4710, loss = 0.00116437
Iteration 4711, loss = 0.00116397
Iteration 4712, loss = 0.00116367
Iteration 4713, loss = 0.00116346
Iteration 4714, loss = 0.00116305
Iteration 4715, loss = 0.00116269
Iteration 4716, loss = 0.00116239
Iteration 4717, loss = 0.00116208
Iteration 4718, loss = 0.00116171
Iteration 4719, loss = 0.00116141
Iteration 4720, loss = 0.00116110
Iteration 4721, loss = 0.00116085
Iteration 4722, loss = 0.00116044
Iteration 4723, loss = 0.00116019
Iteration 4724, loss = 0.00115981
Iteration 4725, loss = 0.00115948
Iteration 4726, loss = 0.00115921
Iteration 4727, loss = 0.00115882
Iteration 4728, loss = 0.00115849
Iteration 4729, loss = 0.00115822
Iteration 4730, loss = 0.00115786
Iteration 4731, loss = 0.00115760
Iteration 4732, loss = 0.00115723
Iteration 4733, loss = 0.00115693
Iteration 4734, loss = 0.00115663
Iteration 4735, loss = 0.00115642
Iteration 4736, loss = 0.00115595
Iteration 4737, loss = 0.00115566
Iteration 4738, loss = 0.00115537
Iteration 4739, loss = 0.00115506
Iteration 4740, loss = 0.00115476
Iteration 4741, loss = 0.00115441
Iteration 4742, loss = 0.00115412
Iteration 4743, loss = 0.00115381
Iteration 4744, loss = 0.00115350
Iteration 4745, loss = 0.00115314
Iteration 4746, loss = 0.00115283
Iteration 4747, loss = 0.00115259
Iteration 4748, loss = 0.00115223
Iteration 4749, loss = 0.00115188
Iteration 4750, loss = 0.00115159
Iteration 4751, loss = 0.00115130
Iteration 4752, loss = 0.00115097
Iteration 4753, loss = 0.00115065
Iteration 4754, loss = 0.00115035
Iteration 4755, loss = 0.00114997
Iteration 4756, loss = 0.00114966
Iteration 4757, loss = 0.00114942
Iteration 4758, loss = 0.00114910
Iteration 4759, loss = 0.00114880
Iteration 4760, loss = 0.00114851
Iteration 4761, loss = 0.00114810
Iteration 4762, loss = 0.00114792
Iteration 4763, loss = 0.00114749
Iteration 4764, loss = 0.00114719
Iteration 4765, loss = 0.00114695
Iteration 4766, loss = 0.00114654
Iteration 4767, loss = 0.00114620
Iteration 4768, loss = 0.00114594
Iteration 4769, loss = 0.00114565
Iteration 4770, loss = 0.00114533
Iteration 4771, loss = 0.00114491
Iteration 4772, loss = 0.00114461
Iteration 4773, loss = 0.00114429
Iteration 4774, loss = 0.00114400
Iteration 4775, loss = 0.00114373
Iteration 4776, loss = 0.00114342
Iteration 4777, loss = 0.00114304
Iteration 4778, loss = 0.00114272
Iteration 4779, loss = 0.00114244
Iteration 4780, loss = 0.00114219
Iteration 4781, loss = 0.00114179
Iteration 4782, loss = 0.00114151
Iteration 4783, loss = 0.00114119
Iteration 4784, loss = 0.00114089
Iteration 4785, loss = 0.00114059
Iteration 4786, loss = 0.00114028
Iteration 4787, loss = 0.00113994
Iteration 4788, loss = 0.00113968
Iteration 4789, loss = 0.00113931
Iteration 4790, loss = 0.00113904
Iteration 4791, loss = 0.00113864
Iteration 4792, loss = 0.00113835
Iteration 4793, loss = 0.00113804
Iteration 4794, loss = 0.00113771
Iteration 4795, loss = 0.00113742
Iteration 4796, loss = 0.00113716
Iteration 4797, loss = 0.00113681
Iteration 4798, loss = 0.00113645
Iteration 4799, loss = 0.00113613
Iteration 4800, loss = 0.00113582
Iteration 4801, loss = 0.00113552
Iteration 4802, loss = 0.00113520
Iteration 4803, loss = 0.00113487
Iteration 4804, loss = 0.00113459
Iteration 4805, loss = 0.00113438
Iteration 4806, loss = 0.00113397
Iteration 4807, loss = 0.00113364
Iteration 4808, loss = 0.00113335
Iteration 4809, loss = 0.00113305
Iteration 4810, loss = 0.00113270
Iteration 4811, loss = 0.00113240
Iteration 4812, loss = 0.00113214
Iteration 4813, loss = 0.00113184
Iteration 4814, loss = 0.00113145
Iteration 4815, loss = 0.00113118
Iteration 4816, loss = 0.00113082
Iteration 4817, loss = 0.00113050
Iteration 4818, loss = 0.00113021
Iteration 4819, loss = 0.00112991
Iteration 4820, loss = 0.00112962
Iteration 4821, loss = 0.00112932
Iteration 4822, loss = 0.00112903
Iteration 4823, loss = 0.00112873
Iteration 4824, loss = 0.00112844
Iteration 4825, loss = 0.00112808
Iteration 4826, loss = 0.00112777
Iteration 4827, loss = 0.00112749
Iteration 4828, loss = 0.00112723
Iteration 4829, loss = 0.00112689
Iteration 4830, loss = 0.00112654
Iteration 4831, loss = 0.00112627
Iteration 4832, loss = 0.00112601
Iteration 4833, loss = 0.00112565
Iteration 4834, loss = 0.00112541
Iteration 4835, loss = 0.00112515
Iteration 4836, loss = 0.00112480
Iteration 4837, loss = 0.00112443
Iteration 4838, loss = 0.00112417
Iteration 4839, loss = 0.00112383
Iteration 4840, loss = 0.00112355
Iteration 4841, loss = 0.00112324
Iteration 4842, loss = 0.00112290
Iteration 4843, loss = 0.00112264
Iteration 4844, loss = 0.00112240
Iteration 4845, loss = 0.00112203
Iteration 4846, loss = 0.00112177
Iteration 4847, loss = 0.00112145
Iteration 4848, loss = 0.00112115
Iteration 4849, loss = 0.00112085
Iteration 4850, loss = 0.00112056
Iteration 4851, loss = 0.00112026
Iteration 4852, loss = 0.00111998
Iteration 4853, loss = 0.00111966
Iteration 4854, loss = 0.00111937
Iteration 4855, loss = 0.00111911
Iteration 4856, loss = 0.00111879
Iteration 4857, loss = 0.00111843
Iteration 4858, loss = 0.00111816
Iteration 4859, loss = 0.00111785
Iteration 4860, loss = 0.00111753
Iteration 4861, loss = 0.00111727
Iteration 4862, loss = 0.00111690
Iteration 4863, loss = 0.00111660
Iteration 4864, loss = 0.00111634
Iteration 4865, loss = 0.00111597
Iteration 4866, loss = 0.00111567
Iteration 4867, loss = 0.00111541
Iteration 4868, loss = 0.00111504
Iteration 4869, loss = 0.00111474
Iteration 4870, loss = 0.00111445
Iteration 4871, loss = 0.00111412
Iteration 4872, loss = 0.00111388
Iteration 4873, loss = 0.00111350
Iteration 4874, loss = 0.00111320
Iteration 4875, loss = 0.00111289
Iteration 4876, loss = 0.00111261
Iteration 4877, loss = 0.00111233
Iteration 4878, loss = 0.00111200
Iteration 4879, loss = 0.00111173
Iteration 4880, loss = 0.00111146
Iteration 4881, loss = 0.00111113
Iteration 4882, loss = 0.00111081
Iteration 4883, loss = 0.00111048
Iteration 4884, loss = 0.00111017
Iteration 4885, loss = 0.00111002
Iteration 4886, loss = 0.00110962
Iteration 4887, loss = 0.00110932
Iteration 4888, loss = 0.00110907
Iteration 4889, loss = 0.00110873
Iteration 4890, loss = 0.00110843
Iteration 4891, loss = 0.00110810
Iteration 4892, loss = 0.00110785
Iteration 4893, loss = 0.00110750
Iteration 4894, loss = 0.00110726
Iteration 4895, loss = 0.00110693
Iteration 4896, loss = 0.00110666
Iteration 4897, loss = 0.00110635
Iteration 4898, loss = 0.00110602
Iteration 4899, loss = 0.00110571
Iteration 4900, loss = 0.00110544
Iteration 4901, loss = 0.00110507
Iteration 4902, loss = 0.00110479
Iteration 4903, loss = 0.00110455
Iteration 4904, loss = 0.00110422
Iteration 4905, loss = 0.00110394
Iteration 4906, loss = 0.00110366
Iteration 4907, loss = 0.00110340
Iteration 4908, loss = 0.00110315
Iteration 4909, loss = 0.00110274
Iteration 4910, loss = 0.00110243
Iteration 4911, loss = 0.00110214
Iteration 4912, loss = 0.00110190
Iteration 4913, loss = 0.00110156
Iteration 4914, loss = 0.00110133
Iteration 4915, loss = 0.00110104
Iteration 4916, loss = 0.00110077
Iteration 4917, loss = 0.00110046
Iteration 4918, loss = 0.00110019
Iteration 4919, loss = 0.00109988
Iteration 4920, loss = 0.00109956
Iteration 4921, loss = 0.00109927
Iteration 4922, loss = 0.00109904
Iteration 4923, loss = 0.00109867
Iteration 4924, loss = 0.00109839
Iteration 4925, loss = 0.00109809
Iteration 4926, loss = 0.00109783
Iteration 4927, loss = 0.00109753
Iteration 4928, loss = 0.00109729
Iteration 4929, loss = 0.00109695
Iteration 4930, loss = 0.00109666
Iteration 4931, loss = 0.00109637
Iteration 4932, loss = 0.00109608
Iteration 4933, loss = 0.00109579
Iteration 4934, loss = 0.00109550
Iteration 4935, loss = 0.00109526
Iteration 4936, loss = 0.00109492
Iteration 4937, loss = 0.00109467
Iteration 4938, loss = 0.00109437
Iteration 4939, loss = 0.00109404
Iteration 4940, loss = 0.00109386
Iteration 4941, loss = 0.00109350
Iteration 4942, loss = 0.00109321
Iteration 4943, loss = 0.00109292
Iteration 4944, loss = 0.00109262
Iteration 4945, loss = 0.00109230
Iteration 4946, loss = 0.00109196
Iteration 4947, loss = 0.00109170
Iteration 4948, loss = 0.00109155
Iteration 4949, loss = 0.00109111
Iteration 4950, loss = 0.00109083
Iteration 4951, loss = 0.00109058
Iteration 4952, loss = 0.00109027
Iteration 4953, loss = 0.00108999
Iteration 4954, loss = 0.00108969
Iteration 4955, loss = 0.00108941
Iteration 4956, loss = 0.00108916
Iteration 4957, loss = 0.00108881
Iteration 4958, loss = 0.00108856
Iteration 4959, loss = 0.00108826
Iteration 4960, loss = 0.00108797
Iteration 4961, loss = 0.00108767
Iteration 4962, loss = 0.00108741
Iteration 4963, loss = 0.00108707
Iteration 4964, loss = 0.00108685
Iteration 4965, loss = 0.00108657
Iteration 4966, loss = 0.00108623
Iteration 4967, loss = 0.00108593
Iteration 4968, loss = 0.00108572
Iteration 4969, loss = 0.00108537
Iteration 4970, loss = 0.00108511
Iteration 4971, loss = 0.00108481
Iteration 4972, loss = 0.00108462
Iteration 4973, loss = 0.00108426
Iteration 4974, loss = 0.00108399
Iteration 4975, loss = 0.00108373
Iteration 4976, loss = 0.00108341
Iteration 4977, loss = 0.00108315
Iteration 4978, loss = 0.00108288
Iteration 4979, loss = 0.00108259
Iteration 4980, loss = 0.00108228
Iteration 4981, loss = 0.00108202
Iteration 4982, loss = 0.00108172
Iteration 4983, loss = 0.00108148
Iteration 4984, loss = 0.00108114
Iteration 4985, loss = 0.00108095
Iteration 4986, loss = 0.00108058
Iteration 4987, loss = 0.00108032
Iteration 4988, loss = 0.00108003
Iteration 4989, loss = 0.00107973
Iteration 4990, loss = 0.00107952
Iteration 4991, loss = 0.00107917
Iteration 4992, loss = 0.00107889
Iteration 4993, loss = 0.00107863
Iteration 4994, loss = 0.00107832
Iteration 4995, loss = 0.00107803
Iteration 4996, loss = 0.00107778
Iteration 4997, loss = 0.00107749
Iteration 4998, loss = 0.00107721
Iteration 4999, loss = 0.00107695
Iteration 5000, loss = 0.00107666
Iteration 5001, loss = 0.00107639
Iteration 5002, loss = 0.00107609
Iteration 5003, loss = 0.00107579
Iteration 5004, loss = 0.00107553
Iteration 5005, loss = 0.00107522
Iteration 5006, loss = 0.00107497
Iteration 5007, loss = 0.00107464
Iteration 5008, loss = 0.00107438
Iteration 5009, loss = 0.00107414
Iteration 5010, loss = 0.00107382
Iteration 5011, loss = 0.00107355
Iteration 5012, loss = 0.00107328
Iteration 5013, loss = 0.00107299
Iteration 5014, loss = 0.00107273
Iteration 5015, loss = 0.00107244
Iteration 5016, loss = 0.00107219
Iteration 5017, loss = 0.00107190
Iteration 5018, loss = 0.00107168
Iteration 5019, loss = 0.00107135
Iteration 5020, loss = 0.00107104
Iteration 5021, loss = 0.00107079
Iteration 5022, loss = 0.00107055
Iteration 5023, loss = 0.00107026
Iteration 5024, loss = 0.00106996
Iteration 5025, loss = 0.00106968
Iteration 5026, loss = 0.00106939
Iteration 5027, loss = 0.00106912
Iteration 5028, loss = 0.00106887
Iteration 5029, loss = 0.00106858
Iteration 5030, loss = 0.00106829
Iteration 5031, loss = 0.00106800
Iteration 5032, loss = 0.00106772
Iteration 5033, loss = 0.00106748
Iteration 5034, loss = 0.00106719
Iteration 5035, loss = 0.00106697
Iteration 5036, loss = 0.00106671
Iteration 5037, loss = 0.00106641
Iteration 5038, loss = 0.00106613
Iteration 5039, loss = 0.00106586
Iteration 5040, loss = 0.00106561
Iteration 5041, loss = 0.00106531
Iteration 5042, loss = 0.00106504
Iteration 5043, loss = 0.00106477
Iteration 5044, loss = 0.00106451
Iteration 5045, loss = 0.00106426
Iteration 5046, loss = 0.00106398
Iteration 5047, loss = 0.00106367
Iteration 5048, loss = 0.00106343
Iteration 5049, loss = 0.00106312
Iteration 5050, loss = 0.00106288
Iteration 5051, loss = 0.00106261
Iteration 5052, loss = 0.00106231
Iteration 5053, loss = 0.00106207
Iteration 5054, loss = 0.00106175
Iteration 5055, loss = 0.00106153
Iteration 5056, loss = 0.00106118
Iteration 5057, loss = 0.00106100
Iteration 5058, loss = 0.00106063
Iteration 5059, loss = 0.00106037
Iteration 5060, loss = 0.00106014
Iteration 5061, loss = 0.00105982
Iteration 5062, loss = 0.00105954
Iteration 5063, loss = 0.00105927
Iteration 5064, loss = 0.00105899
Iteration 5065, loss = 0.00105870
Iteration 5066, loss = 0.00105843
Iteration 5067, loss = 0.00105816
Iteration 5068, loss = 0.00105788
Iteration 5069, loss = 0.00105763
Iteration 5070, loss = 0.00105737
Iteration 5071, loss = 0.00105709
Iteration 5072, loss = 0.00105676
Iteration 5073, loss = 0.00105656
Iteration 5074, loss = 0.00105627
Iteration 5075, loss = 0.00105601
Iteration 5076, loss = 0.00105571
Iteration 5077, loss = 0.00105544
Iteration 5078, loss = 0.00105519
Iteration 5079, loss = 0.00105488
Iteration 5080, loss = 0.00105463
Iteration 5081, loss = 0.00105436
Iteration 5082, loss = 0.00105407
Iteration 5083, loss = 0.00105386
Iteration 5084, loss = 0.00105363
Iteration 5085, loss = 0.00105330
Iteration 5086, loss = 0.00105303
Iteration 5087, loss = 0.00105273
Iteration 5088, loss = 0.00105247
Iteration 5089, loss = 0.00105224
Iteration 5090, loss = 0.00105194
Iteration 5091, loss = 0.00105176
Iteration 5092, loss = 0.00105144
Iteration 5093, loss = 0.00105110
Iteration 5094, loss = 0.00105086
Iteration 5095, loss = 0.00105057
Iteration 5096, loss = 0.00105033
Iteration 5097, loss = 0.00105002
Iteration 5098, loss = 0.00104973
Iteration 5099, loss = 0.00104950
Iteration 5100, loss = 0.00104925
Iteration 5101, loss = 0.00104894
Iteration 5102, loss = 0.00104871
Iteration 5103, loss = 0.00104843
Iteration 5104, loss = 0.00104813
Iteration 5105, loss = 0.00104784
Iteration 5106, loss = 0.00104755
Iteration 5107, loss = 0.00104739
Iteration 5108, loss = 0.00104710
Iteration 5109, loss = 0.00104677
Iteration 5110, loss = 0.00104652
Iteration 5111, loss = 0.00104629
Iteration 5112, loss = 0.00104603
Iteration 5113, loss = 0.00104573
Iteration 5114, loss = 0.00104546
Iteration 5115, loss = 0.00104519
Iteration 5116, loss = 0.00104497
Iteration 5117, loss = 0.00104465
Iteration 5118, loss = 0.00104440
Iteration 5119, loss = 0.00104417
Iteration 5120, loss = 0.00104393
Iteration 5121, loss = 0.00104364
Iteration 5122, loss = 0.00104339
Iteration 5123, loss = 0.00104312
Iteration 5124, loss = 0.00104286
Iteration 5125, loss = 0.00104257
Iteration 5126, loss = 0.00104234
Iteration 5127, loss = 0.00104208
Iteration 5128, loss = 0.00104185
Iteration 5129, loss = 0.00104154
Iteration 5130, loss = 0.00104125
Iteration 5131, loss = 0.00104102
Iteration 5132, loss = 0.00104077
Iteration 5133, loss = 0.00104048
Iteration 5134, loss = 0.00104025
Iteration 5135, loss = 0.00103993
Iteration 5136, loss = 0.00103967
Iteration 5137, loss = 0.00103942
Iteration 5138, loss = 0.00103916
Iteration 5139, loss = 0.00103885
Iteration 5140, loss = 0.00103868
Iteration 5141, loss = 0.00103837
Iteration 5142, loss = 0.00103811
Iteration 5143, loss = 0.00103786
Iteration 5144, loss = 0.00103764
Iteration 5145, loss = 0.00103731
Iteration 5146, loss = 0.00103706
Iteration 5147, loss = 0.00103679
Iteration 5148, loss = 0.00103654
Iteration 5149, loss = 0.00103629
Iteration 5150, loss = 0.00103608
Iteration 5151, loss = 0.00103579
Iteration 5152, loss = 0.00103548
Iteration 5153, loss = 0.00103522
Iteration 5154, loss = 0.00103496
Iteration 5155, loss = 0.00103472
Iteration 5156, loss = 0.00103445
Iteration 5157, loss = 0.00103417
Iteration 5158, loss = 0.00103398
Iteration 5159, loss = 0.00103374
Iteration 5160, loss = 0.00103346
Iteration 5161, loss = 0.00103316
Iteration 5162, loss = 0.00103288
Iteration 5163, loss = 0.00103267
Iteration 5164, loss = 0.00103239
Iteration 5165, loss = 0.00103222
Iteration 5166, loss = 0.00103187
Iteration 5167, loss = 0.00103157
Iteration 5168, loss = 0.00103131
Iteration 5169, loss = 0.00103106
Iteration 5170, loss = 0.00103079
Iteration 5171, loss = 0.00103054
Iteration 5172, loss = 0.00103030
Iteration 5173, loss = 0.00103003
Iteration 5174, loss = 0.00102979
Iteration 5175, loss = 0.00102953
Iteration 5176, loss = 0.00102924
Iteration 5177, loss = 0.00102904
Iteration 5178, loss = 0.00102874
Iteration 5179, loss = 0.00102846
Iteration 5180, loss = 0.00102819
Iteration 5181, loss = 0.00102798
Iteration 5182, loss = 0.00102769
Iteration 5183, loss = 0.00102745
Iteration 5184, loss = 0.00102720
Iteration 5185, loss = 0.00102700
Iteration 5186, loss = 0.00102666
Iteration 5187, loss = 0.00102638
Iteration 5188, loss = 0.00102608
Iteration 5189, loss = 0.00102586
Iteration 5190, loss = 0.00102555
Iteration 5191, loss = 0.00102524
Iteration 5192, loss = 0.00102500
Iteration 5193, loss = 0.00102470
Iteration 5194, loss = 0.00102442
Iteration 5195, loss = 0.00102413
Iteration 5196, loss = 0.00102387
Iteration 5197, loss = 0.00102361
Iteration 5198, loss = 0.00102337
Iteration 5199, loss = 0.00102311
Iteration 5200, loss = 0.00102279
Iteration 5201, loss = 0.00102254
Iteration 5202, loss = 0.00102223
Iteration 5203, loss = 0.00102194
Iteration 5204, loss = 0.00102170
Iteration 5205, loss = 0.00102146
Iteration 5206, loss = 0.00102118
Iteration 5207, loss = 0.00102085
Iteration 5208, loss = 0.00102059
Iteration 5209, loss = 0.00102031
Iteration 5210, loss = 0.00102010
Iteration 5211, loss = 0.00101981
Iteration 5212, loss = 0.00101954
Iteration 5213, loss = 0.00101932
Iteration 5214, loss = 0.00101899
Iteration 5215, loss = 0.00101872
Iteration 5216, loss = 0.00101849
Iteration 5217, loss = 0.00101820
Iteration 5218, loss = 0.00101797
Iteration 5219, loss = 0.00101767
Iteration 5220, loss = 0.00101738
Iteration 5221, loss = 0.00101712
Iteration 5222, loss = 0.00101686
Iteration 5223, loss = 0.00101659
Iteration 5224, loss = 0.00101631
Iteration 5225, loss = 0.00101599
Iteration 5226, loss = 0.00101572
Iteration 5227, loss = 0.00101542
Iteration 5228, loss = 0.00101520
Iteration 5229, loss = 0.00101495
Iteration 5230, loss = 0.00101467
Iteration 5231, loss = 0.00101435
Iteration 5232, loss = 0.00101410
Iteration 5233, loss = 0.00101379
Iteration 5234, loss = 0.00101360
Iteration 5235, loss = 0.00101324
Iteration 5236, loss = 0.00101296
Iteration 5237, loss = 0.00101272
Iteration 5238, loss = 0.00101244
Iteration 5239, loss = 0.00101220
Iteration 5240, loss = 0.00101192
Iteration 5241, loss = 0.00101160
Iteration 5242, loss = 0.00101133
Iteration 5243, loss = 0.00101108
Iteration 5244, loss = 0.00101077
Iteration 5245, loss = 0.00101049
Iteration 5246, loss = 0.00101024
Iteration 5247, loss = 0.00100995
Iteration 5248, loss = 0.00100967
Iteration 5249, loss = 0.00100943
Iteration 5250, loss = 0.00100913
Iteration 5251, loss = 0.00100884
Iteration 5252, loss = 0.00100861
Iteration 5253, loss = 0.00100836
Iteration 5254, loss = 0.00100805
Iteration 5255, loss = 0.00100780
Iteration 5256, loss = 0.00100750
Iteration 5257, loss = 0.00100723
Iteration 5258, loss = 0.00100698
Iteration 5259, loss = 0.00100671
Iteration 5260, loss = 0.00100653
Iteration 5261, loss = 0.00100621
Iteration 5262, loss = 0.00100589
Iteration 5263, loss = 0.00100567
Iteration 5264, loss = 0.00100538
Iteration 5265, loss = 0.00100515
Iteration 5266, loss = 0.00100486
Iteration 5267, loss = 0.00100459
Iteration 5268, loss = 0.00100437
Iteration 5269, loss = 0.00100407
Iteration 5270, loss = 0.00100378
Iteration 5271, loss = 0.00100355
Iteration 5272, loss = 0.00100332
Iteration 5273, loss = 0.00100308
Iteration 5274, loss = 0.00100282
Iteration 5275, loss = 0.00100253
Iteration 5276, loss = 0.00100230
Iteration 5277, loss = 0.00100199
Iteration 5278, loss = 0.00100171
Iteration 5279, loss = 0.00100141
Iteration 5280, loss = 0.00100122
Iteration 5281, loss = 0.00100094
Iteration 5282, loss = 0.00100062
Iteration 5283, loss = 0.00100038
Iteration 5284, loss = 0.00100009
Iteration 5285, loss = 0.00099984
Iteration 5286, loss = 0.00099961
Iteration 5287, loss = 0.00099936
Iteration 5288, loss = 0.00099907
Iteration 5289, loss = 0.00099883
Iteration 5290, loss = 0.00099856
Iteration 5291, loss = 0.00099826
Iteration 5292, loss = 0.00099808
Iteration 5293, loss = 0.00099776
Iteration 5294, loss = 0.00099749
Iteration 5295, loss = 0.00099723
Iteration 5296, loss = 0.00099701
Iteration 5297, loss = 0.00099677
Iteration 5298, loss = 0.00099646
Iteration 5299, loss = 0.00099620
Iteration 5300, loss = 0.00099596
Iteration 5301, loss = 0.00099569
Iteration 5302, loss = 0.00099544
Iteration 5303, loss = 0.00099518
Iteration 5304, loss = 0.00099495
Iteration 5305, loss = 0.00099472
Iteration 5306, loss = 0.00099447
Iteration 5307, loss = 0.00099419
Iteration 5308, loss = 0.00099396
Iteration 5309, loss = 0.00099368
Iteration 5310, loss = 0.00099344
Iteration 5311, loss = 0.00099318
Iteration 5312, loss = 0.00099293
Iteration 5313, loss = 0.00099267
Iteration 5314, loss = 0.00099240
Iteration 5315, loss = 0.00099216
Iteration 5316, loss = 0.00099189
Iteration 5317, loss = 0.00099165
Iteration 5318, loss = 0.00099137
Iteration 5319, loss = 0.00099112
Iteration 5320, loss = 0.00099091
Iteration 5321, loss = 0.00099062
Iteration 5322, loss = 0.00099037
Iteration 5323, loss = 0.00099012
Iteration 5324, loss = 0.00098987
Iteration 5325, loss = 0.00098964
Iteration 5326, loss = 0.00098937
Iteration 5327, loss = 0.00098911
Iteration 5328, loss = 0.00098888
Iteration 5329, loss = 0.00098856
Iteration 5330, loss = 0.00098833
Iteration 5331, loss = 0.00098807
Iteration 5332, loss = 0.00098788
Iteration 5333, loss = 0.00098756
Iteration 5334, loss = 0.00098736
Iteration 5335, loss = 0.00098712
Iteration 5336, loss = 0.00098686
Iteration 5337, loss = 0.00098664
Iteration 5338, loss = 0.00098635
Iteration 5339, loss = 0.00098611
Iteration 5340, loss = 0.00098586
Iteration 5341, loss = 0.00098558
Iteration 5342, loss = 0.00098533
Iteration 5343, loss = 0.00098509
Iteration 5344, loss = 0.00098482
Iteration 5345, loss = 0.00098459
Iteration 5346, loss = 0.00098432
Iteration 5347, loss = 0.00098409
Iteration 5348, loss = 0.00098385
Iteration 5349, loss = 0.00098361
Iteration 5350, loss = 0.00098334
Iteration 5351, loss = 0.00098313
Iteration 5352, loss = 0.00098285
Iteration 5353, loss = 0.00098256
Iteration 5354, loss = 0.00098226
Iteration 5355, loss = 0.00098206
Iteration 5356, loss = 0.00098178
Iteration 5357, loss = 0.00098154
Iteration 5358, loss = 0.00098129
Iteration 5359, loss = 0.00098101
Iteration 5360, loss = 0.00098073
Iteration 5361, loss = 0.00098055
Iteration 5362, loss = 0.00098028
Iteration 5363, loss = 0.00098002
Iteration 5364, loss = 0.00097975
Iteration 5365, loss = 0.00097954
Iteration 5366, loss = 0.00097926
Iteration 5367, loss = 0.00097904
Iteration 5368, loss = 0.00097881
Iteration 5369, loss = 0.00097856
Iteration 5370, loss = 0.00097826
Iteration 5371, loss = 0.00097807
Iteration 5372, loss = 0.00097780
Iteration 5373, loss = 0.00097759
Iteration 5374, loss = 0.00097732
Iteration 5375, loss = 0.00097707
Iteration 5376, loss = 0.00097680
Iteration 5377, loss = 0.00097662
Iteration 5378, loss = 0.00097634
Iteration 5379, loss = 0.00097608
Iteration 5380, loss = 0.00097589
Iteration 5381, loss = 0.00097561
Iteration 5382, loss = 0.00097542
Iteration 5383, loss = 0.00097510
Iteration 5384, loss = 0.00097487
Iteration 5385, loss = 0.00097461
Iteration 5386, loss = 0.00097440
Iteration 5387, loss = 0.00097414
Iteration 5388, loss = 0.00097389
Iteration 5389, loss = 0.00097368
Iteration 5390, loss = 0.00097342
Iteration 5391, loss = 0.00097321
Iteration 5392, loss = 0.00097294
Iteration 5393, loss = 0.00097272
Iteration 5394, loss = 0.00097250
Iteration 5395, loss = 0.00097217
Iteration 5396, loss = 0.00097197
Iteration 5397, loss = 0.00097170
Iteration 5398, loss = 0.00097142
Iteration 5399, loss = 0.00097121
Iteration 5400, loss = 0.00097096
Iteration 5401, loss = 0.00097070
Iteration 5402, loss = 0.00097051
Iteration 5403, loss = 0.00097028
Iteration 5404, loss = 0.00097000
Iteration 5405, loss = 0.00096973
Iteration 5406, loss = 0.00096950
Iteration 5407, loss = 0.00096927
Iteration 5408, loss = 0.00096904
Iteration 5409, loss = 0.00096882
Iteration 5410, loss = 0.00096852
Iteration 5411, loss = 0.00096829
Iteration 5412, loss = 0.00096804
Iteration 5413, loss = 0.00096784
Iteration 5414, loss = 0.00096755
Iteration 5415, loss = 0.00096734
Iteration 5416, loss = 0.00096707
Iteration 5417, loss = 0.00096689
Iteration 5418, loss = 0.00096664
Iteration 5419, loss = 0.00096638
Iteration 5420, loss = 0.00096618
Iteration 5421, loss = 0.00096591
Iteration 5422, loss = 0.00096564
Iteration 5423, loss = 0.00096540
Iteration 5424, loss = 0.00096517
Iteration 5425, loss = 0.00096496
Iteration 5426, loss = 0.00096468
Iteration 5427, loss = 0.00096445
Iteration 5428, loss = 0.00096424
Iteration 5429, loss = 0.00096398
Iteration 5430, loss = 0.00096369
Iteration 5431, loss = 0.00096353
Iteration 5432, loss = 0.00096326
Iteration 5433, loss = 0.00096300
Iteration 5434, loss = 0.00096280
Iteration 5435, loss = 0.00096252
Iteration 5436, loss = 0.00096229
Iteration 5437, loss = 0.00096202
Iteration 5438, loss = 0.00096177
Iteration 5439, loss = 0.00096156
Iteration 5440, loss = 0.00096130
Iteration 5441, loss = 0.00096105
Iteration 5442, loss = 0.00096081
Iteration 5443, loss = 0.00096058
Iteration 5444, loss = 0.00096033
Iteration 5445, loss = 0.00096016
Iteration 5446, loss = 0.00095984
Iteration 5447, loss = 0.00095960
Iteration 5448, loss = 0.00095938
Iteration 5449, loss = 0.00095913
Iteration 5450, loss = 0.00095889
Iteration 5451, loss = 0.00095862
Iteration 5452, loss = 0.00095844
Iteration 5453, loss = 0.00095817
Iteration 5454, loss = 0.00095789
Iteration 5455, loss = 0.00095768
Iteration 5456, loss = 0.00095742
Iteration 5457, loss = 0.00095721
Iteration 5458, loss = 0.00095699
Iteration 5459, loss = 0.00095678
Iteration 5460, loss = 0.00095651
Iteration 5461, loss = 0.00095624
Iteration 5462, loss = 0.00095605
Iteration 5463, loss = 0.00095576
Iteration 5464, loss = 0.00095552
Iteration 5465, loss = 0.00095536
Iteration 5466, loss = 0.00095510
Iteration 5467, loss = 0.00095482
Iteration 5468, loss = 0.00095462
Iteration 5469, loss = 0.00095440
Iteration 5470, loss = 0.00095413
Iteration 5471, loss = 0.00095388
Iteration 5472, loss = 0.00095367
Iteration 5473, loss = 0.00095339
Iteration 5474, loss = 0.00095317
Iteration 5475, loss = 0.00095292
Iteration 5476, loss = 0.00095271
Iteration 5477, loss = 0.00095244
Iteration 5478, loss = 0.00095219
Iteration 5479, loss = 0.00095195
Iteration 5480, loss = 0.00095169
Iteration 5481, loss = 0.00095144
Iteration 5482, loss = 0.00095123
Iteration 5483, loss = 0.00095094
Iteration 5484, loss = 0.00095074
Iteration 5485, loss = 0.00095047
Iteration 5486, loss = 0.00095026
Iteration 5487, loss = 0.00095001
Iteration 5488, loss = 0.00094975
Iteration 5489, loss = 0.00094958
Iteration 5490, loss = 0.00094932
Iteration 5491, loss = 0.00094909
Iteration 5492, loss = 0.00094902
Iteration 5493, loss = 0.00094862
Iteration 5494, loss = 0.00094841
Iteration 5495, loss = 0.00094814
Iteration 5496, loss = 0.00094793
Iteration 5497, loss = 0.00094775
Iteration 5498, loss = 0.00094747
Iteration 5499, loss = 0.00094724
Iteration 5500, loss = 0.00094701
Iteration 5501, loss = 0.00094681
Iteration 5502, loss = 0.00094655
Iteration 5503, loss = 0.00094630
Iteration 5504, loss = 0.00094608
Iteration 5505, loss = 0.00094588
Iteration 5506, loss = 0.00094566
Iteration 5507, loss = 0.00094541
Iteration 5508, loss = 0.00094517
Iteration 5509, loss = 0.00094489
Iteration 5510, loss = 0.00094469
Iteration 5511, loss = 0.00094449
Iteration 5512, loss = 0.00094427
Iteration 5513, loss = 0.00094404
Iteration 5514, loss = 0.00094379
Iteration 5515, loss = 0.00094353
Iteration 5516, loss = 0.00094334
Iteration 5517, loss = 0.00094308
Iteration 5518, loss = 0.00094288
Iteration 5519, loss = 0.00094262
Iteration 5520, loss = 0.00094244
Iteration 5521, loss = 0.00094216
Iteration 5522, loss = 0.00094195
Iteration 5523, loss = 0.00094169
Iteration 5524, loss = 0.00094143
Iteration 5525, loss = 0.00094124
Iteration 5526, loss = 0.00094102
Iteration 5527, loss = 0.00094076
Iteration 5528, loss = 0.00094057
Iteration 5529, loss = 0.00094036
Iteration 5530, loss = 0.00094009
Iteration 5531, loss = 0.00093984
Iteration 5532, loss = 0.00093965
Iteration 5533, loss = 0.00093941
Iteration 5534, loss = 0.00093923
Iteration 5535, loss = 0.00093899
Iteration 5536, loss = 0.00093870
Iteration 5537, loss = 0.00093847
Iteration 5538, loss = 0.00093825
Iteration 5539, loss = 0.00093802
Iteration 5540, loss = 0.00093777
Iteration 5541, loss = 0.00093753
Iteration 5542, loss = 0.00093730
Iteration 5543, loss = 0.00093709
Iteration 5544, loss = 0.00093683
Iteration 5545, loss = 0.00093661
Iteration 5546, loss = 0.00093638
Iteration 5547, loss = 0.00093616
Iteration 5548, loss = 0.00093592
Iteration 5549, loss = 0.00093572
Iteration 5550, loss = 0.00093548
Iteration 5551, loss = 0.00093527
Iteration 5552, loss = 0.00093503
Iteration 5553, loss = 0.00093478
Iteration 5554, loss = 0.00093458
Iteration 5555, loss = 0.00093439
Iteration 5556, loss = 0.00093417
Iteration 5557, loss = 0.00093389
Iteration 5558, loss = 0.00093366
Iteration 5559, loss = 0.00093347
Iteration 5560, loss = 0.00093321
Iteration 5561, loss = 0.00093297
Iteration 5562, loss = 0.00093276
Iteration 5563, loss = 0.00093252
Iteration 5564, loss = 0.00093236
Iteration 5565, loss = 0.00093214
Iteration 5566, loss = 0.00093185
Iteration 5567, loss = 0.00093167
Iteration 5568, loss = 0.00093141
Iteration 5569, loss = 0.00093120
Iteration 5570, loss = 0.00093097
Iteration 5571, loss = 0.00093073
Iteration 5572, loss = 0.00093053
Iteration 5573, loss = 0.00093033
Iteration 5574, loss = 0.00093007
Iteration 5575, loss = 0.00092985
Iteration 5576, loss = 0.00092964
Iteration 5577, loss = 0.00092939
Iteration 5578, loss = 0.00092923
Iteration 5579, loss = 0.00092897
Iteration 5580, loss = 0.00092873
Iteration 5581, loss = 0.00092852
Iteration 5582, loss = 0.00092833
Iteration 5583, loss = 0.00092807
Iteration 5584, loss = 0.00092783
Iteration 5585, loss = 0.00092764
Iteration 5586, loss = 0.00092742
Iteration 5587, loss = 0.00092719
Iteration 5588, loss = 0.00092695
Iteration 5589, loss = 0.00092671
Iteration 5590, loss = 0.00092650
Iteration 5591, loss = 0.00092626
Iteration 5592, loss = 0.00092604
Iteration 5593, loss = 0.00092583
Iteration 5594, loss = 0.00092562
Iteration 5595, loss = 0.00092542
Iteration 5596, loss = 0.00092516
Iteration 5597, loss = 0.00092495
Iteration 5598, loss = 0.00092471
Iteration 5599, loss = 0.00092449
Iteration 5600, loss = 0.00092431
Iteration 5601, loss = 0.00092407
Iteration 5602, loss = 0.00092385
Iteration 5603, loss = 0.00092364
Iteration 5604, loss = 0.00092341
Iteration 5605, loss = 0.00092321
Iteration 5606, loss = 0.00092297
Iteration 5607, loss = 0.00092278
Iteration 5608, loss = 0.00092254
Iteration 5609, loss = 0.00092232
Iteration 5610, loss = 0.00092210
Iteration 5611, loss = 0.00092187
Iteration 5612, loss = 0.00092166
Iteration 5613, loss = 0.00092144
Iteration 5614, loss = 0.00092121
Iteration 5615, loss = 0.00092098
Iteration 5616, loss = 0.00092077
Iteration 5617, loss = 0.00092054
Iteration 5618, loss = 0.00092031
Iteration 5619, loss = 0.00092006
Iteration 5620, loss = 0.00091982
Iteration 5621, loss = 0.00091962
Iteration 5622, loss = 0.00091942
Iteration 5623, loss = 0.00091917
Iteration 5624, loss = 0.00091895
Iteration 5625, loss = 0.00091874
Iteration 5626, loss = 0.00091854
Iteration 5627, loss = 0.00091831
Iteration 5628, loss = 0.00091803
Iteration 5629, loss = 0.00091781
Iteration 5630, loss = 0.00091760
Iteration 5631, loss = 0.00091741
Iteration 5632, loss = 0.00091717
Iteration 5633, loss = 0.00091696
Iteration 5634, loss = 0.00091682
Iteration 5635, loss = 0.00091655
Iteration 5636, loss = 0.00091627
Iteration 5637, loss = 0.00091614
Iteration 5638, loss = 0.00091584
Iteration 5639, loss = 0.00091561
Iteration 5640, loss = 0.00091539
Iteration 5641, loss = 0.00091517
Iteration 5642, loss = 0.00091495
Iteration 5643, loss = 0.00091473
Iteration 5644, loss = 0.00091459
Iteration 5645, loss = 0.00091432
Iteration 5646, loss = 0.00091401
Iteration 5647, loss = 0.00091384
Iteration 5648, loss = 0.00091363
Iteration 5649, loss = 0.00091343
Iteration 5650, loss = 0.00091317
Iteration 5651, loss = 0.00091294
Iteration 5652, loss = 0.00091274
Iteration 5653, loss = 0.00091251
Iteration 5654, loss = 0.00091230
Iteration 5655, loss = 0.00091207
Iteration 5656, loss = 0.00091185
Iteration 5657, loss = 0.00091166
Iteration 5658, loss = 0.00091140
Iteration 5659, loss = 0.00091125
Iteration 5660, loss = 0.00091099
Iteration 5661, loss = 0.00091077
Iteration 5662, loss = 0.00091059
Iteration 5663, loss = 0.00091035
Iteration 5664, loss = 0.00091016
Iteration 5665, loss = 0.00090992
Iteration 5666, loss = 0.00090971
Iteration 5667, loss = 0.00090950
Iteration 5668, loss = 0.00090931
Iteration 5669, loss = 0.00090908
Iteration 5670, loss = 0.00090889
Iteration 5671, loss = 0.00090864
Iteration 5672, loss = 0.00090844
Iteration 5673, loss = 0.00090822
Iteration 5674, loss = 0.00090801
Iteration 5675, loss = 0.00090777
Iteration 5676, loss = 0.00090754
Iteration 5677, loss = 0.00090733
Iteration 5678, loss = 0.00090714
Iteration 5679, loss = 0.00090693
Iteration 5680, loss = 0.00090670
Iteration 5681, loss = 0.00090653
Iteration 5682, loss = 0.00090629
Iteration 5683, loss = 0.00090608
Iteration 5684, loss = 0.00090587
Iteration 5685, loss = 0.00090570
Iteration 5686, loss = 0.00090542
Iteration 5687, loss = 0.00090522
Iteration 5688, loss = 0.00090500
Iteration 5689, loss = 0.00090480
Iteration 5690, loss = 0.00090456
Iteration 5691, loss = 0.00090436
Iteration 5692, loss = 0.00090416
Iteration 5693, loss = 0.00090395
Iteration 5694, loss = 0.00090372
Iteration 5695, loss = 0.00090356
Iteration 5696, loss = 0.00090333
Iteration 5697, loss = 0.00090310
Iteration 5698, loss = 0.00090288
Iteration 5699, loss = 0.00090268
Iteration 5700, loss = 0.00090247
Iteration 5701, loss = 0.00090229
Iteration 5702, loss = 0.00090204
Iteration 5703, loss = 0.00090183
Iteration 5704, loss = 0.00090164
Iteration 5705, loss = 0.00090143
Iteration 5706, loss = 0.00090120
Iteration 5707, loss = 0.00090098
Iteration 5708, loss = 0.00090077
Iteration 5709, loss = 0.00090055
Iteration 5710, loss = 0.00090037
Iteration 5711, loss = 0.00090016
Iteration 5712, loss = 0.00089995
Iteration 5713, loss = 0.00089968
Iteration 5714, loss = 0.00089954
Iteration 5715, loss = 0.00089933
Iteration 5716, loss = 0.00089907
Iteration 5717, loss = 0.00089885
Iteration 5718, loss = 0.00089863
Iteration 5719, loss = 0.00089842
Iteration 5720, loss = 0.00089821
Iteration 5721, loss = 0.00089800
Iteration 5722, loss = 0.00089777
Iteration 5723, loss = 0.00089758
Iteration 5724, loss = 0.00089739
Iteration 5725, loss = 0.00089718
Iteration 5726, loss = 0.00089695
Iteration 5727, loss = 0.00089675
Iteration 5728, loss = 0.00089653
Iteration 5729, loss = 0.00089634
Iteration 5730, loss = 0.00089610
Iteration 5731, loss = 0.00089594
Iteration 5732, loss = 0.00089574
Iteration 5733, loss = 0.00089546
Iteration 5734, loss = 0.00089534
Iteration 5735, loss = 0.00089509
Iteration 5736, loss = 0.00089487
Iteration 5737, loss = 0.00089470
Iteration 5738, loss = 0.00089443
Iteration 5739, loss = 0.00089425
Iteration 5740, loss = 0.00089404
Iteration 5741, loss = 0.00089380
Iteration 5742, loss = 0.00089359
Iteration 5743, loss = 0.00089342
Iteration 5744, loss = 0.00089319
Iteration 5745, loss = 0.00089301
Iteration 5746, loss = 0.00089276
Iteration 5747, loss = 0.00089255
Iteration 5748, loss = 0.00089232
Iteration 5749, loss = 0.00089216
Iteration 5750, loss = 0.00089193
Iteration 5751, loss = 0.00089171
Iteration 5752, loss = 0.00089156
Iteration 5753, loss = 0.00089130
Iteration 5754, loss = 0.00089109
Iteration 5755, loss = 0.00089092
Iteration 5756, loss = 0.00089069
Iteration 5757, loss = 0.00089047
Iteration 5758, loss = 0.00089027
Iteration 5759, loss = 0.00089005
Iteration 5760, loss = 0.00088984
Iteration 5761, loss = 0.00088959
Iteration 5762, loss = 0.00088943
Iteration 5763, loss = 0.00088917
Iteration 5764, loss = 0.00088899
Iteration 5765, loss = 0.00088877
Iteration 5766, loss = 0.00088855
Iteration 5767, loss = 0.00088834
Iteration 5768, loss = 0.00088816
Iteration 5769, loss = 0.00088794
Iteration 5770, loss = 0.00088772
Iteration 5771, loss = 0.00088752
Iteration 5772, loss = 0.00088732
Iteration 5773, loss = 0.00088711
Iteration 5774, loss = 0.00088689
Iteration 5775, loss = 0.00088671
Iteration 5776, loss = 0.00088652
Iteration 5777, loss = 0.00088633
Iteration 5778, loss = 0.00088608
Iteration 5779, loss = 0.00088589
Iteration 5780, loss = 0.00088567
Iteration 5781, loss = 0.00088545
Iteration 5782, loss = 0.00088526
Iteration 5783, loss = 0.00088502
Iteration 5784, loss = 0.00088486
Iteration 5785, loss = 0.00088464
Iteration 5786, loss = 0.00088447
Iteration 5787, loss = 0.00088424
Iteration 5788, loss = 0.00088402
Iteration 5789, loss = 0.00088380
Iteration 5790, loss = 0.00088359
Iteration 5791, loss = 0.00088342
Iteration 5792, loss = 0.00088321
Iteration 5793, loss = 0.00088297
Iteration 5794, loss = 0.00088280
Iteration 5795, loss = 0.00088261
Iteration 5796, loss = 0.00088242
Iteration 5797, loss = 0.00088223
Iteration 5798, loss = 0.00088204
Iteration 5799, loss = 0.00088180
Iteration 5800, loss = 0.00088160
Iteration 5801, loss = 0.00088137
Iteration 5802, loss = 0.00088122
Iteration 5803, loss = 0.00088100
Iteration 5804, loss = 0.00088079
Iteration 5805, loss = 0.00088061
Iteration 5806, loss = 0.00088040
Iteration 5807, loss = 0.00088017
Iteration 5808, loss = 0.00087998
Iteration 5809, loss = 0.00087980
Iteration 5810, loss = 0.00087963
Iteration 5811, loss = 0.00087939
Iteration 5812, loss = 0.00087916
Iteration 5813, loss = 0.00087900
Iteration 5814, loss = 0.00087880
Iteration 5815, loss = 0.00087862
Iteration 5816, loss = 0.00087838
Iteration 5817, loss = 0.00087819
Iteration 5818, loss = 0.00087798
Iteration 5819, loss = 0.00087779
Iteration 5820, loss = 0.00087759
Iteration 5821, loss = 0.00087738
Iteration 5822, loss = 0.00087719
Iteration 5823, loss = 0.00087703
Iteration 5824, loss = 0.00087679
Iteration 5825, loss = 0.00087662
Iteration 5826, loss = 0.00087641
Iteration 5827, loss = 0.00087618
Iteration 5828, loss = 0.00087597
Iteration 5829, loss = 0.00087578
Iteration 5830, loss = 0.00087556
Iteration 5831, loss = 0.00087542
Iteration 5832, loss = 0.00087518
Iteration 5833, loss = 0.00087497
Iteration 5834, loss = 0.00087479
Iteration 5835, loss = 0.00087458
Iteration 5836, loss = 0.00087438
Iteration 5837, loss = 0.00087417
Iteration 5838, loss = 0.00087401
Iteration 5839, loss = 0.00087382
Iteration 5840, loss = 0.00087361
Iteration 5841, loss = 0.00087341
Iteration 5842, loss = 0.00087319
Iteration 5843, loss = 0.00087300
Iteration 5844, loss = 0.00087282
Iteration 5845, loss = 0.00087259
Iteration 5846, loss = 0.00087239
Iteration 5847, loss = 0.00087218
Iteration 5848, loss = 0.00087199
Iteration 5849, loss = 0.00087178
Iteration 5850, loss = 0.00087160
Iteration 5851, loss = 0.00087139
Iteration 5852, loss = 0.00087120
Iteration 5853, loss = 0.00087103
Iteration 5854, loss = 0.00087082
Iteration 5855, loss = 0.00087060
Iteration 5856, loss = 0.00087041
Iteration 5857, loss = 0.00087019
Iteration 5858, loss = 0.00087002
Iteration 5859, loss = 0.00086982
Iteration 5860, loss = 0.00086963
Iteration 5861, loss = 0.00086943
Iteration 5862, loss = 0.00086924
Iteration 5863, loss = 0.00086903
Iteration 5864, loss = 0.00086889
Iteration 5865, loss = 0.00086867
Iteration 5866, loss = 0.00086846
Iteration 5867, loss = 0.00086829
Iteration 5868, loss = 0.00086806
Iteration 5869, loss = 0.00086785
Iteration 5870, loss = 0.00086768
Iteration 5871, loss = 0.00086747
Iteration 5872, loss = 0.00086727
Iteration 5873, loss = 0.00086707
Iteration 5874, loss = 0.00086689
Iteration 5875, loss = 0.00086671
Iteration 5876, loss = 0.00086649
Iteration 5877, loss = 0.00086629
Iteration 5878, loss = 0.00086609
Iteration 5879, loss = 0.00086593
Iteration 5880, loss = 0.00086570
Iteration 5881, loss = 0.00086550
Iteration 5882, loss = 0.00086527
Iteration 5883, loss = 0.00086508
Iteration 5884, loss = 0.00086490
Iteration 5885, loss = 0.00086470
Iteration 5886, loss = 0.00086450
Iteration 5887, loss = 0.00086434
Iteration 5888, loss = 0.00086412
Iteration 5889, loss = 0.00086393
Iteration 5890, loss = 0.00086376
Iteration 5891, loss = 0.00086352
Iteration 5892, loss = 0.00086331
Iteration 5893, loss = 0.00086320
Iteration 5894, loss = 0.00086300
Iteration 5895, loss = 0.00086283
Iteration 5896, loss = 0.00086254
Iteration 5897, loss = 0.00086236
Iteration 5898, loss = 0.00086225
Iteration 5899, loss = 0.00086196
Iteration 5900, loss = 0.00086178
Iteration 5901, loss = 0.00086157
Iteration 5902, loss = 0.00086135
Iteration 5903, loss = 0.00086116
Iteration 5904, loss = 0.00086097
Iteration 5905, loss = 0.00086079
Iteration 5906, loss = 0.00086061
Iteration 5907, loss = 0.00086041
Iteration 5908, loss = 0.00086022
Iteration 5909, loss = 0.00086005
Iteration 5910, loss = 0.00085986
Iteration 5911, loss = 0.00085963
Iteration 5912, loss = 0.00085947
Iteration 5913, loss = 0.00085925
Iteration 5914, loss = 0.00085908
Iteration 5915, loss = 0.00085887
Iteration 5916, loss = 0.00085868
Iteration 5917, loss = 0.00085854
Iteration 5918, loss = 0.00085831
Iteration 5919, loss = 0.00085812
Iteration 5920, loss = 0.00085793
Iteration 5921, loss = 0.00085775
Iteration 5922, loss = 0.00085754
Iteration 5923, loss = 0.00085738
Iteration 5924, loss = 0.00085720
Iteration 5925, loss = 0.00085698
Iteration 5926, loss = 0.00085680
Iteration 5927, loss = 0.00085663
Iteration 5928, loss = 0.00085640
Iteration 5929, loss = 0.00085625
Iteration 5930, loss = 0.00085602
Iteration 5931, loss = 0.00085587
Iteration 5932, loss = 0.00085567
Iteration 5933, loss = 0.00085549
Iteration 5934, loss = 0.00085529
Iteration 5935, loss = 0.00085517
Iteration 5936, loss = 0.00085491
Iteration 5937, loss = 0.00085474
Iteration 5938, loss = 0.00085455
Iteration 5939, loss = 0.00085436
Iteration 5940, loss = 0.00085417
Iteration 5941, loss = 0.00085397
Iteration 5942, loss = 0.00085382
Iteration 5943, loss = 0.00085363
Iteration 5944, loss = 0.00085340
Iteration 5945, loss = 0.00085321
Iteration 5946, loss = 0.00085305
Iteration 5947, loss = 0.00085288
Iteration 5948, loss = 0.00085265
Iteration 5949, loss = 0.00085248
Iteration 5950, loss = 0.00085230
Iteration 5951, loss = 0.00085211
Iteration 5952, loss = 0.00085193
Iteration 5953, loss = 0.00085170
Iteration 5954, loss = 0.00085155
Iteration 5955, loss = 0.00085137
Iteration 5956, loss = 0.00085119
Iteration 5957, loss = 0.00085099
Iteration 5958, loss = 0.00085080
Iteration 5959, loss = 0.00085067
Iteration 5960, loss = 0.00085045
Iteration 5961, loss = 0.00085025
Iteration 5962, loss = 0.00085003
Iteration 5963, loss = 0.00084986
Iteration 5964, loss = 0.00084970
Iteration 5965, loss = 0.00084947
Iteration 5966, loss = 0.00084930
Iteration 5967, loss = 0.00084909
Iteration 5968, loss = 0.00084892
Iteration 5969, loss = 0.00084873
Iteration 5970, loss = 0.00084856
Iteration 5971, loss = 0.00084836
Iteration 5972, loss = 0.00084818
Iteration 5973, loss = 0.00084801
Iteration 5974, loss = 0.00084784
Iteration 5975, loss = 0.00084764
Iteration 5976, loss = 0.00084748
Iteration 5977, loss = 0.00084728
Iteration 5978, loss = 0.00084709
Iteration 5979, loss = 0.00084689
Iteration 5980, loss = 0.00084672
Iteration 5981, loss = 0.00084655
Iteration 5982, loss = 0.00084633
Iteration 5983, loss = 0.00084625
Iteration 5984, loss = 0.00084597
Iteration 5985, loss = 0.00084581
Iteration 5986, loss = 0.00084559
Iteration 5987, loss = 0.00084547
Iteration 5988, loss = 0.00084526
Iteration 5989, loss = 0.00084507
Iteration 5990, loss = 0.00084487
Iteration 5991, loss = 0.00084468
Iteration 5992, loss = 0.00084453
Iteration 5993, loss = 0.00084433
Iteration 5994, loss = 0.00084413
Iteration 5995, loss = 0.00084398
Iteration 5996, loss = 0.00084373
Iteration 5997, loss = 0.00084357
Iteration 5998, loss = 0.00084337
Iteration 5999, loss = 0.00084321
Iteration 6000, loss = 0.00084301
Iteration 6001, loss = 0.00084281
Iteration 6002, loss = 0.00084264
Iteration 6003, loss = 0.00084243
Iteration 6004, loss = 0.00084226
Iteration 6005, loss = 0.00084206
Iteration 6006, loss = 0.00084187
Iteration 6007, loss = 0.00084170
Iteration 6008, loss = 0.00084153
Iteration 6009, loss = 0.00084137
Iteration 6010, loss = 0.00084115
Iteration 6011, loss = 0.00084097
Iteration 6012, loss = 0.00084077
Iteration 6013, loss = 0.00084058
Iteration 6014, loss = 0.00084039
Iteration 6015, loss = 0.00084019
Iteration 6016, loss = 0.00084000
Iteration 6017, loss = 0.00083983
Iteration 6018, loss = 0.00083969
Iteration 6019, loss = 0.00083948
Iteration 6020, loss = 0.00083931
Iteration 6021, loss = 0.00083913
Iteration 6022, loss = 0.00083892
Iteration 6023, loss = 0.00083871
Iteration 6024, loss = 0.00083853
Iteration 6025, loss = 0.00083838
Iteration 6026, loss = 0.00083817
Iteration 6027, loss = 0.00083798
Iteration 6028, loss = 0.00083782
Iteration 6029, loss = 0.00083765
Iteration 6030, loss = 0.00083746
Iteration 6031, loss = 0.00083728
Iteration 6032, loss = 0.00083709
Iteration 6033, loss = 0.00083689
Iteration 6034, loss = 0.00083676
Iteration 6035, loss = 0.00083653
Iteration 6036, loss = 0.00083636
Iteration 6037, loss = 0.00083618
Iteration 6038, loss = 0.00083606
Iteration 6039, loss = 0.00083584
Iteration 6040, loss = 0.00083568
Iteration 6041, loss = 0.00083546
Iteration 6042, loss = 0.00083528
Iteration 6043, loss = 0.00083511
Iteration 6044, loss = 0.00083491
Iteration 6045, loss = 0.00083472
Iteration 6046, loss = 0.00083458
Iteration 6047, loss = 0.00083438
Iteration 6048, loss = 0.00083421
Iteration 6049, loss = 0.00083402
Iteration 6050, loss = 0.00083382
Iteration 6051, loss = 0.00083365
Iteration 6052, loss = 0.00083345
Iteration 6053, loss = 0.00083328
Iteration 6054, loss = 0.00083311
Iteration 6055, loss = 0.00083293
Iteration 6056, loss = 0.00083283
Iteration 6057, loss = 0.00083257
Iteration 6058, loss = 0.00083234
Iteration 6059, loss = 0.00083218
Iteration 6060, loss = 0.00083199
Iteration 6061, loss = 0.00083179
Iteration 6062, loss = 0.00083159
Iteration 6063, loss = 0.00083143
Iteration 6064, loss = 0.00083125
Iteration 6065, loss = 0.00083106
Iteration 6066, loss = 0.00083092
Iteration 6067, loss = 0.00083071
Iteration 6068, loss = 0.00083054
Iteration 6069, loss = 0.00083037
Iteration 6070, loss = 0.00083021
Iteration 6071, loss = 0.00083003
Iteration 6072, loss = 0.00082980
Iteration 6073, loss = 0.00082969
Iteration 6074, loss = 0.00082946
Iteration 6075, loss = 0.00082928
Iteration 6076, loss = 0.00082912
Iteration 6077, loss = 0.00082892
Iteration 6078, loss = 0.00082874
Iteration 6079, loss = 0.00082853
Iteration 6080, loss = 0.00082841
Iteration 6081, loss = 0.00082822
Iteration 6082, loss = 0.00082803
Iteration 6083, loss = 0.00082788
Iteration 6084, loss = 0.00082768
Iteration 6085, loss = 0.00082752
Iteration 6086, loss = 0.00082734
Iteration 6087, loss = 0.00082717
Iteration 6088, loss = 0.00082699
Iteration 6089, loss = 0.00082679
Iteration 6090, loss = 0.00082664
Iteration 6091, loss = 0.00082647
Iteration 6092, loss = 0.00082628
Iteration 6093, loss = 0.00082611
Iteration 6094, loss = 0.00082593
Iteration 6095, loss = 0.00082575
Iteration 6096, loss = 0.00082555
Iteration 6097, loss = 0.00082539
Iteration 6098, loss = 0.00082520
Iteration 6099, loss = 0.00082503
Iteration 6100, loss = 0.00082484
Iteration 6101, loss = 0.00082468
Iteration 6102, loss = 0.00082448
Iteration 6103, loss = 0.00082432
Iteration 6104, loss = 0.00082416
Iteration 6105, loss = 0.00082394
Iteration 6106, loss = 0.00082379
Iteration 6107, loss = 0.00082363
Iteration 6108, loss = 0.00082343
Iteration 6109, loss = 0.00082324
Iteration 6110, loss = 0.00082305
Iteration 6111, loss = 0.00082289
Iteration 6112, loss = 0.00082272
Iteration 6113, loss = 0.00082258
Iteration 6114, loss = 0.00082238
Iteration 6115, loss = 0.00082220
Iteration 6116, loss = 0.00082201
Iteration 6117, loss = 0.00082179
Iteration 6118, loss = 0.00082166
Iteration 6119, loss = 0.00082145
Iteration 6120, loss = 0.00082129
Iteration 6121, loss = 0.00082110
Iteration 6122, loss = 0.00082093
Iteration 6123, loss = 0.00082075
Iteration 6124, loss = 0.00082057
Iteration 6125, loss = 0.00082040
Iteration 6126, loss = 0.00082023
Iteration 6127, loss = 0.00082005
Iteration 6128, loss = 0.00081987
Iteration 6129, loss = 0.00081970
Iteration 6130, loss = 0.00081949
Iteration 6131, loss = 0.00081931
Iteration 6132, loss = 0.00081913
Iteration 6133, loss = 0.00081900
Iteration 6134, loss = 0.00081881
Iteration 6135, loss = 0.00081862
Iteration 6136, loss = 0.00081844
Iteration 6137, loss = 0.00081828
Iteration 6138, loss = 0.00081814
Iteration 6139, loss = 0.00081796
Iteration 6140, loss = 0.00081773
Iteration 6141, loss = 0.00081759
Iteration 6142, loss = 0.00081738
Iteration 6143, loss = 0.00081720
Iteration 6144, loss = 0.00081702
Iteration 6145, loss = 0.00081687
Iteration 6146, loss = 0.00081666
Iteration 6147, loss = 0.00081649
Iteration 6148, loss = 0.00081633
Iteration 6149, loss = 0.00081614
Iteration 6150, loss = 0.00081598
Iteration 6151, loss = 0.00081580
Iteration 6152, loss = 0.00081560
Iteration 6153, loss = 0.00081542
Iteration 6154, loss = 0.00081526
Iteration 6155, loss = 0.00081510
Iteration 6156, loss = 0.00081491
Iteration 6157, loss = 0.00081473
Iteration 6158, loss = 0.00081457
Iteration 6159, loss = 0.00081436
Iteration 6160, loss = 0.00081419
Iteration 6161, loss = 0.00081403
Iteration 6162, loss = 0.00081385
Iteration 6163, loss = 0.00081369
Iteration 6164, loss = 0.00081345
Iteration 6165, loss = 0.00081330
Iteration 6166, loss = 0.00081312
Iteration 6167, loss = 0.00081297
Iteration 6168, loss = 0.00081279
Iteration 6169, loss = 0.00081259
Iteration 6170, loss = 0.00081247
Iteration 6171, loss = 0.00081228
Iteration 6172, loss = 0.00081212
Iteration 6173, loss = 0.00081193
Iteration 6174, loss = 0.00081176
Iteration 6175, loss = 0.00081157
Iteration 6176, loss = 0.00081140
Iteration 6177, loss = 0.00081123
Iteration 6178, loss = 0.00081102
Iteration 6179, loss = 0.00081089
Iteration 6180, loss = 0.00081068
Iteration 6181, loss = 0.00081051
Iteration 6182, loss = 0.00081035
Iteration 6183, loss = 0.00081016
Iteration 6184, loss = 0.00080998
Iteration 6185, loss = 0.00080982
Iteration 6186, loss = 0.00080961
Iteration 6187, loss = 0.00080946
Iteration 6188, loss = 0.00080930
Iteration 6189, loss = 0.00080911
Iteration 6190, loss = 0.00080893
Iteration 6191, loss = 0.00080886
Iteration 6192, loss = 0.00080859
Iteration 6193, loss = 0.00080843
Iteration 6194, loss = 0.00080829
Iteration 6195, loss = 0.00080811
Iteration 6196, loss = 0.00080793
Iteration 6197, loss = 0.00080777
Iteration 6198, loss = 0.00080761
Iteration 6199, loss = 0.00080740
Iteration 6200, loss = 0.00080728
Iteration 6201, loss = 0.00080708
Iteration 6202, loss = 0.00080691
Iteration 6203, loss = 0.00080677
Iteration 6204, loss = 0.00080656
Iteration 6205, loss = 0.00080641
Iteration 6206, loss = 0.00080625
Iteration 6207, loss = 0.00080607
Iteration 6208, loss = 0.00080589
Iteration 6209, loss = 0.00080573
Iteration 6210, loss = 0.00080556
Iteration 6211, loss = 0.00080542
Iteration 6212, loss = 0.00080525
Iteration 6213, loss = 0.00080506
Iteration 6214, loss = 0.00080496
Iteration 6215, loss = 0.00080474
Iteration 6216, loss = 0.00080459
Iteration 6217, loss = 0.00080443
Iteration 6218, loss = 0.00080421
Iteration 6219, loss = 0.00080405
Iteration 6220, loss = 0.00080385
Iteration 6221, loss = 0.00080371
Iteration 6222, loss = 0.00080355
Iteration 6223, loss = 0.00080335
Iteration 6224, loss = 0.00080321
Iteration 6225, loss = 0.00080303
Iteration 6226, loss = 0.00080284
Iteration 6227, loss = 0.00080270
Iteration 6228, loss = 0.00080252
Iteration 6229, loss = 0.00080237
Iteration 6230, loss = 0.00080221
Iteration 6231, loss = 0.00080203
Iteration 6232, loss = 0.00080185
Iteration 6233, loss = 0.00080167
Iteration 6234, loss = 0.00080149
Iteration 6235, loss = 0.00080133
Iteration 6236, loss = 0.00080112
Iteration 6237, loss = 0.00080099
Iteration 6238, loss = 0.00080081
Iteration 6239, loss = 0.00080062
Iteration 6240, loss = 0.00080045
Iteration 6241, loss = 0.00080036
Iteration 6242, loss = 0.00080013
Iteration 6243, loss = 0.00079995
Iteration 6244, loss = 0.00079980
Iteration 6245, loss = 0.00079965
Iteration 6246, loss = 0.00079944
Iteration 6247, loss = 0.00079931
Iteration 6248, loss = 0.00079916
Iteration 6249, loss = 0.00079894
Iteration 6250, loss = 0.00079880
Iteration 6251, loss = 0.00079862
Iteration 6252, loss = 0.00079845
Iteration 6253, loss = 0.00079832
Iteration 6254, loss = 0.00079811
Iteration 6255, loss = 0.00079794
Iteration 6256, loss = 0.00079779
Iteration 6257, loss = 0.00079762
Iteration 6258, loss = 0.00079745
Iteration 6259, loss = 0.00079726
Iteration 6260, loss = 0.00079709
Iteration 6261, loss = 0.00079696
Iteration 6262, loss = 0.00079679
Iteration 6263, loss = 0.00079662
Iteration 6264, loss = 0.00079643
Iteration 6265, loss = 0.00079628
Iteration 6266, loss = 0.00079609
Iteration 6267, loss = 0.00079592
Iteration 6268, loss = 0.00079575
Iteration 6269, loss = 0.00079562
Iteration 6270, loss = 0.00079544
Iteration 6271, loss = 0.00079532
Iteration 6272, loss = 0.00079510
Iteration 6273, loss = 0.00079491
Iteration 6274, loss = 0.00079474
Iteration 6275, loss = 0.00079459
Iteration 6276, loss = 0.00079444
Iteration 6277, loss = 0.00079428
Iteration 6278, loss = 0.00079408
Iteration 6279, loss = 0.00079395
Iteration 6280, loss = 0.00079376
Iteration 6281, loss = 0.00079362
Iteration 6282, loss = 0.00079344
Iteration 6283, loss = 0.00079328
Iteration 6284, loss = 0.00079313
Iteration 6285, loss = 0.00079294
Iteration 6286, loss = 0.00079280
Iteration 6287, loss = 0.00079260
Iteration 6288, loss = 0.00079246
Iteration 6289, loss = 0.00079230
Iteration 6290, loss = 0.00079213
Iteration 6291, loss = 0.00079194
Iteration 6292, loss = 0.00079178
Iteration 6293, loss = 0.00079164
Iteration 6294, loss = 0.00079146
Iteration 6295, loss = 0.00079130
Iteration 6296, loss = 0.00079116
Iteration 6297, loss = 0.00079100
Iteration 6298, loss = 0.00079082
Iteration 6299, loss = 0.00079064
Iteration 6300, loss = 0.00079048
Iteration 6301, loss = 0.00079033
Iteration 6302, loss = 0.00079017
Iteration 6303, loss = 0.00079001
Iteration 6304, loss = 0.00078988
Iteration 6305, loss = 0.00078967
Iteration 6306, loss = 0.00078951
Iteration 6307, loss = 0.00078934
Iteration 6308, loss = 0.00078918
Iteration 6309, loss = 0.00078900
Iteration 6310, loss = 0.00078885
Iteration 6311, loss = 0.00078868
Iteration 6312, loss = 0.00078851
Iteration 6313, loss = 0.00078834
Iteration 6314, loss = 0.00078820
Iteration 6315, loss = 0.00078804
Iteration 6316, loss = 0.00078784
Iteration 6317, loss = 0.00078769
Iteration 6318, loss = 0.00078750
Iteration 6319, loss = 0.00078734
Iteration 6320, loss = 0.00078718
Iteration 6321, loss = 0.00078703
Iteration 6322, loss = 0.00078685
Iteration 6323, loss = 0.00078667
Iteration 6324, loss = 0.00078654
Iteration 6325, loss = 0.00078636
Iteration 6326, loss = 0.00078617
Iteration 6327, loss = 0.00078602
Iteration 6328, loss = 0.00078584
Iteration 6329, loss = 0.00078568
Iteration 6330, loss = 0.00078554
Iteration 6331, loss = 0.00078533
Iteration 6332, loss = 0.00078522
Iteration 6333, loss = 0.00078500
Iteration 6334, loss = 0.00078482
Iteration 6335, loss = 0.00078466
Iteration 6336, loss = 0.00078450
Iteration 6337, loss = 0.00078436
Iteration 6338, loss = 0.00078419
Iteration 6339, loss = 0.00078401
Iteration 6340, loss = 0.00078385
Iteration 6341, loss = 0.00078369
Iteration 6342, loss = 0.00078355
Iteration 6343, loss = 0.00078341
Iteration 6344, loss = 0.00078325
Iteration 6345, loss = 0.00078308
Iteration 6346, loss = 0.00078293
Iteration 6347, loss = 0.00078277
Iteration 6348, loss = 0.00078258
Iteration 6349, loss = 0.00078242
Iteration 6350, loss = 0.00078227
Iteration 6351, loss = 0.00078213
Iteration 6352, loss = 0.00078195
Iteration 6353, loss = 0.00078186
Iteration 6354, loss = 0.00078165
Iteration 6355, loss = 0.00078148
Iteration 6356, loss = 0.00078132
Iteration 6357, loss = 0.00078116
Iteration 6358, loss = 0.00078097
Iteration 6359, loss = 0.00078081
Iteration 6360, loss = 0.00078065
Iteration 6361, loss = 0.00078048
Iteration 6362, loss = 0.00078031
Iteration 6363, loss = 0.00078015
Iteration 6364, loss = 0.00077999
Iteration 6365, loss = 0.00077981
Iteration 6366, loss = 0.00077967
Iteration 6367, loss = 0.00077955
Iteration 6368, loss = 0.00077934
Iteration 6369, loss = 0.00077918
Iteration 6370, loss = 0.00077902
Iteration 6371, loss = 0.00077887
Iteration 6372, loss = 0.00077868
Iteration 6373, loss = 0.00077854
Iteration 6374, loss = 0.00077842
Iteration 6375, loss = 0.00077822
Iteration 6376, loss = 0.00077808
Iteration 6377, loss = 0.00077790
Iteration 6378, loss = 0.00077777
Iteration 6379, loss = 0.00077759
Iteration 6380, loss = 0.00077742
Iteration 6381, loss = 0.00077730
Iteration 6382, loss = 0.00077713
Iteration 6383, loss = 0.00077697
Iteration 6384, loss = 0.00077681
Iteration 6385, loss = 0.00077662
Iteration 6386, loss = 0.00077650
Iteration 6387, loss = 0.00077631
Iteration 6388, loss = 0.00077615
Iteration 6389, loss = 0.00077600
Iteration 6390, loss = 0.00077585
Iteration 6391, loss = 0.00077568
Iteration 6392, loss = 0.00077558
Iteration 6393, loss = 0.00077537
Iteration 6394, loss = 0.00077522
Iteration 6395, loss = 0.00077506
Iteration 6396, loss = 0.00077491
Iteration 6397, loss = 0.00077476
Iteration 6398, loss = 0.00077459
Iteration 6399, loss = 0.00077448
Iteration 6400, loss = 0.00077427
Iteration 6401, loss = 0.00077412
Iteration 6402, loss = 0.00077398
Iteration 6403, loss = 0.00077380
Iteration 6404, loss = 0.00077364
Iteration 6405, loss = 0.00077348
Iteration 6406, loss = 0.00077334
Iteration 6407, loss = 0.00077317
Iteration 6408, loss = 0.00077300
Iteration 6409, loss = 0.00077285
Iteration 6410, loss = 0.00077266
Iteration 6411, loss = 0.00077257
Iteration 6412, loss = 0.00077234
Iteration 6413, loss = 0.00077219
Iteration 6414, loss = 0.00077200
Iteration 6415, loss = 0.00077186
Iteration 6416, loss = 0.00077171
Iteration 6417, loss = 0.00077152
Iteration 6418, loss = 0.00077138
Iteration 6419, loss = 0.00077121
Iteration 6420, loss = 0.00077104
Iteration 6421, loss = 0.00077091
Iteration 6422, loss = 0.00077077
Iteration 6423, loss = 0.00077059
Iteration 6424, loss = 0.00077043
Iteration 6425, loss = 0.00077028
Iteration 6426, loss = 0.00077011
Iteration 6427, loss = 0.00076993
Iteration 6428, loss = 0.00076981
Iteration 6429, loss = 0.00076960
Iteration 6430, loss = 0.00076948
Iteration 6431, loss = 0.00076931
Iteration 6432, loss = 0.00076915
Iteration 6433, loss = 0.00076899
Iteration 6434, loss = 0.00076885
Iteration 6435, loss = 0.00076869
Iteration 6436, loss = 0.00076851
Iteration 6437, loss = 0.00076834
Iteration 6438, loss = 0.00076821
Iteration 6439, loss = 0.00076801
Iteration 6440, loss = 0.00076789
Iteration 6441, loss = 0.00076771
Iteration 6442, loss = 0.00076755
Iteration 6443, loss = 0.00076740
Iteration 6444, loss = 0.00076722
Iteration 6445, loss = 0.00076710
Iteration 6446, loss = 0.00076690
Iteration 6447, loss = 0.00076675
Iteration 6448, loss = 0.00076659
Iteration 6449, loss = 0.00076644
Iteration 6450, loss = 0.00076625
Iteration 6451, loss = 0.00076609
Iteration 6452, loss = 0.00076595
Iteration 6453, loss = 0.00076576
Iteration 6454, loss = 0.00076562
Iteration 6455, loss = 0.00076545
Iteration 6456, loss = 0.00076531
Iteration 6457, loss = 0.00076514
Iteration 6458, loss = 0.00076497
Iteration 6459, loss = 0.00076481
Iteration 6460, loss = 0.00076466
Iteration 6461, loss = 0.00076451
Iteration 6462, loss = 0.00076433
Iteration 6463, loss = 0.00076418
Iteration 6464, loss = 0.00076403
Iteration 6465, loss = 0.00076386
Iteration 6466, loss = 0.00076374
Iteration 6467, loss = 0.00076354
Iteration 6468, loss = 0.00076337
Iteration 6469, loss = 0.00076321
Iteration 6470, loss = 0.00076304
Iteration 6471, loss = 0.00076288
Iteration 6472, loss = 0.00076277
Iteration 6473, loss = 0.00076256
Iteration 6474, loss = 0.00076242
Iteration 6475, loss = 0.00076225
Iteration 6476, loss = 0.00076209
Iteration 6477, loss = 0.00076194
Iteration 6478, loss = 0.00076181
Iteration 6479, loss = 0.00076162
Iteration 6480, loss = 0.00076148
Iteration 6481, loss = 0.00076136
Iteration 6482, loss = 0.00076118
Iteration 6483, loss = 0.00076103
Iteration 6484, loss = 0.00076088
Iteration 6485, loss = 0.00076071
Iteration 6486, loss = 0.00076055
Iteration 6487, loss = 0.00076039
Iteration 6488, loss = 0.00076028
Iteration 6489, loss = 0.00076012
Iteration 6490, loss = 0.00075994
Iteration 6491, loss = 0.00075984
Iteration 6492, loss = 0.00075966
Iteration 6493, loss = 0.00075952
Iteration 6494, loss = 0.00075932
Iteration 6495, loss = 0.00075919
Iteration 6496, loss = 0.00075903
Iteration 6497, loss = 0.00075886
Iteration 6498, loss = 0.00075872
Iteration 6499, loss = 0.00075858
Iteration 6500, loss = 0.00075840
Iteration 6501, loss = 0.00075827
Iteration 6502, loss = 0.00075810
Iteration 6503, loss = 0.00075792
Iteration 6504, loss = 0.00075779
Iteration 6505, loss = 0.00075765
Iteration 6506, loss = 0.00075744
Iteration 6507, loss = 0.00075730
Iteration 6508, loss = 0.00075714
Iteration 6509, loss = 0.00075699
Iteration 6510, loss = 0.00075684
Iteration 6511, loss = 0.00075670
Iteration 6512, loss = 0.00075651
Iteration 6513, loss = 0.00075636
Iteration 6514, loss = 0.00075622
Iteration 6515, loss = 0.00075607
Iteration 6516, loss = 0.00075596
Iteration 6517, loss = 0.00075580
Iteration 6518, loss = 0.00075562
Iteration 6519, loss = 0.00075545
Iteration 6520, loss = 0.00075533
Iteration 6521, loss = 0.00075518
Iteration 6522, loss = 0.00075500
Iteration 6523, loss = 0.00075489
Iteration 6524, loss = 0.00075468
Iteration 6525, loss = 0.00075455
Iteration 6526, loss = 0.00075441
Iteration 6527, loss = 0.00075424
Iteration 6528, loss = 0.00075409
Iteration 6529, loss = 0.00075396
Iteration 6530, loss = 0.00075380
Iteration 6531, loss = 0.00075363
Iteration 6532, loss = 0.00075350
Iteration 6533, loss = 0.00075340
Iteration 6534, loss = 0.00075318
Iteration 6535, loss = 0.00075302
Iteration 6536, loss = 0.00075289
Iteration 6537, loss = 0.00075273
Iteration 6538, loss = 0.00075256
Iteration 6539, loss = 0.00075242
Iteration 6540, loss = 0.00075226
Iteration 6541, loss = 0.00075213
Iteration 6542, loss = 0.00075196
Iteration 6543, loss = 0.00075183
Iteration 6544, loss = 0.00075167
Iteration 6545, loss = 0.00075156
Iteration 6546, loss = 0.00075135
Iteration 6547, loss = 0.00075119
Iteration 6548, loss = 0.00075103
Iteration 6549, loss = 0.00075089
Iteration 6550, loss = 0.00075078
Iteration 6551, loss = 0.00075059
Iteration 6552, loss = 0.00075045
Iteration 6553, loss = 0.00075028
Iteration 6554, loss = 0.00075014
Iteration 6555, loss = 0.00074998
Iteration 6556, loss = 0.00074981
Iteration 6557, loss = 0.00074971
Iteration 6558, loss = 0.00074954
Iteration 6559, loss = 0.00074937
Iteration 6560, loss = 0.00074926
Iteration 6561, loss = 0.00074911
Iteration 6562, loss = 0.00074891
Iteration 6563, loss = 0.00074879
Iteration 6564, loss = 0.00074864
Iteration 6565, loss = 0.00074848
Iteration 6566, loss = 0.00074831
Iteration 6567, loss = 0.00074820
Iteration 6568, loss = 0.00074801
Iteration 6569, loss = 0.00074786
Iteration 6570, loss = 0.00074771
Iteration 6571, loss = 0.00074757
Iteration 6572, loss = 0.00074740
Iteration 6573, loss = 0.00074725
Iteration 6574, loss = 0.00074714
Iteration 6575, loss = 0.00074697
Iteration 6576, loss = 0.00074682
Iteration 6577, loss = 0.00074666
Iteration 6578, loss = 0.00074650
Iteration 6579, loss = 0.00074635
Iteration 6580, loss = 0.00074622
Iteration 6581, loss = 0.00074604
Iteration 6582, loss = 0.00074590
Iteration 6583, loss = 0.00074575
Iteration 6584, loss = 0.00074561
Iteration 6585, loss = 0.00074544
Iteration 6586, loss = 0.00074530
Iteration 6587, loss = 0.00074515
Iteration 6588, loss = 0.00074500
Iteration 6589, loss = 0.00074485
Iteration 6590, loss = 0.00074470
Iteration 6591, loss = 0.00074454
Iteration 6592, loss = 0.00074437
Iteration 6593, loss = 0.00074425
Iteration 6594, loss = 0.00074414
Iteration 6595, loss = 0.00074395
Iteration 6596, loss = 0.00074377
Iteration 6597, loss = 0.00074363
Iteration 6598, loss = 0.00074346
Iteration 6599, loss = 0.00074329
Iteration 6600, loss = 0.00074315
Iteration 6601, loss = 0.00074299
Iteration 6602, loss = 0.00074286
Iteration 6603, loss = 0.00074267
Iteration 6604, loss = 0.00074253
Iteration 6605, loss = 0.00074237
Iteration 6606, loss = 0.00074226
Iteration 6607, loss = 0.00074209
Iteration 6608, loss = 0.00074194
Iteration 6609, loss = 0.00074179
Iteration 6610, loss = 0.00074166
Iteration 6611, loss = 0.00074150
Iteration 6612, loss = 0.00074136
Iteration 6613, loss = 0.00074121
Iteration 6614, loss = 0.00074110
Iteration 6615, loss = 0.00074091
Iteration 6616, loss = 0.00074078
Iteration 6617, loss = 0.00074061
Iteration 6618, loss = 0.00074048
Iteration 6619, loss = 0.00074031
Iteration 6620, loss = 0.00074017
Iteration 6621, loss = 0.00074001
Iteration 6622, loss = 0.00073987
Iteration 6623, loss = 0.00073972
Iteration 6624, loss = 0.00073963
Iteration 6625, loss = 0.00073943
Iteration 6626, loss = 0.00073930
Iteration 6627, loss = 0.00073914
Iteration 6628, loss = 0.00073900
Iteration 6629, loss = 0.00073886
Iteration 6630, loss = 0.00073870
Iteration 6631, loss = 0.00073855
Iteration 6632, loss = 0.00073842
Iteration 6633, loss = 0.00073826
Iteration 6634, loss = 0.00073812
Iteration 6635, loss = 0.00073798
Iteration 6636, loss = 0.00073780
Iteration 6637, loss = 0.00073766
Iteration 6638, loss = 0.00073754
Iteration 6639, loss = 0.00073739
Iteration 6640, loss = 0.00073725
Iteration 6641, loss = 0.00073708
Iteration 6642, loss = 0.00073693
Iteration 6643, loss = 0.00073679
Iteration 6644, loss = 0.00073665
Iteration 6645, loss = 0.00073650
Iteration 6646, loss = 0.00073634
Iteration 6647, loss = 0.00073623
Iteration 6648, loss = 0.00073604
Iteration 6649, loss = 0.00073592
Iteration 6650, loss = 0.00073578
Iteration 6651, loss = 0.00073563
Iteration 6652, loss = 0.00073546
Iteration 6653, loss = 0.00073532
Iteration 6654, loss = 0.00073518
Iteration 6655, loss = 0.00073503
Iteration 6656, loss = 0.00073487
Iteration 6657, loss = 0.00073472
Iteration 6658, loss = 0.00073458
Iteration 6659, loss = 0.00073443
Iteration 6660, loss = 0.00073428
Iteration 6661, loss = 0.00073411
Iteration 6662, loss = 0.00073398
Iteration 6663, loss = 0.00073384
Iteration 6664, loss = 0.00073371
Iteration 6665, loss = 0.00073354
Iteration 6666, loss = 0.00073342
Iteration 6667, loss = 0.00073338
Iteration 6668, loss = 0.00073312
Iteration 6669, loss = 0.00073297
Iteration 6670, loss = 0.00073282
Iteration 6671, loss = 0.00073272
Iteration 6672, loss = 0.00073257
Iteration 6673, loss = 0.00073240
Iteration 6674, loss = 0.00073229
Iteration 6675, loss = 0.00073213
Iteration 6676, loss = 0.00073198
Iteration 6677, loss = 0.00073185
Iteration 6678, loss = 0.00073170
Iteration 6679, loss = 0.00073155
Iteration 6680, loss = 0.00073140
Iteration 6681, loss = 0.00073128
Iteration 6682, loss = 0.00073113
Iteration 6683, loss = 0.00073098
Iteration 6684, loss = 0.00073083
Iteration 6685, loss = 0.00073068
Iteration 6686, loss = 0.00073055
Iteration 6687, loss = 0.00073040
Iteration 6688, loss = 0.00073026
Iteration 6689, loss = 0.00073014
Iteration 6690, loss = 0.00072996
Iteration 6691, loss = 0.00072984
Iteration 6692, loss = 0.00072972
Iteration 6693, loss = 0.00072951
Iteration 6694, loss = 0.00072934
Iteration 6695, loss = 0.00072924
Iteration 6696, loss = 0.00072906
Iteration 6697, loss = 0.00072892
Iteration 6698, loss = 0.00072879
Iteration 6699, loss = 0.00072862
Iteration 6700, loss = 0.00072851
Iteration 6701, loss = 0.00072834
Iteration 6702, loss = 0.00072822
Iteration 6703, loss = 0.00072806
Iteration 6704, loss = 0.00072792
Iteration 6705, loss = 0.00072780
Iteration 6706, loss = 0.00072766
Iteration 6707, loss = 0.00072753
Iteration 6708, loss = 0.00072737
Iteration 6709, loss = 0.00072726
Iteration 6710, loss = 0.00072710
Iteration 6711, loss = 0.00072696
Iteration 6712, loss = 0.00072682
Iteration 6713, loss = 0.00072667
Iteration 6714, loss = 0.00072656
Iteration 6715, loss = 0.00072639
Iteration 6716, loss = 0.00072627
Iteration 6717, loss = 0.00072611
Iteration 6718, loss = 0.00072597
Iteration 6719, loss = 0.00072582
Iteration 6720, loss = 0.00072569
Iteration 6721, loss = 0.00072558
Iteration 6722, loss = 0.00072542
Iteration 6723, loss = 0.00072528
Iteration 6724, loss = 0.00072515
Iteration 6725, loss = 0.00072500
Iteration 6726, loss = 0.00072484
Iteration 6727, loss = 0.00072472
Iteration 6728, loss = 0.00072457
Iteration 6729, loss = 0.00072445
Iteration 6730, loss = 0.00072428
Iteration 6731, loss = 0.00072414
Iteration 6732, loss = 0.00072398
Iteration 6733, loss = 0.00072385
Iteration 6734, loss = 0.00072376
Iteration 6735, loss = 0.00072358
Iteration 6736, loss = 0.00072347
Iteration 6737, loss = 0.00072328
Iteration 6738, loss = 0.00072314
Iteration 6739, loss = 0.00072305
Iteration 6740, loss = 0.00072291
Iteration 6741, loss = 0.00072273
Iteration 6742, loss = 0.00072260
Iteration 6743, loss = 0.00072248
Iteration 6744, loss = 0.00072232
Iteration 6745, loss = 0.00072217
Iteration 6746, loss = 0.00072200
Iteration 6747, loss = 0.00072189
Iteration 6748, loss = 0.00072174
Iteration 6749, loss = 0.00072159
Iteration 6750, loss = 0.00072147
Iteration 6751, loss = 0.00072132
Iteration 6752, loss = 0.00072115
Iteration 6753, loss = 0.00072100
Iteration 6754, loss = 0.00072086
Iteration 6755, loss = 0.00072074
Iteration 6756, loss = 0.00072061
Iteration 6757, loss = 0.00072046
Iteration 6758, loss = 0.00072032
Iteration 6759, loss = 0.00072017
Iteration 6760, loss = 0.00072002
Iteration 6761, loss = 0.00071989
Iteration 6762, loss = 0.00071975
Iteration 6763, loss = 0.00071960
Iteration 6764, loss = 0.00071945
Iteration 6765, loss = 0.00071935
Iteration 6766, loss = 0.00071919
Iteration 6767, loss = 0.00071905
Iteration 6768, loss = 0.00071891
Iteration 6769, loss = 0.00071882
Iteration 6770, loss = 0.00071866
Iteration 6771, loss = 0.00071853
Iteration 6772, loss = 0.00071840
Iteration 6773, loss = 0.00071824
Iteration 6774, loss = 0.00071817
Iteration 6775, loss = 0.00071796
Iteration 6776, loss = 0.00071781
Iteration 6777, loss = 0.00071767
Iteration 6778, loss = 0.00071759
Iteration 6779, loss = 0.00071741
Iteration 6780, loss = 0.00071728
Iteration 6781, loss = 0.00071710
Iteration 6782, loss = 0.00071700
Iteration 6783, loss = 0.00071689
Iteration 6784, loss = 0.00071668
Iteration 6785, loss = 0.00071654
Iteration 6786, loss = 0.00071641
Iteration 6787, loss = 0.00071627
Iteration 6788, loss = 0.00071614
Iteration 6789, loss = 0.00071598
Iteration 6790, loss = 0.00071584
Iteration 6791, loss = 0.00071570
Iteration 6792, loss = 0.00071561
Iteration 6793, loss = 0.00071544
Iteration 6794, loss = 0.00071529
Iteration 6795, loss = 0.00071514
Iteration 6796, loss = 0.00071505
Iteration 6797, loss = 0.00071492
Iteration 6798, loss = 0.00071473
Iteration 6799, loss = 0.00071461
Iteration 6800, loss = 0.00071446
Iteration 6801, loss = 0.00071435
Iteration 6802, loss = 0.00071419
Iteration 6803, loss = 0.00071406
Iteration 6804, loss = 0.00071394
Iteration 6805, loss = 0.00071380
Iteration 6806, loss = 0.00071366
Iteration 6807, loss = 0.00071357
Iteration 6808, loss = 0.00071338
Iteration 6809, loss = 0.00071322
Iteration 6810, loss = 0.00071308
Iteration 6811, loss = 0.00071296
Iteration 6812, loss = 0.00071281
Iteration 6813, loss = 0.00071267
Iteration 6814, loss = 0.00071254
Iteration 6815, loss = 0.00071242
Iteration 6816, loss = 0.00071224
Iteration 6817, loss = 0.00071210
Iteration 6818, loss = 0.00071198
Iteration 6819, loss = 0.00071183
Iteration 6820, loss = 0.00071172
Iteration 6821, loss = 0.00071155
Iteration 6822, loss = 0.00071142
Iteration 6823, loss = 0.00071131
Iteration 6824, loss = 0.00071121
Iteration 6825, loss = 0.00071102
Iteration 6826, loss = 0.00071088
Iteration 6827, loss = 0.00071075
Iteration 6828, loss = 0.00071063
Iteration 6829, loss = 0.00071049
Iteration 6830, loss = 0.00071037
Iteration 6831, loss = 0.00071020
Iteration 6832, loss = 0.00071009
Iteration 6833, loss = 0.00070992
Iteration 6834, loss = 0.00070979
Iteration 6835, loss = 0.00070968
Iteration 6836, loss = 0.00070952
Iteration 6837, loss = 0.00070938
Iteration 6838, loss = 0.00070926
Iteration 6839, loss = 0.00070909
Iteration 6840, loss = 0.00070898
Iteration 6841, loss = 0.00070884
Iteration 6842, loss = 0.00070868
Iteration 6843, loss = 0.00070855
Iteration 6844, loss = 0.00070840
Iteration 6845, loss = 0.00070830
Iteration 6846, loss = 0.00070815
Iteration 6847, loss = 0.00070802
Iteration 6848, loss = 0.00070787
Iteration 6849, loss = 0.00070773
Iteration 6850, loss = 0.00070759
Iteration 6851, loss = 0.00070746
Iteration 6852, loss = 0.00070733
Iteration 6853, loss = 0.00070720
Iteration 6854, loss = 0.00070704
Iteration 6855, loss = 0.00070691
Iteration 6856, loss = 0.00070675
Iteration 6857, loss = 0.00070662
Iteration 6858, loss = 0.00070648
Iteration 6859, loss = 0.00070636
Iteration 6860, loss = 0.00070619
Iteration 6861, loss = 0.00070606
Iteration 6862, loss = 0.00070591
Iteration 6863, loss = 0.00070581
Iteration 6864, loss = 0.00070566
Iteration 6865, loss = 0.00070551
Iteration 6866, loss = 0.00070538
Iteration 6867, loss = 0.00070523
Iteration 6868, loss = 0.00070511
Iteration 6869, loss = 0.00070496
Iteration 6870, loss = 0.00070485
Iteration 6871, loss = 0.00070470
Iteration 6872, loss = 0.00070456
Iteration 6873, loss = 0.00070442
Iteration 6874, loss = 0.00070428
Iteration 6875, loss = 0.00070414
Iteration 6876, loss = 0.00070403
Iteration 6877, loss = 0.00070389
Iteration 6878, loss = 0.00070373
Iteration 6879, loss = 0.00070361
Iteration 6880, loss = 0.00070346
Iteration 6881, loss = 0.00070333
Iteration 6882, loss = 0.00070317
Iteration 6883, loss = 0.00070306
Iteration 6884, loss = 0.00070289
Iteration 6885, loss = 0.00070276
Iteration 6886, loss = 0.00070262
Iteration 6887, loss = 0.00070248
Iteration 6888, loss = 0.00070240
Iteration 6889, loss = 0.00070222
Iteration 6890, loss = 0.00070208
Iteration 6891, loss = 0.00070195
Iteration 6892, loss = 0.00070182
Iteration 6893, loss = 0.00070168
Iteration 6894, loss = 0.00070156
Iteration 6895, loss = 0.00070143
Iteration 6896, loss = 0.00070128
Iteration 6897, loss = 0.00070116
Iteration 6898, loss = 0.00070101
Iteration 6899, loss = 0.00070088
Iteration 6900, loss = 0.00070074
Iteration 6901, loss = 0.00070061
Iteration 6902, loss = 0.00070044
Iteration 6903, loss = 0.00070030
Iteration 6904, loss = 0.00070017
Iteration 6905, loss = 0.00070006
Iteration 6906, loss = 0.00069991
Iteration 6907, loss = 0.00069978
Iteration 6908, loss = 0.00069966
Iteration 6909, loss = 0.00069952
Iteration 6910, loss = 0.00069942
Iteration 6911, loss = 0.00069923
Iteration 6912, loss = 0.00069909
Iteration 6913, loss = 0.00069894
Iteration 6914, loss = 0.00069881
Iteration 6915, loss = 0.00069869
Iteration 6916, loss = 0.00069857
Iteration 6917, loss = 0.00069843
Iteration 6918, loss = 0.00069827
Iteration 6919, loss = 0.00069816
Iteration 6920, loss = 0.00069803
Iteration 6921, loss = 0.00069786
Iteration 6922, loss = 0.00069778
Iteration 6923, loss = 0.00069763
Iteration 6924, loss = 0.00069746
Iteration 6925, loss = 0.00069733
Iteration 6926, loss = 0.00069720
Iteration 6927, loss = 0.00069706
Iteration 6928, loss = 0.00069696
Iteration 6929, loss = 0.00069678
Iteration 6930, loss = 0.00069668
Iteration 6931, loss = 0.00069654
Iteration 6932, loss = 0.00069638
Iteration 6933, loss = 0.00069626
Iteration 6934, loss = 0.00069615
Iteration 6935, loss = 0.00069601
Iteration 6936, loss = 0.00069586
Iteration 6937, loss = 0.00069572
Iteration 6938, loss = 0.00069559
Iteration 6939, loss = 0.00069549
Iteration 6940, loss = 0.00069534
Iteration 6941, loss = 0.00069522
Iteration 6942, loss = 0.00069511
Iteration 6943, loss = 0.00069495
Iteration 6944, loss = 0.00069483
Iteration 6945, loss = 0.00069469
Iteration 6946, loss = 0.00069457
Iteration 6947, loss = 0.00069444
Iteration 6948, loss = 0.00069433
Iteration 6949, loss = 0.00069417
Iteration 6950, loss = 0.00069406
Iteration 6951, loss = 0.00069394
Iteration 6952, loss = 0.00069380
Iteration 6953, loss = 0.00069368
Iteration 6954, loss = 0.00069355
Iteration 6955, loss = 0.00069340
Iteration 6956, loss = 0.00069329
Iteration 6957, loss = 0.00069316
Iteration 6958, loss = 0.00069302
Iteration 6959, loss = 0.00069290
Iteration 6960, loss = 0.00069277
Iteration 6961, loss = 0.00069263
Iteration 6962, loss = 0.00069247
Iteration 6963, loss = 0.00069236
Iteration 6964, loss = 0.00069223
Iteration 6965, loss = 0.00069211
Iteration 6966, loss = 0.00069197
Iteration 6967, loss = 0.00069183
Iteration 6968, loss = 0.00069171
Iteration 6969, loss = 0.00069162
Iteration 6970, loss = 0.00069144
Iteration 6971, loss = 0.00069131
Iteration 6972, loss = 0.00069121
Iteration 6973, loss = 0.00069103
Iteration 6974, loss = 0.00069090
Iteration 6975, loss = 0.00069077
Iteration 6976, loss = 0.00069063
Iteration 6977, loss = 0.00069054
Iteration 6978, loss = 0.00069039
Iteration 6979, loss = 0.00069027
Iteration 6980, loss = 0.00069014
Iteration 6981, loss = 0.00069001
Iteration 6982, loss = 0.00068989
Iteration 6983, loss = 0.00068978
Iteration 6984, loss = 0.00068959
Iteration 6985, loss = 0.00068948
Iteration 6986, loss = 0.00068935
Iteration 6987, loss = 0.00068921
Iteration 6988, loss = 0.00068907
Iteration 6989, loss = 0.00068897
Iteration 6990, loss = 0.00068885
Iteration 6991, loss = 0.00068868
Iteration 6992, loss = 0.00068855
Iteration 6993, loss = 0.00068843
Iteration 6994, loss = 0.00068829
Iteration 6995, loss = 0.00068815
Iteration 6996, loss = 0.00068805
Iteration 6997, loss = 0.00068791
Iteration 6998, loss = 0.00068776
Iteration 6999, loss = 0.00068762
Iteration 7000, loss = 0.00068749
Iteration 7001, loss = 0.00068737
Iteration 7002, loss = 0.00068724
Iteration 7003, loss = 0.00068711
Iteration 7004, loss = 0.00068698
Iteration 7005, loss = 0.00068685
Iteration 7006, loss = 0.00068673
Iteration 7007, loss = 0.00068659
Iteration 7008, loss = 0.00068644
Iteration 7009, loss = 0.00068632
Iteration 7010, loss = 0.00068619
Iteration 7011, loss = 0.00068604
Iteration 7012, loss = 0.00068592
Iteration 7013, loss = 0.00068581
Iteration 7014, loss = 0.00068566
Iteration 7015, loss = 0.00068555
Iteration 7016, loss = 0.00068538
Iteration 7017, loss = 0.00068526
Iteration 7018, loss = 0.00068515
Iteration 7019, loss = 0.00068500
Iteration 7020, loss = 0.00068488
Iteration 7021, loss = 0.00068473
Iteration 7022, loss = 0.00068460
Iteration 7023, loss = 0.00068448
Iteration 7024, loss = 0.00068433
Iteration 7025, loss = 0.00068421
Iteration 7026, loss = 0.00068408
Iteration 7027, loss = 0.00068393
Iteration 7028, loss = 0.00068383
Iteration 7029, loss = 0.00068369
Iteration 7030, loss = 0.00068356
Iteration 7031, loss = 0.00068342
Iteration 7032, loss = 0.00068331
Iteration 7033, loss = 0.00068317
Iteration 7034, loss = 0.00068306
Iteration 7035, loss = 0.00068290
Iteration 7036, loss = 0.00068279
Iteration 7037, loss = 0.00068265
Iteration 7038, loss = 0.00068253
Iteration 7039, loss = 0.00068239
Iteration 7040, loss = 0.00068228
Iteration 7041, loss = 0.00068217
Iteration 7042, loss = 0.00068204
Iteration 7043, loss = 0.00068189
Iteration 7044, loss = 0.00068175
Iteration 7045, loss = 0.00068162
Iteration 7046, loss = 0.00068151
Iteration 7047, loss = 0.00068136
Iteration 7048, loss = 0.00068123
Iteration 7049, loss = 0.00068110
Iteration 7050, loss = 0.00068098
Iteration 7051, loss = 0.00068084
Iteration 7052, loss = 0.00068071
Iteration 7053, loss = 0.00068060
Iteration 7054, loss = 0.00068048
Iteration 7055, loss = 0.00068033
Iteration 7056, loss = 0.00068021
Iteration 7057, loss = 0.00068009
Iteration 7058, loss = 0.00067998
Iteration 7059, loss = 0.00067984
Iteration 7060, loss = 0.00067973
Iteration 7061, loss = 0.00067959
Iteration 7062, loss = 0.00067944
Iteration 7063, loss = 0.00067933
Iteration 7064, loss = 0.00067916
Iteration 7065, loss = 0.00067908
Iteration 7066, loss = 0.00067891
Iteration 7067, loss = 0.00067878
Iteration 7068, loss = 0.00067867
Iteration 7069, loss = 0.00067853
Iteration 7070, loss = 0.00067839
Iteration 7071, loss = 0.00067827
Iteration 7072, loss = 0.00067813
Iteration 7073, loss = 0.00067801
Iteration 7074, loss = 0.00067788
Iteration 7075, loss = 0.00067776
Iteration 7076, loss = 0.00067762
Iteration 7077, loss = 0.00067749
Iteration 7078, loss = 0.00067735
Iteration 7079, loss = 0.00067722
Iteration 7080, loss = 0.00067709
Iteration 7081, loss = 0.00067696
Iteration 7082, loss = 0.00067683
Iteration 7083, loss = 0.00067670
Iteration 7084, loss = 0.00067657
Iteration 7085, loss = 0.00067645
Iteration 7086, loss = 0.00067635
Iteration 7087, loss = 0.00067617
Iteration 7088, loss = 0.00067605
Iteration 7089, loss = 0.00067594
Iteration 7090, loss = 0.00067582
Iteration 7091, loss = 0.00067568
Iteration 7092, loss = 0.00067557
Iteration 7093, loss = 0.00067543
Iteration 7094, loss = 0.00067534
Iteration 7095, loss = 0.00067516
Iteration 7096, loss = 0.00067504
Iteration 7097, loss = 0.00067493
Iteration 7098, loss = 0.00067480
Iteration 7099, loss = 0.00067465
Iteration 7100, loss = 0.00067453
Iteration 7101, loss = 0.00067442
Iteration 7102, loss = 0.00067427
Iteration 7103, loss = 0.00067415
Iteration 7104, loss = 0.00067402
Iteration 7105, loss = 0.00067390
Iteration 7106, loss = 0.00067376
Iteration 7107, loss = 0.00067365
Iteration 7108, loss = 0.00067353
Iteration 7109, loss = 0.00067340
Iteration 7110, loss = 0.00067327
Iteration 7111, loss = 0.00067314
Iteration 7112, loss = 0.00067305
Iteration 7113, loss = 0.00067289
Iteration 7114, loss = 0.00067281
Iteration 7115, loss = 0.00067265
Iteration 7116, loss = 0.00067251
Iteration 7117, loss = 0.00067241
Iteration 7118, loss = 0.00067227
Iteration 7119, loss = 0.00067214
Iteration 7120, loss = 0.00067203
Iteration 7121, loss = 0.00067189
Iteration 7122, loss = 0.00067179
Iteration 7123, loss = 0.00067165
Iteration 7124, loss = 0.00067150
Iteration 7125, loss = 0.00067143
Iteration 7126, loss = 0.00067127
Iteration 7127, loss = 0.00067113
Iteration 7128, loss = 0.00067099
Iteration 7129, loss = 0.00067088
Iteration 7130, loss = 0.00067075
Iteration 7131, loss = 0.00067061
Iteration 7132, loss = 0.00067049
Iteration 7133, loss = 0.00067037
Iteration 7134, loss = 0.00067024
Iteration 7135, loss = 0.00067014
Iteration 7136, loss = 0.00067000
Iteration 7137, loss = 0.00066986
Iteration 7138, loss = 0.00066976
Iteration 7139, loss = 0.00066964
Iteration 7140, loss = 0.00066952
Iteration 7141, loss = 0.00066939
Iteration 7142, loss = 0.00066927
Iteration 7143, loss = 0.00066910
Iteration 7144, loss = 0.00066896
Iteration 7145, loss = 0.00066884
Iteration 7146, loss = 0.00066871
Iteration 7147, loss = 0.00066859
Iteration 7148, loss = 0.00066848
Iteration 7149, loss = 0.00066835
Iteration 7150, loss = 0.00066825
Iteration 7151, loss = 0.00066810
Iteration 7152, loss = 0.00066799
Iteration 7153, loss = 0.00066785
Iteration 7154, loss = 0.00066773
Iteration 7155, loss = 0.00066761
Iteration 7156, loss = 0.00066749
Iteration 7157, loss = 0.00066737
Iteration 7158, loss = 0.00066721
Iteration 7159, loss = 0.00066714
Iteration 7160, loss = 0.00066702
Iteration 7161, loss = 0.00066683
Iteration 7162, loss = 0.00066673
Iteration 7163, loss = 0.00066659
Iteration 7164, loss = 0.00066648
Iteration 7165, loss = 0.00066635
Iteration 7166, loss = 0.00066622
Iteration 7167, loss = 0.00066609
Iteration 7168, loss = 0.00066598
Iteration 7169, loss = 0.00066586
Iteration 7170, loss = 0.00066572
Iteration 7171, loss = 0.00066560
Iteration 7172, loss = 0.00066548
Iteration 7173, loss = 0.00066536
Iteration 7174, loss = 0.00066524
Iteration 7175, loss = 0.00066511
Iteration 7176, loss = 0.00066498
Iteration 7177, loss = 0.00066485
Iteration 7178, loss = 0.00066474
Iteration 7179, loss = 0.00066465
Iteration 7180, loss = 0.00066450
Iteration 7181, loss = 0.00066436
Iteration 7182, loss = 0.00066425
Iteration 7183, loss = 0.00066412
Iteration 7184, loss = 0.00066400
Iteration 7185, loss = 0.00066389
Iteration 7186, loss = 0.00066373
Iteration 7187, loss = 0.00066362
Iteration 7188, loss = 0.00066348
Iteration 7189, loss = 0.00066335
Iteration 7190, loss = 0.00066326
Iteration 7191, loss = 0.00066311
Iteration 7192, loss = 0.00066298
Iteration 7193, loss = 0.00066288
Iteration 7194, loss = 0.00066275
Iteration 7195, loss = 0.00066262
Iteration 7196, loss = 0.00066250
Iteration 7197, loss = 0.00066237
Iteration 7198, loss = 0.00066226
Iteration 7199, loss = 0.00066212
Iteration 7200, loss = 0.00066199
Iteration 7201, loss = 0.00066190
Iteration 7202, loss = 0.00066174
Iteration 7203, loss = 0.00066163
Iteration 7204, loss = 0.00066151
Iteration 7205, loss = 0.00066137
Iteration 7206, loss = 0.00066129
Iteration 7207, loss = 0.00066116
Iteration 7208, loss = 0.00066103
Iteration 7209, loss = 0.00066087
Iteration 7210, loss = 0.00066077
Iteration 7211, loss = 0.00066066
Iteration 7212, loss = 0.00066052
Iteration 7213, loss = 0.00066040
Iteration 7214, loss = 0.00066028
Iteration 7215, loss = 0.00066016
Iteration 7216, loss = 0.00066003
Iteration 7217, loss = 0.00065992
Iteration 7218, loss = 0.00065980
Iteration 7219, loss = 0.00065968
Iteration 7220, loss = 0.00065955
Iteration 7221, loss = 0.00065941
Iteration 7222, loss = 0.00065928
Iteration 7223, loss = 0.00065916
Iteration 7224, loss = 0.00065903
Iteration 7225, loss = 0.00065891
Iteration 7226, loss = 0.00065880
Iteration 7227, loss = 0.00065867
Iteration 7228, loss = 0.00065854
Iteration 7229, loss = 0.00065844
Iteration 7230, loss = 0.00065831
Iteration 7231, loss = 0.00065819
Iteration 7232, loss = 0.00065809
Iteration 7233, loss = 0.00065794
Iteration 7234, loss = 0.00065784
Iteration 7235, loss = 0.00065770
Iteration 7236, loss = 0.00065759
Iteration 7237, loss = 0.00065746
Iteration 7238, loss = 0.00065732
Iteration 7239, loss = 0.00065727
Iteration 7240, loss = 0.00065708
Iteration 7241, loss = 0.00065699
Iteration 7242, loss = 0.00065684
Iteration 7243, loss = 0.00065672
Iteration 7244, loss = 0.00065661
Iteration 7245, loss = 0.00065646
Iteration 7246, loss = 0.00065636
Iteration 7247, loss = 0.00065625
Iteration 7248, loss = 0.00065611
Iteration 7249, loss = 0.00065601
Iteration 7250, loss = 0.00065586
Iteration 7251, loss = 0.00065575
Iteration 7252, loss = 0.00065564
Iteration 7253, loss = 0.00065552
Iteration 7254, loss = 0.00065541
Iteration 7255, loss = 0.00065527
Iteration 7256, loss = 0.00065515
Iteration 7257, loss = 0.00065503
Iteration 7258, loss = 0.00065492
Iteration 7259, loss = 0.00065479
Iteration 7260, loss = 0.00065470
Iteration 7261, loss = 0.00065457
Iteration 7262, loss = 0.00065446
Iteration 7263, loss = 0.00065431
Iteration 7264, loss = 0.00065419
Iteration 7265, loss = 0.00065408
Iteration 7266, loss = 0.00065396
Iteration 7267, loss = 0.00065383
Iteration 7268, loss = 0.00065373
Iteration 7269, loss = 0.00065361
Iteration 7270, loss = 0.00065347
Iteration 7271, loss = 0.00065334
Iteration 7272, loss = 0.00065324
Iteration 7273, loss = 0.00065313
Iteration 7274, loss = 0.00065299
Iteration 7275, loss = 0.00065287
Iteration 7276, loss = 0.00065274
Iteration 7277, loss = 0.00065264
Iteration 7278, loss = 0.00065252
Iteration 7279, loss = 0.00065242
Iteration 7280, loss = 0.00065230
Iteration 7281, loss = 0.00065216
Iteration 7282, loss = 0.00065208
Iteration 7283, loss = 0.00065193
Iteration 7284, loss = 0.00065181
Iteration 7285, loss = 0.00065169
Iteration 7286, loss = 0.00065159
Iteration 7287, loss = 0.00065148
Iteration 7288, loss = 0.00065133
Iteration 7289, loss = 0.00065121
Iteration 7290, loss = 0.00065111
Iteration 7291, loss = 0.00065099
Iteration 7292, loss = 0.00065092
Iteration 7293, loss = 0.00065073
Iteration 7294, loss = 0.00065065
Iteration 7295, loss = 0.00065052
Iteration 7296, loss = 0.00065039
Iteration 7297, loss = 0.00065028
Iteration 7298, loss = 0.00065017
Iteration 7299, loss = 0.00065007
Iteration 7300, loss = 0.00064996
Iteration 7301, loss = 0.00064983
Iteration 7302, loss = 0.00064972
Iteration 7303, loss = 0.00064958
Iteration 7304, loss = 0.00064948
Iteration 7305, loss = 0.00064936
Iteration 7306, loss = 0.00064925
Iteration 7307, loss = 0.00064913
Iteration 7308, loss = 0.00064899
Iteration 7309, loss = 0.00064889
Iteration 7310, loss = 0.00064876
Iteration 7311, loss = 0.00064865
Iteration 7312, loss = 0.00064852
Iteration 7313, loss = 0.00064839
Iteration 7314, loss = 0.00064828
Iteration 7315, loss = 0.00064818
Iteration 7316, loss = 0.00064807
Iteration 7317, loss = 0.00064792
Iteration 7318, loss = 0.00064780
Iteration 7319, loss = 0.00064768
Iteration 7320, loss = 0.00064755
Iteration 7321, loss = 0.00064745
Iteration 7322, loss = 0.00064734
Iteration 7323, loss = 0.00064720
Iteration 7324, loss = 0.00064709
Iteration 7325, loss = 0.00064696
Iteration 7326, loss = 0.00064686
Iteration 7327, loss = 0.00064672
Iteration 7328, loss = 0.00064664
Iteration 7329, loss = 0.00064648
Iteration 7330, loss = 0.00064638
Iteration 7331, loss = 0.00064625
Iteration 7332, loss = 0.00064613
Iteration 7333, loss = 0.00064603
Iteration 7334, loss = 0.00064589
Iteration 7335, loss = 0.00064579
Iteration 7336, loss = 0.00064568
Iteration 7337, loss = 0.00064555
Iteration 7338, loss = 0.00064544
Iteration 7339, loss = 0.00064533
Iteration 7340, loss = 0.00064519
Iteration 7341, loss = 0.00064509
Iteration 7342, loss = 0.00064496
Iteration 7343, loss = 0.00064487
Iteration 7344, loss = 0.00064473
Iteration 7345, loss = 0.00064463
Iteration 7346, loss = 0.00064450
Iteration 7347, loss = 0.00064439
Iteration 7348, loss = 0.00064430
Iteration 7349, loss = 0.00064416
Iteration 7350, loss = 0.00064403
Iteration 7351, loss = 0.00064391
Iteration 7352, loss = 0.00064381
Iteration 7353, loss = 0.00064369
Iteration 7354, loss = 0.00064358
Iteration 7355, loss = 0.00064348
Iteration 7356, loss = 0.00064338
Iteration 7357, loss = 0.00064323
Iteration 7358, loss = 0.00064314
Iteration 7359, loss = 0.00064301
Iteration 7360, loss = 0.00064288
Iteration 7361, loss = 0.00064277
Iteration 7362, loss = 0.00064265
Iteration 7363, loss = 0.00064253
Iteration 7364, loss = 0.00064242
Iteration 7365, loss = 0.00064228
Iteration 7366, loss = 0.00064216
Iteration 7367, loss = 0.00064207
Iteration 7368, loss = 0.00064195
Iteration 7369, loss = 0.00064183
Iteration 7370, loss = 0.00064172
Iteration 7371, loss = 0.00064160
Iteration 7372, loss = 0.00064147
Iteration 7373, loss = 0.00064135
Iteration 7374, loss = 0.00064123
Iteration 7375, loss = 0.00064113
Iteration 7376, loss = 0.00064100
Iteration 7377, loss = 0.00064088
Iteration 7378, loss = 0.00064079
Iteration 7379, loss = 0.00064067
Iteration 7380, loss = 0.00064052
Iteration 7381, loss = 0.00064041
Iteration 7382, loss = 0.00064030
Iteration 7383, loss = 0.00064019
Iteration 7384, loss = 0.00064007
Iteration 7385, loss = 0.00063994
Iteration 7386, loss = 0.00063985
Iteration 7387, loss = 0.00063975
Iteration 7388, loss = 0.00063961
Iteration 7389, loss = 0.00063949
Iteration 7390, loss = 0.00063938
Iteration 7391, loss = 0.00063928
Iteration 7392, loss = 0.00063918
Iteration 7393, loss = 0.00063905
Iteration 7394, loss = 0.00063895
Iteration 7395, loss = 0.00063884
Iteration 7396, loss = 0.00063871
Iteration 7397, loss = 0.00063859
Iteration 7398, loss = 0.00063849
Iteration 7399, loss = 0.00063836
Iteration 7400, loss = 0.00063825
Iteration 7401, loss = 0.00063814
Iteration 7402, loss = 0.00063800
Iteration 7403, loss = 0.00063791
Iteration 7404, loss = 0.00063777
Iteration 7405, loss = 0.00063769
Iteration 7406, loss = 0.00063755
Iteration 7407, loss = 0.00063745
Iteration 7408, loss = 0.00063735
Iteration 7409, loss = 0.00063721
Iteration 7410, loss = 0.00063711
Iteration 7411, loss = 0.00063700
Iteration 7412, loss = 0.00063691
Iteration 7413, loss = 0.00063676
Iteration 7414, loss = 0.00063665
Iteration 7415, loss = 0.00063655
Iteration 7416, loss = 0.00063643
Iteration 7417, loss = 0.00063631
Iteration 7418, loss = 0.00063620
Iteration 7419, loss = 0.00063612
Iteration 7420, loss = 0.00063601
Iteration 7421, loss = 0.00063589
Iteration 7422, loss = 0.00063577
Iteration 7423, loss = 0.00063565
Iteration 7424, loss = 0.00063554
Iteration 7425, loss = 0.00063543
Iteration 7426, loss = 0.00063531
Iteration 7427, loss = 0.00063520
Iteration 7428, loss = 0.00063508
Iteration 7429, loss = 0.00063496
Iteration 7430, loss = 0.00063485
Iteration 7431, loss = 0.00063474
Iteration 7432, loss = 0.00063465
Iteration 7433, loss = 0.00063453
Iteration 7434, loss = 0.00063441
Iteration 7435, loss = 0.00063431
Iteration 7436, loss = 0.00063421
Iteration 7437, loss = 0.00063409
Iteration 7438, loss = 0.00063398
Iteration 7439, loss = 0.00063387
Iteration 7440, loss = 0.00063375
Iteration 7441, loss = 0.00063364
Iteration 7442, loss = 0.00063355
Iteration 7443, loss = 0.00063342
Iteration 7444, loss = 0.00063332
Iteration 7445, loss = 0.00063322
Iteration 7446, loss = 0.00063309
Iteration 7447, loss = 0.00063297
Iteration 7448, loss = 0.00063285
Iteration 7449, loss = 0.00063280
Iteration 7450, loss = 0.00063262
Iteration 7451, loss = 0.00063255
Iteration 7452, loss = 0.00063241
Iteration 7453, loss = 0.00063228
Iteration 7454, loss = 0.00063218
Iteration 7455, loss = 0.00063206
Iteration 7456, loss = 0.00063198
Iteration 7457, loss = 0.00063185
Iteration 7458, loss = 0.00063175
Iteration 7459, loss = 0.00063162
Iteration 7460, loss = 0.00063153
Iteration 7461, loss = 0.00063142
Iteration 7462, loss = 0.00063128
Iteration 7463, loss = 0.00063119
Iteration 7464, loss = 0.00063106
Iteration 7465, loss = 0.00063094
Iteration 7466, loss = 0.00063084
Iteration 7467, loss = 0.00063075
Iteration 7468, loss = 0.00063061
Iteration 7469, loss = 0.00063052
Iteration 7470, loss = 0.00063042
Iteration 7471, loss = 0.00063030
Iteration 7472, loss = 0.00063016
Iteration 7473, loss = 0.00063007
Iteration 7474, loss = 0.00062995
Iteration 7475, loss = 0.00062984
Iteration 7476, loss = 0.00062975
Iteration 7477, loss = 0.00062961
Iteration 7478, loss = 0.00062951
Iteration 7479, loss = 0.00062941
Iteration 7480, loss = 0.00062929
Iteration 7481, loss = 0.00062916
Iteration 7482, loss = 0.00062907
Iteration 7483, loss = 0.00062893
Iteration 7484, loss = 0.00062883
Iteration 7485, loss = 0.00062872
Iteration 7486, loss = 0.00062863
Iteration 7487, loss = 0.00062850
Iteration 7488, loss = 0.00062838
Iteration 7489, loss = 0.00062827
Iteration 7490, loss = 0.00062818
Iteration 7491, loss = 0.00062807
Iteration 7492, loss = 0.00062795
Iteration 7493, loss = 0.00062783
Iteration 7494, loss = 0.00062775
Iteration 7495, loss = 0.00062761
Iteration 7496, loss = 0.00062758
Iteration 7497, loss = 0.00062738
Iteration 7498, loss = 0.00062728
Iteration 7499, loss = 0.00062716
Iteration 7500, loss = 0.00062707
Iteration 7501, loss = 0.00062696
Iteration 7502, loss = 0.00062685
Iteration 7503, loss = 0.00062682
Iteration 7504, loss = 0.00062662
Iteration 7505, loss = 0.00062651
Iteration 7506, loss = 0.00062639
Iteration 7507, loss = 0.00062630
Iteration 7508, loss = 0.00062619
Iteration 7509, loss = 0.00062610
Iteration 7510, loss = 0.00062597
Iteration 7511, loss = 0.00062588
Iteration 7512, loss = 0.00062575
Iteration 7513, loss = 0.00062565
Iteration 7514, loss = 0.00062554
Iteration 7515, loss = 0.00062542
Iteration 7516, loss = 0.00062533
Iteration 7517, loss = 0.00062522
Iteration 7518, loss = 0.00062510
Iteration 7519, loss = 0.00062499
Iteration 7520, loss = 0.00062487
Iteration 7521, loss = 0.00062476
Iteration 7522, loss = 0.00062465
Iteration 7523, loss = 0.00062455
Iteration 7524, loss = 0.00062446
Iteration 7525, loss = 0.00062432
Iteration 7526, loss = 0.00062422
Iteration 7527, loss = 0.00062412
Iteration 7528, loss = 0.00062400
Iteration 7529, loss = 0.00062389
Iteration 7530, loss = 0.00062378
Iteration 7531, loss = 0.00062366
Iteration 7532, loss = 0.00062357
Iteration 7533, loss = 0.00062346
Iteration 7534, loss = 0.00062336
Iteration 7535, loss = 0.00062325
Iteration 7536, loss = 0.00062315
Iteration 7537, loss = 0.00062302
Iteration 7538, loss = 0.00062293
Iteration 7539, loss = 0.00062281
Iteration 7540, loss = 0.00062271
Iteration 7541, loss = 0.00062260
Iteration 7542, loss = 0.00062248
Iteration 7543, loss = 0.00062240
Iteration 7544, loss = 0.00062230
Iteration 7545, loss = 0.00062218
Iteration 7546, loss = 0.00062208
Iteration 7547, loss = 0.00062197
Iteration 7548, loss = 0.00062184
Iteration 7549, loss = 0.00062182
Iteration 7550, loss = 0.00062163
Iteration 7551, loss = 0.00062153
Iteration 7552, loss = 0.00062143
Iteration 7553, loss = 0.00062131
Iteration 7554, loss = 0.00062123
Iteration 7555, loss = 0.00062110
Iteration 7556, loss = 0.00062101
Iteration 7557, loss = 0.00062089
Iteration 7558, loss = 0.00062079
Iteration 7559, loss = 0.00062067
Iteration 7560, loss = 0.00062056
Iteration 7561, loss = 0.00062045
Iteration 7562, loss = 0.00062035
Iteration 7563, loss = 0.00062024
Iteration 7564, loss = 0.00062015
Iteration 7565, loss = 0.00062005
Iteration 7566, loss = 0.00061992
Iteration 7567, loss = 0.00061982
Iteration 7568, loss = 0.00061970
Iteration 7569, loss = 0.00061962
Iteration 7570, loss = 0.00061949
Iteration 7571, loss = 0.00061937
Iteration 7572, loss = 0.00061926
Iteration 7573, loss = 0.00061915
Iteration 7574, loss = 0.00061905
Iteration 7575, loss = 0.00061893
Iteration 7576, loss = 0.00061882
Iteration 7577, loss = 0.00061871
Iteration 7578, loss = 0.00061859
Iteration 7579, loss = 0.00061850
Iteration 7580, loss = 0.00061837
Iteration 7581, loss = 0.00061828
Iteration 7582, loss = 0.00061824
Iteration 7583, loss = 0.00061808
Iteration 7584, loss = 0.00061794
Iteration 7585, loss = 0.00061782
Iteration 7586, loss = 0.00061773
Iteration 7587, loss = 0.00061760
Iteration 7588, loss = 0.00061750
Iteration 7589, loss = 0.00061738
Iteration 7590, loss = 0.00061729
Iteration 7591, loss = 0.00061719
Iteration 7592, loss = 0.00061709
Iteration 7593, loss = 0.00061697
Iteration 7594, loss = 0.00061689
Iteration 7595, loss = 0.00061676
Iteration 7596, loss = 0.00061666
Iteration 7597, loss = 0.00061655
Iteration 7598, loss = 0.00061645
Iteration 7599, loss = 0.00061634
Iteration 7600, loss = 0.00061625
Iteration 7601, loss = 0.00061616
Iteration 7602, loss = 0.00061606
Iteration 7603, loss = 0.00061593
Iteration 7604, loss = 0.00061581
Iteration 7605, loss = 0.00061572
Iteration 7606, loss = 0.00061560
Iteration 7607, loss = 0.00061550
Iteration 7608, loss = 0.00061540
Iteration 7609, loss = 0.00061530
Iteration 7610, loss = 0.00061518
Iteration 7611, loss = 0.00061508
Iteration 7612, loss = 0.00061496
Iteration 7613, loss = 0.00061486
Iteration 7614, loss = 0.00061474
Iteration 7615, loss = 0.00061464
Iteration 7616, loss = 0.00061455
Iteration 7617, loss = 0.00061444
Iteration 7618, loss = 0.00061433
Iteration 7619, loss = 0.00061423
Iteration 7620, loss = 0.00061412
Iteration 7621, loss = 0.00061402
Iteration 7622, loss = 0.00061393
Iteration 7623, loss = 0.00061379
Iteration 7624, loss = 0.00061371
Iteration 7625, loss = 0.00061361
Iteration 7626, loss = 0.00061350
Iteration 7627, loss = 0.00061339
Iteration 7628, loss = 0.00061328
Iteration 7629, loss = 0.00061318
Iteration 7630, loss = 0.00061306
Iteration 7631, loss = 0.00061295
Iteration 7632, loss = 0.00061283
Iteration 7633, loss = 0.00061274
Iteration 7634, loss = 0.00061264
Iteration 7635, loss = 0.00061252
Iteration 7636, loss = 0.00061243
Iteration 7637, loss = 0.00061234
Iteration 7638, loss = 0.00061222
Iteration 7639, loss = 0.00061212
Iteration 7640, loss = 0.00061200
Iteration 7641, loss = 0.00061191
Iteration 7642, loss = 0.00061180
Iteration 7643, loss = 0.00061169
Iteration 7644, loss = 0.00061158
Iteration 7645, loss = 0.00061151
Iteration 7646, loss = 0.00061138
Iteration 7647, loss = 0.00061130
Iteration 7648, loss = 0.00061117
Iteration 7649, loss = 0.00061108
Iteration 7650, loss = 0.00061098
Iteration 7651, loss = 0.00061090
Iteration 7652, loss = 0.00061076
Iteration 7653, loss = 0.00061066
Iteration 7654, loss = 0.00061060
Iteration 7655, loss = 0.00061045
Iteration 7656, loss = 0.00061033
Iteration 7657, loss = 0.00061029
Iteration 7658, loss = 0.00061013
Iteration 7659, loss = 0.00061004
Iteration 7660, loss = 0.00060994
Iteration 7661, loss = 0.00060982
Iteration 7662, loss = 0.00060973
Iteration 7663, loss = 0.00060961
Iteration 7664, loss = 0.00060950
Iteration 7665, loss = 0.00060942
Iteration 7666, loss = 0.00060930
Iteration 7667, loss = 0.00060920
Iteration 7668, loss = 0.00060909
Iteration 7669, loss = 0.00060898
Iteration 7670, loss = 0.00060889
Iteration 7671, loss = 0.00060878
Iteration 7672, loss = 0.00060868
Iteration 7673, loss = 0.00060858
Iteration 7674, loss = 0.00060848
Iteration 7675, loss = 0.00060838
Iteration 7676, loss = 0.00060826
Iteration 7677, loss = 0.00060814
Iteration 7678, loss = 0.00060804
Iteration 7679, loss = 0.00060797
Iteration 7680, loss = 0.00060784
Iteration 7681, loss = 0.00060774
Iteration 7682, loss = 0.00060764
Iteration 7683, loss = 0.00060753
Iteration 7684, loss = 0.00060743
Iteration 7685, loss = 0.00060733
Iteration 7686, loss = 0.00060724
Iteration 7687, loss = 0.00060714
Iteration 7688, loss = 0.00060703
Iteration 7689, loss = 0.00060692
Iteration 7690, loss = 0.00060683
Iteration 7691, loss = 0.00060672
Iteration 7692, loss = 0.00060665
Iteration 7693, loss = 0.00060654
Iteration 7694, loss = 0.00060640
Iteration 7695, loss = 0.00060631
Iteration 7696, loss = 0.00060620
Iteration 7697, loss = 0.00060609
Iteration 7698, loss = 0.00060600
Iteration 7699, loss = 0.00060591
Iteration 7700, loss = 0.00060581
Iteration 7701, loss = 0.00060570
Iteration 7702, loss = 0.00060558
Iteration 7703, loss = 0.00060550
Iteration 7704, loss = 0.00060540
Iteration 7705, loss = 0.00060528
Iteration 7706, loss = 0.00060520
Iteration 7707, loss = 0.00060508
Iteration 7708, loss = 0.00060499
Iteration 7709, loss = 0.00060488
Iteration 7710, loss = 0.00060477
Iteration 7711, loss = 0.00060468
Iteration 7712, loss = 0.00060458
Iteration 7713, loss = 0.00060448
Iteration 7714, loss = 0.00060440
Iteration 7715, loss = 0.00060429
Iteration 7716, loss = 0.00060417
Iteration 7717, loss = 0.00060408
Iteration 7718, loss = 0.00060397
Iteration 7719, loss = 0.00060386
Iteration 7720, loss = 0.00060376
Iteration 7721, loss = 0.00060366
Iteration 7722, loss = 0.00060356
Iteration 7723, loss = 0.00060345
Iteration 7724, loss = 0.00060337
Iteration 7725, loss = 0.00060325
Iteration 7726, loss = 0.00060317
Iteration 7727, loss = 0.00060303
Iteration 7728, loss = 0.00060297
Iteration 7729, loss = 0.00060284
Iteration 7730, loss = 0.00060274
Iteration 7731, loss = 0.00060264
Iteration 7732, loss = 0.00060253
Iteration 7733, loss = 0.00060243
Iteration 7734, loss = 0.00060232
Iteration 7735, loss = 0.00060221
Iteration 7736, loss = 0.00060212
Iteration 7737, loss = 0.00060203
Iteration 7738, loss = 0.00060190
Iteration 7739, loss = 0.00060181
Iteration 7740, loss = 0.00060169
Iteration 7741, loss = 0.00060161
Iteration 7742, loss = 0.00060150
Iteration 7743, loss = 0.00060140
Iteration 7744, loss = 0.00060129
Iteration 7745, loss = 0.00060119
Iteration 7746, loss = 0.00060109
Iteration 7747, loss = 0.00060099
Iteration 7748, loss = 0.00060089
Iteration 7749, loss = 0.00060078
Iteration 7750, loss = 0.00060068
Iteration 7751, loss = 0.00060058
Iteration 7752, loss = 0.00060048
Iteration 7753, loss = 0.00060038
Iteration 7754, loss = 0.00060028
Iteration 7755, loss = 0.00060018
Iteration 7756, loss = 0.00060007
Iteration 7757, loss = 0.00059998
Iteration 7758, loss = 0.00059989
Iteration 7759, loss = 0.00059978
Iteration 7760, loss = 0.00059968
Iteration 7761, loss = 0.00059958
Iteration 7762, loss = 0.00059948
Iteration 7763, loss = 0.00059939
Iteration 7764, loss = 0.00059927
Iteration 7765, loss = 0.00059918
Iteration 7766, loss = 0.00059908
Iteration 7767, loss = 0.00059898
Iteration 7768, loss = 0.00059886
Iteration 7769, loss = 0.00059876
Iteration 7770, loss = 0.00059867
Iteration 7771, loss = 0.00059855
Iteration 7772, loss = 0.00059847
Iteration 7773, loss = 0.00059840
Iteration 7774, loss = 0.00059825
Iteration 7775, loss = 0.00059814
Iteration 7776, loss = 0.00059806
Iteration 7777, loss = 0.00059795
Iteration 7778, loss = 0.00059788
Iteration 7779, loss = 0.00059776
Iteration 7780, loss = 0.00059766
Iteration 7781, loss = 0.00059755
Iteration 7782, loss = 0.00059743
Iteration 7783, loss = 0.00059733
Iteration 7784, loss = 0.00059724
Iteration 7785, loss = 0.00059716
Iteration 7786, loss = 0.00059703
Iteration 7787, loss = 0.00059693
Iteration 7788, loss = 0.00059681
Iteration 7789, loss = 0.00059671
Iteration 7790, loss = 0.00059662
Iteration 7791, loss = 0.00059650
Iteration 7792, loss = 0.00059641
Iteration 7793, loss = 0.00059634
Iteration 7794, loss = 0.00059621
Iteration 7795, loss = 0.00059611
Iteration 7796, loss = 0.00059600
Iteration 7797, loss = 0.00059590
Iteration 7798, loss = 0.00059584
Iteration 7799, loss = 0.00059571
Iteration 7800, loss = 0.00059563
Iteration 7801, loss = 0.00059550
Iteration 7802, loss = 0.00059540
Iteration 7803, loss = 0.00059532
Iteration 7804, loss = 0.00059522
Iteration 7805, loss = 0.00059511
Iteration 7806, loss = 0.00059501
Iteration 7807, loss = 0.00059492
Iteration 7808, loss = 0.00059484
Iteration 7809, loss = 0.00059472
Iteration 7810, loss = 0.00059462
Iteration 7811, loss = 0.00059451
Iteration 7812, loss = 0.00059444
Iteration 7813, loss = 0.00059432
Iteration 7814, loss = 0.00059424
Iteration 7815, loss = 0.00059413
Iteration 7816, loss = 0.00059403
Iteration 7817, loss = 0.00059393
Iteration 7818, loss = 0.00059382
Iteration 7819, loss = 0.00059373
Iteration 7820, loss = 0.00059362
Iteration 7821, loss = 0.00059352
Iteration 7822, loss = 0.00059343
Iteration 7823, loss = 0.00059334
Iteration 7824, loss = 0.00059322
Iteration 7825, loss = 0.00059312
Iteration 7826, loss = 0.00059302
Iteration 7827, loss = 0.00059292
Iteration 7828, loss = 0.00059283
Iteration 7829, loss = 0.00059272
Iteration 7830, loss = 0.00059263
Iteration 7831, loss = 0.00059253
Iteration 7832, loss = 0.00059243
Iteration 7833, loss = 0.00059233
Iteration 7834, loss = 0.00059225
Iteration 7835, loss = 0.00059216
Iteration 7836, loss = 0.00059204
Iteration 7837, loss = 0.00059195
Iteration 7838, loss = 0.00059184
Iteration 7839, loss = 0.00059173
Iteration 7840, loss = 0.00059163
Iteration 7841, loss = 0.00059156
Iteration 7842, loss = 0.00059146
Iteration 7843, loss = 0.00059133
Iteration 7844, loss = 0.00059123
Iteration 7845, loss = 0.00059114
Iteration 7846, loss = 0.00059103
Iteration 7847, loss = 0.00059097
Iteration 7848, loss = 0.00059083
Iteration 7849, loss = 0.00059075
Iteration 7850, loss = 0.00059065
Iteration 7851, loss = 0.00059054
Iteration 7852, loss = 0.00059044
Iteration 7853, loss = 0.00059032
Iteration 7854, loss = 0.00059025
Iteration 7855, loss = 0.00059014
Iteration 7856, loss = 0.00059003
Iteration 7857, loss = 0.00058995
Iteration 7858, loss = 0.00058984
Iteration 7859, loss = 0.00058974
Iteration 7860, loss = 0.00058963
Iteration 7861, loss = 0.00058956
Iteration 7862, loss = 0.00058945
Iteration 7863, loss = 0.00058936
Iteration 7864, loss = 0.00058925
Iteration 7865, loss = 0.00058916
Iteration 7866, loss = 0.00058907
Iteration 7867, loss = 0.00058895
Iteration 7868, loss = 0.00058885
Iteration 7869, loss = 0.00058876
Iteration 7870, loss = 0.00058865
Iteration 7871, loss = 0.00058854
Iteration 7872, loss = 0.00058845
Iteration 7873, loss = 0.00058836
Iteration 7874, loss = 0.00058826
Iteration 7875, loss = 0.00058816
Iteration 7876, loss = 0.00058805
Iteration 7877, loss = 0.00058795
Iteration 7878, loss = 0.00058789
Iteration 7879, loss = 0.00058777
Iteration 7880, loss = 0.00058767
Iteration 7881, loss = 0.00058756
Iteration 7882, loss = 0.00058746
Iteration 7883, loss = 0.00058736
Iteration 7884, loss = 0.00058727
Iteration 7885, loss = 0.00058717
Iteration 7886, loss = 0.00058708
Iteration 7887, loss = 0.00058701
Iteration 7888, loss = 0.00058689
Iteration 7889, loss = 0.00058678
Iteration 7890, loss = 0.00058669
Iteration 7891, loss = 0.00058659
Iteration 7892, loss = 0.00058648
Iteration 7893, loss = 0.00058642
Iteration 7894, loss = 0.00058628
Iteration 7895, loss = 0.00058622
Iteration 7896, loss = 0.00058611
Iteration 7897, loss = 0.00058598
Iteration 7898, loss = 0.00058589
Iteration 7899, loss = 0.00058579
Iteration 7900, loss = 0.00058570
Iteration 7901, loss = 0.00058559
Iteration 7902, loss = 0.00058549
Iteration 7903, loss = 0.00058539
Iteration 7904, loss = 0.00058527
Iteration 7905, loss = 0.00058519
Iteration 7906, loss = 0.00058508
Iteration 7907, loss = 0.00058500
Iteration 7908, loss = 0.00058489
Iteration 7909, loss = 0.00058480
Iteration 7910, loss = 0.00058471
Iteration 7911, loss = 0.00058459
Iteration 7912, loss = 0.00058449
Iteration 7913, loss = 0.00058439
Iteration 7914, loss = 0.00058432
Iteration 7915, loss = 0.00058420
Iteration 7916, loss = 0.00058411
Iteration 7917, loss = 0.00058402
Iteration 7918, loss = 0.00058393
Iteration 7919, loss = 0.00058382
Iteration 7920, loss = 0.00058378
Iteration 7921, loss = 0.00058363
Iteration 7922, loss = 0.00058353
Iteration 7923, loss = 0.00058346
Iteration 7924, loss = 0.00058336
Iteration 7925, loss = 0.00058326
Iteration 7926, loss = 0.00058315
Iteration 7927, loss = 0.00058306
Iteration 7928, loss = 0.00058298
Iteration 7929, loss = 0.00058289
Iteration 7930, loss = 0.00058277
Iteration 7931, loss = 0.00058268
Iteration 7932, loss = 0.00058258
Iteration 7933, loss = 0.00058249
Iteration 7934, loss = 0.00058241
Iteration 7935, loss = 0.00058229
Iteration 7936, loss = 0.00058218
Iteration 7937, loss = 0.00058213
Iteration 7938, loss = 0.00058200
Iteration 7939, loss = 0.00058189
Iteration 7940, loss = 0.00058179
Iteration 7941, loss = 0.00058170
Iteration 7942, loss = 0.00058159
Iteration 7943, loss = 0.00058152
Iteration 7944, loss = 0.00058140
Iteration 7945, loss = 0.00058130
Iteration 7946, loss = 0.00058120
Iteration 7947, loss = 0.00058111
Iteration 7948, loss = 0.00058101
Iteration 7949, loss = 0.00058090
Iteration 7950, loss = 0.00058080
Iteration 7951, loss = 0.00058074
Iteration 7952, loss = 0.00058061
Iteration 7953, loss = 0.00058052
Iteration 7954, loss = 0.00058043
Iteration 7955, loss = 0.00058035
Iteration 7956, loss = 0.00058024
Iteration 7957, loss = 0.00058015
Iteration 7958, loss = 0.00058005
Iteration 7959, loss = 0.00058001
Iteration 7960, loss = 0.00057988
Iteration 7961, loss = 0.00057977
Iteration 7962, loss = 0.00057967
Iteration 7963, loss = 0.00057958
Iteration 7964, loss = 0.00057948
Iteration 7965, loss = 0.00057939
Iteration 7966, loss = 0.00057930
Iteration 7967, loss = 0.00057920
Iteration 7968, loss = 0.00057911
Iteration 7969, loss = 0.00057906
Iteration 7970, loss = 0.00057891
Iteration 7971, loss = 0.00057882
Iteration 7972, loss = 0.00057874
Iteration 7973, loss = 0.00057864
Iteration 7974, loss = 0.00057854
Iteration 7975, loss = 0.00057843
Iteration 7976, loss = 0.00057834
Iteration 7977, loss = 0.00057826
Iteration 7978, loss = 0.00057816
Iteration 7979, loss = 0.00057807
Iteration 7980, loss = 0.00057797
Iteration 7981, loss = 0.00057788
Iteration 7982, loss = 0.00057778
Iteration 7983, loss = 0.00057768
Iteration 7984, loss = 0.00057760
Iteration 7985, loss = 0.00057752
Iteration 7986, loss = 0.00057741
Iteration 7987, loss = 0.00057730
Iteration 7988, loss = 0.00057722
Iteration 7989, loss = 0.00057711
Iteration 7990, loss = 0.00057704
Iteration 7991, loss = 0.00057694
Iteration 7992, loss = 0.00057684
Iteration 7993, loss = 0.00057673
Iteration 7994, loss = 0.00057665
Iteration 7995, loss = 0.00057655
Iteration 7996, loss = 0.00057644
Iteration 7997, loss = 0.00057636
Iteration 7998, loss = 0.00057628
Iteration 7999, loss = 0.00057617
Iteration 8000, loss = 0.00057608
Iteration 1, loss = 1.04307925
Iteration 2, loss = 1.03999583
Iteration 3, loss = 1.03502421
Iteration 4, loss = 1.02882570
Iteration 5, loss = 1.02161886
Iteration 6, loss = 1.01353814
Iteration 7, loss = 1.00518033
Iteration 8, loss = 0.99629146
Iteration 9, loss = 0.98695016
Iteration 10, loss = 0.97780271
Iteration 11, loss = 0.96816411
Iteration 12, loss = 0.95885851
Iteration 13, loss = 0.94941970
Iteration 14, loss = 0.94031499
Iteration 15, loss = 0.93114893
Iteration 16, loss = 0.92247714
Iteration 17, loss = 0.91363217
Iteration 18, loss = 0.90530126
Iteration 19, loss = 0.89702973
Iteration 20, loss = 0.88896846
Iteration 21, loss = 0.88104884
Iteration 22, loss = 0.87349587
Iteration 23, loss = 0.86599414
Iteration 24, loss = 0.85846749
Iteration 25, loss = 0.85146273
Iteration 26, loss = 0.84443121
Iteration 27, loss = 0.83752044
Iteration 28, loss = 0.83091368
Iteration 29, loss = 0.82450974
Iteration 30, loss = 0.81823020
Iteration 31, loss = 0.81226947
Iteration 32, loss = 0.80641652
Iteration 33, loss = 0.80072972
Iteration 34, loss = 0.79533738
Iteration 35, loss = 0.78993272
Iteration 36, loss = 0.78466502
Iteration 37, loss = 0.77968623
Iteration 38, loss = 0.77465106
Iteration 39, loss = 0.76992409
Iteration 40, loss = 0.76532213
Iteration 41, loss = 0.76086048
Iteration 42, loss = 0.75667133
Iteration 43, loss = 0.75255111
Iteration 44, loss = 0.74860564
Iteration 45, loss = 0.74469058
Iteration 46, loss = 0.74091573
Iteration 47, loss = 0.73721243
Iteration 48, loss = 0.73349362
Iteration 49, loss = 0.72993439
Iteration 50, loss = 0.72628398
Iteration 51, loss = 0.72288935
Iteration 52, loss = 0.71937042
Iteration 53, loss = 0.71601488
Iteration 54, loss = 0.71259752
Iteration 55, loss = 0.70924144
Iteration 56, loss = 0.70593159
Iteration 57, loss = 0.70244926
Iteration 58, loss = 0.69918587
Iteration 59, loss = 0.69575496
Iteration 60, loss = 0.69240938
Iteration 61, loss = 0.68913388
Iteration 62, loss = 0.68589264
Iteration 63, loss = 0.68279815
Iteration 64, loss = 0.67959593
Iteration 65, loss = 0.67665969
Iteration 66, loss = 0.67369869
Iteration 67, loss = 0.67074037
Iteration 68, loss = 0.66793161
Iteration 69, loss = 0.66502675
Iteration 70, loss = 0.66227768
Iteration 71, loss = 0.65943683
Iteration 72, loss = 0.65671200
Iteration 73, loss = 0.65390359
Iteration 74, loss = 0.65117480
Iteration 75, loss = 0.64845979
Iteration 76, loss = 0.64573897
Iteration 77, loss = 0.64303636
Iteration 78, loss = 0.64035811
Iteration 79, loss = 0.63772134
Iteration 80, loss = 0.63510050
Iteration 81, loss = 0.63245408
Iteration 82, loss = 0.62989902
Iteration 83, loss = 0.62729651
Iteration 84, loss = 0.62468519
Iteration 85, loss = 0.62213611
Iteration 86, loss = 0.61953900
Iteration 87, loss = 0.61695991
Iteration 88, loss = 0.61441320
Iteration 89, loss = 0.61186128
Iteration 90, loss = 0.60933388
Iteration 91, loss = 0.60679272
Iteration 92, loss = 0.60431857
Iteration 93, loss = 0.60181055
Iteration 94, loss = 0.59932571
Iteration 95, loss = 0.59688260
Iteration 96, loss = 0.59442144
Iteration 97, loss = 0.59198855
Iteration 98, loss = 0.58958768
Iteration 99, loss = 0.58715291
Iteration 100, loss = 0.58477687
Iteration 101, loss = 0.58241489
Iteration 102, loss = 0.58000810
Iteration 103, loss = 0.57765496
Iteration 104, loss = 0.57530083
Iteration 105, loss = 0.57293686
Iteration 106, loss = 0.57063601
Iteration 107, loss = 0.56829556
Iteration 108, loss = 0.56602202
Iteration 109, loss = 0.56368847
Iteration 110, loss = 0.56141310
Iteration 111, loss = 0.55913684
Iteration 112, loss = 0.55684848
Iteration 113, loss = 0.55459141
Iteration 114, loss = 0.55226887
Iteration 115, loss = 0.55003086
Iteration 116, loss = 0.54777725
Iteration 117, loss = 0.54546740
Iteration 118, loss = 0.54325394
Iteration 119, loss = 0.54095827
Iteration 120, loss = 0.53872130
Iteration 121, loss = 0.53648561
Iteration 122, loss = 0.53426424
Iteration 123, loss = 0.53206056
Iteration 124, loss = 0.52986355
Iteration 125, loss = 0.52769955
Iteration 126, loss = 0.52553574
Iteration 127, loss = 0.52336834
Iteration 128, loss = 0.52123012
Iteration 129, loss = 0.51909027
Iteration 130, loss = 0.51699458
Iteration 131, loss = 0.51491887
Iteration 132, loss = 0.51285055
Iteration 133, loss = 0.51081903
Iteration 134, loss = 0.50877880
Iteration 135, loss = 0.50672233
Iteration 136, loss = 0.50468449
Iteration 137, loss = 0.50262792
Iteration 138, loss = 0.50056786
Iteration 139, loss = 0.49851399
Iteration 140, loss = 0.49642186
Iteration 141, loss = 0.49433977
Iteration 142, loss = 0.49227020
Iteration 143, loss = 0.49022006
Iteration 144, loss = 0.48813905
Iteration 145, loss = 0.48608720
Iteration 146, loss = 0.48403280
Iteration 147, loss = 0.48198720
Iteration 148, loss = 0.47996485
Iteration 149, loss = 0.47787730
Iteration 150, loss = 0.47583025
Iteration 151, loss = 0.47378219
Iteration 152, loss = 0.47172546
Iteration 153, loss = 0.46964821
Iteration 154, loss = 0.46761760
Iteration 155, loss = 0.46561831
Iteration 156, loss = 0.46354855
Iteration 157, loss = 0.46154501
Iteration 158, loss = 0.45951984
Iteration 159, loss = 0.45746532
Iteration 160, loss = 0.45542399
Iteration 161, loss = 0.45335974
Iteration 162, loss = 0.45128371
Iteration 163, loss = 0.44919683
Iteration 164, loss = 0.44710284
Iteration 165, loss = 0.44501159
Iteration 166, loss = 0.44289170
Iteration 167, loss = 0.44078787
Iteration 168, loss = 0.43869240
Iteration 169, loss = 0.43657617
Iteration 170, loss = 0.43450220
Iteration 171, loss = 0.43242008
Iteration 172, loss = 0.43033843
Iteration 173, loss = 0.42827048
Iteration 174, loss = 0.42622477
Iteration 175, loss = 0.42413930
Iteration 176, loss = 0.42211244
Iteration 177, loss = 0.42003580
Iteration 178, loss = 0.41799993
Iteration 179, loss = 0.41592504
Iteration 180, loss = 0.41389436
Iteration 181, loss = 0.41181702
Iteration 182, loss = 0.40977596
Iteration 183, loss = 0.40774588
Iteration 184, loss = 0.40567300
Iteration 185, loss = 0.40360979
Iteration 186, loss = 0.40156639
Iteration 187, loss = 0.39946802
Iteration 188, loss = 0.39740670
Iteration 189, loss = 0.39534885
Iteration 190, loss = 0.39326367
Iteration 191, loss = 0.39123002
Iteration 192, loss = 0.38918587
Iteration 193, loss = 0.38716371
Iteration 194, loss = 0.38513573
Iteration 195, loss = 0.38314985
Iteration 196, loss = 0.38111977
Iteration 197, loss = 0.37916040
Iteration 198, loss = 0.37716055
Iteration 199, loss = 0.37518481
Iteration 200, loss = 0.37320718
Iteration 201, loss = 0.37122136
Iteration 202, loss = 0.36925976
Iteration 203, loss = 0.36729194
Iteration 204, loss = 0.36531081
Iteration 205, loss = 0.36335089
Iteration 206, loss = 0.36137313
Iteration 207, loss = 0.35939495
Iteration 208, loss = 0.35740039
Iteration 209, loss = 0.35542377
Iteration 210, loss = 0.35342066
Iteration 211, loss = 0.35145078
Iteration 212, loss = 0.34942133
Iteration 213, loss = 0.34745443
Iteration 214, loss = 0.34545884
Iteration 215, loss = 0.34347444
Iteration 216, loss = 0.34149032
Iteration 217, loss = 0.33954129
Iteration 218, loss = 0.33758305
Iteration 219, loss = 0.33566055
Iteration 220, loss = 0.33374479
Iteration 221, loss = 0.33183759
Iteration 222, loss = 0.32995910
Iteration 223, loss = 0.32807133
Iteration 224, loss = 0.32617934
Iteration 225, loss = 0.32432901
Iteration 226, loss = 0.32243652
Iteration 227, loss = 0.32057577
Iteration 228, loss = 0.31869195
Iteration 229, loss = 0.31681752
Iteration 230, loss = 0.31496279
Iteration 231, loss = 0.31309415
Iteration 232, loss = 0.31124509
Iteration 233, loss = 0.30938812
Iteration 234, loss = 0.30754594
Iteration 235, loss = 0.30570288
Iteration 236, loss = 0.30387288
Iteration 237, loss = 0.30202179
Iteration 238, loss = 0.30022142
Iteration 239, loss = 0.29839110
Iteration 240, loss = 0.29659061
Iteration 241, loss = 0.29480913
Iteration 242, loss = 0.29301025
Iteration 243, loss = 0.29123295
Iteration 244, loss = 0.28945826
Iteration 245, loss = 0.28770300
Iteration 246, loss = 0.28593297
Iteration 247, loss = 0.28421070
Iteration 248, loss = 0.28247010
Iteration 249, loss = 0.28074992
Iteration 250, loss = 0.27907135
Iteration 251, loss = 0.27737733
Iteration 252, loss = 0.27569533
Iteration 253, loss = 0.27404131
Iteration 254, loss = 0.27239762
Iteration 255, loss = 0.27074550
Iteration 256, loss = 0.26912618
Iteration 257, loss = 0.26748297
Iteration 258, loss = 0.26588633
Iteration 259, loss = 0.26427334
Iteration 260, loss = 0.26266983
Iteration 261, loss = 0.26108493
Iteration 262, loss = 0.25951048
Iteration 263, loss = 0.25791507
Iteration 264, loss = 0.25633611
Iteration 265, loss = 0.25476976
Iteration 266, loss = 0.25321638
Iteration 267, loss = 0.25167653
Iteration 268, loss = 0.25014839
Iteration 269, loss = 0.24864041
Iteration 270, loss = 0.24714655
Iteration 271, loss = 0.24566191
Iteration 272, loss = 0.24418844
Iteration 273, loss = 0.24271198
Iteration 274, loss = 0.24127417
Iteration 275, loss = 0.23981910
Iteration 276, loss = 0.23839435
Iteration 277, loss = 0.23697222
Iteration 278, loss = 0.23556227
Iteration 279, loss = 0.23417880
Iteration 280, loss = 0.23279703
Iteration 281, loss = 0.23141961
Iteration 282, loss = 0.23003965
Iteration 283, loss = 0.22867924
Iteration 284, loss = 0.22731074
Iteration 285, loss = 0.22595030
Iteration 286, loss = 0.22460640
Iteration 287, loss = 0.22327046
Iteration 288, loss = 0.22195568
Iteration 289, loss = 0.22064423
Iteration 290, loss = 0.21934793
Iteration 291, loss = 0.21806279
Iteration 292, loss = 0.21679215
Iteration 293, loss = 0.21552655
Iteration 294, loss = 0.21426762
Iteration 295, loss = 0.21302444
Iteration 296, loss = 0.21178478
Iteration 297, loss = 0.21056291
Iteration 298, loss = 0.20932827
Iteration 299, loss = 0.20812384
Iteration 300, loss = 0.20692294
Iteration 301, loss = 0.20572171
Iteration 302, loss = 0.20453463
Iteration 303, loss = 0.20336623
Iteration 304, loss = 0.20219884
Iteration 305, loss = 0.20104435
Iteration 306, loss = 0.19989006
Iteration 307, loss = 0.19875539
Iteration 308, loss = 0.19763488
Iteration 309, loss = 0.19651452
Iteration 310, loss = 0.19541456
Iteration 311, loss = 0.19432513
Iteration 312, loss = 0.19324489
Iteration 313, loss = 0.19218307
Iteration 314, loss = 0.19111764
Iteration 315, loss = 0.19006489
Iteration 316, loss = 0.18901884
Iteration 317, loss = 0.18798074
Iteration 318, loss = 0.18695758
Iteration 319, loss = 0.18592982
Iteration 320, loss = 0.18491732
Iteration 321, loss = 0.18391244
Iteration 322, loss = 0.18290912
Iteration 323, loss = 0.18193561
Iteration 324, loss = 0.18095504
Iteration 325, loss = 0.17997647
Iteration 326, loss = 0.17901808
Iteration 327, loss = 0.17807094
Iteration 328, loss = 0.17712189
Iteration 329, loss = 0.17618393
Iteration 330, loss = 0.17525036
Iteration 331, loss = 0.17431764
Iteration 332, loss = 0.17340402
Iteration 333, loss = 0.17248794
Iteration 334, loss = 0.17158075
Iteration 335, loss = 0.17068278
Iteration 336, loss = 0.16978617
Iteration 337, loss = 0.16888619
Iteration 338, loss = 0.16800143
Iteration 339, loss = 0.16711847
Iteration 340, loss = 0.16624430
Iteration 341, loss = 0.16538058
Iteration 342, loss = 0.16451672
Iteration 343, loss = 0.16367973
Iteration 344, loss = 0.16282328
Iteration 345, loss = 0.16199828
Iteration 346, loss = 0.16117565
Iteration 347, loss = 0.16034228
Iteration 348, loss = 0.15953723
Iteration 349, loss = 0.15871250
Iteration 350, loss = 0.15789987
Iteration 351, loss = 0.15710334
Iteration 352, loss = 0.15630633
Iteration 353, loss = 0.15552530
Iteration 354, loss = 0.15475562
Iteration 355, loss = 0.15398879
Iteration 356, loss = 0.15323914
Iteration 357, loss = 0.15248459
Iteration 358, loss = 0.15173951
Iteration 359, loss = 0.15099669
Iteration 360, loss = 0.15026169
Iteration 361, loss = 0.14953353
Iteration 362, loss = 0.14880375
Iteration 363, loss = 0.14808107
Iteration 364, loss = 0.14736878
Iteration 365, loss = 0.14666962
Iteration 366, loss = 0.14595827
Iteration 367, loss = 0.14526731
Iteration 368, loss = 0.14458408
Iteration 369, loss = 0.14390698
Iteration 370, loss = 0.14323139
Iteration 371, loss = 0.14257827
Iteration 372, loss = 0.14190820
Iteration 373, loss = 0.14126011
Iteration 374, loss = 0.14059744
Iteration 375, loss = 0.13994959
Iteration 376, loss = 0.13930117
Iteration 377, loss = 0.13866319
Iteration 378, loss = 0.13803389
Iteration 379, loss = 0.13739647
Iteration 380, loss = 0.13677701
Iteration 381, loss = 0.13615950
Iteration 382, loss = 0.13554596
Iteration 383, loss = 0.13494024
Iteration 384, loss = 0.13433267
Iteration 385, loss = 0.13373739
Iteration 386, loss = 0.13313569
Iteration 387, loss = 0.13254415
Iteration 388, loss = 0.13195306
Iteration 389, loss = 0.13137545
Iteration 390, loss = 0.13079789
Iteration 391, loss = 0.13022925
Iteration 392, loss = 0.12965555
Iteration 393, loss = 0.12909943
Iteration 394, loss = 0.12854505
Iteration 395, loss = 0.12799619
Iteration 396, loss = 0.12744768
Iteration 397, loss = 0.12691285
Iteration 398, loss = 0.12637566
Iteration 399, loss = 0.12583385
Iteration 400, loss = 0.12530248
Iteration 401, loss = 0.12477453
Iteration 402, loss = 0.12425450
Iteration 403, loss = 0.12373895
Iteration 404, loss = 0.12322720
Iteration 405, loss = 0.12271754
Iteration 406, loss = 0.12220976
Iteration 407, loss = 0.12171283
Iteration 408, loss = 0.12121465
Iteration 409, loss = 0.12071863
Iteration 410, loss = 0.12022876
Iteration 411, loss = 0.11974569
Iteration 412, loss = 0.11926392
Iteration 413, loss = 0.11878708
Iteration 414, loss = 0.11831351
Iteration 415, loss = 0.11783844
Iteration 416, loss = 0.11737401
Iteration 417, loss = 0.11690068
Iteration 418, loss = 0.11643744
Iteration 419, loss = 0.11597359
Iteration 420, loss = 0.11551722
Iteration 421, loss = 0.11505658
Iteration 422, loss = 0.11461234
Iteration 423, loss = 0.11416397
Iteration 424, loss = 0.11372443
Iteration 425, loss = 0.11328239
Iteration 426, loss = 0.11285571
Iteration 427, loss = 0.11242491
Iteration 428, loss = 0.11200538
Iteration 429, loss = 0.11158169
Iteration 430, loss = 0.11116815
Iteration 431, loss = 0.11075861
Iteration 432, loss = 0.11034766
Iteration 433, loss = 0.10992752
Iteration 434, loss = 0.10951661
Iteration 435, loss = 0.10911506
Iteration 436, loss = 0.10870667
Iteration 437, loss = 0.10830406
Iteration 438, loss = 0.10790136
Iteration 439, loss = 0.10751179
Iteration 440, loss = 0.10711374
Iteration 441, loss = 0.10672641
Iteration 442, loss = 0.10633666
Iteration 443, loss = 0.10596099
Iteration 444, loss = 0.10557841
Iteration 445, loss = 0.10520618
Iteration 446, loss = 0.10483513
Iteration 447, loss = 0.10446043
Iteration 448, loss = 0.10408579
Iteration 449, loss = 0.10370768
Iteration 450, loss = 0.10334467
Iteration 451, loss = 0.10297035
Iteration 452, loss = 0.10261371
Iteration 453, loss = 0.10225377
Iteration 454, loss = 0.10190277
Iteration 455, loss = 0.10156222
Iteration 456, loss = 0.10120511
Iteration 457, loss = 0.10085715
Iteration 458, loss = 0.10051421
Iteration 459, loss = 0.10016481
Iteration 460, loss = 0.09982839
Iteration 461, loss = 0.09948636
Iteration 462, loss = 0.09915331
Iteration 463, loss = 0.09882079
Iteration 464, loss = 0.09849379
Iteration 465, loss = 0.09816883
Iteration 466, loss = 0.09784982
Iteration 467, loss = 0.09753644
Iteration 468, loss = 0.09721503
Iteration 469, loss = 0.09689917
Iteration 470, loss = 0.09658038
Iteration 471, loss = 0.09627910
Iteration 472, loss = 0.09596833
Iteration 473, loss = 0.09565642
Iteration 474, loss = 0.09535292
Iteration 475, loss = 0.09504549
Iteration 476, loss = 0.09474972
Iteration 477, loss = 0.09444849
Iteration 478, loss = 0.09415067
Iteration 479, loss = 0.09385454
Iteration 480, loss = 0.09356640
Iteration 481, loss = 0.09327672
Iteration 482, loss = 0.09298090
Iteration 483, loss = 0.09269893
Iteration 484, loss = 0.09240847
Iteration 485, loss = 0.09212093
Iteration 486, loss = 0.09183333
Iteration 487, loss = 0.09154477
Iteration 488, loss = 0.09126854
Iteration 489, loss = 0.09098954
Iteration 490, loss = 0.09070588
Iteration 491, loss = 0.09043449
Iteration 492, loss = 0.09015569
Iteration 493, loss = 0.08988000
Iteration 494, loss = 0.08960489
Iteration 495, loss = 0.08933198
Iteration 496, loss = 0.08906492
Iteration 497, loss = 0.08879630
Iteration 498, loss = 0.08854458
Iteration 499, loss = 0.08826668
Iteration 500, loss = 0.08800176
Iteration 501, loss = 0.08774522
Iteration 502, loss = 0.08747920
Iteration 503, loss = 0.08722209
Iteration 504, loss = 0.08696110
Iteration 505, loss = 0.08670934
Iteration 506, loss = 0.08645193
Iteration 507, loss = 0.08619863
Iteration 508, loss = 0.08595299
Iteration 509, loss = 0.08570242
Iteration 510, loss = 0.08545522
Iteration 511, loss = 0.08521165
Iteration 512, loss = 0.08496437
Iteration 513, loss = 0.08473287
Iteration 514, loss = 0.08449186
Iteration 515, loss = 0.08424581
Iteration 516, loss = 0.08400855
Iteration 517, loss = 0.08376910
Iteration 518, loss = 0.08353224
Iteration 519, loss = 0.08329269
Iteration 520, loss = 0.08306176
Iteration 521, loss = 0.08283082
Iteration 522, loss = 0.08259260
Iteration 523, loss = 0.08236612
Iteration 524, loss = 0.08213440
Iteration 525, loss = 0.08190909
Iteration 526, loss = 0.08168522
Iteration 527, loss = 0.08146482
Iteration 528, loss = 0.08124222
Iteration 529, loss = 0.08102486
Iteration 530, loss = 0.08080203
Iteration 531, loss = 0.08058633
Iteration 532, loss = 0.08036845
Iteration 533, loss = 0.08015290
Iteration 534, loss = 0.07994062
Iteration 535, loss = 0.07973324
Iteration 536, loss = 0.07952150
Iteration 537, loss = 0.07931713
Iteration 538, loss = 0.07911204
Iteration 539, loss = 0.07890893
Iteration 540, loss = 0.07870854
Iteration 541, loss = 0.07850800
Iteration 542, loss = 0.07830766
Iteration 543, loss = 0.07810968
Iteration 544, loss = 0.07791586
Iteration 545, loss = 0.07771893
Iteration 546, loss = 0.07751833
Iteration 547, loss = 0.07732108
Iteration 548, loss = 0.07712864
Iteration 549, loss = 0.07693332
Iteration 550, loss = 0.07674115
Iteration 551, loss = 0.07654665
Iteration 552, loss = 0.07636140
Iteration 553, loss = 0.07617045
Iteration 554, loss = 0.07598365
Iteration 555, loss = 0.07580108
Iteration 556, loss = 0.07562001
Iteration 557, loss = 0.07543959
Iteration 558, loss = 0.07526702
Iteration 559, loss = 0.07508105
Iteration 560, loss = 0.07490580
Iteration 561, loss = 0.07472594
Iteration 562, loss = 0.07454972
Iteration 563, loss = 0.07437347
Iteration 564, loss = 0.07419464
Iteration 565, loss = 0.07402481
Iteration 566, loss = 0.07384622
Iteration 567, loss = 0.07367124
Iteration 568, loss = 0.07349977
Iteration 569, loss = 0.07333160
Iteration 570, loss = 0.07316297
Iteration 571, loss = 0.07299255
Iteration 572, loss = 0.07282303
Iteration 573, loss = 0.07265763
Iteration 574, loss = 0.07248711
Iteration 575, loss = 0.07231770
Iteration 576, loss = 0.07214809
Iteration 577, loss = 0.07198412
Iteration 578, loss = 0.07181731
Iteration 579, loss = 0.07165398
Iteration 580, loss = 0.07148805
Iteration 581, loss = 0.07132903
Iteration 582, loss = 0.07116557
Iteration 583, loss = 0.07100703
Iteration 584, loss = 0.07084793
Iteration 585, loss = 0.07069924
Iteration 586, loss = 0.07053895
Iteration 587, loss = 0.07037917
Iteration 588, loss = 0.07022305
Iteration 589, loss = 0.07006739
Iteration 590, loss = 0.06991468
Iteration 591, loss = 0.06975896
Iteration 592, loss = 0.06960239
Iteration 593, loss = 0.06945601
Iteration 594, loss = 0.06929882
Iteration 595, loss = 0.06914494
Iteration 596, loss = 0.06899132
Iteration 597, loss = 0.06883850
Iteration 598, loss = 0.06868865
Iteration 599, loss = 0.06853699
Iteration 600, loss = 0.06838803
Iteration 601, loss = 0.06823719
Iteration 602, loss = 0.06808957
Iteration 603, loss = 0.06794112
Iteration 604, loss = 0.06779251
Iteration 605, loss = 0.06764292
Iteration 606, loss = 0.06749597
Iteration 607, loss = 0.06734800
Iteration 608, loss = 0.06721185
Iteration 609, loss = 0.06706294
Iteration 610, loss = 0.06692258
Iteration 611, loss = 0.06677555
Iteration 612, loss = 0.06663330
Iteration 613, loss = 0.06649217
Iteration 614, loss = 0.06635140
Iteration 615, loss = 0.06620730
Iteration 616, loss = 0.06606452
Iteration 617, loss = 0.06593024
Iteration 618, loss = 0.06579702
Iteration 619, loss = 0.06565487
Iteration 620, loss = 0.06551732
Iteration 621, loss = 0.06538504
Iteration 622, loss = 0.06525307
Iteration 623, loss = 0.06512367
Iteration 624, loss = 0.06499391
Iteration 625, loss = 0.06485991
Iteration 626, loss = 0.06472956
Iteration 627, loss = 0.06459625
Iteration 628, loss = 0.06446353
Iteration 629, loss = 0.06433604
Iteration 630, loss = 0.06420383
Iteration 631, loss = 0.06407502
Iteration 632, loss = 0.06394778
Iteration 633, loss = 0.06381995
Iteration 634, loss = 0.06369335
Iteration 635, loss = 0.06356780
Iteration 636, loss = 0.06344358
Iteration 637, loss = 0.06331255
Iteration 638, loss = 0.06318858
Iteration 639, loss = 0.06306120
Iteration 640, loss = 0.06293488
Iteration 641, loss = 0.06280748
Iteration 642, loss = 0.06268417
Iteration 643, loss = 0.06255394
Iteration 644, loss = 0.06243234
Iteration 645, loss = 0.06230888
Iteration 646, loss = 0.06218362
Iteration 647, loss = 0.06205848
Iteration 648, loss = 0.06193735
Iteration 649, loss = 0.06181867
Iteration 650, loss = 0.06169871
Iteration 651, loss = 0.06159025
Iteration 652, loss = 0.06146793
Iteration 653, loss = 0.06135282
Iteration 654, loss = 0.06123578
Iteration 655, loss = 0.06112367
Iteration 656, loss = 0.06101051
Iteration 657, loss = 0.06089137
Iteration 658, loss = 0.06077632
Iteration 659, loss = 0.06066478
Iteration 660, loss = 0.06054894
Iteration 661, loss = 0.06043891
Iteration 662, loss = 0.06032615
Iteration 663, loss = 0.06021891
Iteration 664, loss = 0.06010596
Iteration 665, loss = 0.05999879
Iteration 666, loss = 0.05988927
Iteration 667, loss = 0.05978317
Iteration 668, loss = 0.05967394
Iteration 669, loss = 0.05956667
Iteration 670, loss = 0.05945933
Iteration 671, loss = 0.05935577
Iteration 672, loss = 0.05924445
Iteration 673, loss = 0.05913761
Iteration 674, loss = 0.05902984
Iteration 675, loss = 0.05892293
Iteration 676, loss = 0.05881607
Iteration 677, loss = 0.05871022
Iteration 678, loss = 0.05859920
Iteration 679, loss = 0.05849942
Iteration 680, loss = 0.05838975
Iteration 681, loss = 0.05828350
Iteration 682, loss = 0.05817606
Iteration 683, loss = 0.05806947
Iteration 684, loss = 0.05796354
Iteration 685, loss = 0.05785923
Iteration 686, loss = 0.05774957
Iteration 687, loss = 0.05765320
Iteration 688, loss = 0.05754137
Iteration 689, loss = 0.05743778
Iteration 690, loss = 0.05733911
Iteration 691, loss = 0.05723154
Iteration 692, loss = 0.05713179
Iteration 693, loss = 0.05702705
Iteration 694, loss = 0.05693087
Iteration 695, loss = 0.05682528
Iteration 696, loss = 0.05672558
Iteration 697, loss = 0.05662598
Iteration 698, loss = 0.05652687
Iteration 699, loss = 0.05643206
Iteration 700, loss = 0.05633313
Iteration 701, loss = 0.05623778
Iteration 702, loss = 0.05614234
Iteration 703, loss = 0.05604994
Iteration 704, loss = 0.05594717
Iteration 705, loss = 0.05585117
Iteration 706, loss = 0.05576421
Iteration 707, loss = 0.05566685
Iteration 708, loss = 0.05557228
Iteration 709, loss = 0.05547990
Iteration 710, loss = 0.05538740
Iteration 711, loss = 0.05529696
Iteration 712, loss = 0.05520711
Iteration 713, loss = 0.05511017
Iteration 714, loss = 0.05502062
Iteration 715, loss = 0.05492386
Iteration 716, loss = 0.05483538
Iteration 717, loss = 0.05473718
Iteration 718, loss = 0.05464448
Iteration 719, loss = 0.05456137
Iteration 720, loss = 0.05446666
Iteration 721, loss = 0.05437296
Iteration 722, loss = 0.05428137
Iteration 723, loss = 0.05418819
Iteration 724, loss = 0.05410062
Iteration 725, loss = 0.05401128
Iteration 726, loss = 0.05391810
Iteration 727, loss = 0.05383195
Iteration 728, loss = 0.05374942
Iteration 729, loss = 0.05365858
Iteration 730, loss = 0.05357128
Iteration 731, loss = 0.05348427
Iteration 732, loss = 0.05339542
Iteration 733, loss = 0.05331078
Iteration 734, loss = 0.05322348
Iteration 735, loss = 0.05313895
Iteration 736, loss = 0.05305995
Iteration 737, loss = 0.05297755
Iteration 738, loss = 0.05288957
Iteration 739, loss = 0.05280680
Iteration 740, loss = 0.05272463
Iteration 741, loss = 0.05263685
Iteration 742, loss = 0.05254794
Iteration 743, loss = 0.05246703
Iteration 744, loss = 0.05238037
Iteration 745, loss = 0.05229739
Iteration 746, loss = 0.05221555
Iteration 747, loss = 0.05212853
Iteration 748, loss = 0.05204854
Iteration 749, loss = 0.05195666
Iteration 750, loss = 0.05187264
Iteration 751, loss = 0.05179335
Iteration 752, loss = 0.05170427
Iteration 753, loss = 0.05162398
Iteration 754, loss = 0.05154455
Iteration 755, loss = 0.05146430
Iteration 756, loss = 0.05138375
Iteration 757, loss = 0.05130162
Iteration 758, loss = 0.05122712
Iteration 759, loss = 0.05114701
Iteration 760, loss = 0.05107798
Iteration 761, loss = 0.05099793
Iteration 762, loss = 0.05092657
Iteration 763, loss = 0.05084281
Iteration 764, loss = 0.05076793
Iteration 765, loss = 0.05069301
Iteration 766, loss = 0.05061596
Iteration 767, loss = 0.05053826
Iteration 768, loss = 0.05046393
Iteration 769, loss = 0.05038844
Iteration 770, loss = 0.05030947
Iteration 771, loss = 0.05023540
Iteration 772, loss = 0.05015914
Iteration 773, loss = 0.05008456
Iteration 774, loss = 0.05000850
Iteration 775, loss = 0.04992996
Iteration 776, loss = 0.04985635
Iteration 777, loss = 0.04978395
Iteration 778, loss = 0.04970714
Iteration 779, loss = 0.04963465
Iteration 780, loss = 0.04955778
Iteration 781, loss = 0.04948051
Iteration 782, loss = 0.04940798
Iteration 783, loss = 0.04933010
Iteration 784, loss = 0.04925753
Iteration 785, loss = 0.04917930
Iteration 786, loss = 0.04910582
Iteration 787, loss = 0.04903241
Iteration 788, loss = 0.04895950
Iteration 789, loss = 0.04888354
Iteration 790, loss = 0.04881546
Iteration 791, loss = 0.04874223
Iteration 792, loss = 0.04867154
Iteration 793, loss = 0.04860025
Iteration 794, loss = 0.04853022
Iteration 795, loss = 0.04846010
Iteration 796, loss = 0.04839213
Iteration 797, loss = 0.04832695
Iteration 798, loss = 0.04825356
Iteration 799, loss = 0.04818443
Iteration 800, loss = 0.04812290
Iteration 801, loss = 0.04804814
Iteration 802, loss = 0.04798154
Iteration 803, loss = 0.04791244
Iteration 804, loss = 0.04784266
Iteration 805, loss = 0.04777598
Iteration 806, loss = 0.04770899
Iteration 807, loss = 0.04764354
Iteration 808, loss = 0.04757738
Iteration 809, loss = 0.04751181
Iteration 810, loss = 0.04744719
Iteration 811, loss = 0.04738237
Iteration 812, loss = 0.04731421
Iteration 813, loss = 0.04724960
Iteration 814, loss = 0.04718020
Iteration 815, loss = 0.04711121
Iteration 816, loss = 0.04704296
Iteration 817, loss = 0.04697541
Iteration 818, loss = 0.04691123
Iteration 819, loss = 0.04683842
Iteration 820, loss = 0.04677233
Iteration 821, loss = 0.04670505
Iteration 822, loss = 0.04663619
Iteration 823, loss = 0.04657063
Iteration 824, loss = 0.04650228
Iteration 825, loss = 0.04643420
Iteration 826, loss = 0.04636966
Iteration 827, loss = 0.04630865
Iteration 828, loss = 0.04623531
Iteration 829, loss = 0.04617351
Iteration 830, loss = 0.04610814
Iteration 831, loss = 0.04604391
Iteration 832, loss = 0.04598028
Iteration 833, loss = 0.04591904
Iteration 834, loss = 0.04585406
Iteration 835, loss = 0.04579086
Iteration 836, loss = 0.04572993
Iteration 837, loss = 0.04566738
Iteration 838, loss = 0.04560394
Iteration 839, loss = 0.04554216
Iteration 840, loss = 0.04548063
Iteration 841, loss = 0.04542031
Iteration 842, loss = 0.04535771
Iteration 843, loss = 0.04529724
Iteration 844, loss = 0.04523858
Iteration 845, loss = 0.04517870
Iteration 846, loss = 0.04511742
Iteration 847, loss = 0.04505805
Iteration 848, loss = 0.04500044
Iteration 849, loss = 0.04493701
Iteration 850, loss = 0.04488132
Iteration 851, loss = 0.04481854
Iteration 852, loss = 0.04475890
Iteration 853, loss = 0.04470189
Iteration 854, loss = 0.04464039
Iteration 855, loss = 0.04458128
Iteration 856, loss = 0.04452087
Iteration 857, loss = 0.04446648
Iteration 858, loss = 0.04440651
Iteration 859, loss = 0.04434829
Iteration 860, loss = 0.04428885
Iteration 861, loss = 0.04423220
Iteration 862, loss = 0.04417186
Iteration 863, loss = 0.04411363
Iteration 864, loss = 0.04405330
Iteration 865, loss = 0.04399210
Iteration 866, loss = 0.04393519
Iteration 867, loss = 0.04387609
Iteration 868, loss = 0.04381938
Iteration 869, loss = 0.04376184
Iteration 870, loss = 0.04370801
Iteration 871, loss = 0.04365393
Iteration 872, loss = 0.04359773
Iteration 873, loss = 0.04353826
Iteration 874, loss = 0.04348271
Iteration 875, loss = 0.04342597
Iteration 876, loss = 0.04336835
Iteration 877, loss = 0.04332120
Iteration 878, loss = 0.04325838
Iteration 879, loss = 0.04320118
Iteration 880, loss = 0.04314360
Iteration 881, loss = 0.04309054
Iteration 882, loss = 0.04303055
Iteration 883, loss = 0.04297707
Iteration 884, loss = 0.04291810
Iteration 885, loss = 0.04286227
Iteration 886, loss = 0.04280741
Iteration 887, loss = 0.04275268
Iteration 888, loss = 0.04270094
Iteration 889, loss = 0.04264225
Iteration 890, loss = 0.04258814
Iteration 891, loss = 0.04253313
Iteration 892, loss = 0.04247630
Iteration 893, loss = 0.04242117
Iteration 894, loss = 0.04236841
Iteration 895, loss = 0.04231103
Iteration 896, loss = 0.04225761
Iteration 897, loss = 0.04220598
Iteration 898, loss = 0.04215035
Iteration 899, loss = 0.04209604
Iteration 900, loss = 0.04204304
Iteration 901, loss = 0.04199138
Iteration 902, loss = 0.04193890
Iteration 903, loss = 0.04188453
Iteration 904, loss = 0.04183729
Iteration 905, loss = 0.04177740
Iteration 906, loss = 0.04172482
Iteration 907, loss = 0.04166877
Iteration 908, loss = 0.04161672
Iteration 909, loss = 0.04156407
Iteration 910, loss = 0.04151009
Iteration 911, loss = 0.04145765
Iteration 912, loss = 0.04140689
Iteration 913, loss = 0.04135558
Iteration 914, loss = 0.04130390
Iteration 915, loss = 0.04125445
Iteration 916, loss = 0.04120020
Iteration 917, loss = 0.04114809
Iteration 918, loss = 0.04109837
Iteration 919, loss = 0.04104394
Iteration 920, loss = 0.04099727
Iteration 921, loss = 0.04094462
Iteration 922, loss = 0.04089155
Iteration 923, loss = 0.04084031
Iteration 924, loss = 0.04078971
Iteration 925, loss = 0.04073852
Iteration 926, loss = 0.04068862
Iteration 927, loss = 0.04063522
Iteration 928, loss = 0.04058458
Iteration 929, loss = 0.04053948
Iteration 930, loss = 0.04048611
Iteration 931, loss = 0.04043547
Iteration 932, loss = 0.04038419
Iteration 933, loss = 0.04033569
Iteration 934, loss = 0.04028912
Iteration 935, loss = 0.04024148
Iteration 936, loss = 0.04019277
Iteration 937, loss = 0.04015031
Iteration 938, loss = 0.04010045
Iteration 939, loss = 0.04005781
Iteration 940, loss = 0.04000586
Iteration 941, loss = 0.03995411
Iteration 942, loss = 0.03990900
Iteration 943, loss = 0.03985821
Iteration 944, loss = 0.03981483
Iteration 945, loss = 0.03976231
Iteration 946, loss = 0.03971609
Iteration 947, loss = 0.03966990
Iteration 948, loss = 0.03962019
Iteration 949, loss = 0.03957325
Iteration 950, loss = 0.03952428
Iteration 951, loss = 0.03947453
Iteration 952, loss = 0.03942406
Iteration 953, loss = 0.03937634
Iteration 954, loss = 0.03932831
Iteration 955, loss = 0.03927948
Iteration 956, loss = 0.03923361
Iteration 957, loss = 0.03918586
Iteration 958, loss = 0.03913770
Iteration 959, loss = 0.03909198
Iteration 960, loss = 0.03904668
Iteration 961, loss = 0.03899732
Iteration 962, loss = 0.03895071
Iteration 963, loss = 0.03890413
Iteration 964, loss = 0.03885872
Iteration 965, loss = 0.03881297
Iteration 966, loss = 0.03876749
Iteration 967, loss = 0.03872410
Iteration 968, loss = 0.03867786
Iteration 969, loss = 0.03863145
Iteration 970, loss = 0.03858563
Iteration 971, loss = 0.03854109
Iteration 972, loss = 0.03849364
Iteration 973, loss = 0.03844662
Iteration 974, loss = 0.03840453
Iteration 975, loss = 0.03835890
Iteration 976, loss = 0.03831654
Iteration 977, loss = 0.03826794
Iteration 978, loss = 0.03822224
Iteration 979, loss = 0.03817781
Iteration 980, loss = 0.03813384
Iteration 981, loss = 0.03808834
Iteration 982, loss = 0.03804277
Iteration 983, loss = 0.03800081
Iteration 984, loss = 0.03795587
Iteration 985, loss = 0.03791341
Iteration 986, loss = 0.03786945
Iteration 987, loss = 0.03782650
Iteration 988, loss = 0.03778984
Iteration 989, loss = 0.03774435
Iteration 990, loss = 0.03770843
Iteration 991, loss = 0.03766380
Iteration 992, loss = 0.03762151
Iteration 993, loss = 0.03757997
Iteration 994, loss = 0.03753888
Iteration 995, loss = 0.03749600
Iteration 996, loss = 0.03745658
Iteration 997, loss = 0.03741588
Iteration 998, loss = 0.03737505
Iteration 999, loss = 0.03733351
Iteration 1000, loss = 0.03729334
Iteration 1001, loss = 0.03725455
Iteration 1002, loss = 0.03721160
Iteration 1003, loss = 0.03716994
Iteration 1004, loss = 0.03712945
Iteration 1005, loss = 0.03708957
Iteration 1006, loss = 0.03704921
Iteration 1007, loss = 0.03701107
Iteration 1008, loss = 0.03696979
Iteration 1009, loss = 0.03692899
Iteration 1010, loss = 0.03688826
Iteration 1011, loss = 0.03684796
Iteration 1012, loss = 0.03680935
Iteration 1013, loss = 0.03676934
Iteration 1014, loss = 0.03672928
Iteration 1015, loss = 0.03669178
Iteration 1016, loss = 0.03665343
Iteration 1017, loss = 0.03661374
Iteration 1018, loss = 0.03657610
Iteration 1019, loss = 0.03653781
Iteration 1020, loss = 0.03649872
Iteration 1021, loss = 0.03646051
Iteration 1022, loss = 0.03642517
Iteration 1023, loss = 0.03638352
Iteration 1024, loss = 0.03634326
Iteration 1025, loss = 0.03630253
Iteration 1026, loss = 0.03626376
Iteration 1027, loss = 0.03622463
Iteration 1028, loss = 0.03618957
Iteration 1029, loss = 0.03615161
Iteration 1030, loss = 0.03610983
Iteration 1031, loss = 0.03607188
Iteration 1032, loss = 0.03603331
Iteration 1033, loss = 0.03599673
Iteration 1034, loss = 0.03595770
Iteration 1035, loss = 0.03591911
Iteration 1036, loss = 0.03588025
Iteration 1037, loss = 0.03584296
Iteration 1038, loss = 0.03580350
Iteration 1039, loss = 0.03576957
Iteration 1040, loss = 0.03572776
Iteration 1041, loss = 0.03569220
Iteration 1042, loss = 0.03565050
Iteration 1043, loss = 0.03561483
Iteration 1044, loss = 0.03557772
Iteration 1045, loss = 0.03554027
Iteration 1046, loss = 0.03550515
Iteration 1047, loss = 0.03546839
Iteration 1048, loss = 0.03543312
Iteration 1049, loss = 0.03539491
Iteration 1050, loss = 0.03535824
Iteration 1051, loss = 0.03532072
Iteration 1052, loss = 0.03528373
Iteration 1053, loss = 0.03524988
Iteration 1054, loss = 0.03521235
Iteration 1055, loss = 0.03517530
Iteration 1056, loss = 0.03513892
Iteration 1057, loss = 0.03510339
Iteration 1058, loss = 0.03506664
Iteration 1059, loss = 0.03503164
Iteration 1060, loss = 0.03499357
Iteration 1061, loss = 0.03495739
Iteration 1062, loss = 0.03492007
Iteration 1063, loss = 0.03488385
Iteration 1064, loss = 0.03484834
Iteration 1065, loss = 0.03481378
Iteration 1066, loss = 0.03477839
Iteration 1067, loss = 0.03474095
Iteration 1068, loss = 0.03470824
Iteration 1069, loss = 0.03467406
Iteration 1070, loss = 0.03464096
Iteration 1071, loss = 0.03460649
Iteration 1072, loss = 0.03457107
Iteration 1073, loss = 0.03453532
Iteration 1074, loss = 0.03450242
Iteration 1075, loss = 0.03446591
Iteration 1076, loss = 0.03443163
Iteration 1077, loss = 0.03440097
Iteration 1078, loss = 0.03436105
Iteration 1079, loss = 0.03432622
Iteration 1080, loss = 0.03429204
Iteration 1081, loss = 0.03425766
Iteration 1082, loss = 0.03421823
Iteration 1083, loss = 0.03418216
Iteration 1084, loss = 0.03414549
Iteration 1085, loss = 0.03411075
Iteration 1086, loss = 0.03407528
Iteration 1087, loss = 0.03404180
Iteration 1088, loss = 0.03400754
Iteration 1089, loss = 0.03397321
Iteration 1090, loss = 0.03393830
Iteration 1091, loss = 0.03390725
Iteration 1092, loss = 0.03386986
Iteration 1093, loss = 0.03383669
Iteration 1094, loss = 0.03380189
Iteration 1095, loss = 0.03376550
Iteration 1096, loss = 0.03373512
Iteration 1097, loss = 0.03370062
Iteration 1098, loss = 0.03366304
Iteration 1099, loss = 0.03362513
Iteration 1100, loss = 0.03359362
Iteration 1101, loss = 0.03355635
Iteration 1102, loss = 0.03352508
Iteration 1103, loss = 0.03349204
Iteration 1104, loss = 0.03345800
Iteration 1105, loss = 0.03342763
Iteration 1106, loss = 0.03339614
Iteration 1107, loss = 0.03336304
Iteration 1108, loss = 0.03332877
Iteration 1109, loss = 0.03329981
Iteration 1110, loss = 0.03327051
Iteration 1111, loss = 0.03323651
Iteration 1112, loss = 0.03320145
Iteration 1113, loss = 0.03316980
Iteration 1114, loss = 0.03313356
Iteration 1115, loss = 0.03309971
Iteration 1116, loss = 0.03306794
Iteration 1117, loss = 0.03303103
Iteration 1118, loss = 0.03300159
Iteration 1119, loss = 0.03296650
Iteration 1120, loss = 0.03293649
Iteration 1121, loss = 0.03290297
Iteration 1122, loss = 0.03287328
Iteration 1123, loss = 0.03283923
Iteration 1124, loss = 0.03280800
Iteration 1125, loss = 0.03277918
Iteration 1126, loss = 0.03274416
Iteration 1127, loss = 0.03271303
Iteration 1128, loss = 0.03268062
Iteration 1129, loss = 0.03264834
Iteration 1130, loss = 0.03261739
Iteration 1131, loss = 0.03258629
Iteration 1132, loss = 0.03255662
Iteration 1133, loss = 0.03252530
Iteration 1134, loss = 0.03249353
Iteration 1135, loss = 0.03246285
Iteration 1136, loss = 0.03243038
Iteration 1137, loss = 0.03239960
Iteration 1138, loss = 0.03236962
Iteration 1139, loss = 0.03234141
Iteration 1140, loss = 0.03231005
Iteration 1141, loss = 0.03228068
Iteration 1142, loss = 0.03224780
Iteration 1143, loss = 0.03221516
Iteration 1144, loss = 0.03218374
Iteration 1145, loss = 0.03215110
Iteration 1146, loss = 0.03212572
Iteration 1147, loss = 0.03209458
Iteration 1148, loss = 0.03206280
Iteration 1149, loss = 0.03203058
Iteration 1150, loss = 0.03200001
Iteration 1151, loss = 0.03197113
Iteration 1152, loss = 0.03193997
Iteration 1153, loss = 0.03190990
Iteration 1154, loss = 0.03188166
Iteration 1155, loss = 0.03185261
Iteration 1156, loss = 0.03182365
Iteration 1157, loss = 0.03179559
Iteration 1158, loss = 0.03176612
Iteration 1159, loss = 0.03174057
Iteration 1160, loss = 0.03171053
Iteration 1161, loss = 0.03168136
Iteration 1162, loss = 0.03165356
Iteration 1163, loss = 0.03162459
Iteration 1164, loss = 0.03159632
Iteration 1165, loss = 0.03156883
Iteration 1166, loss = 0.03153894
Iteration 1167, loss = 0.03151154
Iteration 1168, loss = 0.03148047
Iteration 1169, loss = 0.03145353
Iteration 1170, loss = 0.03142171
Iteration 1171, loss = 0.03139340
Iteration 1172, loss = 0.03136256
Iteration 1173, loss = 0.03132827
Iteration 1174, loss = 0.03129980
Iteration 1175, loss = 0.03127027
Iteration 1176, loss = 0.03123780
Iteration 1177, loss = 0.03120790
Iteration 1178, loss = 0.03117811
Iteration 1179, loss = 0.03114798
Iteration 1180, loss = 0.03111837
Iteration 1181, loss = 0.03108959
Iteration 1182, loss = 0.03105899
Iteration 1183, loss = 0.03103059
Iteration 1184, loss = 0.03100125
Iteration 1185, loss = 0.03097218
Iteration 1186, loss = 0.03094478
Iteration 1187, loss = 0.03091493
Iteration 1188, loss = 0.03088596
Iteration 1189, loss = 0.03085720
Iteration 1190, loss = 0.03082839
Iteration 1191, loss = 0.03080496
Iteration 1192, loss = 0.03077858
Iteration 1193, loss = 0.03074934
Iteration 1194, loss = 0.03072173
Iteration 1195, loss = 0.03069363
Iteration 1196, loss = 0.03066815
Iteration 1197, loss = 0.03063929
Iteration 1198, loss = 0.03061042
Iteration 1199, loss = 0.03058320
Iteration 1200, loss = 0.03055537
Iteration 1201, loss = 0.03052755
Iteration 1202, loss = 0.03050033
Iteration 1203, loss = 0.03047340
Iteration 1204, loss = 0.03044568
Iteration 1205, loss = 0.03041542
Iteration 1206, loss = 0.03038672
Iteration 1207, loss = 0.03035589
Iteration 1208, loss = 0.03032795
Iteration 1209, loss = 0.03030258
Iteration 1210, loss = 0.03027542
Iteration 1211, loss = 0.03024356
Iteration 1212, loss = 0.03021665
Iteration 1213, loss = 0.03018657
Iteration 1214, loss = 0.03016051
Iteration 1215, loss = 0.03013262
Iteration 1216, loss = 0.03010390
Iteration 1217, loss = 0.03007247
Iteration 1218, loss = 0.03004432
Iteration 1219, loss = 0.03001571
Iteration 1220, loss = 0.02998822
Iteration 1221, loss = 0.02996167
Iteration 1222, loss = 0.02993386
Iteration 1223, loss = 0.02990528
Iteration 1224, loss = 0.02987839
Iteration 1225, loss = 0.02984589
Iteration 1226, loss = 0.02982567
Iteration 1227, loss = 0.02979708
Iteration 1228, loss = 0.02976555
Iteration 1229, loss = 0.02973660
Iteration 1230, loss = 0.02971011
Iteration 1231, loss = 0.02968285
Iteration 1232, loss = 0.02965299
Iteration 1233, loss = 0.02962599
Iteration 1234, loss = 0.02959949
Iteration 1235, loss = 0.02957096
Iteration 1236, loss = 0.02954524
Iteration 1237, loss = 0.02952209
Iteration 1238, loss = 0.02949249
Iteration 1239, loss = 0.02946501
Iteration 1240, loss = 0.02944148
Iteration 1241, loss = 0.02941989
Iteration 1242, loss = 0.02938556
Iteration 1243, loss = 0.02936233
Iteration 1244, loss = 0.02934319
Iteration 1245, loss = 0.02931195
Iteration 1246, loss = 0.02928944
Iteration 1247, loss = 0.02926139
Iteration 1248, loss = 0.02923438
Iteration 1249, loss = 0.02920839
Iteration 1250, loss = 0.02918625
Iteration 1251, loss = 0.02915757
Iteration 1252, loss = 0.02913149
Iteration 1253, loss = 0.02910467
Iteration 1254, loss = 0.02907921
Iteration 1255, loss = 0.02905710
Iteration 1256, loss = 0.02903263
Iteration 1257, loss = 0.02900119
Iteration 1258, loss = 0.02897497
Iteration 1259, loss = 0.02895300
Iteration 1260, loss = 0.02892356
Iteration 1261, loss = 0.02889915
Iteration 1262, loss = 0.02887275
Iteration 1263, loss = 0.02884817
Iteration 1264, loss = 0.02882323
Iteration 1265, loss = 0.02879789
Iteration 1266, loss = 0.02877302
Iteration 1267, loss = 0.02874945
Iteration 1268, loss = 0.02872188
Iteration 1269, loss = 0.02869931
Iteration 1270, loss = 0.02867201
Iteration 1271, loss = 0.02864556
Iteration 1272, loss = 0.02862030
Iteration 1273, loss = 0.02859787
Iteration 1274, loss = 0.02857187
Iteration 1275, loss = 0.02854694
Iteration 1276, loss = 0.02852148
Iteration 1277, loss = 0.02849730
Iteration 1278, loss = 0.02847724
Iteration 1279, loss = 0.02845126
Iteration 1280, loss = 0.02842747
Iteration 1281, loss = 0.02840368
Iteration 1282, loss = 0.02837928
Iteration 1283, loss = 0.02835442
Iteration 1284, loss = 0.02832980
Iteration 1285, loss = 0.02830665
Iteration 1286, loss = 0.02828284
Iteration 1287, loss = 0.02825888
Iteration 1288, loss = 0.02823421
Iteration 1289, loss = 0.02821273
Iteration 1290, loss = 0.02818613
Iteration 1291, loss = 0.02816443
Iteration 1292, loss = 0.02813995
Iteration 1293, loss = 0.02811312
Iteration 1294, loss = 0.02809105
Iteration 1295, loss = 0.02806332
Iteration 1296, loss = 0.02804132
Iteration 1297, loss = 0.02801125
Iteration 1298, loss = 0.02798560
Iteration 1299, loss = 0.02796251
Iteration 1300, loss = 0.02793544
Iteration 1301, loss = 0.02790946
Iteration 1302, loss = 0.02788472
Iteration 1303, loss = 0.02786278
Iteration 1304, loss = 0.02783722
Iteration 1305, loss = 0.02781112
Iteration 1306, loss = 0.02778577
Iteration 1307, loss = 0.02776193
Iteration 1308, loss = 0.02773646
Iteration 1309, loss = 0.02771333
Iteration 1310, loss = 0.02768845
Iteration 1311, loss = 0.02766310
Iteration 1312, loss = 0.02764022
Iteration 1313, loss = 0.02761438
Iteration 1314, loss = 0.02759035
Iteration 1315, loss = 0.02756675
Iteration 1316, loss = 0.02754252
Iteration 1317, loss = 0.02751847
Iteration 1318, loss = 0.02749627
Iteration 1319, loss = 0.02747466
Iteration 1320, loss = 0.02744691
Iteration 1321, loss = 0.02742224
Iteration 1322, loss = 0.02739809
Iteration 1323, loss = 0.02737662
Iteration 1324, loss = 0.02735204
Iteration 1325, loss = 0.02732962
Iteration 1326, loss = 0.02730720
Iteration 1327, loss = 0.02729077
Iteration 1328, loss = 0.02725907
Iteration 1329, loss = 0.02723693
Iteration 1330, loss = 0.02721074
Iteration 1331, loss = 0.02719343
Iteration 1332, loss = 0.02716691
Iteration 1333, loss = 0.02714087
Iteration 1334, loss = 0.02711712
Iteration 1335, loss = 0.02709578
Iteration 1336, loss = 0.02707078
Iteration 1337, loss = 0.02705224
Iteration 1338, loss = 0.02702593
Iteration 1339, loss = 0.02700361
Iteration 1340, loss = 0.02698311
Iteration 1341, loss = 0.02695845
Iteration 1342, loss = 0.02693554
Iteration 1343, loss = 0.02691273
Iteration 1344, loss = 0.02689437
Iteration 1345, loss = 0.02687062
Iteration 1346, loss = 0.02684715
Iteration 1347, loss = 0.02682563
Iteration 1348, loss = 0.02680416
Iteration 1349, loss = 0.02678347
Iteration 1350, loss = 0.02675867
Iteration 1351, loss = 0.02673705
Iteration 1352, loss = 0.02671237
Iteration 1353, loss = 0.02669035
Iteration 1354, loss = 0.02666710
Iteration 1355, loss = 0.02664393
Iteration 1356, loss = 0.02662400
Iteration 1357, loss = 0.02659989
Iteration 1358, loss = 0.02657896
Iteration 1359, loss = 0.02656136
Iteration 1360, loss = 0.02653365
Iteration 1361, loss = 0.02651420
Iteration 1362, loss = 0.02649394
Iteration 1363, loss = 0.02646939
Iteration 1364, loss = 0.02644719
Iteration 1365, loss = 0.02642458
Iteration 1366, loss = 0.02640275
Iteration 1367, loss = 0.02638053
Iteration 1368, loss = 0.02635879
Iteration 1369, loss = 0.02633688
Iteration 1370, loss = 0.02631681
Iteration 1371, loss = 0.02629407
Iteration 1372, loss = 0.02627179
Iteration 1373, loss = 0.02625047
Iteration 1374, loss = 0.02622844
Iteration 1375, loss = 0.02620757
Iteration 1376, loss = 0.02618710
Iteration 1377, loss = 0.02616588
Iteration 1378, loss = 0.02614600
Iteration 1379, loss = 0.02612488
Iteration 1380, loss = 0.02610425
Iteration 1381, loss = 0.02608338
Iteration 1382, loss = 0.02606237
Iteration 1383, loss = 0.02604179
Iteration 1384, loss = 0.02602133
Iteration 1385, loss = 0.02599843
Iteration 1386, loss = 0.02597503
Iteration 1387, loss = 0.02595509
Iteration 1388, loss = 0.02593345
Iteration 1389, loss = 0.02591118
Iteration 1390, loss = 0.02589061
Iteration 1391, loss = 0.02586867
Iteration 1392, loss = 0.02584651
Iteration 1393, loss = 0.02582527
Iteration 1394, loss = 0.02580767
Iteration 1395, loss = 0.02578680
Iteration 1396, loss = 0.02576816
Iteration 1397, loss = 0.02574567
Iteration 1398, loss = 0.02572492
Iteration 1399, loss = 0.02570431
Iteration 1400, loss = 0.02568443
Iteration 1401, loss = 0.02566336
Iteration 1402, loss = 0.02564103
Iteration 1403, loss = 0.02562017
Iteration 1404, loss = 0.02559955
Iteration 1405, loss = 0.02558040
Iteration 1406, loss = 0.02555917
Iteration 1407, loss = 0.02553838
Iteration 1408, loss = 0.02551920
Iteration 1409, loss = 0.02550027
Iteration 1410, loss = 0.02547770
Iteration 1411, loss = 0.02545813
Iteration 1412, loss = 0.02543910
Iteration 1413, loss = 0.02542207
Iteration 1414, loss = 0.02539935
Iteration 1415, loss = 0.02537968
Iteration 1416, loss = 0.02536059
Iteration 1417, loss = 0.02534154
Iteration 1418, loss = 0.02532181
Iteration 1419, loss = 0.02530550
Iteration 1420, loss = 0.02528668
Iteration 1421, loss = 0.02526393
Iteration 1422, loss = 0.02524344
Iteration 1423, loss = 0.02522399
Iteration 1424, loss = 0.02520290
Iteration 1425, loss = 0.02518324
Iteration 1426, loss = 0.02516412
Iteration 1427, loss = 0.02514494
Iteration 1428, loss = 0.02512967
Iteration 1429, loss = 0.02510570
Iteration 1430, loss = 0.02508379
Iteration 1431, loss = 0.02506273
Iteration 1432, loss = 0.02504379
Iteration 1433, loss = 0.02502137
Iteration 1434, loss = 0.02500010
Iteration 1435, loss = 0.02498606
Iteration 1436, loss = 0.02496185
Iteration 1437, loss = 0.02494128
Iteration 1438, loss = 0.02492393
Iteration 1439, loss = 0.02490271
Iteration 1440, loss = 0.02488684
Iteration 1441, loss = 0.02486422
Iteration 1442, loss = 0.02484321
Iteration 1443, loss = 0.02482344
Iteration 1444, loss = 0.02480517
Iteration 1445, loss = 0.02478599
Iteration 1446, loss = 0.02476732
Iteration 1447, loss = 0.02474446
Iteration 1448, loss = 0.02472477
Iteration 1449, loss = 0.02470455
Iteration 1450, loss = 0.02468777
Iteration 1451, loss = 0.02466838
Iteration 1452, loss = 0.02465023
Iteration 1453, loss = 0.02462955
Iteration 1454, loss = 0.02461313
Iteration 1455, loss = 0.02459120
Iteration 1456, loss = 0.02457268
Iteration 1457, loss = 0.02455413
Iteration 1458, loss = 0.02453474
Iteration 1459, loss = 0.02451671
Iteration 1460, loss = 0.02449652
Iteration 1461, loss = 0.02447680
Iteration 1462, loss = 0.02446112
Iteration 1463, loss = 0.02444134
Iteration 1464, loss = 0.02442061
Iteration 1465, loss = 0.02440032
Iteration 1466, loss = 0.02438088
Iteration 1467, loss = 0.02436105
Iteration 1468, loss = 0.02434294
Iteration 1469, loss = 0.02432386
Iteration 1470, loss = 0.02430423
Iteration 1471, loss = 0.02428502
Iteration 1472, loss = 0.02426238
Iteration 1473, loss = 0.02424531
Iteration 1474, loss = 0.02422836
Iteration 1475, loss = 0.02421608
Iteration 1476, loss = 0.02419358
Iteration 1477, loss = 0.02417549
Iteration 1478, loss = 0.02415888
Iteration 1479, loss = 0.02414012
Iteration 1480, loss = 0.02412696
Iteration 1481, loss = 0.02410591
Iteration 1482, loss = 0.02408788
Iteration 1483, loss = 0.02406834
Iteration 1484, loss = 0.02404913
Iteration 1485, loss = 0.02403035
Iteration 1486, loss = 0.02401141
Iteration 1487, loss = 0.02399294
Iteration 1488, loss = 0.02397346
Iteration 1489, loss = 0.02395569
Iteration 1490, loss = 0.02393698
Iteration 1491, loss = 0.02392014
Iteration 1492, loss = 0.02390065
Iteration 1493, loss = 0.02388324
Iteration 1494, loss = 0.02386505
Iteration 1495, loss = 0.02384823
Iteration 1496, loss = 0.02383056
Iteration 1497, loss = 0.02381349
Iteration 1498, loss = 0.02379499
Iteration 1499, loss = 0.02377589
Iteration 1500, loss = 0.02375623
Iteration 1501, loss = 0.02373954
Iteration 1502, loss = 0.02372046
Iteration 1503, loss = 0.02370244
Iteration 1504, loss = 0.02368317
Iteration 1505, loss = 0.02366442
Iteration 1506, loss = 0.02364609
Iteration 1507, loss = 0.02362551
Iteration 1508, loss = 0.02360408
Iteration 1509, loss = 0.02358651
Iteration 1510, loss = 0.02357148
Iteration 1511, loss = 0.02354810
Iteration 1512, loss = 0.02353240
Iteration 1513, loss = 0.02351253
Iteration 1514, loss = 0.02349515
Iteration 1515, loss = 0.02347916
Iteration 1516, loss = 0.02346036
Iteration 1517, loss = 0.02344387
Iteration 1518, loss = 0.02342525
Iteration 1519, loss = 0.02341169
Iteration 1520, loss = 0.02339144
Iteration 1521, loss = 0.02337491
Iteration 1522, loss = 0.02335669
Iteration 1523, loss = 0.02334024
Iteration 1524, loss = 0.02332359
Iteration 1525, loss = 0.02330542
Iteration 1526, loss = 0.02328640
Iteration 1527, loss = 0.02326835
Iteration 1528, loss = 0.02324999
Iteration 1529, loss = 0.02323202
Iteration 1530, loss = 0.02321565
Iteration 1531, loss = 0.02319723
Iteration 1532, loss = 0.02318137
Iteration 1533, loss = 0.02316440
Iteration 1534, loss = 0.02314655
Iteration 1535, loss = 0.02312928
Iteration 1536, loss = 0.02311217
Iteration 1537, loss = 0.02309548
Iteration 1538, loss = 0.02308009
Iteration 1539, loss = 0.02306368
Iteration 1540, loss = 0.02304712
Iteration 1541, loss = 0.02303068
Iteration 1542, loss = 0.02301398
Iteration 1543, loss = 0.02299778
Iteration 1544, loss = 0.02298110
Iteration 1545, loss = 0.02296480
Iteration 1546, loss = 0.02294833
Iteration 1547, loss = 0.02293405
Iteration 1548, loss = 0.02291610
Iteration 1549, loss = 0.02289893
Iteration 1550, loss = 0.02288270
Iteration 1551, loss = 0.02286645
Iteration 1552, loss = 0.02285009
Iteration 1553, loss = 0.02283504
Iteration 1554, loss = 0.02281743
Iteration 1555, loss = 0.02280246
Iteration 1556, loss = 0.02278531
Iteration 1557, loss = 0.02276911
Iteration 1558, loss = 0.02275196
Iteration 1559, loss = 0.02273585
Iteration 1560, loss = 0.02272032
Iteration 1561, loss = 0.02270077
Iteration 1562, loss = 0.02268369
Iteration 1563, loss = 0.02266577
Iteration 1564, loss = 0.02264839
Iteration 1565, loss = 0.02263177
Iteration 1566, loss = 0.02261622
Iteration 1567, loss = 0.02259922
Iteration 1568, loss = 0.02258365
Iteration 1569, loss = 0.02256712
Iteration 1570, loss = 0.02255173
Iteration 1571, loss = 0.02253517
Iteration 1572, loss = 0.02251823
Iteration 1573, loss = 0.02250243
Iteration 1574, loss = 0.02248318
Iteration 1575, loss = 0.02246956
Iteration 1576, loss = 0.02245056
Iteration 1577, loss = 0.02243689
Iteration 1578, loss = 0.02241925
Iteration 1579, loss = 0.02240382
Iteration 1580, loss = 0.02238767
Iteration 1581, loss = 0.02237231
Iteration 1582, loss = 0.02235644
Iteration 1583, loss = 0.02233944
Iteration 1584, loss = 0.02232459
Iteration 1585, loss = 0.02230903
Iteration 1586, loss = 0.02229393
Iteration 1587, loss = 0.02227924
Iteration 1588, loss = 0.02226159
Iteration 1589, loss = 0.02224592
Iteration 1590, loss = 0.02223114
Iteration 1591, loss = 0.02221682
Iteration 1592, loss = 0.02219767
Iteration 1593, loss = 0.02218411
Iteration 1594, loss = 0.02216717
Iteration 1595, loss = 0.02215341
Iteration 1596, loss = 0.02213721
Iteration 1597, loss = 0.02212066
Iteration 1598, loss = 0.02210384
Iteration 1599, loss = 0.02208585
Iteration 1600, loss = 0.02207288
Iteration 1601, loss = 0.02205379
Iteration 1602, loss = 0.02203760
Iteration 1603, loss = 0.02202124
Iteration 1604, loss = 0.02200425
Iteration 1605, loss = 0.02198735
Iteration 1606, loss = 0.02197344
Iteration 1607, loss = 0.02195467
Iteration 1608, loss = 0.02193734
Iteration 1609, loss = 0.02192122
Iteration 1610, loss = 0.02190579
Iteration 1611, loss = 0.02189187
Iteration 1612, loss = 0.02187462
Iteration 1613, loss = 0.02186007
Iteration 1614, loss = 0.02184508
Iteration 1615, loss = 0.02182944
Iteration 1616, loss = 0.02181327
Iteration 1617, loss = 0.02180201
Iteration 1618, loss = 0.02178278
Iteration 1619, loss = 0.02176617
Iteration 1620, loss = 0.02175225
Iteration 1621, loss = 0.02173573
Iteration 1622, loss = 0.02171923
Iteration 1623, loss = 0.02170551
Iteration 1624, loss = 0.02168783
Iteration 1625, loss = 0.02167294
Iteration 1626, loss = 0.02165629
Iteration 1627, loss = 0.02164016
Iteration 1628, loss = 0.02162483
Iteration 1629, loss = 0.02160777
Iteration 1630, loss = 0.02159273
Iteration 1631, loss = 0.02157446
Iteration 1632, loss = 0.02155839
Iteration 1633, loss = 0.02154300
Iteration 1634, loss = 0.02152546
Iteration 1635, loss = 0.02151071
Iteration 1636, loss = 0.02149227
Iteration 1637, loss = 0.02147690
Iteration 1638, loss = 0.02146177
Iteration 1639, loss = 0.02144506
Iteration 1640, loss = 0.02142896
Iteration 1641, loss = 0.02141293
Iteration 1642, loss = 0.02139784
Iteration 1643, loss = 0.02138197
Iteration 1644, loss = 0.02136665
Iteration 1645, loss = 0.02135303
Iteration 1646, loss = 0.02133792
Iteration 1647, loss = 0.02132189
Iteration 1648, loss = 0.02131073
Iteration 1649, loss = 0.02129249
Iteration 1650, loss = 0.02127841
Iteration 1651, loss = 0.02126471
Iteration 1652, loss = 0.02124903
Iteration 1653, loss = 0.02123569
Iteration 1654, loss = 0.02122119
Iteration 1655, loss = 0.02120672
Iteration 1656, loss = 0.02119117
Iteration 1657, loss = 0.02117618
Iteration 1658, loss = 0.02116046
Iteration 1659, loss = 0.02114392
Iteration 1660, loss = 0.02113126
Iteration 1661, loss = 0.02111538
Iteration 1662, loss = 0.02109832
Iteration 1663, loss = 0.02108416
Iteration 1664, loss = 0.02107024
Iteration 1665, loss = 0.02105486
Iteration 1666, loss = 0.02103979
Iteration 1667, loss = 0.02102583
Iteration 1668, loss = 0.02101298
Iteration 1669, loss = 0.02099723
Iteration 1670, loss = 0.02098321
Iteration 1671, loss = 0.02096861
Iteration 1672, loss = 0.02095414
Iteration 1673, loss = 0.02094022
Iteration 1674, loss = 0.02092674
Iteration 1675, loss = 0.02091579
Iteration 1676, loss = 0.02089936
Iteration 1677, loss = 0.02088720
Iteration 1678, loss = 0.02087038
Iteration 1679, loss = 0.02085559
Iteration 1680, loss = 0.02084285
Iteration 1681, loss = 0.02082503
Iteration 1682, loss = 0.02081117
Iteration 1683, loss = 0.02079576
Iteration 1684, loss = 0.02078332
Iteration 1685, loss = 0.02076983
Iteration 1686, loss = 0.02075518
Iteration 1687, loss = 0.02073884
Iteration 1688, loss = 0.02072408
Iteration 1689, loss = 0.02071033
Iteration 1690, loss = 0.02069768
Iteration 1691, loss = 0.02068212
Iteration 1692, loss = 0.02066835
Iteration 1693, loss = 0.02065450
Iteration 1694, loss = 0.02064031
Iteration 1695, loss = 0.02062658
Iteration 1696, loss = 0.02061273
Iteration 1697, loss = 0.02059736
Iteration 1698, loss = 0.02058436
Iteration 1699, loss = 0.02057161
Iteration 1700, loss = 0.02055747
Iteration 1701, loss = 0.02054386
Iteration 1702, loss = 0.02053034
Iteration 1703, loss = 0.02051598
Iteration 1704, loss = 0.02050557
Iteration 1705, loss = 0.02048920
Iteration 1706, loss = 0.02047533
Iteration 1707, loss = 0.02046251
Iteration 1708, loss = 0.02044826
Iteration 1709, loss = 0.02043430
Iteration 1710, loss = 0.02042124
Iteration 1711, loss = 0.02040672
Iteration 1712, loss = 0.02039955
Iteration 1713, loss = 0.02038214
Iteration 1714, loss = 0.02036747
Iteration 1715, loss = 0.02035458
Iteration 1716, loss = 0.02034061
Iteration 1717, loss = 0.02032431
Iteration 1718, loss = 0.02031179
Iteration 1719, loss = 0.02029404
Iteration 1720, loss = 0.02028010
Iteration 1721, loss = 0.02026530
Iteration 1722, loss = 0.02024998
Iteration 1723, loss = 0.02023566
Iteration 1724, loss = 0.02022153
Iteration 1725, loss = 0.02020791
Iteration 1726, loss = 0.02019503
Iteration 1727, loss = 0.02018094
Iteration 1728, loss = 0.02016886
Iteration 1729, loss = 0.02015320
Iteration 1730, loss = 0.02013793
Iteration 1731, loss = 0.02012394
Iteration 1732, loss = 0.02010929
Iteration 1733, loss = 0.02009833
Iteration 1734, loss = 0.02008084
Iteration 1735, loss = 0.02006639
Iteration 1736, loss = 0.02005245
Iteration 1737, loss = 0.02003637
Iteration 1738, loss = 0.02002189
Iteration 1739, loss = 0.02000897
Iteration 1740, loss = 0.01999363
Iteration 1741, loss = 0.01997829
Iteration 1742, loss = 0.01996439
Iteration 1743, loss = 0.01995013
Iteration 1744, loss = 0.01993722
Iteration 1745, loss = 0.01992253
Iteration 1746, loss = 0.01990790
Iteration 1747, loss = 0.01989574
Iteration 1748, loss = 0.01988280
Iteration 1749, loss = 0.01986970
Iteration 1750, loss = 0.01986008
Iteration 1751, loss = 0.01984474
Iteration 1752, loss = 0.01983113
Iteration 1753, loss = 0.01981756
Iteration 1754, loss = 0.01980498
Iteration 1755, loss = 0.01979209
Iteration 1756, loss = 0.01978145
Iteration 1757, loss = 0.01976781
Iteration 1758, loss = 0.01975578
Iteration 1759, loss = 0.01974411
Iteration 1760, loss = 0.01973016
Iteration 1761, loss = 0.01971840
Iteration 1762, loss = 0.01970628
Iteration 1763, loss = 0.01969422
Iteration 1764, loss = 0.01968230
Iteration 1765, loss = 0.01967170
Iteration 1766, loss = 0.01965873
Iteration 1767, loss = 0.01964692
Iteration 1768, loss = 0.01963537
Iteration 1769, loss = 0.01962109
Iteration 1770, loss = 0.01960924
Iteration 1771, loss = 0.01959608
Iteration 1772, loss = 0.01958516
Iteration 1773, loss = 0.01957229
Iteration 1774, loss = 0.01955985
Iteration 1775, loss = 0.01954676
Iteration 1776, loss = 0.01953357
Iteration 1777, loss = 0.01952057
Iteration 1778, loss = 0.01950897
Iteration 1779, loss = 0.01949757
Iteration 1780, loss = 0.01948259
Iteration 1781, loss = 0.01946829
Iteration 1782, loss = 0.01945429
Iteration 1783, loss = 0.01944031
Iteration 1784, loss = 0.01942936
Iteration 1785, loss = 0.01941325
Iteration 1786, loss = 0.01940257
Iteration 1787, loss = 0.01938725
Iteration 1788, loss = 0.01937370
Iteration 1789, loss = 0.01936365
Iteration 1790, loss = 0.01935212
Iteration 1791, loss = 0.01933756
Iteration 1792, loss = 0.01932614
Iteration 1793, loss = 0.01931473
Iteration 1794, loss = 0.01930341
Iteration 1795, loss = 0.01929282
Iteration 1796, loss = 0.01928216
Iteration 1797, loss = 0.01926899
Iteration 1798, loss = 0.01925611
Iteration 1799, loss = 0.01924309
Iteration 1800, loss = 0.01923116
Iteration 1801, loss = 0.01921860
Iteration 1802, loss = 0.01920715
Iteration 1803, loss = 0.01919586
Iteration 1804, loss = 0.01918333
Iteration 1805, loss = 0.01917299
Iteration 1806, loss = 0.01916030
Iteration 1807, loss = 0.01914721
Iteration 1808, loss = 0.01913487
Iteration 1809, loss = 0.01912543
Iteration 1810, loss = 0.01911088
Iteration 1811, loss = 0.01909876
Iteration 1812, loss = 0.01908720
Iteration 1813, loss = 0.01907491
Iteration 1814, loss = 0.01906316
Iteration 1815, loss = 0.01905216
Iteration 1816, loss = 0.01903888
Iteration 1817, loss = 0.01902827
Iteration 1818, loss = 0.01901383
Iteration 1819, loss = 0.01900222
Iteration 1820, loss = 0.01898854
Iteration 1821, loss = 0.01897727
Iteration 1822, loss = 0.01896534
Iteration 1823, loss = 0.01895242
Iteration 1824, loss = 0.01894044
Iteration 1825, loss = 0.01892832
Iteration 1826, loss = 0.01891777
Iteration 1827, loss = 0.01890636
Iteration 1828, loss = 0.01889355
Iteration 1829, loss = 0.01888254
Iteration 1830, loss = 0.01887120
Iteration 1831, loss = 0.01886099
Iteration 1832, loss = 0.01885147
Iteration 1833, loss = 0.01884158
Iteration 1834, loss = 0.01882983
Iteration 1835, loss = 0.01881880
Iteration 1836, loss = 0.01880691
Iteration 1837, loss = 0.01879790
Iteration 1838, loss = 0.01878573
Iteration 1839, loss = 0.01877605
Iteration 1840, loss = 0.01876860
Iteration 1841, loss = 0.01875129
Iteration 1842, loss = 0.01874080
Iteration 1843, loss = 0.01872786
Iteration 1844, loss = 0.01871493
Iteration 1845, loss = 0.01870334
Iteration 1846, loss = 0.01869341
Iteration 1847, loss = 0.01868195
Iteration 1848, loss = 0.01867030
Iteration 1849, loss = 0.01865990
Iteration 1850, loss = 0.01864866
Iteration 1851, loss = 0.01863824
Iteration 1852, loss = 0.01862661
Iteration 1853, loss = 0.01861746
Iteration 1854, loss = 0.01860587
Iteration 1855, loss = 0.01859319
Iteration 1856, loss = 0.01858112
Iteration 1857, loss = 0.01856924
Iteration 1858, loss = 0.01855810
Iteration 1859, loss = 0.01854577
Iteration 1860, loss = 0.01853624
Iteration 1861, loss = 0.01852661
Iteration 1862, loss = 0.01851709
Iteration 1863, loss = 0.01850449
Iteration 1864, loss = 0.01849307
Iteration 1865, loss = 0.01848177
Iteration 1866, loss = 0.01846842
Iteration 1867, loss = 0.01845513
Iteration 1868, loss = 0.01844079
Iteration 1869, loss = 0.01842859
Iteration 1870, loss = 0.01841270
Iteration 1871, loss = 0.01840423
Iteration 1872, loss = 0.01838937
Iteration 1873, loss = 0.01837471
Iteration 1874, loss = 0.01836285
Iteration 1875, loss = 0.01835175
Iteration 1876, loss = 0.01833933
Iteration 1877, loss = 0.01832736
Iteration 1878, loss = 0.01831525
Iteration 1879, loss = 0.01830407
Iteration 1880, loss = 0.01829181
Iteration 1881, loss = 0.01828110
Iteration 1882, loss = 0.01827260
Iteration 1883, loss = 0.01825996
Iteration 1884, loss = 0.01824733
Iteration 1885, loss = 0.01823659
Iteration 1886, loss = 0.01822350
Iteration 1887, loss = 0.01821112
Iteration 1888, loss = 0.01819993
Iteration 1889, loss = 0.01818745
Iteration 1890, loss = 0.01817399
Iteration 1891, loss = 0.01816780
Iteration 1892, loss = 0.01815306
Iteration 1893, loss = 0.01814133
Iteration 1894, loss = 0.01813325
Iteration 1895, loss = 0.01811997
Iteration 1896, loss = 0.01810899
Iteration 1897, loss = 0.01809809
Iteration 1898, loss = 0.01808706
Iteration 1899, loss = 0.01807653
Iteration 1900, loss = 0.01806557
Iteration 1901, loss = 0.01805442
Iteration 1902, loss = 0.01804472
Iteration 1903, loss = 0.01803318
Iteration 1904, loss = 0.01802202
Iteration 1905, loss = 0.01801068
Iteration 1906, loss = 0.01799945
Iteration 1907, loss = 0.01798820
Iteration 1908, loss = 0.01797868
Iteration 1909, loss = 0.01796607
Iteration 1910, loss = 0.01795419
Iteration 1911, loss = 0.01794235
Iteration 1912, loss = 0.01793199
Iteration 1913, loss = 0.01791870
Iteration 1914, loss = 0.01790871
Iteration 1915, loss = 0.01789737
Iteration 1916, loss = 0.01788908
Iteration 1917, loss = 0.01787742
Iteration 1918, loss = 0.01786489
Iteration 1919, loss = 0.01785418
Iteration 1920, loss = 0.01784455
Iteration 1921, loss = 0.01783151
Iteration 1922, loss = 0.01782017
Iteration 1923, loss = 0.01781077
Iteration 1924, loss = 0.01779754
Iteration 1925, loss = 0.01778749
Iteration 1926, loss = 0.01777592
Iteration 1927, loss = 0.01776498
Iteration 1928, loss = 0.01775455
Iteration 1929, loss = 0.01774284
Iteration 1930, loss = 0.01773358
Iteration 1931, loss = 0.01772087
Iteration 1932, loss = 0.01771016
Iteration 1933, loss = 0.01769832
Iteration 1934, loss = 0.01768841
Iteration 1935, loss = 0.01767714
Iteration 1936, loss = 0.01766717
Iteration 1937, loss = 0.01766240
Iteration 1938, loss = 0.01764849
Iteration 1939, loss = 0.01763656
Iteration 1940, loss = 0.01762591
Iteration 1941, loss = 0.01761532
Iteration 1942, loss = 0.01760401
Iteration 1943, loss = 0.01759442
Iteration 1944, loss = 0.01758448
Iteration 1945, loss = 0.01757198
Iteration 1946, loss = 0.01756164
Iteration 1947, loss = 0.01754924
Iteration 1948, loss = 0.01753979
Iteration 1949, loss = 0.01752644
Iteration 1950, loss = 0.01751495
Iteration 1951, loss = 0.01750534
Iteration 1952, loss = 0.01749573
Iteration 1953, loss = 0.01748464
Iteration 1954, loss = 0.01747325
Iteration 1955, loss = 0.01746322
Iteration 1956, loss = 0.01745288
Iteration 1957, loss = 0.01744352
Iteration 1958, loss = 0.01743310
Iteration 1959, loss = 0.01742227
Iteration 1960, loss = 0.01741128
Iteration 1961, loss = 0.01740102
Iteration 1962, loss = 0.01739038
Iteration 1963, loss = 0.01737952
Iteration 1964, loss = 0.01736887
Iteration 1965, loss = 0.01736092
Iteration 1966, loss = 0.01734981
Iteration 1967, loss = 0.01733842
Iteration 1968, loss = 0.01732839
Iteration 1969, loss = 0.01731911
Iteration 1970, loss = 0.01730731
Iteration 1971, loss = 0.01729835
Iteration 1972, loss = 0.01728774
Iteration 1973, loss = 0.01727742
Iteration 1974, loss = 0.01727350
Iteration 1975, loss = 0.01725401
Iteration 1976, loss = 0.01724693
Iteration 1977, loss = 0.01723309
Iteration 1978, loss = 0.01722217
Iteration 1979, loss = 0.01721385
Iteration 1980, loss = 0.01720130
Iteration 1981, loss = 0.01719052
Iteration 1982, loss = 0.01717982
Iteration 1983, loss = 0.01716804
Iteration 1984, loss = 0.01715698
Iteration 1985, loss = 0.01714640
Iteration 1986, loss = 0.01713858
Iteration 1987, loss = 0.01712661
Iteration 1988, loss = 0.01711633
Iteration 1989, loss = 0.01710661
Iteration 1990, loss = 0.01709664
Iteration 1991, loss = 0.01708583
Iteration 1992, loss = 0.01707628
Iteration 1993, loss = 0.01706545
Iteration 1994, loss = 0.01705546
Iteration 1995, loss = 0.01704539
Iteration 1996, loss = 0.01703472
Iteration 1997, loss = 0.01702422
Iteration 1998, loss = 0.01701396
Iteration 1999, loss = 0.01700355
Iteration 2000, loss = 0.01699285
Iteration 2001, loss = 0.01698204
Iteration 2002, loss = 0.01697286
Iteration 2003, loss = 0.01696087
Iteration 2004, loss = 0.01695087
Iteration 2005, loss = 0.01694211
Iteration 2006, loss = 0.01693071
Iteration 2007, loss = 0.01692046
Iteration 2008, loss = 0.01691060
Iteration 2009, loss = 0.01690080
Iteration 2010, loss = 0.01689078
Iteration 2011, loss = 0.01688186
Iteration 2012, loss = 0.01687107
Iteration 2013, loss = 0.01686053
Iteration 2014, loss = 0.01685083
Iteration 2015, loss = 0.01684094
Iteration 2016, loss = 0.01683013
Iteration 2017, loss = 0.01682209
Iteration 2018, loss = 0.01681092
Iteration 2019, loss = 0.01679969
Iteration 2020, loss = 0.01679076
Iteration 2021, loss = 0.01678076
Iteration 2022, loss = 0.01676956
Iteration 2023, loss = 0.01676046
Iteration 2024, loss = 0.01675050
Iteration 2025, loss = 0.01674154
Iteration 2026, loss = 0.01673320
Iteration 2027, loss = 0.01672318
Iteration 2028, loss = 0.01671248
Iteration 2029, loss = 0.01670483
Iteration 2030, loss = 0.01669444
Iteration 2031, loss = 0.01668471
Iteration 2032, loss = 0.01667499
Iteration 2033, loss = 0.01666520
Iteration 2034, loss = 0.01665552
Iteration 2035, loss = 0.01664598
Iteration 2036, loss = 0.01663695
Iteration 2037, loss = 0.01662829
Iteration 2038, loss = 0.01661821
Iteration 2039, loss = 0.01660849
Iteration 2040, loss = 0.01659956
Iteration 2041, loss = 0.01658936
Iteration 2042, loss = 0.01658099
Iteration 2043, loss = 0.01657226
Iteration 2044, loss = 0.01656237
Iteration 2045, loss = 0.01655344
Iteration 2046, loss = 0.01654420
Iteration 2047, loss = 0.01653519
Iteration 2048, loss = 0.01652686
Iteration 2049, loss = 0.01651504
Iteration 2050, loss = 0.01650503
Iteration 2051, loss = 0.01649506
Iteration 2052, loss = 0.01648759
Iteration 2053, loss = 0.01647640
Iteration 2054, loss = 0.01646739
Iteration 2055, loss = 0.01645790
Iteration 2056, loss = 0.01644784
Iteration 2057, loss = 0.01643869
Iteration 2058, loss = 0.01643082
Iteration 2059, loss = 0.01641938
Iteration 2060, loss = 0.01640945
Iteration 2061, loss = 0.01640003
Iteration 2062, loss = 0.01639058
Iteration 2063, loss = 0.01637970
Iteration 2064, loss = 0.01636912
Iteration 2065, loss = 0.01635953
Iteration 2066, loss = 0.01634928
Iteration 2067, loss = 0.01633953
Iteration 2068, loss = 0.01633238
Iteration 2069, loss = 0.01631987
Iteration 2070, loss = 0.01631233
Iteration 2071, loss = 0.01630049
Iteration 2072, loss = 0.01629077
Iteration 2073, loss = 0.01628110
Iteration 2074, loss = 0.01627111
Iteration 2075, loss = 0.01626088
Iteration 2076, loss = 0.01625115
Iteration 2077, loss = 0.01624093
Iteration 2078, loss = 0.01623129
Iteration 2079, loss = 0.01622362
Iteration 2080, loss = 0.01621343
Iteration 2081, loss = 0.01620476
Iteration 2082, loss = 0.01619449
Iteration 2083, loss = 0.01618580
Iteration 2084, loss = 0.01617777
Iteration 2085, loss = 0.01616727
Iteration 2086, loss = 0.01615842
Iteration 2087, loss = 0.01614692
Iteration 2088, loss = 0.01613765
Iteration 2089, loss = 0.01612778
Iteration 2090, loss = 0.01611873
Iteration 2091, loss = 0.01610758
Iteration 2092, loss = 0.01609904
Iteration 2093, loss = 0.01608953
Iteration 2094, loss = 0.01607987
Iteration 2095, loss = 0.01607121
Iteration 2096, loss = 0.01606292
Iteration 2097, loss = 0.01605265
Iteration 2098, loss = 0.01604294
Iteration 2099, loss = 0.01603292
Iteration 2100, loss = 0.01602317
Iteration 2101, loss = 0.01601623
Iteration 2102, loss = 0.01600468
Iteration 2103, loss = 0.01599493
Iteration 2104, loss = 0.01598677
Iteration 2105, loss = 0.01597833
Iteration 2106, loss = 0.01596797
Iteration 2107, loss = 0.01595781
Iteration 2108, loss = 0.01594801
Iteration 2109, loss = 0.01593844
Iteration 2110, loss = 0.01592910
Iteration 2111, loss = 0.01591831
Iteration 2112, loss = 0.01590865
Iteration 2113, loss = 0.01589834
Iteration 2114, loss = 0.01588893
Iteration 2115, loss = 0.01587837
Iteration 2116, loss = 0.01587003
Iteration 2117, loss = 0.01586034
Iteration 2118, loss = 0.01585016
Iteration 2119, loss = 0.01584292
Iteration 2120, loss = 0.01583207
Iteration 2121, loss = 0.01582237
Iteration 2122, loss = 0.01581371
Iteration 2123, loss = 0.01580419
Iteration 2124, loss = 0.01579457
Iteration 2125, loss = 0.01578687
Iteration 2126, loss = 0.01577842
Iteration 2127, loss = 0.01576813
Iteration 2128, loss = 0.01575852
Iteration 2129, loss = 0.01574962
Iteration 2130, loss = 0.01574047
Iteration 2131, loss = 0.01573200
Iteration 2132, loss = 0.01572353
Iteration 2133, loss = 0.01571397
Iteration 2134, loss = 0.01570564
Iteration 2135, loss = 0.01569623
Iteration 2136, loss = 0.01568775
Iteration 2137, loss = 0.01567885
Iteration 2138, loss = 0.01567027
Iteration 2139, loss = 0.01566231
Iteration 2140, loss = 0.01565252
Iteration 2141, loss = 0.01564309
Iteration 2142, loss = 0.01563399
Iteration 2143, loss = 0.01562541
Iteration 2144, loss = 0.01561681
Iteration 2145, loss = 0.01560695
Iteration 2146, loss = 0.01559734
Iteration 2147, loss = 0.01558896
Iteration 2148, loss = 0.01558023
Iteration 2149, loss = 0.01557131
Iteration 2150, loss = 0.01556213
Iteration 2151, loss = 0.01555363
Iteration 2152, loss = 0.01554529
Iteration 2153, loss = 0.01553521
Iteration 2154, loss = 0.01552655
Iteration 2155, loss = 0.01551742
Iteration 2156, loss = 0.01550880
Iteration 2157, loss = 0.01550007
Iteration 2158, loss = 0.01549115
Iteration 2159, loss = 0.01548284
Iteration 2160, loss = 0.01547498
Iteration 2161, loss = 0.01546567
Iteration 2162, loss = 0.01545664
Iteration 2163, loss = 0.01544808
Iteration 2164, loss = 0.01544067
Iteration 2165, loss = 0.01543465
Iteration 2166, loss = 0.01542436
Iteration 2167, loss = 0.01541594
Iteration 2168, loss = 0.01540786
Iteration 2169, loss = 0.01539876
Iteration 2170, loss = 0.01539286
Iteration 2171, loss = 0.01538281
Iteration 2172, loss = 0.01537485
Iteration 2173, loss = 0.01536677
Iteration 2174, loss = 0.01535875
Iteration 2175, loss = 0.01535156
Iteration 2176, loss = 0.01534273
Iteration 2177, loss = 0.01533543
Iteration 2178, loss = 0.01532618
Iteration 2179, loss = 0.01531753
Iteration 2180, loss = 0.01530968
Iteration 2181, loss = 0.01530095
Iteration 2182, loss = 0.01529200
Iteration 2183, loss = 0.01528359
Iteration 2184, loss = 0.01527535
Iteration 2185, loss = 0.01526727
Iteration 2186, loss = 0.01525980
Iteration 2187, loss = 0.01525034
Iteration 2188, loss = 0.01524365
Iteration 2189, loss = 0.01523464
Iteration 2190, loss = 0.01522468
Iteration 2191, loss = 0.01521614
Iteration 2192, loss = 0.01520663
Iteration 2193, loss = 0.01519848
Iteration 2194, loss = 0.01518859
Iteration 2195, loss = 0.01518300
Iteration 2196, loss = 0.01517199
Iteration 2197, loss = 0.01516404
Iteration 2198, loss = 0.01515506
Iteration 2199, loss = 0.01514692
Iteration 2200, loss = 0.01513936
Iteration 2201, loss = 0.01513087
Iteration 2202, loss = 0.01512215
Iteration 2203, loss = 0.01511404
Iteration 2204, loss = 0.01510589
Iteration 2205, loss = 0.01510078
Iteration 2206, loss = 0.01509011
Iteration 2207, loss = 0.01508132
Iteration 2208, loss = 0.01507436
Iteration 2209, loss = 0.01506801
Iteration 2210, loss = 0.01505988
Iteration 2211, loss = 0.01505041
Iteration 2212, loss = 0.01504205
Iteration 2213, loss = 0.01503237
Iteration 2214, loss = 0.01502336
Iteration 2215, loss = 0.01501443
Iteration 2216, loss = 0.01500566
Iteration 2217, loss = 0.01499478
Iteration 2218, loss = 0.01498594
Iteration 2219, loss = 0.01497785
Iteration 2220, loss = 0.01497064
Iteration 2221, loss = 0.01496042
Iteration 2222, loss = 0.01495288
Iteration 2223, loss = 0.01494369
Iteration 2224, loss = 0.01493654
Iteration 2225, loss = 0.01492815
Iteration 2226, loss = 0.01492060
Iteration 2227, loss = 0.01491334
Iteration 2228, loss = 0.01490316
Iteration 2229, loss = 0.01489528
Iteration 2230, loss = 0.01488693
Iteration 2231, loss = 0.01487862
Iteration 2232, loss = 0.01487086
Iteration 2233, loss = 0.01486218
Iteration 2234, loss = 0.01485465
Iteration 2235, loss = 0.01484598
Iteration 2236, loss = 0.01483800
Iteration 2237, loss = 0.01483138
Iteration 2238, loss = 0.01482140
Iteration 2239, loss = 0.01481310
Iteration 2240, loss = 0.01480587
Iteration 2241, loss = 0.01479796
Iteration 2242, loss = 0.01478822
Iteration 2243, loss = 0.01477968
Iteration 2244, loss = 0.01477240
Iteration 2245, loss = 0.01476313
Iteration 2246, loss = 0.01475555
Iteration 2247, loss = 0.01474696
Iteration 2248, loss = 0.01473892
Iteration 2249, loss = 0.01473241
Iteration 2250, loss = 0.01472352
Iteration 2251, loss = 0.01471573
Iteration 2252, loss = 0.01470842
Iteration 2253, loss = 0.01470161
Iteration 2254, loss = 0.01469262
Iteration 2255, loss = 0.01468490
Iteration 2256, loss = 0.01467741
Iteration 2257, loss = 0.01466952
Iteration 2258, loss = 0.01466221
Iteration 2259, loss = 0.01465391
Iteration 2260, loss = 0.01464662
Iteration 2261, loss = 0.01463848
Iteration 2262, loss = 0.01463107
Iteration 2263, loss = 0.01462428
Iteration 2264, loss = 0.01461640
Iteration 2265, loss = 0.01460872
Iteration 2266, loss = 0.01460082
Iteration 2267, loss = 0.01459541
Iteration 2268, loss = 0.01458653
Iteration 2269, loss = 0.01457791
Iteration 2270, loss = 0.01456993
Iteration 2271, loss = 0.01456286
Iteration 2272, loss = 0.01455405
Iteration 2273, loss = 0.01454636
Iteration 2274, loss = 0.01453828
Iteration 2275, loss = 0.01453089
Iteration 2276, loss = 0.01452225
Iteration 2277, loss = 0.01451268
Iteration 2278, loss = 0.01450347
Iteration 2279, loss = 0.01449627
Iteration 2280, loss = 0.01448683
Iteration 2281, loss = 0.01447895
Iteration 2282, loss = 0.01446967
Iteration 2283, loss = 0.01446058
Iteration 2284, loss = 0.01445431
Iteration 2285, loss = 0.01444359
Iteration 2286, loss = 0.01443704
Iteration 2287, loss = 0.01442666
Iteration 2288, loss = 0.01441804
Iteration 2289, loss = 0.01441349
Iteration 2290, loss = 0.01440545
Iteration 2291, loss = 0.01439739
Iteration 2292, loss = 0.01438947
Iteration 2293, loss = 0.01438192
Iteration 2294, loss = 0.01437369
Iteration 2295, loss = 0.01436582
Iteration 2296, loss = 0.01435654
Iteration 2297, loss = 0.01435025
Iteration 2298, loss = 0.01434021
Iteration 2299, loss = 0.01433327
Iteration 2300, loss = 0.01432417
Iteration 2301, loss = 0.01431636
Iteration 2302, loss = 0.01430842
Iteration 2303, loss = 0.01430123
Iteration 2304, loss = 0.01429262
Iteration 2305, loss = 0.01428507
Iteration 2306, loss = 0.01427761
Iteration 2307, loss = 0.01426945
Iteration 2308, loss = 0.01426197
Iteration 2309, loss = 0.01425307
Iteration 2310, loss = 0.01424775
Iteration 2311, loss = 0.01423850
Iteration 2312, loss = 0.01423100
Iteration 2313, loss = 0.01422431
Iteration 2314, loss = 0.01421572
Iteration 2315, loss = 0.01420804
Iteration 2316, loss = 0.01419943
Iteration 2317, loss = 0.01419187
Iteration 2318, loss = 0.01418385
Iteration 2319, loss = 0.01417640
Iteration 2320, loss = 0.01416906
Iteration 2321, loss = 0.01416337
Iteration 2322, loss = 0.01415451
Iteration 2323, loss = 0.01414636
Iteration 2324, loss = 0.01413963
Iteration 2325, loss = 0.01413233
Iteration 2326, loss = 0.01412511
Iteration 2327, loss = 0.01411831
Iteration 2328, loss = 0.01411147
Iteration 2329, loss = 0.01410377
Iteration 2330, loss = 0.01409675
Iteration 2331, loss = 0.01408971
Iteration 2332, loss = 0.01408445
Iteration 2333, loss = 0.01407660
Iteration 2334, loss = 0.01407020
Iteration 2335, loss = 0.01406480
Iteration 2336, loss = 0.01405506
Iteration 2337, loss = 0.01404960
Iteration 2338, loss = 0.01404005
Iteration 2339, loss = 0.01403378
Iteration 2340, loss = 0.01402543
Iteration 2341, loss = 0.01401830
Iteration 2342, loss = 0.01401048
Iteration 2343, loss = 0.01400296
Iteration 2344, loss = 0.01399608
Iteration 2345, loss = 0.01398931
Iteration 2346, loss = 0.01398036
Iteration 2347, loss = 0.01397371
Iteration 2348, loss = 0.01396534
Iteration 2349, loss = 0.01395872
Iteration 2350, loss = 0.01395119
Iteration 2351, loss = 0.01394409
Iteration 2352, loss = 0.01393739
Iteration 2353, loss = 0.01393070
Iteration 2354, loss = 0.01392359
Iteration 2355, loss = 0.01391656
Iteration 2356, loss = 0.01390895
Iteration 2357, loss = 0.01390224
Iteration 2358, loss = 0.01389506
Iteration 2359, loss = 0.01388866
Iteration 2360, loss = 0.01387937
Iteration 2361, loss = 0.01387045
Iteration 2362, loss = 0.01386177
Iteration 2363, loss = 0.01385539
Iteration 2364, loss = 0.01384777
Iteration 2365, loss = 0.01384027
Iteration 2366, loss = 0.01383224
Iteration 2367, loss = 0.01382560
Iteration 2368, loss = 0.01381935
Iteration 2369, loss = 0.01381208
Iteration 2370, loss = 0.01380463
Iteration 2371, loss = 0.01380032
Iteration 2372, loss = 0.01379243
Iteration 2373, loss = 0.01378301
Iteration 2374, loss = 0.01377555
Iteration 2375, loss = 0.01376775
Iteration 2376, loss = 0.01376113
Iteration 2377, loss = 0.01375248
Iteration 2378, loss = 0.01374605
Iteration 2379, loss = 0.01374013
Iteration 2380, loss = 0.01373219
Iteration 2381, loss = 0.01372301
Iteration 2382, loss = 0.01371625
Iteration 2383, loss = 0.01370877
Iteration 2384, loss = 0.01370089
Iteration 2385, loss = 0.01369387
Iteration 2386, loss = 0.01368757
Iteration 2387, loss = 0.01367914
Iteration 2388, loss = 0.01367513
Iteration 2389, loss = 0.01366656
Iteration 2390, loss = 0.01365926
Iteration 2391, loss = 0.01365173
Iteration 2392, loss = 0.01364454
Iteration 2393, loss = 0.01363813
Iteration 2394, loss = 0.01363213
Iteration 2395, loss = 0.01362367
Iteration 2396, loss = 0.01361649
Iteration 2397, loss = 0.01360797
Iteration 2398, loss = 0.01360167
Iteration 2399, loss = 0.01359410
Iteration 2400, loss = 0.01358680
Iteration 2401, loss = 0.01357923
Iteration 2402, loss = 0.01357225
Iteration 2403, loss = 0.01356483
Iteration 2404, loss = 0.01355916
Iteration 2405, loss = 0.01354998
Iteration 2406, loss = 0.01354257
Iteration 2407, loss = 0.01353510
Iteration 2408, loss = 0.01352897
Iteration 2409, loss = 0.01352187
Iteration 2410, loss = 0.01351442
Iteration 2411, loss = 0.01350835
Iteration 2412, loss = 0.01350151
Iteration 2413, loss = 0.01349521
Iteration 2414, loss = 0.01348907
Iteration 2415, loss = 0.01348281
Iteration 2416, loss = 0.01347780
Iteration 2417, loss = 0.01346975
Iteration 2418, loss = 0.01346298
Iteration 2419, loss = 0.01345592
Iteration 2420, loss = 0.01344875
Iteration 2421, loss = 0.01344220
Iteration 2422, loss = 0.01343663
Iteration 2423, loss = 0.01342835
Iteration 2424, loss = 0.01342100
Iteration 2425, loss = 0.01341423
Iteration 2426, loss = 0.01340741
Iteration 2427, loss = 0.01340146
Iteration 2428, loss = 0.01339485
Iteration 2429, loss = 0.01339165
Iteration 2430, loss = 0.01338170
Iteration 2431, loss = 0.01337451
Iteration 2432, loss = 0.01336799
Iteration 2433, loss = 0.01336120
Iteration 2434, loss = 0.01335281
Iteration 2435, loss = 0.01334536
Iteration 2436, loss = 0.01333772
Iteration 2437, loss = 0.01333157
Iteration 2438, loss = 0.01332506
Iteration 2439, loss = 0.01331664
Iteration 2440, loss = 0.01330988
Iteration 2441, loss = 0.01330405
Iteration 2442, loss = 0.01329700
Iteration 2443, loss = 0.01328981
Iteration 2444, loss = 0.01328361
Iteration 2445, loss = 0.01327701
Iteration 2446, loss = 0.01327014
Iteration 2447, loss = 0.01326329
Iteration 2448, loss = 0.01325666
Iteration 2449, loss = 0.01324883
Iteration 2450, loss = 0.01324289
Iteration 2451, loss = 0.01323558
Iteration 2452, loss = 0.01322873
Iteration 2453, loss = 0.01322167
Iteration 2454, loss = 0.01321518
Iteration 2455, loss = 0.01320836
Iteration 2456, loss = 0.01320162
Iteration 2457, loss = 0.01319524
Iteration 2458, loss = 0.01319015
Iteration 2459, loss = 0.01318309
Iteration 2460, loss = 0.01317649
Iteration 2461, loss = 0.01317005
Iteration 2462, loss = 0.01316407
Iteration 2463, loss = 0.01315717
Iteration 2464, loss = 0.01315040
Iteration 2465, loss = 0.01314328
Iteration 2466, loss = 0.01313586
Iteration 2467, loss = 0.01312944
Iteration 2468, loss = 0.01312432
Iteration 2469, loss = 0.01311623
Iteration 2470, loss = 0.01311020
Iteration 2471, loss = 0.01310405
Iteration 2472, loss = 0.01309766
Iteration 2473, loss = 0.01309193
Iteration 2474, loss = 0.01308626
Iteration 2475, loss = 0.01307977
Iteration 2476, loss = 0.01307369
Iteration 2477, loss = 0.01306822
Iteration 2478, loss = 0.01306093
Iteration 2479, loss = 0.01305506
Iteration 2480, loss = 0.01304805
Iteration 2481, loss = 0.01304053
Iteration 2482, loss = 0.01303348
Iteration 2483, loss = 0.01302735
Iteration 2484, loss = 0.01302036
Iteration 2485, loss = 0.01301266
Iteration 2486, loss = 0.01300556
Iteration 2487, loss = 0.01300043
Iteration 2488, loss = 0.01299327
Iteration 2489, loss = 0.01298457
Iteration 2490, loss = 0.01297763
Iteration 2491, loss = 0.01297197
Iteration 2492, loss = 0.01296378
Iteration 2493, loss = 0.01295700
Iteration 2494, loss = 0.01294985
Iteration 2495, loss = 0.01294356
Iteration 2496, loss = 0.01293659
Iteration 2497, loss = 0.01292899
Iteration 2498, loss = 0.01292263
Iteration 2499, loss = 0.01291607
Iteration 2500, loss = 0.01290946
Iteration 2501, loss = 0.01290308
Iteration 2502, loss = 0.01289573
Iteration 2503, loss = 0.01289036
Iteration 2504, loss = 0.01288224
Iteration 2505, loss = 0.01287734
Iteration 2506, loss = 0.01286947
Iteration 2507, loss = 0.01286417
Iteration 2508, loss = 0.01285620
Iteration 2509, loss = 0.01284831
Iteration 2510, loss = 0.01284112
Iteration 2511, loss = 0.01283551
Iteration 2512, loss = 0.01282726
Iteration 2513, loss = 0.01281944
Iteration 2514, loss = 0.01281313
Iteration 2515, loss = 0.01280815
Iteration 2516, loss = 0.01279919
Iteration 2517, loss = 0.01279205
Iteration 2518, loss = 0.01278539
Iteration 2519, loss = 0.01277816
Iteration 2520, loss = 0.01277222
Iteration 2521, loss = 0.01276554
Iteration 2522, loss = 0.01275809
Iteration 2523, loss = 0.01275251
Iteration 2524, loss = 0.01274495
Iteration 2525, loss = 0.01273831
Iteration 2526, loss = 0.01273450
Iteration 2527, loss = 0.01272569
Iteration 2528, loss = 0.01271877
Iteration 2529, loss = 0.01271161
Iteration 2530, loss = 0.01270447
Iteration 2531, loss = 0.01269722
Iteration 2532, loss = 0.01269362
Iteration 2533, loss = 0.01268564
Iteration 2534, loss = 0.01267931
Iteration 2535, loss = 0.01267337
Iteration 2536, loss = 0.01266744
Iteration 2537, loss = 0.01266171
Iteration 2538, loss = 0.01265592
Iteration 2539, loss = 0.01265028
Iteration 2540, loss = 0.01264423
Iteration 2541, loss = 0.01263812
Iteration 2542, loss = 0.01263242
Iteration 2543, loss = 0.01262656
Iteration 2544, loss = 0.01262095
Iteration 2545, loss = 0.01261614
Iteration 2546, loss = 0.01260974
Iteration 2547, loss = 0.01260451
Iteration 2548, loss = 0.01259866
Iteration 2549, loss = 0.01259306
Iteration 2550, loss = 0.01258751
Iteration 2551, loss = 0.01258131
Iteration 2552, loss = 0.01257630
Iteration 2553, loss = 0.01257037
Iteration 2554, loss = 0.01256410
Iteration 2555, loss = 0.01255860
Iteration 2556, loss = 0.01255199
Iteration 2557, loss = 0.01254593
Iteration 2558, loss = 0.01253984
Iteration 2559, loss = 0.01253360
Iteration 2560, loss = 0.01252771
Iteration 2561, loss = 0.01252186
Iteration 2562, loss = 0.01251608
Iteration 2563, loss = 0.01251107
Iteration 2564, loss = 0.01250454
Iteration 2565, loss = 0.01249931
Iteration 2566, loss = 0.01249240
Iteration 2567, loss = 0.01248868
Iteration 2568, loss = 0.01247978
Iteration 2569, loss = 0.01247491
Iteration 2570, loss = 0.01246885
Iteration 2571, loss = 0.01246137
Iteration 2572, loss = 0.01245464
Iteration 2573, loss = 0.01244896
Iteration 2574, loss = 0.01244254
Iteration 2575, loss = 0.01243651
Iteration 2576, loss = 0.01243093
Iteration 2577, loss = 0.01242400
Iteration 2578, loss = 0.01241768
Iteration 2579, loss = 0.01241346
Iteration 2580, loss = 0.01240546
Iteration 2581, loss = 0.01239785
Iteration 2582, loss = 0.01239300
Iteration 2583, loss = 0.01238535
Iteration 2584, loss = 0.01237993
Iteration 2585, loss = 0.01237386
Iteration 2586, loss = 0.01236736
Iteration 2587, loss = 0.01236137
Iteration 2588, loss = 0.01235547
Iteration 2589, loss = 0.01234906
Iteration 2590, loss = 0.01234321
Iteration 2591, loss = 0.01233726
Iteration 2592, loss = 0.01233084
Iteration 2593, loss = 0.01232609
Iteration 2594, loss = 0.01232059
Iteration 2595, loss = 0.01231416
Iteration 2596, loss = 0.01230847
Iteration 2597, loss = 0.01230278
Iteration 2598, loss = 0.01229777
Iteration 2599, loss = 0.01229153
Iteration 2600, loss = 0.01228581
Iteration 2601, loss = 0.01227963
Iteration 2602, loss = 0.01227346
Iteration 2603, loss = 0.01226769
Iteration 2604, loss = 0.01226261
Iteration 2605, loss = 0.01225616
Iteration 2606, loss = 0.01224991
Iteration 2607, loss = 0.01224423
Iteration 2608, loss = 0.01223901
Iteration 2609, loss = 0.01223320
Iteration 2610, loss = 0.01222747
Iteration 2611, loss = 0.01222261
Iteration 2612, loss = 0.01221637
Iteration 2613, loss = 0.01221064
Iteration 2614, loss = 0.01220466
Iteration 2615, loss = 0.01219934
Iteration 2616, loss = 0.01219345
Iteration 2617, loss = 0.01218799
Iteration 2618, loss = 0.01218022
Iteration 2619, loss = 0.01217334
Iteration 2620, loss = 0.01216621
Iteration 2621, loss = 0.01216010
Iteration 2622, loss = 0.01215428
Iteration 2623, loss = 0.01214679
Iteration 2624, loss = 0.01214053
Iteration 2625, loss = 0.01213376
Iteration 2626, loss = 0.01212774
Iteration 2627, loss = 0.01212149
Iteration 2628, loss = 0.01211605
Iteration 2629, loss = 0.01210925
Iteration 2630, loss = 0.01210340
Iteration 2631, loss = 0.01209735
Iteration 2632, loss = 0.01209137
Iteration 2633, loss = 0.01208619
Iteration 2634, loss = 0.01208002
Iteration 2635, loss = 0.01207364
Iteration 2636, loss = 0.01206924
Iteration 2637, loss = 0.01206299
Iteration 2638, loss = 0.01206202
Iteration 2639, loss = 0.01205249
Iteration 2640, loss = 0.01204770
Iteration 2641, loss = 0.01204266
Iteration 2642, loss = 0.01203648
Iteration 2643, loss = 0.01203078
Iteration 2644, loss = 0.01202573
Iteration 2645, loss = 0.01202008
Iteration 2646, loss = 0.01201707
Iteration 2647, loss = 0.01201202
Iteration 2648, loss = 0.01200578
Iteration 2649, loss = 0.01199933
Iteration 2650, loss = 0.01199423
Iteration 2651, loss = 0.01198741
Iteration 2652, loss = 0.01198187
Iteration 2653, loss = 0.01197612
Iteration 2654, loss = 0.01196912
Iteration 2655, loss = 0.01196334
Iteration 2656, loss = 0.01195884
Iteration 2657, loss = 0.01195195
Iteration 2658, loss = 0.01194554
Iteration 2659, loss = 0.01193953
Iteration 2660, loss = 0.01193306
Iteration 2661, loss = 0.01192793
Iteration 2662, loss = 0.01192200
Iteration 2663, loss = 0.01191541
Iteration 2664, loss = 0.01190930
Iteration 2665, loss = 0.01190368
Iteration 2666, loss = 0.01189842
Iteration 2667, loss = 0.01189257
Iteration 2668, loss = 0.01188734
Iteration 2669, loss = 0.01188143
Iteration 2670, loss = 0.01187607
Iteration 2671, loss = 0.01187031
Iteration 2672, loss = 0.01186794
Iteration 2673, loss = 0.01186139
Iteration 2674, loss = 0.01185471
Iteration 2675, loss = 0.01184851
Iteration 2676, loss = 0.01184290
Iteration 2677, loss = 0.01183736
Iteration 2678, loss = 0.01183231
Iteration 2679, loss = 0.01182638
Iteration 2680, loss = 0.01182044
Iteration 2681, loss = 0.01181554
Iteration 2682, loss = 0.01180951
Iteration 2683, loss = 0.01180479
Iteration 2684, loss = 0.01179867
Iteration 2685, loss = 0.01179357
Iteration 2686, loss = 0.01178826
Iteration 2687, loss = 0.01178260
Iteration 2688, loss = 0.01177794
Iteration 2689, loss = 0.01177227
Iteration 2690, loss = 0.01176706
Iteration 2691, loss = 0.01176207
Iteration 2692, loss = 0.01175715
Iteration 2693, loss = 0.01175177
Iteration 2694, loss = 0.01174837
Iteration 2695, loss = 0.01174155
Iteration 2696, loss = 0.01173636
Iteration 2697, loss = 0.01173085
Iteration 2698, loss = 0.01172565
Iteration 2699, loss = 0.01172071
Iteration 2700, loss = 0.01171523
Iteration 2701, loss = 0.01171083
Iteration 2702, loss = 0.01170563
Iteration 2703, loss = 0.01169987
Iteration 2704, loss = 0.01169454
Iteration 2705, loss = 0.01168991
Iteration 2706, loss = 0.01168493
Iteration 2707, loss = 0.01167970
Iteration 2708, loss = 0.01167570
Iteration 2709, loss = 0.01167041
Iteration 2710, loss = 0.01166785
Iteration 2711, loss = 0.01166147
Iteration 2712, loss = 0.01165769
Iteration 2713, loss = 0.01165263
Iteration 2714, loss = 0.01164896
Iteration 2715, loss = 0.01164378
Iteration 2716, loss = 0.01163715
Iteration 2717, loss = 0.01163164
Iteration 2718, loss = 0.01162595
Iteration 2719, loss = 0.01161996
Iteration 2720, loss = 0.01161499
Iteration 2721, loss = 0.01160787
Iteration 2722, loss = 0.01160169
Iteration 2723, loss = 0.01159572
Iteration 2724, loss = 0.01158779
Iteration 2725, loss = 0.01158348
Iteration 2726, loss = 0.01157592
Iteration 2727, loss = 0.01157232
Iteration 2728, loss = 0.01156437
Iteration 2729, loss = 0.01155789
Iteration 2730, loss = 0.01155324
Iteration 2731, loss = 0.01154726
Iteration 2732, loss = 0.01154082
Iteration 2733, loss = 0.01153397
Iteration 2734, loss = 0.01152806
Iteration 2735, loss = 0.01152244
Iteration 2736, loss = 0.01151728
Iteration 2737, loss = 0.01151040
Iteration 2738, loss = 0.01150613
Iteration 2739, loss = 0.01150134
Iteration 2740, loss = 0.01149461
Iteration 2741, loss = 0.01148908
Iteration 2742, loss = 0.01148415
Iteration 2743, loss = 0.01147832
Iteration 2744, loss = 0.01147260
Iteration 2745, loss = 0.01146783
Iteration 2746, loss = 0.01146139
Iteration 2747, loss = 0.01145746
Iteration 2748, loss = 0.01145121
Iteration 2749, loss = 0.01144467
Iteration 2750, loss = 0.01143868
Iteration 2751, loss = 0.01143634
Iteration 2752, loss = 0.01142826
Iteration 2753, loss = 0.01142341
Iteration 2754, loss = 0.01141826
Iteration 2755, loss = 0.01141272
Iteration 2756, loss = 0.01140769
Iteration 2757, loss = 0.01140241
Iteration 2758, loss = 0.01139733
Iteration 2759, loss = 0.01139192
Iteration 2760, loss = 0.01138839
Iteration 2761, loss = 0.01138233
Iteration 2762, loss = 0.01137767
Iteration 2763, loss = 0.01137141
Iteration 2764, loss = 0.01136632
Iteration 2765, loss = 0.01136115
Iteration 2766, loss = 0.01135568
Iteration 2767, loss = 0.01135023
Iteration 2768, loss = 0.01134535
Iteration 2769, loss = 0.01134094
Iteration 2770, loss = 0.01133523
Iteration 2771, loss = 0.01133047
Iteration 2772, loss = 0.01132598
Iteration 2773, loss = 0.01132044
Iteration 2774, loss = 0.01131616
Iteration 2775, loss = 0.01131075
Iteration 2776, loss = 0.01130555
Iteration 2777, loss = 0.01130047
Iteration 2778, loss = 0.01129601
Iteration 2779, loss = 0.01129148
Iteration 2780, loss = 0.01128703
Iteration 2781, loss = 0.01128310
Iteration 2782, loss = 0.01127713
Iteration 2783, loss = 0.01127219
Iteration 2784, loss = 0.01126829
Iteration 2785, loss = 0.01126304
Iteration 2786, loss = 0.01125779
Iteration 2787, loss = 0.01125265
Iteration 2788, loss = 0.01124704
Iteration 2789, loss = 0.01124192
Iteration 2790, loss = 0.01123645
Iteration 2791, loss = 0.01123162
Iteration 2792, loss = 0.01122512
Iteration 2793, loss = 0.01122035
Iteration 2794, loss = 0.01121383
Iteration 2795, loss = 0.01120942
Iteration 2796, loss = 0.01120421
Iteration 2797, loss = 0.01119782
Iteration 2798, loss = 0.01119250
Iteration 2799, loss = 0.01118738
Iteration 2800, loss = 0.01118181
Iteration 2801, loss = 0.01117701
Iteration 2802, loss = 0.01117167
Iteration 2803, loss = 0.01116636
Iteration 2804, loss = 0.01116179
Iteration 2805, loss = 0.01115626
Iteration 2806, loss = 0.01115134
Iteration 2807, loss = 0.01114528
Iteration 2808, loss = 0.01114013
Iteration 2809, loss = 0.01113585
Iteration 2810, loss = 0.01112914
Iteration 2811, loss = 0.01112428
Iteration 2812, loss = 0.01111939
Iteration 2813, loss = 0.01111448
Iteration 2814, loss = 0.01110946
Iteration 2815, loss = 0.01110460
Iteration 2816, loss = 0.01110177
Iteration 2817, loss = 0.01109569
Iteration 2818, loss = 0.01109063
Iteration 2819, loss = 0.01108544
Iteration 2820, loss = 0.01108018
Iteration 2821, loss = 0.01107509
Iteration 2822, loss = 0.01107031
Iteration 2823, loss = 0.01106479
Iteration 2824, loss = 0.01105983
Iteration 2825, loss = 0.01105577
Iteration 2826, loss = 0.01105215
Iteration 2827, loss = 0.01104633
Iteration 2828, loss = 0.01104112
Iteration 2829, loss = 0.01103565
Iteration 2830, loss = 0.01103168
Iteration 2831, loss = 0.01102612
Iteration 2832, loss = 0.01102396
Iteration 2833, loss = 0.01101720
Iteration 2834, loss = 0.01101393
Iteration 2835, loss = 0.01100839
Iteration 2836, loss = 0.01100374
Iteration 2837, loss = 0.01099953
Iteration 2838, loss = 0.01099490
Iteration 2839, loss = 0.01099123
Iteration 2840, loss = 0.01098751
Iteration 2841, loss = 0.01098189
Iteration 2842, loss = 0.01097803
Iteration 2843, loss = 0.01097214
Iteration 2844, loss = 0.01096770
Iteration 2845, loss = 0.01096344
Iteration 2846, loss = 0.01095801
Iteration 2847, loss = 0.01095272
Iteration 2848, loss = 0.01094761
Iteration 2849, loss = 0.01094257
Iteration 2850, loss = 0.01093821
Iteration 2851, loss = 0.01093271
Iteration 2852, loss = 0.01092680
Iteration 2853, loss = 0.01092179
Iteration 2854, loss = 0.01091711
Iteration 2855, loss = 0.01091164
Iteration 2856, loss = 0.01090692
Iteration 2857, loss = 0.01090197
Iteration 2858, loss = 0.01089738
Iteration 2859, loss = 0.01089238
Iteration 2860, loss = 0.01088790
Iteration 2861, loss = 0.01088307
Iteration 2862, loss = 0.01087870
Iteration 2863, loss = 0.01087468
Iteration 2864, loss = 0.01086967
Iteration 2865, loss = 0.01086564
Iteration 2866, loss = 0.01086087
Iteration 2867, loss = 0.01085599
Iteration 2868, loss = 0.01085212
Iteration 2869, loss = 0.01084644
Iteration 2870, loss = 0.01084165
Iteration 2871, loss = 0.01083659
Iteration 2872, loss = 0.01083214
Iteration 2873, loss = 0.01082795
Iteration 2874, loss = 0.01082212
Iteration 2875, loss = 0.01081797
Iteration 2876, loss = 0.01081323
Iteration 2877, loss = 0.01080907
Iteration 2878, loss = 0.01080352
Iteration 2879, loss = 0.01079780
Iteration 2880, loss = 0.01079297
Iteration 2881, loss = 0.01078699
Iteration 2882, loss = 0.01078314
Iteration 2883, loss = 0.01077665
Iteration 2884, loss = 0.01077270
Iteration 2885, loss = 0.01076809
Iteration 2886, loss = 0.01076255
Iteration 2887, loss = 0.01075785
Iteration 2888, loss = 0.01075314
Iteration 2889, loss = 0.01074963
Iteration 2890, loss = 0.01074432
Iteration 2891, loss = 0.01074012
Iteration 2892, loss = 0.01073464
Iteration 2893, loss = 0.01073052
Iteration 2894, loss = 0.01072563
Iteration 2895, loss = 0.01072099
Iteration 2896, loss = 0.01071562
Iteration 2897, loss = 0.01071058
Iteration 2898, loss = 0.01070536
Iteration 2899, loss = 0.01070031
Iteration 2900, loss = 0.01069545
Iteration 2901, loss = 0.01069049
Iteration 2902, loss = 0.01068629
Iteration 2903, loss = 0.01068155
Iteration 2904, loss = 0.01067660
Iteration 2905, loss = 0.01067183
Iteration 2906, loss = 0.01066706
Iteration 2907, loss = 0.01066233
Iteration 2908, loss = 0.01065733
Iteration 2909, loss = 0.01065284
Iteration 2910, loss = 0.01064955
Iteration 2911, loss = 0.01064361
Iteration 2912, loss = 0.01063914
Iteration 2913, loss = 0.01063465
Iteration 2914, loss = 0.01063045
Iteration 2915, loss = 0.01062596
Iteration 2916, loss = 0.01062140
Iteration 2917, loss = 0.01061688
Iteration 2918, loss = 0.01061322
Iteration 2919, loss = 0.01060837
Iteration 2920, loss = 0.01060514
Iteration 2921, loss = 0.01060004
Iteration 2922, loss = 0.01059647
Iteration 2923, loss = 0.01059231
Iteration 2924, loss = 0.01058702
Iteration 2925, loss = 0.01058308
Iteration 2926, loss = 0.01057864
Iteration 2927, loss = 0.01057427
Iteration 2928, loss = 0.01056981
Iteration 2929, loss = 0.01056532
Iteration 2930, loss = 0.01055942
Iteration 2931, loss = 0.01055425
Iteration 2932, loss = 0.01055024
Iteration 2933, loss = 0.01054493
Iteration 2934, loss = 0.01054041
Iteration 2935, loss = 0.01053652
Iteration 2936, loss = 0.01053057
Iteration 2937, loss = 0.01052738
Iteration 2938, loss = 0.01052080
Iteration 2939, loss = 0.01051665
Iteration 2940, loss = 0.01051188
Iteration 2941, loss = 0.01050739
Iteration 2942, loss = 0.01050238
Iteration 2943, loss = 0.01049797
Iteration 2944, loss = 0.01049330
Iteration 2945, loss = 0.01048906
Iteration 2946, loss = 0.01048596
Iteration 2947, loss = 0.01048142
Iteration 2948, loss = 0.01047808
Iteration 2949, loss = 0.01047609
Iteration 2950, loss = 0.01047030
Iteration 2951, loss = 0.01046574
Iteration 2952, loss = 0.01046155
Iteration 2953, loss = 0.01045641
Iteration 2954, loss = 0.01045117
Iteration 2955, loss = 0.01044744
Iteration 2956, loss = 0.01044354
Iteration 2957, loss = 0.01043738
Iteration 2958, loss = 0.01043292
Iteration 2959, loss = 0.01042799
Iteration 2960, loss = 0.01042285
Iteration 2961, loss = 0.01041807
Iteration 2962, loss = 0.01041449
Iteration 2963, loss = 0.01040879
Iteration 2964, loss = 0.01040325
Iteration 2965, loss = 0.01039903
Iteration 2966, loss = 0.01039431
Iteration 2967, loss = 0.01039095
Iteration 2968, loss = 0.01038541
Iteration 2969, loss = 0.01038274
Iteration 2970, loss = 0.01037562
Iteration 2971, loss = 0.01037060
Iteration 2972, loss = 0.01036619
Iteration 2973, loss = 0.01036171
Iteration 2974, loss = 0.01035691
Iteration 2975, loss = 0.01035276
Iteration 2976, loss = 0.01034852
Iteration 2977, loss = 0.01034384
Iteration 2978, loss = 0.01033967
Iteration 2979, loss = 0.01033553
Iteration 2980, loss = 0.01033113
Iteration 2981, loss = 0.01032737
Iteration 2982, loss = 0.01032371
Iteration 2983, loss = 0.01031956
Iteration 2984, loss = 0.01031591
Iteration 2985, loss = 0.01031057
Iteration 2986, loss = 0.01030662
Iteration 2987, loss = 0.01030249
Iteration 2988, loss = 0.01029853
Iteration 2989, loss = 0.01029442
Iteration 2990, loss = 0.01029123
Iteration 2991, loss = 0.01028648
Iteration 2992, loss = 0.01028237
Iteration 2993, loss = 0.01027816
Iteration 2994, loss = 0.01027376
Iteration 2995, loss = 0.01026977
Iteration 2996, loss = 0.01026546
Iteration 2997, loss = 0.01026110
Iteration 2998, loss = 0.01025618
Iteration 2999, loss = 0.01025197
Iteration 3000, loss = 0.01024730
Iteration 3001, loss = 0.01024405
Iteration 3002, loss = 0.01023926
Iteration 3003, loss = 0.01023461
Iteration 3004, loss = 0.01023004
Iteration 3005, loss = 0.01022590
Iteration 3006, loss = 0.01022162
Iteration 3007, loss = 0.01021804
Iteration 3008, loss = 0.01021363
Iteration 3009, loss = 0.01020962
Iteration 3010, loss = 0.01020522
Iteration 3011, loss = 0.01020120
Iteration 3012, loss = 0.01019631
Iteration 3013, loss = 0.01019173
Iteration 3014, loss = 0.01018726
Iteration 3015, loss = 0.01018308
Iteration 3016, loss = 0.01017844
Iteration 3017, loss = 0.01017423
Iteration 3018, loss = 0.01016914
Iteration 3019, loss = 0.01016527
Iteration 3020, loss = 0.01015981
Iteration 3021, loss = 0.01015479
Iteration 3022, loss = 0.01014917
Iteration 3023, loss = 0.01014480
Iteration 3024, loss = 0.01014040
Iteration 3025, loss = 0.01013780
Iteration 3026, loss = 0.01013175
Iteration 3027, loss = 0.01012868
Iteration 3028, loss = 0.01012353
Iteration 3029, loss = 0.01011940
Iteration 3030, loss = 0.01011564
Iteration 3031, loss = 0.01011192
Iteration 3032, loss = 0.01010644
Iteration 3033, loss = 0.01010199
Iteration 3034, loss = 0.01009786
Iteration 3035, loss = 0.01009266
Iteration 3036, loss = 0.01008708
Iteration 3037, loss = 0.01008221
Iteration 3038, loss = 0.01007742
Iteration 3039, loss = 0.01007474
Iteration 3040, loss = 0.01006838
Iteration 3041, loss = 0.01006463
Iteration 3042, loss = 0.01006197
Iteration 3043, loss = 0.01005594
Iteration 3044, loss = 0.01005212
Iteration 3045, loss = 0.01004935
Iteration 3046, loss = 0.01004549
Iteration 3047, loss = 0.01004047
Iteration 3048, loss = 0.01003753
Iteration 3049, loss = 0.01003300
Iteration 3050, loss = 0.01002926
Iteration 3051, loss = 0.01002464
Iteration 3052, loss = 0.01002007
Iteration 3053, loss = 0.01001505
Iteration 3054, loss = 0.01001085
Iteration 3055, loss = 0.01000697
Iteration 3056, loss = 0.01000236
Iteration 3057, loss = 0.00999778
Iteration 3058, loss = 0.00999322
Iteration 3059, loss = 0.00998880
Iteration 3060, loss = 0.00998557
Iteration 3061, loss = 0.00998090
Iteration 3062, loss = 0.00997606
Iteration 3063, loss = 0.00997150
Iteration 3064, loss = 0.00996701
Iteration 3065, loss = 0.00996194
Iteration 3066, loss = 0.00995776
Iteration 3067, loss = 0.00995385
Iteration 3068, loss = 0.00994942
Iteration 3069, loss = 0.00994558
Iteration 3070, loss = 0.00994241
Iteration 3071, loss = 0.00993794
Iteration 3072, loss = 0.00993298
Iteration 3073, loss = 0.00992874
Iteration 3074, loss = 0.00992467
Iteration 3075, loss = 0.00992037
Iteration 3076, loss = 0.00991580
Iteration 3077, loss = 0.00991166
Iteration 3078, loss = 0.00990685
Iteration 3079, loss = 0.00990263
Iteration 3080, loss = 0.00989988
Iteration 3081, loss = 0.00989454
Iteration 3082, loss = 0.00989111
Iteration 3083, loss = 0.00988641
Iteration 3084, loss = 0.00988217
Iteration 3085, loss = 0.00987796
Iteration 3086, loss = 0.00987520
Iteration 3087, loss = 0.00987036
Iteration 3088, loss = 0.00986656
Iteration 3089, loss = 0.00986199
Iteration 3090, loss = 0.00985782
Iteration 3091, loss = 0.00985336
Iteration 3092, loss = 0.00984881
Iteration 3093, loss = 0.00984464
Iteration 3094, loss = 0.00984123
Iteration 3095, loss = 0.00983679
Iteration 3096, loss = 0.00983238
Iteration 3097, loss = 0.00982802
Iteration 3098, loss = 0.00982342
Iteration 3099, loss = 0.00981895
Iteration 3100, loss = 0.00981601
Iteration 3101, loss = 0.00981049
Iteration 3102, loss = 0.00980627
Iteration 3103, loss = 0.00980183
Iteration 3104, loss = 0.00979907
Iteration 3105, loss = 0.00979362
Iteration 3106, loss = 0.00979084
Iteration 3107, loss = 0.00978653
Iteration 3108, loss = 0.00978227
Iteration 3109, loss = 0.00977852
Iteration 3110, loss = 0.00977472
Iteration 3111, loss = 0.00977188
Iteration 3112, loss = 0.00976726
Iteration 3113, loss = 0.00976328
Iteration 3114, loss = 0.00975961
Iteration 3115, loss = 0.00975536
Iteration 3116, loss = 0.00975198
Iteration 3117, loss = 0.00974706
Iteration 3118, loss = 0.00974280
Iteration 3119, loss = 0.00973907
Iteration 3120, loss = 0.00973466
Iteration 3121, loss = 0.00972992
Iteration 3122, loss = 0.00972632
Iteration 3123, loss = 0.00972213
Iteration 3124, loss = 0.00971823
Iteration 3125, loss = 0.00971408
Iteration 3126, loss = 0.00971008
Iteration 3127, loss = 0.00970661
Iteration 3128, loss = 0.00970167
Iteration 3129, loss = 0.00969730
Iteration 3130, loss = 0.00969350
Iteration 3131, loss = 0.00968960
Iteration 3132, loss = 0.00968523
Iteration 3133, loss = 0.00968084
Iteration 3134, loss = 0.00967690
Iteration 3135, loss = 0.00967384
Iteration 3136, loss = 0.00966903
Iteration 3137, loss = 0.00966528
Iteration 3138, loss = 0.00966222
Iteration 3139, loss = 0.00965771
Iteration 3140, loss = 0.00965352
Iteration 3141, loss = 0.00964923
Iteration 3142, loss = 0.00964526
Iteration 3143, loss = 0.00964094
Iteration 3144, loss = 0.00963905
Iteration 3145, loss = 0.00963243
Iteration 3146, loss = 0.00962852
Iteration 3147, loss = 0.00962381
Iteration 3148, loss = 0.00961980
Iteration 3149, loss = 0.00961620
Iteration 3150, loss = 0.00961136
Iteration 3151, loss = 0.00961018
Iteration 3152, loss = 0.00960425
Iteration 3153, loss = 0.00959974
Iteration 3154, loss = 0.00959573
Iteration 3155, loss = 0.00959228
Iteration 3156, loss = 0.00958808
Iteration 3157, loss = 0.00958522
Iteration 3158, loss = 0.00958117
Iteration 3159, loss = 0.00957659
Iteration 3160, loss = 0.00957240
Iteration 3161, loss = 0.00956796
Iteration 3162, loss = 0.00956423
Iteration 3163, loss = 0.00955962
Iteration 3164, loss = 0.00955494
Iteration 3165, loss = 0.00955044
Iteration 3166, loss = 0.00954814
Iteration 3167, loss = 0.00954193
Iteration 3168, loss = 0.00953815
Iteration 3169, loss = 0.00953390
Iteration 3170, loss = 0.00953213
Iteration 3171, loss = 0.00952661
Iteration 3172, loss = 0.00952099
Iteration 3173, loss = 0.00951744
Iteration 3174, loss = 0.00951392
Iteration 3175, loss = 0.00950892
Iteration 3176, loss = 0.00950489
Iteration 3177, loss = 0.00950084
Iteration 3178, loss = 0.00949757
Iteration 3179, loss = 0.00949340
Iteration 3180, loss = 0.00948909
Iteration 3181, loss = 0.00948576
Iteration 3182, loss = 0.00948097
Iteration 3183, loss = 0.00947759
Iteration 3184, loss = 0.00947346
Iteration 3185, loss = 0.00946975
Iteration 3186, loss = 0.00946550
Iteration 3187, loss = 0.00946231
Iteration 3188, loss = 0.00945826
Iteration 3189, loss = 0.00945413
Iteration 3190, loss = 0.00945041
Iteration 3191, loss = 0.00944648
Iteration 3192, loss = 0.00944197
Iteration 3193, loss = 0.00943826
Iteration 3194, loss = 0.00943419
Iteration 3195, loss = 0.00943119
Iteration 3196, loss = 0.00942727
Iteration 3197, loss = 0.00942373
Iteration 3198, loss = 0.00941869
Iteration 3199, loss = 0.00941461
Iteration 3200, loss = 0.00941118
Iteration 3201, loss = 0.00940754
Iteration 3202, loss = 0.00940361
Iteration 3203, loss = 0.00939907
Iteration 3204, loss = 0.00939570
Iteration 3205, loss = 0.00939234
Iteration 3206, loss = 0.00938773
Iteration 3207, loss = 0.00938359
Iteration 3208, loss = 0.00937959
Iteration 3209, loss = 0.00937663
Iteration 3210, loss = 0.00937232
Iteration 3211, loss = 0.00936766
Iteration 3212, loss = 0.00936372
Iteration 3213, loss = 0.00936024
Iteration 3214, loss = 0.00935597
Iteration 3215, loss = 0.00935241
Iteration 3216, loss = 0.00934970
Iteration 3217, loss = 0.00934585
Iteration 3218, loss = 0.00934086
Iteration 3219, loss = 0.00933733
Iteration 3220, loss = 0.00933386
Iteration 3221, loss = 0.00933009
Iteration 3222, loss = 0.00932648
Iteration 3223, loss = 0.00932368
Iteration 3224, loss = 0.00931966
Iteration 3225, loss = 0.00931626
Iteration 3226, loss = 0.00931258
Iteration 3227, loss = 0.00930878
Iteration 3228, loss = 0.00930600
Iteration 3229, loss = 0.00930199
Iteration 3230, loss = 0.00929810
Iteration 3231, loss = 0.00929427
Iteration 3232, loss = 0.00929060
Iteration 3233, loss = 0.00928655
Iteration 3234, loss = 0.00928284
Iteration 3235, loss = 0.00928022
Iteration 3236, loss = 0.00927553
Iteration 3237, loss = 0.00927120
Iteration 3238, loss = 0.00926860
Iteration 3239, loss = 0.00926465
Iteration 3240, loss = 0.00926077
Iteration 3241, loss = 0.00925719
Iteration 3242, loss = 0.00925361
Iteration 3243, loss = 0.00924990
Iteration 3244, loss = 0.00924626
Iteration 3245, loss = 0.00924259
Iteration 3246, loss = 0.00923853
Iteration 3247, loss = 0.00923474
Iteration 3248, loss = 0.00923036
Iteration 3249, loss = 0.00922625
Iteration 3250, loss = 0.00922249
Iteration 3251, loss = 0.00921840
Iteration 3252, loss = 0.00921525
Iteration 3253, loss = 0.00921141
Iteration 3254, loss = 0.00920869
Iteration 3255, loss = 0.00920407
Iteration 3256, loss = 0.00919988
Iteration 3257, loss = 0.00919562
Iteration 3258, loss = 0.00919139
Iteration 3259, loss = 0.00918758
Iteration 3260, loss = 0.00918358
Iteration 3261, loss = 0.00917952
Iteration 3262, loss = 0.00917645
Iteration 3263, loss = 0.00917143
Iteration 3264, loss = 0.00916761
Iteration 3265, loss = 0.00916394
Iteration 3266, loss = 0.00915951
Iteration 3267, loss = 0.00915628
Iteration 3268, loss = 0.00915256
Iteration 3269, loss = 0.00914975
Iteration 3270, loss = 0.00914620
Iteration 3271, loss = 0.00914246
Iteration 3272, loss = 0.00913825
Iteration 3273, loss = 0.00913513
Iteration 3274, loss = 0.00913092
Iteration 3275, loss = 0.00912631
Iteration 3276, loss = 0.00912243
Iteration 3277, loss = 0.00911996
Iteration 3278, loss = 0.00911523
Iteration 3279, loss = 0.00911114
Iteration 3280, loss = 0.00910716
Iteration 3281, loss = 0.00910397
Iteration 3282, loss = 0.00909908
Iteration 3283, loss = 0.00909664
Iteration 3284, loss = 0.00909173
Iteration 3285, loss = 0.00908775
Iteration 3286, loss = 0.00908328
Iteration 3287, loss = 0.00907949
Iteration 3288, loss = 0.00907609
Iteration 3289, loss = 0.00907184
Iteration 3290, loss = 0.00906802
Iteration 3291, loss = 0.00906441
Iteration 3292, loss = 0.00906063
Iteration 3293, loss = 0.00905699
Iteration 3294, loss = 0.00905431
Iteration 3295, loss = 0.00905025
Iteration 3296, loss = 0.00904727
Iteration 3297, loss = 0.00904256
Iteration 3298, loss = 0.00903865
Iteration 3299, loss = 0.00903553
Iteration 3300, loss = 0.00903188
Iteration 3301, loss = 0.00903029
Iteration 3302, loss = 0.00902549
Iteration 3303, loss = 0.00902178
Iteration 3304, loss = 0.00901860
Iteration 3305, loss = 0.00901580
Iteration 3306, loss = 0.00901157
Iteration 3307, loss = 0.00900778
Iteration 3308, loss = 0.00900426
Iteration 3309, loss = 0.00900073
Iteration 3310, loss = 0.00899744
Iteration 3311, loss = 0.00899316
Iteration 3312, loss = 0.00898947
Iteration 3313, loss = 0.00898560
Iteration 3314, loss = 0.00898224
Iteration 3315, loss = 0.00897907
Iteration 3316, loss = 0.00897474
Iteration 3317, loss = 0.00897100
Iteration 3318, loss = 0.00896789
Iteration 3319, loss = 0.00896418
Iteration 3320, loss = 0.00896068
Iteration 3321, loss = 0.00895677
Iteration 3322, loss = 0.00895379
Iteration 3323, loss = 0.00894956
Iteration 3324, loss = 0.00894650
Iteration 3325, loss = 0.00894315
Iteration 3326, loss = 0.00893971
Iteration 3327, loss = 0.00893607
Iteration 3328, loss = 0.00893295
Iteration 3329, loss = 0.00892953
Iteration 3330, loss = 0.00892594
Iteration 3331, loss = 0.00892219
Iteration 3332, loss = 0.00891896
Iteration 3333, loss = 0.00891561
Iteration 3334, loss = 0.00891193
Iteration 3335, loss = 0.00890863
Iteration 3336, loss = 0.00890560
Iteration 3337, loss = 0.00890205
Iteration 3338, loss = 0.00889902
Iteration 3339, loss = 0.00889744
Iteration 3340, loss = 0.00889255
Iteration 3341, loss = 0.00888893
Iteration 3342, loss = 0.00888595
Iteration 3343, loss = 0.00888221
Iteration 3344, loss = 0.00887967
Iteration 3345, loss = 0.00887599
Iteration 3346, loss = 0.00887284
Iteration 3347, loss = 0.00886865
Iteration 3348, loss = 0.00886576
Iteration 3349, loss = 0.00886195
Iteration 3350, loss = 0.00885870
Iteration 3351, loss = 0.00885525
Iteration 3352, loss = 0.00885157
Iteration 3353, loss = 0.00884837
Iteration 3354, loss = 0.00884516
Iteration 3355, loss = 0.00884171
Iteration 3356, loss = 0.00883843
Iteration 3357, loss = 0.00883530
Iteration 3358, loss = 0.00883141
Iteration 3359, loss = 0.00882732
Iteration 3360, loss = 0.00882491
Iteration 3361, loss = 0.00882064
Iteration 3362, loss = 0.00881749
Iteration 3363, loss = 0.00881370
Iteration 3364, loss = 0.00881049
Iteration 3365, loss = 0.00880654
Iteration 3366, loss = 0.00880269
Iteration 3367, loss = 0.00879880
Iteration 3368, loss = 0.00879543
Iteration 3369, loss = 0.00879147
Iteration 3370, loss = 0.00878842
Iteration 3371, loss = 0.00878431
Iteration 3372, loss = 0.00878219
Iteration 3373, loss = 0.00877835
Iteration 3374, loss = 0.00877451
Iteration 3375, loss = 0.00877170
Iteration 3376, loss = 0.00876785
Iteration 3377, loss = 0.00876549
Iteration 3378, loss = 0.00876167
Iteration 3379, loss = 0.00875843
Iteration 3380, loss = 0.00875524
Iteration 3381, loss = 0.00875229
Iteration 3382, loss = 0.00874892
Iteration 3383, loss = 0.00874578
Iteration 3384, loss = 0.00874223
Iteration 3385, loss = 0.00874041
Iteration 3386, loss = 0.00873637
Iteration 3387, loss = 0.00873338
Iteration 3388, loss = 0.00872985
Iteration 3389, loss = 0.00872705
Iteration 3390, loss = 0.00872388
Iteration 3391, loss = 0.00871999
Iteration 3392, loss = 0.00871695
Iteration 3393, loss = 0.00871334
Iteration 3394, loss = 0.00871004
Iteration 3395, loss = 0.00870658
Iteration 3396, loss = 0.00870342
Iteration 3397, loss = 0.00870114
Iteration 3398, loss = 0.00869720
Iteration 3399, loss = 0.00869400
Iteration 3400, loss = 0.00869015
Iteration 3401, loss = 0.00868684
Iteration 3402, loss = 0.00868252
Iteration 3403, loss = 0.00867976
Iteration 3404, loss = 0.00867588
Iteration 3405, loss = 0.00867242
Iteration 3406, loss = 0.00866924
Iteration 3407, loss = 0.00866510
Iteration 3408, loss = 0.00866173
Iteration 3409, loss = 0.00865825
Iteration 3410, loss = 0.00865495
Iteration 3411, loss = 0.00865171
Iteration 3412, loss = 0.00864818
Iteration 3413, loss = 0.00864439
Iteration 3414, loss = 0.00864183
Iteration 3415, loss = 0.00863838
Iteration 3416, loss = 0.00863495
Iteration 3417, loss = 0.00863229
Iteration 3418, loss = 0.00862825
Iteration 3419, loss = 0.00862503
Iteration 3420, loss = 0.00862188
Iteration 3421, loss = 0.00861862
Iteration 3422, loss = 0.00861538
Iteration 3423, loss = 0.00861241
Iteration 3424, loss = 0.00860885
Iteration 3425, loss = 0.00860539
Iteration 3426, loss = 0.00860230
Iteration 3427, loss = 0.00860016
Iteration 3428, loss = 0.00859629
Iteration 3429, loss = 0.00859304
Iteration 3430, loss = 0.00859156
Iteration 3431, loss = 0.00858768
Iteration 3432, loss = 0.00858457
Iteration 3433, loss = 0.00858118
Iteration 3434, loss = 0.00857780
Iteration 3435, loss = 0.00857506
Iteration 3436, loss = 0.00857161
Iteration 3437, loss = 0.00856704
Iteration 3438, loss = 0.00856378
Iteration 3439, loss = 0.00856048
Iteration 3440, loss = 0.00855685
Iteration 3441, loss = 0.00855388
Iteration 3442, loss = 0.00854970
Iteration 3443, loss = 0.00854647
Iteration 3444, loss = 0.00854363
Iteration 3445, loss = 0.00854029
Iteration 3446, loss = 0.00853632
Iteration 3447, loss = 0.00853284
Iteration 3448, loss = 0.00853030
Iteration 3449, loss = 0.00852621
Iteration 3450, loss = 0.00852268
Iteration 3451, loss = 0.00851921
Iteration 3452, loss = 0.00851616
Iteration 3453, loss = 0.00851300
Iteration 3454, loss = 0.00851001
Iteration 3455, loss = 0.00850673
Iteration 3456, loss = 0.00850363
Iteration 3457, loss = 0.00850274
Iteration 3458, loss = 0.00849734
Iteration 3459, loss = 0.00849359
Iteration 3460, loss = 0.00849062
Iteration 3461, loss = 0.00848680
Iteration 3462, loss = 0.00848332
Iteration 3463, loss = 0.00848013
Iteration 3464, loss = 0.00847625
Iteration 3465, loss = 0.00847363
Iteration 3466, loss = 0.00846972
Iteration 3467, loss = 0.00846692
Iteration 3468, loss = 0.00846349
Iteration 3469, loss = 0.00846043
Iteration 3470, loss = 0.00845833
Iteration 3471, loss = 0.00845484
Iteration 3472, loss = 0.00845088
Iteration 3473, loss = 0.00844763
Iteration 3474, loss = 0.00844405
Iteration 3475, loss = 0.00844101
Iteration 3476, loss = 0.00843813
Iteration 3477, loss = 0.00843536
Iteration 3478, loss = 0.00843206
Iteration 3479, loss = 0.00842942
Iteration 3480, loss = 0.00842603
Iteration 3481, loss = 0.00842322
Iteration 3482, loss = 0.00842164
Iteration 3483, loss = 0.00841953
Iteration 3484, loss = 0.00841567
Iteration 3485, loss = 0.00841273
Iteration 3486, loss = 0.00840975
Iteration 3487, loss = 0.00840697
Iteration 3488, loss = 0.00840416
Iteration 3489, loss = 0.00840115
Iteration 3490, loss = 0.00839821
Iteration 3491, loss = 0.00839562
Iteration 3492, loss = 0.00839305
Iteration 3493, loss = 0.00838968
Iteration 3494, loss = 0.00838636
Iteration 3495, loss = 0.00838281
Iteration 3496, loss = 0.00838101
Iteration 3497, loss = 0.00837661
Iteration 3498, loss = 0.00837391
Iteration 3499, loss = 0.00837126
Iteration 3500, loss = 0.00836716
Iteration 3501, loss = 0.00836338
Iteration 3502, loss = 0.00835939
Iteration 3503, loss = 0.00835638
Iteration 3504, loss = 0.00835265
Iteration 3505, loss = 0.00834974
Iteration 3506, loss = 0.00834588
Iteration 3507, loss = 0.00834263
Iteration 3508, loss = 0.00833956
Iteration 3509, loss = 0.00833548
Iteration 3510, loss = 0.00833308
Iteration 3511, loss = 0.00832920
Iteration 3512, loss = 0.00832564
Iteration 3513, loss = 0.00832273
Iteration 3514, loss = 0.00831909
Iteration 3515, loss = 0.00831596
Iteration 3516, loss = 0.00831274
Iteration 3517, loss = 0.00830991
Iteration 3518, loss = 0.00830663
Iteration 3519, loss = 0.00830373
Iteration 3520, loss = 0.00830064
Iteration 3521, loss = 0.00829763
Iteration 3522, loss = 0.00829484
Iteration 3523, loss = 0.00829173
Iteration 3524, loss = 0.00828937
Iteration 3525, loss = 0.00828594
Iteration 3526, loss = 0.00828379
Iteration 3527, loss = 0.00828138
Iteration 3528, loss = 0.00827853
Iteration 3529, loss = 0.00827479
Iteration 3530, loss = 0.00827273
Iteration 3531, loss = 0.00826831
Iteration 3532, loss = 0.00826659
Iteration 3533, loss = 0.00826277
Iteration 3534, loss = 0.00826004
Iteration 3535, loss = 0.00825713
Iteration 3536, loss = 0.00825392
Iteration 3537, loss = 0.00825129
Iteration 3538, loss = 0.00824862
Iteration 3539, loss = 0.00824546
Iteration 3540, loss = 0.00824204
Iteration 3541, loss = 0.00823904
Iteration 3542, loss = 0.00823642
Iteration 3543, loss = 0.00823346
Iteration 3544, loss = 0.00823033
Iteration 3545, loss = 0.00822700
Iteration 3546, loss = 0.00822399
Iteration 3547, loss = 0.00822075
Iteration 3548, loss = 0.00821816
Iteration 3549, loss = 0.00821521
Iteration 3550, loss = 0.00821246
Iteration 3551, loss = 0.00820984
Iteration 3552, loss = 0.00820631
Iteration 3553, loss = 0.00820347
Iteration 3554, loss = 0.00819977
Iteration 3555, loss = 0.00819597
Iteration 3556, loss = 0.00819229
Iteration 3557, loss = 0.00818948
Iteration 3558, loss = 0.00818637
Iteration 3559, loss = 0.00818288
Iteration 3560, loss = 0.00817987
Iteration 3561, loss = 0.00817656
Iteration 3562, loss = 0.00817378
Iteration 3563, loss = 0.00817006
Iteration 3564, loss = 0.00816687
Iteration 3565, loss = 0.00816335
Iteration 3566, loss = 0.00816014
Iteration 3567, loss = 0.00815712
Iteration 3568, loss = 0.00815401
Iteration 3569, loss = 0.00815054
Iteration 3570, loss = 0.00814677
Iteration 3571, loss = 0.00814420
Iteration 3572, loss = 0.00814048
Iteration 3573, loss = 0.00813713
Iteration 3574, loss = 0.00813492
Iteration 3575, loss = 0.00813142
Iteration 3576, loss = 0.00812837
Iteration 3577, loss = 0.00812496
Iteration 3578, loss = 0.00812197
Iteration 3579, loss = 0.00811901
Iteration 3580, loss = 0.00811625
Iteration 3581, loss = 0.00811363
Iteration 3582, loss = 0.00811066
Iteration 3583, loss = 0.00810753
Iteration 3584, loss = 0.00810457
Iteration 3585, loss = 0.00810204
Iteration 3586, loss = 0.00809967
Iteration 3587, loss = 0.00809726
Iteration 3588, loss = 0.00809356
Iteration 3589, loss = 0.00809109
Iteration 3590, loss = 0.00808943
Iteration 3591, loss = 0.00808699
Iteration 3592, loss = 0.00808327
Iteration 3593, loss = 0.00808058
Iteration 3594, loss = 0.00807810
Iteration 3595, loss = 0.00807441
Iteration 3596, loss = 0.00807123
Iteration 3597, loss = 0.00806941
Iteration 3598, loss = 0.00806579
Iteration 3599, loss = 0.00806261
Iteration 3600, loss = 0.00805982
Iteration 3601, loss = 0.00805716
Iteration 3602, loss = 0.00805412
Iteration 3603, loss = 0.00805150
Iteration 3604, loss = 0.00804879
Iteration 3605, loss = 0.00804578
Iteration 3606, loss = 0.00804388
Iteration 3607, loss = 0.00804039
Iteration 3608, loss = 0.00803779
Iteration 3609, loss = 0.00803428
Iteration 3610, loss = 0.00803135
Iteration 3611, loss = 0.00802809
Iteration 3612, loss = 0.00802523
Iteration 3613, loss = 0.00802306
Iteration 3614, loss = 0.00801992
Iteration 3615, loss = 0.00801730
Iteration 3616, loss = 0.00801493
Iteration 3617, loss = 0.00801108
Iteration 3618, loss = 0.00800776
Iteration 3619, loss = 0.00800481
Iteration 3620, loss = 0.00800131
Iteration 3621, loss = 0.00799782
Iteration 3622, loss = 0.00799509
Iteration 3623, loss = 0.00799205
Iteration 3624, loss = 0.00798869
Iteration 3625, loss = 0.00798560
Iteration 3626, loss = 0.00798293
Iteration 3627, loss = 0.00798018
Iteration 3628, loss = 0.00797761
Iteration 3629, loss = 0.00797469
Iteration 3630, loss = 0.00797195
Iteration 3631, loss = 0.00797052
Iteration 3632, loss = 0.00796655
Iteration 3633, loss = 0.00796401
Iteration 3634, loss = 0.00796119
Iteration 3635, loss = 0.00795858
Iteration 3636, loss = 0.00795612
Iteration 3637, loss = 0.00795282
Iteration 3638, loss = 0.00795030
Iteration 3639, loss = 0.00794700
Iteration 3640, loss = 0.00794445
Iteration 3641, loss = 0.00794137
Iteration 3642, loss = 0.00793844
Iteration 3643, loss = 0.00793556
Iteration 3644, loss = 0.00793270
Iteration 3645, loss = 0.00793017
Iteration 3646, loss = 0.00792683
Iteration 3647, loss = 0.00792401
Iteration 3648, loss = 0.00792146
Iteration 3649, loss = 0.00791870
Iteration 3650, loss = 0.00791585
Iteration 3651, loss = 0.00791305
Iteration 3652, loss = 0.00791003
Iteration 3653, loss = 0.00790811
Iteration 3654, loss = 0.00790429
Iteration 3655, loss = 0.00790024
Iteration 3656, loss = 0.00789920
Iteration 3657, loss = 0.00789382
Iteration 3658, loss = 0.00789092
Iteration 3659, loss = 0.00788796
Iteration 3660, loss = 0.00788485
Iteration 3661, loss = 0.00788215
Iteration 3662, loss = 0.00787904
Iteration 3663, loss = 0.00787610
Iteration 3664, loss = 0.00787306
Iteration 3665, loss = 0.00787012
Iteration 3666, loss = 0.00786769
Iteration 3667, loss = 0.00786469
Iteration 3668, loss = 0.00786136
Iteration 3669, loss = 0.00785829
Iteration 3670, loss = 0.00785550
Iteration 3671, loss = 0.00785306
Iteration 3672, loss = 0.00784976
Iteration 3673, loss = 0.00784680
Iteration 3674, loss = 0.00784426
Iteration 3675, loss = 0.00784171
Iteration 3676, loss = 0.00783961
Iteration 3677, loss = 0.00783690
Iteration 3678, loss = 0.00783482
Iteration 3679, loss = 0.00783154
Iteration 3680, loss = 0.00782927
Iteration 3681, loss = 0.00782694
Iteration 3682, loss = 0.00782383
Iteration 3683, loss = 0.00782145
Iteration 3684, loss = 0.00781842
Iteration 3685, loss = 0.00781639
Iteration 3686, loss = 0.00781318
Iteration 3687, loss = 0.00781062
Iteration 3688, loss = 0.00780779
Iteration 3689, loss = 0.00780476
Iteration 3690, loss = 0.00780257
Iteration 3691, loss = 0.00780088
Iteration 3692, loss = 0.00779811
Iteration 3693, loss = 0.00779505
Iteration 3694, loss = 0.00779273
Iteration 3695, loss = 0.00779026
Iteration 3696, loss = 0.00778714
Iteration 3697, loss = 0.00778407
Iteration 3698, loss = 0.00778047
Iteration 3699, loss = 0.00777827
Iteration 3700, loss = 0.00777466
Iteration 3701, loss = 0.00777220
Iteration 3702, loss = 0.00776915
Iteration 3703, loss = 0.00776578
Iteration 3704, loss = 0.00776257
Iteration 3705, loss = 0.00775923
Iteration 3706, loss = 0.00775620
Iteration 3707, loss = 0.00775293
Iteration 3708, loss = 0.00774987
Iteration 3709, loss = 0.00774662
Iteration 3710, loss = 0.00774359
Iteration 3711, loss = 0.00774192
Iteration 3712, loss = 0.00773892
Iteration 3713, loss = 0.00773597
Iteration 3714, loss = 0.00773323
Iteration 3715, loss = 0.00773035
Iteration 3716, loss = 0.00772795
Iteration 3717, loss = 0.00772404
Iteration 3718, loss = 0.00772149
Iteration 3719, loss = 0.00771836
Iteration 3720, loss = 0.00771552
Iteration 3721, loss = 0.00771282
Iteration 3722, loss = 0.00770910
Iteration 3723, loss = 0.00770623
Iteration 3724, loss = 0.00770305
Iteration 3725, loss = 0.00769961
Iteration 3726, loss = 0.00769677
Iteration 3727, loss = 0.00769325
Iteration 3728, loss = 0.00769083
Iteration 3729, loss = 0.00768813
Iteration 3730, loss = 0.00768510
Iteration 3731, loss = 0.00768189
Iteration 3732, loss = 0.00767958
Iteration 3733, loss = 0.00767665
Iteration 3734, loss = 0.00767426
Iteration 3735, loss = 0.00767091
Iteration 3736, loss = 0.00766885
Iteration 3737, loss = 0.00766546
Iteration 3738, loss = 0.00766302
Iteration 3739, loss = 0.00766018
Iteration 3740, loss = 0.00765751
Iteration 3741, loss = 0.00765455
Iteration 3742, loss = 0.00765146
Iteration 3743, loss = 0.00764940
Iteration 3744, loss = 0.00764561
Iteration 3745, loss = 0.00764283
Iteration 3746, loss = 0.00764007
Iteration 3747, loss = 0.00763735
Iteration 3748, loss = 0.00763460
Iteration 3749, loss = 0.00763220
Iteration 3750, loss = 0.00762884
Iteration 3751, loss = 0.00762587
Iteration 3752, loss = 0.00762403
Iteration 3753, loss = 0.00762051
Iteration 3754, loss = 0.00761809
Iteration 3755, loss = 0.00761532
Iteration 3756, loss = 0.00761279
Iteration 3757, loss = 0.00760914
Iteration 3758, loss = 0.00760636
Iteration 3759, loss = 0.00760349
Iteration 3760, loss = 0.00760130
Iteration 3761, loss = 0.00759772
Iteration 3762, loss = 0.00759502
Iteration 3763, loss = 0.00759225
Iteration 3764, loss = 0.00758948
Iteration 3765, loss = 0.00758678
Iteration 3766, loss = 0.00758414
Iteration 3767, loss = 0.00758074
Iteration 3768, loss = 0.00757793
Iteration 3769, loss = 0.00757499
Iteration 3770, loss = 0.00757259
Iteration 3771, loss = 0.00756960
Iteration 3772, loss = 0.00756670
Iteration 3773, loss = 0.00756342
Iteration 3774, loss = 0.00756088
Iteration 3775, loss = 0.00755821
Iteration 3776, loss = 0.00755518
Iteration 3777, loss = 0.00755237
Iteration 3778, loss = 0.00754916
Iteration 3779, loss = 0.00754739
Iteration 3780, loss = 0.00754416
Iteration 3781, loss = 0.00754241
Iteration 3782, loss = 0.00754020
Iteration 3783, loss = 0.00753684
Iteration 3784, loss = 0.00753485
Iteration 3785, loss = 0.00753255
Iteration 3786, loss = 0.00752994
Iteration 3787, loss = 0.00752685
Iteration 3788, loss = 0.00752372
Iteration 3789, loss = 0.00752130
Iteration 3790, loss = 0.00751863
Iteration 3791, loss = 0.00751565
Iteration 3792, loss = 0.00751304
Iteration 3793, loss = 0.00751072
Iteration 3794, loss = 0.00750774
Iteration 3795, loss = 0.00750546
Iteration 3796, loss = 0.00750247
Iteration 3797, loss = 0.00750011
Iteration 3798, loss = 0.00749744
Iteration 3799, loss = 0.00749510
Iteration 3800, loss = 0.00749272
Iteration 3801, loss = 0.00749042
Iteration 3802, loss = 0.00748803
Iteration 3803, loss = 0.00748564
Iteration 3804, loss = 0.00748351
Iteration 3805, loss = 0.00748141
Iteration 3806, loss = 0.00747778
Iteration 3807, loss = 0.00747535
Iteration 3808, loss = 0.00747296
Iteration 3809, loss = 0.00747030
Iteration 3810, loss = 0.00746755
Iteration 3811, loss = 0.00746507
Iteration 3812, loss = 0.00746227
Iteration 3813, loss = 0.00745983
Iteration 3814, loss = 0.00745744
Iteration 3815, loss = 0.00745434
Iteration 3816, loss = 0.00745291
Iteration 3817, loss = 0.00744925
Iteration 3818, loss = 0.00744624
Iteration 3819, loss = 0.00744337
Iteration 3820, loss = 0.00744056
Iteration 3821, loss = 0.00743728
Iteration 3822, loss = 0.00743555
Iteration 3823, loss = 0.00743217
Iteration 3824, loss = 0.00742960
Iteration 3825, loss = 0.00742684
Iteration 3826, loss = 0.00742450
Iteration 3827, loss = 0.00742187
Iteration 3828, loss = 0.00741917
Iteration 3829, loss = 0.00741631
Iteration 3830, loss = 0.00741390
Iteration 3831, loss = 0.00741091
Iteration 3832, loss = 0.00740850
Iteration 3833, loss = 0.00740552
Iteration 3834, loss = 0.00740321
Iteration 3835, loss = 0.00740034
Iteration 3836, loss = 0.00739806
Iteration 3837, loss = 0.00739684
Iteration 3838, loss = 0.00739291
Iteration 3839, loss = 0.00739007
Iteration 3840, loss = 0.00738776
Iteration 3841, loss = 0.00738511
Iteration 3842, loss = 0.00738308
Iteration 3843, loss = 0.00737957
Iteration 3844, loss = 0.00737647
Iteration 3845, loss = 0.00737422
Iteration 3846, loss = 0.00737097
Iteration 3847, loss = 0.00736925
Iteration 3848, loss = 0.00736569
Iteration 3849, loss = 0.00736333
Iteration 3850, loss = 0.00736024
Iteration 3851, loss = 0.00735803
Iteration 3852, loss = 0.00735533
Iteration 3853, loss = 0.00735282
Iteration 3854, loss = 0.00735013
Iteration 3855, loss = 0.00734737
Iteration 3856, loss = 0.00734487
Iteration 3857, loss = 0.00734265
Iteration 3858, loss = 0.00734039
Iteration 3859, loss = 0.00733799
Iteration 3860, loss = 0.00733538
Iteration 3861, loss = 0.00733250
Iteration 3862, loss = 0.00733098
Iteration 3863, loss = 0.00732817
Iteration 3864, loss = 0.00732544
Iteration 3865, loss = 0.00732285
Iteration 3866, loss = 0.00732079
Iteration 3867, loss = 0.00731854
Iteration 3868, loss = 0.00731517
Iteration 3869, loss = 0.00731278
Iteration 3870, loss = 0.00730973
Iteration 3871, loss = 0.00730758
Iteration 3872, loss = 0.00730448
Iteration 3873, loss = 0.00730231
Iteration 3874, loss = 0.00729974
Iteration 3875, loss = 0.00729683
Iteration 3876, loss = 0.00729456
Iteration 3877, loss = 0.00729182
Iteration 3878, loss = 0.00728907
Iteration 3879, loss = 0.00728647
Iteration 3880, loss = 0.00728408
Iteration 3881, loss = 0.00728113
Iteration 3882, loss = 0.00727863
Iteration 3883, loss = 0.00727594
Iteration 3884, loss = 0.00727335
Iteration 3885, loss = 0.00727057
Iteration 3886, loss = 0.00726810
Iteration 3887, loss = 0.00726571
Iteration 3888, loss = 0.00726308
Iteration 3889, loss = 0.00726044
Iteration 3890, loss = 0.00725887
Iteration 3891, loss = 0.00725570
Iteration 3892, loss = 0.00725313
Iteration 3893, loss = 0.00725066
Iteration 3894, loss = 0.00724855
Iteration 3895, loss = 0.00724562
Iteration 3896, loss = 0.00724348
Iteration 3897, loss = 0.00724037
Iteration 3898, loss = 0.00723799
Iteration 3899, loss = 0.00723551
Iteration 3900, loss = 0.00723298
Iteration 3901, loss = 0.00723071
Iteration 3902, loss = 0.00722838
Iteration 3903, loss = 0.00722545
Iteration 3904, loss = 0.00722321
Iteration 3905, loss = 0.00722045
Iteration 3906, loss = 0.00721792
Iteration 3907, loss = 0.00721548
Iteration 3908, loss = 0.00721305
Iteration 3909, loss = 0.00721039
Iteration 3910, loss = 0.00720830
Iteration 3911, loss = 0.00720612
Iteration 3912, loss = 0.00720304
Iteration 3913, loss = 0.00720060
Iteration 3914, loss = 0.00719822
Iteration 3915, loss = 0.00719563
Iteration 3916, loss = 0.00719334
Iteration 3917, loss = 0.00719050
Iteration 3918, loss = 0.00718838
Iteration 3919, loss = 0.00718589
Iteration 3920, loss = 0.00718337
Iteration 3921, loss = 0.00718157
Iteration 3922, loss = 0.00717871
Iteration 3923, loss = 0.00717646
Iteration 3924, loss = 0.00717406
Iteration 3925, loss = 0.00717156
Iteration 3926, loss = 0.00716936
Iteration 3927, loss = 0.00716681
Iteration 3928, loss = 0.00716482
Iteration 3929, loss = 0.00716212
Iteration 3930, loss = 0.00715923
Iteration 3931, loss = 0.00715690
Iteration 3932, loss = 0.00715447
Iteration 3933, loss = 0.00715158
Iteration 3934, loss = 0.00714927
Iteration 3935, loss = 0.00714668
Iteration 3936, loss = 0.00714437
Iteration 3937, loss = 0.00714175
Iteration 3938, loss = 0.00713884
Iteration 3939, loss = 0.00713711
Iteration 3940, loss = 0.00713381
Iteration 3941, loss = 0.00713170
Iteration 3942, loss = 0.00712902
Iteration 3943, loss = 0.00712640
Iteration 3944, loss = 0.00712380
Iteration 3945, loss = 0.00712141
Iteration 3946, loss = 0.00711912
Iteration 3947, loss = 0.00711725
Iteration 3948, loss = 0.00711508
Iteration 3949, loss = 0.00711199
Iteration 3950, loss = 0.00710987
Iteration 3951, loss = 0.00710733
Iteration 3952, loss = 0.00710501
Iteration 3953, loss = 0.00710295
Iteration 3954, loss = 0.00710082
Iteration 3955, loss = 0.00709832
Iteration 3956, loss = 0.00709609
Iteration 3957, loss = 0.00709428
Iteration 3958, loss = 0.00709211
Iteration 3959, loss = 0.00709002
Iteration 3960, loss = 0.00708750
Iteration 3961, loss = 0.00708489
Iteration 3962, loss = 0.00708244
Iteration 3963, loss = 0.00708019
Iteration 3964, loss = 0.00707766
Iteration 3965, loss = 0.00707446
Iteration 3966, loss = 0.00707263
Iteration 3967, loss = 0.00706944
Iteration 3968, loss = 0.00706703
Iteration 3969, loss = 0.00706437
Iteration 3970, loss = 0.00706187
Iteration 3971, loss = 0.00705966
Iteration 3972, loss = 0.00705686
Iteration 3973, loss = 0.00705436
Iteration 3974, loss = 0.00705250
Iteration 3975, loss = 0.00704936
Iteration 3976, loss = 0.00704770
Iteration 3977, loss = 0.00704482
Iteration 3978, loss = 0.00704294
Iteration 3979, loss = 0.00704013
Iteration 3980, loss = 0.00703788
Iteration 3981, loss = 0.00703587
Iteration 3982, loss = 0.00703313
Iteration 3983, loss = 0.00703081
Iteration 3984, loss = 0.00702992
Iteration 3985, loss = 0.00702633
Iteration 3986, loss = 0.00702385
Iteration 3987, loss = 0.00702153
Iteration 3988, loss = 0.00701920
Iteration 3989, loss = 0.00701666
Iteration 3990, loss = 0.00701429
Iteration 3991, loss = 0.00701203
Iteration 3992, loss = 0.00700920
Iteration 3993, loss = 0.00700694
Iteration 3994, loss = 0.00700481
Iteration 3995, loss = 0.00700251
Iteration 3996, loss = 0.00700052
Iteration 3997, loss = 0.00699886
Iteration 3998, loss = 0.00699640
Iteration 3999, loss = 0.00699413
Iteration 4000, loss = 0.00699188
Iteration 4001, loss = 0.00698972
Iteration 4002, loss = 0.00698777
Iteration 4003, loss = 0.00698535
Iteration 4004, loss = 0.00698310
Iteration 4005, loss = 0.00698093
Iteration 4006, loss = 0.00697850
Iteration 4007, loss = 0.00697615
Iteration 4008, loss = 0.00697398
Iteration 4009, loss = 0.00697143
Iteration 4010, loss = 0.00696887
Iteration 4011, loss = 0.00696630
Iteration 4012, loss = 0.00696508
Iteration 4013, loss = 0.00696198
Iteration 4014, loss = 0.00696020
Iteration 4015, loss = 0.00695743
Iteration 4016, loss = 0.00695542
Iteration 4017, loss = 0.00695331
Iteration 4018, loss = 0.00695055
Iteration 4019, loss = 0.00694805
Iteration 4020, loss = 0.00694567
Iteration 4021, loss = 0.00694359
Iteration 4022, loss = 0.00694136
Iteration 4023, loss = 0.00693896
Iteration 4024, loss = 0.00693656
Iteration 4025, loss = 0.00693562
Iteration 4026, loss = 0.00693233
Iteration 4027, loss = 0.00693077
Iteration 4028, loss = 0.00692795
Iteration 4029, loss = 0.00692591
Iteration 4030, loss = 0.00692368
Iteration 4031, loss = 0.00692175
Iteration 4032, loss = 0.00691952
Iteration 4033, loss = 0.00691729
Iteration 4034, loss = 0.00691621
Iteration 4035, loss = 0.00691337
Iteration 4036, loss = 0.00691206
Iteration 4037, loss = 0.00690913
Iteration 4038, loss = 0.00690687
Iteration 4039, loss = 0.00690410
Iteration 4040, loss = 0.00690130
Iteration 4041, loss = 0.00689932
Iteration 4042, loss = 0.00689634
Iteration 4043, loss = 0.00689410
Iteration 4044, loss = 0.00689163
Iteration 4045, loss = 0.00688907
Iteration 4046, loss = 0.00688681
Iteration 4047, loss = 0.00688433
Iteration 4048, loss = 0.00688252
Iteration 4049, loss = 0.00687989
Iteration 4050, loss = 0.00687770
Iteration 4051, loss = 0.00687542
Iteration 4052, loss = 0.00687340
Iteration 4053, loss = 0.00687110
Iteration 4054, loss = 0.00686867
Iteration 4055, loss = 0.00686714
Iteration 4056, loss = 0.00686404
Iteration 4057, loss = 0.00686224
Iteration 4058, loss = 0.00685939
Iteration 4059, loss = 0.00685749
Iteration 4060, loss = 0.00685477
Iteration 4061, loss = 0.00685285
Iteration 4062, loss = 0.00685053
Iteration 4063, loss = 0.00684796
Iteration 4064, loss = 0.00684547
Iteration 4065, loss = 0.00684304
Iteration 4066, loss = 0.00684079
Iteration 4067, loss = 0.00683873
Iteration 4068, loss = 0.00683714
Iteration 4069, loss = 0.00683436
Iteration 4070, loss = 0.00683251
Iteration 4071, loss = 0.00683015
Iteration 4072, loss = 0.00682795
Iteration 4073, loss = 0.00682639
Iteration 4074, loss = 0.00682417
Iteration 4075, loss = 0.00682186
Iteration 4076, loss = 0.00681880
Iteration 4077, loss = 0.00681596
Iteration 4078, loss = 0.00681363
Iteration 4079, loss = 0.00681129
Iteration 4080, loss = 0.00680866
Iteration 4081, loss = 0.00680641
Iteration 4082, loss = 0.00680377
Iteration 4083, loss = 0.00680093
Iteration 4084, loss = 0.00679899
Iteration 4085, loss = 0.00679577
Iteration 4086, loss = 0.00679399
Iteration 4087, loss = 0.00679119
Iteration 4088, loss = 0.00678913
Iteration 4089, loss = 0.00678695
Iteration 4090, loss = 0.00678458
Iteration 4091, loss = 0.00678233
Iteration 4092, loss = 0.00678030
Iteration 4093, loss = 0.00677821
Iteration 4094, loss = 0.00677613
Iteration 4095, loss = 0.00677416
Iteration 4096, loss = 0.00677211
Iteration 4097, loss = 0.00677172
Iteration 4098, loss = 0.00676903
Iteration 4099, loss = 0.00676649
Iteration 4100, loss = 0.00676451
Iteration 4101, loss = 0.00676252
Iteration 4102, loss = 0.00676030
Iteration 4103, loss = 0.00675831
Iteration 4104, loss = 0.00675624
Iteration 4105, loss = 0.00675424
Iteration 4106, loss = 0.00675314
Iteration 4107, loss = 0.00675011
Iteration 4108, loss = 0.00674778
Iteration 4109, loss = 0.00674565
Iteration 4110, loss = 0.00674320
Iteration 4111, loss = 0.00674059
Iteration 4112, loss = 0.00673840
Iteration 4113, loss = 0.00673689
Iteration 4114, loss = 0.00673401
Iteration 4115, loss = 0.00673178
Iteration 4116, loss = 0.00672873
Iteration 4117, loss = 0.00672630
Iteration 4118, loss = 0.00672504
Iteration 4119, loss = 0.00672176
Iteration 4120, loss = 0.00671898
Iteration 4121, loss = 0.00671667
Iteration 4122, loss = 0.00671433
Iteration 4123, loss = 0.00671268
Iteration 4124, loss = 0.00671003
Iteration 4125, loss = 0.00670753
Iteration 4126, loss = 0.00670537
Iteration 4127, loss = 0.00670286
Iteration 4128, loss = 0.00670044
Iteration 4129, loss = 0.00669822
Iteration 4130, loss = 0.00669580
Iteration 4131, loss = 0.00669371
Iteration 4132, loss = 0.00669129
Iteration 4133, loss = 0.00668978
Iteration 4134, loss = 0.00668719
Iteration 4135, loss = 0.00668551
Iteration 4136, loss = 0.00668378
Iteration 4137, loss = 0.00668143
Iteration 4138, loss = 0.00667929
Iteration 4139, loss = 0.00667731
Iteration 4140, loss = 0.00667496
Iteration 4141, loss = 0.00667308
Iteration 4142, loss = 0.00667062
Iteration 4143, loss = 0.00666831
Iteration 4144, loss = 0.00666594
Iteration 4145, loss = 0.00666340
Iteration 4146, loss = 0.00666096
Iteration 4147, loss = 0.00665833
Iteration 4148, loss = 0.00665621
Iteration 4149, loss = 0.00665402
Iteration 4150, loss = 0.00665191
Iteration 4151, loss = 0.00664960
Iteration 4152, loss = 0.00664724
Iteration 4153, loss = 0.00664511
Iteration 4154, loss = 0.00664290
Iteration 4155, loss = 0.00664079
Iteration 4156, loss = 0.00663861
Iteration 4157, loss = 0.00663669
Iteration 4158, loss = 0.00663452
Iteration 4159, loss = 0.00663272
Iteration 4160, loss = 0.00663066
Iteration 4161, loss = 0.00662877
Iteration 4162, loss = 0.00662658
Iteration 4163, loss = 0.00662473
Iteration 4164, loss = 0.00662279
Iteration 4165, loss = 0.00662126
Iteration 4166, loss = 0.00661874
Iteration 4167, loss = 0.00661703
Iteration 4168, loss = 0.00661483
Iteration 4169, loss = 0.00661312
Iteration 4170, loss = 0.00661089
Iteration 4171, loss = 0.00660896
Iteration 4172, loss = 0.00660751
Iteration 4173, loss = 0.00660551
Iteration 4174, loss = 0.00660283
Iteration 4175, loss = 0.00660059
Iteration 4176, loss = 0.00659810
Iteration 4177, loss = 0.00659547
Iteration 4178, loss = 0.00659410
Iteration 4179, loss = 0.00659139
Iteration 4180, loss = 0.00658948
Iteration 4181, loss = 0.00658703
Iteration 4182, loss = 0.00658480
Iteration 4183, loss = 0.00658297
Iteration 4184, loss = 0.00658053
Iteration 4185, loss = 0.00657837
Iteration 4186, loss = 0.00657604
Iteration 4187, loss = 0.00657386
Iteration 4188, loss = 0.00657156
Iteration 4189, loss = 0.00656921
Iteration 4190, loss = 0.00656719
Iteration 4191, loss = 0.00656549
Iteration 4192, loss = 0.00656324
Iteration 4193, loss = 0.00656167
Iteration 4194, loss = 0.00655929
Iteration 4195, loss = 0.00655778
Iteration 4196, loss = 0.00655560
Iteration 4197, loss = 0.00655281
Iteration 4198, loss = 0.00655106
Iteration 4199, loss = 0.00654834
Iteration 4200, loss = 0.00654624
Iteration 4201, loss = 0.00654390
Iteration 4202, loss = 0.00654192
Iteration 4203, loss = 0.00653966
Iteration 4204, loss = 0.00653772
Iteration 4205, loss = 0.00653558
Iteration 4206, loss = 0.00653334
Iteration 4207, loss = 0.00653140
Iteration 4208, loss = 0.00652962
Iteration 4209, loss = 0.00652785
Iteration 4210, loss = 0.00652593
Iteration 4211, loss = 0.00652464
Iteration 4212, loss = 0.00652269
Iteration 4213, loss = 0.00652045
Iteration 4214, loss = 0.00651857
Iteration 4215, loss = 0.00651632
Iteration 4216, loss = 0.00651383
Iteration 4217, loss = 0.00651158
Iteration 4218, loss = 0.00650913
Iteration 4219, loss = 0.00650796
Iteration 4220, loss = 0.00650509
Iteration 4221, loss = 0.00650408
Iteration 4222, loss = 0.00650185
Iteration 4223, loss = 0.00649962
Iteration 4224, loss = 0.00649751
Iteration 4225, loss = 0.00649531
Iteration 4226, loss = 0.00649301
Iteration 4227, loss = 0.00649258
Iteration 4228, loss = 0.00648951
Iteration 4229, loss = 0.00648710
Iteration 4230, loss = 0.00648531
Iteration 4231, loss = 0.00648372
Iteration 4232, loss = 0.00648113
Iteration 4233, loss = 0.00647898
Iteration 4234, loss = 0.00647727
Iteration 4235, loss = 0.00647518
Iteration 4236, loss = 0.00647319
Iteration 4237, loss = 0.00647140
Iteration 4238, loss = 0.00646918
Iteration 4239, loss = 0.00646722
Iteration 4240, loss = 0.00646509
Iteration 4241, loss = 0.00646321
Iteration 4242, loss = 0.00646150
Iteration 4243, loss = 0.00645915
Iteration 4244, loss = 0.00645724
Iteration 4245, loss = 0.00645503
Iteration 4246, loss = 0.00645294
Iteration 4247, loss = 0.00645153
Iteration 4248, loss = 0.00644894
Iteration 4249, loss = 0.00644817
Iteration 4250, loss = 0.00644473
Iteration 4251, loss = 0.00644258
Iteration 4252, loss = 0.00644022
Iteration 4253, loss = 0.00643834
Iteration 4254, loss = 0.00643586
Iteration 4255, loss = 0.00643349
Iteration 4256, loss = 0.00643099
Iteration 4257, loss = 0.00642923
Iteration 4258, loss = 0.00642670
Iteration 4259, loss = 0.00642462
Iteration 4260, loss = 0.00642237
Iteration 4261, loss = 0.00642012
Iteration 4262, loss = 0.00641862
Iteration 4263, loss = 0.00641591
Iteration 4264, loss = 0.00641383
Iteration 4265, loss = 0.00641164
Iteration 4266, loss = 0.00640960
Iteration 4267, loss = 0.00640770
Iteration 4268, loss = 0.00640539
Iteration 4269, loss = 0.00640320
Iteration 4270, loss = 0.00640099
Iteration 4271, loss = 0.00639891
Iteration 4272, loss = 0.00639661
Iteration 4273, loss = 0.00639473
Iteration 4274, loss = 0.00639259
Iteration 4275, loss = 0.00639042
Iteration 4276, loss = 0.00638891
Iteration 4277, loss = 0.00638633
Iteration 4278, loss = 0.00638411
Iteration 4279, loss = 0.00638204
Iteration 4280, loss = 0.00637998
Iteration 4281, loss = 0.00637800
Iteration 4282, loss = 0.00637588
Iteration 4283, loss = 0.00637389
Iteration 4284, loss = 0.00637228
Iteration 4285, loss = 0.00637022
Iteration 4286, loss = 0.00636850
Iteration 4287, loss = 0.00636648
Iteration 4288, loss = 0.00636468
Iteration 4289, loss = 0.00636286
Iteration 4290, loss = 0.00636084
Iteration 4291, loss = 0.00635878
Iteration 4292, loss = 0.00635739
Iteration 4293, loss = 0.00635527
Iteration 4294, loss = 0.00635379
Iteration 4295, loss = 0.00635194
Iteration 4296, loss = 0.00635023
Iteration 4297, loss = 0.00634815
Iteration 4298, loss = 0.00634603
Iteration 4299, loss = 0.00634455
Iteration 4300, loss = 0.00634239
Iteration 4301, loss = 0.00634016
Iteration 4302, loss = 0.00633830
Iteration 4303, loss = 0.00633635
Iteration 4304, loss = 0.00633452
Iteration 4305, loss = 0.00633266
Iteration 4306, loss = 0.00633105
Iteration 4307, loss = 0.00632909
Iteration 4308, loss = 0.00632776
Iteration 4309, loss = 0.00632591
Iteration 4310, loss = 0.00632416
Iteration 4311, loss = 0.00632220
Iteration 4312, loss = 0.00631996
Iteration 4313, loss = 0.00631775
Iteration 4314, loss = 0.00631554
Iteration 4315, loss = 0.00631370
Iteration 4316, loss = 0.00631169
Iteration 4317, loss = 0.00630946
Iteration 4318, loss = 0.00630732
Iteration 4319, loss = 0.00630529
Iteration 4320, loss = 0.00630357
Iteration 4321, loss = 0.00630156
Iteration 4322, loss = 0.00629960
Iteration 4323, loss = 0.00629778
Iteration 4324, loss = 0.00629604
Iteration 4325, loss = 0.00629428
Iteration 4326, loss = 0.00629248
Iteration 4327, loss = 0.00629071
Iteration 4328, loss = 0.00628905
Iteration 4329, loss = 0.00628711
Iteration 4330, loss = 0.00628543
Iteration 4331, loss = 0.00628337
Iteration 4332, loss = 0.00628227
Iteration 4333, loss = 0.00627924
Iteration 4334, loss = 0.00627703
Iteration 4335, loss = 0.00627560
Iteration 4336, loss = 0.00627314
Iteration 4337, loss = 0.00627105
Iteration 4338, loss = 0.00626924
Iteration 4339, loss = 0.00626718
Iteration 4340, loss = 0.00626526
Iteration 4341, loss = 0.00626271
Iteration 4342, loss = 0.00626119
Iteration 4343, loss = 0.00625843
Iteration 4344, loss = 0.00625685
Iteration 4345, loss = 0.00625516
Iteration 4346, loss = 0.00625277
Iteration 4347, loss = 0.00624998
Iteration 4348, loss = 0.00624760
Iteration 4349, loss = 0.00624598
Iteration 4350, loss = 0.00624379
Iteration 4351, loss = 0.00624140
Iteration 4352, loss = 0.00623924
Iteration 4353, loss = 0.00623791
Iteration 4354, loss = 0.00623548
Iteration 4355, loss = 0.00623378
Iteration 4356, loss = 0.00623192
Iteration 4357, loss = 0.00623004
Iteration 4358, loss = 0.00622819
Iteration 4359, loss = 0.00622629
Iteration 4360, loss = 0.00622429
Iteration 4361, loss = 0.00622261
Iteration 4362, loss = 0.00622051
Iteration 4363, loss = 0.00621874
Iteration 4364, loss = 0.00621666
Iteration 4365, loss = 0.00621489
Iteration 4366, loss = 0.00621314
Iteration 4367, loss = 0.00621098
Iteration 4368, loss = 0.00620949
Iteration 4369, loss = 0.00620742
Iteration 4370, loss = 0.00620531
Iteration 4371, loss = 0.00620338
Iteration 4372, loss = 0.00620122
Iteration 4373, loss = 0.00620053
Iteration 4374, loss = 0.00619811
Iteration 4375, loss = 0.00619605
Iteration 4376, loss = 0.00619463
Iteration 4377, loss = 0.00619252
Iteration 4378, loss = 0.00619031
Iteration 4379, loss = 0.00618858
Iteration 4380, loss = 0.00618668
Iteration 4381, loss = 0.00618487
Iteration 4382, loss = 0.00618306
Iteration 4383, loss = 0.00618120
Iteration 4384, loss = 0.00617966
Iteration 4385, loss = 0.00617788
Iteration 4386, loss = 0.00617581
Iteration 4387, loss = 0.00617402
Iteration 4388, loss = 0.00617212
Iteration 4389, loss = 0.00617009
Iteration 4390, loss = 0.00616950
Iteration 4391, loss = 0.00616635
Iteration 4392, loss = 0.00616433
Iteration 4393, loss = 0.00616207
Iteration 4394, loss = 0.00616047
Iteration 4395, loss = 0.00615820
Iteration 4396, loss = 0.00615636
Iteration 4397, loss = 0.00615431
Iteration 4398, loss = 0.00615222
Iteration 4399, loss = 0.00615057
Iteration 4400, loss = 0.00614872
Iteration 4401, loss = 0.00614651
Iteration 4402, loss = 0.00614487
Iteration 4403, loss = 0.00614257
Iteration 4404, loss = 0.00614064
Iteration 4405, loss = 0.00613863
Iteration 4406, loss = 0.00613657
Iteration 4407, loss = 0.00613486
Iteration 4408, loss = 0.00613256
Iteration 4409, loss = 0.00613056
Iteration 4410, loss = 0.00612864
Iteration 4411, loss = 0.00612658
Iteration 4412, loss = 0.00612488
Iteration 4413, loss = 0.00612352
Iteration 4414, loss = 0.00612148
Iteration 4415, loss = 0.00611973
Iteration 4416, loss = 0.00611817
Iteration 4417, loss = 0.00611626
Iteration 4418, loss = 0.00611446
Iteration 4419, loss = 0.00611268
Iteration 4420, loss = 0.00611092
Iteration 4421, loss = 0.00610905
Iteration 4422, loss = 0.00610742
Iteration 4423, loss = 0.00610588
Iteration 4424, loss = 0.00610337
Iteration 4425, loss = 0.00610166
Iteration 4426, loss = 0.00610034
Iteration 4427, loss = 0.00609803
Iteration 4428, loss = 0.00609600
Iteration 4429, loss = 0.00609424
Iteration 4430, loss = 0.00609211
Iteration 4431, loss = 0.00609013
Iteration 4432, loss = 0.00608834
Iteration 4433, loss = 0.00608631
Iteration 4434, loss = 0.00608444
Iteration 4435, loss = 0.00608282
Iteration 4436, loss = 0.00608128
Iteration 4437, loss = 0.00607924
Iteration 4438, loss = 0.00607713
Iteration 4439, loss = 0.00607545
Iteration 4440, loss = 0.00607374
Iteration 4441, loss = 0.00607157
Iteration 4442, loss = 0.00606963
Iteration 4443, loss = 0.00606821
Iteration 4444, loss = 0.00606644
Iteration 4445, loss = 0.00606439
Iteration 4446, loss = 0.00606293
Iteration 4447, loss = 0.00606080
Iteration 4448, loss = 0.00605923
Iteration 4449, loss = 0.00605742
Iteration 4450, loss = 0.00605557
Iteration 4451, loss = 0.00605390
Iteration 4452, loss = 0.00605208
Iteration 4453, loss = 0.00605035
Iteration 4454, loss = 0.00604842
Iteration 4455, loss = 0.00604659
Iteration 4456, loss = 0.00604471
Iteration 4457, loss = 0.00604292
Iteration 4458, loss = 0.00604127
Iteration 4459, loss = 0.00603951
Iteration 4460, loss = 0.00603728
Iteration 4461, loss = 0.00603539
Iteration 4462, loss = 0.00603340
Iteration 4463, loss = 0.00603147
Iteration 4464, loss = 0.00602944
Iteration 4465, loss = 0.00602846
Iteration 4466, loss = 0.00602641
Iteration 4467, loss = 0.00602458
Iteration 4468, loss = 0.00602266
Iteration 4469, loss = 0.00602123
Iteration 4470, loss = 0.00601937
Iteration 4471, loss = 0.00601756
Iteration 4472, loss = 0.00601551
Iteration 4473, loss = 0.00601369
Iteration 4474, loss = 0.00601197
Iteration 4475, loss = 0.00601032
Iteration 4476, loss = 0.00600829
Iteration 4477, loss = 0.00600679
Iteration 4478, loss = 0.00600532
Iteration 4479, loss = 0.00600336
Iteration 4480, loss = 0.00600185
Iteration 4481, loss = 0.00599985
Iteration 4482, loss = 0.00599811
Iteration 4483, loss = 0.00599646
Iteration 4484, loss = 0.00599459
Iteration 4485, loss = 0.00599285
Iteration 4486, loss = 0.00599162
Iteration 4487, loss = 0.00598930
Iteration 4488, loss = 0.00598771
Iteration 4489, loss = 0.00598548
Iteration 4490, loss = 0.00598417
Iteration 4491, loss = 0.00598165
Iteration 4492, loss = 0.00598032
Iteration 4493, loss = 0.00597815
Iteration 4494, loss = 0.00597652
Iteration 4495, loss = 0.00597470
Iteration 4496, loss = 0.00597280
Iteration 4497, loss = 0.00597123
Iteration 4498, loss = 0.00596952
Iteration 4499, loss = 0.00596757
Iteration 4500, loss = 0.00596637
Iteration 4501, loss = 0.00596426
Iteration 4502, loss = 0.00596187
Iteration 4503, loss = 0.00596033
Iteration 4504, loss = 0.00595772
Iteration 4505, loss = 0.00595564
Iteration 4506, loss = 0.00595357
Iteration 4507, loss = 0.00595190
Iteration 4508, loss = 0.00594971
Iteration 4509, loss = 0.00594777
Iteration 4510, loss = 0.00594518
Iteration 4511, loss = 0.00594344
Iteration 4512, loss = 0.00594102
Iteration 4513, loss = 0.00593943
Iteration 4514, loss = 0.00593819
Iteration 4515, loss = 0.00593658
Iteration 4516, loss = 0.00593476
Iteration 4517, loss = 0.00593302
Iteration 4518, loss = 0.00593100
Iteration 4519, loss = 0.00592938
Iteration 4520, loss = 0.00592801
Iteration 4521, loss = 0.00592594
Iteration 4522, loss = 0.00592417
Iteration 4523, loss = 0.00592218
Iteration 4524, loss = 0.00592012
Iteration 4525, loss = 0.00591810
Iteration 4526, loss = 0.00591711
Iteration 4527, loss = 0.00591453
Iteration 4528, loss = 0.00591276
Iteration 4529, loss = 0.00591075
Iteration 4530, loss = 0.00590870
Iteration 4531, loss = 0.00590683
Iteration 4532, loss = 0.00590489
Iteration 4533, loss = 0.00590299
Iteration 4534, loss = 0.00590091
Iteration 4535, loss = 0.00589854
Iteration 4536, loss = 0.00589650
Iteration 4537, loss = 0.00589524
Iteration 4538, loss = 0.00589278
Iteration 4539, loss = 0.00589069
Iteration 4540, loss = 0.00588872
Iteration 4541, loss = 0.00588751
Iteration 4542, loss = 0.00588515
Iteration 4543, loss = 0.00588325
Iteration 4544, loss = 0.00588145
Iteration 4545, loss = 0.00587957
Iteration 4546, loss = 0.00587785
Iteration 4547, loss = 0.00587608
Iteration 4548, loss = 0.00587416
Iteration 4549, loss = 0.00587223
Iteration 4550, loss = 0.00587038
Iteration 4551, loss = 0.00586890
Iteration 4552, loss = 0.00586661
Iteration 4553, loss = 0.00586501
Iteration 4554, loss = 0.00586306
Iteration 4555, loss = 0.00586123
Iteration 4556, loss = 0.00585954
Iteration 4557, loss = 0.00585800
Iteration 4558, loss = 0.00585606
Iteration 4559, loss = 0.00585445
Iteration 4560, loss = 0.00585253
Iteration 4561, loss = 0.00585077
Iteration 4562, loss = 0.00584893
Iteration 4563, loss = 0.00584718
Iteration 4564, loss = 0.00584581
Iteration 4565, loss = 0.00584375
Iteration 4566, loss = 0.00584244
Iteration 4567, loss = 0.00584068
Iteration 4568, loss = 0.00583866
Iteration 4569, loss = 0.00583762
Iteration 4570, loss = 0.00583527
Iteration 4571, loss = 0.00583344
Iteration 4572, loss = 0.00583186
Iteration 4573, loss = 0.00582975
Iteration 4574, loss = 0.00582782
Iteration 4575, loss = 0.00582604
Iteration 4576, loss = 0.00582400
Iteration 4577, loss = 0.00582212
Iteration 4578, loss = 0.00582107
Iteration 4579, loss = 0.00581939
Iteration 4580, loss = 0.00581700
Iteration 4581, loss = 0.00581569
Iteration 4582, loss = 0.00581328
Iteration 4583, loss = 0.00581135
Iteration 4584, loss = 0.00580966
Iteration 4585, loss = 0.00580774
Iteration 4586, loss = 0.00580557
Iteration 4587, loss = 0.00580376
Iteration 4588, loss = 0.00580222
Iteration 4589, loss = 0.00580095
Iteration 4590, loss = 0.00579822
Iteration 4591, loss = 0.00579619
Iteration 4592, loss = 0.00579431
Iteration 4593, loss = 0.00579331
Iteration 4594, loss = 0.00579094
Iteration 4595, loss = 0.00578938
Iteration 4596, loss = 0.00578797
Iteration 4597, loss = 0.00578551
Iteration 4598, loss = 0.00578435
Iteration 4599, loss = 0.00578214
Iteration 4600, loss = 0.00578067
Iteration 4601, loss = 0.00577870
Iteration 4602, loss = 0.00577700
Iteration 4603, loss = 0.00577518
Iteration 4604, loss = 0.00577345
Iteration 4605, loss = 0.00577184
Iteration 4606, loss = 0.00577020
Iteration 4607, loss = 0.00576860
Iteration 4608, loss = 0.00576644
Iteration 4609, loss = 0.00576482
Iteration 4610, loss = 0.00576319
Iteration 4611, loss = 0.00576167
Iteration 4612, loss = 0.00576035
Iteration 4613, loss = 0.00575831
Iteration 4614, loss = 0.00575690
Iteration 4615, loss = 0.00575517
Iteration 4616, loss = 0.00575380
Iteration 4617, loss = 0.00575179
Iteration 4618, loss = 0.00574992
Iteration 4619, loss = 0.00574853
Iteration 4620, loss = 0.00574685
Iteration 4621, loss = 0.00574514
Iteration 4622, loss = 0.00574332
Iteration 4623, loss = 0.00574178
Iteration 4624, loss = 0.00574008
Iteration 4625, loss = 0.00573840
Iteration 4626, loss = 0.00573721
Iteration 4627, loss = 0.00573514
Iteration 4628, loss = 0.00573366
Iteration 4629, loss = 0.00573165
Iteration 4630, loss = 0.00572983
Iteration 4631, loss = 0.00572797
Iteration 4632, loss = 0.00572636
Iteration 4633, loss = 0.00572440
Iteration 4634, loss = 0.00572320
Iteration 4635, loss = 0.00572109
Iteration 4636, loss = 0.00571959
Iteration 4637, loss = 0.00571832
Iteration 4638, loss = 0.00571587
Iteration 4639, loss = 0.00571421
Iteration 4640, loss = 0.00571249
Iteration 4641, loss = 0.00571070
Iteration 4642, loss = 0.00570911
Iteration 4643, loss = 0.00570745
Iteration 4644, loss = 0.00570574
Iteration 4645, loss = 0.00570419
Iteration 4646, loss = 0.00570247
Iteration 4647, loss = 0.00570074
Iteration 4648, loss = 0.00569933
Iteration 4649, loss = 0.00569772
Iteration 4650, loss = 0.00569604
Iteration 4651, loss = 0.00569451
Iteration 4652, loss = 0.00569297
Iteration 4653, loss = 0.00569203
Iteration 4654, loss = 0.00569009
Iteration 4655, loss = 0.00568840
Iteration 4656, loss = 0.00568691
Iteration 4657, loss = 0.00568523
Iteration 4658, loss = 0.00568369
Iteration 4659, loss = 0.00568211
Iteration 4660, loss = 0.00568024
Iteration 4661, loss = 0.00567852
Iteration 4662, loss = 0.00567699
Iteration 4663, loss = 0.00567534
Iteration 4664, loss = 0.00567368
Iteration 4665, loss = 0.00567261
Iteration 4666, loss = 0.00567108
Iteration 4667, loss = 0.00566927
Iteration 4668, loss = 0.00566809
Iteration 4669, loss = 0.00566650
Iteration 4670, loss = 0.00566523
Iteration 4671, loss = 0.00566314
Iteration 4672, loss = 0.00566131
Iteration 4673, loss = 0.00565944
Iteration 4674, loss = 0.00565782
Iteration 4675, loss = 0.00565596
Iteration 4676, loss = 0.00565449
Iteration 4677, loss = 0.00565274
Iteration 4678, loss = 0.00565097
Iteration 4679, loss = 0.00564927
Iteration 4680, loss = 0.00564749
Iteration 4681, loss = 0.00564607
Iteration 4682, loss = 0.00564421
Iteration 4683, loss = 0.00564271
Iteration 4684, loss = 0.00564137
Iteration 4685, loss = 0.00563930
Iteration 4686, loss = 0.00563765
Iteration 4687, loss = 0.00563624
Iteration 4688, loss = 0.00563434
Iteration 4689, loss = 0.00563276
Iteration 4690, loss = 0.00563109
Iteration 4691, loss = 0.00562981
Iteration 4692, loss = 0.00562812
Iteration 4693, loss = 0.00562682
Iteration 4694, loss = 0.00562484
Iteration 4695, loss = 0.00562338
Iteration 4696, loss = 0.00562149
Iteration 4697, loss = 0.00561986
Iteration 4698, loss = 0.00561847
Iteration 4699, loss = 0.00561639
Iteration 4700, loss = 0.00561465
Iteration 4701, loss = 0.00561304
Iteration 4702, loss = 0.00561132
Iteration 4703, loss = 0.00560934
Iteration 4704, loss = 0.00560739
Iteration 4705, loss = 0.00560585
Iteration 4706, loss = 0.00560454
Iteration 4707, loss = 0.00560246
Iteration 4708, loss = 0.00560061
Iteration 4709, loss = 0.00559940
Iteration 4710, loss = 0.00559757
Iteration 4711, loss = 0.00559630
Iteration 4712, loss = 0.00559423
Iteration 4713, loss = 0.00559262
Iteration 4714, loss = 0.00559098
Iteration 4715, loss = 0.00559024
Iteration 4716, loss = 0.00558807
Iteration 4717, loss = 0.00558656
Iteration 4718, loss = 0.00558492
Iteration 4719, loss = 0.00558350
Iteration 4720, loss = 0.00558184
Iteration 4721, loss = 0.00558059
Iteration 4722, loss = 0.00557892
Iteration 4723, loss = 0.00557753
Iteration 4724, loss = 0.00557604
Iteration 4725, loss = 0.00557477
Iteration 4726, loss = 0.00557299
Iteration 4727, loss = 0.00557151
Iteration 4728, loss = 0.00556962
Iteration 4729, loss = 0.00556821
Iteration 4730, loss = 0.00556663
Iteration 4731, loss = 0.00556520
Iteration 4732, loss = 0.00556381
Iteration 4733, loss = 0.00556205
Iteration 4734, loss = 0.00556049
Iteration 4735, loss = 0.00555897
Iteration 4736, loss = 0.00555730
Iteration 4737, loss = 0.00555571
Iteration 4738, loss = 0.00555441
Iteration 4739, loss = 0.00555285
Iteration 4740, loss = 0.00555116
Iteration 4741, loss = 0.00554926
Iteration 4742, loss = 0.00554758
Iteration 4743, loss = 0.00554637
Iteration 4744, loss = 0.00554420
Iteration 4745, loss = 0.00554242
Iteration 4746, loss = 0.00554066
Iteration 4747, loss = 0.00553929
Iteration 4748, loss = 0.00553831
Iteration 4749, loss = 0.00553624
Iteration 4750, loss = 0.00553463
Iteration 4751, loss = 0.00553292
Iteration 4752, loss = 0.00553166
Iteration 4753, loss = 0.00553000
Iteration 4754, loss = 0.00552839
Iteration 4755, loss = 0.00552690
Iteration 4756, loss = 0.00552551
Iteration 4757, loss = 0.00552367
Iteration 4758, loss = 0.00552217
Iteration 4759, loss = 0.00552049
Iteration 4760, loss = 0.00551872
Iteration 4761, loss = 0.00551708
Iteration 4762, loss = 0.00551535
Iteration 4763, loss = 0.00551387
Iteration 4764, loss = 0.00551210
Iteration 4765, loss = 0.00551018
Iteration 4766, loss = 0.00550930
Iteration 4767, loss = 0.00550763
Iteration 4768, loss = 0.00550596
Iteration 4769, loss = 0.00550414
Iteration 4770, loss = 0.00550242
Iteration 4771, loss = 0.00550079
Iteration 4772, loss = 0.00549912
Iteration 4773, loss = 0.00549796
Iteration 4774, loss = 0.00549596
Iteration 4775, loss = 0.00549447
Iteration 4776, loss = 0.00549273
Iteration 4777, loss = 0.00549077
Iteration 4778, loss = 0.00548910
Iteration 4779, loss = 0.00548806
Iteration 4780, loss = 0.00548591
Iteration 4781, loss = 0.00548456
Iteration 4782, loss = 0.00548283
Iteration 4783, loss = 0.00548097
Iteration 4784, loss = 0.00547936
Iteration 4785, loss = 0.00547767
Iteration 4786, loss = 0.00547628
Iteration 4787, loss = 0.00547486
Iteration 4788, loss = 0.00547230
Iteration 4789, loss = 0.00547076
Iteration 4790, loss = 0.00547118
Iteration 4791, loss = 0.00546795
Iteration 4792, loss = 0.00546626
Iteration 4793, loss = 0.00546445
Iteration 4794, loss = 0.00546298
Iteration 4795, loss = 0.00546100
Iteration 4796, loss = 0.00545925
Iteration 4797, loss = 0.00545763
Iteration 4798, loss = 0.00545597
Iteration 4799, loss = 0.00545450
Iteration 4800, loss = 0.00545246
Iteration 4801, loss = 0.00545118
Iteration 4802, loss = 0.00544923
Iteration 4803, loss = 0.00544753
Iteration 4804, loss = 0.00544590
Iteration 4805, loss = 0.00544453
Iteration 4806, loss = 0.00544270
Iteration 4807, loss = 0.00544169
Iteration 4808, loss = 0.00543980
Iteration 4809, loss = 0.00543832
Iteration 4810, loss = 0.00543699
Iteration 4811, loss = 0.00543605
Iteration 4812, loss = 0.00543458
Iteration 4813, loss = 0.00543274
Iteration 4814, loss = 0.00543129
Iteration 4815, loss = 0.00542897
Iteration 4816, loss = 0.00542741
Iteration 4817, loss = 0.00542621
Iteration 4818, loss = 0.00542473
Iteration 4819, loss = 0.00542330
Iteration 4820, loss = 0.00542182
Iteration 4821, loss = 0.00542042
Iteration 4822, loss = 0.00541902
Iteration 4823, loss = 0.00541762
Iteration 4824, loss = 0.00541605
Iteration 4825, loss = 0.00541494
Iteration 4826, loss = 0.00541346
Iteration 4827, loss = 0.00541207
Iteration 4828, loss = 0.00541101
Iteration 4829, loss = 0.00540931
Iteration 4830, loss = 0.00540811
Iteration 4831, loss = 0.00540655
Iteration 4832, loss = 0.00540507
Iteration 4833, loss = 0.00540339
Iteration 4834, loss = 0.00540186
Iteration 4835, loss = 0.00540027
Iteration 4836, loss = 0.00539952
Iteration 4837, loss = 0.00539731
Iteration 4838, loss = 0.00539608
Iteration 4839, loss = 0.00539422
Iteration 4840, loss = 0.00539272
Iteration 4841, loss = 0.00539182
Iteration 4842, loss = 0.00539048
Iteration 4843, loss = 0.00538919
Iteration 4844, loss = 0.00538718
Iteration 4845, loss = 0.00538574
Iteration 4846, loss = 0.00538406
Iteration 4847, loss = 0.00538232
Iteration 4848, loss = 0.00538071
Iteration 4849, loss = 0.00537927
Iteration 4850, loss = 0.00537796
Iteration 4851, loss = 0.00537606
Iteration 4852, loss = 0.00537431
Iteration 4853, loss = 0.00537281
Iteration 4854, loss = 0.00537140
Iteration 4855, loss = 0.00536988
Iteration 4856, loss = 0.00536828
Iteration 4857, loss = 0.00536692
Iteration 4858, loss = 0.00536502
Iteration 4859, loss = 0.00536394
Iteration 4860, loss = 0.00536216
Iteration 4861, loss = 0.00536027
Iteration 4862, loss = 0.00535882
Iteration 4863, loss = 0.00535721
Iteration 4864, loss = 0.00535580
Iteration 4865, loss = 0.00535394
Iteration 4866, loss = 0.00535229
Iteration 4867, loss = 0.00535065
Iteration 4868, loss = 0.00534904
Iteration 4869, loss = 0.00534735
Iteration 4870, loss = 0.00534562
Iteration 4871, loss = 0.00534399
Iteration 4872, loss = 0.00534272
Iteration 4873, loss = 0.00534077
Iteration 4874, loss = 0.00533933
Iteration 4875, loss = 0.00533770
Iteration 4876, loss = 0.00533588
Iteration 4877, loss = 0.00533439
Iteration 4878, loss = 0.00533367
Iteration 4879, loss = 0.00533139
Iteration 4880, loss = 0.00532998
Iteration 4881, loss = 0.00532836
Iteration 4882, loss = 0.00532715
Iteration 4883, loss = 0.00532573
Iteration 4884, loss = 0.00532413
Iteration 4885, loss = 0.00532259
Iteration 4886, loss = 0.00532122
Iteration 4887, loss = 0.00531980
Iteration 4888, loss = 0.00531841
Iteration 4889, loss = 0.00531707
Iteration 4890, loss = 0.00531582
Iteration 4891, loss = 0.00531423
Iteration 4892, loss = 0.00531268
Iteration 4893, loss = 0.00531136
Iteration 4894, loss = 0.00531040
Iteration 4895, loss = 0.00530901
Iteration 4896, loss = 0.00530734
Iteration 4897, loss = 0.00530587
Iteration 4898, loss = 0.00530406
Iteration 4899, loss = 0.00530269
Iteration 4900, loss = 0.00530100
Iteration 4901, loss = 0.00529972
Iteration 4902, loss = 0.00529809
Iteration 4903, loss = 0.00529657
Iteration 4904, loss = 0.00529513
Iteration 4905, loss = 0.00529390
Iteration 4906, loss = 0.00529223
Iteration 4907, loss = 0.00529065
Iteration 4908, loss = 0.00528917
Iteration 4909, loss = 0.00528784
Iteration 4910, loss = 0.00528628
Iteration 4911, loss = 0.00528497
Iteration 4912, loss = 0.00528354
Iteration 4913, loss = 0.00528206
Iteration 4914, loss = 0.00528076
Iteration 4915, loss = 0.00527971
Iteration 4916, loss = 0.00527783
Iteration 4917, loss = 0.00527639
Iteration 4918, loss = 0.00527526
Iteration 4919, loss = 0.00527350
Iteration 4920, loss = 0.00527243
Iteration 4921, loss = 0.00527064
Iteration 4922, loss = 0.00526946
Iteration 4923, loss = 0.00526793
Iteration 4924, loss = 0.00526645
Iteration 4925, loss = 0.00526498
Iteration 4926, loss = 0.00526387
Iteration 4927, loss = 0.00526218
Iteration 4928, loss = 0.00526037
Iteration 4929, loss = 0.00525948
Iteration 4930, loss = 0.00525778
Iteration 4931, loss = 0.00525575
Iteration 4932, loss = 0.00525444
Iteration 4933, loss = 0.00525273
Iteration 4934, loss = 0.00525110
Iteration 4935, loss = 0.00525027
Iteration 4936, loss = 0.00524849
Iteration 4937, loss = 0.00524694
Iteration 4938, loss = 0.00524535
Iteration 4939, loss = 0.00524431
Iteration 4940, loss = 0.00524366
Iteration 4941, loss = 0.00524149
Iteration 4942, loss = 0.00524010
Iteration 4943, loss = 0.00523857
Iteration 4944, loss = 0.00523736
Iteration 4945, loss = 0.00523562
Iteration 4946, loss = 0.00523414
Iteration 4947, loss = 0.00523266
Iteration 4948, loss = 0.00523139
Iteration 4949, loss = 0.00522977
Iteration 4950, loss = 0.00522818
Iteration 4951, loss = 0.00522671
Iteration 4952, loss = 0.00522544
Iteration 4953, loss = 0.00522383
Iteration 4954, loss = 0.00522238
Iteration 4955, loss = 0.00522090
Iteration 4956, loss = 0.00521947
Iteration 4957, loss = 0.00521804
Iteration 4958, loss = 0.00521673
Iteration 4959, loss = 0.00521551
Iteration 4960, loss = 0.00521412
Iteration 4961, loss = 0.00521281
Iteration 4962, loss = 0.00521144
Iteration 4963, loss = 0.00521018
Iteration 4964, loss = 0.00520906
Iteration 4965, loss = 0.00520747
Iteration 4966, loss = 0.00520601
Iteration 4967, loss = 0.00520479
Iteration 4968, loss = 0.00520354
Iteration 4969, loss = 0.00520253
Iteration 4970, loss = 0.00520053
Iteration 4971, loss = 0.00519915
Iteration 4972, loss = 0.00519810
Iteration 4973, loss = 0.00519635
Iteration 4974, loss = 0.00519458
Iteration 4975, loss = 0.00519318
Iteration 4976, loss = 0.00519171
Iteration 4977, loss = 0.00519025
Iteration 4978, loss = 0.00518875
Iteration 4979, loss = 0.00518745
Iteration 4980, loss = 0.00518623
Iteration 4981, loss = 0.00518479
Iteration 4982, loss = 0.00518362
Iteration 4983, loss = 0.00518185
Iteration 4984, loss = 0.00518093
Iteration 4985, loss = 0.00517918
Iteration 4986, loss = 0.00517782
Iteration 4987, loss = 0.00517618
Iteration 4988, loss = 0.00517454
Iteration 4989, loss = 0.00517354
Iteration 4990, loss = 0.00517167
Iteration 4991, loss = 0.00517023
Iteration 4992, loss = 0.00516926
Iteration 4993, loss = 0.00516745
Iteration 4994, loss = 0.00516594
Iteration 4995, loss = 0.00516421
Iteration 4996, loss = 0.00516270
Iteration 4997, loss = 0.00516166
Iteration 4998, loss = 0.00516028
Iteration 4999, loss = 0.00515793
Iteration 5000, loss = 0.00515650
Iteration 5001, loss = 0.00515487
Iteration 5002, loss = 0.00515320
Iteration 5003, loss = 0.00515167
Iteration 5004, loss = 0.00515031
Iteration 5005, loss = 0.00514892
Iteration 5006, loss = 0.00514731
Iteration 5007, loss = 0.00514587
Iteration 5008, loss = 0.00514458
Iteration 5009, loss = 0.00514318
Iteration 5010, loss = 0.00514248
Iteration 5011, loss = 0.00514025
Iteration 5012, loss = 0.00513903
Iteration 5013, loss = 0.00513738
Iteration 5014, loss = 0.00513595
Iteration 5015, loss = 0.00513436
Iteration 5016, loss = 0.00513303
Iteration 5017, loss = 0.00513177
Iteration 5018, loss = 0.00513025
Iteration 5019, loss = 0.00512938
Iteration 5020, loss = 0.00512748
Iteration 5021, loss = 0.00512625
Iteration 5022, loss = 0.00512451
Iteration 5023, loss = 0.00512367
Iteration 5024, loss = 0.00512188
Iteration 5025, loss = 0.00512043
Iteration 5026, loss = 0.00511902
Iteration 5027, loss = 0.00511798
Iteration 5028, loss = 0.00511607
Iteration 5029, loss = 0.00511485
Iteration 5030, loss = 0.00511318
Iteration 5031, loss = 0.00511160
Iteration 5032, loss = 0.00511023
Iteration 5033, loss = 0.00510882
Iteration 5034, loss = 0.00510719
Iteration 5035, loss = 0.00510581
Iteration 5036, loss = 0.00510431
Iteration 5037, loss = 0.00510351
Iteration 5038, loss = 0.00510174
Iteration 5039, loss = 0.00510064
Iteration 5040, loss = 0.00509887
Iteration 5041, loss = 0.00509761
Iteration 5042, loss = 0.00509608
Iteration 5043, loss = 0.00509456
Iteration 5044, loss = 0.00509342
Iteration 5045, loss = 0.00509250
Iteration 5046, loss = 0.00509060
Iteration 5047, loss = 0.00508924
Iteration 5048, loss = 0.00508774
Iteration 5049, loss = 0.00508640
Iteration 5050, loss = 0.00508526
Iteration 5051, loss = 0.00508401
Iteration 5052, loss = 0.00508235
Iteration 5053, loss = 0.00508219
Iteration 5054, loss = 0.00507986
Iteration 5055, loss = 0.00507837
Iteration 5056, loss = 0.00507770
Iteration 5057, loss = 0.00507599
Iteration 5058, loss = 0.00507457
Iteration 5059, loss = 0.00507307
Iteration 5060, loss = 0.00507169
Iteration 5061, loss = 0.00507036
Iteration 5062, loss = 0.00506908
Iteration 5063, loss = 0.00506772
Iteration 5064, loss = 0.00506700
Iteration 5065, loss = 0.00506520
Iteration 5066, loss = 0.00506370
Iteration 5067, loss = 0.00506218
Iteration 5068, loss = 0.00506059
Iteration 5069, loss = 0.00505930
Iteration 5070, loss = 0.00505839
Iteration 5071, loss = 0.00505665
Iteration 5072, loss = 0.00505545
Iteration 5073, loss = 0.00505433
Iteration 5074, loss = 0.00505264
Iteration 5075, loss = 0.00505149
Iteration 5076, loss = 0.00505000
Iteration 5077, loss = 0.00504886
Iteration 5078, loss = 0.00504750
Iteration 5079, loss = 0.00504613
Iteration 5080, loss = 0.00504478
Iteration 5081, loss = 0.00504353
Iteration 5082, loss = 0.00504242
Iteration 5083, loss = 0.00504094
Iteration 5084, loss = 0.00503952
Iteration 5085, loss = 0.00503800
Iteration 5086, loss = 0.00503686
Iteration 5087, loss = 0.00503501
Iteration 5088, loss = 0.00503356
Iteration 5089, loss = 0.00503260
Iteration 5090, loss = 0.00503100
Iteration 5091, loss = 0.00502983
Iteration 5092, loss = 0.00502840
Iteration 5093, loss = 0.00502719
Iteration 5094, loss = 0.00502585
Iteration 5095, loss = 0.00502472
Iteration 5096, loss = 0.00502349
Iteration 5097, loss = 0.00502227
Iteration 5098, loss = 0.00502080
Iteration 5099, loss = 0.00501938
Iteration 5100, loss = 0.00501884
Iteration 5101, loss = 0.00501686
Iteration 5102, loss = 0.00501561
Iteration 5103, loss = 0.00501410
Iteration 5104, loss = 0.00501264
Iteration 5105, loss = 0.00501123
Iteration 5106, loss = 0.00500987
Iteration 5107, loss = 0.00500858
Iteration 5108, loss = 0.00500728
Iteration 5109, loss = 0.00500717
Iteration 5110, loss = 0.00500512
Iteration 5111, loss = 0.00500331
Iteration 5112, loss = 0.00500208
Iteration 5113, loss = 0.00500068
Iteration 5114, loss = 0.00499927
Iteration 5115, loss = 0.00499781
Iteration 5116, loss = 0.00499650
Iteration 5117, loss = 0.00499542
Iteration 5118, loss = 0.00499437
Iteration 5119, loss = 0.00499268
Iteration 5120, loss = 0.00499136
Iteration 5121, loss = 0.00499005
Iteration 5122, loss = 0.00498893
Iteration 5123, loss = 0.00498738
Iteration 5124, loss = 0.00498602
Iteration 5125, loss = 0.00498474
Iteration 5126, loss = 0.00498337
Iteration 5127, loss = 0.00498204
Iteration 5128, loss = 0.00498059
Iteration 5129, loss = 0.00497922
Iteration 5130, loss = 0.00497782
Iteration 5131, loss = 0.00497648
Iteration 5132, loss = 0.00497529
Iteration 5133, loss = 0.00497490
Iteration 5134, loss = 0.00497265
Iteration 5135, loss = 0.00497137
Iteration 5136, loss = 0.00496985
Iteration 5137, loss = 0.00496857
Iteration 5138, loss = 0.00496735
Iteration 5139, loss = 0.00496590
Iteration 5140, loss = 0.00496438
Iteration 5141, loss = 0.00496307
Iteration 5142, loss = 0.00496162
Iteration 5143, loss = 0.00496072
Iteration 5144, loss = 0.00495881
Iteration 5145, loss = 0.00495756
Iteration 5146, loss = 0.00495642
Iteration 5147, loss = 0.00495509
Iteration 5148, loss = 0.00495359
Iteration 5149, loss = 0.00495254
Iteration 5150, loss = 0.00495110
Iteration 5151, loss = 0.00494973
Iteration 5152, loss = 0.00494831
Iteration 5153, loss = 0.00494701
Iteration 5154, loss = 0.00494556
Iteration 5155, loss = 0.00494433
Iteration 5156, loss = 0.00494284
Iteration 5157, loss = 0.00494145
Iteration 5158, loss = 0.00494041
Iteration 5159, loss = 0.00493901
Iteration 5160, loss = 0.00493763
Iteration 5161, loss = 0.00493630
Iteration 5162, loss = 0.00493536
Iteration 5163, loss = 0.00493368
Iteration 5164, loss = 0.00493228
Iteration 5165, loss = 0.00493105
Iteration 5166, loss = 0.00492979
Iteration 5167, loss = 0.00492852
Iteration 5168, loss = 0.00492718
Iteration 5169, loss = 0.00492609
Iteration 5170, loss = 0.00492478
Iteration 5171, loss = 0.00492333
Iteration 5172, loss = 0.00492254
Iteration 5173, loss = 0.00492129
Iteration 5174, loss = 0.00491977
Iteration 5175, loss = 0.00491856
Iteration 5176, loss = 0.00491777
Iteration 5177, loss = 0.00491632
Iteration 5178, loss = 0.00491500
Iteration 5179, loss = 0.00491371
Iteration 5180, loss = 0.00491302
Iteration 5181, loss = 0.00491138
Iteration 5182, loss = 0.00491022
Iteration 5183, loss = 0.00490896
Iteration 5184, loss = 0.00490753
Iteration 5185, loss = 0.00490627
Iteration 5186, loss = 0.00490465
Iteration 5187, loss = 0.00490341
Iteration 5188, loss = 0.00490225
Iteration 5189, loss = 0.00490083
Iteration 5190, loss = 0.00489951
Iteration 5191, loss = 0.00489817
Iteration 5192, loss = 0.00489684
Iteration 5193, loss = 0.00489540
Iteration 5194, loss = 0.00489424
Iteration 5195, loss = 0.00489293
Iteration 5196, loss = 0.00489173
Iteration 5197, loss = 0.00489040
Iteration 5198, loss = 0.00488899
Iteration 5199, loss = 0.00488768
Iteration 5200, loss = 0.00488652
Iteration 5201, loss = 0.00488489
Iteration 5202, loss = 0.00488391
Iteration 5203, loss = 0.00488236
Iteration 5204, loss = 0.00488093
Iteration 5205, loss = 0.00487990
Iteration 5206, loss = 0.00487826
Iteration 5207, loss = 0.00487699
Iteration 5208, loss = 0.00487544
Iteration 5209, loss = 0.00487420
Iteration 5210, loss = 0.00487280
Iteration 5211, loss = 0.00487152
Iteration 5212, loss = 0.00487011
Iteration 5213, loss = 0.00486873
Iteration 5214, loss = 0.00486745
Iteration 5215, loss = 0.00486621
Iteration 5216, loss = 0.00486492
Iteration 5217, loss = 0.00486371
Iteration 5218, loss = 0.00486249
Iteration 5219, loss = 0.00486148
Iteration 5220, loss = 0.00486002
Iteration 5221, loss = 0.00485880
Iteration 5222, loss = 0.00485833
Iteration 5223, loss = 0.00485611
Iteration 5224, loss = 0.00485492
Iteration 5225, loss = 0.00485366
Iteration 5226, loss = 0.00485232
Iteration 5227, loss = 0.00485152
Iteration 5228, loss = 0.00485031
Iteration 5229, loss = 0.00484873
Iteration 5230, loss = 0.00484780
Iteration 5231, loss = 0.00484625
Iteration 5232, loss = 0.00484504
Iteration 5233, loss = 0.00484369
Iteration 5234, loss = 0.00484283
Iteration 5235, loss = 0.00484134
Iteration 5236, loss = 0.00483939
Iteration 5237, loss = 0.00483854
Iteration 5238, loss = 0.00483709
Iteration 5239, loss = 0.00483541
Iteration 5240, loss = 0.00483427
Iteration 5241, loss = 0.00483274
Iteration 5242, loss = 0.00483157
Iteration 5243, loss = 0.00483017
Iteration 5244, loss = 0.00482883
Iteration 5245, loss = 0.00482818
Iteration 5246, loss = 0.00482641
Iteration 5247, loss = 0.00482502
Iteration 5248, loss = 0.00482417
Iteration 5249, loss = 0.00482250
Iteration 5250, loss = 0.00482131
Iteration 5251, loss = 0.00482068
Iteration 5252, loss = 0.00481888
Iteration 5253, loss = 0.00481765
Iteration 5254, loss = 0.00481639
Iteration 5255, loss = 0.00481520
Iteration 5256, loss = 0.00481426
Iteration 5257, loss = 0.00481269
Iteration 5258, loss = 0.00481140
Iteration 5259, loss = 0.00481011
Iteration 5260, loss = 0.00480886
Iteration 5261, loss = 0.00480720
Iteration 5262, loss = 0.00480584
Iteration 5263, loss = 0.00480475
Iteration 5264, loss = 0.00480328
Iteration 5265, loss = 0.00480237
Iteration 5266, loss = 0.00480072
Iteration 5267, loss = 0.00479971
Iteration 5268, loss = 0.00479816
Iteration 5269, loss = 0.00479712
Iteration 5270, loss = 0.00479649
Iteration 5271, loss = 0.00479519
Iteration 5272, loss = 0.00479360
Iteration 5273, loss = 0.00479234
Iteration 5274, loss = 0.00479101
Iteration 5275, loss = 0.00478979
Iteration 5276, loss = 0.00478901
Iteration 5277, loss = 0.00478744
Iteration 5278, loss = 0.00478587
Iteration 5279, loss = 0.00478463
Iteration 5280, loss = 0.00478345
Iteration 5281, loss = 0.00478203
Iteration 5282, loss = 0.00478067
Iteration 5283, loss = 0.00477962
Iteration 5284, loss = 0.00477816
Iteration 5285, loss = 0.00477688
Iteration 5286, loss = 0.00477604
Iteration 5287, loss = 0.00477510
Iteration 5288, loss = 0.00477359
Iteration 5289, loss = 0.00477219
Iteration 5290, loss = 0.00477081
Iteration 5291, loss = 0.00476965
Iteration 5292, loss = 0.00476843
Iteration 5293, loss = 0.00476703
Iteration 5294, loss = 0.00476587
Iteration 5295, loss = 0.00476451
Iteration 5296, loss = 0.00476353
Iteration 5297, loss = 0.00476198
Iteration 5298, loss = 0.00476086
Iteration 5299, loss = 0.00475972
Iteration 5300, loss = 0.00475845
Iteration 5301, loss = 0.00475731
Iteration 5302, loss = 0.00475582
Iteration 5303, loss = 0.00475470
Iteration 5304, loss = 0.00475350
Iteration 5305, loss = 0.00475250
Iteration 5306, loss = 0.00475099
Iteration 5307, loss = 0.00474959
Iteration 5308, loss = 0.00474826
Iteration 5309, loss = 0.00474716
Iteration 5310, loss = 0.00474585
Iteration 5311, loss = 0.00474444
Iteration 5312, loss = 0.00474302
Iteration 5313, loss = 0.00474181
Iteration 5314, loss = 0.00474054
Iteration 5315, loss = 0.00473939
Iteration 5316, loss = 0.00473793
Iteration 5317, loss = 0.00473680
Iteration 5318, loss = 0.00473673
Iteration 5319, loss = 0.00473403
Iteration 5320, loss = 0.00473273
Iteration 5321, loss = 0.00473134
Iteration 5322, loss = 0.00473009
Iteration 5323, loss = 0.00472880
Iteration 5324, loss = 0.00472781
Iteration 5325, loss = 0.00472638
Iteration 5326, loss = 0.00472550
Iteration 5327, loss = 0.00472382
Iteration 5328, loss = 0.00472298
Iteration 5329, loss = 0.00472148
Iteration 5330, loss = 0.00472042
Iteration 5331, loss = 0.00471904
Iteration 5332, loss = 0.00471758
Iteration 5333, loss = 0.00471650
Iteration 5334, loss = 0.00471517
Iteration 5335, loss = 0.00471395
Iteration 5336, loss = 0.00471259
Iteration 5337, loss = 0.00471134
Iteration 5338, loss = 0.00471017
Iteration 5339, loss = 0.00470907
Iteration 5340, loss = 0.00470775
Iteration 5341, loss = 0.00470649
Iteration 5342, loss = 0.00470543
Iteration 5343, loss = 0.00470424
Iteration 5344, loss = 0.00470289
Iteration 5345, loss = 0.00470210
Iteration 5346, loss = 0.00470047
Iteration 5347, loss = 0.00469950
Iteration 5348, loss = 0.00469838
Iteration 5349, loss = 0.00469684
Iteration 5350, loss = 0.00469603
Iteration 5351, loss = 0.00469455
Iteration 5352, loss = 0.00469367
Iteration 5353, loss = 0.00469207
Iteration 5354, loss = 0.00469095
Iteration 5355, loss = 0.00469027
Iteration 5356, loss = 0.00468863
Iteration 5357, loss = 0.00468746
Iteration 5358, loss = 0.00468612
Iteration 5359, loss = 0.00468540
Iteration 5360, loss = 0.00468373
Iteration 5361, loss = 0.00468279
Iteration 5362, loss = 0.00468154
Iteration 5363, loss = 0.00468011
Iteration 5364, loss = 0.00467903
Iteration 5365, loss = 0.00467772
Iteration 5366, loss = 0.00467663
Iteration 5367, loss = 0.00467532
Iteration 5368, loss = 0.00467412
Iteration 5369, loss = 0.00467304
Iteration 5370, loss = 0.00467186
Iteration 5371, loss = 0.00467103
Iteration 5372, loss = 0.00466959
Iteration 5373, loss = 0.00466871
Iteration 5374, loss = 0.00466770
Iteration 5375, loss = 0.00466607
Iteration 5376, loss = 0.00466514
Iteration 5377, loss = 0.00466370
Iteration 5378, loss = 0.00466282
Iteration 5379, loss = 0.00466125
Iteration 5380, loss = 0.00466022
Iteration 5381, loss = 0.00465893
Iteration 5382, loss = 0.00465734
Iteration 5383, loss = 0.00465624
Iteration 5384, loss = 0.00465500
Iteration 5385, loss = 0.00465397
Iteration 5386, loss = 0.00465272
Iteration 5387, loss = 0.00465159
Iteration 5388, loss = 0.00465043
Iteration 5389, loss = 0.00464894
Iteration 5390, loss = 0.00464773
Iteration 5391, loss = 0.00464674
Iteration 5392, loss = 0.00464561
Iteration 5393, loss = 0.00464450
Iteration 5394, loss = 0.00464334
Iteration 5395, loss = 0.00464224
Iteration 5396, loss = 0.00464106
Iteration 5397, loss = 0.00464000
Iteration 5398, loss = 0.00463901
Iteration 5399, loss = 0.00463812
Iteration 5400, loss = 0.00463689
Iteration 5401, loss = 0.00463594
Iteration 5402, loss = 0.00463453
Iteration 5403, loss = 0.00463349
Iteration 5404, loss = 0.00463250
Iteration 5405, loss = 0.00463159
Iteration 5406, loss = 0.00463002
Iteration 5407, loss = 0.00462901
Iteration 5408, loss = 0.00462775
Iteration 5409, loss = 0.00462666
Iteration 5410, loss = 0.00462567
Iteration 5411, loss = 0.00462444
Iteration 5412, loss = 0.00462339
Iteration 5413, loss = 0.00462258
Iteration 5414, loss = 0.00462120
Iteration 5415, loss = 0.00462003
Iteration 5416, loss = 0.00461886
Iteration 5417, loss = 0.00461814
Iteration 5418, loss = 0.00461683
Iteration 5419, loss = 0.00461567
Iteration 5420, loss = 0.00461465
Iteration 5421, loss = 0.00461350
Iteration 5422, loss = 0.00461254
Iteration 5423, loss = 0.00461142
Iteration 5424, loss = 0.00461036
Iteration 5425, loss = 0.00460897
Iteration 5426, loss = 0.00460770
Iteration 5427, loss = 0.00460655
Iteration 5428, loss = 0.00460539
Iteration 5429, loss = 0.00460422
Iteration 5430, loss = 0.00460321
Iteration 5431, loss = 0.00460184
Iteration 5432, loss = 0.00460069
Iteration 5433, loss = 0.00459956
Iteration 5434, loss = 0.00459827
Iteration 5435, loss = 0.00459733
Iteration 5436, loss = 0.00459660
Iteration 5437, loss = 0.00459520
Iteration 5438, loss = 0.00459416
Iteration 5439, loss = 0.00459302
Iteration 5440, loss = 0.00459185
Iteration 5441, loss = 0.00459150
Iteration 5442, loss = 0.00458959
Iteration 5443, loss = 0.00458862
Iteration 5444, loss = 0.00458772
Iteration 5445, loss = 0.00458617
Iteration 5446, loss = 0.00458465
Iteration 5447, loss = 0.00458376
Iteration 5448, loss = 0.00458236
Iteration 5449, loss = 0.00458117
Iteration 5450, loss = 0.00457988
Iteration 5451, loss = 0.00457881
Iteration 5452, loss = 0.00457781
Iteration 5453, loss = 0.00457635
Iteration 5454, loss = 0.00457548
Iteration 5455, loss = 0.00457420
Iteration 5456, loss = 0.00457297
Iteration 5457, loss = 0.00457175
Iteration 5458, loss = 0.00457063
Iteration 5459, loss = 0.00456952
Iteration 5460, loss = 0.00456847
Iteration 5461, loss = 0.00456733
Iteration 5462, loss = 0.00456640
Iteration 5463, loss = 0.00456531
Iteration 5464, loss = 0.00456427
Iteration 5465, loss = 0.00456297
Iteration 5466, loss = 0.00456192
Iteration 5467, loss = 0.00456074
Iteration 5468, loss = 0.00455974
Iteration 5469, loss = 0.00455870
Iteration 5470, loss = 0.00455751
Iteration 5471, loss = 0.00455632
Iteration 5472, loss = 0.00455521
Iteration 5473, loss = 0.00455404
Iteration 5474, loss = 0.00455295
Iteration 5475, loss = 0.00455173
Iteration 5476, loss = 0.00455060
Iteration 5477, loss = 0.00454957
Iteration 5478, loss = 0.00454841
Iteration 5479, loss = 0.00454742
Iteration 5480, loss = 0.00454623
Iteration 5481, loss = 0.00454522
Iteration 5482, loss = 0.00454425
Iteration 5483, loss = 0.00454311
Iteration 5484, loss = 0.00454213
Iteration 5485, loss = 0.00454103
Iteration 5486, loss = 0.00454010
Iteration 5487, loss = 0.00453878
Iteration 5488, loss = 0.00453855
Iteration 5489, loss = 0.00453710
Iteration 5490, loss = 0.00453588
Iteration 5491, loss = 0.00453474
Iteration 5492, loss = 0.00453362
Iteration 5493, loss = 0.00453255
Iteration 5494, loss = 0.00453138
Iteration 5495, loss = 0.00453019
Iteration 5496, loss = 0.00452904
Iteration 5497, loss = 0.00452796
Iteration 5498, loss = 0.00452719
Iteration 5499, loss = 0.00452561
Iteration 5500, loss = 0.00452407
Iteration 5501, loss = 0.00452303
Iteration 5502, loss = 0.00452174
Iteration 5503, loss = 0.00452055
Iteration 5504, loss = 0.00451938
Iteration 5505, loss = 0.00451818
Iteration 5506, loss = 0.00451700
Iteration 5507, loss = 0.00451579
Iteration 5508, loss = 0.00451445
Iteration 5509, loss = 0.00451341
Iteration 5510, loss = 0.00451210
Iteration 5511, loss = 0.00451103
Iteration 5512, loss = 0.00450991
Iteration 5513, loss = 0.00450874
Iteration 5514, loss = 0.00450762
Iteration 5515, loss = 0.00450657
Iteration 5516, loss = 0.00450553
Iteration 5517, loss = 0.00450442
Iteration 5518, loss = 0.00450339
Iteration 5519, loss = 0.00450239
Iteration 5520, loss = 0.00450173
Iteration 5521, loss = 0.00450006
Iteration 5522, loss = 0.00449891
Iteration 5523, loss = 0.00449762
Iteration 5524, loss = 0.00449636
Iteration 5525, loss = 0.00449514
Iteration 5526, loss = 0.00449398
Iteration 5527, loss = 0.00449292
Iteration 5528, loss = 0.00449198
Iteration 5529, loss = 0.00449060
Iteration 5530, loss = 0.00448961
Iteration 5531, loss = 0.00448829
Iteration 5532, loss = 0.00448754
Iteration 5533, loss = 0.00448575
Iteration 5534, loss = 0.00448461
Iteration 5535, loss = 0.00448323
Iteration 5536, loss = 0.00448213
Iteration 5537, loss = 0.00448113
Iteration 5538, loss = 0.00447969
Iteration 5539, loss = 0.00447892
Iteration 5540, loss = 0.00447782
Iteration 5541, loss = 0.00447649
Iteration 5542, loss = 0.00447540
Iteration 5543, loss = 0.00447450
Iteration 5544, loss = 0.00447334
Iteration 5545, loss = 0.00447197
Iteration 5546, loss = 0.00447137
Iteration 5547, loss = 0.00447003
Iteration 5548, loss = 0.00446896
Iteration 5549, loss = 0.00446780
Iteration 5550, loss = 0.00446676
Iteration 5551, loss = 0.00446613
Iteration 5552, loss = 0.00446497
Iteration 5553, loss = 0.00446372
Iteration 5554, loss = 0.00446231
Iteration 5555, loss = 0.00446115
Iteration 5556, loss = 0.00446006
Iteration 5557, loss = 0.00445897
Iteration 5558, loss = 0.00445802
Iteration 5559, loss = 0.00445680
Iteration 5560, loss = 0.00445609
Iteration 5561, loss = 0.00445486
Iteration 5562, loss = 0.00445393
Iteration 5563, loss = 0.00445276
Iteration 5564, loss = 0.00445165
Iteration 5565, loss = 0.00445064
Iteration 5566, loss = 0.00444985
Iteration 5567, loss = 0.00444827
Iteration 5568, loss = 0.00444700
Iteration 5569, loss = 0.00444604
Iteration 5570, loss = 0.00444482
Iteration 5571, loss = 0.00444347
Iteration 5572, loss = 0.00444219
Iteration 5573, loss = 0.00444102
Iteration 5574, loss = 0.00443960
Iteration 5575, loss = 0.00443847
Iteration 5576, loss = 0.00443730
Iteration 5577, loss = 0.00443589
Iteration 5578, loss = 0.00443501
Iteration 5579, loss = 0.00443427
Iteration 5580, loss = 0.00443297
Iteration 5581, loss = 0.00443217
Iteration 5582, loss = 0.00443101
Iteration 5583, loss = 0.00443009
Iteration 5584, loss = 0.00442901
Iteration 5585, loss = 0.00442806
Iteration 5586, loss = 0.00442711
Iteration 5587, loss = 0.00442628
Iteration 5588, loss = 0.00442578
Iteration 5589, loss = 0.00442435
Iteration 5590, loss = 0.00442314
Iteration 5591, loss = 0.00442178
Iteration 5592, loss = 0.00442156
Iteration 5593, loss = 0.00441986
Iteration 5594, loss = 0.00441868
Iteration 5595, loss = 0.00441717
Iteration 5596, loss = 0.00441649
Iteration 5597, loss = 0.00441491
Iteration 5598, loss = 0.00441383
Iteration 5599, loss = 0.00441269
Iteration 5600, loss = 0.00441180
Iteration 5601, loss = 0.00441025
Iteration 5602, loss = 0.00440951
Iteration 5603, loss = 0.00440808
Iteration 5604, loss = 0.00440674
Iteration 5605, loss = 0.00440550
Iteration 5606, loss = 0.00440447
Iteration 5607, loss = 0.00440326
Iteration 5608, loss = 0.00440233
Iteration 5609, loss = 0.00440128
Iteration 5610, loss = 0.00439987
Iteration 5611, loss = 0.00439888
Iteration 5612, loss = 0.00439786
Iteration 5613, loss = 0.00439666
Iteration 5614, loss = 0.00439577
Iteration 5615, loss = 0.00439463
Iteration 5616, loss = 0.00439350
Iteration 5617, loss = 0.00439232
Iteration 5618, loss = 0.00439129
Iteration 5619, loss = 0.00438984
Iteration 5620, loss = 0.00438873
Iteration 5621, loss = 0.00438736
Iteration 5622, loss = 0.00438623
Iteration 5623, loss = 0.00438542
Iteration 5624, loss = 0.00438389
Iteration 5625, loss = 0.00438273
Iteration 5626, loss = 0.00438168
Iteration 5627, loss = 0.00438047
Iteration 5628, loss = 0.00437942
Iteration 5629, loss = 0.00437856
Iteration 5630, loss = 0.00437737
Iteration 5631, loss = 0.00437660
Iteration 5632, loss = 0.00437504
Iteration 5633, loss = 0.00437385
Iteration 5634, loss = 0.00437278
Iteration 5635, loss = 0.00437185
Iteration 5636, loss = 0.00437056
Iteration 5637, loss = 0.00436944
Iteration 5638, loss = 0.00436866
Iteration 5639, loss = 0.00436743
Iteration 5640, loss = 0.00436623
Iteration 5641, loss = 0.00436500
Iteration 5642, loss = 0.00436416
Iteration 5643, loss = 0.00436306
Iteration 5644, loss = 0.00436218
Iteration 5645, loss = 0.00436107
Iteration 5646, loss = 0.00435991
Iteration 5647, loss = 0.00435876
Iteration 5648, loss = 0.00435779
Iteration 5649, loss = 0.00435674
Iteration 5650, loss = 0.00435556
Iteration 5651, loss = 0.00435454
Iteration 5652, loss = 0.00435331
Iteration 5653, loss = 0.00435234
Iteration 5654, loss = 0.00435119
Iteration 5655, loss = 0.00435023
Iteration 5656, loss = 0.00434912
Iteration 5657, loss = 0.00434813
Iteration 5658, loss = 0.00434716
Iteration 5659, loss = 0.00434686
Iteration 5660, loss = 0.00434512
Iteration 5661, loss = 0.00434405
Iteration 5662, loss = 0.00434322
Iteration 5663, loss = 0.00434218
Iteration 5664, loss = 0.00434111
Iteration 5665, loss = 0.00433990
Iteration 5666, loss = 0.00433870
Iteration 5667, loss = 0.00433754
Iteration 5668, loss = 0.00433663
Iteration 5669, loss = 0.00433571
Iteration 5670, loss = 0.00433448
Iteration 5671, loss = 0.00433346
Iteration 5672, loss = 0.00433248
Iteration 5673, loss = 0.00433155
Iteration 5674, loss = 0.00433036
Iteration 5675, loss = 0.00432985
Iteration 5676, loss = 0.00432885
Iteration 5677, loss = 0.00432768
Iteration 5678, loss = 0.00432670
Iteration 5679, loss = 0.00432525
Iteration 5680, loss = 0.00432424
Iteration 5681, loss = 0.00432307
Iteration 5682, loss = 0.00432185
Iteration 5683, loss = 0.00432067
Iteration 5684, loss = 0.00431954
Iteration 5685, loss = 0.00431841
Iteration 5686, loss = 0.00431712
Iteration 5687, loss = 0.00431600
Iteration 5688, loss = 0.00431498
Iteration 5689, loss = 0.00431385
Iteration 5690, loss = 0.00431274
Iteration 5691, loss = 0.00431164
Iteration 5692, loss = 0.00431053
Iteration 5693, loss = 0.00430926
Iteration 5694, loss = 0.00430829
Iteration 5695, loss = 0.00430704
Iteration 5696, loss = 0.00430569
Iteration 5697, loss = 0.00430427
Iteration 5698, loss = 0.00430383
Iteration 5699, loss = 0.00430280
Iteration 5700, loss = 0.00430119
Iteration 5701, loss = 0.00430005
Iteration 5702, loss = 0.00429911
Iteration 5703, loss = 0.00429790
Iteration 5704, loss = 0.00429661
Iteration 5705, loss = 0.00429529
Iteration 5706, loss = 0.00429406
Iteration 5707, loss = 0.00429331
Iteration 5708, loss = 0.00429225
Iteration 5709, loss = 0.00429070
Iteration 5710, loss = 0.00428988
Iteration 5711, loss = 0.00428865
Iteration 5712, loss = 0.00428766
Iteration 5713, loss = 0.00428632
Iteration 5714, loss = 0.00428551
Iteration 5715, loss = 0.00428424
Iteration 5716, loss = 0.00428299
Iteration 5717, loss = 0.00428188
Iteration 5718, loss = 0.00428073
Iteration 5719, loss = 0.00427971
Iteration 5720, loss = 0.00427860
Iteration 5721, loss = 0.00427787
Iteration 5722, loss = 0.00427666
Iteration 5723, loss = 0.00427640
Iteration 5724, loss = 0.00427483
Iteration 5725, loss = 0.00427370
Iteration 5726, loss = 0.00427234
Iteration 5727, loss = 0.00427125
Iteration 5728, loss = 0.00427086
Iteration 5729, loss = 0.00426921
Iteration 5730, loss = 0.00426814
Iteration 5731, loss = 0.00426709
Iteration 5732, loss = 0.00426586
Iteration 5733, loss = 0.00426478
Iteration 5734, loss = 0.00426372
Iteration 5735, loss = 0.00426297
Iteration 5736, loss = 0.00426185
Iteration 5737, loss = 0.00426088
Iteration 5738, loss = 0.00425990
Iteration 5739, loss = 0.00425914
Iteration 5740, loss = 0.00425816
Iteration 5741, loss = 0.00425720
Iteration 5742, loss = 0.00425686
Iteration 5743, loss = 0.00425556
Iteration 5744, loss = 0.00425438
Iteration 5745, loss = 0.00425325
Iteration 5746, loss = 0.00425234
Iteration 5747, loss = 0.00425131
Iteration 5748, loss = 0.00425025
Iteration 5749, loss = 0.00424937
Iteration 5750, loss = 0.00424864
Iteration 5751, loss = 0.00424753
Iteration 5752, loss = 0.00424656
Iteration 5753, loss = 0.00424556
Iteration 5754, loss = 0.00424445
Iteration 5755, loss = 0.00424351
Iteration 5756, loss = 0.00424225
Iteration 5757, loss = 0.00424140
Iteration 5758, loss = 0.00424055
Iteration 5759, loss = 0.00423962
Iteration 5760, loss = 0.00423931
Iteration 5761, loss = 0.00423770
Iteration 5762, loss = 0.00423635
Iteration 5763, loss = 0.00423534
Iteration 5764, loss = 0.00423449
Iteration 5765, loss = 0.00423347
Iteration 5766, loss = 0.00423253
Iteration 5767, loss = 0.00423156
Iteration 5768, loss = 0.00423033
Iteration 5769, loss = 0.00422950
Iteration 5770, loss = 0.00422833
Iteration 5771, loss = 0.00422742
Iteration 5772, loss = 0.00422649
Iteration 5773, loss = 0.00422629
Iteration 5774, loss = 0.00422431
Iteration 5775, loss = 0.00422343
Iteration 5776, loss = 0.00422209
Iteration 5777, loss = 0.00422089
Iteration 5778, loss = 0.00421983
Iteration 5779, loss = 0.00421871
Iteration 5780, loss = 0.00421747
Iteration 5781, loss = 0.00421656
Iteration 5782, loss = 0.00421540
Iteration 5783, loss = 0.00421427
Iteration 5784, loss = 0.00421338
Iteration 5785, loss = 0.00421231
Iteration 5786, loss = 0.00421125
Iteration 5787, loss = 0.00421027
Iteration 5788, loss = 0.00420940
Iteration 5789, loss = 0.00420848
Iteration 5790, loss = 0.00420758
Iteration 5791, loss = 0.00420652
Iteration 5792, loss = 0.00420612
Iteration 5793, loss = 0.00420473
Iteration 5794, loss = 0.00420369
Iteration 5795, loss = 0.00420266
Iteration 5796, loss = 0.00420162
Iteration 5797, loss = 0.00420078
Iteration 5798, loss = 0.00419934
Iteration 5799, loss = 0.00419814
Iteration 5800, loss = 0.00419708
Iteration 5801, loss = 0.00419593
Iteration 5802, loss = 0.00419495
Iteration 5803, loss = 0.00419425
Iteration 5804, loss = 0.00419290
Iteration 5805, loss = 0.00419196
Iteration 5806, loss = 0.00419094
Iteration 5807, loss = 0.00419037
Iteration 5808, loss = 0.00418921
Iteration 5809, loss = 0.00418835
Iteration 5810, loss = 0.00418735
Iteration 5811, loss = 0.00418630
Iteration 5812, loss = 0.00418531
Iteration 5813, loss = 0.00418437
Iteration 5814, loss = 0.00418347
Iteration 5815, loss = 0.00418297
Iteration 5816, loss = 0.00418165
Iteration 5817, loss = 0.00418064
Iteration 5818, loss = 0.00417968
Iteration 5819, loss = 0.00417876
Iteration 5820, loss = 0.00417790
Iteration 5821, loss = 0.00417688
Iteration 5822, loss = 0.00417576
Iteration 5823, loss = 0.00417480
Iteration 5824, loss = 0.00417381
Iteration 5825, loss = 0.00417303
Iteration 5826, loss = 0.00417174
Iteration 5827, loss = 0.00417088
Iteration 5828, loss = 0.00416979
Iteration 5829, loss = 0.00416909
Iteration 5830, loss = 0.00416744
Iteration 5831, loss = 0.00416650
Iteration 5832, loss = 0.00416535
Iteration 5833, loss = 0.00416424
Iteration 5834, loss = 0.00416329
Iteration 5835, loss = 0.00416236
Iteration 5836, loss = 0.00416133
Iteration 5837, loss = 0.00416017
Iteration 5838, loss = 0.00415910
Iteration 5839, loss = 0.00415820
Iteration 5840, loss = 0.00415729
Iteration 5841, loss = 0.00415601
Iteration 5842, loss = 0.00415514
Iteration 5843, loss = 0.00415394
Iteration 5844, loss = 0.00415313
Iteration 5845, loss = 0.00415242
Iteration 5846, loss = 0.00415113
Iteration 5847, loss = 0.00415009
Iteration 5848, loss = 0.00414910
Iteration 5849, loss = 0.00414813
Iteration 5850, loss = 0.00414702
Iteration 5851, loss = 0.00414586
Iteration 5852, loss = 0.00414518
Iteration 5853, loss = 0.00414398
Iteration 5854, loss = 0.00414282
Iteration 5855, loss = 0.00414160
Iteration 5856, loss = 0.00414086
Iteration 5857, loss = 0.00413965
Iteration 5858, loss = 0.00413880
Iteration 5859, loss = 0.00413773
Iteration 5860, loss = 0.00413642
Iteration 5861, loss = 0.00413548
Iteration 5862, loss = 0.00413433
Iteration 5863, loss = 0.00413345
Iteration 5864, loss = 0.00413249
Iteration 5865, loss = 0.00413141
Iteration 5866, loss = 0.00413071
Iteration 5867, loss = 0.00412956
Iteration 5868, loss = 0.00412863
Iteration 5869, loss = 0.00412763
Iteration 5870, loss = 0.00412664
Iteration 5871, loss = 0.00412561
Iteration 5872, loss = 0.00412464
Iteration 5873, loss = 0.00412358
Iteration 5874, loss = 0.00412265
Iteration 5875, loss = 0.00412157
Iteration 5876, loss = 0.00412039
Iteration 5877, loss = 0.00411922
Iteration 5878, loss = 0.00411809
Iteration 5879, loss = 0.00411722
Iteration 5880, loss = 0.00411654
Iteration 5881, loss = 0.00411519
Iteration 5882, loss = 0.00411425
Iteration 5883, loss = 0.00411320
Iteration 5884, loss = 0.00411233
Iteration 5885, loss = 0.00411118
Iteration 5886, loss = 0.00411061
Iteration 5887, loss = 0.00410933
Iteration 5888, loss = 0.00410835
Iteration 5889, loss = 0.00410732
Iteration 5890, loss = 0.00410659
Iteration 5891, loss = 0.00410536
Iteration 5892, loss = 0.00410468
Iteration 5893, loss = 0.00410356
Iteration 5894, loss = 0.00410256
Iteration 5895, loss = 0.00410172
Iteration 5896, loss = 0.00410066
Iteration 5897, loss = 0.00409941
Iteration 5898, loss = 0.00409865
Iteration 5899, loss = 0.00409763
Iteration 5900, loss = 0.00409655
Iteration 5901, loss = 0.00409565
Iteration 5902, loss = 0.00409475
Iteration 5903, loss = 0.00409382
Iteration 5904, loss = 0.00409295
Iteration 5905, loss = 0.00409202
Iteration 5906, loss = 0.00409171
Iteration 5907, loss = 0.00409027
Iteration 5908, loss = 0.00408943
Iteration 5909, loss = 0.00408857
Iteration 5910, loss = 0.00408752
Iteration 5911, loss = 0.00408672
Iteration 5912, loss = 0.00408563
Iteration 5913, loss = 0.00408480
Iteration 5914, loss = 0.00408392
Iteration 5915, loss = 0.00408308
Iteration 5916, loss = 0.00408208
Iteration 5917, loss = 0.00408117
Iteration 5918, loss = 0.00408020
Iteration 5919, loss = 0.00407957
Iteration 5920, loss = 0.00407849
Iteration 5921, loss = 0.00407737
Iteration 5922, loss = 0.00407634
Iteration 5923, loss = 0.00407562
Iteration 5924, loss = 0.00407446
Iteration 5925, loss = 0.00407343
Iteration 5926, loss = 0.00407240
Iteration 5927, loss = 0.00407149
Iteration 5928, loss = 0.00407044
Iteration 5929, loss = 0.00406938
Iteration 5930, loss = 0.00406836
Iteration 5931, loss = 0.00406738
Iteration 5932, loss = 0.00406636
Iteration 5933, loss = 0.00406521
Iteration 5934, loss = 0.00406402
Iteration 5935, loss = 0.00406282
Iteration 5936, loss = 0.00406163
Iteration 5937, loss = 0.00406128
Iteration 5938, loss = 0.00406029
Iteration 5939, loss = 0.00405959
Iteration 5940, loss = 0.00405818
Iteration 5941, loss = 0.00405715
Iteration 5942, loss = 0.00405631
Iteration 5943, loss = 0.00405571
Iteration 5944, loss = 0.00405453
Iteration 5945, loss = 0.00405365
Iteration 5946, loss = 0.00405273
Iteration 5947, loss = 0.00405184
Iteration 5948, loss = 0.00405085
Iteration 5949, loss = 0.00404998
Iteration 5950, loss = 0.00404907
Iteration 5951, loss = 0.00404825
Iteration 5952, loss = 0.00404722
Iteration 5953, loss = 0.00404627
Iteration 5954, loss = 0.00404544
Iteration 5955, loss = 0.00404445
Iteration 5956, loss = 0.00404353
Iteration 5957, loss = 0.00404249
Iteration 5958, loss = 0.00404151
Iteration 5959, loss = 0.00404051
Iteration 5960, loss = 0.00403958
Iteration 5961, loss = 0.00403877
Iteration 5962, loss = 0.00403802
Iteration 5963, loss = 0.00403735
Iteration 5964, loss = 0.00403613
Iteration 5965, loss = 0.00403517
Iteration 5966, loss = 0.00403405
Iteration 5967, loss = 0.00403329
Iteration 5968, loss = 0.00403213
Iteration 5969, loss = 0.00403110
Iteration 5970, loss = 0.00403022
Iteration 5971, loss = 0.00402948
Iteration 5972, loss = 0.00402819
Iteration 5973, loss = 0.00402741
Iteration 5974, loss = 0.00402663
Iteration 5975, loss = 0.00402555
Iteration 5976, loss = 0.00402461
Iteration 5977, loss = 0.00402369
Iteration 5978, loss = 0.00402275
Iteration 5979, loss = 0.00402167
Iteration 5980, loss = 0.00402106
Iteration 5981, loss = 0.00401994
Iteration 5982, loss = 0.00401872
Iteration 5983, loss = 0.00401785
Iteration 5984, loss = 0.00401678
Iteration 5985, loss = 0.00401613
Iteration 5986, loss = 0.00401479
Iteration 5987, loss = 0.00401406
Iteration 5988, loss = 0.00401279
Iteration 5989, loss = 0.00401189
Iteration 5990, loss = 0.00401104
Iteration 5991, loss = 0.00401005
Iteration 5992, loss = 0.00400895
Iteration 5993, loss = 0.00400808
Iteration 5994, loss = 0.00400707
Iteration 5995, loss = 0.00400598
Iteration 5996, loss = 0.00400505
Iteration 5997, loss = 0.00400413
Iteration 5998, loss = 0.00400302
Iteration 5999, loss = 0.00400231
Iteration 6000, loss = 0.00400134
Iteration 6001, loss = 0.00400032
Iteration 6002, loss = 0.00399936
Iteration 6003, loss = 0.00399844
Iteration 6004, loss = 0.00399748
Iteration 6005, loss = 0.00399669
Iteration 6006, loss = 0.00399583
Iteration 6007, loss = 0.00399497
Iteration 6008, loss = 0.00399410
Iteration 6009, loss = 0.00399329
Iteration 6010, loss = 0.00399249
Iteration 6011, loss = 0.00399157
Iteration 6012, loss = 0.00399121
Iteration 6013, loss = 0.00398988
Iteration 6014, loss = 0.00398895
Iteration 6015, loss = 0.00398808
Iteration 6016, loss = 0.00398715
Iteration 6017, loss = 0.00398621
Iteration 6018, loss = 0.00398544
Iteration 6019, loss = 0.00398437
Iteration 6020, loss = 0.00398336
Iteration 6021, loss = 0.00398247
Iteration 6022, loss = 0.00398152
Iteration 6023, loss = 0.00398061
Iteration 6024, loss = 0.00398028
Iteration 6025, loss = 0.00397921
Iteration 6026, loss = 0.00397837
Iteration 6027, loss = 0.00397755
Iteration 6028, loss = 0.00397661
Iteration 6029, loss = 0.00397585
Iteration 6030, loss = 0.00397524
Iteration 6031, loss = 0.00397412
Iteration 6032, loss = 0.00397330
Iteration 6033, loss = 0.00397243
Iteration 6034, loss = 0.00397172
Iteration 6035, loss = 0.00397067
Iteration 6036, loss = 0.00396976
Iteration 6037, loss = 0.00396878
Iteration 6038, loss = 0.00396810
Iteration 6039, loss = 0.00396709
Iteration 6040, loss = 0.00396641
Iteration 6041, loss = 0.00396565
Iteration 6042, loss = 0.00396452
Iteration 6043, loss = 0.00396361
Iteration 6044, loss = 0.00396257
Iteration 6045, loss = 0.00396186
Iteration 6046, loss = 0.00396078
Iteration 6047, loss = 0.00395967
Iteration 6048, loss = 0.00395871
Iteration 6049, loss = 0.00395761
Iteration 6050, loss = 0.00395672
Iteration 6051, loss = 0.00395590
Iteration 6052, loss = 0.00395488
Iteration 6053, loss = 0.00395390
Iteration 6054, loss = 0.00395285
Iteration 6055, loss = 0.00395213
Iteration 6056, loss = 0.00395093
Iteration 6057, loss = 0.00395010
Iteration 6058, loss = 0.00394938
Iteration 6059, loss = 0.00394877
Iteration 6060, loss = 0.00394732
Iteration 6061, loss = 0.00394645
Iteration 6062, loss = 0.00394560
Iteration 6063, loss = 0.00394503
Iteration 6064, loss = 0.00394373
Iteration 6065, loss = 0.00394311
Iteration 6066, loss = 0.00394226
Iteration 6067, loss = 0.00394129
Iteration 6068, loss = 0.00394036
Iteration 6069, loss = 0.00393948
Iteration 6070, loss = 0.00393899
Iteration 6071, loss = 0.00393784
Iteration 6072, loss = 0.00393690
Iteration 6073, loss = 0.00393635
Iteration 6074, loss = 0.00393523
Iteration 6075, loss = 0.00393429
Iteration 6076, loss = 0.00393333
Iteration 6077, loss = 0.00393246
Iteration 6078, loss = 0.00393171
Iteration 6079, loss = 0.00393070
Iteration 6080, loss = 0.00392951
Iteration 6081, loss = 0.00392853
Iteration 6082, loss = 0.00392756
Iteration 6083, loss = 0.00392644
Iteration 6084, loss = 0.00392562
Iteration 6085, loss = 0.00392443
Iteration 6086, loss = 0.00392348
Iteration 6087, loss = 0.00392277
Iteration 6088, loss = 0.00392190
Iteration 6089, loss = 0.00392089
Iteration 6090, loss = 0.00391987
Iteration 6091, loss = 0.00391921
Iteration 6092, loss = 0.00391805
Iteration 6093, loss = 0.00391717
Iteration 6094, loss = 0.00391624
Iteration 6095, loss = 0.00391555
Iteration 6096, loss = 0.00391465
Iteration 6097, loss = 0.00391360
Iteration 6098, loss = 0.00391245
Iteration 6099, loss = 0.00391182
Iteration 6100, loss = 0.00391066
Iteration 6101, loss = 0.00390992
Iteration 6102, loss = 0.00390902
Iteration 6103, loss = 0.00390816
Iteration 6104, loss = 0.00390713
Iteration 6105, loss = 0.00390629
Iteration 6106, loss = 0.00390546
Iteration 6107, loss = 0.00390450
Iteration 6108, loss = 0.00390371
Iteration 6109, loss = 0.00390273
Iteration 6110, loss = 0.00390207
Iteration 6111, loss = 0.00390116
Iteration 6112, loss = 0.00390017
Iteration 6113, loss = 0.00389948
Iteration 6114, loss = 0.00389850
Iteration 6115, loss = 0.00389767
Iteration 6116, loss = 0.00389692
Iteration 6117, loss = 0.00389604
Iteration 6118, loss = 0.00389511
Iteration 6119, loss = 0.00389432
Iteration 6120, loss = 0.00389342
Iteration 6121, loss = 0.00389318
Iteration 6122, loss = 0.00389199
Iteration 6123, loss = 0.00389139
Iteration 6124, loss = 0.00389039
Iteration 6125, loss = 0.00388960
Iteration 6126, loss = 0.00388868
Iteration 6127, loss = 0.00388781
Iteration 6128, loss = 0.00388696
Iteration 6129, loss = 0.00388598
Iteration 6130, loss = 0.00388559
Iteration 6131, loss = 0.00388440
Iteration 6132, loss = 0.00388331
Iteration 6133, loss = 0.00388230
Iteration 6134, loss = 0.00388152
Iteration 6135, loss = 0.00388030
Iteration 6136, loss = 0.00387956
Iteration 6137, loss = 0.00387861
Iteration 6138, loss = 0.00387760
Iteration 6139, loss = 0.00387683
Iteration 6140, loss = 0.00387598
Iteration 6141, loss = 0.00387497
Iteration 6142, loss = 0.00387401
Iteration 6143, loss = 0.00387337
Iteration 6144, loss = 0.00387213
Iteration 6145, loss = 0.00387142
Iteration 6146, loss = 0.00387069
Iteration 6147, loss = 0.00386964
Iteration 6148, loss = 0.00386873
Iteration 6149, loss = 0.00386784
Iteration 6150, loss = 0.00386700
Iteration 6151, loss = 0.00386618
Iteration 6152, loss = 0.00386540
Iteration 6153, loss = 0.00386455
Iteration 6154, loss = 0.00386372
Iteration 6155, loss = 0.00386296
Iteration 6156, loss = 0.00386201
Iteration 6157, loss = 0.00386114
Iteration 6158, loss = 0.00386025
Iteration 6159, loss = 0.00385944
Iteration 6160, loss = 0.00385857
Iteration 6161, loss = 0.00385738
Iteration 6162, loss = 0.00385641
Iteration 6163, loss = 0.00385542
Iteration 6164, loss = 0.00385527
Iteration 6165, loss = 0.00385360
Iteration 6166, loss = 0.00385275
Iteration 6167, loss = 0.00385208
Iteration 6168, loss = 0.00385131
Iteration 6169, loss = 0.00385036
Iteration 6170, loss = 0.00384925
Iteration 6171, loss = 0.00384829
Iteration 6172, loss = 0.00384764
Iteration 6173, loss = 0.00384649
Iteration 6174, loss = 0.00384578
Iteration 6175, loss = 0.00384462
Iteration 6176, loss = 0.00384395
Iteration 6177, loss = 0.00384288
Iteration 6178, loss = 0.00384198
Iteration 6179, loss = 0.00384101
Iteration 6180, loss = 0.00384026
Iteration 6181, loss = 0.00383939
Iteration 6182, loss = 0.00383835
Iteration 6183, loss = 0.00383761
Iteration 6184, loss = 0.00383667
Iteration 6185, loss = 0.00383568
Iteration 6186, loss = 0.00383488
Iteration 6187, loss = 0.00383411
Iteration 6188, loss = 0.00383356
Iteration 6189, loss = 0.00383257
Iteration 6190, loss = 0.00383182
Iteration 6191, loss = 0.00383097
Iteration 6192, loss = 0.00383040
Iteration 6193, loss = 0.00382954
Iteration 6194, loss = 0.00382867
Iteration 6195, loss = 0.00382781
Iteration 6196, loss = 0.00382712
Iteration 6197, loss = 0.00382619
Iteration 6198, loss = 0.00382540
Iteration 6199, loss = 0.00382464
Iteration 6200, loss = 0.00382413
Iteration 6201, loss = 0.00382333
Iteration 6202, loss = 0.00382246
Iteration 6203, loss = 0.00382151
Iteration 6204, loss = 0.00382075
Iteration 6205, loss = 0.00381998
Iteration 6206, loss = 0.00381904
Iteration 6207, loss = 0.00381821
Iteration 6208, loss = 0.00381754
Iteration 6209, loss = 0.00381659
Iteration 6210, loss = 0.00381594
Iteration 6211, loss = 0.00381507
Iteration 6212, loss = 0.00381433
Iteration 6213, loss = 0.00381356
Iteration 6214, loss = 0.00381290
Iteration 6215, loss = 0.00381201
Iteration 6216, loss = 0.00381112
Iteration 6217, loss = 0.00381023
Iteration 6218, loss = 0.00380959
Iteration 6219, loss = 0.00380853
Iteration 6220, loss = 0.00380800
Iteration 6221, loss = 0.00380720
Iteration 6222, loss = 0.00380654
Iteration 6223, loss = 0.00380534
Iteration 6224, loss = 0.00380454
Iteration 6225, loss = 0.00380351
Iteration 6226, loss = 0.00380232
Iteration 6227, loss = 0.00380192
Iteration 6228, loss = 0.00380035
Iteration 6229, loss = 0.00379995
Iteration 6230, loss = 0.00379868
Iteration 6231, loss = 0.00379777
Iteration 6232, loss = 0.00379675
Iteration 6233, loss = 0.00379579
Iteration 6234, loss = 0.00379482
Iteration 6235, loss = 0.00379388
Iteration 6236, loss = 0.00379324
Iteration 6237, loss = 0.00379216
Iteration 6238, loss = 0.00379121
Iteration 6239, loss = 0.00379044
Iteration 6240, loss = 0.00378953
Iteration 6241, loss = 0.00378875
Iteration 6242, loss = 0.00378798
Iteration 6243, loss = 0.00378723
Iteration 6244, loss = 0.00378647
Iteration 6245, loss = 0.00378574
Iteration 6246, loss = 0.00378494
Iteration 6247, loss = 0.00378419
Iteration 6248, loss = 0.00378353
Iteration 6249, loss = 0.00378270
Iteration 6250, loss = 0.00378182
Iteration 6251, loss = 0.00378101
Iteration 6252, loss = 0.00378025
Iteration 6253, loss = 0.00377924
Iteration 6254, loss = 0.00377840
Iteration 6255, loss = 0.00377765
Iteration 6256, loss = 0.00377664
Iteration 6257, loss = 0.00377634
Iteration 6258, loss = 0.00377507
Iteration 6259, loss = 0.00377415
Iteration 6260, loss = 0.00377330
Iteration 6261, loss = 0.00377240
Iteration 6262, loss = 0.00377147
Iteration 6263, loss = 0.00377052
Iteration 6264, loss = 0.00376981
Iteration 6265, loss = 0.00376877
Iteration 6266, loss = 0.00376808
Iteration 6267, loss = 0.00376698
Iteration 6268, loss = 0.00376612
Iteration 6269, loss = 0.00376526
Iteration 6270, loss = 0.00376432
Iteration 6271, loss = 0.00376353
Iteration 6272, loss = 0.00376265
Iteration 6273, loss = 0.00376191
Iteration 6274, loss = 0.00376084
Iteration 6275, loss = 0.00375996
Iteration 6276, loss = 0.00375909
Iteration 6277, loss = 0.00375804
Iteration 6278, loss = 0.00375721
Iteration 6279, loss = 0.00375649
Iteration 6280, loss = 0.00375548
Iteration 6281, loss = 0.00375478
Iteration 6282, loss = 0.00375397
Iteration 6283, loss = 0.00375316
Iteration 6284, loss = 0.00375246
Iteration 6285, loss = 0.00375163
Iteration 6286, loss = 0.00375086
Iteration 6287, loss = 0.00375044
Iteration 6288, loss = 0.00374948
Iteration 6289, loss = 0.00374868
Iteration 6290, loss = 0.00374771
Iteration 6291, loss = 0.00374675
Iteration 6292, loss = 0.00374596
Iteration 6293, loss = 0.00374517
Iteration 6294, loss = 0.00374442
Iteration 6295, loss = 0.00374340
Iteration 6296, loss = 0.00374243
Iteration 6297, loss = 0.00374185
Iteration 6298, loss = 0.00374065
Iteration 6299, loss = 0.00374046
Iteration 6300, loss = 0.00373920
Iteration 6301, loss = 0.00373821
Iteration 6302, loss = 0.00373755
Iteration 6303, loss = 0.00373668
Iteration 6304, loss = 0.00373555
Iteration 6305, loss = 0.00373494
Iteration 6306, loss = 0.00373378
Iteration 6307, loss = 0.00373327
Iteration 6308, loss = 0.00373209
Iteration 6309, loss = 0.00373124
Iteration 6310, loss = 0.00373059
Iteration 6311, loss = 0.00372972
Iteration 6312, loss = 0.00372884
Iteration 6313, loss = 0.00372848
Iteration 6314, loss = 0.00372720
Iteration 6315, loss = 0.00372652
Iteration 6316, loss = 0.00372551
Iteration 6317, loss = 0.00372470
Iteration 6318, loss = 0.00372385
Iteration 6319, loss = 0.00372327
Iteration 6320, loss = 0.00372223
Iteration 6321, loss = 0.00372138
Iteration 6322, loss = 0.00372049
Iteration 6323, loss = 0.00371972
Iteration 6324, loss = 0.00371871
Iteration 6325, loss = 0.00371826
Iteration 6326, loss = 0.00371710
Iteration 6327, loss = 0.00371629
Iteration 6328, loss = 0.00371544
Iteration 6329, loss = 0.00371462
Iteration 6330, loss = 0.00371421
Iteration 6331, loss = 0.00371304
Iteration 6332, loss = 0.00371226
Iteration 6333, loss = 0.00371147
Iteration 6334, loss = 0.00371068
Iteration 6335, loss = 0.00370995
Iteration 6336, loss = 0.00370919
Iteration 6337, loss = 0.00370839
Iteration 6338, loss = 0.00370765
Iteration 6339, loss = 0.00370704
Iteration 6340, loss = 0.00370608
Iteration 6341, loss = 0.00370521
Iteration 6342, loss = 0.00370448
Iteration 6343, loss = 0.00370381
Iteration 6344, loss = 0.00370297
Iteration 6345, loss = 0.00370196
Iteration 6346, loss = 0.00370131
Iteration 6347, loss = 0.00370047
Iteration 6348, loss = 0.00369959
Iteration 6349, loss = 0.00369895
Iteration 6350, loss = 0.00369814
Iteration 6351, loss = 0.00369726
Iteration 6352, loss = 0.00369657
Iteration 6353, loss = 0.00369572
Iteration 6354, loss = 0.00369496
Iteration 6355, loss = 0.00369425
Iteration 6356, loss = 0.00369341
Iteration 6357, loss = 0.00369269
Iteration 6358, loss = 0.00369176
Iteration 6359, loss = 0.00369105
Iteration 6360, loss = 0.00369015
Iteration 6361, loss = 0.00368941
Iteration 6362, loss = 0.00368870
Iteration 6363, loss = 0.00368780
Iteration 6364, loss = 0.00368698
Iteration 6365, loss = 0.00368682
Iteration 6366, loss = 0.00368527
Iteration 6367, loss = 0.00368458
Iteration 6368, loss = 0.00368361
Iteration 6369, loss = 0.00368281
Iteration 6370, loss = 0.00368239
Iteration 6371, loss = 0.00368187
Iteration 6372, loss = 0.00368076
Iteration 6373, loss = 0.00368001
Iteration 6374, loss = 0.00367944
Iteration 6375, loss = 0.00367886
Iteration 6376, loss = 0.00367790
Iteration 6377, loss = 0.00367728
Iteration 6378, loss = 0.00367628
Iteration 6379, loss = 0.00367540
Iteration 6380, loss = 0.00367448
Iteration 6381, loss = 0.00367392
Iteration 6382, loss = 0.00367289
Iteration 6383, loss = 0.00367209
Iteration 6384, loss = 0.00367138
Iteration 6385, loss = 0.00367063
Iteration 6386, loss = 0.00366999
Iteration 6387, loss = 0.00366903
Iteration 6388, loss = 0.00366818
Iteration 6389, loss = 0.00366731
Iteration 6390, loss = 0.00366663
Iteration 6391, loss = 0.00366583
Iteration 6392, loss = 0.00366484
Iteration 6393, loss = 0.00366389
Iteration 6394, loss = 0.00366297
Iteration 6395, loss = 0.00366219
Iteration 6396, loss = 0.00366137
Iteration 6397, loss = 0.00366048
Iteration 6398, loss = 0.00365990
Iteration 6399, loss = 0.00365909
Iteration 6400, loss = 0.00365838
Iteration 6401, loss = 0.00365787
Iteration 6402, loss = 0.00365701
Iteration 6403, loss = 0.00365608
Iteration 6404, loss = 0.00365537
Iteration 6405, loss = 0.00365483
Iteration 6406, loss = 0.00365410
Iteration 6407, loss = 0.00365342
Iteration 6408, loss = 0.00365273
Iteration 6409, loss = 0.00365214
Iteration 6410, loss = 0.00365185
Iteration 6411, loss = 0.00365074
Iteration 6412, loss = 0.00365000
Iteration 6413, loss = 0.00364923
Iteration 6414, loss = 0.00364846
Iteration 6415, loss = 0.00364778
Iteration 6416, loss = 0.00364697
Iteration 6417, loss = 0.00364642
Iteration 6418, loss = 0.00364530
Iteration 6419, loss = 0.00364475
Iteration 6420, loss = 0.00364384
Iteration 6421, loss = 0.00364274
Iteration 6422, loss = 0.00364199
Iteration 6423, loss = 0.00364085
Iteration 6424, loss = 0.00364018
Iteration 6425, loss = 0.00363911
Iteration 6426, loss = 0.00363818
Iteration 6427, loss = 0.00363736
Iteration 6428, loss = 0.00363642
Iteration 6429, loss = 0.00363594
Iteration 6430, loss = 0.00363496
Iteration 6431, loss = 0.00363419
Iteration 6432, loss = 0.00363334
Iteration 6433, loss = 0.00363243
Iteration 6434, loss = 0.00363184
Iteration 6435, loss = 0.00363099
Iteration 6436, loss = 0.00363045
Iteration 6437, loss = 0.00362911
Iteration 6438, loss = 0.00362818
Iteration 6439, loss = 0.00362715
Iteration 6440, loss = 0.00362642
Iteration 6441, loss = 0.00362540
Iteration 6442, loss = 0.00362447
Iteration 6443, loss = 0.00362348
Iteration 6444, loss = 0.00362258
Iteration 6445, loss = 0.00362155
Iteration 6446, loss = 0.00362133
Iteration 6447, loss = 0.00361990
Iteration 6448, loss = 0.00361894
Iteration 6449, loss = 0.00361837
Iteration 6450, loss = 0.00361757
Iteration 6451, loss = 0.00361650
Iteration 6452, loss = 0.00361579
Iteration 6453, loss = 0.00361501
Iteration 6454, loss = 0.00361428
Iteration 6455, loss = 0.00361354
Iteration 6456, loss = 0.00361298
Iteration 6457, loss = 0.00361217
Iteration 6458, loss = 0.00361150
Iteration 6459, loss = 0.00361082
Iteration 6460, loss = 0.00361003
Iteration 6461, loss = 0.00360947
Iteration 6462, loss = 0.00360861
Iteration 6463, loss = 0.00360795
Iteration 6464, loss = 0.00360707
Iteration 6465, loss = 0.00360626
Iteration 6466, loss = 0.00360550
Iteration 6467, loss = 0.00360572
Iteration 6468, loss = 0.00360418
Iteration 6469, loss = 0.00360347
Iteration 6470, loss = 0.00360271
Iteration 6471, loss = 0.00360217
Iteration 6472, loss = 0.00360112
Iteration 6473, loss = 0.00360085
Iteration 6474, loss = 0.00359948
Iteration 6475, loss = 0.00359886
Iteration 6476, loss = 0.00359844
Iteration 6477, loss = 0.00359727
Iteration 6478, loss = 0.00359653
Iteration 6479, loss = 0.00359573
Iteration 6480, loss = 0.00359493
Iteration 6481, loss = 0.00359406
Iteration 6482, loss = 0.00359343
Iteration 6483, loss = 0.00359279
Iteration 6484, loss = 0.00359228
Iteration 6485, loss = 0.00359126
Iteration 6486, loss = 0.00359054
Iteration 6487, loss = 0.00358970
Iteration 6488, loss = 0.00358903
Iteration 6489, loss = 0.00358816
Iteration 6490, loss = 0.00358729
Iteration 6491, loss = 0.00358629
Iteration 6492, loss = 0.00358532
Iteration 6493, loss = 0.00358446
Iteration 6494, loss = 0.00358398
Iteration 6495, loss = 0.00358292
Iteration 6496, loss = 0.00358206
Iteration 6497, loss = 0.00358159
Iteration 6498, loss = 0.00358058
Iteration 6499, loss = 0.00357977
Iteration 6500, loss = 0.00357876
Iteration 6501, loss = 0.00357849
Iteration 6502, loss = 0.00357732
Iteration 6503, loss = 0.00357667
Iteration 6504, loss = 0.00357581
Iteration 6505, loss = 0.00357513
Iteration 6506, loss = 0.00357438
Iteration 6507, loss = 0.00357377
Iteration 6508, loss = 0.00357306
Iteration 6509, loss = 0.00357226
Iteration 6510, loss = 0.00357157
Iteration 6511, loss = 0.00357086
Iteration 6512, loss = 0.00357010
Iteration 6513, loss = 0.00356946
Iteration 6514, loss = 0.00356865
Iteration 6515, loss = 0.00356791
Iteration 6516, loss = 0.00356723
Iteration 6517, loss = 0.00356684
Iteration 6518, loss = 0.00356586
Iteration 6519, loss = 0.00356513
Iteration 6520, loss = 0.00356430
Iteration 6521, loss = 0.00356345
Iteration 6522, loss = 0.00356295
Iteration 6523, loss = 0.00356218
Iteration 6524, loss = 0.00356117
Iteration 6525, loss = 0.00356039
Iteration 6526, loss = 0.00355970
Iteration 6527, loss = 0.00355889
Iteration 6528, loss = 0.00355828
Iteration 6529, loss = 0.00355739
Iteration 6530, loss = 0.00355694
Iteration 6531, loss = 0.00355584
Iteration 6532, loss = 0.00355499
Iteration 6533, loss = 0.00355428
Iteration 6534, loss = 0.00355344
Iteration 6535, loss = 0.00355267
Iteration 6536, loss = 0.00355196
Iteration 6537, loss = 0.00355106
Iteration 6538, loss = 0.00355034
Iteration 6539, loss = 0.00354950
Iteration 6540, loss = 0.00354875
Iteration 6541, loss = 0.00354810
Iteration 6542, loss = 0.00354729
Iteration 6543, loss = 0.00354642
Iteration 6544, loss = 0.00354567
Iteration 6545, loss = 0.00354499
Iteration 6546, loss = 0.00354435
Iteration 6547, loss = 0.00354345
Iteration 6548, loss = 0.00354272
Iteration 6549, loss = 0.00354192
Iteration 6550, loss = 0.00354119
Iteration 6551, loss = 0.00354047
Iteration 6552, loss = 0.00353975
Iteration 6553, loss = 0.00353892
Iteration 6554, loss = 0.00353812
Iteration 6555, loss = 0.00353732
Iteration 6556, loss = 0.00353660
Iteration 6557, loss = 0.00353579
Iteration 6558, loss = 0.00353502
Iteration 6559, loss = 0.00353444
Iteration 6560, loss = 0.00353358
Iteration 6561, loss = 0.00353254
Iteration 6562, loss = 0.00353192
Iteration 6563, loss = 0.00353098
Iteration 6564, loss = 0.00353057
Iteration 6565, loss = 0.00352949
Iteration 6566, loss = 0.00352868
Iteration 6567, loss = 0.00352794
Iteration 6568, loss = 0.00352721
Iteration 6569, loss = 0.00352650
Iteration 6570, loss = 0.00352572
Iteration 6571, loss = 0.00352503
Iteration 6572, loss = 0.00352443
Iteration 6573, loss = 0.00352363
Iteration 6574, loss = 0.00352292
Iteration 6575, loss = 0.00352207
Iteration 6576, loss = 0.00352148
Iteration 6577, loss = 0.00352070
Iteration 6578, loss = 0.00351986
Iteration 6579, loss = 0.00351907
Iteration 6580, loss = 0.00351835
Iteration 6581, loss = 0.00351761
Iteration 6582, loss = 0.00351689
Iteration 6583, loss = 0.00351629
Iteration 6584, loss = 0.00351550
Iteration 6585, loss = 0.00351472
Iteration 6586, loss = 0.00351384
Iteration 6587, loss = 0.00351307
Iteration 6588, loss = 0.00351266
Iteration 6589, loss = 0.00351178
Iteration 6590, loss = 0.00351102
Iteration 6591, loss = 0.00351041
Iteration 6592, loss = 0.00350960
Iteration 6593, loss = 0.00350921
Iteration 6594, loss = 0.00350834
Iteration 6595, loss = 0.00350755
Iteration 6596, loss = 0.00350694
Iteration 6597, loss = 0.00350628
Iteration 6598, loss = 0.00350563
Iteration 6599, loss = 0.00350471
Iteration 6600, loss = 0.00350384
Iteration 6601, loss = 0.00350306
Iteration 6602, loss = 0.00350228
Iteration 6603, loss = 0.00350135
Iteration 6604, loss = 0.00350058
Iteration 6605, loss = 0.00349980
Iteration 6606, loss = 0.00349903
Iteration 6607, loss = 0.00349842
Iteration 6608, loss = 0.00349763
Iteration 6609, loss = 0.00349709
Iteration 6610, loss = 0.00349625
Iteration 6611, loss = 0.00349563
Iteration 6612, loss = 0.00349516
Iteration 6613, loss = 0.00349430
Iteration 6614, loss = 0.00349353
Iteration 6615, loss = 0.00349273
Iteration 6616, loss = 0.00349194
Iteration 6617, loss = 0.00349126
Iteration 6618, loss = 0.00349060
Iteration 6619, loss = 0.00348998
Iteration 6620, loss = 0.00348914
Iteration 6621, loss = 0.00348840
Iteration 6622, loss = 0.00348767
Iteration 6623, loss = 0.00348683
Iteration 6624, loss = 0.00348613
Iteration 6625, loss = 0.00348536
Iteration 6626, loss = 0.00348481
Iteration 6627, loss = 0.00348399
Iteration 6628, loss = 0.00348299
Iteration 6629, loss = 0.00348214
Iteration 6630, loss = 0.00348157
Iteration 6631, loss = 0.00348108
Iteration 6632, loss = 0.00348010
Iteration 6633, loss = 0.00347915
Iteration 6634, loss = 0.00347833
Iteration 6635, loss = 0.00347763
Iteration 6636, loss = 0.00347675
Iteration 6637, loss = 0.00347617
Iteration 6638, loss = 0.00347528
Iteration 6639, loss = 0.00347445
Iteration 6640, loss = 0.00347370
Iteration 6641, loss = 0.00347303
Iteration 6642, loss = 0.00347240
Iteration 6643, loss = 0.00347155
Iteration 6644, loss = 0.00347104
Iteration 6645, loss = 0.00347039
Iteration 6646, loss = 0.00346957
Iteration 6647, loss = 0.00346891
Iteration 6648, loss = 0.00346825
Iteration 6649, loss = 0.00346749
Iteration 6650, loss = 0.00346681
Iteration 6651, loss = 0.00346626
Iteration 6652, loss = 0.00346544
Iteration 6653, loss = 0.00346479
Iteration 6654, loss = 0.00346433
Iteration 6655, loss = 0.00346341
Iteration 6656, loss = 0.00346265
Iteration 6657, loss = 0.00346201
Iteration 6658, loss = 0.00346136
Iteration 6659, loss = 0.00346049
Iteration 6660, loss = 0.00345978
Iteration 6661, loss = 0.00345906
Iteration 6662, loss = 0.00345830
Iteration 6663, loss = 0.00345757
Iteration 6664, loss = 0.00345681
Iteration 6665, loss = 0.00345619
Iteration 6666, loss = 0.00345526
Iteration 6667, loss = 0.00345470
Iteration 6668, loss = 0.00345396
Iteration 6669, loss = 0.00345310
Iteration 6670, loss = 0.00345237
Iteration 6671, loss = 0.00345166
Iteration 6672, loss = 0.00345095
Iteration 6673, loss = 0.00345017
Iteration 6674, loss = 0.00344950
Iteration 6675, loss = 0.00344880
Iteration 6676, loss = 0.00344799
Iteration 6677, loss = 0.00344727
Iteration 6678, loss = 0.00344663
Iteration 6679, loss = 0.00344578
Iteration 6680, loss = 0.00344504
Iteration 6681, loss = 0.00344451
Iteration 6682, loss = 0.00344358
Iteration 6683, loss = 0.00344289
Iteration 6684, loss = 0.00344221
Iteration 6685, loss = 0.00344147
Iteration 6686, loss = 0.00344081
Iteration 6687, loss = 0.00344028
Iteration 6688, loss = 0.00343945
Iteration 6689, loss = 0.00343894
Iteration 6690, loss = 0.00343823
Iteration 6691, loss = 0.00343752
Iteration 6692, loss = 0.00343696
Iteration 6693, loss = 0.00343630
Iteration 6694, loss = 0.00343571
Iteration 6695, loss = 0.00343493
Iteration 6696, loss = 0.00343434
Iteration 6697, loss = 0.00343376
Iteration 6698, loss = 0.00343303
Iteration 6699, loss = 0.00343251
Iteration 6700, loss = 0.00343159
Iteration 6701, loss = 0.00343090
Iteration 6702, loss = 0.00343005
Iteration 6703, loss = 0.00342939
Iteration 6704, loss = 0.00342874
Iteration 6705, loss = 0.00342788
Iteration 6706, loss = 0.00342720
Iteration 6707, loss = 0.00342643
Iteration 6708, loss = 0.00342570
Iteration 6709, loss = 0.00342499
Iteration 6710, loss = 0.00342426
Iteration 6711, loss = 0.00342388
Iteration 6712, loss = 0.00342275
Iteration 6713, loss = 0.00342199
Iteration 6714, loss = 0.00342128
Iteration 6715, loss = 0.00342055
Iteration 6716, loss = 0.00342006
Iteration 6717, loss = 0.00341913
Iteration 6718, loss = 0.00341859
Iteration 6719, loss = 0.00341773
Iteration 6720, loss = 0.00341696
Iteration 6721, loss = 0.00341620
Iteration 6722, loss = 0.00341552
Iteration 6723, loss = 0.00341480
Iteration 6724, loss = 0.00341396
Iteration 6725, loss = 0.00341327
Iteration 6726, loss = 0.00341256
Iteration 6727, loss = 0.00341200
Iteration 6728, loss = 0.00341110
Iteration 6729, loss = 0.00341060
Iteration 6730, loss = 0.00340976
Iteration 6731, loss = 0.00340926
Iteration 6732, loss = 0.00340840
Iteration 6733, loss = 0.00340754
Iteration 6734, loss = 0.00340672
Iteration 6735, loss = 0.00340602
Iteration 6736, loss = 0.00340519
Iteration 6737, loss = 0.00340460
Iteration 6738, loss = 0.00340373
Iteration 6739, loss = 0.00340296
Iteration 6740, loss = 0.00340230
Iteration 6741, loss = 0.00340155
Iteration 6742, loss = 0.00340085
Iteration 6743, loss = 0.00340029
Iteration 6744, loss = 0.00339956
Iteration 6745, loss = 0.00339873
Iteration 6746, loss = 0.00339813
Iteration 6747, loss = 0.00339728
Iteration 6748, loss = 0.00339664
Iteration 6749, loss = 0.00339643
Iteration 6750, loss = 0.00339508
Iteration 6751, loss = 0.00339420
Iteration 6752, loss = 0.00339371
Iteration 6753, loss = 0.00339285
Iteration 6754, loss = 0.00339204
Iteration 6755, loss = 0.00339137
Iteration 6756, loss = 0.00339070
Iteration 6757, loss = 0.00339003
Iteration 6758, loss = 0.00338934
Iteration 6759, loss = 0.00338867
Iteration 6760, loss = 0.00338800
Iteration 6761, loss = 0.00338746
Iteration 6762, loss = 0.00338681
Iteration 6763, loss = 0.00338632
Iteration 6764, loss = 0.00338531
Iteration 6765, loss = 0.00338470
Iteration 6766, loss = 0.00338396
Iteration 6767, loss = 0.00338334
Iteration 6768, loss = 0.00338255
Iteration 6769, loss = 0.00338205
Iteration 6770, loss = 0.00338134
Iteration 6771, loss = 0.00338077
Iteration 6772, loss = 0.00337997
Iteration 6773, loss = 0.00337931
Iteration 6774, loss = 0.00337862
Iteration 6775, loss = 0.00337809
Iteration 6776, loss = 0.00337749
Iteration 6777, loss = 0.00337660
Iteration 6778, loss = 0.00337605
Iteration 6779, loss = 0.00337520
Iteration 6780, loss = 0.00337450
Iteration 6781, loss = 0.00337391
Iteration 6782, loss = 0.00337309
Iteration 6783, loss = 0.00337251
Iteration 6784, loss = 0.00337175
Iteration 6785, loss = 0.00337117
Iteration 6786, loss = 0.00337037
Iteration 6787, loss = 0.00336953
Iteration 6788, loss = 0.00336916
Iteration 6789, loss = 0.00336826
Iteration 6790, loss = 0.00336774
Iteration 6791, loss = 0.00336674
Iteration 6792, loss = 0.00336611
Iteration 6793, loss = 0.00336555
Iteration 6794, loss = 0.00336487
Iteration 6795, loss = 0.00336412
Iteration 6796, loss = 0.00336345
Iteration 6797, loss = 0.00336266
Iteration 6798, loss = 0.00336201
Iteration 6799, loss = 0.00336122
Iteration 6800, loss = 0.00336071
Iteration 6801, loss = 0.00335999
Iteration 6802, loss = 0.00335936
Iteration 6803, loss = 0.00335855
Iteration 6804, loss = 0.00335789
Iteration 6805, loss = 0.00335731
Iteration 6806, loss = 0.00335689
Iteration 6807, loss = 0.00335603
Iteration 6808, loss = 0.00335550
Iteration 6809, loss = 0.00335485
Iteration 6810, loss = 0.00335401
Iteration 6811, loss = 0.00335331
Iteration 6812, loss = 0.00335273
Iteration 6813, loss = 0.00335194
Iteration 6814, loss = 0.00335116
Iteration 6815, loss = 0.00335043
Iteration 6816, loss = 0.00334973
Iteration 6817, loss = 0.00334910
Iteration 6818, loss = 0.00334830
Iteration 6819, loss = 0.00334751
Iteration 6820, loss = 0.00334680
Iteration 6821, loss = 0.00334597
Iteration 6822, loss = 0.00334512
Iteration 6823, loss = 0.00334443
Iteration 6824, loss = 0.00334381
Iteration 6825, loss = 0.00334323
Iteration 6826, loss = 0.00334243
Iteration 6827, loss = 0.00334159
Iteration 6828, loss = 0.00334112
Iteration 6829, loss = 0.00334021
Iteration 6830, loss = 0.00333959
Iteration 6831, loss = 0.00333886
Iteration 6832, loss = 0.00333816
Iteration 6833, loss = 0.00333712
Iteration 6834, loss = 0.00333636
Iteration 6835, loss = 0.00333542
Iteration 6836, loss = 0.00333464
Iteration 6837, loss = 0.00333376
Iteration 6838, loss = 0.00333290
Iteration 6839, loss = 0.00333244
Iteration 6840, loss = 0.00333151
Iteration 6841, loss = 0.00333091
Iteration 6842, loss = 0.00332999
Iteration 6843, loss = 0.00332930
Iteration 6844, loss = 0.00332858
Iteration 6845, loss = 0.00332778
Iteration 6846, loss = 0.00332700
Iteration 6847, loss = 0.00332598
Iteration 6848, loss = 0.00332567
Iteration 6849, loss = 0.00332444
Iteration 6850, loss = 0.00332370
Iteration 6851, loss = 0.00332292
Iteration 6852, loss = 0.00332212
Iteration 6853, loss = 0.00332144
Iteration 6854, loss = 0.00332072
Iteration 6855, loss = 0.00331994
Iteration 6856, loss = 0.00331924
Iteration 6857, loss = 0.00331847
Iteration 6858, loss = 0.00331776
Iteration 6859, loss = 0.00331709
Iteration 6860, loss = 0.00331639
Iteration 6861, loss = 0.00331579
Iteration 6862, loss = 0.00331525
Iteration 6863, loss = 0.00331440
Iteration 6864, loss = 0.00331355
Iteration 6865, loss = 0.00331286
Iteration 6866, loss = 0.00331222
Iteration 6867, loss = 0.00331149
Iteration 6868, loss = 0.00331087
Iteration 6869, loss = 0.00331029
Iteration 6870, loss = 0.00330956
Iteration 6871, loss = 0.00330892
Iteration 6872, loss = 0.00330851
Iteration 6873, loss = 0.00330760
Iteration 6874, loss = 0.00330694
Iteration 6875, loss = 0.00330636
Iteration 6876, loss = 0.00330579
Iteration 6877, loss = 0.00330514
Iteration 6878, loss = 0.00330453
Iteration 6879, loss = 0.00330396
Iteration 6880, loss = 0.00330346
Iteration 6881, loss = 0.00330290
Iteration 6882, loss = 0.00330218
Iteration 6883, loss = 0.00330166
Iteration 6884, loss = 0.00330095
Iteration 6885, loss = 0.00330042
Iteration 6886, loss = 0.00329983
Iteration 6887, loss = 0.00329926
Iteration 6888, loss = 0.00329843
Iteration 6889, loss = 0.00329779
Iteration 6890, loss = 0.00329722
Iteration 6891, loss = 0.00329651
Iteration 6892, loss = 0.00329572
Iteration 6893, loss = 0.00329529
Iteration 6894, loss = 0.00329458
Iteration 6895, loss = 0.00329388
Iteration 6896, loss = 0.00329327
Iteration 6897, loss = 0.00329282
Iteration 6898, loss = 0.00329190
Iteration 6899, loss = 0.00329126
Iteration 6900, loss = 0.00329052
Iteration 6901, loss = 0.00328992
Iteration 6902, loss = 0.00328942
Iteration 6903, loss = 0.00328885
Iteration 6904, loss = 0.00328795
Iteration 6905, loss = 0.00328735
Iteration 6906, loss = 0.00328658
Iteration 6907, loss = 0.00328608
Iteration 6908, loss = 0.00328522
Iteration 6909, loss = 0.00328461
Iteration 6910, loss = 0.00328415
Iteration 6911, loss = 0.00328325
Iteration 6912, loss = 0.00328241
Iteration 6913, loss = 0.00328183
Iteration 6914, loss = 0.00328125
Iteration 6915, loss = 0.00328054
Iteration 6916, loss = 0.00327969
Iteration 6917, loss = 0.00327915
Iteration 6918, loss = 0.00327838
Iteration 6919, loss = 0.00327760
Iteration 6920, loss = 0.00327692
Iteration 6921, loss = 0.00327621
Iteration 6922, loss = 0.00327547
Iteration 6923, loss = 0.00327484
Iteration 6924, loss = 0.00327412
Iteration 6925, loss = 0.00327374
Iteration 6926, loss = 0.00327271
Iteration 6927, loss = 0.00327203
Iteration 6928, loss = 0.00327153
Iteration 6929, loss = 0.00327041
Iteration 6930, loss = 0.00326977
Iteration 6931, loss = 0.00326896
Iteration 6932, loss = 0.00326832
Iteration 6933, loss = 0.00326765
Iteration 6934, loss = 0.00326700
Iteration 6935, loss = 0.00326637
Iteration 6936, loss = 0.00326569
Iteration 6937, loss = 0.00326507
Iteration 6938, loss = 0.00326444
Iteration 6939, loss = 0.00326376
Iteration 6940, loss = 0.00326303
Iteration 6941, loss = 0.00326256
Iteration 6942, loss = 0.00326186
Iteration 6943, loss = 0.00326140
Iteration 6944, loss = 0.00326105
Iteration 6945, loss = 0.00326018
Iteration 6946, loss = 0.00325972
Iteration 6947, loss = 0.00325893
Iteration 6948, loss = 0.00325824
Iteration 6949, loss = 0.00325756
Iteration 6950, loss = 0.00325701
Iteration 6951, loss = 0.00325625
Iteration 6952, loss = 0.00325571
Iteration 6953, loss = 0.00325506
Iteration 6954, loss = 0.00325448
Iteration 6955, loss = 0.00325376
Iteration 6956, loss = 0.00325315
Iteration 6957, loss = 0.00325254
Iteration 6958, loss = 0.00325192
Iteration 6959, loss = 0.00325137
Iteration 6960, loss = 0.00325076
Iteration 6961, loss = 0.00325015
Iteration 6962, loss = 0.00324958
Iteration 6963, loss = 0.00324900
Iteration 6964, loss = 0.00324839
Iteration 6965, loss = 0.00324780
Iteration 6966, loss = 0.00324726
Iteration 6967, loss = 0.00324654
Iteration 6968, loss = 0.00324605
Iteration 6969, loss = 0.00324610
Iteration 6970, loss = 0.00324506
Iteration 6971, loss = 0.00324433
Iteration 6972, loss = 0.00324365
Iteration 6973, loss = 0.00324291
Iteration 6974, loss = 0.00324234
Iteration 6975, loss = 0.00324161
Iteration 6976, loss = 0.00324094
Iteration 6977, loss = 0.00324033
Iteration 6978, loss = 0.00323956
Iteration 6979, loss = 0.00323887
Iteration 6980, loss = 0.00323833
Iteration 6981, loss = 0.00323745
Iteration 6982, loss = 0.00323679
Iteration 6983, loss = 0.00323628
Iteration 6984, loss = 0.00323547
Iteration 6985, loss = 0.00323476
Iteration 6986, loss = 0.00323397
Iteration 6987, loss = 0.00323333
Iteration 6988, loss = 0.00323250
Iteration 6989, loss = 0.00323183
Iteration 6990, loss = 0.00323123
Iteration 6991, loss = 0.00323035
Iteration 6992, loss = 0.00322962
Iteration 6993, loss = 0.00322907
Iteration 6994, loss = 0.00322819
Iteration 6995, loss = 0.00322745
Iteration 6996, loss = 0.00322675
Iteration 6997, loss = 0.00322610
Iteration 6998, loss = 0.00322562
Iteration 6999, loss = 0.00322479
Iteration 7000, loss = 0.00322424
Iteration 7001, loss = 0.00322349
Iteration 7002, loss = 0.00322285
Iteration 7003, loss = 0.00322222
Iteration 7004, loss = 0.00322160
Iteration 7005, loss = 0.00322111
Iteration 7006, loss = 0.00322018
Iteration 7007, loss = 0.00321959
Iteration 7008, loss = 0.00321892
Iteration 7009, loss = 0.00321839
Iteration 7010, loss = 0.00321759
Iteration 7011, loss = 0.00321722
Iteration 7012, loss = 0.00321635
Iteration 7013, loss = 0.00321597
Iteration 7014, loss = 0.00321513
Iteration 7015, loss = 0.00321450
Iteration 7016, loss = 0.00321399
Iteration 7017, loss = 0.00321338
Iteration 7018, loss = 0.00321279
Iteration 7019, loss = 0.00321218
Iteration 7020, loss = 0.00321167
Iteration 7021, loss = 0.00321114
Iteration 7022, loss = 0.00321050
Iteration 7023, loss = 0.00320991
Iteration 7024, loss = 0.00320945
Iteration 7025, loss = 0.00320883
Iteration 7026, loss = 0.00320816
Iteration 7027, loss = 0.00320769
Iteration 7028, loss = 0.00320704
Iteration 7029, loss = 0.00320654
Iteration 7030, loss = 0.00320580
Iteration 7031, loss = 0.00320510
Iteration 7032, loss = 0.00320447
Iteration 7033, loss = 0.00320410
Iteration 7034, loss = 0.00320324
Iteration 7035, loss = 0.00320265
Iteration 7036, loss = 0.00320202
Iteration 7037, loss = 0.00320133
Iteration 7038, loss = 0.00320075
Iteration 7039, loss = 0.00320021
Iteration 7040, loss = 0.00319960
Iteration 7041, loss = 0.00319891
Iteration 7042, loss = 0.00319845
Iteration 7043, loss = 0.00319775
Iteration 7044, loss = 0.00319713
Iteration 7045, loss = 0.00319653
Iteration 7046, loss = 0.00319592
Iteration 7047, loss = 0.00319541
Iteration 7048, loss = 0.00319504
Iteration 7049, loss = 0.00319422
Iteration 7050, loss = 0.00319411
Iteration 7051, loss = 0.00319304
Iteration 7052, loss = 0.00319236
Iteration 7053, loss = 0.00319170
Iteration 7054, loss = 0.00319113
Iteration 7055, loss = 0.00319046
Iteration 7056, loss = 0.00318981
Iteration 7057, loss = 0.00318898
Iteration 7058, loss = 0.00318826
Iteration 7059, loss = 0.00318748
Iteration 7060, loss = 0.00318685
Iteration 7061, loss = 0.00318612
Iteration 7062, loss = 0.00318603
Iteration 7063, loss = 0.00318479
Iteration 7064, loss = 0.00318413
Iteration 7065, loss = 0.00318342
Iteration 7066, loss = 0.00318278
Iteration 7067, loss = 0.00318222
Iteration 7068, loss = 0.00318153
Iteration 7069, loss = 0.00318092
Iteration 7070, loss = 0.00318030
Iteration 7071, loss = 0.00318007
Iteration 7072, loss = 0.00317916
Iteration 7073, loss = 0.00317849
Iteration 7074, loss = 0.00317784
Iteration 7075, loss = 0.00317726
Iteration 7076, loss = 0.00317665
Iteration 7077, loss = 0.00317602
Iteration 7078, loss = 0.00317539
Iteration 7079, loss = 0.00317468
Iteration 7080, loss = 0.00317405
Iteration 7081, loss = 0.00317342
Iteration 7082, loss = 0.00317297
Iteration 7083, loss = 0.00317222
Iteration 7084, loss = 0.00317164
Iteration 7085, loss = 0.00317106
Iteration 7086, loss = 0.00317058
Iteration 7087, loss = 0.00316997
Iteration 7088, loss = 0.00316915
Iteration 7089, loss = 0.00316839
Iteration 7090, loss = 0.00316788
Iteration 7091, loss = 0.00316716
Iteration 7092, loss = 0.00316647
Iteration 7093, loss = 0.00316591
Iteration 7094, loss = 0.00316517
Iteration 7095, loss = 0.00316453
Iteration 7096, loss = 0.00316384
Iteration 7097, loss = 0.00316320
Iteration 7098, loss = 0.00316259
Iteration 7099, loss = 0.00316189
Iteration 7100, loss = 0.00316120
Iteration 7101, loss = 0.00316102
Iteration 7102, loss = 0.00315993
Iteration 7103, loss = 0.00315933
Iteration 7104, loss = 0.00315872
Iteration 7105, loss = 0.00315810
Iteration 7106, loss = 0.00315752
Iteration 7107, loss = 0.00315692
Iteration 7108, loss = 0.00315640
Iteration 7109, loss = 0.00315574
Iteration 7110, loss = 0.00315519
Iteration 7111, loss = 0.00315459
Iteration 7112, loss = 0.00315396
Iteration 7113, loss = 0.00315334
Iteration 7114, loss = 0.00315277
Iteration 7115, loss = 0.00315220
Iteration 7116, loss = 0.00315162
Iteration 7117, loss = 0.00315100
Iteration 7118, loss = 0.00315061
Iteration 7119, loss = 0.00314978
Iteration 7120, loss = 0.00314932
Iteration 7121, loss = 0.00314875
Iteration 7122, loss = 0.00314813
Iteration 7123, loss = 0.00314739
Iteration 7124, loss = 0.00314663
Iteration 7125, loss = 0.00314597
Iteration 7126, loss = 0.00314531
Iteration 7127, loss = 0.00314458
Iteration 7128, loss = 0.00314406
Iteration 7129, loss = 0.00314336
Iteration 7130, loss = 0.00314268
Iteration 7131, loss = 0.00314209
Iteration 7132, loss = 0.00314156
Iteration 7133, loss = 0.00314087
Iteration 7134, loss = 0.00314040
Iteration 7135, loss = 0.00313968
Iteration 7136, loss = 0.00313916
Iteration 7137, loss = 0.00313845
Iteration 7138, loss = 0.00313786
Iteration 7139, loss = 0.00313732
Iteration 7140, loss = 0.00313676
Iteration 7141, loss = 0.00313625
Iteration 7142, loss = 0.00313554
Iteration 7143, loss = 0.00313507
Iteration 7144, loss = 0.00313459
Iteration 7145, loss = 0.00313400
Iteration 7146, loss = 0.00313342
Iteration 7147, loss = 0.00313309
Iteration 7148, loss = 0.00313245
Iteration 7149, loss = 0.00313197
Iteration 7150, loss = 0.00313159
Iteration 7151, loss = 0.00313102
Iteration 7152, loss = 0.00313057
Iteration 7153, loss = 0.00313023
Iteration 7154, loss = 0.00312935
Iteration 7155, loss = 0.00312874
Iteration 7156, loss = 0.00312821
Iteration 7157, loss = 0.00312764
Iteration 7158, loss = 0.00312698
Iteration 7159, loss = 0.00312639
Iteration 7160, loss = 0.00312598
Iteration 7161, loss = 0.00312516
Iteration 7162, loss = 0.00312452
Iteration 7163, loss = 0.00312395
Iteration 7164, loss = 0.00312315
Iteration 7165, loss = 0.00312261
Iteration 7166, loss = 0.00312196
Iteration 7167, loss = 0.00312132
Iteration 7168, loss = 0.00312081
Iteration 7169, loss = 0.00312010
Iteration 7170, loss = 0.00311969
Iteration 7171, loss = 0.00311896
Iteration 7172, loss = 0.00311852
Iteration 7173, loss = 0.00311777
Iteration 7174, loss = 0.00311716
Iteration 7175, loss = 0.00311650
Iteration 7176, loss = 0.00311584
Iteration 7177, loss = 0.00311518
Iteration 7178, loss = 0.00311461
Iteration 7179, loss = 0.00311401
Iteration 7180, loss = 0.00311317
Iteration 7181, loss = 0.00311258
Iteration 7182, loss = 0.00311191
Iteration 7183, loss = 0.00311158
Iteration 7184, loss = 0.00311076
Iteration 7185, loss = 0.00311005
Iteration 7186, loss = 0.00310957
Iteration 7187, loss = 0.00310907
Iteration 7188, loss = 0.00310820
Iteration 7189, loss = 0.00310764
Iteration 7190, loss = 0.00310704
Iteration 7191, loss = 0.00310662
Iteration 7192, loss = 0.00310567
Iteration 7193, loss = 0.00310509
Iteration 7194, loss = 0.00310451
Iteration 7195, loss = 0.00310388
Iteration 7196, loss = 0.00310316
Iteration 7197, loss = 0.00310250
Iteration 7198, loss = 0.00310169
Iteration 7199, loss = 0.00310127
Iteration 7200, loss = 0.00310047
Iteration 7201, loss = 0.00309970
Iteration 7202, loss = 0.00309915
Iteration 7203, loss = 0.00309848
Iteration 7204, loss = 0.00309763
Iteration 7205, loss = 0.00309700
Iteration 7206, loss = 0.00309624
Iteration 7207, loss = 0.00309565
Iteration 7208, loss = 0.00309496
Iteration 7209, loss = 0.00309444
Iteration 7210, loss = 0.00309378
Iteration 7211, loss = 0.00309307
Iteration 7212, loss = 0.00309267
Iteration 7213, loss = 0.00309185
Iteration 7214, loss = 0.00309121
Iteration 7215, loss = 0.00309071
Iteration 7216, loss = 0.00309015
Iteration 7217, loss = 0.00308959
Iteration 7218, loss = 0.00308897
Iteration 7219, loss = 0.00308837
Iteration 7220, loss = 0.00308786
Iteration 7221, loss = 0.00308727
Iteration 7222, loss = 0.00308673
Iteration 7223, loss = 0.00308609
Iteration 7224, loss = 0.00308555
Iteration 7225, loss = 0.00308510
Iteration 7226, loss = 0.00308462
Iteration 7227, loss = 0.00308401
Iteration 7228, loss = 0.00308342
Iteration 7229, loss = 0.00308288
Iteration 7230, loss = 0.00308236
Iteration 7231, loss = 0.00308183
Iteration 7232, loss = 0.00308131
Iteration 7233, loss = 0.00308076
Iteration 7234, loss = 0.00308016
Iteration 7235, loss = 0.00307953
Iteration 7236, loss = 0.00307889
Iteration 7237, loss = 0.00307839
Iteration 7238, loss = 0.00307795
Iteration 7239, loss = 0.00307724
Iteration 7240, loss = 0.00307660
Iteration 7241, loss = 0.00307620
Iteration 7242, loss = 0.00307548
Iteration 7243, loss = 0.00307494
Iteration 7244, loss = 0.00307456
Iteration 7245, loss = 0.00307379
Iteration 7246, loss = 0.00307311
Iteration 7247, loss = 0.00307271
Iteration 7248, loss = 0.00307206
Iteration 7249, loss = 0.00307162
Iteration 7250, loss = 0.00307084
Iteration 7251, loss = 0.00307028
Iteration 7252, loss = 0.00306974
Iteration 7253, loss = 0.00306917
Iteration 7254, loss = 0.00306853
Iteration 7255, loss = 0.00306794
Iteration 7256, loss = 0.00306731
Iteration 7257, loss = 0.00306682
Iteration 7258, loss = 0.00306652
Iteration 7259, loss = 0.00306577
Iteration 7260, loss = 0.00306528
Iteration 7261, loss = 0.00306455
Iteration 7262, loss = 0.00306419
Iteration 7263, loss = 0.00306350
Iteration 7264, loss = 0.00306274
Iteration 7265, loss = 0.00306227
Iteration 7266, loss = 0.00306152
Iteration 7267, loss = 0.00306090
Iteration 7268, loss = 0.00306041
Iteration 7269, loss = 0.00305981
Iteration 7270, loss = 0.00305916
Iteration 7271, loss = 0.00305868
Iteration 7272, loss = 0.00305811
Iteration 7273, loss = 0.00305753
Iteration 7274, loss = 0.00305702
Iteration 7275, loss = 0.00305634
Iteration 7276, loss = 0.00305582
Iteration 7277, loss = 0.00305544
Iteration 7278, loss = 0.00305467
Iteration 7279, loss = 0.00305416
Iteration 7280, loss = 0.00305359
Iteration 7281, loss = 0.00305291
Iteration 7282, loss = 0.00305225
Iteration 7283, loss = 0.00305178
Iteration 7284, loss = 0.00305110
Iteration 7285, loss = 0.00305050
Iteration 7286, loss = 0.00304987
Iteration 7287, loss = 0.00304928
Iteration 7288, loss = 0.00304866
Iteration 7289, loss = 0.00304840
Iteration 7290, loss = 0.00304755
Iteration 7291, loss = 0.00304720
Iteration 7292, loss = 0.00304652
Iteration 7293, loss = 0.00304573
Iteration 7294, loss = 0.00304504
Iteration 7295, loss = 0.00304449
Iteration 7296, loss = 0.00304376
Iteration 7297, loss = 0.00304318
Iteration 7298, loss = 0.00304249
Iteration 7299, loss = 0.00304184
Iteration 7300, loss = 0.00304142
Iteration 7301, loss = 0.00304071
Iteration 7302, loss = 0.00304017
Iteration 7303, loss = 0.00303954
Iteration 7304, loss = 0.00303925
Iteration 7305, loss = 0.00303842
Iteration 7306, loss = 0.00303782
Iteration 7307, loss = 0.00303726
Iteration 7308, loss = 0.00303660
Iteration 7309, loss = 0.00303633
Iteration 7310, loss = 0.00303546
Iteration 7311, loss = 0.00303489
Iteration 7312, loss = 0.00303421
Iteration 7313, loss = 0.00303353
Iteration 7314, loss = 0.00303298
Iteration 7315, loss = 0.00303224
Iteration 7316, loss = 0.00303165
Iteration 7317, loss = 0.00303124
Iteration 7318, loss = 0.00303024
Iteration 7319, loss = 0.00302956
Iteration 7320, loss = 0.00302874
Iteration 7321, loss = 0.00302816
Iteration 7322, loss = 0.00302764
Iteration 7323, loss = 0.00302711
Iteration 7324, loss = 0.00302650
Iteration 7325, loss = 0.00302589
Iteration 7326, loss = 0.00302560
Iteration 7327, loss = 0.00302480
Iteration 7328, loss = 0.00302426
Iteration 7329, loss = 0.00302352
Iteration 7330, loss = 0.00302291
Iteration 7331, loss = 0.00302228
Iteration 7332, loss = 0.00302160
Iteration 7333, loss = 0.00302100
Iteration 7334, loss = 0.00302023
Iteration 7335, loss = 0.00301973
Iteration 7336, loss = 0.00301922
Iteration 7337, loss = 0.00301850
Iteration 7338, loss = 0.00301785
Iteration 7339, loss = 0.00301740
Iteration 7340, loss = 0.00301675
Iteration 7341, loss = 0.00301621
Iteration 7342, loss = 0.00301546
Iteration 7343, loss = 0.00301508
Iteration 7344, loss = 0.00301433
Iteration 7345, loss = 0.00301401
Iteration 7346, loss = 0.00301350
Iteration 7347, loss = 0.00301278
Iteration 7348, loss = 0.00301223
Iteration 7349, loss = 0.00301171
Iteration 7350, loss = 0.00301122
Iteration 7351, loss = 0.00301081
Iteration 7352, loss = 0.00301027
Iteration 7353, loss = 0.00300978
Iteration 7354, loss = 0.00300925
Iteration 7355, loss = 0.00300877
Iteration 7356, loss = 0.00300817
Iteration 7357, loss = 0.00300765
Iteration 7358, loss = 0.00300719
Iteration 7359, loss = 0.00300655
Iteration 7360, loss = 0.00300601
Iteration 7361, loss = 0.00300549
Iteration 7362, loss = 0.00300497
Iteration 7363, loss = 0.00300451
Iteration 7364, loss = 0.00300378
Iteration 7365, loss = 0.00300322
Iteration 7366, loss = 0.00300265
Iteration 7367, loss = 0.00300200
Iteration 7368, loss = 0.00300134
Iteration 7369, loss = 0.00300104
Iteration 7370, loss = 0.00300042
Iteration 7371, loss = 0.00299988
Iteration 7372, loss = 0.00299910
Iteration 7373, loss = 0.00299870
Iteration 7374, loss = 0.00299795
Iteration 7375, loss = 0.00299735
Iteration 7376, loss = 0.00299678
Iteration 7377, loss = 0.00299617
Iteration 7378, loss = 0.00299557
Iteration 7379, loss = 0.00299519
Iteration 7380, loss = 0.00299444
Iteration 7381, loss = 0.00299372
Iteration 7382, loss = 0.00299338
Iteration 7383, loss = 0.00299263
Iteration 7384, loss = 0.00299211
Iteration 7385, loss = 0.00299144
Iteration 7386, loss = 0.00299085
Iteration 7387, loss = 0.00299031
Iteration 7388, loss = 0.00298965
Iteration 7389, loss = 0.00298909
Iteration 7390, loss = 0.00298864
Iteration 7391, loss = 0.00298800
Iteration 7392, loss = 0.00298758
Iteration 7393, loss = 0.00298695
Iteration 7394, loss = 0.00298639
Iteration 7395, loss = 0.00298587
Iteration 7396, loss = 0.00298529
Iteration 7397, loss = 0.00298481
Iteration 7398, loss = 0.00298431
Iteration 7399, loss = 0.00298400
Iteration 7400, loss = 0.00298312
Iteration 7401, loss = 0.00298260
Iteration 7402, loss = 0.00298219
Iteration 7403, loss = 0.00298151
Iteration 7404, loss = 0.00298105
Iteration 7405, loss = 0.00298047
Iteration 7406, loss = 0.00297998
Iteration 7407, loss = 0.00297951
Iteration 7408, loss = 0.00297906
Iteration 7409, loss = 0.00297837
Iteration 7410, loss = 0.00297769
Iteration 7411, loss = 0.00297735
Iteration 7412, loss = 0.00297646
Iteration 7413, loss = 0.00297594
Iteration 7414, loss = 0.00297532
Iteration 7415, loss = 0.00297452
Iteration 7416, loss = 0.00297389
Iteration 7417, loss = 0.00297326
Iteration 7418, loss = 0.00297257
Iteration 7419, loss = 0.00297180
Iteration 7420, loss = 0.00297124
Iteration 7421, loss = 0.00297072
Iteration 7422, loss = 0.00297026
Iteration 7423, loss = 0.00296942
Iteration 7424, loss = 0.00296895
Iteration 7425, loss = 0.00296824
Iteration 7426, loss = 0.00296761
Iteration 7427, loss = 0.00296700
Iteration 7428, loss = 0.00296661
Iteration 7429, loss = 0.00296593
Iteration 7430, loss = 0.00296543
Iteration 7431, loss = 0.00296467
Iteration 7432, loss = 0.00296404
Iteration 7433, loss = 0.00296340
Iteration 7434, loss = 0.00296282
Iteration 7435, loss = 0.00296236
Iteration 7436, loss = 0.00296172
Iteration 7437, loss = 0.00296137
Iteration 7438, loss = 0.00296083
Iteration 7439, loss = 0.00296027
Iteration 7440, loss = 0.00295968
Iteration 7441, loss = 0.00295912
Iteration 7442, loss = 0.00295865
Iteration 7443, loss = 0.00295806
Iteration 7444, loss = 0.00295750
Iteration 7445, loss = 0.00295704
Iteration 7446, loss = 0.00295640
Iteration 7447, loss = 0.00295589
Iteration 7448, loss = 0.00295546
Iteration 7449, loss = 0.00295491
Iteration 7450, loss = 0.00295442
Iteration 7451, loss = 0.00295394
Iteration 7452, loss = 0.00295350
Iteration 7453, loss = 0.00295295
Iteration 7454, loss = 0.00295265
Iteration 7455, loss = 0.00295212
Iteration 7456, loss = 0.00295171
Iteration 7457, loss = 0.00295107
Iteration 7458, loss = 0.00295068
Iteration 7459, loss = 0.00295027
Iteration 7460, loss = 0.00294959
Iteration 7461, loss = 0.00294934
Iteration 7462, loss = 0.00294880
Iteration 7463, loss = 0.00294800
Iteration 7464, loss = 0.00294742
Iteration 7465, loss = 0.00294687
Iteration 7466, loss = 0.00294638
Iteration 7467, loss = 0.00294586
Iteration 7468, loss = 0.00294539
Iteration 7469, loss = 0.00294469
Iteration 7470, loss = 0.00294415
Iteration 7471, loss = 0.00294368
Iteration 7472, loss = 0.00294302
Iteration 7473, loss = 0.00294249
Iteration 7474, loss = 0.00294205
Iteration 7475, loss = 0.00294156
Iteration 7476, loss = 0.00294103
Iteration 7477, loss = 0.00294051
Iteration 7478, loss = 0.00294010
Iteration 7479, loss = 0.00293954
Iteration 7480, loss = 0.00293896
Iteration 7481, loss = 0.00293841
Iteration 7482, loss = 0.00293782
Iteration 7483, loss = 0.00293750
Iteration 7484, loss = 0.00293681
Iteration 7485, loss = 0.00293625
Iteration 7486, loss = 0.00293586
Iteration 7487, loss = 0.00293517
Iteration 7488, loss = 0.00293466
Iteration 7489, loss = 0.00293410
Iteration 7490, loss = 0.00293363
Iteration 7491, loss = 0.00293312
Iteration 7492, loss = 0.00293262
Iteration 7493, loss = 0.00293208
Iteration 7494, loss = 0.00293156
Iteration 7495, loss = 0.00293109
Iteration 7496, loss = 0.00293055
Iteration 7497, loss = 0.00293017
Iteration 7498, loss = 0.00292962
Iteration 7499, loss = 0.00292922
Iteration 7500, loss = 0.00292867
Iteration 7501, loss = 0.00292795
Iteration 7502, loss = 0.00292763
Iteration 7503, loss = 0.00292691
Iteration 7504, loss = 0.00292630
Iteration 7505, loss = 0.00292573
Iteration 7506, loss = 0.00292524
Iteration 7507, loss = 0.00292466
Iteration 7508, loss = 0.00292416
Iteration 7509, loss = 0.00292352
Iteration 7510, loss = 0.00292296
Iteration 7511, loss = 0.00292243
Iteration 7512, loss = 0.00292175
Iteration 7513, loss = 0.00292126
Iteration 7514, loss = 0.00292063
Iteration 7515, loss = 0.00292016
Iteration 7516, loss = 0.00291958
Iteration 7517, loss = 0.00291915
Iteration 7518, loss = 0.00291842
Iteration 7519, loss = 0.00291794
Iteration 7520, loss = 0.00291739
Iteration 7521, loss = 0.00291681
Iteration 7522, loss = 0.00291624
Iteration 7523, loss = 0.00291594
Iteration 7524, loss = 0.00291525
Iteration 7525, loss = 0.00291471
Iteration 7526, loss = 0.00291421
Iteration 7527, loss = 0.00291371
Iteration 7528, loss = 0.00291314
Iteration 7529, loss = 0.00291273
Iteration 7530, loss = 0.00291212
Iteration 7531, loss = 0.00291169
Iteration 7532, loss = 0.00291124
Iteration 7533, loss = 0.00291063
Iteration 7534, loss = 0.00291016
Iteration 7535, loss = 0.00290974
Iteration 7536, loss = 0.00290902
Iteration 7537, loss = 0.00290837
Iteration 7538, loss = 0.00290781
Iteration 7539, loss = 0.00290732
Iteration 7540, loss = 0.00290663
Iteration 7541, loss = 0.00290606
Iteration 7542, loss = 0.00290550
Iteration 7543, loss = 0.00290502
Iteration 7544, loss = 0.00290448
Iteration 7545, loss = 0.00290399
Iteration 7546, loss = 0.00290365
Iteration 7547, loss = 0.00290309
Iteration 7548, loss = 0.00290268
Iteration 7549, loss = 0.00290199
Iteration 7550, loss = 0.00290147
Iteration 7551, loss = 0.00290094
Iteration 7552, loss = 0.00290048
Iteration 7553, loss = 0.00289995
Iteration 7554, loss = 0.00289953
Iteration 7555, loss = 0.00289906
Iteration 7556, loss = 0.00289850
Iteration 7557, loss = 0.00289796
Iteration 7558, loss = 0.00289742
Iteration 7559, loss = 0.00289693
Iteration 7560, loss = 0.00289633
Iteration 7561, loss = 0.00289598
Iteration 7562, loss = 0.00289542
Iteration 7563, loss = 0.00289486
Iteration 7564, loss = 0.00289440
Iteration 7565, loss = 0.00289388
Iteration 7566, loss = 0.00289340
Iteration 7567, loss = 0.00289302
Iteration 7568, loss = 0.00289253
Iteration 7569, loss = 0.00289190
Iteration 7570, loss = 0.00289138
Iteration 7571, loss = 0.00289087
Iteration 7572, loss = 0.00289043
Iteration 7573, loss = 0.00288999
Iteration 7574, loss = 0.00288937
Iteration 7575, loss = 0.00288894
Iteration 7576, loss = 0.00288844
Iteration 7577, loss = 0.00288805
Iteration 7578, loss = 0.00288746
Iteration 7579, loss = 0.00288703
Iteration 7580, loss = 0.00288637
Iteration 7581, loss = 0.00288584
Iteration 7582, loss = 0.00288559
Iteration 7583, loss = 0.00288489
Iteration 7584, loss = 0.00288435
Iteration 7585, loss = 0.00288382
Iteration 7586, loss = 0.00288325
Iteration 7587, loss = 0.00288274
Iteration 7588, loss = 0.00288221
Iteration 7589, loss = 0.00288165
Iteration 7590, loss = 0.00288108
Iteration 7591, loss = 0.00288064
Iteration 7592, loss = 0.00287992
Iteration 7593, loss = 0.00287937
Iteration 7594, loss = 0.00287871
Iteration 7595, loss = 0.00287827
Iteration 7596, loss = 0.00287767
Iteration 7597, loss = 0.00287712
Iteration 7598, loss = 0.00287658
Iteration 7599, loss = 0.00287604
Iteration 7600, loss = 0.00287554
Iteration 7601, loss = 0.00287502
Iteration 7602, loss = 0.00287453
Iteration 7603, loss = 0.00287418
Iteration 7604, loss = 0.00287355
Iteration 7605, loss = 0.00287334
Iteration 7606, loss = 0.00287259
Iteration 7607, loss = 0.00287213
Iteration 7608, loss = 0.00287160
Iteration 7609, loss = 0.00287116
Iteration 7610, loss = 0.00287057
Iteration 7611, loss = 0.00287009
Iteration 7612, loss = 0.00286947
Iteration 7613, loss = 0.00286910
Iteration 7614, loss = 0.00286842
Iteration 7615, loss = 0.00286796
Iteration 7616, loss = 0.00286740
Iteration 7617, loss = 0.00286688
Iteration 7618, loss = 0.00286636
Iteration 7619, loss = 0.00286589
Iteration 7620, loss = 0.00286542
Iteration 7621, loss = 0.00286498
Iteration 7622, loss = 0.00286475
Iteration 7623, loss = 0.00286410
Iteration 7624, loss = 0.00286359
Iteration 7625, loss = 0.00286332
Iteration 7626, loss = 0.00286274
Iteration 7627, loss = 0.00286244
Iteration 7628, loss = 0.00286172
Iteration 7629, loss = 0.00286127
Iteration 7630, loss = 0.00286074
Iteration 7631, loss = 0.00286019
Iteration 7632, loss = 0.00285977
Iteration 7633, loss = 0.00285906
Iteration 7634, loss = 0.00285851
Iteration 7635, loss = 0.00285793
Iteration 7636, loss = 0.00285740
Iteration 7637, loss = 0.00285688
Iteration 7638, loss = 0.00285637
Iteration 7639, loss = 0.00285568
Iteration 7640, loss = 0.00285514
Iteration 7641, loss = 0.00285453
Iteration 7642, loss = 0.00285412
Iteration 7643, loss = 0.00285338
Iteration 7644, loss = 0.00285277
Iteration 7645, loss = 0.00285229
Iteration 7646, loss = 0.00285163
Iteration 7647, loss = 0.00285111
Iteration 7648, loss = 0.00285055
Iteration 7649, loss = 0.00285004
Iteration 7650, loss = 0.00284948
Iteration 7651, loss = 0.00284897
Iteration 7652, loss = 0.00284834
Iteration 7653, loss = 0.00284777
Iteration 7654, loss = 0.00284735
Iteration 7655, loss = 0.00284694
Iteration 7656, loss = 0.00284620
Iteration 7657, loss = 0.00284562
Iteration 7658, loss = 0.00284527
Iteration 7659, loss = 0.00284457
Iteration 7660, loss = 0.00284423
Iteration 7661, loss = 0.00284370
Iteration 7662, loss = 0.00284310
Iteration 7663, loss = 0.00284263
Iteration 7664, loss = 0.00284214
Iteration 7665, loss = 0.00284216
Iteration 7666, loss = 0.00284127
Iteration 7667, loss = 0.00284075
Iteration 7668, loss = 0.00284016
Iteration 7669, loss = 0.00283961
Iteration 7670, loss = 0.00283906
Iteration 7671, loss = 0.00283854
Iteration 7672, loss = 0.00283793
Iteration 7673, loss = 0.00283756
Iteration 7674, loss = 0.00283691
Iteration 7675, loss = 0.00283632
Iteration 7676, loss = 0.00283582
Iteration 7677, loss = 0.00283537
Iteration 7678, loss = 0.00283487
Iteration 7679, loss = 0.00283440
Iteration 7680, loss = 0.00283417
Iteration 7681, loss = 0.00283345
Iteration 7682, loss = 0.00283287
Iteration 7683, loss = 0.00283240
Iteration 7684, loss = 0.00283186
Iteration 7685, loss = 0.00283144
Iteration 7686, loss = 0.00283091
Iteration 7687, loss = 0.00283040
Iteration 7688, loss = 0.00282994
Iteration 7689, loss = 0.00282938
Iteration 7690, loss = 0.00282894
Iteration 7691, loss = 0.00282869
Iteration 7692, loss = 0.00282806
Iteration 7693, loss = 0.00282753
Iteration 7694, loss = 0.00282711
Iteration 7695, loss = 0.00282663
Iteration 7696, loss = 0.00282621
Iteration 7697, loss = 0.00282574
Iteration 7698, loss = 0.00282538
Iteration 7699, loss = 0.00282492
Iteration 7700, loss = 0.00282455
Iteration 7701, loss = 0.00282424
Iteration 7702, loss = 0.00282392
Iteration 7703, loss = 0.00282336
Iteration 7704, loss = 0.00282276
Iteration 7705, loss = 0.00282232
Iteration 7706, loss = 0.00282188
Iteration 7707, loss = 0.00282137
Iteration 7708, loss = 0.00282120
Iteration 7709, loss = 0.00282058
Iteration 7710, loss = 0.00282004
Iteration 7711, loss = 0.00281950
Iteration 7712, loss = 0.00281898
Iteration 7713, loss = 0.00281852
Iteration 7714, loss = 0.00281788
Iteration 7715, loss = 0.00281740
Iteration 7716, loss = 0.00281700
Iteration 7717, loss = 0.00281641
Iteration 7718, loss = 0.00281594
Iteration 7719, loss = 0.00281541
Iteration 7720, loss = 0.00281506
Iteration 7721, loss = 0.00281525
Iteration 7722, loss = 0.00281405
Iteration 7723, loss = 0.00281358
Iteration 7724, loss = 0.00281299
Iteration 7725, loss = 0.00281249
Iteration 7726, loss = 0.00281191
Iteration 7727, loss = 0.00281130
Iteration 7728, loss = 0.00281062
Iteration 7729, loss = 0.00281041
Iteration 7730, loss = 0.00280950
Iteration 7731, loss = 0.00280870
Iteration 7732, loss = 0.00280839
Iteration 7733, loss = 0.00280767
Iteration 7734, loss = 0.00280716
Iteration 7735, loss = 0.00280677
Iteration 7736, loss = 0.00280617
Iteration 7737, loss = 0.00280585
Iteration 7738, loss = 0.00280542
Iteration 7739, loss = 0.00280492
Iteration 7740, loss = 0.00280460
Iteration 7741, loss = 0.00280413
Iteration 7742, loss = 0.00280380
Iteration 7743, loss = 0.00280325
Iteration 7744, loss = 0.00280270
Iteration 7745, loss = 0.00280220
Iteration 7746, loss = 0.00280160
Iteration 7747, loss = 0.00280124
Iteration 7748, loss = 0.00280050
Iteration 7749, loss = 0.00279996
Iteration 7750, loss = 0.00279941
Iteration 7751, loss = 0.00279884
Iteration 7752, loss = 0.00279842
Iteration 7753, loss = 0.00279778
Iteration 7754, loss = 0.00279720
Iteration 7755, loss = 0.00279662
Iteration 7756, loss = 0.00279639
Iteration 7757, loss = 0.00279563
Iteration 7758, loss = 0.00279515
Iteration 7759, loss = 0.00279466
Iteration 7760, loss = 0.00279409
Iteration 7761, loss = 0.00279347
Iteration 7762, loss = 0.00279318
Iteration 7763, loss = 0.00279243
Iteration 7764, loss = 0.00279199
Iteration 7765, loss = 0.00279138
Iteration 7766, loss = 0.00279086
Iteration 7767, loss = 0.00279035
Iteration 7768, loss = 0.00278982
Iteration 7769, loss = 0.00278932
Iteration 7770, loss = 0.00278880
Iteration 7771, loss = 0.00278831
Iteration 7772, loss = 0.00278775
Iteration 7773, loss = 0.00278712
Iteration 7774, loss = 0.00278664
Iteration 7775, loss = 0.00278610
Iteration 7776, loss = 0.00278557
Iteration 7777, loss = 0.00278537
Iteration 7778, loss = 0.00278460
Iteration 7779, loss = 0.00278407
Iteration 7780, loss = 0.00278373
Iteration 7781, loss = 0.00278314
Iteration 7782, loss = 0.00278266
Iteration 7783, loss = 0.00278199
Iteration 7784, loss = 0.00278168
Iteration 7785, loss = 0.00278115
Iteration 7786, loss = 0.00278053
Iteration 7787, loss = 0.00277994
Iteration 7788, loss = 0.00277949
Iteration 7789, loss = 0.00277892
Iteration 7790, loss = 0.00277835
Iteration 7791, loss = 0.00277784
Iteration 7792, loss = 0.00277742
Iteration 7793, loss = 0.00277695
Iteration 7794, loss = 0.00277649
Iteration 7795, loss = 0.00277600
Iteration 7796, loss = 0.00277565
Iteration 7797, loss = 0.00277483
Iteration 7798, loss = 0.00277434
Iteration 7799, loss = 0.00277380
Iteration 7800, loss = 0.00277330
Iteration 7801, loss = 0.00277285
Iteration 7802, loss = 0.00277253
Iteration 7803, loss = 0.00277181
Iteration 7804, loss = 0.00277154
Iteration 7805, loss = 0.00277081
Iteration 7806, loss = 0.00277038
Iteration 7807, loss = 0.00276986
Iteration 7808, loss = 0.00276935
Iteration 7809, loss = 0.00276894
Iteration 7810, loss = 0.00276847
Iteration 7811, loss = 0.00276795
Iteration 7812, loss = 0.00276749
Iteration 7813, loss = 0.00276708
Iteration 7814, loss = 0.00276643
Iteration 7815, loss = 0.00276590
Iteration 7816, loss = 0.00276543
Iteration 7817, loss = 0.00276521
Iteration 7818, loss = 0.00276447
Iteration 7819, loss = 0.00276402
Iteration 7820, loss = 0.00276354
Iteration 7821, loss = 0.00276296
Iteration 7822, loss = 0.00276239
Iteration 7823, loss = 0.00276190
Iteration 7824, loss = 0.00276140
Iteration 7825, loss = 0.00276100
Iteration 7826, loss = 0.00276036
Iteration 7827, loss = 0.00275995
Iteration 7828, loss = 0.00275968
Iteration 7829, loss = 0.00275915
Iteration 7830, loss = 0.00275862
Iteration 7831, loss = 0.00275813
Iteration 7832, loss = 0.00275766
Iteration 7833, loss = 0.00275733
Iteration 7834, loss = 0.00275669
Iteration 7835, loss = 0.00275650
Iteration 7836, loss = 0.00275571
Iteration 7837, loss = 0.00275517
Iteration 7838, loss = 0.00275464
Iteration 7839, loss = 0.00275441
Iteration 7840, loss = 0.00275401
Iteration 7841, loss = 0.00275315
Iteration 7842, loss = 0.00275269
Iteration 7843, loss = 0.00275221
Iteration 7844, loss = 0.00275166
Iteration 7845, loss = 0.00275111
Iteration 7846, loss = 0.00275042
Iteration 7847, loss = 0.00274998
Iteration 7848, loss = 0.00274944
Iteration 7849, loss = 0.00274894
Iteration 7850, loss = 0.00274878
Iteration 7851, loss = 0.00274810
Iteration 7852, loss = 0.00274758
Iteration 7853, loss = 0.00274714
Iteration 7854, loss = 0.00274671
Iteration 7855, loss = 0.00274619
Iteration 7856, loss = 0.00274571
Iteration 7857, loss = 0.00274564
Iteration 7858, loss = 0.00274476
Iteration 7859, loss = 0.00274412
Iteration 7860, loss = 0.00274349
Iteration 7861, loss = 0.00274308
Iteration 7862, loss = 0.00274249
Iteration 7863, loss = 0.00274200
Iteration 7864, loss = 0.00274148
Iteration 7865, loss = 0.00274094
Iteration 7866, loss = 0.00274046
Iteration 7867, loss = 0.00273996
Iteration 7868, loss = 0.00273959
Iteration 7869, loss = 0.00273901
Iteration 7870, loss = 0.00273855
Iteration 7871, loss = 0.00273820
Iteration 7872, loss = 0.00273789
Iteration 7873, loss = 0.00273719
Iteration 7874, loss = 0.00273683
Iteration 7875, loss = 0.00273655
Iteration 7876, loss = 0.00273583
Iteration 7877, loss = 0.00273533
Iteration 7878, loss = 0.00273489
Iteration 7879, loss = 0.00273446
Iteration 7880, loss = 0.00273400
Iteration 7881, loss = 0.00273376
Iteration 7882, loss = 0.00273334
Iteration 7883, loss = 0.00273238
Iteration 7884, loss = 0.00273196
Iteration 7885, loss = 0.00273127
Iteration 7886, loss = 0.00273088
Iteration 7887, loss = 0.00273025
Iteration 7888, loss = 0.00272964
Iteration 7889, loss = 0.00272920
Iteration 7890, loss = 0.00272859
Iteration 7891, loss = 0.00272843
Iteration 7892, loss = 0.00272774
Iteration 7893, loss = 0.00272717
Iteration 7894, loss = 0.00272673
Iteration 7895, loss = 0.00272618
Iteration 7896, loss = 0.00272563
Iteration 7897, loss = 0.00272514
Iteration 7898, loss = 0.00272468
Iteration 7899, loss = 0.00272417
Iteration 7900, loss = 0.00272381
Iteration 7901, loss = 0.00272339
Iteration 7902, loss = 0.00272308
Iteration 7903, loss = 0.00272257
Iteration 7904, loss = 0.00272212
Iteration 7905, loss = 0.00272167
Iteration 7906, loss = 0.00272118
Iteration 7907, loss = 0.00272094
Iteration 7908, loss = 0.00272022
Iteration 7909, loss = 0.00271986
Iteration 7910, loss = 0.00271944
Iteration 7911, loss = 0.00271884
Iteration 7912, loss = 0.00271852
Iteration 7913, loss = 0.00271787
Iteration 7914, loss = 0.00271731
Iteration 7915, loss = 0.00271695
Iteration 7916, loss = 0.00271636
Iteration 7917, loss = 0.00271582
Iteration 7918, loss = 0.00271526
Iteration 7919, loss = 0.00271477
Iteration 7920, loss = 0.00271427
Iteration 7921, loss = 0.00271376
Iteration 7922, loss = 0.00271318
Iteration 7923, loss = 0.00271292
Iteration 7924, loss = 0.00271222
Iteration 7925, loss = 0.00271177
Iteration 7926, loss = 0.00271133
Iteration 7927, loss = 0.00271084
Iteration 7928, loss = 0.00271075
Iteration 7929, loss = 0.00270994
Iteration 7930, loss = 0.00270937
Iteration 7931, loss = 0.00270887
Iteration 7932, loss = 0.00270838
Iteration 7933, loss = 0.00270796
Iteration 7934, loss = 0.00270739
Iteration 7935, loss = 0.00270685
Iteration 7936, loss = 0.00270644
Iteration 7937, loss = 0.00270588
Iteration 7938, loss = 0.00270544
Iteration 7939, loss = 0.00270487
Iteration 7940, loss = 0.00270429
Iteration 7941, loss = 0.00270399
Iteration 7942, loss = 0.00270343
Iteration 7943, loss = 0.00270285
Iteration 7944, loss = 0.00270237
Iteration 7945, loss = 0.00270173
Iteration 7946, loss = 0.00270130
Iteration 7947, loss = 0.00270109
Iteration 7948, loss = 0.00270034
Iteration 7949, loss = 0.00269983
Iteration 7950, loss = 0.00269944
Iteration 7951, loss = 0.00269888
Iteration 7952, loss = 0.00269835
Iteration 7953, loss = 0.00269786
Iteration 7954, loss = 0.00269745
Iteration 7955, loss = 0.00269690
Iteration 7956, loss = 0.00269645
Iteration 7957, loss = 0.00269594
Iteration 7958, loss = 0.00269556
Iteration 7959, loss = 0.00269504
Iteration 7960, loss = 0.00269454
Iteration 7961, loss = 0.00269411
Iteration 7962, loss = 0.00269366
Iteration 7963, loss = 0.00269323
Iteration 7964, loss = 0.00269280
Iteration 7965, loss = 0.00269240
Iteration 7966, loss = 0.00269195
Iteration 7967, loss = 0.00269144
Iteration 7968, loss = 0.00269128
Iteration 7969, loss = 0.00269086
Iteration 7970, loss = 0.00269038
Iteration 7971, loss = 0.00269016
Iteration 7972, loss = 0.00268948
Iteration 7973, loss = 0.00268915
Iteration 7974, loss = 0.00268865
Iteration 7975, loss = 0.00268818
Iteration 7976, loss = 0.00268773
Iteration 7977, loss = 0.00268716
Iteration 7978, loss = 0.00268701
Iteration 7979, loss = 0.00268618
Iteration 7980, loss = 0.00268571
Iteration 7981, loss = 0.00268524
Iteration 7982, loss = 0.00268474
Iteration 7983, loss = 0.00268397
Iteration 7984, loss = 0.00268360
Iteration 7985, loss = 0.00268298
Iteration 7986, loss = 0.00268248
Iteration 7987, loss = 0.00268263
Iteration 7988, loss = 0.00268162
Iteration 7989, loss = 0.00268111
Iteration 7990, loss = 0.00268073
Iteration 7991, loss = 0.00268029
Iteration 7992, loss = 0.00267986
Iteration 7993, loss = 0.00267939
Iteration 7994, loss = 0.00267897
Iteration 7995, loss = 0.00267861
Iteration 7996, loss = 0.00267811
Iteration 7997, loss = 0.00267762
Iteration 7998, loss = 0.00267726
Iteration 7999, loss = 0.00267684
Iteration 8000, loss = 0.00267637
Iteration 1, loss = 1.04177453
Iteration 2, loss = 1.03868137
Iteration 3, loss = 1.03371997
Iteration 4, loss = 1.02749678
Iteration 5, loss = 1.02020169
Iteration 6, loss = 1.01210999
Iteration 7, loss = 1.00359825
Iteration 8, loss = 0.99474913
Iteration 9, loss = 0.98528209
Iteration 10, loss = 0.97619983
Iteration 11, loss = 0.96665718
Iteration 12, loss = 0.95742216
Iteration 13, loss = 0.94805584
Iteration 14, loss = 0.93908173
Iteration 15, loss = 0.93015474
Iteration 16, loss = 0.92142719
Iteration 17, loss = 0.91277785
Iteration 18, loss = 0.90440662
Iteration 19, loss = 0.89643144
Iteration 20, loss = 0.88845959
Iteration 21, loss = 0.88066510
Iteration 22, loss = 0.87326192
Iteration 23, loss = 0.86597243
Iteration 24, loss = 0.85862085
Iteration 25, loss = 0.85173467
Iteration 26, loss = 0.84479330
Iteration 27, loss = 0.83793228
Iteration 28, loss = 0.83143110
Iteration 29, loss = 0.82513226
Iteration 30, loss = 0.81889463
Iteration 31, loss = 0.81293504
Iteration 32, loss = 0.80711047
Iteration 33, loss = 0.80139018
Iteration 34, loss = 0.79597413
Iteration 35, loss = 0.79059570
Iteration 36, loss = 0.78527792
Iteration 37, loss = 0.78035267
Iteration 38, loss = 0.77536576
Iteration 39, loss = 0.77058748
Iteration 40, loss = 0.76609830
Iteration 41, loss = 0.76157937
Iteration 42, loss = 0.75728338
Iteration 43, loss = 0.75319195
Iteration 44, loss = 0.74913297
Iteration 45, loss = 0.74511883
Iteration 46, loss = 0.74135742
Iteration 47, loss = 0.73756034
Iteration 48, loss = 0.73382059
Iteration 49, loss = 0.73018910
Iteration 50, loss = 0.72654406
Iteration 51, loss = 0.72308977
Iteration 52, loss = 0.71956484
Iteration 53, loss = 0.71622283
Iteration 54, loss = 0.71279432
Iteration 55, loss = 0.70950648
Iteration 56, loss = 0.70619254
Iteration 57, loss = 0.70278269
Iteration 58, loss = 0.69954013
Iteration 59, loss = 0.69616671
Iteration 60, loss = 0.69282500
Iteration 61, loss = 0.68958101
Iteration 62, loss = 0.68638941
Iteration 63, loss = 0.68326864
Iteration 64, loss = 0.68011906
Iteration 65, loss = 0.67715892
Iteration 66, loss = 0.67424079
Iteration 67, loss = 0.67124514
Iteration 68, loss = 0.66847300
Iteration 69, loss = 0.66553256
Iteration 70, loss = 0.66281070
Iteration 71, loss = 0.65995989
Iteration 72, loss = 0.65725613
Iteration 73, loss = 0.65443971
Iteration 74, loss = 0.65174448
Iteration 75, loss = 0.64900530
Iteration 76, loss = 0.64627414
Iteration 77, loss = 0.64358511
Iteration 78, loss = 0.64088997
Iteration 79, loss = 0.63825574
Iteration 80, loss = 0.63560560
Iteration 81, loss = 0.63294966
Iteration 82, loss = 0.63034024
Iteration 83, loss = 0.62774287
Iteration 84, loss = 0.62507733
Iteration 85, loss = 0.62253007
Iteration 86, loss = 0.61992816
Iteration 87, loss = 0.61733878
Iteration 88, loss = 0.61474525
Iteration 89, loss = 0.61222777
Iteration 90, loss = 0.60966141
Iteration 91, loss = 0.60707329
Iteration 92, loss = 0.60460827
Iteration 93, loss = 0.60207671
Iteration 94, loss = 0.59956383
Iteration 95, loss = 0.59709881
Iteration 96, loss = 0.59464580
Iteration 97, loss = 0.59222003
Iteration 98, loss = 0.58978862
Iteration 99, loss = 0.58733894
Iteration 100, loss = 0.58495603
Iteration 101, loss = 0.58256681
Iteration 102, loss = 0.58015083
Iteration 103, loss = 0.57778214
Iteration 104, loss = 0.57543506
Iteration 105, loss = 0.57303841
Iteration 106, loss = 0.57070784
Iteration 107, loss = 0.56835610
Iteration 108, loss = 0.56607527
Iteration 109, loss = 0.56371591
Iteration 110, loss = 0.56142137
Iteration 111, loss = 0.55913530
Iteration 112, loss = 0.55683816
Iteration 113, loss = 0.55457258
Iteration 114, loss = 0.55222002
Iteration 115, loss = 0.54997821
Iteration 116, loss = 0.54769384
Iteration 117, loss = 0.54536897
Iteration 118, loss = 0.54318059
Iteration 119, loss = 0.54088372
Iteration 120, loss = 0.53868925
Iteration 121, loss = 0.53650413
Iteration 122, loss = 0.53432362
Iteration 123, loss = 0.53215247
Iteration 124, loss = 0.52998663
Iteration 125, loss = 0.52783436
Iteration 126, loss = 0.52568419
Iteration 127, loss = 0.52357154
Iteration 128, loss = 0.52148724
Iteration 129, loss = 0.51937764
Iteration 130, loss = 0.51732254
Iteration 131, loss = 0.51527378
Iteration 132, loss = 0.51319389
Iteration 133, loss = 0.51115364
Iteration 134, loss = 0.50911974
Iteration 135, loss = 0.50706445
Iteration 136, loss = 0.50502858
Iteration 137, loss = 0.50295859
Iteration 138, loss = 0.50089770
Iteration 139, loss = 0.49883001
Iteration 140, loss = 0.49673090
Iteration 141, loss = 0.49464261
Iteration 142, loss = 0.49255469
Iteration 143, loss = 0.49048270
Iteration 144, loss = 0.48841305
Iteration 145, loss = 0.48634201
Iteration 146, loss = 0.48428205
Iteration 147, loss = 0.48224242
Iteration 148, loss = 0.48021676
Iteration 149, loss = 0.47812948
Iteration 150, loss = 0.47609411
Iteration 151, loss = 0.47403857
Iteration 152, loss = 0.47196802
Iteration 153, loss = 0.46990518
Iteration 154, loss = 0.46784949
Iteration 155, loss = 0.46584427
Iteration 156, loss = 0.46376998
Iteration 157, loss = 0.46175781
Iteration 158, loss = 0.45970990
Iteration 159, loss = 0.45765699
Iteration 160, loss = 0.45557920
Iteration 161, loss = 0.45351563
Iteration 162, loss = 0.45141661
Iteration 163, loss = 0.44932752
Iteration 164, loss = 0.44723323
Iteration 165, loss = 0.44511576
Iteration 166, loss = 0.44301619
Iteration 167, loss = 0.44090005
Iteration 168, loss = 0.43881737
Iteration 169, loss = 0.43667688
Iteration 170, loss = 0.43461121
Iteration 171, loss = 0.43249538
Iteration 172, loss = 0.43040965
Iteration 173, loss = 0.42834228
Iteration 174, loss = 0.42626233
Iteration 175, loss = 0.42418190
Iteration 176, loss = 0.42214217
Iteration 177, loss = 0.42007525
Iteration 178, loss = 0.41802062
Iteration 179, loss = 0.41595475
Iteration 180, loss = 0.41392610
Iteration 181, loss = 0.41184082
Iteration 182, loss = 0.40980242
Iteration 183, loss = 0.40777699
Iteration 184, loss = 0.40569220
Iteration 185, loss = 0.40364512
Iteration 186, loss = 0.40159005
Iteration 187, loss = 0.39950365
Iteration 188, loss = 0.39746437
Iteration 189, loss = 0.39541085
Iteration 190, loss = 0.39334285
Iteration 191, loss = 0.39131976
Iteration 192, loss = 0.38927878
Iteration 193, loss = 0.38726546
Iteration 194, loss = 0.38524730
Iteration 195, loss = 0.38325991
Iteration 196, loss = 0.38123122
Iteration 197, loss = 0.37926933
Iteration 198, loss = 0.37726739
Iteration 199, loss = 0.37530145
Iteration 200, loss = 0.37332332
Iteration 201, loss = 0.37133910
Iteration 202, loss = 0.36938701
Iteration 203, loss = 0.36742032
Iteration 204, loss = 0.36544638
Iteration 205, loss = 0.36348875
Iteration 206, loss = 0.36153449
Iteration 207, loss = 0.35954676
Iteration 208, loss = 0.35757568
Iteration 209, loss = 0.35559529
Iteration 210, loss = 0.35360813
Iteration 211, loss = 0.35163312
Iteration 212, loss = 0.34960790
Iteration 213, loss = 0.34764730
Iteration 214, loss = 0.34565365
Iteration 215, loss = 0.34366947
Iteration 216, loss = 0.34170303
Iteration 217, loss = 0.33974351
Iteration 218, loss = 0.33779131
Iteration 219, loss = 0.33585650
Iteration 220, loss = 0.33392512
Iteration 221, loss = 0.33200227
Iteration 222, loss = 0.33011402
Iteration 223, loss = 0.32820327
Iteration 224, loss = 0.32629477
Iteration 225, loss = 0.32442637
Iteration 226, loss = 0.32251983
Iteration 227, loss = 0.32063337
Iteration 228, loss = 0.31874542
Iteration 229, loss = 0.31685704
Iteration 230, loss = 0.31497983
Iteration 231, loss = 0.31311700
Iteration 232, loss = 0.31125061
Iteration 233, loss = 0.30937834
Iteration 234, loss = 0.30752760
Iteration 235, loss = 0.30568281
Iteration 236, loss = 0.30382634
Iteration 237, loss = 0.30198406
Iteration 238, loss = 0.30016336
Iteration 239, loss = 0.29833604
Iteration 240, loss = 0.29652663
Iteration 241, loss = 0.29473207
Iteration 242, loss = 0.29294790
Iteration 243, loss = 0.29115608
Iteration 244, loss = 0.28937525
Iteration 245, loss = 0.28762391
Iteration 246, loss = 0.28582865
Iteration 247, loss = 0.28409827
Iteration 248, loss = 0.28233175
Iteration 249, loss = 0.28058975
Iteration 250, loss = 0.27889390
Iteration 251, loss = 0.27718080
Iteration 252, loss = 0.27548324
Iteration 253, loss = 0.27379591
Iteration 254, loss = 0.27213639
Iteration 255, loss = 0.27045945
Iteration 256, loss = 0.26881339
Iteration 257, loss = 0.26714510
Iteration 258, loss = 0.26552177
Iteration 259, loss = 0.26387386
Iteration 260, loss = 0.26225335
Iteration 261, loss = 0.26062966
Iteration 262, loss = 0.25903589
Iteration 263, loss = 0.25741547
Iteration 264, loss = 0.25582473
Iteration 265, loss = 0.25423773
Iteration 266, loss = 0.25267482
Iteration 267, loss = 0.25110200
Iteration 268, loss = 0.24955838
Iteration 269, loss = 0.24802795
Iteration 270, loss = 0.24652324
Iteration 271, loss = 0.24501677
Iteration 272, loss = 0.24353297
Iteration 273, loss = 0.24204221
Iteration 274, loss = 0.24058678
Iteration 275, loss = 0.23912452
Iteration 276, loss = 0.23768899
Iteration 277, loss = 0.23625117
Iteration 278, loss = 0.23483474
Iteration 279, loss = 0.23343248
Iteration 280, loss = 0.23203316
Iteration 281, loss = 0.23063816
Iteration 282, loss = 0.22925294
Iteration 283, loss = 0.22787293
Iteration 284, loss = 0.22649685
Iteration 285, loss = 0.22512511
Iteration 286, loss = 0.22377191
Iteration 287, loss = 0.22244038
Iteration 288, loss = 0.22110542
Iteration 289, loss = 0.21978557
Iteration 290, loss = 0.21847512
Iteration 291, loss = 0.21717289
Iteration 292, loss = 0.21589175
Iteration 293, loss = 0.21460437
Iteration 294, loss = 0.21333023
Iteration 295, loss = 0.21207436
Iteration 296, loss = 0.21081191
Iteration 297, loss = 0.20957536
Iteration 298, loss = 0.20832089
Iteration 299, loss = 0.20710471
Iteration 300, loss = 0.20587862
Iteration 301, loss = 0.20466667
Iteration 302, loss = 0.20347151
Iteration 303, loss = 0.20229091
Iteration 304, loss = 0.20110568
Iteration 305, loss = 0.19994242
Iteration 306, loss = 0.19877991
Iteration 307, loss = 0.19762764
Iteration 308, loss = 0.19650048
Iteration 309, loss = 0.19536271
Iteration 310, loss = 0.19425350
Iteration 311, loss = 0.19314666
Iteration 312, loss = 0.19204928
Iteration 313, loss = 0.19096253
Iteration 314, loss = 0.18988092
Iteration 315, loss = 0.18880075
Iteration 316, loss = 0.18773520
Iteration 317, loss = 0.18666858
Iteration 318, loss = 0.18561471
Iteration 319, loss = 0.18456048
Iteration 320, loss = 0.18351707
Iteration 321, loss = 0.18248067
Iteration 322, loss = 0.18146406
Iteration 323, loss = 0.18045405
Iteration 324, loss = 0.17945469
Iteration 325, loss = 0.17845109
Iteration 326, loss = 0.17747347
Iteration 327, loss = 0.17650082
Iteration 328, loss = 0.17552974
Iteration 329, loss = 0.17457048
Iteration 330, loss = 0.17361132
Iteration 331, loss = 0.17265787
Iteration 332, loss = 0.17171454
Iteration 333, loss = 0.17078316
Iteration 334, loss = 0.16985148
Iteration 335, loss = 0.16893595
Iteration 336, loss = 0.16802035
Iteration 337, loss = 0.16710678
Iteration 338, loss = 0.16620777
Iteration 339, loss = 0.16531504
Iteration 340, loss = 0.16442473
Iteration 341, loss = 0.16354346
Iteration 342, loss = 0.16266678
Iteration 343, loss = 0.16181488
Iteration 344, loss = 0.16094426
Iteration 345, loss = 0.16010174
Iteration 346, loss = 0.15925905
Iteration 347, loss = 0.15841100
Iteration 348, loss = 0.15758614
Iteration 349, loss = 0.15675157
Iteration 350, loss = 0.15592960
Iteration 351, loss = 0.15511402
Iteration 352, loss = 0.15430873
Iteration 353, loss = 0.15351764
Iteration 354, loss = 0.15272836
Iteration 355, loss = 0.15194977
Iteration 356, loss = 0.15118354
Iteration 357, loss = 0.15041555
Iteration 358, loss = 0.14965471
Iteration 359, loss = 0.14890210
Iteration 360, loss = 0.14815972
Iteration 361, loss = 0.14742137
Iteration 362, loss = 0.14669196
Iteration 363, loss = 0.14596167
Iteration 364, loss = 0.14524570
Iteration 365, loss = 0.14453815
Iteration 366, loss = 0.14382242
Iteration 367, loss = 0.14312549
Iteration 368, loss = 0.14243044
Iteration 369, loss = 0.14174573
Iteration 370, loss = 0.14106085
Iteration 371, loss = 0.14039043
Iteration 372, loss = 0.13971921
Iteration 373, loss = 0.13905682
Iteration 374, loss = 0.13838411
Iteration 375, loss = 0.13772630
Iteration 376, loss = 0.13707523
Iteration 377, loss = 0.13642616
Iteration 378, loss = 0.13578584
Iteration 379, loss = 0.13514343
Iteration 380, loss = 0.13451573
Iteration 381, loss = 0.13388987
Iteration 382, loss = 0.13327073
Iteration 383, loss = 0.13265707
Iteration 384, loss = 0.13204377
Iteration 385, loss = 0.13144337
Iteration 386, loss = 0.13083742
Iteration 387, loss = 0.13024086
Iteration 388, loss = 0.12964434
Iteration 389, loss = 0.12906002
Iteration 390, loss = 0.12847145
Iteration 391, loss = 0.12789728
Iteration 392, loss = 0.12731278
Iteration 393, loss = 0.12674636
Iteration 394, loss = 0.12618635
Iteration 395, loss = 0.12562648
Iteration 396, loss = 0.12507545
Iteration 397, loss = 0.12453123
Iteration 398, loss = 0.12399003
Iteration 399, loss = 0.12345264
Iteration 400, loss = 0.12292272
Iteration 401, loss = 0.12239119
Iteration 402, loss = 0.12187814
Iteration 403, loss = 0.12135715
Iteration 404, loss = 0.12084351
Iteration 405, loss = 0.12032732
Iteration 406, loss = 0.11981631
Iteration 407, loss = 0.11930703
Iteration 408, loss = 0.11880115
Iteration 409, loss = 0.11829536
Iteration 410, loss = 0.11779726
Iteration 411, loss = 0.11730519
Iteration 412, loss = 0.11681439
Iteration 413, loss = 0.11633579
Iteration 414, loss = 0.11585612
Iteration 415, loss = 0.11537430
Iteration 416, loss = 0.11490886
Iteration 417, loss = 0.11442960
Iteration 418, loss = 0.11396636
Iteration 419, loss = 0.11349896
Iteration 420, loss = 0.11303775
Iteration 421, loss = 0.11257486
Iteration 422, loss = 0.11212326
Iteration 423, loss = 0.11166809
Iteration 424, loss = 0.11122189
Iteration 425, loss = 0.11077281
Iteration 426, loss = 0.11033145
Iteration 427, loss = 0.10989753
Iteration 428, loss = 0.10946865
Iteration 429, loss = 0.10903406
Iteration 430, loss = 0.10861485
Iteration 431, loss = 0.10819805
Iteration 432, loss = 0.10778154
Iteration 433, loss = 0.10736023
Iteration 434, loss = 0.10694388
Iteration 435, loss = 0.10654247
Iteration 436, loss = 0.10612957
Iteration 437, loss = 0.10572616
Iteration 438, loss = 0.10532509
Iteration 439, loss = 0.10492886
Iteration 440, loss = 0.10452830
Iteration 441, loss = 0.10414161
Iteration 442, loss = 0.10374858
Iteration 443, loss = 0.10336927
Iteration 444, loss = 0.10298912
Iteration 445, loss = 0.10261119
Iteration 446, loss = 0.10223632
Iteration 447, loss = 0.10186492
Iteration 448, loss = 0.10148163
Iteration 449, loss = 0.10110623
Iteration 450, loss = 0.10073376
Iteration 451, loss = 0.10035915
Iteration 452, loss = 0.09999802
Iteration 453, loss = 0.09963459
Iteration 454, loss = 0.09928082
Iteration 455, loss = 0.09893552
Iteration 456, loss = 0.09857376
Iteration 457, loss = 0.09822398
Iteration 458, loss = 0.09787415
Iteration 459, loss = 0.09752187
Iteration 460, loss = 0.09718279
Iteration 461, loss = 0.09683865
Iteration 462, loss = 0.09650064
Iteration 463, loss = 0.09616693
Iteration 464, loss = 0.09583753
Iteration 465, loss = 0.09551228
Iteration 466, loss = 0.09518940
Iteration 467, loss = 0.09487475
Iteration 468, loss = 0.09455190
Iteration 469, loss = 0.09423342
Iteration 470, loss = 0.09391299
Iteration 471, loss = 0.09360496
Iteration 472, loss = 0.09328848
Iteration 473, loss = 0.09297735
Iteration 474, loss = 0.09266644
Iteration 475, loss = 0.09235735
Iteration 476, loss = 0.09205634
Iteration 477, loss = 0.09175200
Iteration 478, loss = 0.09144960
Iteration 479, loss = 0.09115149
Iteration 480, loss = 0.09085929
Iteration 481, loss = 0.09057146
Iteration 482, loss = 0.09027114
Iteration 483, loss = 0.08998711
Iteration 484, loss = 0.08969718
Iteration 485, loss = 0.08940885
Iteration 486, loss = 0.08911878
Iteration 487, loss = 0.08882792
Iteration 488, loss = 0.08855221
Iteration 489, loss = 0.08827151
Iteration 490, loss = 0.08798988
Iteration 491, loss = 0.08772154
Iteration 492, loss = 0.08744127
Iteration 493, loss = 0.08716617
Iteration 494, loss = 0.08689118
Iteration 495, loss = 0.08661859
Iteration 496, loss = 0.08635359
Iteration 497, loss = 0.08608672
Iteration 498, loss = 0.08583959
Iteration 499, loss = 0.08555472
Iteration 500, loss = 0.08528989
Iteration 501, loss = 0.08504044
Iteration 502, loss = 0.08476608
Iteration 503, loss = 0.08451083
Iteration 504, loss = 0.08425015
Iteration 505, loss = 0.08399851
Iteration 506, loss = 0.08374015
Iteration 507, loss = 0.08348690
Iteration 508, loss = 0.08324070
Iteration 509, loss = 0.08298932
Iteration 510, loss = 0.08273726
Iteration 511, loss = 0.08249429
Iteration 512, loss = 0.08224489
Iteration 513, loss = 0.08200842
Iteration 514, loss = 0.08176491
Iteration 515, loss = 0.08151745
Iteration 516, loss = 0.08127991
Iteration 517, loss = 0.08103511
Iteration 518, loss = 0.08079681
Iteration 519, loss = 0.08055718
Iteration 520, loss = 0.08032262
Iteration 521, loss = 0.08009348
Iteration 522, loss = 0.07985214
Iteration 523, loss = 0.07962591
Iteration 524, loss = 0.07939259
Iteration 525, loss = 0.07916476
Iteration 526, loss = 0.07894247
Iteration 527, loss = 0.07871821
Iteration 528, loss = 0.07849468
Iteration 529, loss = 0.07827654
Iteration 530, loss = 0.07805414
Iteration 531, loss = 0.07783702
Iteration 532, loss = 0.07761764
Iteration 533, loss = 0.07740199
Iteration 534, loss = 0.07718810
Iteration 535, loss = 0.07697968
Iteration 536, loss = 0.07676678
Iteration 537, loss = 0.07655956
Iteration 538, loss = 0.07635345
Iteration 539, loss = 0.07614694
Iteration 540, loss = 0.07594481
Iteration 541, loss = 0.07574515
Iteration 542, loss = 0.07554297
Iteration 543, loss = 0.07534611
Iteration 544, loss = 0.07515068
Iteration 545, loss = 0.07495487
Iteration 546, loss = 0.07475547
Iteration 547, loss = 0.07456133
Iteration 548, loss = 0.07436891
Iteration 549, loss = 0.07417407
Iteration 550, loss = 0.07398018
Iteration 551, loss = 0.07378739
Iteration 552, loss = 0.07360044
Iteration 553, loss = 0.07340928
Iteration 554, loss = 0.07322594
Iteration 555, loss = 0.07304033
Iteration 556, loss = 0.07286175
Iteration 557, loss = 0.07267911
Iteration 558, loss = 0.07250559
Iteration 559, loss = 0.07232140
Iteration 560, loss = 0.07214550
Iteration 561, loss = 0.07196767
Iteration 562, loss = 0.07178997
Iteration 563, loss = 0.07161394
Iteration 564, loss = 0.07143635
Iteration 565, loss = 0.07126619
Iteration 566, loss = 0.07108654
Iteration 567, loss = 0.07091237
Iteration 568, loss = 0.07073953
Iteration 569, loss = 0.07057093
Iteration 570, loss = 0.07040003
Iteration 571, loss = 0.07022978
Iteration 572, loss = 0.07006156
Iteration 573, loss = 0.06989938
Iteration 574, loss = 0.06973072
Iteration 575, loss = 0.06956128
Iteration 576, loss = 0.06939244
Iteration 577, loss = 0.06923000
Iteration 578, loss = 0.06906380
Iteration 579, loss = 0.06890235
Iteration 580, loss = 0.06873753
Iteration 581, loss = 0.06858100
Iteration 582, loss = 0.06841974
Iteration 583, loss = 0.06826147
Iteration 584, loss = 0.06810376
Iteration 585, loss = 0.06795561
Iteration 586, loss = 0.06779463
Iteration 587, loss = 0.06763522
Iteration 588, loss = 0.06747882
Iteration 589, loss = 0.06732349
Iteration 590, loss = 0.06716741
Iteration 591, loss = 0.06701486
Iteration 592, loss = 0.06685713
Iteration 593, loss = 0.06671138
Iteration 594, loss = 0.06655717
Iteration 595, loss = 0.06640629
Iteration 596, loss = 0.06625520
Iteration 597, loss = 0.06610556
Iteration 598, loss = 0.06595775
Iteration 599, loss = 0.06581255
Iteration 600, loss = 0.06566530
Iteration 601, loss = 0.06551838
Iteration 602, loss = 0.06537324
Iteration 603, loss = 0.06522713
Iteration 604, loss = 0.06508072
Iteration 605, loss = 0.06493346
Iteration 606, loss = 0.06478920
Iteration 607, loss = 0.06464147
Iteration 608, loss = 0.06450357
Iteration 609, loss = 0.06435683
Iteration 610, loss = 0.06421735
Iteration 611, loss = 0.06407037
Iteration 612, loss = 0.06392799
Iteration 613, loss = 0.06378483
Iteration 614, loss = 0.06364608
Iteration 615, loss = 0.06350269
Iteration 616, loss = 0.06336016
Iteration 617, loss = 0.06322566
Iteration 618, loss = 0.06309515
Iteration 619, loss = 0.06295081
Iteration 620, loss = 0.06281201
Iteration 621, loss = 0.06267893
Iteration 622, loss = 0.06254778
Iteration 623, loss = 0.06241935
Iteration 624, loss = 0.06228855
Iteration 625, loss = 0.06215272
Iteration 626, loss = 0.06202113
Iteration 627, loss = 0.06188765
Iteration 628, loss = 0.06175431
Iteration 629, loss = 0.06162399
Iteration 630, loss = 0.06149081
Iteration 631, loss = 0.06136009
Iteration 632, loss = 0.06123450
Iteration 633, loss = 0.06110349
Iteration 634, loss = 0.06097809
Iteration 635, loss = 0.06085015
Iteration 636, loss = 0.06072648
Iteration 637, loss = 0.06059776
Iteration 638, loss = 0.06047209
Iteration 639, loss = 0.06034638
Iteration 640, loss = 0.06022292
Iteration 641, loss = 0.06009679
Iteration 642, loss = 0.05997611
Iteration 643, loss = 0.05984659
Iteration 644, loss = 0.05972611
Iteration 645, loss = 0.05960120
Iteration 646, loss = 0.05947631
Iteration 647, loss = 0.05935216
Iteration 648, loss = 0.05923087
Iteration 649, loss = 0.05910899
Iteration 650, loss = 0.05899004
Iteration 651, loss = 0.05887868
Iteration 652, loss = 0.05875718
Iteration 653, loss = 0.05864295
Iteration 654, loss = 0.05852461
Iteration 655, loss = 0.05841289
Iteration 656, loss = 0.05829582
Iteration 657, loss = 0.05817824
Iteration 658, loss = 0.05806401
Iteration 659, loss = 0.05795109
Iteration 660, loss = 0.05783624
Iteration 661, loss = 0.05772784
Iteration 662, loss = 0.05761540
Iteration 663, loss = 0.05750819
Iteration 664, loss = 0.05739442
Iteration 665, loss = 0.05728743
Iteration 666, loss = 0.05717964
Iteration 667, loss = 0.05707119
Iteration 668, loss = 0.05696422
Iteration 669, loss = 0.05685734
Iteration 670, loss = 0.05675048
Iteration 671, loss = 0.05664812
Iteration 672, loss = 0.05653820
Iteration 673, loss = 0.05643212
Iteration 674, loss = 0.05632670
Iteration 675, loss = 0.05622344
Iteration 676, loss = 0.05611782
Iteration 677, loss = 0.05601279
Iteration 678, loss = 0.05590683
Iteration 679, loss = 0.05580956
Iteration 680, loss = 0.05570311
Iteration 681, loss = 0.05560013
Iteration 682, loss = 0.05549813
Iteration 683, loss = 0.05539424
Iteration 684, loss = 0.05529228
Iteration 685, loss = 0.05519013
Iteration 686, loss = 0.05508614
Iteration 687, loss = 0.05499052
Iteration 688, loss = 0.05488469
Iteration 689, loss = 0.05478320
Iteration 690, loss = 0.05468516
Iteration 691, loss = 0.05458187
Iteration 692, loss = 0.05448575
Iteration 693, loss = 0.05438144
Iteration 694, loss = 0.05428682
Iteration 695, loss = 0.05418412
Iteration 696, loss = 0.05408520
Iteration 697, loss = 0.05398816
Iteration 698, loss = 0.05389139
Iteration 699, loss = 0.05380020
Iteration 700, loss = 0.05370049
Iteration 701, loss = 0.05360680
Iteration 702, loss = 0.05351176
Iteration 703, loss = 0.05342392
Iteration 704, loss = 0.05332149
Iteration 705, loss = 0.05322783
Iteration 706, loss = 0.05314021
Iteration 707, loss = 0.05304827
Iteration 708, loss = 0.05295685
Iteration 709, loss = 0.05286441
Iteration 710, loss = 0.05277285
Iteration 711, loss = 0.05268471
Iteration 712, loss = 0.05259427
Iteration 713, loss = 0.05250047
Iteration 714, loss = 0.05241273
Iteration 715, loss = 0.05231730
Iteration 716, loss = 0.05222763
Iteration 717, loss = 0.05213354
Iteration 718, loss = 0.05204161
Iteration 719, loss = 0.05196303
Iteration 720, loss = 0.05186455
Iteration 721, loss = 0.05177297
Iteration 722, loss = 0.05168276
Iteration 723, loss = 0.05159102
Iteration 724, loss = 0.05150362
Iteration 725, loss = 0.05141545
Iteration 726, loss = 0.05132477
Iteration 727, loss = 0.05123865
Iteration 728, loss = 0.05115881
Iteration 729, loss = 0.05106786
Iteration 730, loss = 0.05098160
Iteration 731, loss = 0.05089497
Iteration 732, loss = 0.05080801
Iteration 733, loss = 0.05072589
Iteration 734, loss = 0.05063851
Iteration 735, loss = 0.05055452
Iteration 736, loss = 0.05047682
Iteration 737, loss = 0.05039655
Iteration 738, loss = 0.05030678
Iteration 739, loss = 0.05022534
Iteration 740, loss = 0.05014540
Iteration 741, loss = 0.05005596
Iteration 742, loss = 0.04996764
Iteration 743, loss = 0.04988721
Iteration 744, loss = 0.04980243
Iteration 745, loss = 0.04971956
Iteration 746, loss = 0.04963881
Iteration 747, loss = 0.04955376
Iteration 748, loss = 0.04947686
Iteration 749, loss = 0.04938948
Iteration 750, loss = 0.04931164
Iteration 751, loss = 0.04923004
Iteration 752, loss = 0.04914751
Iteration 753, loss = 0.04907036
Iteration 754, loss = 0.04899260
Iteration 755, loss = 0.04891567
Iteration 756, loss = 0.04883706
Iteration 757, loss = 0.04875865
Iteration 758, loss = 0.04868632
Iteration 759, loss = 0.04860920
Iteration 760, loss = 0.04854157
Iteration 761, loss = 0.04846396
Iteration 762, loss = 0.04839154
Iteration 763, loss = 0.04831475
Iteration 764, loss = 0.04824041
Iteration 765, loss = 0.04816681
Iteration 766, loss = 0.04809278
Iteration 767, loss = 0.04801670
Iteration 768, loss = 0.04794465
Iteration 769, loss = 0.04786945
Iteration 770, loss = 0.04779356
Iteration 771, loss = 0.04772017
Iteration 772, loss = 0.04764464
Iteration 773, loss = 0.04757174
Iteration 774, loss = 0.04749746
Iteration 775, loss = 0.04742107
Iteration 776, loss = 0.04735039
Iteration 777, loss = 0.04727916
Iteration 778, loss = 0.04720445
Iteration 779, loss = 0.04713562
Iteration 780, loss = 0.04706325
Iteration 781, loss = 0.04698515
Iteration 782, loss = 0.04691467
Iteration 783, loss = 0.04683961
Iteration 784, loss = 0.04676876
Iteration 785, loss = 0.04669346
Iteration 786, loss = 0.04662427
Iteration 787, loss = 0.04655195
Iteration 788, loss = 0.04647945
Iteration 789, loss = 0.04640576
Iteration 790, loss = 0.04633919
Iteration 791, loss = 0.04626882
Iteration 792, loss = 0.04619986
Iteration 793, loss = 0.04613062
Iteration 794, loss = 0.04606190
Iteration 795, loss = 0.04599439
Iteration 796, loss = 0.04592815
Iteration 797, loss = 0.04586216
Iteration 798, loss = 0.04579262
Iteration 799, loss = 0.04572566
Iteration 800, loss = 0.04566200
Iteration 801, loss = 0.04559019
Iteration 802, loss = 0.04552273
Iteration 803, loss = 0.04545719
Iteration 804, loss = 0.04538910
Iteration 805, loss = 0.04532429
Iteration 806, loss = 0.04526111
Iteration 807, loss = 0.04519680
Iteration 808, loss = 0.04513179
Iteration 809, loss = 0.04506805
Iteration 810, loss = 0.04500488
Iteration 811, loss = 0.04494126
Iteration 812, loss = 0.04487216
Iteration 813, loss = 0.04481089
Iteration 814, loss = 0.04474332
Iteration 815, loss = 0.04467863
Iteration 816, loss = 0.04461122
Iteration 817, loss = 0.04454580
Iteration 818, loss = 0.04448350
Iteration 819, loss = 0.04441403
Iteration 820, loss = 0.04435051
Iteration 821, loss = 0.04428239
Iteration 822, loss = 0.04421885
Iteration 823, loss = 0.04415594
Iteration 824, loss = 0.04409041
Iteration 825, loss = 0.04402350
Iteration 826, loss = 0.04395912
Iteration 827, loss = 0.04390300
Iteration 828, loss = 0.04382906
Iteration 829, loss = 0.04377006
Iteration 830, loss = 0.04370631
Iteration 831, loss = 0.04364396
Iteration 832, loss = 0.04358436
Iteration 833, loss = 0.04352350
Iteration 834, loss = 0.04346148
Iteration 835, loss = 0.04340080
Iteration 836, loss = 0.04334149
Iteration 837, loss = 0.04328275
Iteration 838, loss = 0.04322104
Iteration 839, loss = 0.04316208
Iteration 840, loss = 0.04310418
Iteration 841, loss = 0.04304501
Iteration 842, loss = 0.04298552
Iteration 843, loss = 0.04292735
Iteration 844, loss = 0.04286904
Iteration 845, loss = 0.04281165
Iteration 846, loss = 0.04275498
Iteration 847, loss = 0.04269756
Iteration 848, loss = 0.04264027
Iteration 849, loss = 0.04258212
Iteration 850, loss = 0.04252792
Iteration 851, loss = 0.04246871
Iteration 852, loss = 0.04241240
Iteration 853, loss = 0.04235592
Iteration 854, loss = 0.04229926
Iteration 855, loss = 0.04224116
Iteration 856, loss = 0.04218301
Iteration 857, loss = 0.04213009
Iteration 858, loss = 0.04207248
Iteration 859, loss = 0.04201714
Iteration 860, loss = 0.04196232
Iteration 861, loss = 0.04190479
Iteration 862, loss = 0.04184997
Iteration 863, loss = 0.04179138
Iteration 864, loss = 0.04173454
Iteration 865, loss = 0.04167552
Iteration 866, loss = 0.04162152
Iteration 867, loss = 0.04156551
Iteration 868, loss = 0.04151032
Iteration 869, loss = 0.04145719
Iteration 870, loss = 0.04140540
Iteration 871, loss = 0.04135483
Iteration 872, loss = 0.04129942
Iteration 873, loss = 0.04124294
Iteration 874, loss = 0.04118958
Iteration 875, loss = 0.04113580
Iteration 876, loss = 0.04107989
Iteration 877, loss = 0.04103323
Iteration 878, loss = 0.04097406
Iteration 879, loss = 0.04091948
Iteration 880, loss = 0.04086539
Iteration 881, loss = 0.04081344
Iteration 882, loss = 0.04075807
Iteration 883, loss = 0.04070476
Iteration 884, loss = 0.04064906
Iteration 885, loss = 0.04059541
Iteration 886, loss = 0.04054233
Iteration 887, loss = 0.04048975
Iteration 888, loss = 0.04043988
Iteration 889, loss = 0.04038285
Iteration 890, loss = 0.04032945
Iteration 891, loss = 0.04027616
Iteration 892, loss = 0.04022103
Iteration 893, loss = 0.04016776
Iteration 894, loss = 0.04011563
Iteration 895, loss = 0.04005948
Iteration 896, loss = 0.04000705
Iteration 897, loss = 0.03995684
Iteration 898, loss = 0.03990230
Iteration 899, loss = 0.03984921
Iteration 900, loss = 0.03979678
Iteration 901, loss = 0.03974684
Iteration 902, loss = 0.03969539
Iteration 903, loss = 0.03964318
Iteration 904, loss = 0.03959747
Iteration 905, loss = 0.03953934
Iteration 906, loss = 0.03948849
Iteration 907, loss = 0.03943614
Iteration 908, loss = 0.03938580
Iteration 909, loss = 0.03933651
Iteration 910, loss = 0.03928528
Iteration 911, loss = 0.03923540
Iteration 912, loss = 0.03918707
Iteration 913, loss = 0.03913689
Iteration 914, loss = 0.03908830
Iteration 915, loss = 0.03904243
Iteration 916, loss = 0.03899088
Iteration 917, loss = 0.03894184
Iteration 918, loss = 0.03889529
Iteration 919, loss = 0.03884302
Iteration 920, loss = 0.03879826
Iteration 921, loss = 0.03874740
Iteration 922, loss = 0.03869612
Iteration 923, loss = 0.03864815
Iteration 924, loss = 0.03860191
Iteration 925, loss = 0.03855179
Iteration 926, loss = 0.03850332
Iteration 927, loss = 0.03845417
Iteration 928, loss = 0.03840718
Iteration 929, loss = 0.03836240
Iteration 930, loss = 0.03831378
Iteration 931, loss = 0.03826433
Iteration 932, loss = 0.03821542
Iteration 933, loss = 0.03816871
Iteration 934, loss = 0.03812445
Iteration 935, loss = 0.03807890
Iteration 936, loss = 0.03803242
Iteration 937, loss = 0.03799252
Iteration 938, loss = 0.03794492
Iteration 939, loss = 0.03790008
Iteration 940, loss = 0.03785255
Iteration 941, loss = 0.03780182
Iteration 942, loss = 0.03776044
Iteration 943, loss = 0.03771074
Iteration 944, loss = 0.03766978
Iteration 945, loss = 0.03762067
Iteration 946, loss = 0.03757792
Iteration 947, loss = 0.03753305
Iteration 948, loss = 0.03748701
Iteration 949, loss = 0.03744278
Iteration 950, loss = 0.03739757
Iteration 951, loss = 0.03734986
Iteration 952, loss = 0.03730249
Iteration 953, loss = 0.03725780
Iteration 954, loss = 0.03721227
Iteration 955, loss = 0.03716625
Iteration 956, loss = 0.03712377
Iteration 957, loss = 0.03707881
Iteration 958, loss = 0.03703411
Iteration 959, loss = 0.03699111
Iteration 960, loss = 0.03694926
Iteration 961, loss = 0.03690235
Iteration 962, loss = 0.03685919
Iteration 963, loss = 0.03681587
Iteration 964, loss = 0.03677341
Iteration 965, loss = 0.03673050
Iteration 966, loss = 0.03668740
Iteration 967, loss = 0.03664584
Iteration 968, loss = 0.03660403
Iteration 969, loss = 0.03655867
Iteration 970, loss = 0.03651630
Iteration 971, loss = 0.03647304
Iteration 972, loss = 0.03642762
Iteration 973, loss = 0.03638370
Iteration 974, loss = 0.03634316
Iteration 975, loss = 0.03630036
Iteration 976, loss = 0.03625731
Iteration 977, loss = 0.03621325
Iteration 978, loss = 0.03617169
Iteration 979, loss = 0.03612981
Iteration 980, loss = 0.03608859
Iteration 981, loss = 0.03604744
Iteration 982, loss = 0.03600597
Iteration 983, loss = 0.03596561
Iteration 984, loss = 0.03592575
Iteration 985, loss = 0.03588427
Iteration 986, loss = 0.03584383
Iteration 987, loss = 0.03580354
Iteration 988, loss = 0.03576738
Iteration 989, loss = 0.03572495
Iteration 990, loss = 0.03569163
Iteration 991, loss = 0.03564988
Iteration 992, loss = 0.03560737
Iteration 993, loss = 0.03556651
Iteration 994, loss = 0.03552667
Iteration 995, loss = 0.03548399
Iteration 996, loss = 0.03544463
Iteration 997, loss = 0.03540456
Iteration 998, loss = 0.03536446
Iteration 999, loss = 0.03532388
Iteration 1000, loss = 0.03528408
Iteration 1001, loss = 0.03524785
Iteration 1002, loss = 0.03520654
Iteration 1003, loss = 0.03516620
Iteration 1004, loss = 0.03512874
Iteration 1005, loss = 0.03509012
Iteration 1006, loss = 0.03505225
Iteration 1007, loss = 0.03501542
Iteration 1008, loss = 0.03497485
Iteration 1009, loss = 0.03493696
Iteration 1010, loss = 0.03489943
Iteration 1011, loss = 0.03485964
Iteration 1012, loss = 0.03482318
Iteration 1013, loss = 0.03478136
Iteration 1014, loss = 0.03474552
Iteration 1015, loss = 0.03470698
Iteration 1016, loss = 0.03467037
Iteration 1017, loss = 0.03463211
Iteration 1018, loss = 0.03459507
Iteration 1019, loss = 0.03455758
Iteration 1020, loss = 0.03452190
Iteration 1021, loss = 0.03448403
Iteration 1022, loss = 0.03445069
Iteration 1023, loss = 0.03440893
Iteration 1024, loss = 0.03437014
Iteration 1025, loss = 0.03433119
Iteration 1026, loss = 0.03429256
Iteration 1027, loss = 0.03425514
Iteration 1028, loss = 0.03421805
Iteration 1029, loss = 0.03418063
Iteration 1030, loss = 0.03414169
Iteration 1031, loss = 0.03410397
Iteration 1032, loss = 0.03406802
Iteration 1033, loss = 0.03403026
Iteration 1034, loss = 0.03399170
Iteration 1035, loss = 0.03395303
Iteration 1036, loss = 0.03391583
Iteration 1037, loss = 0.03387877
Iteration 1038, loss = 0.03384050
Iteration 1039, loss = 0.03380688
Iteration 1040, loss = 0.03376359
Iteration 1041, loss = 0.03372954
Iteration 1042, loss = 0.03368771
Iteration 1043, loss = 0.03365305
Iteration 1044, loss = 0.03361631
Iteration 1045, loss = 0.03357876
Iteration 1046, loss = 0.03354525
Iteration 1047, loss = 0.03350850
Iteration 1048, loss = 0.03347248
Iteration 1049, loss = 0.03343816
Iteration 1050, loss = 0.03340080
Iteration 1051, loss = 0.03336410
Iteration 1052, loss = 0.03332842
Iteration 1053, loss = 0.03329490
Iteration 1054, loss = 0.03325781
Iteration 1055, loss = 0.03322231
Iteration 1056, loss = 0.03318611
Iteration 1057, loss = 0.03315285
Iteration 1058, loss = 0.03311845
Iteration 1059, loss = 0.03308563
Iteration 1060, loss = 0.03305018
Iteration 1061, loss = 0.03301610
Iteration 1062, loss = 0.03297896
Iteration 1063, loss = 0.03294441
Iteration 1064, loss = 0.03290909
Iteration 1065, loss = 0.03287586
Iteration 1066, loss = 0.03284193
Iteration 1067, loss = 0.03280509
Iteration 1068, loss = 0.03277422
Iteration 1069, loss = 0.03274111
Iteration 1070, loss = 0.03270917
Iteration 1071, loss = 0.03267639
Iteration 1072, loss = 0.03264340
Iteration 1073, loss = 0.03261017
Iteration 1074, loss = 0.03257842
Iteration 1075, loss = 0.03254489
Iteration 1076, loss = 0.03251190
Iteration 1077, loss = 0.03248362
Iteration 1078, loss = 0.03244591
Iteration 1079, loss = 0.03241298
Iteration 1080, loss = 0.03237911
Iteration 1081, loss = 0.03234656
Iteration 1082, loss = 0.03231027
Iteration 1083, loss = 0.03227463
Iteration 1084, loss = 0.03224039
Iteration 1085, loss = 0.03220752
Iteration 1086, loss = 0.03217478
Iteration 1087, loss = 0.03214329
Iteration 1088, loss = 0.03211066
Iteration 1089, loss = 0.03207681
Iteration 1090, loss = 0.03204453
Iteration 1091, loss = 0.03201204
Iteration 1092, loss = 0.03197923
Iteration 1093, loss = 0.03194701
Iteration 1094, loss = 0.03191489
Iteration 1095, loss = 0.03188037
Iteration 1096, loss = 0.03185059
Iteration 1097, loss = 0.03181756
Iteration 1098, loss = 0.03178314
Iteration 1099, loss = 0.03174749
Iteration 1100, loss = 0.03171691
Iteration 1101, loss = 0.03168192
Iteration 1102, loss = 0.03165206
Iteration 1103, loss = 0.03162079
Iteration 1104, loss = 0.03158813
Iteration 1105, loss = 0.03155936
Iteration 1106, loss = 0.03152870
Iteration 1107, loss = 0.03149796
Iteration 1108, loss = 0.03146628
Iteration 1109, loss = 0.03143704
Iteration 1110, loss = 0.03140863
Iteration 1111, loss = 0.03137553
Iteration 1112, loss = 0.03134296
Iteration 1113, loss = 0.03131267
Iteration 1114, loss = 0.03127878
Iteration 1115, loss = 0.03124688
Iteration 1116, loss = 0.03121678
Iteration 1117, loss = 0.03118187
Iteration 1118, loss = 0.03115411
Iteration 1119, loss = 0.03112184
Iteration 1120, loss = 0.03109160
Iteration 1121, loss = 0.03106068
Iteration 1122, loss = 0.03103304
Iteration 1123, loss = 0.03100157
Iteration 1124, loss = 0.03096983
Iteration 1125, loss = 0.03094167
Iteration 1126, loss = 0.03091037
Iteration 1127, loss = 0.03088073
Iteration 1128, loss = 0.03084912
Iteration 1129, loss = 0.03081958
Iteration 1130, loss = 0.03078914
Iteration 1131, loss = 0.03076029
Iteration 1132, loss = 0.03073303
Iteration 1133, loss = 0.03070185
Iteration 1134, loss = 0.03067286
Iteration 1135, loss = 0.03064231
Iteration 1136, loss = 0.03061276
Iteration 1137, loss = 0.03058191
Iteration 1138, loss = 0.03055348
Iteration 1139, loss = 0.03052680
Iteration 1140, loss = 0.03049754
Iteration 1141, loss = 0.03046910
Iteration 1142, loss = 0.03043897
Iteration 1143, loss = 0.03040684
Iteration 1144, loss = 0.03037708
Iteration 1145, loss = 0.03034776
Iteration 1146, loss = 0.03032162
Iteration 1147, loss = 0.03029456
Iteration 1148, loss = 0.03026453
Iteration 1149, loss = 0.03023400
Iteration 1150, loss = 0.03020468
Iteration 1151, loss = 0.03017803
Iteration 1152, loss = 0.03014864
Iteration 1153, loss = 0.03012016
Iteration 1154, loss = 0.03009373
Iteration 1155, loss = 0.03006571
Iteration 1156, loss = 0.03003838
Iteration 1157, loss = 0.03001230
Iteration 1158, loss = 0.02998432
Iteration 1159, loss = 0.02995825
Iteration 1160, loss = 0.02993156
Iteration 1161, loss = 0.02990619
Iteration 1162, loss = 0.02987840
Iteration 1163, loss = 0.02985198
Iteration 1164, loss = 0.02982507
Iteration 1165, loss = 0.02980026
Iteration 1166, loss = 0.02977179
Iteration 1167, loss = 0.02974541
Iteration 1168, loss = 0.02971901
Iteration 1169, loss = 0.02969159
Iteration 1170, loss = 0.02966293
Iteration 1171, loss = 0.02963451
Iteration 1172, loss = 0.02960845
Iteration 1173, loss = 0.02957528
Iteration 1174, loss = 0.02954816
Iteration 1175, loss = 0.02952049
Iteration 1176, loss = 0.02949022
Iteration 1177, loss = 0.02946129
Iteration 1178, loss = 0.02943304
Iteration 1179, loss = 0.02940621
Iteration 1180, loss = 0.02937669
Iteration 1181, loss = 0.02934890
Iteration 1182, loss = 0.02932096
Iteration 1183, loss = 0.02929329
Iteration 1184, loss = 0.02926669
Iteration 1185, loss = 0.02923958
Iteration 1186, loss = 0.02921441
Iteration 1187, loss = 0.02918643
Iteration 1188, loss = 0.02915980
Iteration 1189, loss = 0.02913323
Iteration 1190, loss = 0.02910677
Iteration 1191, loss = 0.02908709
Iteration 1192, loss = 0.02906193
Iteration 1193, loss = 0.02903464
Iteration 1194, loss = 0.02901012
Iteration 1195, loss = 0.02898323
Iteration 1196, loss = 0.02895806
Iteration 1197, loss = 0.02893089
Iteration 1198, loss = 0.02890300
Iteration 1199, loss = 0.02887679
Iteration 1200, loss = 0.02885088
Iteration 1201, loss = 0.02882335
Iteration 1202, loss = 0.02879625
Iteration 1203, loss = 0.02877186
Iteration 1204, loss = 0.02874458
Iteration 1205, loss = 0.02871523
Iteration 1206, loss = 0.02868803
Iteration 1207, loss = 0.02865934
Iteration 1208, loss = 0.02863174
Iteration 1209, loss = 0.02860912
Iteration 1210, loss = 0.02858244
Iteration 1211, loss = 0.02855043
Iteration 1212, loss = 0.02852572
Iteration 1213, loss = 0.02849560
Iteration 1214, loss = 0.02847031
Iteration 1215, loss = 0.02844312
Iteration 1216, loss = 0.02841713
Iteration 1217, loss = 0.02838554
Iteration 1218, loss = 0.02836096
Iteration 1219, loss = 0.02833323
Iteration 1220, loss = 0.02830572
Iteration 1221, loss = 0.02828210
Iteration 1222, loss = 0.02825373
Iteration 1223, loss = 0.02822626
Iteration 1224, loss = 0.02820215
Iteration 1225, loss = 0.02817078
Iteration 1226, loss = 0.02814939
Iteration 1227, loss = 0.02812460
Iteration 1228, loss = 0.02809354
Iteration 1229, loss = 0.02806649
Iteration 1230, loss = 0.02804124
Iteration 1231, loss = 0.02801446
Iteration 1232, loss = 0.02798714
Iteration 1233, loss = 0.02796118
Iteration 1234, loss = 0.02793614
Iteration 1235, loss = 0.02791158
Iteration 1236, loss = 0.02788631
Iteration 1237, loss = 0.02786560
Iteration 1238, loss = 0.02783677
Iteration 1239, loss = 0.02781072
Iteration 1240, loss = 0.02778956
Iteration 1241, loss = 0.02776633
Iteration 1242, loss = 0.02773586
Iteration 1243, loss = 0.02771573
Iteration 1244, loss = 0.02769329
Iteration 1245, loss = 0.02766482
Iteration 1246, loss = 0.02764110
Iteration 1247, loss = 0.02761580
Iteration 1248, loss = 0.02759111
Iteration 1249, loss = 0.02756551
Iteration 1250, loss = 0.02754498
Iteration 1251, loss = 0.02751806
Iteration 1252, loss = 0.02749420
Iteration 1253, loss = 0.02746856
Iteration 1254, loss = 0.02744553
Iteration 1255, loss = 0.02742291
Iteration 1256, loss = 0.02739786
Iteration 1257, loss = 0.02737087
Iteration 1258, loss = 0.02734594
Iteration 1259, loss = 0.02732696
Iteration 1260, loss = 0.02729802
Iteration 1261, loss = 0.02727607
Iteration 1262, loss = 0.02725064
Iteration 1263, loss = 0.02722760
Iteration 1264, loss = 0.02720410
Iteration 1265, loss = 0.02718009
Iteration 1266, loss = 0.02715700
Iteration 1267, loss = 0.02713422
Iteration 1268, loss = 0.02710924
Iteration 1269, loss = 0.02708484
Iteration 1270, loss = 0.02706052
Iteration 1271, loss = 0.02703529
Iteration 1272, loss = 0.02701247
Iteration 1273, loss = 0.02698865
Iteration 1274, loss = 0.02696576
Iteration 1275, loss = 0.02694285
Iteration 1276, loss = 0.02691980
Iteration 1277, loss = 0.02689662
Iteration 1278, loss = 0.02687692
Iteration 1279, loss = 0.02685358
Iteration 1280, loss = 0.02683163
Iteration 1281, loss = 0.02680958
Iteration 1282, loss = 0.02678561
Iteration 1283, loss = 0.02676461
Iteration 1284, loss = 0.02674104
Iteration 1285, loss = 0.02671944
Iteration 1286, loss = 0.02669981
Iteration 1287, loss = 0.02667690
Iteration 1288, loss = 0.02665337
Iteration 1289, loss = 0.02663320
Iteration 1290, loss = 0.02661082
Iteration 1291, loss = 0.02659045
Iteration 1292, loss = 0.02656746
Iteration 1293, loss = 0.02654283
Iteration 1294, loss = 0.02652105
Iteration 1295, loss = 0.02649513
Iteration 1296, loss = 0.02647495
Iteration 1297, loss = 0.02644640
Iteration 1298, loss = 0.02642204
Iteration 1299, loss = 0.02639860
Iteration 1300, loss = 0.02637474
Iteration 1301, loss = 0.02635008
Iteration 1302, loss = 0.02632681
Iteration 1303, loss = 0.02630558
Iteration 1304, loss = 0.02628181
Iteration 1305, loss = 0.02625745
Iteration 1306, loss = 0.02623381
Iteration 1307, loss = 0.02621076
Iteration 1308, loss = 0.02618683
Iteration 1309, loss = 0.02616552
Iteration 1310, loss = 0.02614133
Iteration 1311, loss = 0.02611991
Iteration 1312, loss = 0.02610079
Iteration 1313, loss = 0.02607542
Iteration 1314, loss = 0.02605325
Iteration 1315, loss = 0.02603113
Iteration 1316, loss = 0.02600907
Iteration 1317, loss = 0.02598664
Iteration 1318, loss = 0.02596584
Iteration 1319, loss = 0.02594714
Iteration 1320, loss = 0.02591985
Iteration 1321, loss = 0.02589711
Iteration 1322, loss = 0.02587326
Iteration 1323, loss = 0.02585424
Iteration 1324, loss = 0.02582976
Iteration 1325, loss = 0.02580857
Iteration 1326, loss = 0.02578708
Iteration 1327, loss = 0.02577092
Iteration 1328, loss = 0.02574255
Iteration 1329, loss = 0.02572184
Iteration 1330, loss = 0.02569897
Iteration 1331, loss = 0.02568150
Iteration 1332, loss = 0.02565591
Iteration 1333, loss = 0.02563248
Iteration 1334, loss = 0.02561326
Iteration 1335, loss = 0.02559229
Iteration 1336, loss = 0.02556815
Iteration 1337, loss = 0.02554922
Iteration 1338, loss = 0.02552497
Iteration 1339, loss = 0.02550448
Iteration 1340, loss = 0.02548362
Iteration 1341, loss = 0.02546138
Iteration 1342, loss = 0.02543939
Iteration 1343, loss = 0.02541781
Iteration 1344, loss = 0.02540156
Iteration 1345, loss = 0.02537816
Iteration 1346, loss = 0.02535618
Iteration 1347, loss = 0.02533663
Iteration 1348, loss = 0.02531581
Iteration 1349, loss = 0.02529806
Iteration 1350, loss = 0.02527425
Iteration 1351, loss = 0.02525245
Iteration 1352, loss = 0.02523004
Iteration 1353, loss = 0.02520833
Iteration 1354, loss = 0.02518739
Iteration 1355, loss = 0.02516635
Iteration 1356, loss = 0.02514633
Iteration 1357, loss = 0.02512527
Iteration 1358, loss = 0.02510645
Iteration 1359, loss = 0.02508976
Iteration 1360, loss = 0.02506329
Iteration 1361, loss = 0.02504438
Iteration 1362, loss = 0.02502406
Iteration 1363, loss = 0.02500180
Iteration 1364, loss = 0.02498026
Iteration 1365, loss = 0.02495949
Iteration 1366, loss = 0.02493900
Iteration 1367, loss = 0.02491783
Iteration 1368, loss = 0.02489763
Iteration 1369, loss = 0.02487672
Iteration 1370, loss = 0.02485590
Iteration 1371, loss = 0.02483658
Iteration 1372, loss = 0.02481617
Iteration 1373, loss = 0.02479553
Iteration 1374, loss = 0.02477568
Iteration 1375, loss = 0.02475535
Iteration 1376, loss = 0.02473614
Iteration 1377, loss = 0.02471677
Iteration 1378, loss = 0.02469974
Iteration 1379, loss = 0.02467969
Iteration 1380, loss = 0.02466015
Iteration 1381, loss = 0.02464041
Iteration 1382, loss = 0.02462118
Iteration 1383, loss = 0.02460179
Iteration 1384, loss = 0.02458209
Iteration 1385, loss = 0.02456008
Iteration 1386, loss = 0.02453782
Iteration 1387, loss = 0.02451906
Iteration 1388, loss = 0.02449822
Iteration 1389, loss = 0.02447842
Iteration 1390, loss = 0.02445908
Iteration 1391, loss = 0.02443792
Iteration 1392, loss = 0.02441770
Iteration 1393, loss = 0.02439790
Iteration 1394, loss = 0.02437990
Iteration 1395, loss = 0.02436191
Iteration 1396, loss = 0.02434538
Iteration 1397, loss = 0.02432440
Iteration 1398, loss = 0.02430426
Iteration 1399, loss = 0.02428643
Iteration 1400, loss = 0.02426682
Iteration 1401, loss = 0.02424811
Iteration 1402, loss = 0.02422596
Iteration 1403, loss = 0.02420643
Iteration 1404, loss = 0.02418649
Iteration 1405, loss = 0.02416867
Iteration 1406, loss = 0.02414869
Iteration 1407, loss = 0.02412939
Iteration 1408, loss = 0.02411322
Iteration 1409, loss = 0.02409468
Iteration 1410, loss = 0.02407356
Iteration 1411, loss = 0.02405509
Iteration 1412, loss = 0.02403684
Iteration 1413, loss = 0.02402089
Iteration 1414, loss = 0.02400034
Iteration 1415, loss = 0.02398210
Iteration 1416, loss = 0.02396374
Iteration 1417, loss = 0.02394493
Iteration 1418, loss = 0.02392727
Iteration 1419, loss = 0.02390986
Iteration 1420, loss = 0.02389243
Iteration 1421, loss = 0.02387105
Iteration 1422, loss = 0.02385249
Iteration 1423, loss = 0.02383378
Iteration 1424, loss = 0.02381368
Iteration 1425, loss = 0.02379522
Iteration 1426, loss = 0.02377714
Iteration 1427, loss = 0.02375912
Iteration 1428, loss = 0.02374433
Iteration 1429, loss = 0.02372139
Iteration 1430, loss = 0.02370029
Iteration 1431, loss = 0.02368388
Iteration 1432, loss = 0.02366475
Iteration 1433, loss = 0.02364545
Iteration 1434, loss = 0.02362650
Iteration 1435, loss = 0.02361165
Iteration 1436, loss = 0.02359050
Iteration 1437, loss = 0.02357263
Iteration 1438, loss = 0.02355510
Iteration 1439, loss = 0.02353561
Iteration 1440, loss = 0.02352216
Iteration 1441, loss = 0.02349992
Iteration 1442, loss = 0.02348012
Iteration 1443, loss = 0.02346137
Iteration 1444, loss = 0.02344434
Iteration 1445, loss = 0.02342654
Iteration 1446, loss = 0.02340888
Iteration 1447, loss = 0.02338802
Iteration 1448, loss = 0.02337006
Iteration 1449, loss = 0.02335300
Iteration 1450, loss = 0.02333507
Iteration 1451, loss = 0.02331862
Iteration 1452, loss = 0.02330038
Iteration 1453, loss = 0.02328222
Iteration 1454, loss = 0.02326555
Iteration 1455, loss = 0.02324640
Iteration 1456, loss = 0.02322880
Iteration 1457, loss = 0.02321178
Iteration 1458, loss = 0.02319466
Iteration 1459, loss = 0.02317688
Iteration 1460, loss = 0.02315858
Iteration 1461, loss = 0.02314004
Iteration 1462, loss = 0.02312426
Iteration 1463, loss = 0.02310904
Iteration 1464, loss = 0.02308798
Iteration 1465, loss = 0.02307014
Iteration 1466, loss = 0.02305138
Iteration 1467, loss = 0.02303385
Iteration 1468, loss = 0.02301693
Iteration 1469, loss = 0.02299926
Iteration 1470, loss = 0.02298030
Iteration 1471, loss = 0.02296387
Iteration 1472, loss = 0.02294238
Iteration 1473, loss = 0.02292469
Iteration 1474, loss = 0.02290937
Iteration 1475, loss = 0.02289579
Iteration 1476, loss = 0.02287536
Iteration 1477, loss = 0.02285923
Iteration 1478, loss = 0.02284229
Iteration 1479, loss = 0.02282491
Iteration 1480, loss = 0.02281135
Iteration 1481, loss = 0.02279265
Iteration 1482, loss = 0.02277642
Iteration 1483, loss = 0.02275815
Iteration 1484, loss = 0.02274134
Iteration 1485, loss = 0.02272418
Iteration 1486, loss = 0.02270641
Iteration 1487, loss = 0.02268969
Iteration 1488, loss = 0.02267134
Iteration 1489, loss = 0.02265516
Iteration 1490, loss = 0.02263838
Iteration 1491, loss = 0.02262174
Iteration 1492, loss = 0.02260451
Iteration 1493, loss = 0.02258841
Iteration 1494, loss = 0.02257148
Iteration 1495, loss = 0.02255536
Iteration 1496, loss = 0.02253876
Iteration 1497, loss = 0.02252249
Iteration 1498, loss = 0.02250590
Iteration 1499, loss = 0.02248795
Iteration 1500, loss = 0.02246919
Iteration 1501, loss = 0.02245418
Iteration 1502, loss = 0.02243648
Iteration 1503, loss = 0.02241994
Iteration 1504, loss = 0.02240199
Iteration 1505, loss = 0.02238688
Iteration 1506, loss = 0.02236838
Iteration 1507, loss = 0.02234965
Iteration 1508, loss = 0.02232953
Iteration 1509, loss = 0.02231396
Iteration 1510, loss = 0.02229849
Iteration 1511, loss = 0.02227720
Iteration 1512, loss = 0.02226212
Iteration 1513, loss = 0.02224434
Iteration 1514, loss = 0.02222747
Iteration 1515, loss = 0.02221340
Iteration 1516, loss = 0.02219566
Iteration 1517, loss = 0.02217999
Iteration 1518, loss = 0.02216395
Iteration 1519, loss = 0.02214900
Iteration 1520, loss = 0.02213258
Iteration 1521, loss = 0.02211736
Iteration 1522, loss = 0.02210054
Iteration 1523, loss = 0.02208455
Iteration 1524, loss = 0.02206944
Iteration 1525, loss = 0.02205209
Iteration 1526, loss = 0.02203465
Iteration 1527, loss = 0.02201736
Iteration 1528, loss = 0.02200117
Iteration 1529, loss = 0.02198414
Iteration 1530, loss = 0.02196925
Iteration 1531, loss = 0.02195120
Iteration 1532, loss = 0.02193785
Iteration 1533, loss = 0.02192189
Iteration 1534, loss = 0.02190533
Iteration 1535, loss = 0.02188942
Iteration 1536, loss = 0.02187329
Iteration 1537, loss = 0.02185771
Iteration 1538, loss = 0.02184384
Iteration 1539, loss = 0.02182765
Iteration 1540, loss = 0.02181195
Iteration 1541, loss = 0.02179673
Iteration 1542, loss = 0.02178096
Iteration 1543, loss = 0.02176557
Iteration 1544, loss = 0.02175126
Iteration 1545, loss = 0.02173559
Iteration 1546, loss = 0.02172024
Iteration 1547, loss = 0.02170752
Iteration 1548, loss = 0.02168982
Iteration 1549, loss = 0.02167418
Iteration 1550, loss = 0.02165854
Iteration 1551, loss = 0.02164319
Iteration 1552, loss = 0.02162751
Iteration 1553, loss = 0.02161291
Iteration 1554, loss = 0.02159664
Iteration 1555, loss = 0.02158210
Iteration 1556, loss = 0.02156615
Iteration 1557, loss = 0.02155132
Iteration 1558, loss = 0.02153602
Iteration 1559, loss = 0.02152169
Iteration 1560, loss = 0.02150777
Iteration 1561, loss = 0.02149247
Iteration 1562, loss = 0.02147450
Iteration 1563, loss = 0.02145919
Iteration 1564, loss = 0.02144396
Iteration 1565, loss = 0.02142864
Iteration 1566, loss = 0.02141485
Iteration 1567, loss = 0.02139846
Iteration 1568, loss = 0.02138438
Iteration 1569, loss = 0.02136813
Iteration 1570, loss = 0.02135469
Iteration 1571, loss = 0.02133844
Iteration 1572, loss = 0.02132320
Iteration 1573, loss = 0.02130628
Iteration 1574, loss = 0.02128927
Iteration 1575, loss = 0.02127627
Iteration 1576, loss = 0.02125849
Iteration 1577, loss = 0.02124541
Iteration 1578, loss = 0.02122920
Iteration 1579, loss = 0.02121393
Iteration 1580, loss = 0.02119904
Iteration 1581, loss = 0.02118437
Iteration 1582, loss = 0.02117049
Iteration 1583, loss = 0.02115477
Iteration 1584, loss = 0.02114042
Iteration 1585, loss = 0.02112689
Iteration 1586, loss = 0.02111234
Iteration 1587, loss = 0.02109917
Iteration 1588, loss = 0.02108387
Iteration 1589, loss = 0.02107018
Iteration 1590, loss = 0.02105550
Iteration 1591, loss = 0.02104140
Iteration 1592, loss = 0.02102474
Iteration 1593, loss = 0.02101070
Iteration 1594, loss = 0.02099547
Iteration 1595, loss = 0.02098113
Iteration 1596, loss = 0.02096846
Iteration 1597, loss = 0.02095165
Iteration 1598, loss = 0.02093520
Iteration 1599, loss = 0.02091866
Iteration 1600, loss = 0.02090665
Iteration 1601, loss = 0.02088921
Iteration 1602, loss = 0.02087413
Iteration 1603, loss = 0.02085920
Iteration 1604, loss = 0.02084324
Iteration 1605, loss = 0.02082740
Iteration 1606, loss = 0.02081494
Iteration 1607, loss = 0.02079639
Iteration 1608, loss = 0.02077978
Iteration 1609, loss = 0.02076469
Iteration 1610, loss = 0.02074934
Iteration 1611, loss = 0.02073711
Iteration 1612, loss = 0.02072007
Iteration 1613, loss = 0.02070679
Iteration 1614, loss = 0.02069207
Iteration 1615, loss = 0.02067645
Iteration 1616, loss = 0.02066105
Iteration 1617, loss = 0.02065113
Iteration 1618, loss = 0.02063267
Iteration 1619, loss = 0.02061844
Iteration 1620, loss = 0.02060529
Iteration 1621, loss = 0.02058870
Iteration 1622, loss = 0.02057441
Iteration 1623, loss = 0.02056029
Iteration 1624, loss = 0.02054360
Iteration 1625, loss = 0.02052989
Iteration 1626, loss = 0.02051421
Iteration 1627, loss = 0.02049868
Iteration 1628, loss = 0.02048386
Iteration 1629, loss = 0.02046916
Iteration 1630, loss = 0.02045488
Iteration 1631, loss = 0.02043704
Iteration 1632, loss = 0.02042192
Iteration 1633, loss = 0.02040743
Iteration 1634, loss = 0.02039218
Iteration 1635, loss = 0.02037817
Iteration 1636, loss = 0.02036171
Iteration 1637, loss = 0.02034708
Iteration 1638, loss = 0.02033218
Iteration 1639, loss = 0.02031676
Iteration 1640, loss = 0.02030248
Iteration 1641, loss = 0.02028822
Iteration 1642, loss = 0.02027313
Iteration 1643, loss = 0.02025912
Iteration 1644, loss = 0.02024531
Iteration 1645, loss = 0.02023115
Iteration 1646, loss = 0.02021800
Iteration 1647, loss = 0.02020384
Iteration 1648, loss = 0.02019181
Iteration 1649, loss = 0.02017573
Iteration 1650, loss = 0.02016278
Iteration 1651, loss = 0.02014976
Iteration 1652, loss = 0.02013459
Iteration 1653, loss = 0.02012019
Iteration 1654, loss = 0.02010681
Iteration 1655, loss = 0.02009495
Iteration 1656, loss = 0.02007892
Iteration 1657, loss = 0.02006460
Iteration 1658, loss = 0.02005002
Iteration 1659, loss = 0.02003534
Iteration 1660, loss = 0.02002251
Iteration 1661, loss = 0.02000819
Iteration 1662, loss = 0.01999210
Iteration 1663, loss = 0.01997868
Iteration 1664, loss = 0.01996531
Iteration 1665, loss = 0.01995122
Iteration 1666, loss = 0.01993700
Iteration 1667, loss = 0.01992415
Iteration 1668, loss = 0.01991128
Iteration 1669, loss = 0.01989788
Iteration 1670, loss = 0.01988374
Iteration 1671, loss = 0.01986991
Iteration 1672, loss = 0.01985562
Iteration 1673, loss = 0.01984281
Iteration 1674, loss = 0.01982951
Iteration 1675, loss = 0.01981898
Iteration 1676, loss = 0.01980318
Iteration 1677, loss = 0.01979114
Iteration 1678, loss = 0.01977570
Iteration 1679, loss = 0.01976216
Iteration 1680, loss = 0.01975020
Iteration 1681, loss = 0.01973542
Iteration 1682, loss = 0.01972165
Iteration 1683, loss = 0.01970876
Iteration 1684, loss = 0.01969579
Iteration 1685, loss = 0.01968346
Iteration 1686, loss = 0.01966880
Iteration 1687, loss = 0.01965422
Iteration 1688, loss = 0.01964096
Iteration 1689, loss = 0.01962775
Iteration 1690, loss = 0.01961527
Iteration 1691, loss = 0.01960149
Iteration 1692, loss = 0.01958842
Iteration 1693, loss = 0.01957442
Iteration 1694, loss = 0.01956215
Iteration 1695, loss = 0.01954906
Iteration 1696, loss = 0.01953586
Iteration 1697, loss = 0.01952110
Iteration 1698, loss = 0.01950860
Iteration 1699, loss = 0.01949624
Iteration 1700, loss = 0.01948287
Iteration 1701, loss = 0.01946942
Iteration 1702, loss = 0.01945640
Iteration 1703, loss = 0.01944293
Iteration 1704, loss = 0.01943318
Iteration 1705, loss = 0.01941734
Iteration 1706, loss = 0.01940388
Iteration 1707, loss = 0.01939216
Iteration 1708, loss = 0.01937805
Iteration 1709, loss = 0.01936448
Iteration 1710, loss = 0.01935217
Iteration 1711, loss = 0.01933808
Iteration 1712, loss = 0.01932787
Iteration 1713, loss = 0.01931272
Iteration 1714, loss = 0.01930169
Iteration 1715, loss = 0.01928791
Iteration 1716, loss = 0.01927656
Iteration 1717, loss = 0.01925989
Iteration 1718, loss = 0.01925085
Iteration 1719, loss = 0.01923363
Iteration 1720, loss = 0.01922073
Iteration 1721, loss = 0.01920769
Iteration 1722, loss = 0.01919391
Iteration 1723, loss = 0.01918091
Iteration 1724, loss = 0.01916844
Iteration 1725, loss = 0.01915445
Iteration 1726, loss = 0.01914214
Iteration 1727, loss = 0.01912907
Iteration 1728, loss = 0.01911681
Iteration 1729, loss = 0.01910240
Iteration 1730, loss = 0.01908875
Iteration 1731, loss = 0.01907574
Iteration 1732, loss = 0.01906361
Iteration 1733, loss = 0.01905032
Iteration 1734, loss = 0.01903530
Iteration 1735, loss = 0.01902228
Iteration 1736, loss = 0.01901017
Iteration 1737, loss = 0.01899522
Iteration 1738, loss = 0.01898169
Iteration 1739, loss = 0.01896987
Iteration 1740, loss = 0.01895598
Iteration 1741, loss = 0.01894192
Iteration 1742, loss = 0.01892837
Iteration 1743, loss = 0.01891525
Iteration 1744, loss = 0.01890268
Iteration 1745, loss = 0.01888998
Iteration 1746, loss = 0.01887673
Iteration 1747, loss = 0.01886539
Iteration 1748, loss = 0.01885205
Iteration 1749, loss = 0.01884066
Iteration 1750, loss = 0.01883065
Iteration 1751, loss = 0.01881717
Iteration 1752, loss = 0.01880446
Iteration 1753, loss = 0.01879223
Iteration 1754, loss = 0.01878062
Iteration 1755, loss = 0.01876883
Iteration 1756, loss = 0.01875920
Iteration 1757, loss = 0.01874580
Iteration 1758, loss = 0.01873469
Iteration 1759, loss = 0.01872364
Iteration 1760, loss = 0.01871052
Iteration 1761, loss = 0.01869892
Iteration 1762, loss = 0.01868757
Iteration 1763, loss = 0.01867572
Iteration 1764, loss = 0.01866456
Iteration 1765, loss = 0.01865433
Iteration 1766, loss = 0.01864135
Iteration 1767, loss = 0.01862973
Iteration 1768, loss = 0.01861961
Iteration 1769, loss = 0.01860534
Iteration 1770, loss = 0.01859374
Iteration 1771, loss = 0.01858181
Iteration 1772, loss = 0.01857053
Iteration 1773, loss = 0.01855904
Iteration 1774, loss = 0.01854648
Iteration 1775, loss = 0.01853418
Iteration 1776, loss = 0.01852155
Iteration 1777, loss = 0.01850894
Iteration 1778, loss = 0.01849878
Iteration 1779, loss = 0.01848573
Iteration 1780, loss = 0.01847210
Iteration 1781, loss = 0.01845849
Iteration 1782, loss = 0.01844499
Iteration 1783, loss = 0.01843216
Iteration 1784, loss = 0.01842202
Iteration 1785, loss = 0.01840671
Iteration 1786, loss = 0.01839744
Iteration 1787, loss = 0.01838239
Iteration 1788, loss = 0.01836944
Iteration 1789, loss = 0.01836012
Iteration 1790, loss = 0.01834966
Iteration 1791, loss = 0.01833576
Iteration 1792, loss = 0.01832480
Iteration 1793, loss = 0.01831334
Iteration 1794, loss = 0.01830246
Iteration 1795, loss = 0.01829196
Iteration 1796, loss = 0.01828176
Iteration 1797, loss = 0.01826848
Iteration 1798, loss = 0.01825586
Iteration 1799, loss = 0.01824360
Iteration 1800, loss = 0.01823187
Iteration 1801, loss = 0.01821941
Iteration 1802, loss = 0.01820836
Iteration 1803, loss = 0.01819557
Iteration 1804, loss = 0.01818497
Iteration 1805, loss = 0.01817752
Iteration 1806, loss = 0.01816322
Iteration 1807, loss = 0.01815106
Iteration 1808, loss = 0.01814035
Iteration 1809, loss = 0.01812990
Iteration 1810, loss = 0.01811713
Iteration 1811, loss = 0.01810563
Iteration 1812, loss = 0.01809470
Iteration 1813, loss = 0.01808266
Iteration 1814, loss = 0.01807097
Iteration 1815, loss = 0.01806140
Iteration 1816, loss = 0.01804848
Iteration 1817, loss = 0.01804039
Iteration 1818, loss = 0.01802540
Iteration 1819, loss = 0.01801467
Iteration 1820, loss = 0.01800177
Iteration 1821, loss = 0.01799112
Iteration 1822, loss = 0.01798100
Iteration 1823, loss = 0.01796843
Iteration 1824, loss = 0.01795649
Iteration 1825, loss = 0.01794513
Iteration 1826, loss = 0.01793532
Iteration 1827, loss = 0.01792514
Iteration 1828, loss = 0.01791246
Iteration 1829, loss = 0.01790144
Iteration 1830, loss = 0.01789025
Iteration 1831, loss = 0.01787973
Iteration 1832, loss = 0.01786996
Iteration 1833, loss = 0.01785931
Iteration 1834, loss = 0.01784827
Iteration 1835, loss = 0.01783723
Iteration 1836, loss = 0.01782635
Iteration 1837, loss = 0.01781652
Iteration 1838, loss = 0.01780619
Iteration 1839, loss = 0.01779715
Iteration 1840, loss = 0.01778994
Iteration 1841, loss = 0.01777544
Iteration 1842, loss = 0.01776484
Iteration 1843, loss = 0.01775281
Iteration 1844, loss = 0.01774192
Iteration 1845, loss = 0.01773134
Iteration 1846, loss = 0.01772220
Iteration 1847, loss = 0.01771046
Iteration 1848, loss = 0.01770022
Iteration 1849, loss = 0.01769097
Iteration 1850, loss = 0.01767995
Iteration 1851, loss = 0.01767153
Iteration 1852, loss = 0.01765963
Iteration 1853, loss = 0.01765092
Iteration 1854, loss = 0.01763996
Iteration 1855, loss = 0.01762779
Iteration 1856, loss = 0.01761630
Iteration 1857, loss = 0.01760506
Iteration 1858, loss = 0.01759473
Iteration 1859, loss = 0.01758289
Iteration 1860, loss = 0.01757321
Iteration 1861, loss = 0.01756457
Iteration 1862, loss = 0.01755462
Iteration 1863, loss = 0.01754224
Iteration 1864, loss = 0.01753082
Iteration 1865, loss = 0.01752122
Iteration 1866, loss = 0.01751043
Iteration 1867, loss = 0.01749877
Iteration 1868, loss = 0.01748710
Iteration 1869, loss = 0.01747458
Iteration 1870, loss = 0.01746133
Iteration 1871, loss = 0.01745260
Iteration 1872, loss = 0.01743960
Iteration 1873, loss = 0.01742603
Iteration 1874, loss = 0.01741602
Iteration 1875, loss = 0.01740479
Iteration 1876, loss = 0.01739459
Iteration 1877, loss = 0.01738272
Iteration 1878, loss = 0.01737208
Iteration 1879, loss = 0.01736202
Iteration 1880, loss = 0.01735113
Iteration 1881, loss = 0.01734084
Iteration 1882, loss = 0.01733245
Iteration 1883, loss = 0.01732205
Iteration 1884, loss = 0.01730947
Iteration 1885, loss = 0.01729961
Iteration 1886, loss = 0.01728744
Iteration 1887, loss = 0.01727710
Iteration 1888, loss = 0.01726633
Iteration 1889, loss = 0.01725522
Iteration 1890, loss = 0.01724407
Iteration 1891, loss = 0.01723746
Iteration 1892, loss = 0.01722470
Iteration 1893, loss = 0.01721419
Iteration 1894, loss = 0.01720601
Iteration 1895, loss = 0.01719352
Iteration 1896, loss = 0.01718335
Iteration 1897, loss = 0.01717415
Iteration 1898, loss = 0.01716260
Iteration 1899, loss = 0.01715302
Iteration 1900, loss = 0.01714314
Iteration 1901, loss = 0.01713372
Iteration 1902, loss = 0.01712487
Iteration 1903, loss = 0.01711519
Iteration 1904, loss = 0.01710490
Iteration 1905, loss = 0.01709524
Iteration 1906, loss = 0.01708419
Iteration 1907, loss = 0.01707364
Iteration 1908, loss = 0.01706430
Iteration 1909, loss = 0.01705237
Iteration 1910, loss = 0.01704125
Iteration 1911, loss = 0.01702996
Iteration 1912, loss = 0.01701955
Iteration 1913, loss = 0.01700843
Iteration 1914, loss = 0.01700031
Iteration 1915, loss = 0.01698782
Iteration 1916, loss = 0.01697937
Iteration 1917, loss = 0.01696949
Iteration 1918, loss = 0.01695826
Iteration 1919, loss = 0.01694778
Iteration 1920, loss = 0.01693857
Iteration 1921, loss = 0.01692701
Iteration 1922, loss = 0.01691676
Iteration 1923, loss = 0.01690800
Iteration 1924, loss = 0.01689583
Iteration 1925, loss = 0.01688636
Iteration 1926, loss = 0.01687578
Iteration 1927, loss = 0.01686555
Iteration 1928, loss = 0.01685607
Iteration 1929, loss = 0.01684512
Iteration 1930, loss = 0.01683478
Iteration 1931, loss = 0.01682440
Iteration 1932, loss = 0.01681428
Iteration 1933, loss = 0.01680361
Iteration 1934, loss = 0.01679329
Iteration 1935, loss = 0.01678371
Iteration 1936, loss = 0.01677405
Iteration 1937, loss = 0.01676848
Iteration 1938, loss = 0.01675661
Iteration 1939, loss = 0.01674593
Iteration 1940, loss = 0.01673608
Iteration 1941, loss = 0.01672616
Iteration 1942, loss = 0.01671543
Iteration 1943, loss = 0.01670652
Iteration 1944, loss = 0.01669755
Iteration 1945, loss = 0.01668537
Iteration 1946, loss = 0.01667560
Iteration 1947, loss = 0.01666325
Iteration 1948, loss = 0.01665381
Iteration 1949, loss = 0.01664202
Iteration 1950, loss = 0.01663044
Iteration 1951, loss = 0.01662140
Iteration 1952, loss = 0.01661166
Iteration 1953, loss = 0.01660170
Iteration 1954, loss = 0.01659115
Iteration 1955, loss = 0.01658181
Iteration 1956, loss = 0.01657200
Iteration 1957, loss = 0.01656334
Iteration 1958, loss = 0.01655363
Iteration 1959, loss = 0.01654269
Iteration 1960, loss = 0.01653234
Iteration 1961, loss = 0.01652277
Iteration 1962, loss = 0.01651389
Iteration 1963, loss = 0.01650208
Iteration 1964, loss = 0.01649229
Iteration 1965, loss = 0.01648377
Iteration 1966, loss = 0.01647454
Iteration 1967, loss = 0.01646446
Iteration 1968, loss = 0.01645459
Iteration 1969, loss = 0.01644594
Iteration 1970, loss = 0.01643509
Iteration 1971, loss = 0.01642623
Iteration 1972, loss = 0.01641684
Iteration 1973, loss = 0.01640730
Iteration 1974, loss = 0.01640330
Iteration 1975, loss = 0.01638660
Iteration 1976, loss = 0.01637897
Iteration 1977, loss = 0.01636688
Iteration 1978, loss = 0.01635589
Iteration 1979, loss = 0.01634918
Iteration 1980, loss = 0.01633705
Iteration 1981, loss = 0.01632700
Iteration 1982, loss = 0.01631606
Iteration 1983, loss = 0.01630496
Iteration 1984, loss = 0.01629662
Iteration 1985, loss = 0.01628517
Iteration 1986, loss = 0.01627812
Iteration 1987, loss = 0.01626603
Iteration 1988, loss = 0.01625679
Iteration 1989, loss = 0.01624806
Iteration 1990, loss = 0.01623901
Iteration 1991, loss = 0.01622846
Iteration 1992, loss = 0.01621930
Iteration 1993, loss = 0.01620908
Iteration 1994, loss = 0.01619939
Iteration 1995, loss = 0.01618958
Iteration 1996, loss = 0.01618013
Iteration 1997, loss = 0.01616993
Iteration 1998, loss = 0.01616082
Iteration 1999, loss = 0.01615037
Iteration 2000, loss = 0.01614060
Iteration 2001, loss = 0.01613056
Iteration 2002, loss = 0.01612272
Iteration 2003, loss = 0.01611101
Iteration 2004, loss = 0.01610110
Iteration 2005, loss = 0.01609276
Iteration 2006, loss = 0.01608209
Iteration 2007, loss = 0.01607211
Iteration 2008, loss = 0.01606288
Iteration 2009, loss = 0.01605323
Iteration 2010, loss = 0.01604365
Iteration 2011, loss = 0.01603644
Iteration 2012, loss = 0.01602513
Iteration 2013, loss = 0.01601533
Iteration 2014, loss = 0.01600630
Iteration 2015, loss = 0.01599717
Iteration 2016, loss = 0.01598680
Iteration 2017, loss = 0.01597963
Iteration 2018, loss = 0.01596881
Iteration 2019, loss = 0.01595829
Iteration 2020, loss = 0.01594878
Iteration 2021, loss = 0.01594036
Iteration 2022, loss = 0.01593028
Iteration 2023, loss = 0.01592184
Iteration 2024, loss = 0.01591259
Iteration 2025, loss = 0.01590472
Iteration 2026, loss = 0.01589630
Iteration 2027, loss = 0.01588717
Iteration 2028, loss = 0.01587698
Iteration 2029, loss = 0.01587167
Iteration 2030, loss = 0.01586016
Iteration 2031, loss = 0.01585130
Iteration 2032, loss = 0.01584183
Iteration 2033, loss = 0.01583326
Iteration 2034, loss = 0.01582360
Iteration 2035, loss = 0.01581453
Iteration 2036, loss = 0.01580572
Iteration 2037, loss = 0.01579652
Iteration 2038, loss = 0.01578795
Iteration 2039, loss = 0.01577833
Iteration 2040, loss = 0.01577121
Iteration 2041, loss = 0.01576117
Iteration 2042, loss = 0.01575284
Iteration 2043, loss = 0.01574444
Iteration 2044, loss = 0.01573573
Iteration 2045, loss = 0.01572715
Iteration 2046, loss = 0.01571883
Iteration 2047, loss = 0.01571006
Iteration 2048, loss = 0.01570163
Iteration 2049, loss = 0.01569041
Iteration 2050, loss = 0.01568160
Iteration 2051, loss = 0.01567311
Iteration 2052, loss = 0.01566470
Iteration 2053, loss = 0.01565491
Iteration 2054, loss = 0.01564621
Iteration 2055, loss = 0.01563756
Iteration 2056, loss = 0.01562843
Iteration 2057, loss = 0.01561946
Iteration 2058, loss = 0.01561249
Iteration 2059, loss = 0.01560230
Iteration 2060, loss = 0.01559188
Iteration 2061, loss = 0.01558283
Iteration 2062, loss = 0.01557526
Iteration 2063, loss = 0.01556376
Iteration 2064, loss = 0.01555397
Iteration 2065, loss = 0.01554523
Iteration 2066, loss = 0.01553518
Iteration 2067, loss = 0.01552665
Iteration 2068, loss = 0.01551883
Iteration 2069, loss = 0.01550799
Iteration 2070, loss = 0.01549987
Iteration 2071, loss = 0.01549048
Iteration 2072, loss = 0.01548087
Iteration 2073, loss = 0.01547154
Iteration 2074, loss = 0.01546316
Iteration 2075, loss = 0.01545226
Iteration 2076, loss = 0.01544515
Iteration 2077, loss = 0.01543440
Iteration 2078, loss = 0.01542521
Iteration 2079, loss = 0.01541926
Iteration 2080, loss = 0.01540906
Iteration 2081, loss = 0.01540125
Iteration 2082, loss = 0.01539233
Iteration 2083, loss = 0.01538343
Iteration 2084, loss = 0.01537601
Iteration 2085, loss = 0.01536753
Iteration 2086, loss = 0.01535905
Iteration 2087, loss = 0.01534806
Iteration 2088, loss = 0.01533949
Iteration 2089, loss = 0.01532969
Iteration 2090, loss = 0.01532146
Iteration 2091, loss = 0.01531142
Iteration 2092, loss = 0.01530323
Iteration 2093, loss = 0.01529548
Iteration 2094, loss = 0.01528529
Iteration 2095, loss = 0.01527693
Iteration 2096, loss = 0.01526766
Iteration 2097, loss = 0.01525833
Iteration 2098, loss = 0.01524916
Iteration 2099, loss = 0.01524020
Iteration 2100, loss = 0.01523018
Iteration 2101, loss = 0.01522435
Iteration 2102, loss = 0.01521450
Iteration 2103, loss = 0.01520466
Iteration 2104, loss = 0.01519685
Iteration 2105, loss = 0.01518910
Iteration 2106, loss = 0.01517947
Iteration 2107, loss = 0.01517059
Iteration 2108, loss = 0.01516066
Iteration 2109, loss = 0.01515211
Iteration 2110, loss = 0.01514362
Iteration 2111, loss = 0.01513425
Iteration 2112, loss = 0.01512505
Iteration 2113, loss = 0.01511644
Iteration 2114, loss = 0.01510822
Iteration 2115, loss = 0.01509895
Iteration 2116, loss = 0.01509122
Iteration 2117, loss = 0.01508151
Iteration 2118, loss = 0.01507363
Iteration 2119, loss = 0.01506667
Iteration 2120, loss = 0.01505647
Iteration 2121, loss = 0.01504760
Iteration 2122, loss = 0.01503965
Iteration 2123, loss = 0.01503073
Iteration 2124, loss = 0.01502102
Iteration 2125, loss = 0.01501499
Iteration 2126, loss = 0.01500648
Iteration 2127, loss = 0.01499673
Iteration 2128, loss = 0.01498775
Iteration 2129, loss = 0.01497940
Iteration 2130, loss = 0.01497092
Iteration 2131, loss = 0.01496286
Iteration 2132, loss = 0.01495473
Iteration 2133, loss = 0.01494573
Iteration 2134, loss = 0.01493871
Iteration 2135, loss = 0.01492952
Iteration 2136, loss = 0.01492137
Iteration 2137, loss = 0.01491313
Iteration 2138, loss = 0.01490515
Iteration 2139, loss = 0.01489794
Iteration 2140, loss = 0.01488914
Iteration 2141, loss = 0.01487982
Iteration 2142, loss = 0.01487190
Iteration 2143, loss = 0.01486361
Iteration 2144, loss = 0.01485563
Iteration 2145, loss = 0.01484673
Iteration 2146, loss = 0.01483783
Iteration 2147, loss = 0.01483010
Iteration 2148, loss = 0.01482261
Iteration 2149, loss = 0.01481385
Iteration 2150, loss = 0.01480456
Iteration 2151, loss = 0.01479654
Iteration 2152, loss = 0.01478889
Iteration 2153, loss = 0.01477999
Iteration 2154, loss = 0.01477178
Iteration 2155, loss = 0.01476307
Iteration 2156, loss = 0.01475528
Iteration 2157, loss = 0.01474711
Iteration 2158, loss = 0.01473947
Iteration 2159, loss = 0.01473189
Iteration 2160, loss = 0.01472448
Iteration 2161, loss = 0.01471625
Iteration 2162, loss = 0.01470812
Iteration 2163, loss = 0.01470020
Iteration 2164, loss = 0.01469295
Iteration 2165, loss = 0.01468679
Iteration 2166, loss = 0.01467709
Iteration 2167, loss = 0.01466886
Iteration 2168, loss = 0.01466126
Iteration 2169, loss = 0.01465307
Iteration 2170, loss = 0.01464601
Iteration 2171, loss = 0.01463790
Iteration 2172, loss = 0.01463099
Iteration 2173, loss = 0.01462424
Iteration 2174, loss = 0.01461616
Iteration 2175, loss = 0.01460908
Iteration 2176, loss = 0.01460207
Iteration 2177, loss = 0.01459523
Iteration 2178, loss = 0.01458754
Iteration 2179, loss = 0.01457919
Iteration 2180, loss = 0.01457154
Iteration 2181, loss = 0.01456325
Iteration 2182, loss = 0.01455483
Iteration 2183, loss = 0.01454762
Iteration 2184, loss = 0.01453924
Iteration 2185, loss = 0.01453193
Iteration 2186, loss = 0.01452561
Iteration 2187, loss = 0.01451651
Iteration 2188, loss = 0.01451010
Iteration 2189, loss = 0.01450102
Iteration 2190, loss = 0.01449308
Iteration 2191, loss = 0.01448355
Iteration 2192, loss = 0.01447591
Iteration 2193, loss = 0.01446759
Iteration 2194, loss = 0.01445807
Iteration 2195, loss = 0.01445247
Iteration 2196, loss = 0.01444237
Iteration 2197, loss = 0.01443502
Iteration 2198, loss = 0.01442729
Iteration 2199, loss = 0.01441922
Iteration 2200, loss = 0.01441235
Iteration 2201, loss = 0.01440443
Iteration 2202, loss = 0.01439712
Iteration 2203, loss = 0.01438866
Iteration 2204, loss = 0.01438123
Iteration 2205, loss = 0.01437635
Iteration 2206, loss = 0.01436661
Iteration 2207, loss = 0.01435837
Iteration 2208, loss = 0.01435258
Iteration 2209, loss = 0.01434692
Iteration 2210, loss = 0.01433935
Iteration 2211, loss = 0.01432989
Iteration 2212, loss = 0.01432132
Iteration 2213, loss = 0.01431216
Iteration 2214, loss = 0.01430365
Iteration 2215, loss = 0.01429484
Iteration 2216, loss = 0.01428622
Iteration 2217, loss = 0.01427445
Iteration 2218, loss = 0.01426617
Iteration 2219, loss = 0.01425890
Iteration 2220, loss = 0.01425273
Iteration 2221, loss = 0.01424169
Iteration 2222, loss = 0.01423378
Iteration 2223, loss = 0.01422504
Iteration 2224, loss = 0.01421781
Iteration 2225, loss = 0.01420977
Iteration 2226, loss = 0.01420297
Iteration 2227, loss = 0.01419545
Iteration 2228, loss = 0.01418616
Iteration 2229, loss = 0.01417854
Iteration 2230, loss = 0.01417062
Iteration 2231, loss = 0.01416318
Iteration 2232, loss = 0.01415582
Iteration 2233, loss = 0.01414785
Iteration 2234, loss = 0.01414088
Iteration 2235, loss = 0.01413294
Iteration 2236, loss = 0.01412546
Iteration 2237, loss = 0.01411988
Iteration 2238, loss = 0.01410994
Iteration 2239, loss = 0.01410229
Iteration 2240, loss = 0.01409535
Iteration 2241, loss = 0.01408789
Iteration 2242, loss = 0.01407930
Iteration 2243, loss = 0.01407180
Iteration 2244, loss = 0.01406438
Iteration 2245, loss = 0.01405650
Iteration 2246, loss = 0.01404902
Iteration 2247, loss = 0.01404199
Iteration 2248, loss = 0.01403380
Iteration 2249, loss = 0.01402782
Iteration 2250, loss = 0.01401906
Iteration 2251, loss = 0.01401196
Iteration 2252, loss = 0.01400437
Iteration 2253, loss = 0.01399753
Iteration 2254, loss = 0.01398940
Iteration 2255, loss = 0.01398225
Iteration 2256, loss = 0.01397541
Iteration 2257, loss = 0.01396774
Iteration 2258, loss = 0.01396078
Iteration 2259, loss = 0.01395240
Iteration 2260, loss = 0.01394585
Iteration 2261, loss = 0.01393827
Iteration 2262, loss = 0.01393136
Iteration 2263, loss = 0.01392496
Iteration 2264, loss = 0.01391702
Iteration 2265, loss = 0.01391061
Iteration 2266, loss = 0.01390292
Iteration 2267, loss = 0.01389798
Iteration 2268, loss = 0.01388980
Iteration 2269, loss = 0.01388130
Iteration 2270, loss = 0.01387373
Iteration 2271, loss = 0.01386705
Iteration 2272, loss = 0.01385834
Iteration 2273, loss = 0.01385114
Iteration 2274, loss = 0.01384266
Iteration 2275, loss = 0.01383543
Iteration 2276, loss = 0.01382819
Iteration 2277, loss = 0.01381862
Iteration 2278, loss = 0.01380992
Iteration 2279, loss = 0.01380302
Iteration 2280, loss = 0.01379425
Iteration 2281, loss = 0.01378658
Iteration 2282, loss = 0.01377718
Iteration 2283, loss = 0.01376913
Iteration 2284, loss = 0.01376301
Iteration 2285, loss = 0.01375290
Iteration 2286, loss = 0.01374620
Iteration 2287, loss = 0.01373718
Iteration 2288, loss = 0.01372930
Iteration 2289, loss = 0.01372503
Iteration 2290, loss = 0.01371874
Iteration 2291, loss = 0.01371078
Iteration 2292, loss = 0.01370283
Iteration 2293, loss = 0.01369568
Iteration 2294, loss = 0.01368853
Iteration 2295, loss = 0.01368112
Iteration 2296, loss = 0.01367298
Iteration 2297, loss = 0.01366678
Iteration 2298, loss = 0.01365686
Iteration 2299, loss = 0.01365069
Iteration 2300, loss = 0.01364175
Iteration 2301, loss = 0.01363457
Iteration 2302, loss = 0.01362699
Iteration 2303, loss = 0.01361945
Iteration 2304, loss = 0.01361175
Iteration 2305, loss = 0.01360481
Iteration 2306, loss = 0.01359768
Iteration 2307, loss = 0.01359004
Iteration 2308, loss = 0.01358329
Iteration 2309, loss = 0.01357460
Iteration 2310, loss = 0.01357005
Iteration 2311, loss = 0.01356050
Iteration 2312, loss = 0.01355310
Iteration 2313, loss = 0.01354710
Iteration 2314, loss = 0.01353815
Iteration 2315, loss = 0.01353127
Iteration 2316, loss = 0.01352245
Iteration 2317, loss = 0.01351539
Iteration 2318, loss = 0.01350775
Iteration 2319, loss = 0.01350043
Iteration 2320, loss = 0.01349368
Iteration 2321, loss = 0.01348681
Iteration 2322, loss = 0.01347951
Iteration 2323, loss = 0.01347163
Iteration 2324, loss = 0.01346520
Iteration 2325, loss = 0.01345836
Iteration 2326, loss = 0.01345116
Iteration 2327, loss = 0.01344454
Iteration 2328, loss = 0.01343870
Iteration 2329, loss = 0.01343112
Iteration 2330, loss = 0.01342445
Iteration 2331, loss = 0.01341735
Iteration 2332, loss = 0.01341238
Iteration 2333, loss = 0.01340521
Iteration 2334, loss = 0.01339891
Iteration 2335, loss = 0.01339418
Iteration 2336, loss = 0.01338533
Iteration 2337, loss = 0.01337981
Iteration 2338, loss = 0.01337108
Iteration 2339, loss = 0.01336511
Iteration 2340, loss = 0.01335755
Iteration 2341, loss = 0.01335027
Iteration 2342, loss = 0.01334375
Iteration 2343, loss = 0.01333589
Iteration 2344, loss = 0.01332892
Iteration 2345, loss = 0.01332290
Iteration 2346, loss = 0.01331503
Iteration 2347, loss = 0.01330872
Iteration 2348, loss = 0.01330123
Iteration 2349, loss = 0.01329410
Iteration 2350, loss = 0.01328734
Iteration 2351, loss = 0.01328076
Iteration 2352, loss = 0.01327615
Iteration 2353, loss = 0.01326823
Iteration 2354, loss = 0.01326232
Iteration 2355, loss = 0.01325500
Iteration 2356, loss = 0.01324779
Iteration 2357, loss = 0.01324134
Iteration 2358, loss = 0.01323483
Iteration 2359, loss = 0.01322930
Iteration 2360, loss = 0.01322017
Iteration 2361, loss = 0.01321161
Iteration 2362, loss = 0.01320354
Iteration 2363, loss = 0.01319729
Iteration 2364, loss = 0.01318971
Iteration 2365, loss = 0.01318365
Iteration 2366, loss = 0.01317657
Iteration 2367, loss = 0.01316994
Iteration 2368, loss = 0.01316372
Iteration 2369, loss = 0.01315773
Iteration 2370, loss = 0.01315076
Iteration 2371, loss = 0.01314557
Iteration 2372, loss = 0.01313962
Iteration 2373, loss = 0.01313145
Iteration 2374, loss = 0.01312456
Iteration 2375, loss = 0.01311731
Iteration 2376, loss = 0.01311037
Iteration 2377, loss = 0.01310312
Iteration 2378, loss = 0.01309706
Iteration 2379, loss = 0.01309076
Iteration 2380, loss = 0.01308225
Iteration 2381, loss = 0.01307492
Iteration 2382, loss = 0.01306844
Iteration 2383, loss = 0.01306223
Iteration 2384, loss = 0.01305516
Iteration 2385, loss = 0.01304934
Iteration 2386, loss = 0.01304331
Iteration 2387, loss = 0.01303593
Iteration 2388, loss = 0.01303168
Iteration 2389, loss = 0.01302464
Iteration 2390, loss = 0.01301835
Iteration 2391, loss = 0.01301019
Iteration 2392, loss = 0.01300380
Iteration 2393, loss = 0.01299733
Iteration 2394, loss = 0.01299279
Iteration 2395, loss = 0.01298474
Iteration 2396, loss = 0.01297843
Iteration 2397, loss = 0.01297018
Iteration 2398, loss = 0.01296412
Iteration 2399, loss = 0.01295683
Iteration 2400, loss = 0.01295061
Iteration 2401, loss = 0.01294340
Iteration 2402, loss = 0.01293655
Iteration 2403, loss = 0.01292976
Iteration 2404, loss = 0.01292406
Iteration 2405, loss = 0.01291631
Iteration 2406, loss = 0.01290801
Iteration 2407, loss = 0.01290115
Iteration 2408, loss = 0.01289507
Iteration 2409, loss = 0.01288825
Iteration 2410, loss = 0.01288153
Iteration 2411, loss = 0.01287586
Iteration 2412, loss = 0.01286975
Iteration 2413, loss = 0.01286355
Iteration 2414, loss = 0.01285792
Iteration 2415, loss = 0.01285155
Iteration 2416, loss = 0.01284720
Iteration 2417, loss = 0.01283952
Iteration 2418, loss = 0.01283281
Iteration 2419, loss = 0.01282555
Iteration 2420, loss = 0.01281907
Iteration 2421, loss = 0.01281297
Iteration 2422, loss = 0.01280676
Iteration 2423, loss = 0.01279907
Iteration 2424, loss = 0.01279279
Iteration 2425, loss = 0.01278695
Iteration 2426, loss = 0.01278124
Iteration 2427, loss = 0.01277571
Iteration 2428, loss = 0.01276926
Iteration 2429, loss = 0.01276745
Iteration 2430, loss = 0.01275792
Iteration 2431, loss = 0.01275126
Iteration 2432, loss = 0.01274372
Iteration 2433, loss = 0.01273796
Iteration 2434, loss = 0.01273031
Iteration 2435, loss = 0.01272306
Iteration 2436, loss = 0.01271571
Iteration 2437, loss = 0.01271002
Iteration 2438, loss = 0.01270365
Iteration 2439, loss = 0.01269635
Iteration 2440, loss = 0.01268952
Iteration 2441, loss = 0.01268475
Iteration 2442, loss = 0.01267706
Iteration 2443, loss = 0.01267051
Iteration 2444, loss = 0.01266486
Iteration 2445, loss = 0.01265887
Iteration 2446, loss = 0.01265137
Iteration 2447, loss = 0.01264511
Iteration 2448, loss = 0.01263918
Iteration 2449, loss = 0.01263134
Iteration 2450, loss = 0.01262509
Iteration 2451, loss = 0.01261828
Iteration 2452, loss = 0.01261188
Iteration 2453, loss = 0.01260576
Iteration 2454, loss = 0.01259965
Iteration 2455, loss = 0.01259327
Iteration 2456, loss = 0.01258678
Iteration 2457, loss = 0.01258054
Iteration 2458, loss = 0.01257614
Iteration 2459, loss = 0.01256978
Iteration 2460, loss = 0.01256368
Iteration 2461, loss = 0.01255736
Iteration 2462, loss = 0.01255207
Iteration 2463, loss = 0.01254401
Iteration 2464, loss = 0.01253779
Iteration 2465, loss = 0.01253143
Iteration 2466, loss = 0.01252386
Iteration 2467, loss = 0.01251688
Iteration 2468, loss = 0.01251320
Iteration 2469, loss = 0.01250438
Iteration 2470, loss = 0.01249861
Iteration 2471, loss = 0.01249250
Iteration 2472, loss = 0.01248656
Iteration 2473, loss = 0.01248137
Iteration 2474, loss = 0.01247576
Iteration 2475, loss = 0.01246962
Iteration 2476, loss = 0.01246445
Iteration 2477, loss = 0.01245921
Iteration 2478, loss = 0.01245199
Iteration 2479, loss = 0.01244698
Iteration 2480, loss = 0.01244037
Iteration 2481, loss = 0.01243422
Iteration 2482, loss = 0.01242719
Iteration 2483, loss = 0.01242138
Iteration 2484, loss = 0.01241482
Iteration 2485, loss = 0.01240753
Iteration 2486, loss = 0.01240118
Iteration 2487, loss = 0.01239665
Iteration 2488, loss = 0.01238939
Iteration 2489, loss = 0.01238185
Iteration 2490, loss = 0.01237576
Iteration 2491, loss = 0.01236921
Iteration 2492, loss = 0.01236201
Iteration 2493, loss = 0.01235583
Iteration 2494, loss = 0.01234927
Iteration 2495, loss = 0.01234336
Iteration 2496, loss = 0.01233690
Iteration 2497, loss = 0.01233042
Iteration 2498, loss = 0.01232534
Iteration 2499, loss = 0.01231875
Iteration 2500, loss = 0.01231238
Iteration 2501, loss = 0.01230574
Iteration 2502, loss = 0.01229882
Iteration 2503, loss = 0.01229407
Iteration 2504, loss = 0.01228578
Iteration 2505, loss = 0.01228083
Iteration 2506, loss = 0.01227351
Iteration 2507, loss = 0.01226818
Iteration 2508, loss = 0.01225973
Iteration 2509, loss = 0.01225191
Iteration 2510, loss = 0.01224519
Iteration 2511, loss = 0.01224015
Iteration 2512, loss = 0.01223212
Iteration 2513, loss = 0.01222434
Iteration 2514, loss = 0.01221842
Iteration 2515, loss = 0.01221465
Iteration 2516, loss = 0.01220602
Iteration 2517, loss = 0.01219843
Iteration 2518, loss = 0.01219252
Iteration 2519, loss = 0.01218589
Iteration 2520, loss = 0.01217947
Iteration 2521, loss = 0.01217394
Iteration 2522, loss = 0.01216687
Iteration 2523, loss = 0.01216085
Iteration 2524, loss = 0.01215455
Iteration 2525, loss = 0.01214785
Iteration 2526, loss = 0.01214372
Iteration 2527, loss = 0.01213597
Iteration 2528, loss = 0.01212984
Iteration 2529, loss = 0.01212311
Iteration 2530, loss = 0.01211737
Iteration 2531, loss = 0.01210967
Iteration 2532, loss = 0.01210659
Iteration 2533, loss = 0.01209943
Iteration 2534, loss = 0.01209348
Iteration 2535, loss = 0.01208790
Iteration 2536, loss = 0.01208202
Iteration 2537, loss = 0.01207649
Iteration 2538, loss = 0.01207046
Iteration 2539, loss = 0.01206552
Iteration 2540, loss = 0.01205976
Iteration 2541, loss = 0.01205380
Iteration 2542, loss = 0.01204800
Iteration 2543, loss = 0.01204240
Iteration 2544, loss = 0.01203685
Iteration 2545, loss = 0.01203164
Iteration 2546, loss = 0.01202556
Iteration 2547, loss = 0.01202081
Iteration 2548, loss = 0.01201488
Iteration 2549, loss = 0.01200914
Iteration 2550, loss = 0.01200410
Iteration 2551, loss = 0.01199789
Iteration 2552, loss = 0.01199242
Iteration 2553, loss = 0.01198731
Iteration 2554, loss = 0.01198130
Iteration 2555, loss = 0.01197554
Iteration 2556, loss = 0.01197014
Iteration 2557, loss = 0.01196434
Iteration 2558, loss = 0.01195867
Iteration 2559, loss = 0.01195310
Iteration 2560, loss = 0.01194758
Iteration 2561, loss = 0.01194228
Iteration 2562, loss = 0.01193684
Iteration 2563, loss = 0.01193240
Iteration 2564, loss = 0.01192665
Iteration 2565, loss = 0.01192118
Iteration 2566, loss = 0.01191509
Iteration 2567, loss = 0.01191170
Iteration 2568, loss = 0.01190292
Iteration 2569, loss = 0.01189784
Iteration 2570, loss = 0.01189301
Iteration 2571, loss = 0.01188466
Iteration 2572, loss = 0.01187961
Iteration 2573, loss = 0.01187337
Iteration 2574, loss = 0.01186734
Iteration 2575, loss = 0.01186155
Iteration 2576, loss = 0.01185599
Iteration 2577, loss = 0.01184943
Iteration 2578, loss = 0.01184320
Iteration 2579, loss = 0.01183930
Iteration 2580, loss = 0.01183270
Iteration 2581, loss = 0.01182589
Iteration 2582, loss = 0.01182025
Iteration 2583, loss = 0.01181340
Iteration 2584, loss = 0.01180838
Iteration 2585, loss = 0.01180281
Iteration 2586, loss = 0.01179678
Iteration 2587, loss = 0.01179112
Iteration 2588, loss = 0.01178556
Iteration 2589, loss = 0.01177912
Iteration 2590, loss = 0.01177375
Iteration 2591, loss = 0.01176808
Iteration 2592, loss = 0.01176201
Iteration 2593, loss = 0.01175799
Iteration 2594, loss = 0.01175246
Iteration 2595, loss = 0.01174624
Iteration 2596, loss = 0.01174066
Iteration 2597, loss = 0.01173529
Iteration 2598, loss = 0.01173055
Iteration 2599, loss = 0.01172487
Iteration 2600, loss = 0.01172024
Iteration 2601, loss = 0.01171361
Iteration 2602, loss = 0.01170808
Iteration 2603, loss = 0.01170356
Iteration 2604, loss = 0.01169754
Iteration 2605, loss = 0.01169179
Iteration 2606, loss = 0.01168593
Iteration 2607, loss = 0.01168054
Iteration 2608, loss = 0.01167525
Iteration 2609, loss = 0.01167074
Iteration 2610, loss = 0.01166497
Iteration 2611, loss = 0.01165988
Iteration 2612, loss = 0.01165474
Iteration 2613, loss = 0.01164919
Iteration 2614, loss = 0.01164378
Iteration 2615, loss = 0.01163845
Iteration 2616, loss = 0.01163285
Iteration 2617, loss = 0.01162778
Iteration 2618, loss = 0.01162024
Iteration 2619, loss = 0.01161410
Iteration 2620, loss = 0.01160707
Iteration 2621, loss = 0.01160089
Iteration 2622, loss = 0.01159577
Iteration 2623, loss = 0.01158901
Iteration 2624, loss = 0.01158340
Iteration 2625, loss = 0.01157700
Iteration 2626, loss = 0.01157132
Iteration 2627, loss = 0.01156544
Iteration 2628, loss = 0.01156034
Iteration 2629, loss = 0.01155392
Iteration 2630, loss = 0.01154819
Iteration 2631, loss = 0.01154266
Iteration 2632, loss = 0.01153701
Iteration 2633, loss = 0.01153236
Iteration 2634, loss = 0.01152703
Iteration 2635, loss = 0.01152073
Iteration 2636, loss = 0.01151606
Iteration 2637, loss = 0.01151030
Iteration 2638, loss = 0.01150782
Iteration 2639, loss = 0.01150000
Iteration 2640, loss = 0.01149566
Iteration 2641, loss = 0.01149073
Iteration 2642, loss = 0.01148490
Iteration 2643, loss = 0.01147962
Iteration 2644, loss = 0.01147452
Iteration 2645, loss = 0.01146934
Iteration 2646, loss = 0.01146590
Iteration 2647, loss = 0.01146089
Iteration 2648, loss = 0.01145553
Iteration 2649, loss = 0.01144956
Iteration 2650, loss = 0.01144468
Iteration 2651, loss = 0.01143814
Iteration 2652, loss = 0.01143233
Iteration 2653, loss = 0.01142712
Iteration 2654, loss = 0.01142035
Iteration 2655, loss = 0.01141491
Iteration 2656, loss = 0.01141046
Iteration 2657, loss = 0.01140368
Iteration 2658, loss = 0.01139725
Iteration 2659, loss = 0.01139243
Iteration 2660, loss = 0.01138589
Iteration 2661, loss = 0.01138110
Iteration 2662, loss = 0.01137569
Iteration 2663, loss = 0.01136999
Iteration 2664, loss = 0.01136411
Iteration 2665, loss = 0.01135885
Iteration 2666, loss = 0.01135451
Iteration 2667, loss = 0.01134847
Iteration 2668, loss = 0.01134350
Iteration 2669, loss = 0.01133782
Iteration 2670, loss = 0.01133260
Iteration 2671, loss = 0.01132732
Iteration 2672, loss = 0.01132394
Iteration 2673, loss = 0.01131895
Iteration 2674, loss = 0.01131267
Iteration 2675, loss = 0.01130761
Iteration 2676, loss = 0.01130226
Iteration 2677, loss = 0.01129707
Iteration 2678, loss = 0.01129213
Iteration 2679, loss = 0.01128744
Iteration 2680, loss = 0.01128175
Iteration 2681, loss = 0.01127745
Iteration 2682, loss = 0.01127148
Iteration 2683, loss = 0.01126675
Iteration 2684, loss = 0.01126131
Iteration 2685, loss = 0.01125625
Iteration 2686, loss = 0.01125134
Iteration 2687, loss = 0.01124624
Iteration 2688, loss = 0.01124147
Iteration 2689, loss = 0.01123636
Iteration 2690, loss = 0.01123171
Iteration 2691, loss = 0.01122758
Iteration 2692, loss = 0.01122240
Iteration 2693, loss = 0.01121770
Iteration 2694, loss = 0.01121508
Iteration 2695, loss = 0.01120809
Iteration 2696, loss = 0.01120329
Iteration 2697, loss = 0.01119789
Iteration 2698, loss = 0.01119312
Iteration 2699, loss = 0.01118818
Iteration 2700, loss = 0.01118290
Iteration 2701, loss = 0.01117897
Iteration 2702, loss = 0.01117373
Iteration 2703, loss = 0.01116778
Iteration 2704, loss = 0.01116276
Iteration 2705, loss = 0.01115776
Iteration 2706, loss = 0.01115310
Iteration 2707, loss = 0.01114770
Iteration 2708, loss = 0.01114307
Iteration 2709, loss = 0.01113823
Iteration 2710, loss = 0.01113650
Iteration 2711, loss = 0.01112989
Iteration 2712, loss = 0.01112591
Iteration 2713, loss = 0.01112131
Iteration 2714, loss = 0.01111955
Iteration 2715, loss = 0.01111375
Iteration 2716, loss = 0.01110709
Iteration 2717, loss = 0.01110195
Iteration 2718, loss = 0.01109645
Iteration 2719, loss = 0.01109062
Iteration 2720, loss = 0.01108602
Iteration 2721, loss = 0.01107946
Iteration 2722, loss = 0.01107416
Iteration 2723, loss = 0.01106829
Iteration 2724, loss = 0.01106196
Iteration 2725, loss = 0.01105727
Iteration 2726, loss = 0.01105171
Iteration 2727, loss = 0.01104774
Iteration 2728, loss = 0.01104079
Iteration 2729, loss = 0.01103584
Iteration 2730, loss = 0.01103063
Iteration 2731, loss = 0.01102503
Iteration 2732, loss = 0.01101982
Iteration 2733, loss = 0.01101406
Iteration 2734, loss = 0.01100852
Iteration 2735, loss = 0.01100293
Iteration 2736, loss = 0.01099790
Iteration 2737, loss = 0.01099137
Iteration 2738, loss = 0.01098667
Iteration 2739, loss = 0.01098246
Iteration 2740, loss = 0.01097586
Iteration 2741, loss = 0.01097159
Iteration 2742, loss = 0.01096626
Iteration 2743, loss = 0.01096071
Iteration 2744, loss = 0.01095564
Iteration 2745, loss = 0.01095068
Iteration 2746, loss = 0.01094474
Iteration 2747, loss = 0.01094132
Iteration 2748, loss = 0.01093525
Iteration 2749, loss = 0.01092877
Iteration 2750, loss = 0.01092308
Iteration 2751, loss = 0.01092061
Iteration 2752, loss = 0.01091262
Iteration 2753, loss = 0.01090781
Iteration 2754, loss = 0.01090273
Iteration 2755, loss = 0.01089714
Iteration 2756, loss = 0.01089262
Iteration 2757, loss = 0.01088724
Iteration 2758, loss = 0.01088217
Iteration 2759, loss = 0.01087692
Iteration 2760, loss = 0.01087313
Iteration 2761, loss = 0.01086757
Iteration 2762, loss = 0.01086265
Iteration 2763, loss = 0.01085732
Iteration 2764, loss = 0.01085258
Iteration 2765, loss = 0.01084778
Iteration 2766, loss = 0.01084251
Iteration 2767, loss = 0.01083774
Iteration 2768, loss = 0.01083296
Iteration 2769, loss = 0.01082863
Iteration 2770, loss = 0.01082368
Iteration 2771, loss = 0.01081892
Iteration 2772, loss = 0.01081450
Iteration 2773, loss = 0.01080957
Iteration 2774, loss = 0.01080535
Iteration 2775, loss = 0.01080039
Iteration 2776, loss = 0.01079525
Iteration 2777, loss = 0.01079039
Iteration 2778, loss = 0.01078580
Iteration 2779, loss = 0.01078188
Iteration 2780, loss = 0.01077665
Iteration 2781, loss = 0.01077212
Iteration 2782, loss = 0.01076715
Iteration 2783, loss = 0.01076218
Iteration 2784, loss = 0.01075878
Iteration 2785, loss = 0.01075333
Iteration 2786, loss = 0.01074815
Iteration 2787, loss = 0.01074334
Iteration 2788, loss = 0.01073774
Iteration 2789, loss = 0.01073325
Iteration 2790, loss = 0.01072817
Iteration 2791, loss = 0.01072330
Iteration 2792, loss = 0.01071826
Iteration 2793, loss = 0.01071367
Iteration 2794, loss = 0.01070792
Iteration 2795, loss = 0.01070386
Iteration 2796, loss = 0.01069870
Iteration 2797, loss = 0.01069318
Iteration 2798, loss = 0.01068852
Iteration 2799, loss = 0.01068382
Iteration 2800, loss = 0.01067856
Iteration 2801, loss = 0.01067459
Iteration 2802, loss = 0.01066908
Iteration 2803, loss = 0.01066404
Iteration 2804, loss = 0.01065951
Iteration 2805, loss = 0.01065461
Iteration 2806, loss = 0.01065020
Iteration 2807, loss = 0.01064380
Iteration 2808, loss = 0.01063920
Iteration 2809, loss = 0.01063458
Iteration 2810, loss = 0.01062834
Iteration 2811, loss = 0.01062358
Iteration 2812, loss = 0.01061904
Iteration 2813, loss = 0.01061426
Iteration 2814, loss = 0.01060924
Iteration 2815, loss = 0.01060457
Iteration 2816, loss = 0.01060212
Iteration 2817, loss = 0.01059575
Iteration 2818, loss = 0.01059135
Iteration 2819, loss = 0.01058604
Iteration 2820, loss = 0.01058140
Iteration 2821, loss = 0.01057617
Iteration 2822, loss = 0.01057187
Iteration 2823, loss = 0.01056675
Iteration 2824, loss = 0.01056215
Iteration 2825, loss = 0.01055814
Iteration 2826, loss = 0.01055436
Iteration 2827, loss = 0.01054919
Iteration 2828, loss = 0.01054464
Iteration 2829, loss = 0.01053957
Iteration 2830, loss = 0.01053600
Iteration 2831, loss = 0.01053104
Iteration 2832, loss = 0.01052947
Iteration 2833, loss = 0.01052265
Iteration 2834, loss = 0.01051919
Iteration 2835, loss = 0.01051392
Iteration 2836, loss = 0.01050932
Iteration 2837, loss = 0.01050511
Iteration 2838, loss = 0.01050059
Iteration 2839, loss = 0.01049704
Iteration 2840, loss = 0.01049253
Iteration 2841, loss = 0.01048779
Iteration 2842, loss = 0.01048453
Iteration 2843, loss = 0.01047877
Iteration 2844, loss = 0.01047441
Iteration 2845, loss = 0.01046981
Iteration 2846, loss = 0.01046539
Iteration 2847, loss = 0.01045987
Iteration 2848, loss = 0.01045521
Iteration 2849, loss = 0.01045020
Iteration 2850, loss = 0.01044570
Iteration 2851, loss = 0.01044071
Iteration 2852, loss = 0.01043453
Iteration 2853, loss = 0.01042946
Iteration 2854, loss = 0.01042495
Iteration 2855, loss = 0.01041996
Iteration 2856, loss = 0.01041509
Iteration 2857, loss = 0.01041074
Iteration 2858, loss = 0.01040617
Iteration 2859, loss = 0.01040162
Iteration 2860, loss = 0.01039737
Iteration 2861, loss = 0.01039287
Iteration 2862, loss = 0.01038860
Iteration 2863, loss = 0.01038450
Iteration 2864, loss = 0.01038041
Iteration 2865, loss = 0.01037602
Iteration 2866, loss = 0.01037151
Iteration 2867, loss = 0.01036711
Iteration 2868, loss = 0.01036352
Iteration 2869, loss = 0.01035830
Iteration 2870, loss = 0.01035367
Iteration 2871, loss = 0.01034881
Iteration 2872, loss = 0.01034464
Iteration 2873, loss = 0.01034111
Iteration 2874, loss = 0.01033569
Iteration 2875, loss = 0.01033140
Iteration 2876, loss = 0.01032743
Iteration 2877, loss = 0.01032316
Iteration 2878, loss = 0.01031871
Iteration 2879, loss = 0.01031305
Iteration 2880, loss = 0.01030838
Iteration 2881, loss = 0.01030277
Iteration 2882, loss = 0.01029951
Iteration 2883, loss = 0.01029306
Iteration 2884, loss = 0.01028964
Iteration 2885, loss = 0.01028472
Iteration 2886, loss = 0.01027999
Iteration 2887, loss = 0.01027515
Iteration 2888, loss = 0.01027141
Iteration 2889, loss = 0.01026709
Iteration 2890, loss = 0.01026255
Iteration 2891, loss = 0.01025857
Iteration 2892, loss = 0.01025305
Iteration 2893, loss = 0.01024955
Iteration 2894, loss = 0.01024451
Iteration 2895, loss = 0.01024137
Iteration 2896, loss = 0.01023518
Iteration 2897, loss = 0.01023050
Iteration 2898, loss = 0.01022585
Iteration 2899, loss = 0.01022104
Iteration 2900, loss = 0.01021643
Iteration 2901, loss = 0.01021189
Iteration 2902, loss = 0.01020798
Iteration 2903, loss = 0.01020397
Iteration 2904, loss = 0.01019856
Iteration 2905, loss = 0.01019369
Iteration 2906, loss = 0.01018912
Iteration 2907, loss = 0.01018448
Iteration 2908, loss = 0.01017956
Iteration 2909, loss = 0.01017516
Iteration 2910, loss = 0.01017243
Iteration 2911, loss = 0.01016636
Iteration 2912, loss = 0.01016208
Iteration 2913, loss = 0.01015755
Iteration 2914, loss = 0.01015338
Iteration 2915, loss = 0.01014939
Iteration 2916, loss = 0.01014479
Iteration 2917, loss = 0.01014034
Iteration 2918, loss = 0.01013656
Iteration 2919, loss = 0.01013214
Iteration 2920, loss = 0.01012919
Iteration 2921, loss = 0.01012406
Iteration 2922, loss = 0.01012032
Iteration 2923, loss = 0.01011626
Iteration 2924, loss = 0.01011160
Iteration 2925, loss = 0.01010814
Iteration 2926, loss = 0.01010352
Iteration 2927, loss = 0.01009932
Iteration 2928, loss = 0.01009460
Iteration 2929, loss = 0.01009081
Iteration 2930, loss = 0.01008483
Iteration 2931, loss = 0.01008006
Iteration 2932, loss = 0.01007638
Iteration 2933, loss = 0.01007114
Iteration 2934, loss = 0.01006725
Iteration 2935, loss = 0.01006309
Iteration 2936, loss = 0.01005679
Iteration 2937, loss = 0.01005349
Iteration 2938, loss = 0.01004821
Iteration 2939, loss = 0.01004415
Iteration 2940, loss = 0.01003938
Iteration 2941, loss = 0.01003530
Iteration 2942, loss = 0.01003009
Iteration 2943, loss = 0.01002575
Iteration 2944, loss = 0.01002117
Iteration 2945, loss = 0.01001698
Iteration 2946, loss = 0.01001349
Iteration 2947, loss = 0.01000876
Iteration 2948, loss = 0.01000514
Iteration 2949, loss = 0.01000251
Iteration 2950, loss = 0.00999730
Iteration 2951, loss = 0.00999291
Iteration 2952, loss = 0.00998965
Iteration 2953, loss = 0.00998474
Iteration 2954, loss = 0.00997981
Iteration 2955, loss = 0.00997627
Iteration 2956, loss = 0.00997301
Iteration 2957, loss = 0.00996729
Iteration 2958, loss = 0.00996312
Iteration 2959, loss = 0.00995922
Iteration 2960, loss = 0.00995371
Iteration 2961, loss = 0.00994968
Iteration 2962, loss = 0.00994543
Iteration 2963, loss = 0.00993999
Iteration 2964, loss = 0.00993481
Iteration 2965, loss = 0.00993036
Iteration 2966, loss = 0.00992590
Iteration 2967, loss = 0.00992393
Iteration 2968, loss = 0.00991799
Iteration 2969, loss = 0.00991631
Iteration 2970, loss = 0.00990920
Iteration 2971, loss = 0.00990500
Iteration 2972, loss = 0.00990103
Iteration 2973, loss = 0.00989645
Iteration 2974, loss = 0.00989213
Iteration 2975, loss = 0.00988829
Iteration 2976, loss = 0.00988404
Iteration 2977, loss = 0.00988005
Iteration 2978, loss = 0.00987616
Iteration 2979, loss = 0.00987214
Iteration 2980, loss = 0.00986832
Iteration 2981, loss = 0.00986470
Iteration 2982, loss = 0.00986183
Iteration 2983, loss = 0.00985726
Iteration 2984, loss = 0.00985380
Iteration 2985, loss = 0.00984921
Iteration 2986, loss = 0.00984526
Iteration 2987, loss = 0.00984128
Iteration 2988, loss = 0.00983741
Iteration 2989, loss = 0.00983349
Iteration 2990, loss = 0.00983012
Iteration 2991, loss = 0.00982574
Iteration 2992, loss = 0.00982161
Iteration 2993, loss = 0.00981756
Iteration 2994, loss = 0.00981388
Iteration 2995, loss = 0.00980958
Iteration 2996, loss = 0.00980547
Iteration 2997, loss = 0.00980169
Iteration 2998, loss = 0.00979762
Iteration 2999, loss = 0.00979345
Iteration 3000, loss = 0.00978932
Iteration 3001, loss = 0.00978638
Iteration 3002, loss = 0.00978167
Iteration 3003, loss = 0.00977725
Iteration 3004, loss = 0.00977295
Iteration 3005, loss = 0.00976896
Iteration 3006, loss = 0.00976473
Iteration 3007, loss = 0.00976113
Iteration 3008, loss = 0.00975744
Iteration 3009, loss = 0.00975395
Iteration 3010, loss = 0.00975154
Iteration 3011, loss = 0.00974659
Iteration 3012, loss = 0.00974208
Iteration 3013, loss = 0.00973735
Iteration 3014, loss = 0.00973334
Iteration 3015, loss = 0.00972923
Iteration 3016, loss = 0.00972497
Iteration 3017, loss = 0.00972131
Iteration 3018, loss = 0.00971559
Iteration 3019, loss = 0.00971189
Iteration 3020, loss = 0.00970659
Iteration 3021, loss = 0.00970185
Iteration 3022, loss = 0.00969666
Iteration 3023, loss = 0.00969176
Iteration 3024, loss = 0.00968739
Iteration 3025, loss = 0.00968465
Iteration 3026, loss = 0.00967967
Iteration 3027, loss = 0.00967577
Iteration 3028, loss = 0.00967118
Iteration 3029, loss = 0.00966718
Iteration 3030, loss = 0.00966383
Iteration 3031, loss = 0.00966070
Iteration 3032, loss = 0.00965480
Iteration 3033, loss = 0.00965061
Iteration 3034, loss = 0.00964647
Iteration 3035, loss = 0.00964111
Iteration 3036, loss = 0.00963675
Iteration 3037, loss = 0.00963169
Iteration 3038, loss = 0.00962688
Iteration 3039, loss = 0.00962380
Iteration 3040, loss = 0.00961812
Iteration 3041, loss = 0.00961390
Iteration 3042, loss = 0.00961187
Iteration 3043, loss = 0.00960552
Iteration 3044, loss = 0.00960177
Iteration 3045, loss = 0.00959938
Iteration 3046, loss = 0.00959581
Iteration 3047, loss = 0.00959071
Iteration 3048, loss = 0.00958794
Iteration 3049, loss = 0.00958365
Iteration 3050, loss = 0.00958043
Iteration 3051, loss = 0.00957633
Iteration 3052, loss = 0.00957232
Iteration 3053, loss = 0.00956756
Iteration 3054, loss = 0.00956343
Iteration 3055, loss = 0.00955959
Iteration 3056, loss = 0.00955559
Iteration 3057, loss = 0.00955140
Iteration 3058, loss = 0.00954730
Iteration 3059, loss = 0.00954295
Iteration 3060, loss = 0.00953971
Iteration 3061, loss = 0.00953583
Iteration 3062, loss = 0.00953104
Iteration 3063, loss = 0.00952668
Iteration 3064, loss = 0.00952281
Iteration 3065, loss = 0.00951843
Iteration 3066, loss = 0.00951456
Iteration 3067, loss = 0.00951089
Iteration 3068, loss = 0.00950659
Iteration 3069, loss = 0.00950266
Iteration 3070, loss = 0.00950072
Iteration 3071, loss = 0.00949557
Iteration 3072, loss = 0.00949124
Iteration 3073, loss = 0.00948738
Iteration 3074, loss = 0.00948331
Iteration 3075, loss = 0.00947912
Iteration 3076, loss = 0.00947500
Iteration 3077, loss = 0.00947134
Iteration 3078, loss = 0.00946699
Iteration 3079, loss = 0.00946279
Iteration 3080, loss = 0.00945954
Iteration 3081, loss = 0.00945487
Iteration 3082, loss = 0.00945124
Iteration 3083, loss = 0.00944737
Iteration 3084, loss = 0.00944313
Iteration 3085, loss = 0.00943897
Iteration 3086, loss = 0.00943602
Iteration 3087, loss = 0.00943148
Iteration 3088, loss = 0.00942815
Iteration 3089, loss = 0.00942404
Iteration 3090, loss = 0.00941962
Iteration 3091, loss = 0.00941541
Iteration 3092, loss = 0.00941119
Iteration 3093, loss = 0.00940728
Iteration 3094, loss = 0.00940393
Iteration 3095, loss = 0.00939968
Iteration 3096, loss = 0.00939572
Iteration 3097, loss = 0.00939166
Iteration 3098, loss = 0.00938723
Iteration 3099, loss = 0.00938347
Iteration 3100, loss = 0.00937966
Iteration 3101, loss = 0.00937548
Iteration 3102, loss = 0.00937149
Iteration 3103, loss = 0.00936737
Iteration 3104, loss = 0.00936539
Iteration 3105, loss = 0.00936048
Iteration 3106, loss = 0.00935738
Iteration 3107, loss = 0.00935309
Iteration 3108, loss = 0.00934942
Iteration 3109, loss = 0.00934581
Iteration 3110, loss = 0.00934262
Iteration 3111, loss = 0.00933965
Iteration 3112, loss = 0.00933569
Iteration 3113, loss = 0.00933166
Iteration 3114, loss = 0.00932844
Iteration 3115, loss = 0.00932405
Iteration 3116, loss = 0.00932036
Iteration 3117, loss = 0.00931645
Iteration 3118, loss = 0.00931178
Iteration 3119, loss = 0.00930803
Iteration 3120, loss = 0.00930372
Iteration 3121, loss = 0.00929957
Iteration 3122, loss = 0.00929636
Iteration 3123, loss = 0.00929226
Iteration 3124, loss = 0.00928869
Iteration 3125, loss = 0.00928432
Iteration 3126, loss = 0.00928030
Iteration 3127, loss = 0.00927752
Iteration 3128, loss = 0.00927223
Iteration 3129, loss = 0.00926819
Iteration 3130, loss = 0.00926435
Iteration 3131, loss = 0.00926040
Iteration 3132, loss = 0.00925656
Iteration 3133, loss = 0.00925283
Iteration 3134, loss = 0.00924906
Iteration 3135, loss = 0.00924538
Iteration 3136, loss = 0.00924173
Iteration 3137, loss = 0.00923816
Iteration 3138, loss = 0.00923607
Iteration 3139, loss = 0.00923128
Iteration 3140, loss = 0.00922750
Iteration 3141, loss = 0.00922313
Iteration 3142, loss = 0.00921903
Iteration 3143, loss = 0.00921509
Iteration 3144, loss = 0.00921290
Iteration 3145, loss = 0.00920713
Iteration 3146, loss = 0.00920358
Iteration 3147, loss = 0.00919914
Iteration 3148, loss = 0.00919505
Iteration 3149, loss = 0.00919158
Iteration 3150, loss = 0.00918722
Iteration 3151, loss = 0.00918592
Iteration 3152, loss = 0.00918054
Iteration 3153, loss = 0.00917651
Iteration 3154, loss = 0.00917276
Iteration 3155, loss = 0.00916965
Iteration 3156, loss = 0.00916580
Iteration 3157, loss = 0.00916364
Iteration 3158, loss = 0.00915956
Iteration 3159, loss = 0.00915584
Iteration 3160, loss = 0.00915146
Iteration 3161, loss = 0.00914753
Iteration 3162, loss = 0.00914377
Iteration 3163, loss = 0.00913930
Iteration 3164, loss = 0.00913527
Iteration 3165, loss = 0.00913076
Iteration 3166, loss = 0.00912878
Iteration 3167, loss = 0.00912227
Iteration 3168, loss = 0.00911928
Iteration 3169, loss = 0.00911484
Iteration 3170, loss = 0.00911211
Iteration 3171, loss = 0.00910755
Iteration 3172, loss = 0.00910229
Iteration 3173, loss = 0.00909906
Iteration 3174, loss = 0.00909566
Iteration 3175, loss = 0.00909094
Iteration 3176, loss = 0.00908685
Iteration 3177, loss = 0.00908296
Iteration 3178, loss = 0.00907972
Iteration 3179, loss = 0.00907607
Iteration 3180, loss = 0.00907181
Iteration 3181, loss = 0.00906866
Iteration 3182, loss = 0.00906376
Iteration 3183, loss = 0.00906039
Iteration 3184, loss = 0.00905652
Iteration 3185, loss = 0.00905256
Iteration 3186, loss = 0.00904870
Iteration 3187, loss = 0.00904513
Iteration 3188, loss = 0.00904132
Iteration 3189, loss = 0.00903713
Iteration 3190, loss = 0.00903383
Iteration 3191, loss = 0.00903028
Iteration 3192, loss = 0.00902566
Iteration 3193, loss = 0.00902224
Iteration 3194, loss = 0.00901857
Iteration 3195, loss = 0.00901506
Iteration 3196, loss = 0.00901166
Iteration 3197, loss = 0.00900839
Iteration 3198, loss = 0.00900346
Iteration 3199, loss = 0.00900009
Iteration 3200, loss = 0.00899654
Iteration 3201, loss = 0.00899324
Iteration 3202, loss = 0.00898949
Iteration 3203, loss = 0.00898492
Iteration 3204, loss = 0.00898159
Iteration 3205, loss = 0.00897816
Iteration 3206, loss = 0.00897358
Iteration 3207, loss = 0.00896931
Iteration 3208, loss = 0.00896507
Iteration 3209, loss = 0.00896194
Iteration 3210, loss = 0.00895756
Iteration 3211, loss = 0.00895342
Iteration 3212, loss = 0.00894955
Iteration 3213, loss = 0.00894604
Iteration 3214, loss = 0.00894197
Iteration 3215, loss = 0.00893854
Iteration 3216, loss = 0.00893519
Iteration 3217, loss = 0.00893178
Iteration 3218, loss = 0.00892741
Iteration 3219, loss = 0.00892402
Iteration 3220, loss = 0.00892055
Iteration 3221, loss = 0.00891707
Iteration 3222, loss = 0.00891363
Iteration 3223, loss = 0.00891089
Iteration 3224, loss = 0.00890673
Iteration 3225, loss = 0.00890349
Iteration 3226, loss = 0.00889991
Iteration 3227, loss = 0.00889585
Iteration 3228, loss = 0.00889345
Iteration 3229, loss = 0.00888951
Iteration 3230, loss = 0.00888555
Iteration 3231, loss = 0.00888198
Iteration 3232, loss = 0.00887820
Iteration 3233, loss = 0.00887459
Iteration 3234, loss = 0.00887105
Iteration 3235, loss = 0.00886902
Iteration 3236, loss = 0.00886420
Iteration 3237, loss = 0.00885970
Iteration 3238, loss = 0.00885710
Iteration 3239, loss = 0.00885372
Iteration 3240, loss = 0.00884954
Iteration 3241, loss = 0.00884613
Iteration 3242, loss = 0.00884244
Iteration 3243, loss = 0.00883869
Iteration 3244, loss = 0.00883526
Iteration 3245, loss = 0.00883180
Iteration 3246, loss = 0.00882757
Iteration 3247, loss = 0.00882500
Iteration 3248, loss = 0.00882013
Iteration 3249, loss = 0.00881621
Iteration 3250, loss = 0.00881261
Iteration 3251, loss = 0.00880885
Iteration 3252, loss = 0.00880572
Iteration 3253, loss = 0.00880233
Iteration 3254, loss = 0.00879934
Iteration 3255, loss = 0.00879484
Iteration 3256, loss = 0.00879198
Iteration 3257, loss = 0.00878770
Iteration 3258, loss = 0.00878388
Iteration 3259, loss = 0.00878043
Iteration 3260, loss = 0.00877678
Iteration 3261, loss = 0.00877300
Iteration 3262, loss = 0.00876957
Iteration 3263, loss = 0.00876525
Iteration 3264, loss = 0.00876118
Iteration 3265, loss = 0.00875803
Iteration 3266, loss = 0.00875373
Iteration 3267, loss = 0.00875055
Iteration 3268, loss = 0.00874687
Iteration 3269, loss = 0.00874414
Iteration 3270, loss = 0.00874001
Iteration 3271, loss = 0.00873697
Iteration 3272, loss = 0.00873333
Iteration 3273, loss = 0.00873097
Iteration 3274, loss = 0.00872625
Iteration 3275, loss = 0.00872282
Iteration 3276, loss = 0.00871880
Iteration 3277, loss = 0.00871627
Iteration 3278, loss = 0.00871195
Iteration 3279, loss = 0.00870825
Iteration 3280, loss = 0.00870410
Iteration 3281, loss = 0.00870147
Iteration 3282, loss = 0.00869694
Iteration 3283, loss = 0.00869428
Iteration 3284, loss = 0.00868966
Iteration 3285, loss = 0.00868607
Iteration 3286, loss = 0.00868225
Iteration 3287, loss = 0.00867848
Iteration 3288, loss = 0.00867608
Iteration 3289, loss = 0.00867170
Iteration 3290, loss = 0.00866823
Iteration 3291, loss = 0.00866491
Iteration 3292, loss = 0.00866131
Iteration 3293, loss = 0.00865790
Iteration 3294, loss = 0.00865496
Iteration 3295, loss = 0.00865137
Iteration 3296, loss = 0.00864778
Iteration 3297, loss = 0.00864409
Iteration 3298, loss = 0.00864040
Iteration 3299, loss = 0.00863768
Iteration 3300, loss = 0.00863431
Iteration 3301, loss = 0.00863301
Iteration 3302, loss = 0.00862833
Iteration 3303, loss = 0.00862499
Iteration 3304, loss = 0.00862163
Iteration 3305, loss = 0.00861947
Iteration 3306, loss = 0.00861548
Iteration 3307, loss = 0.00861142
Iteration 3308, loss = 0.00860831
Iteration 3309, loss = 0.00860437
Iteration 3310, loss = 0.00860106
Iteration 3311, loss = 0.00859689
Iteration 3312, loss = 0.00859280
Iteration 3313, loss = 0.00858896
Iteration 3314, loss = 0.00858561
Iteration 3315, loss = 0.00858224
Iteration 3316, loss = 0.00857802
Iteration 3317, loss = 0.00857429
Iteration 3318, loss = 0.00857097
Iteration 3319, loss = 0.00856766
Iteration 3320, loss = 0.00856403
Iteration 3321, loss = 0.00856044
Iteration 3322, loss = 0.00855762
Iteration 3323, loss = 0.00855386
Iteration 3324, loss = 0.00855112
Iteration 3325, loss = 0.00854783
Iteration 3326, loss = 0.00854504
Iteration 3327, loss = 0.00854206
Iteration 3328, loss = 0.00853961
Iteration 3329, loss = 0.00853639
Iteration 3330, loss = 0.00853318
Iteration 3331, loss = 0.00852983
Iteration 3332, loss = 0.00852646
Iteration 3333, loss = 0.00852330
Iteration 3334, loss = 0.00852019
Iteration 3335, loss = 0.00851709
Iteration 3336, loss = 0.00851439
Iteration 3337, loss = 0.00851145
Iteration 3338, loss = 0.00850851
Iteration 3339, loss = 0.00850706
Iteration 3340, loss = 0.00850275
Iteration 3341, loss = 0.00849949
Iteration 3342, loss = 0.00849678
Iteration 3343, loss = 0.00849318
Iteration 3344, loss = 0.00849064
Iteration 3345, loss = 0.00848737
Iteration 3346, loss = 0.00848465
Iteration 3347, loss = 0.00848085
Iteration 3348, loss = 0.00847809
Iteration 3349, loss = 0.00847484
Iteration 3350, loss = 0.00847159
Iteration 3351, loss = 0.00846826
Iteration 3352, loss = 0.00846500
Iteration 3353, loss = 0.00846184
Iteration 3354, loss = 0.00845890
Iteration 3355, loss = 0.00845627
Iteration 3356, loss = 0.00845338
Iteration 3357, loss = 0.00844979
Iteration 3358, loss = 0.00844595
Iteration 3359, loss = 0.00844212
Iteration 3360, loss = 0.00843954
Iteration 3361, loss = 0.00843536
Iteration 3362, loss = 0.00843227
Iteration 3363, loss = 0.00842837
Iteration 3364, loss = 0.00842523
Iteration 3365, loss = 0.00842091
Iteration 3366, loss = 0.00841776
Iteration 3367, loss = 0.00841297
Iteration 3368, loss = 0.00840983
Iteration 3369, loss = 0.00840547
Iteration 3370, loss = 0.00840287
Iteration 3371, loss = 0.00839836
Iteration 3372, loss = 0.00839636
Iteration 3373, loss = 0.00839249
Iteration 3374, loss = 0.00838849
Iteration 3375, loss = 0.00838592
Iteration 3376, loss = 0.00838218
Iteration 3377, loss = 0.00837978
Iteration 3378, loss = 0.00837620
Iteration 3379, loss = 0.00837287
Iteration 3380, loss = 0.00836973
Iteration 3381, loss = 0.00836656
Iteration 3382, loss = 0.00836360
Iteration 3383, loss = 0.00836038
Iteration 3384, loss = 0.00835686
Iteration 3385, loss = 0.00835408
Iteration 3386, loss = 0.00835083
Iteration 3387, loss = 0.00834774
Iteration 3388, loss = 0.00834472
Iteration 3389, loss = 0.00834259
Iteration 3390, loss = 0.00833936
Iteration 3391, loss = 0.00833606
Iteration 3392, loss = 0.00833274
Iteration 3393, loss = 0.00832988
Iteration 3394, loss = 0.00832653
Iteration 3395, loss = 0.00832349
Iteration 3396, loss = 0.00832040
Iteration 3397, loss = 0.00831855
Iteration 3398, loss = 0.00831460
Iteration 3399, loss = 0.00831178
Iteration 3400, loss = 0.00830834
Iteration 3401, loss = 0.00830478
Iteration 3402, loss = 0.00830111
Iteration 3403, loss = 0.00829801
Iteration 3404, loss = 0.00829491
Iteration 3405, loss = 0.00829150
Iteration 3406, loss = 0.00828841
Iteration 3407, loss = 0.00828472
Iteration 3408, loss = 0.00828170
Iteration 3409, loss = 0.00827857
Iteration 3410, loss = 0.00827544
Iteration 3411, loss = 0.00827227
Iteration 3412, loss = 0.00826914
Iteration 3413, loss = 0.00826580
Iteration 3414, loss = 0.00826306
Iteration 3415, loss = 0.00825986
Iteration 3416, loss = 0.00825671
Iteration 3417, loss = 0.00825399
Iteration 3418, loss = 0.00825024
Iteration 3419, loss = 0.00824705
Iteration 3420, loss = 0.00824410
Iteration 3421, loss = 0.00824115
Iteration 3422, loss = 0.00823777
Iteration 3423, loss = 0.00823487
Iteration 3424, loss = 0.00823158
Iteration 3425, loss = 0.00822877
Iteration 3426, loss = 0.00822587
Iteration 3427, loss = 0.00822451
Iteration 3428, loss = 0.00822045
Iteration 3429, loss = 0.00821752
Iteration 3430, loss = 0.00821539
Iteration 3431, loss = 0.00821238
Iteration 3432, loss = 0.00820943
Iteration 3433, loss = 0.00820590
Iteration 3434, loss = 0.00820308
Iteration 3435, loss = 0.00819957
Iteration 3436, loss = 0.00819662
Iteration 3437, loss = 0.00819222
Iteration 3438, loss = 0.00818949
Iteration 3439, loss = 0.00818575
Iteration 3440, loss = 0.00818255
Iteration 3441, loss = 0.00817928
Iteration 3442, loss = 0.00817560
Iteration 3443, loss = 0.00817263
Iteration 3444, loss = 0.00817009
Iteration 3445, loss = 0.00816689
Iteration 3446, loss = 0.00816362
Iteration 3447, loss = 0.00816056
Iteration 3448, loss = 0.00815780
Iteration 3449, loss = 0.00815478
Iteration 3450, loss = 0.00815206
Iteration 3451, loss = 0.00814949
Iteration 3452, loss = 0.00814723
Iteration 3453, loss = 0.00814468
Iteration 3454, loss = 0.00814209
Iteration 3455, loss = 0.00813943
Iteration 3456, loss = 0.00813684
Iteration 3457, loss = 0.00813524
Iteration 3458, loss = 0.00813056
Iteration 3459, loss = 0.00812713
Iteration 3460, loss = 0.00812429
Iteration 3461, loss = 0.00812044
Iteration 3462, loss = 0.00811697
Iteration 3463, loss = 0.00811399
Iteration 3464, loss = 0.00811025
Iteration 3465, loss = 0.00810748
Iteration 3466, loss = 0.00810403
Iteration 3467, loss = 0.00810088
Iteration 3468, loss = 0.00809789
Iteration 3469, loss = 0.00809492
Iteration 3470, loss = 0.00809286
Iteration 3471, loss = 0.00809014
Iteration 3472, loss = 0.00808656
Iteration 3473, loss = 0.00808359
Iteration 3474, loss = 0.00808061
Iteration 3475, loss = 0.00807744
Iteration 3476, loss = 0.00807466
Iteration 3477, loss = 0.00807254
Iteration 3478, loss = 0.00806895
Iteration 3479, loss = 0.00806635
Iteration 3480, loss = 0.00806324
Iteration 3481, loss = 0.00806042
Iteration 3482, loss = 0.00805901
Iteration 3483, loss = 0.00805651
Iteration 3484, loss = 0.00805350
Iteration 3485, loss = 0.00805138
Iteration 3486, loss = 0.00804797
Iteration 3487, loss = 0.00804525
Iteration 3488, loss = 0.00804239
Iteration 3489, loss = 0.00803963
Iteration 3490, loss = 0.00803726
Iteration 3491, loss = 0.00803486
Iteration 3492, loss = 0.00803239
Iteration 3493, loss = 0.00802909
Iteration 3494, loss = 0.00802566
Iteration 3495, loss = 0.00802193
Iteration 3496, loss = 0.00802037
Iteration 3497, loss = 0.00801555
Iteration 3498, loss = 0.00801264
Iteration 3499, loss = 0.00800921
Iteration 3500, loss = 0.00800558
Iteration 3501, loss = 0.00800177
Iteration 3502, loss = 0.00799749
Iteration 3503, loss = 0.00799434
Iteration 3504, loss = 0.00799042
Iteration 3505, loss = 0.00798751
Iteration 3506, loss = 0.00798332
Iteration 3507, loss = 0.00797941
Iteration 3508, loss = 0.00797713
Iteration 3509, loss = 0.00797234
Iteration 3510, loss = 0.00797051
Iteration 3511, loss = 0.00796640
Iteration 3512, loss = 0.00796259
Iteration 3513, loss = 0.00796005
Iteration 3514, loss = 0.00795658
Iteration 3515, loss = 0.00795358
Iteration 3516, loss = 0.00795041
Iteration 3517, loss = 0.00794778
Iteration 3518, loss = 0.00794451
Iteration 3519, loss = 0.00794147
Iteration 3520, loss = 0.00793845
Iteration 3521, loss = 0.00793548
Iteration 3522, loss = 0.00793276
Iteration 3523, loss = 0.00792973
Iteration 3524, loss = 0.00792728
Iteration 3525, loss = 0.00792415
Iteration 3526, loss = 0.00792210
Iteration 3527, loss = 0.00791974
Iteration 3528, loss = 0.00791750
Iteration 3529, loss = 0.00791351
Iteration 3530, loss = 0.00791155
Iteration 3531, loss = 0.00790722
Iteration 3532, loss = 0.00790560
Iteration 3533, loss = 0.00790172
Iteration 3534, loss = 0.00789892
Iteration 3535, loss = 0.00789623
Iteration 3536, loss = 0.00789324
Iteration 3537, loss = 0.00789072
Iteration 3538, loss = 0.00788827
Iteration 3539, loss = 0.00788504
Iteration 3540, loss = 0.00788157
Iteration 3541, loss = 0.00787875
Iteration 3542, loss = 0.00787593
Iteration 3543, loss = 0.00787306
Iteration 3544, loss = 0.00786985
Iteration 3545, loss = 0.00786655
Iteration 3546, loss = 0.00786350
Iteration 3547, loss = 0.00786042
Iteration 3548, loss = 0.00785756
Iteration 3549, loss = 0.00785435
Iteration 3550, loss = 0.00785165
Iteration 3551, loss = 0.00784889
Iteration 3552, loss = 0.00784521
Iteration 3553, loss = 0.00784156
Iteration 3554, loss = 0.00783828
Iteration 3555, loss = 0.00783430
Iteration 3556, loss = 0.00783115
Iteration 3557, loss = 0.00782783
Iteration 3558, loss = 0.00782502
Iteration 3559, loss = 0.00782173
Iteration 3560, loss = 0.00781916
Iteration 3561, loss = 0.00781601
Iteration 3562, loss = 0.00781302
Iteration 3563, loss = 0.00781024
Iteration 3564, loss = 0.00780661
Iteration 3565, loss = 0.00780374
Iteration 3566, loss = 0.00780046
Iteration 3567, loss = 0.00779741
Iteration 3568, loss = 0.00779436
Iteration 3569, loss = 0.00779089
Iteration 3570, loss = 0.00778704
Iteration 3571, loss = 0.00778419
Iteration 3572, loss = 0.00778080
Iteration 3573, loss = 0.00777721
Iteration 3574, loss = 0.00777518
Iteration 3575, loss = 0.00777145
Iteration 3576, loss = 0.00776825
Iteration 3577, loss = 0.00776503
Iteration 3578, loss = 0.00776217
Iteration 3579, loss = 0.00775882
Iteration 3580, loss = 0.00775614
Iteration 3581, loss = 0.00775335
Iteration 3582, loss = 0.00775037
Iteration 3583, loss = 0.00774739
Iteration 3584, loss = 0.00774433
Iteration 3585, loss = 0.00774157
Iteration 3586, loss = 0.00773919
Iteration 3587, loss = 0.00773676
Iteration 3588, loss = 0.00773381
Iteration 3589, loss = 0.00773185
Iteration 3590, loss = 0.00772996
Iteration 3591, loss = 0.00772770
Iteration 3592, loss = 0.00772422
Iteration 3593, loss = 0.00772171
Iteration 3594, loss = 0.00771928
Iteration 3595, loss = 0.00771594
Iteration 3596, loss = 0.00771287
Iteration 3597, loss = 0.00771181
Iteration 3598, loss = 0.00770817
Iteration 3599, loss = 0.00770524
Iteration 3600, loss = 0.00770241
Iteration 3601, loss = 0.00769983
Iteration 3602, loss = 0.00769683
Iteration 3603, loss = 0.00769440
Iteration 3604, loss = 0.00769154
Iteration 3605, loss = 0.00768859
Iteration 3606, loss = 0.00768625
Iteration 3607, loss = 0.00768273
Iteration 3608, loss = 0.00768039
Iteration 3609, loss = 0.00767657
Iteration 3610, loss = 0.00767355
Iteration 3611, loss = 0.00767021
Iteration 3612, loss = 0.00766725
Iteration 3613, loss = 0.00766513
Iteration 3614, loss = 0.00766184
Iteration 3615, loss = 0.00765909
Iteration 3616, loss = 0.00765682
Iteration 3617, loss = 0.00765342
Iteration 3618, loss = 0.00765006
Iteration 3619, loss = 0.00764723
Iteration 3620, loss = 0.00764448
Iteration 3621, loss = 0.00764125
Iteration 3622, loss = 0.00763863
Iteration 3623, loss = 0.00763569
Iteration 3624, loss = 0.00763241
Iteration 3625, loss = 0.00762967
Iteration 3626, loss = 0.00762706
Iteration 3627, loss = 0.00762455
Iteration 3628, loss = 0.00762211
Iteration 3629, loss = 0.00761938
Iteration 3630, loss = 0.00761666
Iteration 3631, loss = 0.00761489
Iteration 3632, loss = 0.00761122
Iteration 3633, loss = 0.00760868
Iteration 3634, loss = 0.00760586
Iteration 3635, loss = 0.00760329
Iteration 3636, loss = 0.00760081
Iteration 3637, loss = 0.00759732
Iteration 3638, loss = 0.00759476
Iteration 3639, loss = 0.00759168
Iteration 3640, loss = 0.00758893
Iteration 3641, loss = 0.00758599
Iteration 3642, loss = 0.00758333
Iteration 3643, loss = 0.00758051
Iteration 3644, loss = 0.00757823
Iteration 3645, loss = 0.00757528
Iteration 3646, loss = 0.00757250
Iteration 3647, loss = 0.00756967
Iteration 3648, loss = 0.00756724
Iteration 3649, loss = 0.00756443
Iteration 3650, loss = 0.00756176
Iteration 3651, loss = 0.00755881
Iteration 3652, loss = 0.00755591
Iteration 3653, loss = 0.00755312
Iteration 3654, loss = 0.00755059
Iteration 3655, loss = 0.00754671
Iteration 3656, loss = 0.00754557
Iteration 3657, loss = 0.00754017
Iteration 3658, loss = 0.00753732
Iteration 3659, loss = 0.00753442
Iteration 3660, loss = 0.00753135
Iteration 3661, loss = 0.00752876
Iteration 3662, loss = 0.00752544
Iteration 3663, loss = 0.00752262
Iteration 3664, loss = 0.00751948
Iteration 3665, loss = 0.00751637
Iteration 3666, loss = 0.00751394
Iteration 3667, loss = 0.00751077
Iteration 3668, loss = 0.00750764
Iteration 3669, loss = 0.00750442
Iteration 3670, loss = 0.00750158
Iteration 3671, loss = 0.00749908
Iteration 3672, loss = 0.00749546
Iteration 3673, loss = 0.00749258
Iteration 3674, loss = 0.00748998
Iteration 3675, loss = 0.00748733
Iteration 3676, loss = 0.00748523
Iteration 3677, loss = 0.00748235
Iteration 3678, loss = 0.00748009
Iteration 3679, loss = 0.00747708
Iteration 3680, loss = 0.00747445
Iteration 3681, loss = 0.00747235
Iteration 3682, loss = 0.00746892
Iteration 3683, loss = 0.00746641
Iteration 3684, loss = 0.00746333
Iteration 3685, loss = 0.00746131
Iteration 3686, loss = 0.00745805
Iteration 3687, loss = 0.00745548
Iteration 3688, loss = 0.00745267
Iteration 3689, loss = 0.00744939
Iteration 3690, loss = 0.00744699
Iteration 3691, loss = 0.00744493
Iteration 3692, loss = 0.00744238
Iteration 3693, loss = 0.00743957
Iteration 3694, loss = 0.00743725
Iteration 3695, loss = 0.00743544
Iteration 3696, loss = 0.00743271
Iteration 3697, loss = 0.00742935
Iteration 3698, loss = 0.00742614
Iteration 3699, loss = 0.00742397
Iteration 3700, loss = 0.00742047
Iteration 3701, loss = 0.00741827
Iteration 3702, loss = 0.00741505
Iteration 3703, loss = 0.00741190
Iteration 3704, loss = 0.00740879
Iteration 3705, loss = 0.00740544
Iteration 3706, loss = 0.00740370
Iteration 3707, loss = 0.00739993
Iteration 3708, loss = 0.00739670
Iteration 3709, loss = 0.00739374
Iteration 3710, loss = 0.00739064
Iteration 3711, loss = 0.00738919
Iteration 3712, loss = 0.00738622
Iteration 3713, loss = 0.00738323
Iteration 3714, loss = 0.00738035
Iteration 3715, loss = 0.00737751
Iteration 3716, loss = 0.00737545
Iteration 3717, loss = 0.00737119
Iteration 3718, loss = 0.00736919
Iteration 3719, loss = 0.00736625
Iteration 3720, loss = 0.00736290
Iteration 3721, loss = 0.00736040
Iteration 3722, loss = 0.00735772
Iteration 3723, loss = 0.00735491
Iteration 3724, loss = 0.00735177
Iteration 3725, loss = 0.00734866
Iteration 3726, loss = 0.00734632
Iteration 3727, loss = 0.00734297
Iteration 3728, loss = 0.00734062
Iteration 3729, loss = 0.00733804
Iteration 3730, loss = 0.00733509
Iteration 3731, loss = 0.00733214
Iteration 3732, loss = 0.00732961
Iteration 3733, loss = 0.00732664
Iteration 3734, loss = 0.00732412
Iteration 3735, loss = 0.00732124
Iteration 3736, loss = 0.00731907
Iteration 3737, loss = 0.00731602
Iteration 3738, loss = 0.00731376
Iteration 3739, loss = 0.00731112
Iteration 3740, loss = 0.00730845
Iteration 3741, loss = 0.00730528
Iteration 3742, loss = 0.00730264
Iteration 3743, loss = 0.00730030
Iteration 3744, loss = 0.00729711
Iteration 3745, loss = 0.00729426
Iteration 3746, loss = 0.00729167
Iteration 3747, loss = 0.00728879
Iteration 3748, loss = 0.00728641
Iteration 3749, loss = 0.00728341
Iteration 3750, loss = 0.00728071
Iteration 3751, loss = 0.00727822
Iteration 3752, loss = 0.00727595
Iteration 3753, loss = 0.00727292
Iteration 3754, loss = 0.00727071
Iteration 3755, loss = 0.00726803
Iteration 3756, loss = 0.00726551
Iteration 3757, loss = 0.00726282
Iteration 3758, loss = 0.00725985
Iteration 3759, loss = 0.00725713
Iteration 3760, loss = 0.00725493
Iteration 3761, loss = 0.00725185
Iteration 3762, loss = 0.00724946
Iteration 3763, loss = 0.00724646
Iteration 3764, loss = 0.00724371
Iteration 3765, loss = 0.00724108
Iteration 3766, loss = 0.00723857
Iteration 3767, loss = 0.00723544
Iteration 3768, loss = 0.00723317
Iteration 3769, loss = 0.00723016
Iteration 3770, loss = 0.00722776
Iteration 3771, loss = 0.00722514
Iteration 3772, loss = 0.00722220
Iteration 3773, loss = 0.00721927
Iteration 3774, loss = 0.00721682
Iteration 3775, loss = 0.00721432
Iteration 3776, loss = 0.00721126
Iteration 3777, loss = 0.00720883
Iteration 3778, loss = 0.00720566
Iteration 3779, loss = 0.00720394
Iteration 3780, loss = 0.00720060
Iteration 3781, loss = 0.00719873
Iteration 3782, loss = 0.00719711
Iteration 3783, loss = 0.00719321
Iteration 3784, loss = 0.00719060
Iteration 3785, loss = 0.00718872
Iteration 3786, loss = 0.00718717
Iteration 3787, loss = 0.00718371
Iteration 3788, loss = 0.00718036
Iteration 3789, loss = 0.00717778
Iteration 3790, loss = 0.00717530
Iteration 3791, loss = 0.00717269
Iteration 3792, loss = 0.00717008
Iteration 3793, loss = 0.00716824
Iteration 3794, loss = 0.00716517
Iteration 3795, loss = 0.00716307
Iteration 3796, loss = 0.00716016
Iteration 3797, loss = 0.00715796
Iteration 3798, loss = 0.00715538
Iteration 3799, loss = 0.00715294
Iteration 3800, loss = 0.00715069
Iteration 3801, loss = 0.00714831
Iteration 3802, loss = 0.00714596
Iteration 3803, loss = 0.00714364
Iteration 3804, loss = 0.00714149
Iteration 3805, loss = 0.00713894
Iteration 3806, loss = 0.00713571
Iteration 3807, loss = 0.00713338
Iteration 3808, loss = 0.00713105
Iteration 3809, loss = 0.00712890
Iteration 3810, loss = 0.00712561
Iteration 3811, loss = 0.00712414
Iteration 3812, loss = 0.00712109
Iteration 3813, loss = 0.00711857
Iteration 3814, loss = 0.00711640
Iteration 3815, loss = 0.00711363
Iteration 3816, loss = 0.00711232
Iteration 3817, loss = 0.00710864
Iteration 3818, loss = 0.00710588
Iteration 3819, loss = 0.00710273
Iteration 3820, loss = 0.00710036
Iteration 3821, loss = 0.00709723
Iteration 3822, loss = 0.00709509
Iteration 3823, loss = 0.00709174
Iteration 3824, loss = 0.00708907
Iteration 3825, loss = 0.00708637
Iteration 3826, loss = 0.00708465
Iteration 3827, loss = 0.00708184
Iteration 3828, loss = 0.00707887
Iteration 3829, loss = 0.00707610
Iteration 3830, loss = 0.00707378
Iteration 3831, loss = 0.00707070
Iteration 3832, loss = 0.00706829
Iteration 3833, loss = 0.00706544
Iteration 3834, loss = 0.00706293
Iteration 3835, loss = 0.00706035
Iteration 3836, loss = 0.00705806
Iteration 3837, loss = 0.00705662
Iteration 3838, loss = 0.00705290
Iteration 3839, loss = 0.00705022
Iteration 3840, loss = 0.00704792
Iteration 3841, loss = 0.00704527
Iteration 3842, loss = 0.00704334
Iteration 3843, loss = 0.00704016
Iteration 3844, loss = 0.00703714
Iteration 3845, loss = 0.00703492
Iteration 3846, loss = 0.00703193
Iteration 3847, loss = 0.00702996
Iteration 3848, loss = 0.00702689
Iteration 3849, loss = 0.00702450
Iteration 3850, loss = 0.00702166
Iteration 3851, loss = 0.00701925
Iteration 3852, loss = 0.00701675
Iteration 3853, loss = 0.00701432
Iteration 3854, loss = 0.00701177
Iteration 3855, loss = 0.00700920
Iteration 3856, loss = 0.00700676
Iteration 3857, loss = 0.00700453
Iteration 3858, loss = 0.00700255
Iteration 3859, loss = 0.00699979
Iteration 3860, loss = 0.00699760
Iteration 3861, loss = 0.00699448
Iteration 3862, loss = 0.00699292
Iteration 3863, loss = 0.00698992
Iteration 3864, loss = 0.00698697
Iteration 3865, loss = 0.00698438
Iteration 3866, loss = 0.00698235
Iteration 3867, loss = 0.00697927
Iteration 3868, loss = 0.00697671
Iteration 3869, loss = 0.00697417
Iteration 3870, loss = 0.00697165
Iteration 3871, loss = 0.00696938
Iteration 3872, loss = 0.00696626
Iteration 3873, loss = 0.00696398
Iteration 3874, loss = 0.00696116
Iteration 3875, loss = 0.00695832
Iteration 3876, loss = 0.00695620
Iteration 3877, loss = 0.00695365
Iteration 3878, loss = 0.00695098
Iteration 3879, loss = 0.00694873
Iteration 3880, loss = 0.00694640
Iteration 3881, loss = 0.00694366
Iteration 3882, loss = 0.00694122
Iteration 3883, loss = 0.00693898
Iteration 3884, loss = 0.00693649
Iteration 3885, loss = 0.00693360
Iteration 3886, loss = 0.00693132
Iteration 3887, loss = 0.00692906
Iteration 3888, loss = 0.00692648
Iteration 3889, loss = 0.00692428
Iteration 3890, loss = 0.00692231
Iteration 3891, loss = 0.00691936
Iteration 3892, loss = 0.00691706
Iteration 3893, loss = 0.00691443
Iteration 3894, loss = 0.00691220
Iteration 3895, loss = 0.00690942
Iteration 3896, loss = 0.00690709
Iteration 3897, loss = 0.00690431
Iteration 3898, loss = 0.00690196
Iteration 3899, loss = 0.00689939
Iteration 3900, loss = 0.00689697
Iteration 3901, loss = 0.00689441
Iteration 3902, loss = 0.00689279
Iteration 3903, loss = 0.00688940
Iteration 3904, loss = 0.00688734
Iteration 3905, loss = 0.00688499
Iteration 3906, loss = 0.00688232
Iteration 3907, loss = 0.00688007
Iteration 3908, loss = 0.00687751
Iteration 3909, loss = 0.00687481
Iteration 3910, loss = 0.00687286
Iteration 3911, loss = 0.00687046
Iteration 3912, loss = 0.00686787
Iteration 3913, loss = 0.00686504
Iteration 3914, loss = 0.00686271
Iteration 3915, loss = 0.00686021
Iteration 3916, loss = 0.00685830
Iteration 3917, loss = 0.00685535
Iteration 3918, loss = 0.00685320
Iteration 3919, loss = 0.00685058
Iteration 3920, loss = 0.00684795
Iteration 3921, loss = 0.00684633
Iteration 3922, loss = 0.00684340
Iteration 3923, loss = 0.00684101
Iteration 3924, loss = 0.00683854
Iteration 3925, loss = 0.00683606
Iteration 3926, loss = 0.00683371
Iteration 3927, loss = 0.00683127
Iteration 3928, loss = 0.00682895
Iteration 3929, loss = 0.00682657
Iteration 3930, loss = 0.00682390
Iteration 3931, loss = 0.00682203
Iteration 3932, loss = 0.00681966
Iteration 3933, loss = 0.00681704
Iteration 3934, loss = 0.00681444
Iteration 3935, loss = 0.00681216
Iteration 3936, loss = 0.00681019
Iteration 3937, loss = 0.00680837
Iteration 3938, loss = 0.00680535
Iteration 3939, loss = 0.00680319
Iteration 3940, loss = 0.00680057
Iteration 3941, loss = 0.00679846
Iteration 3942, loss = 0.00679572
Iteration 3943, loss = 0.00679350
Iteration 3944, loss = 0.00679092
Iteration 3945, loss = 0.00678863
Iteration 3946, loss = 0.00678652
Iteration 3947, loss = 0.00678454
Iteration 3948, loss = 0.00678259
Iteration 3949, loss = 0.00677982
Iteration 3950, loss = 0.00677829
Iteration 3951, loss = 0.00677549
Iteration 3952, loss = 0.00677337
Iteration 3953, loss = 0.00677143
Iteration 3954, loss = 0.00676944
Iteration 3955, loss = 0.00676698
Iteration 3956, loss = 0.00676501
Iteration 3957, loss = 0.00676315
Iteration 3958, loss = 0.00676114
Iteration 3959, loss = 0.00675897
Iteration 3960, loss = 0.00675622
Iteration 3961, loss = 0.00675378
Iteration 3962, loss = 0.00675145
Iteration 3963, loss = 0.00674912
Iteration 3964, loss = 0.00674631
Iteration 3965, loss = 0.00674332
Iteration 3966, loss = 0.00674130
Iteration 3967, loss = 0.00673840
Iteration 3968, loss = 0.00673574
Iteration 3969, loss = 0.00673318
Iteration 3970, loss = 0.00673080
Iteration 3971, loss = 0.00672886
Iteration 3972, loss = 0.00672586
Iteration 3973, loss = 0.00672352
Iteration 3974, loss = 0.00672109
Iteration 3975, loss = 0.00671856
Iteration 3976, loss = 0.00671694
Iteration 3977, loss = 0.00671431
Iteration 3978, loss = 0.00671206
Iteration 3979, loss = 0.00670951
Iteration 3980, loss = 0.00670738
Iteration 3981, loss = 0.00670524
Iteration 3982, loss = 0.00670260
Iteration 3983, loss = 0.00670035
Iteration 3984, loss = 0.00669926
Iteration 3985, loss = 0.00669633
Iteration 3986, loss = 0.00669378
Iteration 3987, loss = 0.00669144
Iteration 3988, loss = 0.00668929
Iteration 3989, loss = 0.00668692
Iteration 3990, loss = 0.00668474
Iteration 3991, loss = 0.00668234
Iteration 3992, loss = 0.00667982
Iteration 3993, loss = 0.00667774
Iteration 3994, loss = 0.00667579
Iteration 3995, loss = 0.00667355
Iteration 3996, loss = 0.00667160
Iteration 3997, loss = 0.00666971
Iteration 3998, loss = 0.00666771
Iteration 3999, loss = 0.00666639
Iteration 4000, loss = 0.00666394
Iteration 4001, loss = 0.00666198
Iteration 4002, loss = 0.00666003
Iteration 4003, loss = 0.00665814
Iteration 4004, loss = 0.00665595
Iteration 4005, loss = 0.00665444
Iteration 4006, loss = 0.00665166
Iteration 4007, loss = 0.00664950
Iteration 4008, loss = 0.00664727
Iteration 4009, loss = 0.00664486
Iteration 4010, loss = 0.00664242
Iteration 4011, loss = 0.00663988
Iteration 4012, loss = 0.00663871
Iteration 4013, loss = 0.00663547
Iteration 4014, loss = 0.00663381
Iteration 4015, loss = 0.00663094
Iteration 4016, loss = 0.00662926
Iteration 4017, loss = 0.00662698
Iteration 4018, loss = 0.00662427
Iteration 4019, loss = 0.00662196
Iteration 4020, loss = 0.00661984
Iteration 4021, loss = 0.00661793
Iteration 4022, loss = 0.00661618
Iteration 4023, loss = 0.00661373
Iteration 4024, loss = 0.00661141
Iteration 4025, loss = 0.00660976
Iteration 4026, loss = 0.00660727
Iteration 4027, loss = 0.00660549
Iteration 4028, loss = 0.00660328
Iteration 4029, loss = 0.00660134
Iteration 4030, loss = 0.00659929
Iteration 4031, loss = 0.00659751
Iteration 4032, loss = 0.00659539
Iteration 4033, loss = 0.00659336
Iteration 4034, loss = 0.00659273
Iteration 4035, loss = 0.00658966
Iteration 4036, loss = 0.00658777
Iteration 4037, loss = 0.00658547
Iteration 4038, loss = 0.00658356
Iteration 4039, loss = 0.00658118
Iteration 4040, loss = 0.00657865
Iteration 4041, loss = 0.00657622
Iteration 4042, loss = 0.00657345
Iteration 4043, loss = 0.00657183
Iteration 4044, loss = 0.00656893
Iteration 4045, loss = 0.00656643
Iteration 4046, loss = 0.00656402
Iteration 4047, loss = 0.00656154
Iteration 4048, loss = 0.00656003
Iteration 4049, loss = 0.00655717
Iteration 4050, loss = 0.00655489
Iteration 4051, loss = 0.00655252
Iteration 4052, loss = 0.00655070
Iteration 4053, loss = 0.00654804
Iteration 4054, loss = 0.00654569
Iteration 4055, loss = 0.00654338
Iteration 4056, loss = 0.00654102
Iteration 4057, loss = 0.00653911
Iteration 4058, loss = 0.00653649
Iteration 4059, loss = 0.00653418
Iteration 4060, loss = 0.00653201
Iteration 4061, loss = 0.00653018
Iteration 4062, loss = 0.00652799
Iteration 4063, loss = 0.00652544
Iteration 4064, loss = 0.00652307
Iteration 4065, loss = 0.00652088
Iteration 4066, loss = 0.00651864
Iteration 4067, loss = 0.00651663
Iteration 4068, loss = 0.00651511
Iteration 4069, loss = 0.00651242
Iteration 4070, loss = 0.00651041
Iteration 4071, loss = 0.00650837
Iteration 4072, loss = 0.00650625
Iteration 4073, loss = 0.00650490
Iteration 4074, loss = 0.00650263
Iteration 4075, loss = 0.00650015
Iteration 4076, loss = 0.00649755
Iteration 4077, loss = 0.00649487
Iteration 4078, loss = 0.00649255
Iteration 4079, loss = 0.00649025
Iteration 4080, loss = 0.00648756
Iteration 4081, loss = 0.00648571
Iteration 4082, loss = 0.00648296
Iteration 4083, loss = 0.00647983
Iteration 4084, loss = 0.00647795
Iteration 4085, loss = 0.00647490
Iteration 4086, loss = 0.00647300
Iteration 4087, loss = 0.00647021
Iteration 4088, loss = 0.00646823
Iteration 4089, loss = 0.00646631
Iteration 4090, loss = 0.00646393
Iteration 4091, loss = 0.00646177
Iteration 4092, loss = 0.00645982
Iteration 4093, loss = 0.00645787
Iteration 4094, loss = 0.00645598
Iteration 4095, loss = 0.00645393
Iteration 4096, loss = 0.00645207
Iteration 4097, loss = 0.00645137
Iteration 4098, loss = 0.00644875
Iteration 4099, loss = 0.00644636
Iteration 4100, loss = 0.00644418
Iteration 4101, loss = 0.00644244
Iteration 4102, loss = 0.00644046
Iteration 4103, loss = 0.00643809
Iteration 4104, loss = 0.00643618
Iteration 4105, loss = 0.00643415
Iteration 4106, loss = 0.00643340
Iteration 4107, loss = 0.00643012
Iteration 4108, loss = 0.00642820
Iteration 4109, loss = 0.00642584
Iteration 4110, loss = 0.00642362
Iteration 4111, loss = 0.00642124
Iteration 4112, loss = 0.00641913
Iteration 4113, loss = 0.00641777
Iteration 4114, loss = 0.00641480
Iteration 4115, loss = 0.00641279
Iteration 4116, loss = 0.00640929
Iteration 4117, loss = 0.00640786
Iteration 4118, loss = 0.00640655
Iteration 4119, loss = 0.00640281
Iteration 4120, loss = 0.00640035
Iteration 4121, loss = 0.00639809
Iteration 4122, loss = 0.00639574
Iteration 4123, loss = 0.00639419
Iteration 4124, loss = 0.00639140
Iteration 4125, loss = 0.00638912
Iteration 4126, loss = 0.00638703
Iteration 4127, loss = 0.00638433
Iteration 4128, loss = 0.00638229
Iteration 4129, loss = 0.00638029
Iteration 4130, loss = 0.00637780
Iteration 4131, loss = 0.00637561
Iteration 4132, loss = 0.00637320
Iteration 4133, loss = 0.00637223
Iteration 4134, loss = 0.00636948
Iteration 4135, loss = 0.00636787
Iteration 4136, loss = 0.00636633
Iteration 4137, loss = 0.00636378
Iteration 4138, loss = 0.00636167
Iteration 4139, loss = 0.00635971
Iteration 4140, loss = 0.00635729
Iteration 4141, loss = 0.00635544
Iteration 4142, loss = 0.00635267
Iteration 4143, loss = 0.00635037
Iteration 4144, loss = 0.00634779
Iteration 4145, loss = 0.00634560
Iteration 4146, loss = 0.00634345
Iteration 4147, loss = 0.00634074
Iteration 4148, loss = 0.00633844
Iteration 4149, loss = 0.00633641
Iteration 4150, loss = 0.00633435
Iteration 4151, loss = 0.00633219
Iteration 4152, loss = 0.00632987
Iteration 4153, loss = 0.00632780
Iteration 4154, loss = 0.00632557
Iteration 4155, loss = 0.00632358
Iteration 4156, loss = 0.00632132
Iteration 4157, loss = 0.00631934
Iteration 4158, loss = 0.00631720
Iteration 4159, loss = 0.00631533
Iteration 4160, loss = 0.00631338
Iteration 4161, loss = 0.00631155
Iteration 4162, loss = 0.00630941
Iteration 4163, loss = 0.00630755
Iteration 4164, loss = 0.00630564
Iteration 4165, loss = 0.00630383
Iteration 4166, loss = 0.00630165
Iteration 4167, loss = 0.00630011
Iteration 4168, loss = 0.00629816
Iteration 4169, loss = 0.00629617
Iteration 4170, loss = 0.00629435
Iteration 4171, loss = 0.00629242
Iteration 4172, loss = 0.00629131
Iteration 4173, loss = 0.00628963
Iteration 4174, loss = 0.00628701
Iteration 4175, loss = 0.00628495
Iteration 4176, loss = 0.00628260
Iteration 4177, loss = 0.00628022
Iteration 4178, loss = 0.00627869
Iteration 4179, loss = 0.00627619
Iteration 4180, loss = 0.00627414
Iteration 4181, loss = 0.00627190
Iteration 4182, loss = 0.00626972
Iteration 4183, loss = 0.00626756
Iteration 4184, loss = 0.00626552
Iteration 4185, loss = 0.00626342
Iteration 4186, loss = 0.00626099
Iteration 4187, loss = 0.00625894
Iteration 4188, loss = 0.00625674
Iteration 4189, loss = 0.00625434
Iteration 4190, loss = 0.00625241
Iteration 4191, loss = 0.00625099
Iteration 4192, loss = 0.00624868
Iteration 4193, loss = 0.00624716
Iteration 4194, loss = 0.00624509
Iteration 4195, loss = 0.00624319
Iteration 4196, loss = 0.00624179
Iteration 4197, loss = 0.00623862
Iteration 4198, loss = 0.00623695
Iteration 4199, loss = 0.00623431
Iteration 4200, loss = 0.00623248
Iteration 4201, loss = 0.00623017
Iteration 4202, loss = 0.00622812
Iteration 4203, loss = 0.00622604
Iteration 4204, loss = 0.00622415
Iteration 4205, loss = 0.00622197
Iteration 4206, loss = 0.00621977
Iteration 4207, loss = 0.00621784
Iteration 4208, loss = 0.00621599
Iteration 4209, loss = 0.00621424
Iteration 4210, loss = 0.00621236
Iteration 4211, loss = 0.00621105
Iteration 4212, loss = 0.00620907
Iteration 4213, loss = 0.00620652
Iteration 4214, loss = 0.00620495
Iteration 4215, loss = 0.00620232
Iteration 4216, loss = 0.00620001
Iteration 4217, loss = 0.00619752
Iteration 4218, loss = 0.00619508
Iteration 4219, loss = 0.00619378
Iteration 4220, loss = 0.00619093
Iteration 4221, loss = 0.00619018
Iteration 4222, loss = 0.00618779
Iteration 4223, loss = 0.00618555
Iteration 4224, loss = 0.00618325
Iteration 4225, loss = 0.00618095
Iteration 4226, loss = 0.00617914
Iteration 4227, loss = 0.00617852
Iteration 4228, loss = 0.00617559
Iteration 4229, loss = 0.00617348
Iteration 4230, loss = 0.00617183
Iteration 4231, loss = 0.00617045
Iteration 4232, loss = 0.00616766
Iteration 4233, loss = 0.00616554
Iteration 4234, loss = 0.00616391
Iteration 4235, loss = 0.00616170
Iteration 4236, loss = 0.00615972
Iteration 4237, loss = 0.00615771
Iteration 4238, loss = 0.00615571
Iteration 4239, loss = 0.00615377
Iteration 4240, loss = 0.00615189
Iteration 4241, loss = 0.00614994
Iteration 4242, loss = 0.00614810
Iteration 4243, loss = 0.00614609
Iteration 4244, loss = 0.00614411
Iteration 4245, loss = 0.00614197
Iteration 4246, loss = 0.00613992
Iteration 4247, loss = 0.00613798
Iteration 4248, loss = 0.00613588
Iteration 4249, loss = 0.00613571
Iteration 4250, loss = 0.00613178
Iteration 4251, loss = 0.00612967
Iteration 4252, loss = 0.00612734
Iteration 4253, loss = 0.00612607
Iteration 4254, loss = 0.00612320
Iteration 4255, loss = 0.00612085
Iteration 4256, loss = 0.00611868
Iteration 4257, loss = 0.00611646
Iteration 4258, loss = 0.00611422
Iteration 4259, loss = 0.00611235
Iteration 4260, loss = 0.00611015
Iteration 4261, loss = 0.00610833
Iteration 4262, loss = 0.00610634
Iteration 4263, loss = 0.00610423
Iteration 4264, loss = 0.00610191
Iteration 4265, loss = 0.00609981
Iteration 4266, loss = 0.00609773
Iteration 4267, loss = 0.00609655
Iteration 4268, loss = 0.00609349
Iteration 4269, loss = 0.00609134
Iteration 4270, loss = 0.00608902
Iteration 4271, loss = 0.00608722
Iteration 4272, loss = 0.00608490
Iteration 4273, loss = 0.00608307
Iteration 4274, loss = 0.00608089
Iteration 4275, loss = 0.00607867
Iteration 4276, loss = 0.00607759
Iteration 4277, loss = 0.00607465
Iteration 4278, loss = 0.00607251
Iteration 4279, loss = 0.00607024
Iteration 4280, loss = 0.00606841
Iteration 4281, loss = 0.00606638
Iteration 4282, loss = 0.00606412
Iteration 4283, loss = 0.00606192
Iteration 4284, loss = 0.00606007
Iteration 4285, loss = 0.00605795
Iteration 4286, loss = 0.00605699
Iteration 4287, loss = 0.00605444
Iteration 4288, loss = 0.00605268
Iteration 4289, loss = 0.00605091
Iteration 4290, loss = 0.00604868
Iteration 4291, loss = 0.00604654
Iteration 4292, loss = 0.00604488
Iteration 4293, loss = 0.00604297
Iteration 4294, loss = 0.00604182
Iteration 4295, loss = 0.00603990
Iteration 4296, loss = 0.00603808
Iteration 4297, loss = 0.00603618
Iteration 4298, loss = 0.00603402
Iteration 4299, loss = 0.00603249
Iteration 4300, loss = 0.00603020
Iteration 4301, loss = 0.00602808
Iteration 4302, loss = 0.00602613
Iteration 4303, loss = 0.00602425
Iteration 4304, loss = 0.00602243
Iteration 4305, loss = 0.00602045
Iteration 4306, loss = 0.00601890
Iteration 4307, loss = 0.00601696
Iteration 4308, loss = 0.00601554
Iteration 4309, loss = 0.00601376
Iteration 4310, loss = 0.00601196
Iteration 4311, loss = 0.00601021
Iteration 4312, loss = 0.00600878
Iteration 4313, loss = 0.00600680
Iteration 4314, loss = 0.00600466
Iteration 4315, loss = 0.00600299
Iteration 4316, loss = 0.00600142
Iteration 4317, loss = 0.00599921
Iteration 4318, loss = 0.00599728
Iteration 4319, loss = 0.00599548
Iteration 4320, loss = 0.00599357
Iteration 4321, loss = 0.00599184
Iteration 4322, loss = 0.00598991
Iteration 4323, loss = 0.00598809
Iteration 4324, loss = 0.00598632
Iteration 4325, loss = 0.00598451
Iteration 4326, loss = 0.00598263
Iteration 4327, loss = 0.00598100
Iteration 4328, loss = 0.00597911
Iteration 4329, loss = 0.00597708
Iteration 4330, loss = 0.00597534
Iteration 4331, loss = 0.00597323
Iteration 4332, loss = 0.00597187
Iteration 4333, loss = 0.00596934
Iteration 4334, loss = 0.00596709
Iteration 4335, loss = 0.00596546
Iteration 4336, loss = 0.00596336
Iteration 4337, loss = 0.00596165
Iteration 4338, loss = 0.00595969
Iteration 4339, loss = 0.00595773
Iteration 4340, loss = 0.00595598
Iteration 4341, loss = 0.00595374
Iteration 4342, loss = 0.00595221
Iteration 4343, loss = 0.00594988
Iteration 4344, loss = 0.00594836
Iteration 4345, loss = 0.00594745
Iteration 4346, loss = 0.00594478
Iteration 4347, loss = 0.00594265
Iteration 4348, loss = 0.00594054
Iteration 4349, loss = 0.00593871
Iteration 4350, loss = 0.00593671
Iteration 4351, loss = 0.00593455
Iteration 4352, loss = 0.00593261
Iteration 4353, loss = 0.00593089
Iteration 4354, loss = 0.00592859
Iteration 4355, loss = 0.00592697
Iteration 4356, loss = 0.00592518
Iteration 4357, loss = 0.00592322
Iteration 4358, loss = 0.00592155
Iteration 4359, loss = 0.00591945
Iteration 4360, loss = 0.00591747
Iteration 4361, loss = 0.00591609
Iteration 4362, loss = 0.00591379
Iteration 4363, loss = 0.00591194
Iteration 4364, loss = 0.00590987
Iteration 4365, loss = 0.00590836
Iteration 4366, loss = 0.00590658
Iteration 4367, loss = 0.00590440
Iteration 4368, loss = 0.00590302
Iteration 4369, loss = 0.00590054
Iteration 4370, loss = 0.00589866
Iteration 4371, loss = 0.00589669
Iteration 4372, loss = 0.00589471
Iteration 4373, loss = 0.00589348
Iteration 4374, loss = 0.00589164
Iteration 4375, loss = 0.00588953
Iteration 4376, loss = 0.00588815
Iteration 4377, loss = 0.00588604
Iteration 4378, loss = 0.00588381
Iteration 4379, loss = 0.00588206
Iteration 4380, loss = 0.00588026
Iteration 4381, loss = 0.00587844
Iteration 4382, loss = 0.00587654
Iteration 4383, loss = 0.00587482
Iteration 4384, loss = 0.00587315
Iteration 4385, loss = 0.00587131
Iteration 4386, loss = 0.00586938
Iteration 4387, loss = 0.00586761
Iteration 4388, loss = 0.00586600
Iteration 4389, loss = 0.00586378
Iteration 4390, loss = 0.00586265
Iteration 4391, loss = 0.00586006
Iteration 4392, loss = 0.00585825
Iteration 4393, loss = 0.00585594
Iteration 4394, loss = 0.00585441
Iteration 4395, loss = 0.00585229
Iteration 4396, loss = 0.00585032
Iteration 4397, loss = 0.00584856
Iteration 4398, loss = 0.00584659
Iteration 4399, loss = 0.00584498
Iteration 4400, loss = 0.00584319
Iteration 4401, loss = 0.00584107
Iteration 4402, loss = 0.00583932
Iteration 4403, loss = 0.00583713
Iteration 4404, loss = 0.00583563
Iteration 4405, loss = 0.00583345
Iteration 4406, loss = 0.00583144
Iteration 4407, loss = 0.00582978
Iteration 4408, loss = 0.00582756
Iteration 4409, loss = 0.00582560
Iteration 4410, loss = 0.00582369
Iteration 4411, loss = 0.00582173
Iteration 4412, loss = 0.00581992
Iteration 4413, loss = 0.00581859
Iteration 4414, loss = 0.00581663
Iteration 4415, loss = 0.00581483
Iteration 4416, loss = 0.00581328
Iteration 4417, loss = 0.00581142
Iteration 4418, loss = 0.00580946
Iteration 4419, loss = 0.00580786
Iteration 4420, loss = 0.00580614
Iteration 4421, loss = 0.00580433
Iteration 4422, loss = 0.00580266
Iteration 4423, loss = 0.00580097
Iteration 4424, loss = 0.00579887
Iteration 4425, loss = 0.00579695
Iteration 4426, loss = 0.00579601
Iteration 4427, loss = 0.00579342
Iteration 4428, loss = 0.00579151
Iteration 4429, loss = 0.00578971
Iteration 4430, loss = 0.00578759
Iteration 4431, loss = 0.00578555
Iteration 4432, loss = 0.00578384
Iteration 4433, loss = 0.00578171
Iteration 4434, loss = 0.00577994
Iteration 4435, loss = 0.00577817
Iteration 4436, loss = 0.00577639
Iteration 4437, loss = 0.00577437
Iteration 4438, loss = 0.00577250
Iteration 4439, loss = 0.00577080
Iteration 4440, loss = 0.00576882
Iteration 4441, loss = 0.00576681
Iteration 4442, loss = 0.00576490
Iteration 4443, loss = 0.00576347
Iteration 4444, loss = 0.00576135
Iteration 4445, loss = 0.00575966
Iteration 4446, loss = 0.00575827
Iteration 4447, loss = 0.00575622
Iteration 4448, loss = 0.00575452
Iteration 4449, loss = 0.00575277
Iteration 4450, loss = 0.00575084
Iteration 4451, loss = 0.00574936
Iteration 4452, loss = 0.00574755
Iteration 4453, loss = 0.00574588
Iteration 4454, loss = 0.00574401
Iteration 4455, loss = 0.00574230
Iteration 4456, loss = 0.00574071
Iteration 4457, loss = 0.00573905
Iteration 4458, loss = 0.00573759
Iteration 4459, loss = 0.00573614
Iteration 4460, loss = 0.00573352
Iteration 4461, loss = 0.00573167
Iteration 4462, loss = 0.00572961
Iteration 4463, loss = 0.00572836
Iteration 4464, loss = 0.00572617
Iteration 4465, loss = 0.00572486
Iteration 4466, loss = 0.00572306
Iteration 4467, loss = 0.00572151
Iteration 4468, loss = 0.00571986
Iteration 4469, loss = 0.00571820
Iteration 4470, loss = 0.00571661
Iteration 4471, loss = 0.00571472
Iteration 4472, loss = 0.00571304
Iteration 4473, loss = 0.00571143
Iteration 4474, loss = 0.00570971
Iteration 4475, loss = 0.00570795
Iteration 4476, loss = 0.00570620
Iteration 4477, loss = 0.00570481
Iteration 4478, loss = 0.00570319
Iteration 4479, loss = 0.00570152
Iteration 4480, loss = 0.00570074
Iteration 4481, loss = 0.00569851
Iteration 4482, loss = 0.00569678
Iteration 4483, loss = 0.00569510
Iteration 4484, loss = 0.00569339
Iteration 4485, loss = 0.00569182
Iteration 4486, loss = 0.00569036
Iteration 4487, loss = 0.00568837
Iteration 4488, loss = 0.00568680
Iteration 4489, loss = 0.00568481
Iteration 4490, loss = 0.00568351
Iteration 4491, loss = 0.00568142
Iteration 4492, loss = 0.00567982
Iteration 4493, loss = 0.00567790
Iteration 4494, loss = 0.00567629
Iteration 4495, loss = 0.00567461
Iteration 4496, loss = 0.00567307
Iteration 4497, loss = 0.00567153
Iteration 4498, loss = 0.00566976
Iteration 4499, loss = 0.00566781
Iteration 4500, loss = 0.00566666
Iteration 4501, loss = 0.00566402
Iteration 4502, loss = 0.00566191
Iteration 4503, loss = 0.00566064
Iteration 4504, loss = 0.00565788
Iteration 4505, loss = 0.00565600
Iteration 4506, loss = 0.00565467
Iteration 4507, loss = 0.00565233
Iteration 4508, loss = 0.00565020
Iteration 4509, loss = 0.00564841
Iteration 4510, loss = 0.00564591
Iteration 4511, loss = 0.00564467
Iteration 4512, loss = 0.00564227
Iteration 4513, loss = 0.00564023
Iteration 4514, loss = 0.00563959
Iteration 4515, loss = 0.00563763
Iteration 4516, loss = 0.00563578
Iteration 4517, loss = 0.00563443
Iteration 4518, loss = 0.00563232
Iteration 4519, loss = 0.00563081
Iteration 4520, loss = 0.00562907
Iteration 4521, loss = 0.00562737
Iteration 4522, loss = 0.00562573
Iteration 4523, loss = 0.00562405
Iteration 4524, loss = 0.00562230
Iteration 4525, loss = 0.00562017
Iteration 4526, loss = 0.00561891
Iteration 4527, loss = 0.00561663
Iteration 4528, loss = 0.00561499
Iteration 4529, loss = 0.00561322
Iteration 4530, loss = 0.00561126
Iteration 4531, loss = 0.00560929
Iteration 4532, loss = 0.00560752
Iteration 4533, loss = 0.00560595
Iteration 4534, loss = 0.00560392
Iteration 4535, loss = 0.00560206
Iteration 4536, loss = 0.00560054
Iteration 4537, loss = 0.00559948
Iteration 4538, loss = 0.00559735
Iteration 4539, loss = 0.00559547
Iteration 4540, loss = 0.00559368
Iteration 4541, loss = 0.00559209
Iteration 4542, loss = 0.00559044
Iteration 4543, loss = 0.00558872
Iteration 4544, loss = 0.00558707
Iteration 4545, loss = 0.00558535
Iteration 4546, loss = 0.00558359
Iteration 4547, loss = 0.00558182
Iteration 4548, loss = 0.00557999
Iteration 4549, loss = 0.00557801
Iteration 4550, loss = 0.00557660
Iteration 4551, loss = 0.00557460
Iteration 4552, loss = 0.00557256
Iteration 4553, loss = 0.00557083
Iteration 4554, loss = 0.00556912
Iteration 4555, loss = 0.00556729
Iteration 4556, loss = 0.00556557
Iteration 4557, loss = 0.00556386
Iteration 4558, loss = 0.00556217
Iteration 4559, loss = 0.00556062
Iteration 4560, loss = 0.00555881
Iteration 4561, loss = 0.00555718
Iteration 4562, loss = 0.00555542
Iteration 4563, loss = 0.00555362
Iteration 4564, loss = 0.00555229
Iteration 4565, loss = 0.00555050
Iteration 4566, loss = 0.00554890
Iteration 4567, loss = 0.00554724
Iteration 4568, loss = 0.00554561
Iteration 4569, loss = 0.00554419
Iteration 4570, loss = 0.00554230
Iteration 4571, loss = 0.00554054
Iteration 4572, loss = 0.00553909
Iteration 4573, loss = 0.00553711
Iteration 4574, loss = 0.00553532
Iteration 4575, loss = 0.00553370
Iteration 4576, loss = 0.00553281
Iteration 4577, loss = 0.00552991
Iteration 4578, loss = 0.00552872
Iteration 4579, loss = 0.00552699
Iteration 4580, loss = 0.00552493
Iteration 4581, loss = 0.00552330
Iteration 4582, loss = 0.00552136
Iteration 4583, loss = 0.00551965
Iteration 4584, loss = 0.00551826
Iteration 4585, loss = 0.00551649
Iteration 4586, loss = 0.00551461
Iteration 4587, loss = 0.00551307
Iteration 4588, loss = 0.00551149
Iteration 4589, loss = 0.00551113
Iteration 4590, loss = 0.00550820
Iteration 4591, loss = 0.00550647
Iteration 4592, loss = 0.00550481
Iteration 4593, loss = 0.00550401
Iteration 4594, loss = 0.00550174
Iteration 4595, loss = 0.00550020
Iteration 4596, loss = 0.00549888
Iteration 4597, loss = 0.00549649
Iteration 4598, loss = 0.00549494
Iteration 4599, loss = 0.00549280
Iteration 4600, loss = 0.00549139
Iteration 4601, loss = 0.00548964
Iteration 4602, loss = 0.00548789
Iteration 4603, loss = 0.00548614
Iteration 4604, loss = 0.00548454
Iteration 4605, loss = 0.00548288
Iteration 4606, loss = 0.00548141
Iteration 4607, loss = 0.00547985
Iteration 4608, loss = 0.00547807
Iteration 4609, loss = 0.00547644
Iteration 4610, loss = 0.00547492
Iteration 4611, loss = 0.00547336
Iteration 4612, loss = 0.00547185
Iteration 4613, loss = 0.00547013
Iteration 4614, loss = 0.00546880
Iteration 4615, loss = 0.00546716
Iteration 4616, loss = 0.00546559
Iteration 4617, loss = 0.00546379
Iteration 4618, loss = 0.00546207
Iteration 4619, loss = 0.00546074
Iteration 4620, loss = 0.00545886
Iteration 4621, loss = 0.00545712
Iteration 4622, loss = 0.00545500
Iteration 4623, loss = 0.00545368
Iteration 4624, loss = 0.00545203
Iteration 4625, loss = 0.00545026
Iteration 4626, loss = 0.00544932
Iteration 4627, loss = 0.00544722
Iteration 4628, loss = 0.00544569
Iteration 4629, loss = 0.00544392
Iteration 4630, loss = 0.00544221
Iteration 4631, loss = 0.00544048
Iteration 4632, loss = 0.00543900
Iteration 4633, loss = 0.00543713
Iteration 4634, loss = 0.00543583
Iteration 4635, loss = 0.00543411
Iteration 4636, loss = 0.00543261
Iteration 4637, loss = 0.00543073
Iteration 4638, loss = 0.00542885
Iteration 4639, loss = 0.00542728
Iteration 4640, loss = 0.00542560
Iteration 4641, loss = 0.00542410
Iteration 4642, loss = 0.00542245
Iteration 4643, loss = 0.00542081
Iteration 4644, loss = 0.00541922
Iteration 4645, loss = 0.00541776
Iteration 4646, loss = 0.00541616
Iteration 4647, loss = 0.00541448
Iteration 4648, loss = 0.00541325
Iteration 4649, loss = 0.00541173
Iteration 4650, loss = 0.00541019
Iteration 4651, loss = 0.00540888
Iteration 4652, loss = 0.00540735
Iteration 4653, loss = 0.00540619
Iteration 4654, loss = 0.00540455
Iteration 4655, loss = 0.00540308
Iteration 4656, loss = 0.00540179
Iteration 4657, loss = 0.00539998
Iteration 4658, loss = 0.00539834
Iteration 4659, loss = 0.00539691
Iteration 4660, loss = 0.00539533
Iteration 4661, loss = 0.00539364
Iteration 4662, loss = 0.00539191
Iteration 4663, loss = 0.00539048
Iteration 4664, loss = 0.00538883
Iteration 4665, loss = 0.00538726
Iteration 4666, loss = 0.00538586
Iteration 4667, loss = 0.00538434
Iteration 4668, loss = 0.00538315
Iteration 4669, loss = 0.00538175
Iteration 4670, loss = 0.00538019
Iteration 4671, loss = 0.00537838
Iteration 4672, loss = 0.00537661
Iteration 4673, loss = 0.00537506
Iteration 4674, loss = 0.00537340
Iteration 4675, loss = 0.00537177
Iteration 4676, loss = 0.00537058
Iteration 4677, loss = 0.00536888
Iteration 4678, loss = 0.00536761
Iteration 4679, loss = 0.00536607
Iteration 4680, loss = 0.00536460
Iteration 4681, loss = 0.00536341
Iteration 4682, loss = 0.00536182
Iteration 4683, loss = 0.00536065
Iteration 4684, loss = 0.00535928
Iteration 4685, loss = 0.00535765
Iteration 4686, loss = 0.00535625
Iteration 4687, loss = 0.00535498
Iteration 4688, loss = 0.00535343
Iteration 4689, loss = 0.00535211
Iteration 4690, loss = 0.00535069
Iteration 4691, loss = 0.00534953
Iteration 4692, loss = 0.00534832
Iteration 4693, loss = 0.00534687
Iteration 4694, loss = 0.00534509
Iteration 4695, loss = 0.00534358
Iteration 4696, loss = 0.00534170
Iteration 4697, loss = 0.00533981
Iteration 4698, loss = 0.00533843
Iteration 4699, loss = 0.00533657
Iteration 4700, loss = 0.00533470
Iteration 4701, loss = 0.00533326
Iteration 4702, loss = 0.00533105
Iteration 4703, loss = 0.00532943
Iteration 4704, loss = 0.00532762
Iteration 4705, loss = 0.00532592
Iteration 4706, loss = 0.00532456
Iteration 4707, loss = 0.00532255
Iteration 4708, loss = 0.00532076
Iteration 4709, loss = 0.00531966
Iteration 4710, loss = 0.00531775
Iteration 4711, loss = 0.00531659
Iteration 4712, loss = 0.00531455
Iteration 4713, loss = 0.00531310
Iteration 4714, loss = 0.00531154
Iteration 4715, loss = 0.00531026
Iteration 4716, loss = 0.00530869
Iteration 4717, loss = 0.00530728
Iteration 4718, loss = 0.00530565
Iteration 4719, loss = 0.00530420
Iteration 4720, loss = 0.00530282
Iteration 4721, loss = 0.00530165
Iteration 4722, loss = 0.00529991
Iteration 4723, loss = 0.00529865
Iteration 4724, loss = 0.00529739
Iteration 4725, loss = 0.00529597
Iteration 4726, loss = 0.00529444
Iteration 4727, loss = 0.00529266
Iteration 4728, loss = 0.00529125
Iteration 4729, loss = 0.00529001
Iteration 4730, loss = 0.00528858
Iteration 4731, loss = 0.00528727
Iteration 4732, loss = 0.00528613
Iteration 4733, loss = 0.00528425
Iteration 4734, loss = 0.00528267
Iteration 4735, loss = 0.00528106
Iteration 4736, loss = 0.00527968
Iteration 4737, loss = 0.00527797
Iteration 4738, loss = 0.00527658
Iteration 4739, loss = 0.00527491
Iteration 4740, loss = 0.00527307
Iteration 4741, loss = 0.00527089
Iteration 4742, loss = 0.00526937
Iteration 4743, loss = 0.00526824
Iteration 4744, loss = 0.00526634
Iteration 4745, loss = 0.00526413
Iteration 4746, loss = 0.00526257
Iteration 4747, loss = 0.00526128
Iteration 4748, loss = 0.00526032
Iteration 4749, loss = 0.00525809
Iteration 4750, loss = 0.00525674
Iteration 4751, loss = 0.00525531
Iteration 4752, loss = 0.00525389
Iteration 4753, loss = 0.00525228
Iteration 4754, loss = 0.00525093
Iteration 4755, loss = 0.00524940
Iteration 4756, loss = 0.00524801
Iteration 4757, loss = 0.00524640
Iteration 4758, loss = 0.00524480
Iteration 4759, loss = 0.00524320
Iteration 4760, loss = 0.00524160
Iteration 4761, loss = 0.00523988
Iteration 4762, loss = 0.00523833
Iteration 4763, loss = 0.00523689
Iteration 4764, loss = 0.00523527
Iteration 4765, loss = 0.00523339
Iteration 4766, loss = 0.00523230
Iteration 4767, loss = 0.00523061
Iteration 4768, loss = 0.00522912
Iteration 4769, loss = 0.00522735
Iteration 4770, loss = 0.00522584
Iteration 4771, loss = 0.00522439
Iteration 4772, loss = 0.00522278
Iteration 4773, loss = 0.00522138
Iteration 4774, loss = 0.00521964
Iteration 4775, loss = 0.00521833
Iteration 4776, loss = 0.00521685
Iteration 4777, loss = 0.00521527
Iteration 4778, loss = 0.00521371
Iteration 4779, loss = 0.00521267
Iteration 4780, loss = 0.00521090
Iteration 4781, loss = 0.00520956
Iteration 4782, loss = 0.00520814
Iteration 4783, loss = 0.00520650
Iteration 4784, loss = 0.00520500
Iteration 4785, loss = 0.00520349
Iteration 4786, loss = 0.00520187
Iteration 4787, loss = 0.00520046
Iteration 4788, loss = 0.00519847
Iteration 4789, loss = 0.00519666
Iteration 4790, loss = 0.00519611
Iteration 4791, loss = 0.00519406
Iteration 4792, loss = 0.00519232
Iteration 4793, loss = 0.00519045
Iteration 4794, loss = 0.00518898
Iteration 4795, loss = 0.00518725
Iteration 4796, loss = 0.00518584
Iteration 4797, loss = 0.00518398
Iteration 4798, loss = 0.00518261
Iteration 4799, loss = 0.00518154
Iteration 4800, loss = 0.00517929
Iteration 4801, loss = 0.00517775
Iteration 4802, loss = 0.00517618
Iteration 4803, loss = 0.00517441
Iteration 4804, loss = 0.00517289
Iteration 4805, loss = 0.00517148
Iteration 4806, loss = 0.00516972
Iteration 4807, loss = 0.00516857
Iteration 4808, loss = 0.00516714
Iteration 4809, loss = 0.00516534
Iteration 4810, loss = 0.00516400
Iteration 4811, loss = 0.00516284
Iteration 4812, loss = 0.00516140
Iteration 4813, loss = 0.00515975
Iteration 4814, loss = 0.00515854
Iteration 4815, loss = 0.00515655
Iteration 4816, loss = 0.00515515
Iteration 4817, loss = 0.00515365
Iteration 4818, loss = 0.00515207
Iteration 4819, loss = 0.00515078
Iteration 4820, loss = 0.00514936
Iteration 4821, loss = 0.00514805
Iteration 4822, loss = 0.00514664
Iteration 4823, loss = 0.00514554
Iteration 4824, loss = 0.00514394
Iteration 4825, loss = 0.00514272
Iteration 4826, loss = 0.00514129
Iteration 4827, loss = 0.00513981
Iteration 4828, loss = 0.00513880
Iteration 4829, loss = 0.00513715
Iteration 4830, loss = 0.00513590
Iteration 4831, loss = 0.00513437
Iteration 4832, loss = 0.00513309
Iteration 4833, loss = 0.00513153
Iteration 4834, loss = 0.00513011
Iteration 4835, loss = 0.00512869
Iteration 4836, loss = 0.00512825
Iteration 4837, loss = 0.00512587
Iteration 4838, loss = 0.00512448
Iteration 4839, loss = 0.00512288
Iteration 4840, loss = 0.00512142
Iteration 4841, loss = 0.00512038
Iteration 4842, loss = 0.00511893
Iteration 4843, loss = 0.00511766
Iteration 4844, loss = 0.00511590
Iteration 4845, loss = 0.00511447
Iteration 4846, loss = 0.00511287
Iteration 4847, loss = 0.00511130
Iteration 4848, loss = 0.00510980
Iteration 4849, loss = 0.00510844
Iteration 4850, loss = 0.00510710
Iteration 4851, loss = 0.00510560
Iteration 4852, loss = 0.00510406
Iteration 4853, loss = 0.00510273
Iteration 4854, loss = 0.00510144
Iteration 4855, loss = 0.00510002
Iteration 4856, loss = 0.00509853
Iteration 4857, loss = 0.00509721
Iteration 4858, loss = 0.00509566
Iteration 4859, loss = 0.00509447
Iteration 4860, loss = 0.00509274
Iteration 4861, loss = 0.00509111
Iteration 4862, loss = 0.00508977
Iteration 4863, loss = 0.00508835
Iteration 4864, loss = 0.00508717
Iteration 4865, loss = 0.00508521
Iteration 4866, loss = 0.00508359
Iteration 4867, loss = 0.00508214
Iteration 4868, loss = 0.00508073
Iteration 4869, loss = 0.00507921
Iteration 4870, loss = 0.00507757
Iteration 4871, loss = 0.00507614
Iteration 4872, loss = 0.00507461
Iteration 4873, loss = 0.00507305
Iteration 4874, loss = 0.00507194
Iteration 4875, loss = 0.00507039
Iteration 4876, loss = 0.00506873
Iteration 4877, loss = 0.00506730
Iteration 4878, loss = 0.00506609
Iteration 4879, loss = 0.00506450
Iteration 4880, loss = 0.00506319
Iteration 4881, loss = 0.00506167
Iteration 4882, loss = 0.00506061
Iteration 4883, loss = 0.00505914
Iteration 4884, loss = 0.00505763
Iteration 4885, loss = 0.00505625
Iteration 4886, loss = 0.00505506
Iteration 4887, loss = 0.00505378
Iteration 4888, loss = 0.00505244
Iteration 4889, loss = 0.00505123
Iteration 4890, loss = 0.00504996
Iteration 4891, loss = 0.00504856
Iteration 4892, loss = 0.00504715
Iteration 4893, loss = 0.00504611
Iteration 4894, loss = 0.00504509
Iteration 4895, loss = 0.00504329
Iteration 4896, loss = 0.00504208
Iteration 4897, loss = 0.00504057
Iteration 4898, loss = 0.00503895
Iteration 4899, loss = 0.00503779
Iteration 4900, loss = 0.00503635
Iteration 4901, loss = 0.00503471
Iteration 4902, loss = 0.00503332
Iteration 4903, loss = 0.00503161
Iteration 4904, loss = 0.00503016
Iteration 4905, loss = 0.00502883
Iteration 4906, loss = 0.00502724
Iteration 4907, loss = 0.00502564
Iteration 4908, loss = 0.00502414
Iteration 4909, loss = 0.00502280
Iteration 4910, loss = 0.00502127
Iteration 4911, loss = 0.00501979
Iteration 4912, loss = 0.00501850
Iteration 4913, loss = 0.00501701
Iteration 4914, loss = 0.00501583
Iteration 4915, loss = 0.00501450
Iteration 4916, loss = 0.00501301
Iteration 4917, loss = 0.00501171
Iteration 4918, loss = 0.00501055
Iteration 4919, loss = 0.00500899
Iteration 4920, loss = 0.00500786
Iteration 4921, loss = 0.00500630
Iteration 4922, loss = 0.00500493
Iteration 4923, loss = 0.00500362
Iteration 4924, loss = 0.00500225
Iteration 4925, loss = 0.00500078
Iteration 4926, loss = 0.00500016
Iteration 4927, loss = 0.00499808
Iteration 4928, loss = 0.00499640
Iteration 4929, loss = 0.00499529
Iteration 4930, loss = 0.00499356
Iteration 4931, loss = 0.00499197
Iteration 4932, loss = 0.00499044
Iteration 4933, loss = 0.00498900
Iteration 4934, loss = 0.00498756
Iteration 4935, loss = 0.00498638
Iteration 4936, loss = 0.00498478
Iteration 4937, loss = 0.00498356
Iteration 4938, loss = 0.00498202
Iteration 4939, loss = 0.00498082
Iteration 4940, loss = 0.00497980
Iteration 4941, loss = 0.00497797
Iteration 4942, loss = 0.00497664
Iteration 4943, loss = 0.00497512
Iteration 4944, loss = 0.00497381
Iteration 4945, loss = 0.00497238
Iteration 4946, loss = 0.00497091
Iteration 4947, loss = 0.00496948
Iteration 4948, loss = 0.00496846
Iteration 4949, loss = 0.00496673
Iteration 4950, loss = 0.00496537
Iteration 4951, loss = 0.00496393
Iteration 4952, loss = 0.00496276
Iteration 4953, loss = 0.00496127
Iteration 4954, loss = 0.00495983
Iteration 4955, loss = 0.00495853
Iteration 4956, loss = 0.00495732
Iteration 4957, loss = 0.00495614
Iteration 4958, loss = 0.00495490
Iteration 4959, loss = 0.00495392
Iteration 4960, loss = 0.00495247
Iteration 4961, loss = 0.00495124
Iteration 4962, loss = 0.00495002
Iteration 4963, loss = 0.00494883
Iteration 4964, loss = 0.00494757
Iteration 4965, loss = 0.00494625
Iteration 4966, loss = 0.00494481
Iteration 4967, loss = 0.00494370
Iteration 4968, loss = 0.00494242
Iteration 4969, loss = 0.00494144
Iteration 4970, loss = 0.00493946
Iteration 4971, loss = 0.00493832
Iteration 4972, loss = 0.00493653
Iteration 4973, loss = 0.00493523
Iteration 4974, loss = 0.00493343
Iteration 4975, loss = 0.00493219
Iteration 4976, loss = 0.00493072
Iteration 4977, loss = 0.00492931
Iteration 4978, loss = 0.00492779
Iteration 4979, loss = 0.00492644
Iteration 4980, loss = 0.00492517
Iteration 4981, loss = 0.00492369
Iteration 4982, loss = 0.00492246
Iteration 4983, loss = 0.00492068
Iteration 4984, loss = 0.00491993
Iteration 4985, loss = 0.00491813
Iteration 4986, loss = 0.00491688
Iteration 4987, loss = 0.00491518
Iteration 4988, loss = 0.00491379
Iteration 4989, loss = 0.00491249
Iteration 4990, loss = 0.00491083
Iteration 4991, loss = 0.00490947
Iteration 4992, loss = 0.00490872
Iteration 4993, loss = 0.00490671
Iteration 4994, loss = 0.00490551
Iteration 4995, loss = 0.00490370
Iteration 4996, loss = 0.00490241
Iteration 4997, loss = 0.00490108
Iteration 4998, loss = 0.00489954
Iteration 4999, loss = 0.00489756
Iteration 5000, loss = 0.00489659
Iteration 5001, loss = 0.00489481
Iteration 5002, loss = 0.00489330
Iteration 5003, loss = 0.00489173
Iteration 5004, loss = 0.00489039
Iteration 5005, loss = 0.00488909
Iteration 5006, loss = 0.00488761
Iteration 5007, loss = 0.00488631
Iteration 5008, loss = 0.00488510
Iteration 5009, loss = 0.00488372
Iteration 5010, loss = 0.00488313
Iteration 5011, loss = 0.00488092
Iteration 5012, loss = 0.00487962
Iteration 5013, loss = 0.00487830
Iteration 5014, loss = 0.00487692
Iteration 5015, loss = 0.00487511
Iteration 5016, loss = 0.00487379
Iteration 5017, loss = 0.00487254
Iteration 5018, loss = 0.00487100
Iteration 5019, loss = 0.00487012
Iteration 5020, loss = 0.00486827
Iteration 5021, loss = 0.00486684
Iteration 5022, loss = 0.00486536
Iteration 5023, loss = 0.00486441
Iteration 5024, loss = 0.00486263
Iteration 5025, loss = 0.00486139
Iteration 5026, loss = 0.00486007
Iteration 5027, loss = 0.00485911
Iteration 5028, loss = 0.00485731
Iteration 5029, loss = 0.00485624
Iteration 5030, loss = 0.00485448
Iteration 5031, loss = 0.00485304
Iteration 5032, loss = 0.00485151
Iteration 5033, loss = 0.00485033
Iteration 5034, loss = 0.00484882
Iteration 5035, loss = 0.00484751
Iteration 5036, loss = 0.00484606
Iteration 5037, loss = 0.00484495
Iteration 5038, loss = 0.00484370
Iteration 5039, loss = 0.00484274
Iteration 5040, loss = 0.00484106
Iteration 5041, loss = 0.00483981
Iteration 5042, loss = 0.00483822
Iteration 5043, loss = 0.00483701
Iteration 5044, loss = 0.00483566
Iteration 5045, loss = 0.00483458
Iteration 5046, loss = 0.00483298
Iteration 5047, loss = 0.00483159
Iteration 5048, loss = 0.00483026
Iteration 5049, loss = 0.00482896
Iteration 5050, loss = 0.00482816
Iteration 5051, loss = 0.00482680
Iteration 5052, loss = 0.00482522
Iteration 5053, loss = 0.00482440
Iteration 5054, loss = 0.00482270
Iteration 5055, loss = 0.00482133
Iteration 5056, loss = 0.00482037
Iteration 5057, loss = 0.00481927
Iteration 5058, loss = 0.00481777
Iteration 5059, loss = 0.00481639
Iteration 5060, loss = 0.00481504
Iteration 5061, loss = 0.00481371
Iteration 5062, loss = 0.00481245
Iteration 5063, loss = 0.00481119
Iteration 5064, loss = 0.00481100
Iteration 5065, loss = 0.00480886
Iteration 5066, loss = 0.00480730
Iteration 5067, loss = 0.00480588
Iteration 5068, loss = 0.00480436
Iteration 5069, loss = 0.00480308
Iteration 5070, loss = 0.00480213
Iteration 5071, loss = 0.00480055
Iteration 5072, loss = 0.00479953
Iteration 5073, loss = 0.00479822
Iteration 5074, loss = 0.00479674
Iteration 5075, loss = 0.00479560
Iteration 5076, loss = 0.00479437
Iteration 5077, loss = 0.00479355
Iteration 5078, loss = 0.00479204
Iteration 5079, loss = 0.00479067
Iteration 5080, loss = 0.00478941
Iteration 5081, loss = 0.00478825
Iteration 5082, loss = 0.00478714
Iteration 5083, loss = 0.00478559
Iteration 5084, loss = 0.00478416
Iteration 5085, loss = 0.00478276
Iteration 5086, loss = 0.00478159
Iteration 5087, loss = 0.00477989
Iteration 5088, loss = 0.00477880
Iteration 5089, loss = 0.00477739
Iteration 5090, loss = 0.00477600
Iteration 5091, loss = 0.00477485
Iteration 5092, loss = 0.00477346
Iteration 5093, loss = 0.00477236
Iteration 5094, loss = 0.00477103
Iteration 5095, loss = 0.00477012
Iteration 5096, loss = 0.00476879
Iteration 5097, loss = 0.00476757
Iteration 5098, loss = 0.00476649
Iteration 5099, loss = 0.00476499
Iteration 5100, loss = 0.00476428
Iteration 5101, loss = 0.00476283
Iteration 5102, loss = 0.00476153
Iteration 5103, loss = 0.00476032
Iteration 5104, loss = 0.00475898
Iteration 5105, loss = 0.00475772
Iteration 5106, loss = 0.00475645
Iteration 5107, loss = 0.00475532
Iteration 5108, loss = 0.00475408
Iteration 5109, loss = 0.00475415
Iteration 5110, loss = 0.00475203
Iteration 5111, loss = 0.00475021
Iteration 5112, loss = 0.00474901
Iteration 5113, loss = 0.00474757
Iteration 5114, loss = 0.00474621
Iteration 5115, loss = 0.00474456
Iteration 5116, loss = 0.00474326
Iteration 5117, loss = 0.00474209
Iteration 5118, loss = 0.00474140
Iteration 5119, loss = 0.00473947
Iteration 5120, loss = 0.00473809
Iteration 5121, loss = 0.00473677
Iteration 5122, loss = 0.00473554
Iteration 5123, loss = 0.00473445
Iteration 5124, loss = 0.00473266
Iteration 5125, loss = 0.00473138
Iteration 5126, loss = 0.00472998
Iteration 5127, loss = 0.00472873
Iteration 5128, loss = 0.00472743
Iteration 5129, loss = 0.00472609
Iteration 5130, loss = 0.00472480
Iteration 5131, loss = 0.00472349
Iteration 5132, loss = 0.00472221
Iteration 5133, loss = 0.00472156
Iteration 5134, loss = 0.00471968
Iteration 5135, loss = 0.00471847
Iteration 5136, loss = 0.00471694
Iteration 5137, loss = 0.00471571
Iteration 5138, loss = 0.00471442
Iteration 5139, loss = 0.00471299
Iteration 5140, loss = 0.00471182
Iteration 5141, loss = 0.00471051
Iteration 5142, loss = 0.00470903
Iteration 5143, loss = 0.00470828
Iteration 5144, loss = 0.00470629
Iteration 5145, loss = 0.00470505
Iteration 5146, loss = 0.00470386
Iteration 5147, loss = 0.00470286
Iteration 5148, loss = 0.00470135
Iteration 5149, loss = 0.00470027
Iteration 5150, loss = 0.00469899
Iteration 5151, loss = 0.00469759
Iteration 5152, loss = 0.00469644
Iteration 5153, loss = 0.00469510
Iteration 5154, loss = 0.00469374
Iteration 5155, loss = 0.00469273
Iteration 5156, loss = 0.00469125
Iteration 5157, loss = 0.00468999
Iteration 5158, loss = 0.00468896
Iteration 5159, loss = 0.00468761
Iteration 5160, loss = 0.00468627
Iteration 5161, loss = 0.00468520
Iteration 5162, loss = 0.00468389
Iteration 5163, loss = 0.00468254
Iteration 5164, loss = 0.00468127
Iteration 5165, loss = 0.00468009
Iteration 5166, loss = 0.00467887
Iteration 5167, loss = 0.00467763
Iteration 5168, loss = 0.00467646
Iteration 5169, loss = 0.00467537
Iteration 5170, loss = 0.00467405
Iteration 5171, loss = 0.00467264
Iteration 5172, loss = 0.00467157
Iteration 5173, loss = 0.00467057
Iteration 5174, loss = 0.00466922
Iteration 5175, loss = 0.00466810
Iteration 5176, loss = 0.00466731
Iteration 5177, loss = 0.00466596
Iteration 5178, loss = 0.00466469
Iteration 5179, loss = 0.00466359
Iteration 5180, loss = 0.00466252
Iteration 5181, loss = 0.00466126
Iteration 5182, loss = 0.00466024
Iteration 5183, loss = 0.00465896
Iteration 5184, loss = 0.00465770
Iteration 5185, loss = 0.00465651
Iteration 5186, loss = 0.00465505
Iteration 5187, loss = 0.00465365
Iteration 5188, loss = 0.00465234
Iteration 5189, loss = 0.00465130
Iteration 5190, loss = 0.00464995
Iteration 5191, loss = 0.00464874
Iteration 5192, loss = 0.00464732
Iteration 5193, loss = 0.00464623
Iteration 5194, loss = 0.00464473
Iteration 5195, loss = 0.00464345
Iteration 5196, loss = 0.00464237
Iteration 5197, loss = 0.00464111
Iteration 5198, loss = 0.00463962
Iteration 5199, loss = 0.00463852
Iteration 5200, loss = 0.00463726
Iteration 5201, loss = 0.00463575
Iteration 5202, loss = 0.00463483
Iteration 5203, loss = 0.00463318
Iteration 5204, loss = 0.00463190
Iteration 5205, loss = 0.00463092
Iteration 5206, loss = 0.00462928
Iteration 5207, loss = 0.00462800
Iteration 5208, loss = 0.00462648
Iteration 5209, loss = 0.00462532
Iteration 5210, loss = 0.00462394
Iteration 5211, loss = 0.00462255
Iteration 5212, loss = 0.00462123
Iteration 5213, loss = 0.00461991
Iteration 5214, loss = 0.00461862
Iteration 5215, loss = 0.00461744
Iteration 5216, loss = 0.00461621
Iteration 5217, loss = 0.00461503
Iteration 5218, loss = 0.00461395
Iteration 5219, loss = 0.00461288
Iteration 5220, loss = 0.00461158
Iteration 5221, loss = 0.00461039
Iteration 5222, loss = 0.00461030
Iteration 5223, loss = 0.00460765
Iteration 5224, loss = 0.00460654
Iteration 5225, loss = 0.00460564
Iteration 5226, loss = 0.00460403
Iteration 5227, loss = 0.00460326
Iteration 5228, loss = 0.00460212
Iteration 5229, loss = 0.00460053
Iteration 5230, loss = 0.00459964
Iteration 5231, loss = 0.00459816
Iteration 5232, loss = 0.00459693
Iteration 5233, loss = 0.00459567
Iteration 5234, loss = 0.00459468
Iteration 5235, loss = 0.00459354
Iteration 5236, loss = 0.00459130
Iteration 5237, loss = 0.00459027
Iteration 5238, loss = 0.00458919
Iteration 5239, loss = 0.00458740
Iteration 5240, loss = 0.00458623
Iteration 5241, loss = 0.00458480
Iteration 5242, loss = 0.00458355
Iteration 5243, loss = 0.00458222
Iteration 5244, loss = 0.00458105
Iteration 5245, loss = 0.00458018
Iteration 5246, loss = 0.00457853
Iteration 5247, loss = 0.00457717
Iteration 5248, loss = 0.00457633
Iteration 5249, loss = 0.00457472
Iteration 5250, loss = 0.00457348
Iteration 5251, loss = 0.00457302
Iteration 5252, loss = 0.00457103
Iteration 5253, loss = 0.00456995
Iteration 5254, loss = 0.00456876
Iteration 5255, loss = 0.00456746
Iteration 5256, loss = 0.00456638
Iteration 5257, loss = 0.00456501
Iteration 5258, loss = 0.00456392
Iteration 5259, loss = 0.00456258
Iteration 5260, loss = 0.00456134
Iteration 5261, loss = 0.00455984
Iteration 5262, loss = 0.00455857
Iteration 5263, loss = 0.00455767
Iteration 5264, loss = 0.00455631
Iteration 5265, loss = 0.00455525
Iteration 5266, loss = 0.00455387
Iteration 5267, loss = 0.00455290
Iteration 5268, loss = 0.00455153
Iteration 5269, loss = 0.00455057
Iteration 5270, loss = 0.00454991
Iteration 5271, loss = 0.00454841
Iteration 5272, loss = 0.00454716
Iteration 5273, loss = 0.00454599
Iteration 5274, loss = 0.00454484
Iteration 5275, loss = 0.00454371
Iteration 5276, loss = 0.00454338
Iteration 5277, loss = 0.00454178
Iteration 5278, loss = 0.00454083
Iteration 5279, loss = 0.00453950
Iteration 5280, loss = 0.00453827
Iteration 5281, loss = 0.00453701
Iteration 5282, loss = 0.00453565
Iteration 5283, loss = 0.00453459
Iteration 5284, loss = 0.00453336
Iteration 5285, loss = 0.00453213
Iteration 5286, loss = 0.00453108
Iteration 5287, loss = 0.00453018
Iteration 5288, loss = 0.00452900
Iteration 5289, loss = 0.00452766
Iteration 5290, loss = 0.00452623
Iteration 5291, loss = 0.00452516
Iteration 5292, loss = 0.00452387
Iteration 5293, loss = 0.00452251
Iteration 5294, loss = 0.00452142
Iteration 5295, loss = 0.00452001
Iteration 5296, loss = 0.00451911
Iteration 5297, loss = 0.00451734
Iteration 5298, loss = 0.00451642
Iteration 5299, loss = 0.00451526
Iteration 5300, loss = 0.00451412
Iteration 5301, loss = 0.00451282
Iteration 5302, loss = 0.00451130
Iteration 5303, loss = 0.00451018
Iteration 5304, loss = 0.00450890
Iteration 5305, loss = 0.00450803
Iteration 5306, loss = 0.00450646
Iteration 5307, loss = 0.00450513
Iteration 5308, loss = 0.00450390
Iteration 5309, loss = 0.00450264
Iteration 5310, loss = 0.00450148
Iteration 5311, loss = 0.00450015
Iteration 5312, loss = 0.00449880
Iteration 5313, loss = 0.00449756
Iteration 5314, loss = 0.00449637
Iteration 5315, loss = 0.00449523
Iteration 5316, loss = 0.00449387
Iteration 5317, loss = 0.00449292
Iteration 5318, loss = 0.00449250
Iteration 5319, loss = 0.00449003
Iteration 5320, loss = 0.00448894
Iteration 5321, loss = 0.00448761
Iteration 5322, loss = 0.00448644
Iteration 5323, loss = 0.00448517
Iteration 5324, loss = 0.00448439
Iteration 5325, loss = 0.00448282
Iteration 5326, loss = 0.00448207
Iteration 5327, loss = 0.00448051
Iteration 5328, loss = 0.00447975
Iteration 5329, loss = 0.00447814
Iteration 5330, loss = 0.00447706
Iteration 5331, loss = 0.00447585
Iteration 5332, loss = 0.00447454
Iteration 5333, loss = 0.00447346
Iteration 5334, loss = 0.00447224
Iteration 5335, loss = 0.00447102
Iteration 5336, loss = 0.00446992
Iteration 5337, loss = 0.00446861
Iteration 5338, loss = 0.00446746
Iteration 5339, loss = 0.00446650
Iteration 5340, loss = 0.00446517
Iteration 5341, loss = 0.00446393
Iteration 5342, loss = 0.00446288
Iteration 5343, loss = 0.00446175
Iteration 5344, loss = 0.00446034
Iteration 5345, loss = 0.00445961
Iteration 5346, loss = 0.00445805
Iteration 5347, loss = 0.00445702
Iteration 5348, loss = 0.00445576
Iteration 5349, loss = 0.00445446
Iteration 5350, loss = 0.00445382
Iteration 5351, loss = 0.00445228
Iteration 5352, loss = 0.00445127
Iteration 5353, loss = 0.00444979
Iteration 5354, loss = 0.00444878
Iteration 5355, loss = 0.00444814
Iteration 5356, loss = 0.00444651
Iteration 5357, loss = 0.00444523
Iteration 5358, loss = 0.00444396
Iteration 5359, loss = 0.00444295
Iteration 5360, loss = 0.00444163
Iteration 5361, loss = 0.00444081
Iteration 5362, loss = 0.00443956
Iteration 5363, loss = 0.00443813
Iteration 5364, loss = 0.00443695
Iteration 5365, loss = 0.00443571
Iteration 5366, loss = 0.00443468
Iteration 5367, loss = 0.00443342
Iteration 5368, loss = 0.00443217
Iteration 5369, loss = 0.00443105
Iteration 5370, loss = 0.00442987
Iteration 5371, loss = 0.00442895
Iteration 5372, loss = 0.00442756
Iteration 5373, loss = 0.00442650
Iteration 5374, loss = 0.00442585
Iteration 5375, loss = 0.00442410
Iteration 5376, loss = 0.00442320
Iteration 5377, loss = 0.00442192
Iteration 5378, loss = 0.00442080
Iteration 5379, loss = 0.00441928
Iteration 5380, loss = 0.00441824
Iteration 5381, loss = 0.00441715
Iteration 5382, loss = 0.00441558
Iteration 5383, loss = 0.00441436
Iteration 5384, loss = 0.00441315
Iteration 5385, loss = 0.00441200
Iteration 5386, loss = 0.00441088
Iteration 5387, loss = 0.00440967
Iteration 5388, loss = 0.00440859
Iteration 5389, loss = 0.00440701
Iteration 5390, loss = 0.00440590
Iteration 5391, loss = 0.00440485
Iteration 5392, loss = 0.00440366
Iteration 5393, loss = 0.00440242
Iteration 5394, loss = 0.00440146
Iteration 5395, loss = 0.00440022
Iteration 5396, loss = 0.00439916
Iteration 5397, loss = 0.00439810
Iteration 5398, loss = 0.00439721
Iteration 5399, loss = 0.00439612
Iteration 5400, loss = 0.00439523
Iteration 5401, loss = 0.00439402
Iteration 5402, loss = 0.00439287
Iteration 5403, loss = 0.00439182
Iteration 5404, loss = 0.00439078
Iteration 5405, loss = 0.00438975
Iteration 5406, loss = 0.00438848
Iteration 5407, loss = 0.00438749
Iteration 5408, loss = 0.00438637
Iteration 5409, loss = 0.00438531
Iteration 5410, loss = 0.00438439
Iteration 5411, loss = 0.00438317
Iteration 5412, loss = 0.00438217
Iteration 5413, loss = 0.00438151
Iteration 5414, loss = 0.00438008
Iteration 5415, loss = 0.00437887
Iteration 5416, loss = 0.00437765
Iteration 5417, loss = 0.00437697
Iteration 5418, loss = 0.00437555
Iteration 5419, loss = 0.00437438
Iteration 5420, loss = 0.00437330
Iteration 5421, loss = 0.00437235
Iteration 5422, loss = 0.00437156
Iteration 5423, loss = 0.00437021
Iteration 5424, loss = 0.00436927
Iteration 5425, loss = 0.00436816
Iteration 5426, loss = 0.00436698
Iteration 5427, loss = 0.00436581
Iteration 5428, loss = 0.00436458
Iteration 5429, loss = 0.00436345
Iteration 5430, loss = 0.00436249
Iteration 5431, loss = 0.00436108
Iteration 5432, loss = 0.00435990
Iteration 5433, loss = 0.00435865
Iteration 5434, loss = 0.00435738
Iteration 5435, loss = 0.00435646
Iteration 5436, loss = 0.00435570
Iteration 5437, loss = 0.00435448
Iteration 5438, loss = 0.00435343
Iteration 5439, loss = 0.00435227
Iteration 5440, loss = 0.00435109
Iteration 5441, loss = 0.00435053
Iteration 5442, loss = 0.00434886
Iteration 5443, loss = 0.00434784
Iteration 5444, loss = 0.00434706
Iteration 5445, loss = 0.00434570
Iteration 5446, loss = 0.00434423
Iteration 5447, loss = 0.00434314
Iteration 5448, loss = 0.00434197
Iteration 5449, loss = 0.00434085
Iteration 5450, loss = 0.00433970
Iteration 5451, loss = 0.00433866
Iteration 5452, loss = 0.00433755
Iteration 5453, loss = 0.00433629
Iteration 5454, loss = 0.00433563
Iteration 5455, loss = 0.00433435
Iteration 5456, loss = 0.00433321
Iteration 5457, loss = 0.00433212
Iteration 5458, loss = 0.00433115
Iteration 5459, loss = 0.00433012
Iteration 5460, loss = 0.00432913
Iteration 5461, loss = 0.00432809
Iteration 5462, loss = 0.00432720
Iteration 5463, loss = 0.00432655
Iteration 5464, loss = 0.00432554
Iteration 5465, loss = 0.00432436
Iteration 5466, loss = 0.00432338
Iteration 5467, loss = 0.00432232
Iteration 5468, loss = 0.00432143
Iteration 5469, loss = 0.00432041
Iteration 5470, loss = 0.00431928
Iteration 5471, loss = 0.00431831
Iteration 5472, loss = 0.00431732
Iteration 5473, loss = 0.00431623
Iteration 5474, loss = 0.00431525
Iteration 5475, loss = 0.00431449
Iteration 5476, loss = 0.00431343
Iteration 5477, loss = 0.00431271
Iteration 5478, loss = 0.00431150
Iteration 5479, loss = 0.00431062
Iteration 5480, loss = 0.00430948
Iteration 5481, loss = 0.00430851
Iteration 5482, loss = 0.00430759
Iteration 5483, loss = 0.00430664
Iteration 5484, loss = 0.00430560
Iteration 5485, loss = 0.00430448
Iteration 5486, loss = 0.00430362
Iteration 5487, loss = 0.00430251
Iteration 5488, loss = 0.00430238
Iteration 5489, loss = 0.00430087
Iteration 5490, loss = 0.00429949
Iteration 5491, loss = 0.00429843
Iteration 5492, loss = 0.00429732
Iteration 5493, loss = 0.00429633
Iteration 5494, loss = 0.00429521
Iteration 5495, loss = 0.00429399
Iteration 5496, loss = 0.00429291
Iteration 5497, loss = 0.00429179
Iteration 5498, loss = 0.00429106
Iteration 5499, loss = 0.00428962
Iteration 5500, loss = 0.00428827
Iteration 5501, loss = 0.00428724
Iteration 5502, loss = 0.00428601
Iteration 5503, loss = 0.00428483
Iteration 5504, loss = 0.00428368
Iteration 5505, loss = 0.00428248
Iteration 5506, loss = 0.00428138
Iteration 5507, loss = 0.00428025
Iteration 5508, loss = 0.00427897
Iteration 5509, loss = 0.00427785
Iteration 5510, loss = 0.00427665
Iteration 5511, loss = 0.00427559
Iteration 5512, loss = 0.00427455
Iteration 5513, loss = 0.00427345
Iteration 5514, loss = 0.00427233
Iteration 5515, loss = 0.00427130
Iteration 5516, loss = 0.00427028
Iteration 5517, loss = 0.00426916
Iteration 5518, loss = 0.00426813
Iteration 5519, loss = 0.00426727
Iteration 5520, loss = 0.00426696
Iteration 5521, loss = 0.00426493
Iteration 5522, loss = 0.00426374
Iteration 5523, loss = 0.00426235
Iteration 5524, loss = 0.00426141
Iteration 5525, loss = 0.00426024
Iteration 5526, loss = 0.00425892
Iteration 5527, loss = 0.00425791
Iteration 5528, loss = 0.00425707
Iteration 5529, loss = 0.00425585
Iteration 5530, loss = 0.00425493
Iteration 5531, loss = 0.00425348
Iteration 5532, loss = 0.00425263
Iteration 5533, loss = 0.00425102
Iteration 5534, loss = 0.00424995
Iteration 5535, loss = 0.00424867
Iteration 5536, loss = 0.00424746
Iteration 5537, loss = 0.00424653
Iteration 5538, loss = 0.00424517
Iteration 5539, loss = 0.00424470
Iteration 5540, loss = 0.00424336
Iteration 5541, loss = 0.00424214
Iteration 5542, loss = 0.00424115
Iteration 5543, loss = 0.00424019
Iteration 5544, loss = 0.00423927
Iteration 5545, loss = 0.00423802
Iteration 5546, loss = 0.00423758
Iteration 5547, loss = 0.00423618
Iteration 5548, loss = 0.00423510
Iteration 5549, loss = 0.00423422
Iteration 5550, loss = 0.00423317
Iteration 5551, loss = 0.00423236
Iteration 5552, loss = 0.00423126
Iteration 5553, loss = 0.00423069
Iteration 5554, loss = 0.00422900
Iteration 5555, loss = 0.00422787
Iteration 5556, loss = 0.00422679
Iteration 5557, loss = 0.00422574
Iteration 5558, loss = 0.00422482
Iteration 5559, loss = 0.00422365
Iteration 5560, loss = 0.00422288
Iteration 5561, loss = 0.00422160
Iteration 5562, loss = 0.00422080
Iteration 5563, loss = 0.00421969
Iteration 5564, loss = 0.00421879
Iteration 5565, loss = 0.00421778
Iteration 5566, loss = 0.00421700
Iteration 5567, loss = 0.00421576
Iteration 5568, loss = 0.00421458
Iteration 5569, loss = 0.00421353
Iteration 5570, loss = 0.00421247
Iteration 5571, loss = 0.00421132
Iteration 5572, loss = 0.00420981
Iteration 5573, loss = 0.00420875
Iteration 5574, loss = 0.00420731
Iteration 5575, loss = 0.00420614
Iteration 5576, loss = 0.00420514
Iteration 5577, loss = 0.00420368
Iteration 5578, loss = 0.00420285
Iteration 5579, loss = 0.00420197
Iteration 5580, loss = 0.00420078
Iteration 5581, loss = 0.00419999
Iteration 5582, loss = 0.00419886
Iteration 5583, loss = 0.00419797
Iteration 5584, loss = 0.00419698
Iteration 5585, loss = 0.00419607
Iteration 5586, loss = 0.00419520
Iteration 5587, loss = 0.00419442
Iteration 5588, loss = 0.00419395
Iteration 5589, loss = 0.00419238
Iteration 5590, loss = 0.00419106
Iteration 5591, loss = 0.00418993
Iteration 5592, loss = 0.00418950
Iteration 5593, loss = 0.00418783
Iteration 5594, loss = 0.00418667
Iteration 5595, loss = 0.00418553
Iteration 5596, loss = 0.00418455
Iteration 5597, loss = 0.00418333
Iteration 5598, loss = 0.00418227
Iteration 5599, loss = 0.00418129
Iteration 5600, loss = 0.00418024
Iteration 5601, loss = 0.00417902
Iteration 5602, loss = 0.00417829
Iteration 5603, loss = 0.00417693
Iteration 5604, loss = 0.00417589
Iteration 5605, loss = 0.00417468
Iteration 5606, loss = 0.00417355
Iteration 5607, loss = 0.00417246
Iteration 5608, loss = 0.00417133
Iteration 5609, loss = 0.00417049
Iteration 5610, loss = 0.00416922
Iteration 5611, loss = 0.00416840
Iteration 5612, loss = 0.00416743
Iteration 5613, loss = 0.00416634
Iteration 5614, loss = 0.00416544
Iteration 5615, loss = 0.00416462
Iteration 5616, loss = 0.00416341
Iteration 5617, loss = 0.00416239
Iteration 5618, loss = 0.00416125
Iteration 5619, loss = 0.00415980
Iteration 5620, loss = 0.00415872
Iteration 5621, loss = 0.00415748
Iteration 5622, loss = 0.00415636
Iteration 5623, loss = 0.00415545
Iteration 5624, loss = 0.00415413
Iteration 5625, loss = 0.00415312
Iteration 5626, loss = 0.00415208
Iteration 5627, loss = 0.00415100
Iteration 5628, loss = 0.00414995
Iteration 5629, loss = 0.00414931
Iteration 5630, loss = 0.00414809
Iteration 5631, loss = 0.00414722
Iteration 5632, loss = 0.00414599
Iteration 5633, loss = 0.00414469
Iteration 5634, loss = 0.00414351
Iteration 5635, loss = 0.00414268
Iteration 5636, loss = 0.00414135
Iteration 5637, loss = 0.00414013
Iteration 5638, loss = 0.00413938
Iteration 5639, loss = 0.00413827
Iteration 5640, loss = 0.00413707
Iteration 5641, loss = 0.00413581
Iteration 5642, loss = 0.00413500
Iteration 5643, loss = 0.00413391
Iteration 5644, loss = 0.00413313
Iteration 5645, loss = 0.00413195
Iteration 5646, loss = 0.00413089
Iteration 5647, loss = 0.00412981
Iteration 5648, loss = 0.00412874
Iteration 5649, loss = 0.00412769
Iteration 5650, loss = 0.00412681
Iteration 5651, loss = 0.00412562
Iteration 5652, loss = 0.00412448
Iteration 5653, loss = 0.00412364
Iteration 5654, loss = 0.00412250
Iteration 5655, loss = 0.00412152
Iteration 5656, loss = 0.00412051
Iteration 5657, loss = 0.00411956
Iteration 5658, loss = 0.00411867
Iteration 5659, loss = 0.00411781
Iteration 5660, loss = 0.00411664
Iteration 5661, loss = 0.00411557
Iteration 5662, loss = 0.00411492
Iteration 5663, loss = 0.00411373
Iteration 5664, loss = 0.00411267
Iteration 5665, loss = 0.00411172
Iteration 5666, loss = 0.00411067
Iteration 5667, loss = 0.00410946
Iteration 5668, loss = 0.00410867
Iteration 5669, loss = 0.00410763
Iteration 5670, loss = 0.00410664
Iteration 5671, loss = 0.00410567
Iteration 5672, loss = 0.00410483
Iteration 5673, loss = 0.00410383
Iteration 5674, loss = 0.00410280
Iteration 5675, loss = 0.00410232
Iteration 5676, loss = 0.00410111
Iteration 5677, loss = 0.00410021
Iteration 5678, loss = 0.00409908
Iteration 5679, loss = 0.00409799
Iteration 5680, loss = 0.00409702
Iteration 5681, loss = 0.00409585
Iteration 5682, loss = 0.00409462
Iteration 5683, loss = 0.00409344
Iteration 5684, loss = 0.00409230
Iteration 5685, loss = 0.00409107
Iteration 5686, loss = 0.00408974
Iteration 5687, loss = 0.00408856
Iteration 5688, loss = 0.00408773
Iteration 5689, loss = 0.00408634
Iteration 5690, loss = 0.00408539
Iteration 5691, loss = 0.00408418
Iteration 5692, loss = 0.00408314
Iteration 5693, loss = 0.00408197
Iteration 5694, loss = 0.00408100
Iteration 5695, loss = 0.00407993
Iteration 5696, loss = 0.00407870
Iteration 5697, loss = 0.00407757
Iteration 5698, loss = 0.00407702
Iteration 5699, loss = 0.00407595
Iteration 5700, loss = 0.00407441
Iteration 5701, loss = 0.00407331
Iteration 5702, loss = 0.00407254
Iteration 5703, loss = 0.00407120
Iteration 5704, loss = 0.00406977
Iteration 5705, loss = 0.00406840
Iteration 5706, loss = 0.00406740
Iteration 5707, loss = 0.00406668
Iteration 5708, loss = 0.00406595
Iteration 5709, loss = 0.00406427
Iteration 5710, loss = 0.00406335
Iteration 5711, loss = 0.00406223
Iteration 5712, loss = 0.00406124
Iteration 5713, loss = 0.00406003
Iteration 5714, loss = 0.00405939
Iteration 5715, loss = 0.00405815
Iteration 5716, loss = 0.00405696
Iteration 5717, loss = 0.00405581
Iteration 5718, loss = 0.00405469
Iteration 5719, loss = 0.00405371
Iteration 5720, loss = 0.00405264
Iteration 5721, loss = 0.00405202
Iteration 5722, loss = 0.00405073
Iteration 5723, loss = 0.00405033
Iteration 5724, loss = 0.00404897
Iteration 5725, loss = 0.00404787
Iteration 5726, loss = 0.00404664
Iteration 5727, loss = 0.00404574
Iteration 5728, loss = 0.00404499
Iteration 5729, loss = 0.00404368
Iteration 5730, loss = 0.00404282
Iteration 5731, loss = 0.00404182
Iteration 5732, loss = 0.00404065
Iteration 5733, loss = 0.00403972
Iteration 5734, loss = 0.00403881
Iteration 5735, loss = 0.00403812
Iteration 5736, loss = 0.00403710
Iteration 5737, loss = 0.00403620
Iteration 5738, loss = 0.00403528
Iteration 5739, loss = 0.00403460
Iteration 5740, loss = 0.00403372
Iteration 5741, loss = 0.00403288
Iteration 5742, loss = 0.00403227
Iteration 5743, loss = 0.00403132
Iteration 5744, loss = 0.00403030
Iteration 5745, loss = 0.00402914
Iteration 5746, loss = 0.00402833
Iteration 5747, loss = 0.00402731
Iteration 5748, loss = 0.00402630
Iteration 5749, loss = 0.00402538
Iteration 5750, loss = 0.00402455
Iteration 5751, loss = 0.00402355
Iteration 5752, loss = 0.00402265
Iteration 5753, loss = 0.00402171
Iteration 5754, loss = 0.00402076
Iteration 5755, loss = 0.00401969
Iteration 5756, loss = 0.00401845
Iteration 5757, loss = 0.00401759
Iteration 5758, loss = 0.00401672
Iteration 5759, loss = 0.00401598
Iteration 5760, loss = 0.00401508
Iteration 5761, loss = 0.00401395
Iteration 5762, loss = 0.00401268
Iteration 5763, loss = 0.00401178
Iteration 5764, loss = 0.00401098
Iteration 5765, loss = 0.00400988
Iteration 5766, loss = 0.00400879
Iteration 5767, loss = 0.00400805
Iteration 5768, loss = 0.00400688
Iteration 5769, loss = 0.00400609
Iteration 5770, loss = 0.00400506
Iteration 5771, loss = 0.00400416
Iteration 5772, loss = 0.00400325
Iteration 5773, loss = 0.00400273
Iteration 5774, loss = 0.00400121
Iteration 5775, loss = 0.00400036
Iteration 5776, loss = 0.00399910
Iteration 5777, loss = 0.00399820
Iteration 5778, loss = 0.00399729
Iteration 5779, loss = 0.00399592
Iteration 5780, loss = 0.00399485
Iteration 5781, loss = 0.00399390
Iteration 5782, loss = 0.00399285
Iteration 5783, loss = 0.00399173
Iteration 5784, loss = 0.00399089
Iteration 5785, loss = 0.00398984
Iteration 5786, loss = 0.00398881
Iteration 5787, loss = 0.00398786
Iteration 5788, loss = 0.00398702
Iteration 5789, loss = 0.00398608
Iteration 5790, loss = 0.00398520
Iteration 5791, loss = 0.00398404
Iteration 5792, loss = 0.00398375
Iteration 5793, loss = 0.00398223
Iteration 5794, loss = 0.00398123
Iteration 5795, loss = 0.00398017
Iteration 5796, loss = 0.00397927
Iteration 5797, loss = 0.00397861
Iteration 5798, loss = 0.00397701
Iteration 5799, loss = 0.00397589
Iteration 5800, loss = 0.00397490
Iteration 5801, loss = 0.00397389
Iteration 5802, loss = 0.00397287
Iteration 5803, loss = 0.00397225
Iteration 5804, loss = 0.00397103
Iteration 5805, loss = 0.00397003
Iteration 5806, loss = 0.00396917
Iteration 5807, loss = 0.00396866
Iteration 5808, loss = 0.00396768
Iteration 5809, loss = 0.00396691
Iteration 5810, loss = 0.00396575
Iteration 5811, loss = 0.00396488
Iteration 5812, loss = 0.00396393
Iteration 5813, loss = 0.00396305
Iteration 5814, loss = 0.00396219
Iteration 5815, loss = 0.00396195
Iteration 5816, loss = 0.00396043
Iteration 5817, loss = 0.00395942
Iteration 5818, loss = 0.00395867
Iteration 5819, loss = 0.00395754
Iteration 5820, loss = 0.00395686
Iteration 5821, loss = 0.00395591
Iteration 5822, loss = 0.00395502
Iteration 5823, loss = 0.00395384
Iteration 5824, loss = 0.00395297
Iteration 5825, loss = 0.00395209
Iteration 5826, loss = 0.00395103
Iteration 5827, loss = 0.00395006
Iteration 5828, loss = 0.00394886
Iteration 5829, loss = 0.00394846
Iteration 5830, loss = 0.00394670
Iteration 5831, loss = 0.00394564
Iteration 5832, loss = 0.00394460
Iteration 5833, loss = 0.00394354
Iteration 5834, loss = 0.00394260
Iteration 5835, loss = 0.00394165
Iteration 5836, loss = 0.00394064
Iteration 5837, loss = 0.00393949
Iteration 5838, loss = 0.00393841
Iteration 5839, loss = 0.00393743
Iteration 5840, loss = 0.00393658
Iteration 5841, loss = 0.00393561
Iteration 5842, loss = 0.00393459
Iteration 5843, loss = 0.00393348
Iteration 5844, loss = 0.00393266
Iteration 5845, loss = 0.00393215
Iteration 5846, loss = 0.00393077
Iteration 5847, loss = 0.00392968
Iteration 5848, loss = 0.00392873
Iteration 5849, loss = 0.00392778
Iteration 5850, loss = 0.00392666
Iteration 5851, loss = 0.00392547
Iteration 5852, loss = 0.00392502
Iteration 5853, loss = 0.00392388
Iteration 5854, loss = 0.00392277
Iteration 5855, loss = 0.00392157
Iteration 5856, loss = 0.00392075
Iteration 5857, loss = 0.00391994
Iteration 5858, loss = 0.00391888
Iteration 5859, loss = 0.00391799
Iteration 5860, loss = 0.00391675
Iteration 5861, loss = 0.00391584
Iteration 5862, loss = 0.00391477
Iteration 5863, loss = 0.00391387
Iteration 5864, loss = 0.00391323
Iteration 5865, loss = 0.00391204
Iteration 5866, loss = 0.00391145
Iteration 5867, loss = 0.00391033
Iteration 5868, loss = 0.00390942
Iteration 5869, loss = 0.00390851
Iteration 5870, loss = 0.00390751
Iteration 5871, loss = 0.00390648
Iteration 5872, loss = 0.00390549
Iteration 5873, loss = 0.00390444
Iteration 5874, loss = 0.00390370
Iteration 5875, loss = 0.00390246
Iteration 5876, loss = 0.00390158
Iteration 5877, loss = 0.00390051
Iteration 5878, loss = 0.00389953
Iteration 5879, loss = 0.00389867
Iteration 5880, loss = 0.00389785
Iteration 5881, loss = 0.00389697
Iteration 5882, loss = 0.00389606
Iteration 5883, loss = 0.00389523
Iteration 5884, loss = 0.00389425
Iteration 5885, loss = 0.00389338
Iteration 5886, loss = 0.00389254
Iteration 5887, loss = 0.00389144
Iteration 5888, loss = 0.00389056
Iteration 5889, loss = 0.00388976
Iteration 5890, loss = 0.00388884
Iteration 5891, loss = 0.00388776
Iteration 5892, loss = 0.00388718
Iteration 5893, loss = 0.00388598
Iteration 5894, loss = 0.00388512
Iteration 5895, loss = 0.00388428
Iteration 5896, loss = 0.00388321
Iteration 5897, loss = 0.00388214
Iteration 5898, loss = 0.00388131
Iteration 5899, loss = 0.00388032
Iteration 5900, loss = 0.00387929
Iteration 5901, loss = 0.00387842
Iteration 5902, loss = 0.00387750
Iteration 5903, loss = 0.00387663
Iteration 5904, loss = 0.00387579
Iteration 5905, loss = 0.00387486
Iteration 5906, loss = 0.00387426
Iteration 5907, loss = 0.00387315
Iteration 5908, loss = 0.00387240
Iteration 5909, loss = 0.00387163
Iteration 5910, loss = 0.00387057
Iteration 5911, loss = 0.00386976
Iteration 5912, loss = 0.00386865
Iteration 5913, loss = 0.00386789
Iteration 5914, loss = 0.00386700
Iteration 5915, loss = 0.00386617
Iteration 5916, loss = 0.00386524
Iteration 5917, loss = 0.00386443
Iteration 5918, loss = 0.00386352
Iteration 5919, loss = 0.00386289
Iteration 5920, loss = 0.00386184
Iteration 5921, loss = 0.00386086
Iteration 5922, loss = 0.00385973
Iteration 5923, loss = 0.00385892
Iteration 5924, loss = 0.00385792
Iteration 5925, loss = 0.00385702
Iteration 5926, loss = 0.00385604
Iteration 5927, loss = 0.00385509
Iteration 5928, loss = 0.00385414
Iteration 5929, loss = 0.00385310
Iteration 5930, loss = 0.00385212
Iteration 5931, loss = 0.00385115
Iteration 5932, loss = 0.00385013
Iteration 5933, loss = 0.00384910
Iteration 5934, loss = 0.00384796
Iteration 5935, loss = 0.00384664
Iteration 5936, loss = 0.00384535
Iteration 5937, loss = 0.00384477
Iteration 5938, loss = 0.00384406
Iteration 5939, loss = 0.00384330
Iteration 5940, loss = 0.00384179
Iteration 5941, loss = 0.00384106
Iteration 5942, loss = 0.00384018
Iteration 5943, loss = 0.00383934
Iteration 5944, loss = 0.00383839
Iteration 5945, loss = 0.00383743
Iteration 5946, loss = 0.00383652
Iteration 5947, loss = 0.00383554
Iteration 5948, loss = 0.00383465
Iteration 5949, loss = 0.00383381
Iteration 5950, loss = 0.00383284
Iteration 5951, loss = 0.00383205
Iteration 5952, loss = 0.00383106
Iteration 5953, loss = 0.00383005
Iteration 5954, loss = 0.00382919
Iteration 5955, loss = 0.00382821
Iteration 5956, loss = 0.00382728
Iteration 5957, loss = 0.00382637
Iteration 5958, loss = 0.00382547
Iteration 5959, loss = 0.00382458
Iteration 5960, loss = 0.00382365
Iteration 5961, loss = 0.00382280
Iteration 5962, loss = 0.00382205
Iteration 5963, loss = 0.00382130
Iteration 5964, loss = 0.00382017
Iteration 5965, loss = 0.00381932
Iteration 5966, loss = 0.00381825
Iteration 5967, loss = 0.00381747
Iteration 5968, loss = 0.00381629
Iteration 5969, loss = 0.00381529
Iteration 5970, loss = 0.00381455
Iteration 5971, loss = 0.00381379
Iteration 5972, loss = 0.00381262
Iteration 5973, loss = 0.00381191
Iteration 5974, loss = 0.00381120
Iteration 5975, loss = 0.00381011
Iteration 5976, loss = 0.00380931
Iteration 5977, loss = 0.00380828
Iteration 5978, loss = 0.00380747
Iteration 5979, loss = 0.00380634
Iteration 5980, loss = 0.00380582
Iteration 5981, loss = 0.00380462
Iteration 5982, loss = 0.00380374
Iteration 5983, loss = 0.00380268
Iteration 5984, loss = 0.00380180
Iteration 5985, loss = 0.00380100
Iteration 5986, loss = 0.00379990
Iteration 5987, loss = 0.00379909
Iteration 5988, loss = 0.00379803
Iteration 5989, loss = 0.00379711
Iteration 5990, loss = 0.00379644
Iteration 5991, loss = 0.00379532
Iteration 5992, loss = 0.00379426
Iteration 5993, loss = 0.00379344
Iteration 5994, loss = 0.00379237
Iteration 5995, loss = 0.00379135
Iteration 5996, loss = 0.00379058
Iteration 5997, loss = 0.00378957
Iteration 5998, loss = 0.00378858
Iteration 5999, loss = 0.00378803
Iteration 6000, loss = 0.00378707
Iteration 6001, loss = 0.00378597
Iteration 6002, loss = 0.00378505
Iteration 6003, loss = 0.00378435
Iteration 6004, loss = 0.00378333
Iteration 6005, loss = 0.00378255
Iteration 6006, loss = 0.00378174
Iteration 6007, loss = 0.00378091
Iteration 6008, loss = 0.00378007
Iteration 6009, loss = 0.00377923
Iteration 6010, loss = 0.00377859
Iteration 6011, loss = 0.00377766
Iteration 6012, loss = 0.00377739
Iteration 6013, loss = 0.00377594
Iteration 6014, loss = 0.00377511
Iteration 6015, loss = 0.00377422
Iteration 6016, loss = 0.00377334
Iteration 6017, loss = 0.00377238
Iteration 6018, loss = 0.00377158
Iteration 6019, loss = 0.00377050
Iteration 6020, loss = 0.00376949
Iteration 6021, loss = 0.00376855
Iteration 6022, loss = 0.00376757
Iteration 6023, loss = 0.00376668
Iteration 6024, loss = 0.00376636
Iteration 6025, loss = 0.00376531
Iteration 6026, loss = 0.00376445
Iteration 6027, loss = 0.00376358
Iteration 6028, loss = 0.00376265
Iteration 6029, loss = 0.00376186
Iteration 6030, loss = 0.00376105
Iteration 6031, loss = 0.00376016
Iteration 6032, loss = 0.00375939
Iteration 6033, loss = 0.00375856
Iteration 6034, loss = 0.00375790
Iteration 6035, loss = 0.00375684
Iteration 6036, loss = 0.00375600
Iteration 6037, loss = 0.00375513
Iteration 6038, loss = 0.00375435
Iteration 6039, loss = 0.00375338
Iteration 6040, loss = 0.00375252
Iteration 6041, loss = 0.00375201
Iteration 6042, loss = 0.00375085
Iteration 6043, loss = 0.00374984
Iteration 6044, loss = 0.00374907
Iteration 6045, loss = 0.00374840
Iteration 6046, loss = 0.00374714
Iteration 6047, loss = 0.00374609
Iteration 6048, loss = 0.00374517
Iteration 6049, loss = 0.00374421
Iteration 6050, loss = 0.00374332
Iteration 6051, loss = 0.00374253
Iteration 6052, loss = 0.00374155
Iteration 6053, loss = 0.00374058
Iteration 6054, loss = 0.00373956
Iteration 6055, loss = 0.00373937
Iteration 6056, loss = 0.00373775
Iteration 6057, loss = 0.00373698
Iteration 6058, loss = 0.00373633
Iteration 6059, loss = 0.00373553
Iteration 6060, loss = 0.00373435
Iteration 6061, loss = 0.00373354
Iteration 6062, loss = 0.00373273
Iteration 6063, loss = 0.00373205
Iteration 6064, loss = 0.00373089
Iteration 6065, loss = 0.00373028
Iteration 6066, loss = 0.00372944
Iteration 6067, loss = 0.00372844
Iteration 6068, loss = 0.00372760
Iteration 6069, loss = 0.00372682
Iteration 6070, loss = 0.00372612
Iteration 6071, loss = 0.00372515
Iteration 6072, loss = 0.00372441
Iteration 6073, loss = 0.00372354
Iteration 6074, loss = 0.00372274
Iteration 6075, loss = 0.00372188
Iteration 6076, loss = 0.00372089
Iteration 6077, loss = 0.00372005
Iteration 6078, loss = 0.00371921
Iteration 6079, loss = 0.00371853
Iteration 6080, loss = 0.00371739
Iteration 6081, loss = 0.00371636
Iteration 6082, loss = 0.00371567
Iteration 6083, loss = 0.00371458
Iteration 6084, loss = 0.00371362
Iteration 6085, loss = 0.00371276
Iteration 6086, loss = 0.00371183
Iteration 6087, loss = 0.00371101
Iteration 6088, loss = 0.00371012
Iteration 6089, loss = 0.00370917
Iteration 6090, loss = 0.00370822
Iteration 6091, loss = 0.00370751
Iteration 6092, loss = 0.00370645
Iteration 6093, loss = 0.00370558
Iteration 6094, loss = 0.00370466
Iteration 6095, loss = 0.00370426
Iteration 6096, loss = 0.00370306
Iteration 6097, loss = 0.00370211
Iteration 6098, loss = 0.00370102
Iteration 6099, loss = 0.00370035
Iteration 6100, loss = 0.00369927
Iteration 6101, loss = 0.00369860
Iteration 6102, loss = 0.00369758
Iteration 6103, loss = 0.00369690
Iteration 6104, loss = 0.00369577
Iteration 6105, loss = 0.00369493
Iteration 6106, loss = 0.00369406
Iteration 6107, loss = 0.00369322
Iteration 6108, loss = 0.00369263
Iteration 6109, loss = 0.00369166
Iteration 6110, loss = 0.00369091
Iteration 6111, loss = 0.00369014
Iteration 6112, loss = 0.00368924
Iteration 6113, loss = 0.00368851
Iteration 6114, loss = 0.00368767
Iteration 6115, loss = 0.00368695
Iteration 6116, loss = 0.00368625
Iteration 6117, loss = 0.00368547
Iteration 6118, loss = 0.00368458
Iteration 6119, loss = 0.00368386
Iteration 6120, loss = 0.00368312
Iteration 6121, loss = 0.00368266
Iteration 6122, loss = 0.00368162
Iteration 6123, loss = 0.00368081
Iteration 6124, loss = 0.00368002
Iteration 6125, loss = 0.00367935
Iteration 6126, loss = 0.00367848
Iteration 6127, loss = 0.00367766
Iteration 6128, loss = 0.00367684
Iteration 6129, loss = 0.00367594
Iteration 6130, loss = 0.00367534
Iteration 6131, loss = 0.00367498
Iteration 6132, loss = 0.00367364
Iteration 6133, loss = 0.00367295
Iteration 6134, loss = 0.00367207
Iteration 6135, loss = 0.00367101
Iteration 6136, loss = 0.00367032
Iteration 6137, loss = 0.00366947
Iteration 6138, loss = 0.00366864
Iteration 6139, loss = 0.00366774
Iteration 6140, loss = 0.00366692
Iteration 6141, loss = 0.00366613
Iteration 6142, loss = 0.00366521
Iteration 6143, loss = 0.00366476
Iteration 6144, loss = 0.00366337
Iteration 6145, loss = 0.00366254
Iteration 6146, loss = 0.00366202
Iteration 6147, loss = 0.00366087
Iteration 6148, loss = 0.00366006
Iteration 6149, loss = 0.00365923
Iteration 6150, loss = 0.00365833
Iteration 6151, loss = 0.00365744
Iteration 6152, loss = 0.00365666
Iteration 6153, loss = 0.00365576
Iteration 6154, loss = 0.00365494
Iteration 6155, loss = 0.00365414
Iteration 6156, loss = 0.00365315
Iteration 6157, loss = 0.00365231
Iteration 6158, loss = 0.00365124
Iteration 6159, loss = 0.00365065
Iteration 6160, loss = 0.00364976
Iteration 6161, loss = 0.00364863
Iteration 6162, loss = 0.00364762
Iteration 6163, loss = 0.00364654
Iteration 6164, loss = 0.00364664
Iteration 6165, loss = 0.00364496
Iteration 6166, loss = 0.00364411
Iteration 6167, loss = 0.00364337
Iteration 6168, loss = 0.00364274
Iteration 6169, loss = 0.00364177
Iteration 6170, loss = 0.00364073
Iteration 6171, loss = 0.00363972
Iteration 6172, loss = 0.00363922
Iteration 6173, loss = 0.00363797
Iteration 6174, loss = 0.00363711
Iteration 6175, loss = 0.00363610
Iteration 6176, loss = 0.00363548
Iteration 6177, loss = 0.00363438
Iteration 6178, loss = 0.00363349
Iteration 6179, loss = 0.00363267
Iteration 6180, loss = 0.00363190
Iteration 6181, loss = 0.00363120
Iteration 6182, loss = 0.00363022
Iteration 6183, loss = 0.00362940
Iteration 6184, loss = 0.00362851
Iteration 6185, loss = 0.00362760
Iteration 6186, loss = 0.00362674
Iteration 6187, loss = 0.00362597
Iteration 6188, loss = 0.00362533
Iteration 6189, loss = 0.00362444
Iteration 6190, loss = 0.00362368
Iteration 6191, loss = 0.00362307
Iteration 6192, loss = 0.00362233
Iteration 6193, loss = 0.00362173
Iteration 6194, loss = 0.00362092
Iteration 6195, loss = 0.00362011
Iteration 6196, loss = 0.00361945
Iteration 6197, loss = 0.00361858
Iteration 6198, loss = 0.00361779
Iteration 6199, loss = 0.00361710
Iteration 6200, loss = 0.00361654
Iteration 6201, loss = 0.00361584
Iteration 6202, loss = 0.00361491
Iteration 6203, loss = 0.00361396
Iteration 6204, loss = 0.00361320
Iteration 6205, loss = 0.00361230
Iteration 6206, loss = 0.00361145
Iteration 6207, loss = 0.00361072
Iteration 6208, loss = 0.00360990
Iteration 6209, loss = 0.00360919
Iteration 6210, loss = 0.00360847
Iteration 6211, loss = 0.00360779
Iteration 6212, loss = 0.00360736
Iteration 6213, loss = 0.00360651
Iteration 6214, loss = 0.00360569
Iteration 6215, loss = 0.00360496
Iteration 6216, loss = 0.00360420
Iteration 6217, loss = 0.00360346
Iteration 6218, loss = 0.00360271
Iteration 6219, loss = 0.00360190
Iteration 6220, loss = 0.00360133
Iteration 6221, loss = 0.00360057
Iteration 6222, loss = 0.00359962
Iteration 6223, loss = 0.00359878
Iteration 6224, loss = 0.00359806
Iteration 6225, loss = 0.00359717
Iteration 6226, loss = 0.00359621
Iteration 6227, loss = 0.00359575
Iteration 6228, loss = 0.00359448
Iteration 6229, loss = 0.00359388
Iteration 6230, loss = 0.00359284
Iteration 6231, loss = 0.00359198
Iteration 6232, loss = 0.00359113
Iteration 6233, loss = 0.00359022
Iteration 6234, loss = 0.00358934
Iteration 6235, loss = 0.00358835
Iteration 6236, loss = 0.00358775
Iteration 6237, loss = 0.00358673
Iteration 6238, loss = 0.00358587
Iteration 6239, loss = 0.00358504
Iteration 6240, loss = 0.00358414
Iteration 6241, loss = 0.00358338
Iteration 6242, loss = 0.00358269
Iteration 6243, loss = 0.00358191
Iteration 6244, loss = 0.00358119
Iteration 6245, loss = 0.00358062
Iteration 6246, loss = 0.00357983
Iteration 6247, loss = 0.00357901
Iteration 6248, loss = 0.00357842
Iteration 6249, loss = 0.00357771
Iteration 6250, loss = 0.00357685
Iteration 6251, loss = 0.00357605
Iteration 6252, loss = 0.00357534
Iteration 6253, loss = 0.00357452
Iteration 6254, loss = 0.00357360
Iteration 6255, loss = 0.00357287
Iteration 6256, loss = 0.00357189
Iteration 6257, loss = 0.00357158
Iteration 6258, loss = 0.00357037
Iteration 6259, loss = 0.00356947
Iteration 6260, loss = 0.00356869
Iteration 6261, loss = 0.00356775
Iteration 6262, loss = 0.00356683
Iteration 6263, loss = 0.00356585
Iteration 6264, loss = 0.00356529
Iteration 6265, loss = 0.00356429
Iteration 6266, loss = 0.00356345
Iteration 6267, loss = 0.00356248
Iteration 6268, loss = 0.00356169
Iteration 6269, loss = 0.00356086
Iteration 6270, loss = 0.00355995
Iteration 6271, loss = 0.00355911
Iteration 6272, loss = 0.00355828
Iteration 6273, loss = 0.00355757
Iteration 6274, loss = 0.00355655
Iteration 6275, loss = 0.00355569
Iteration 6276, loss = 0.00355484
Iteration 6277, loss = 0.00355382
Iteration 6278, loss = 0.00355300
Iteration 6279, loss = 0.00355231
Iteration 6280, loss = 0.00355130
Iteration 6281, loss = 0.00355058
Iteration 6282, loss = 0.00354968
Iteration 6283, loss = 0.00354896
Iteration 6284, loss = 0.00354830
Iteration 6285, loss = 0.00354740
Iteration 6286, loss = 0.00354664
Iteration 6287, loss = 0.00354630
Iteration 6288, loss = 0.00354524
Iteration 6289, loss = 0.00354443
Iteration 6290, loss = 0.00354343
Iteration 6291, loss = 0.00354249
Iteration 6292, loss = 0.00354168
Iteration 6293, loss = 0.00354141
Iteration 6294, loss = 0.00354025
Iteration 6295, loss = 0.00353940
Iteration 6296, loss = 0.00353875
Iteration 6297, loss = 0.00353800
Iteration 6298, loss = 0.00353698
Iteration 6299, loss = 0.00353659
Iteration 6300, loss = 0.00353557
Iteration 6301, loss = 0.00353459
Iteration 6302, loss = 0.00353393
Iteration 6303, loss = 0.00353310
Iteration 6304, loss = 0.00353198
Iteration 6305, loss = 0.00353147
Iteration 6306, loss = 0.00353033
Iteration 6307, loss = 0.00352986
Iteration 6308, loss = 0.00352873
Iteration 6309, loss = 0.00352792
Iteration 6310, loss = 0.00352726
Iteration 6311, loss = 0.00352647
Iteration 6312, loss = 0.00352552
Iteration 6313, loss = 0.00352505
Iteration 6314, loss = 0.00352399
Iteration 6315, loss = 0.00352340
Iteration 6316, loss = 0.00352232
Iteration 6317, loss = 0.00352159
Iteration 6318, loss = 0.00352078
Iteration 6319, loss = 0.00352004
Iteration 6320, loss = 0.00351915
Iteration 6321, loss = 0.00351835
Iteration 6322, loss = 0.00351755
Iteration 6323, loss = 0.00351676
Iteration 6324, loss = 0.00351586
Iteration 6325, loss = 0.00351529
Iteration 6326, loss = 0.00351419
Iteration 6327, loss = 0.00351340
Iteration 6328, loss = 0.00351259
Iteration 6329, loss = 0.00351180
Iteration 6330, loss = 0.00351116
Iteration 6331, loss = 0.00351007
Iteration 6332, loss = 0.00350924
Iteration 6333, loss = 0.00350848
Iteration 6334, loss = 0.00350768
Iteration 6335, loss = 0.00350687
Iteration 6336, loss = 0.00350614
Iteration 6337, loss = 0.00350541
Iteration 6338, loss = 0.00350466
Iteration 6339, loss = 0.00350398
Iteration 6340, loss = 0.00350319
Iteration 6341, loss = 0.00350249
Iteration 6342, loss = 0.00350184
Iteration 6343, loss = 0.00350104
Iteration 6344, loss = 0.00350029
Iteration 6345, loss = 0.00349942
Iteration 6346, loss = 0.00349905
Iteration 6347, loss = 0.00349790
Iteration 6348, loss = 0.00349713
Iteration 6349, loss = 0.00349643
Iteration 6350, loss = 0.00349599
Iteration 6351, loss = 0.00349505
Iteration 6352, loss = 0.00349426
Iteration 6353, loss = 0.00349348
Iteration 6354, loss = 0.00349279
Iteration 6355, loss = 0.00349204
Iteration 6356, loss = 0.00349133
Iteration 6357, loss = 0.00349048
Iteration 6358, loss = 0.00348967
Iteration 6359, loss = 0.00348888
Iteration 6360, loss = 0.00348801
Iteration 6361, loss = 0.00348729
Iteration 6362, loss = 0.00348651
Iteration 6363, loss = 0.00348578
Iteration 6364, loss = 0.00348498
Iteration 6365, loss = 0.00348460
Iteration 6366, loss = 0.00348327
Iteration 6367, loss = 0.00348255
Iteration 6368, loss = 0.00348162
Iteration 6369, loss = 0.00348081
Iteration 6370, loss = 0.00348047
Iteration 6371, loss = 0.00347992
Iteration 6372, loss = 0.00347878
Iteration 6373, loss = 0.00347817
Iteration 6374, loss = 0.00347751
Iteration 6375, loss = 0.00347696
Iteration 6376, loss = 0.00347598
Iteration 6377, loss = 0.00347530
Iteration 6378, loss = 0.00347441
Iteration 6379, loss = 0.00347362
Iteration 6380, loss = 0.00347278
Iteration 6381, loss = 0.00347211
Iteration 6382, loss = 0.00347126
Iteration 6383, loss = 0.00347044
Iteration 6384, loss = 0.00346970
Iteration 6385, loss = 0.00346893
Iteration 6386, loss = 0.00346836
Iteration 6387, loss = 0.00346735
Iteration 6388, loss = 0.00346661
Iteration 6389, loss = 0.00346566
Iteration 6390, loss = 0.00346496
Iteration 6391, loss = 0.00346407
Iteration 6392, loss = 0.00346334
Iteration 6393, loss = 0.00346239
Iteration 6394, loss = 0.00346155
Iteration 6395, loss = 0.00346084
Iteration 6396, loss = 0.00346006
Iteration 6397, loss = 0.00345916
Iteration 6398, loss = 0.00345874
Iteration 6399, loss = 0.00345789
Iteration 6400, loss = 0.00345715
Iteration 6401, loss = 0.00345642
Iteration 6402, loss = 0.00345568
Iteration 6403, loss = 0.00345490
Iteration 6404, loss = 0.00345419
Iteration 6405, loss = 0.00345372
Iteration 6406, loss = 0.00345296
Iteration 6407, loss = 0.00345227
Iteration 6408, loss = 0.00345162
Iteration 6409, loss = 0.00345103
Iteration 6410, loss = 0.00345046
Iteration 6411, loss = 0.00344966
Iteration 6412, loss = 0.00344895
Iteration 6413, loss = 0.00344829
Iteration 6414, loss = 0.00344761
Iteration 6415, loss = 0.00344727
Iteration 6416, loss = 0.00344647
Iteration 6417, loss = 0.00344572
Iteration 6418, loss = 0.00344494
Iteration 6419, loss = 0.00344464
Iteration 6420, loss = 0.00344364
Iteration 6421, loss = 0.00344288
Iteration 6422, loss = 0.00344202
Iteration 6423, loss = 0.00344123
Iteration 6424, loss = 0.00344043
Iteration 6425, loss = 0.00343957
Iteration 6426, loss = 0.00343891
Iteration 6427, loss = 0.00343801
Iteration 6428, loss = 0.00343713
Iteration 6429, loss = 0.00343664
Iteration 6430, loss = 0.00343579
Iteration 6431, loss = 0.00343512
Iteration 6432, loss = 0.00343422
Iteration 6433, loss = 0.00343324
Iteration 6434, loss = 0.00343258
Iteration 6435, loss = 0.00343182
Iteration 6436, loss = 0.00343121
Iteration 6437, loss = 0.00342987
Iteration 6438, loss = 0.00342908
Iteration 6439, loss = 0.00342798
Iteration 6440, loss = 0.00342719
Iteration 6441, loss = 0.00342648
Iteration 6442, loss = 0.00342555
Iteration 6443, loss = 0.00342451
Iteration 6444, loss = 0.00342364
Iteration 6445, loss = 0.00342265
Iteration 6446, loss = 0.00342256
Iteration 6447, loss = 0.00342135
Iteration 6448, loss = 0.00342038
Iteration 6449, loss = 0.00341993
Iteration 6450, loss = 0.00341900
Iteration 6451, loss = 0.00341817
Iteration 6452, loss = 0.00341746
Iteration 6453, loss = 0.00341675
Iteration 6454, loss = 0.00341607
Iteration 6455, loss = 0.00341543
Iteration 6456, loss = 0.00341486
Iteration 6457, loss = 0.00341412
Iteration 6458, loss = 0.00341350
Iteration 6459, loss = 0.00341288
Iteration 6460, loss = 0.00341216
Iteration 6461, loss = 0.00341160
Iteration 6462, loss = 0.00341081
Iteration 6463, loss = 0.00341005
Iteration 6464, loss = 0.00340932
Iteration 6465, loss = 0.00340873
Iteration 6466, loss = 0.00340790
Iteration 6467, loss = 0.00340794
Iteration 6468, loss = 0.00340660
Iteration 6469, loss = 0.00340591
Iteration 6470, loss = 0.00340517
Iteration 6471, loss = 0.00340449
Iteration 6472, loss = 0.00340371
Iteration 6473, loss = 0.00340327
Iteration 6474, loss = 0.00340220
Iteration 6475, loss = 0.00340162
Iteration 6476, loss = 0.00340098
Iteration 6477, loss = 0.00340021
Iteration 6478, loss = 0.00339949
Iteration 6479, loss = 0.00339874
Iteration 6480, loss = 0.00339795
Iteration 6481, loss = 0.00339717
Iteration 6482, loss = 0.00339664
Iteration 6483, loss = 0.00339596
Iteration 6484, loss = 0.00339550
Iteration 6485, loss = 0.00339458
Iteration 6486, loss = 0.00339391
Iteration 6487, loss = 0.00339319
Iteration 6488, loss = 0.00339238
Iteration 6489, loss = 0.00339191
Iteration 6490, loss = 0.00339093
Iteration 6491, loss = 0.00339005
Iteration 6492, loss = 0.00338918
Iteration 6493, loss = 0.00338833
Iteration 6494, loss = 0.00338794
Iteration 6495, loss = 0.00338696
Iteration 6496, loss = 0.00338610
Iteration 6497, loss = 0.00338574
Iteration 6498, loss = 0.00338480
Iteration 6499, loss = 0.00338389
Iteration 6500, loss = 0.00338298
Iteration 6501, loss = 0.00338270
Iteration 6502, loss = 0.00338173
Iteration 6503, loss = 0.00338102
Iteration 6504, loss = 0.00338028
Iteration 6505, loss = 0.00337961
Iteration 6506, loss = 0.00337887
Iteration 6507, loss = 0.00337834
Iteration 6508, loss = 0.00337769
Iteration 6509, loss = 0.00337686
Iteration 6510, loss = 0.00337611
Iteration 6511, loss = 0.00337563
Iteration 6512, loss = 0.00337481
Iteration 6513, loss = 0.00337422
Iteration 6514, loss = 0.00337354
Iteration 6515, loss = 0.00337286
Iteration 6516, loss = 0.00337223
Iteration 6517, loss = 0.00337158
Iteration 6518, loss = 0.00337081
Iteration 6519, loss = 0.00337018
Iteration 6520, loss = 0.00336948
Iteration 6521, loss = 0.00336867
Iteration 6522, loss = 0.00336813
Iteration 6523, loss = 0.00336739
Iteration 6524, loss = 0.00336643
Iteration 6525, loss = 0.00336565
Iteration 6526, loss = 0.00336499
Iteration 6527, loss = 0.00336414
Iteration 6528, loss = 0.00336351
Iteration 6529, loss = 0.00336272
Iteration 6530, loss = 0.00336233
Iteration 6531, loss = 0.00336130
Iteration 6532, loss = 0.00336046
Iteration 6533, loss = 0.00335974
Iteration 6534, loss = 0.00335896
Iteration 6535, loss = 0.00335824
Iteration 6536, loss = 0.00335769
Iteration 6537, loss = 0.00335692
Iteration 6538, loss = 0.00335608
Iteration 6539, loss = 0.00335532
Iteration 6540, loss = 0.00335463
Iteration 6541, loss = 0.00335395
Iteration 6542, loss = 0.00335335
Iteration 6543, loss = 0.00335256
Iteration 6544, loss = 0.00335186
Iteration 6545, loss = 0.00335113
Iteration 6546, loss = 0.00335058
Iteration 6547, loss = 0.00334966
Iteration 6548, loss = 0.00334893
Iteration 6549, loss = 0.00334819
Iteration 6550, loss = 0.00334745
Iteration 6551, loss = 0.00334672
Iteration 6552, loss = 0.00334599
Iteration 6553, loss = 0.00334513
Iteration 6554, loss = 0.00334432
Iteration 6555, loss = 0.00334356
Iteration 6556, loss = 0.00334315
Iteration 6557, loss = 0.00334206
Iteration 6558, loss = 0.00334137
Iteration 6559, loss = 0.00334079
Iteration 6560, loss = 0.00333992
Iteration 6561, loss = 0.00333913
Iteration 6562, loss = 0.00333849
Iteration 6563, loss = 0.00333763
Iteration 6564, loss = 0.00333754
Iteration 6565, loss = 0.00333633
Iteration 6566, loss = 0.00333557
Iteration 6567, loss = 0.00333501
Iteration 6568, loss = 0.00333412
Iteration 6569, loss = 0.00333342
Iteration 6570, loss = 0.00333273
Iteration 6571, loss = 0.00333203
Iteration 6572, loss = 0.00333143
Iteration 6573, loss = 0.00333075
Iteration 6574, loss = 0.00332995
Iteration 6575, loss = 0.00332926
Iteration 6576, loss = 0.00332853
Iteration 6577, loss = 0.00332816
Iteration 6578, loss = 0.00332717
Iteration 6579, loss = 0.00332649
Iteration 6580, loss = 0.00332579
Iteration 6581, loss = 0.00332510
Iteration 6582, loss = 0.00332439
Iteration 6583, loss = 0.00332380
Iteration 6584, loss = 0.00332310
Iteration 6585, loss = 0.00332233
Iteration 6586, loss = 0.00332155
Iteration 6587, loss = 0.00332085
Iteration 6588, loss = 0.00332032
Iteration 6589, loss = 0.00331951
Iteration 6590, loss = 0.00331877
Iteration 6591, loss = 0.00331818
Iteration 6592, loss = 0.00331736
Iteration 6593, loss = 0.00331686
Iteration 6594, loss = 0.00331609
Iteration 6595, loss = 0.00331530
Iteration 6596, loss = 0.00331469
Iteration 6597, loss = 0.00331413
Iteration 6598, loss = 0.00331342
Iteration 6599, loss = 0.00331235
Iteration 6600, loss = 0.00331183
Iteration 6601, loss = 0.00331094
Iteration 6602, loss = 0.00331011
Iteration 6603, loss = 0.00330922
Iteration 6604, loss = 0.00330850
Iteration 6605, loss = 0.00330779
Iteration 6606, loss = 0.00330705
Iteration 6607, loss = 0.00330650
Iteration 6608, loss = 0.00330571
Iteration 6609, loss = 0.00330517
Iteration 6610, loss = 0.00330433
Iteration 6611, loss = 0.00330367
Iteration 6612, loss = 0.00330320
Iteration 6613, loss = 0.00330226
Iteration 6614, loss = 0.00330161
Iteration 6615, loss = 0.00330083
Iteration 6616, loss = 0.00330006
Iteration 6617, loss = 0.00329938
Iteration 6618, loss = 0.00329871
Iteration 6619, loss = 0.00329818
Iteration 6620, loss = 0.00329720
Iteration 6621, loss = 0.00329657
Iteration 6622, loss = 0.00329576
Iteration 6623, loss = 0.00329506
Iteration 6624, loss = 0.00329427
Iteration 6625, loss = 0.00329347
Iteration 6626, loss = 0.00329291
Iteration 6627, loss = 0.00329219
Iteration 6628, loss = 0.00329139
Iteration 6629, loss = 0.00329065
Iteration 6630, loss = 0.00329000
Iteration 6631, loss = 0.00328924
Iteration 6632, loss = 0.00328898
Iteration 6633, loss = 0.00328779
Iteration 6634, loss = 0.00328700
Iteration 6635, loss = 0.00328643
Iteration 6636, loss = 0.00328561
Iteration 6637, loss = 0.00328520
Iteration 6638, loss = 0.00328427
Iteration 6639, loss = 0.00328357
Iteration 6640, loss = 0.00328277
Iteration 6641, loss = 0.00328213
Iteration 6642, loss = 0.00328152
Iteration 6643, loss = 0.00328072
Iteration 6644, loss = 0.00328016
Iteration 6645, loss = 0.00327959
Iteration 6646, loss = 0.00327878
Iteration 6647, loss = 0.00327810
Iteration 6648, loss = 0.00327757
Iteration 6649, loss = 0.00327679
Iteration 6650, loss = 0.00327612
Iteration 6651, loss = 0.00327554
Iteration 6652, loss = 0.00327486
Iteration 6653, loss = 0.00327415
Iteration 6654, loss = 0.00327350
Iteration 6655, loss = 0.00327271
Iteration 6656, loss = 0.00327207
Iteration 6657, loss = 0.00327162
Iteration 6658, loss = 0.00327081
Iteration 6659, loss = 0.00327007
Iteration 6660, loss = 0.00326939
Iteration 6661, loss = 0.00326871
Iteration 6662, loss = 0.00326794
Iteration 6663, loss = 0.00326728
Iteration 6664, loss = 0.00326656
Iteration 6665, loss = 0.00326593
Iteration 6666, loss = 0.00326507
Iteration 6667, loss = 0.00326448
Iteration 6668, loss = 0.00326376
Iteration 6669, loss = 0.00326314
Iteration 6670, loss = 0.00326238
Iteration 6671, loss = 0.00326171
Iteration 6672, loss = 0.00326105
Iteration 6673, loss = 0.00326034
Iteration 6674, loss = 0.00325971
Iteration 6675, loss = 0.00325903
Iteration 6676, loss = 0.00325831
Iteration 6677, loss = 0.00325757
Iteration 6678, loss = 0.00325705
Iteration 6679, loss = 0.00325625
Iteration 6680, loss = 0.00325554
Iteration 6681, loss = 0.00325492
Iteration 6682, loss = 0.00325411
Iteration 6683, loss = 0.00325345
Iteration 6684, loss = 0.00325280
Iteration 6685, loss = 0.00325213
Iteration 6686, loss = 0.00325147
Iteration 6687, loss = 0.00325120
Iteration 6688, loss = 0.00325018
Iteration 6689, loss = 0.00324961
Iteration 6690, loss = 0.00324895
Iteration 6691, loss = 0.00324825
Iteration 6692, loss = 0.00324776
Iteration 6693, loss = 0.00324707
Iteration 6694, loss = 0.00324641
Iteration 6695, loss = 0.00324571
Iteration 6696, loss = 0.00324509
Iteration 6697, loss = 0.00324450
Iteration 6698, loss = 0.00324382
Iteration 6699, loss = 0.00324333
Iteration 6700, loss = 0.00324242
Iteration 6701, loss = 0.00324166
Iteration 6702, loss = 0.00324103
Iteration 6703, loss = 0.00324028
Iteration 6704, loss = 0.00323962
Iteration 6705, loss = 0.00323885
Iteration 6706, loss = 0.00323812
Iteration 6707, loss = 0.00323748
Iteration 6708, loss = 0.00323673
Iteration 6709, loss = 0.00323606
Iteration 6710, loss = 0.00323532
Iteration 6711, loss = 0.00323491
Iteration 6712, loss = 0.00323390
Iteration 6713, loss = 0.00323318
Iteration 6714, loss = 0.00323254
Iteration 6715, loss = 0.00323191
Iteration 6716, loss = 0.00323131
Iteration 6717, loss = 0.00323057
Iteration 6718, loss = 0.00322993
Iteration 6719, loss = 0.00322926
Iteration 6720, loss = 0.00322867
Iteration 6721, loss = 0.00322787
Iteration 6722, loss = 0.00322718
Iteration 6723, loss = 0.00322655
Iteration 6724, loss = 0.00322576
Iteration 6725, loss = 0.00322512
Iteration 6726, loss = 0.00322441
Iteration 6727, loss = 0.00322376
Iteration 6728, loss = 0.00322300
Iteration 6729, loss = 0.00322265
Iteration 6730, loss = 0.00322166
Iteration 6731, loss = 0.00322117
Iteration 6732, loss = 0.00322037
Iteration 6733, loss = 0.00321971
Iteration 6734, loss = 0.00321884
Iteration 6735, loss = 0.00321819
Iteration 6736, loss = 0.00321738
Iteration 6737, loss = 0.00321685
Iteration 6738, loss = 0.00321605
Iteration 6739, loss = 0.00321536
Iteration 6740, loss = 0.00321470
Iteration 6741, loss = 0.00321401
Iteration 6742, loss = 0.00321333
Iteration 6743, loss = 0.00321271
Iteration 6744, loss = 0.00321207
Iteration 6745, loss = 0.00321137
Iteration 6746, loss = 0.00321084
Iteration 6747, loss = 0.00321016
Iteration 6748, loss = 0.00320958
Iteration 6749, loss = 0.00320931
Iteration 6750, loss = 0.00320805
Iteration 6751, loss = 0.00320720
Iteration 6752, loss = 0.00320679
Iteration 6753, loss = 0.00320608
Iteration 6754, loss = 0.00320521
Iteration 6755, loss = 0.00320454
Iteration 6756, loss = 0.00320397
Iteration 6757, loss = 0.00320325
Iteration 6758, loss = 0.00320264
Iteration 6759, loss = 0.00320199
Iteration 6760, loss = 0.00320136
Iteration 6761, loss = 0.00320077
Iteration 6762, loss = 0.00320014
Iteration 6763, loss = 0.00319958
Iteration 6764, loss = 0.00319875
Iteration 6765, loss = 0.00319820
Iteration 6766, loss = 0.00319751
Iteration 6767, loss = 0.00319688
Iteration 6768, loss = 0.00319612
Iteration 6769, loss = 0.00319564
Iteration 6770, loss = 0.00319491
Iteration 6771, loss = 0.00319456
Iteration 6772, loss = 0.00319364
Iteration 6773, loss = 0.00319295
Iteration 6774, loss = 0.00319231
Iteration 6775, loss = 0.00319166
Iteration 6776, loss = 0.00319102
Iteration 6777, loss = 0.00319032
Iteration 6778, loss = 0.00318972
Iteration 6779, loss = 0.00318906
Iteration 6780, loss = 0.00318839
Iteration 6781, loss = 0.00318778
Iteration 6782, loss = 0.00318709
Iteration 6783, loss = 0.00318641
Iteration 6784, loss = 0.00318593
Iteration 6785, loss = 0.00318538
Iteration 6786, loss = 0.00318456
Iteration 6787, loss = 0.00318387
Iteration 6788, loss = 0.00318359
Iteration 6789, loss = 0.00318272
Iteration 6790, loss = 0.00318227
Iteration 6791, loss = 0.00318120
Iteration 6792, loss = 0.00318059
Iteration 6793, loss = 0.00317995
Iteration 6794, loss = 0.00317955
Iteration 6795, loss = 0.00317869
Iteration 6796, loss = 0.00317796
Iteration 6797, loss = 0.00317732
Iteration 6798, loss = 0.00317674
Iteration 6799, loss = 0.00317607
Iteration 6800, loss = 0.00317541
Iteration 6801, loss = 0.00317477
Iteration 6802, loss = 0.00317413
Iteration 6803, loss = 0.00317342
Iteration 6804, loss = 0.00317278
Iteration 6805, loss = 0.00317222
Iteration 6806, loss = 0.00317169
Iteration 6807, loss = 0.00317095
Iteration 6808, loss = 0.00317049
Iteration 6809, loss = 0.00316984
Iteration 6810, loss = 0.00316901
Iteration 6811, loss = 0.00316846
Iteration 6812, loss = 0.00316784
Iteration 6813, loss = 0.00316705
Iteration 6814, loss = 0.00316642
Iteration 6815, loss = 0.00316569
Iteration 6816, loss = 0.00316500
Iteration 6817, loss = 0.00316438
Iteration 6818, loss = 0.00316360
Iteration 6819, loss = 0.00316302
Iteration 6820, loss = 0.00316244
Iteration 6821, loss = 0.00316144
Iteration 6822, loss = 0.00316075
Iteration 6823, loss = 0.00316005
Iteration 6824, loss = 0.00315948
Iteration 6825, loss = 0.00315882
Iteration 6826, loss = 0.00315811
Iteration 6827, loss = 0.00315736
Iteration 6828, loss = 0.00315669
Iteration 6829, loss = 0.00315595
Iteration 6830, loss = 0.00315515
Iteration 6831, loss = 0.00315493
Iteration 6832, loss = 0.00315388
Iteration 6833, loss = 0.00315303
Iteration 6834, loss = 0.00315230
Iteration 6835, loss = 0.00315145
Iteration 6836, loss = 0.00315082
Iteration 6837, loss = 0.00314999
Iteration 6838, loss = 0.00314923
Iteration 6839, loss = 0.00314856
Iteration 6840, loss = 0.00314794
Iteration 6841, loss = 0.00314740
Iteration 6842, loss = 0.00314647
Iteration 6843, loss = 0.00314572
Iteration 6844, loss = 0.00314525
Iteration 6845, loss = 0.00314429
Iteration 6846, loss = 0.00314382
Iteration 6847, loss = 0.00314282
Iteration 6848, loss = 0.00314225
Iteration 6849, loss = 0.00314146
Iteration 6850, loss = 0.00314064
Iteration 6851, loss = 0.00313999
Iteration 6852, loss = 0.00313923
Iteration 6853, loss = 0.00313856
Iteration 6854, loss = 0.00313791
Iteration 6855, loss = 0.00313720
Iteration 6856, loss = 0.00313649
Iteration 6857, loss = 0.00313579
Iteration 6858, loss = 0.00313520
Iteration 6859, loss = 0.00313449
Iteration 6860, loss = 0.00313384
Iteration 6861, loss = 0.00313313
Iteration 6862, loss = 0.00313265
Iteration 6863, loss = 0.00313183
Iteration 6864, loss = 0.00313104
Iteration 6865, loss = 0.00313033
Iteration 6866, loss = 0.00312972
Iteration 6867, loss = 0.00312900
Iteration 6868, loss = 0.00312843
Iteration 6869, loss = 0.00312783
Iteration 6870, loss = 0.00312713
Iteration 6871, loss = 0.00312653
Iteration 6872, loss = 0.00312613
Iteration 6873, loss = 0.00312536
Iteration 6874, loss = 0.00312474
Iteration 6875, loss = 0.00312424
Iteration 6876, loss = 0.00312370
Iteration 6877, loss = 0.00312308
Iteration 6878, loss = 0.00312250
Iteration 6879, loss = 0.00312193
Iteration 6880, loss = 0.00312139
Iteration 6881, loss = 0.00312104
Iteration 6882, loss = 0.00312028
Iteration 6883, loss = 0.00311973
Iteration 6884, loss = 0.00311910
Iteration 6885, loss = 0.00311855
Iteration 6886, loss = 0.00311799
Iteration 6887, loss = 0.00311747
Iteration 6888, loss = 0.00311669
Iteration 6889, loss = 0.00311609
Iteration 6890, loss = 0.00311555
Iteration 6891, loss = 0.00311474
Iteration 6892, loss = 0.00311408
Iteration 6893, loss = 0.00311358
Iteration 6894, loss = 0.00311293
Iteration 6895, loss = 0.00311218
Iteration 6896, loss = 0.00311161
Iteration 6897, loss = 0.00311112
Iteration 6898, loss = 0.00311030
Iteration 6899, loss = 0.00310966
Iteration 6900, loss = 0.00310889
Iteration 6901, loss = 0.00310825
Iteration 6902, loss = 0.00310789
Iteration 6903, loss = 0.00310725
Iteration 6904, loss = 0.00310645
Iteration 6905, loss = 0.00310570
Iteration 6906, loss = 0.00310498
Iteration 6907, loss = 0.00310454
Iteration 6908, loss = 0.00310373
Iteration 6909, loss = 0.00310313
Iteration 6910, loss = 0.00310261
Iteration 6911, loss = 0.00310183
Iteration 6912, loss = 0.00310107
Iteration 6913, loss = 0.00310045
Iteration 6914, loss = 0.00309981
Iteration 6915, loss = 0.00309926
Iteration 6916, loss = 0.00309848
Iteration 6917, loss = 0.00309806
Iteration 6918, loss = 0.00309734
Iteration 6919, loss = 0.00309658
Iteration 6920, loss = 0.00309598
Iteration 6921, loss = 0.00309533
Iteration 6922, loss = 0.00309466
Iteration 6923, loss = 0.00309396
Iteration 6924, loss = 0.00309338
Iteration 6925, loss = 0.00309270
Iteration 6926, loss = 0.00309201
Iteration 6927, loss = 0.00309134
Iteration 6928, loss = 0.00309090
Iteration 6929, loss = 0.00308998
Iteration 6930, loss = 0.00308948
Iteration 6931, loss = 0.00308872
Iteration 6932, loss = 0.00308814
Iteration 6933, loss = 0.00308753
Iteration 6934, loss = 0.00308692
Iteration 6935, loss = 0.00308634
Iteration 6936, loss = 0.00308567
Iteration 6937, loss = 0.00308508
Iteration 6938, loss = 0.00308449
Iteration 6939, loss = 0.00308386
Iteration 6940, loss = 0.00308315
Iteration 6941, loss = 0.00308264
Iteration 6942, loss = 0.00308204
Iteration 6943, loss = 0.00308156
Iteration 6944, loss = 0.00308106
Iteration 6945, loss = 0.00308038
Iteration 6946, loss = 0.00308010
Iteration 6947, loss = 0.00307929
Iteration 6948, loss = 0.00307858
Iteration 6949, loss = 0.00307798
Iteration 6950, loss = 0.00307756
Iteration 6951, loss = 0.00307686
Iteration 6952, loss = 0.00307639
Iteration 6953, loss = 0.00307574
Iteration 6954, loss = 0.00307511
Iteration 6955, loss = 0.00307454
Iteration 6956, loss = 0.00307399
Iteration 6957, loss = 0.00307338
Iteration 6958, loss = 0.00307286
Iteration 6959, loss = 0.00307231
Iteration 6960, loss = 0.00307178
Iteration 6961, loss = 0.00307119
Iteration 6962, loss = 0.00307064
Iteration 6963, loss = 0.00307005
Iteration 6964, loss = 0.00306946
Iteration 6965, loss = 0.00306893
Iteration 6966, loss = 0.00306836
Iteration 6967, loss = 0.00306773
Iteration 6968, loss = 0.00306719
Iteration 6969, loss = 0.00306710
Iteration 6970, loss = 0.00306639
Iteration 6971, loss = 0.00306565
Iteration 6972, loss = 0.00306504
Iteration 6973, loss = 0.00306445
Iteration 6974, loss = 0.00306402
Iteration 6975, loss = 0.00306330
Iteration 6976, loss = 0.00306270
Iteration 6977, loss = 0.00306209
Iteration 6978, loss = 0.00306143
Iteration 6979, loss = 0.00306077
Iteration 6980, loss = 0.00306027
Iteration 6981, loss = 0.00305949
Iteration 6982, loss = 0.00305885
Iteration 6983, loss = 0.00305843
Iteration 6984, loss = 0.00305766
Iteration 6985, loss = 0.00305704
Iteration 6986, loss = 0.00305622
Iteration 6987, loss = 0.00305578
Iteration 6988, loss = 0.00305469
Iteration 6989, loss = 0.00305403
Iteration 6990, loss = 0.00305348
Iteration 6991, loss = 0.00305270
Iteration 6992, loss = 0.00305196
Iteration 6993, loss = 0.00305137
Iteration 6994, loss = 0.00305056
Iteration 6995, loss = 0.00304999
Iteration 6996, loss = 0.00304921
Iteration 6997, loss = 0.00304863
Iteration 6998, loss = 0.00304817
Iteration 6999, loss = 0.00304736
Iteration 7000, loss = 0.00304679
Iteration 7001, loss = 0.00304621
Iteration 7002, loss = 0.00304556
Iteration 7003, loss = 0.00304489
Iteration 7004, loss = 0.00304435
Iteration 7005, loss = 0.00304381
Iteration 7006, loss = 0.00304278
Iteration 7007, loss = 0.00304247
Iteration 7008, loss = 0.00304159
Iteration 7009, loss = 0.00304120
Iteration 7010, loss = 0.00304030
Iteration 7011, loss = 0.00303991
Iteration 7012, loss = 0.00303911
Iteration 7013, loss = 0.00303860
Iteration 7014, loss = 0.00303795
Iteration 7015, loss = 0.00303737
Iteration 7016, loss = 0.00303694
Iteration 7017, loss = 0.00303636
Iteration 7018, loss = 0.00303579
Iteration 7019, loss = 0.00303523
Iteration 7020, loss = 0.00303473
Iteration 7021, loss = 0.00303419
Iteration 7022, loss = 0.00303370
Iteration 7023, loss = 0.00303314
Iteration 7024, loss = 0.00303257
Iteration 7025, loss = 0.00303208
Iteration 7026, loss = 0.00303150
Iteration 7027, loss = 0.00303097
Iteration 7028, loss = 0.00303050
Iteration 7029, loss = 0.00302994
Iteration 7030, loss = 0.00302930
Iteration 7031, loss = 0.00302855
Iteration 7032, loss = 0.00302794
Iteration 7033, loss = 0.00302755
Iteration 7034, loss = 0.00302668
Iteration 7035, loss = 0.00302618
Iteration 7036, loss = 0.00302546
Iteration 7037, loss = 0.00302489
Iteration 7038, loss = 0.00302432
Iteration 7039, loss = 0.00302378
Iteration 7040, loss = 0.00302321
Iteration 7041, loss = 0.00302249
Iteration 7042, loss = 0.00302206
Iteration 7043, loss = 0.00302139
Iteration 7044, loss = 0.00302079
Iteration 7045, loss = 0.00302023
Iteration 7046, loss = 0.00301962
Iteration 7047, loss = 0.00301911
Iteration 7048, loss = 0.00301882
Iteration 7049, loss = 0.00301798
Iteration 7050, loss = 0.00301776
Iteration 7051, loss = 0.00301682
Iteration 7052, loss = 0.00301614
Iteration 7053, loss = 0.00301556
Iteration 7054, loss = 0.00301489
Iteration 7055, loss = 0.00301452
Iteration 7056, loss = 0.00301360
Iteration 7057, loss = 0.00301296
Iteration 7058, loss = 0.00301230
Iteration 7059, loss = 0.00301165
Iteration 7060, loss = 0.00301099
Iteration 7061, loss = 0.00301042
Iteration 7062, loss = 0.00300995
Iteration 7063, loss = 0.00300913
Iteration 7064, loss = 0.00300847
Iteration 7065, loss = 0.00300780
Iteration 7066, loss = 0.00300718
Iteration 7067, loss = 0.00300666
Iteration 7068, loss = 0.00300609
Iteration 7069, loss = 0.00300538
Iteration 7070, loss = 0.00300483
Iteration 7071, loss = 0.00300453
Iteration 7072, loss = 0.00300378
Iteration 7073, loss = 0.00300314
Iteration 7074, loss = 0.00300260
Iteration 7075, loss = 0.00300200
Iteration 7076, loss = 0.00300139
Iteration 7077, loss = 0.00300107
Iteration 7078, loss = 0.00300012
Iteration 7079, loss = 0.00299955
Iteration 7080, loss = 0.00299893
Iteration 7081, loss = 0.00299833
Iteration 7082, loss = 0.00299785
Iteration 7083, loss = 0.00299716
Iteration 7084, loss = 0.00299671
Iteration 7085, loss = 0.00299604
Iteration 7086, loss = 0.00299548
Iteration 7087, loss = 0.00299492
Iteration 7088, loss = 0.00299431
Iteration 7089, loss = 0.00299352
Iteration 7090, loss = 0.00299321
Iteration 7091, loss = 0.00299232
Iteration 7092, loss = 0.00299173
Iteration 7093, loss = 0.00299120
Iteration 7094, loss = 0.00299050
Iteration 7095, loss = 0.00298985
Iteration 7096, loss = 0.00298924
Iteration 7097, loss = 0.00298862
Iteration 7098, loss = 0.00298806
Iteration 7099, loss = 0.00298739
Iteration 7100, loss = 0.00298666
Iteration 7101, loss = 0.00298658
Iteration 7102, loss = 0.00298544
Iteration 7103, loss = 0.00298484
Iteration 7104, loss = 0.00298434
Iteration 7105, loss = 0.00298371
Iteration 7106, loss = 0.00298322
Iteration 7107, loss = 0.00298261
Iteration 7108, loss = 0.00298214
Iteration 7109, loss = 0.00298148
Iteration 7110, loss = 0.00298097
Iteration 7111, loss = 0.00298038
Iteration 7112, loss = 0.00297979
Iteration 7113, loss = 0.00297914
Iteration 7114, loss = 0.00297859
Iteration 7115, loss = 0.00297801
Iteration 7116, loss = 0.00297749
Iteration 7117, loss = 0.00297691
Iteration 7118, loss = 0.00297653
Iteration 7119, loss = 0.00297575
Iteration 7120, loss = 0.00297524
Iteration 7121, loss = 0.00297467
Iteration 7122, loss = 0.00297389
Iteration 7123, loss = 0.00297339
Iteration 7124, loss = 0.00297265
Iteration 7125, loss = 0.00297197
Iteration 7126, loss = 0.00297141
Iteration 7127, loss = 0.00297067
Iteration 7128, loss = 0.00297011
Iteration 7129, loss = 0.00296944
Iteration 7130, loss = 0.00296880
Iteration 7131, loss = 0.00296827
Iteration 7132, loss = 0.00296772
Iteration 7133, loss = 0.00296709
Iteration 7134, loss = 0.00296654
Iteration 7135, loss = 0.00296594
Iteration 7136, loss = 0.00296549
Iteration 7137, loss = 0.00296473
Iteration 7138, loss = 0.00296415
Iteration 7139, loss = 0.00296362
Iteration 7140, loss = 0.00296309
Iteration 7141, loss = 0.00296259
Iteration 7142, loss = 0.00296183
Iteration 7143, loss = 0.00296136
Iteration 7144, loss = 0.00296094
Iteration 7145, loss = 0.00296036
Iteration 7146, loss = 0.00295973
Iteration 7147, loss = 0.00295938
Iteration 7148, loss = 0.00295878
Iteration 7149, loss = 0.00295826
Iteration 7150, loss = 0.00295776
Iteration 7151, loss = 0.00295744
Iteration 7152, loss = 0.00295684
Iteration 7153, loss = 0.00295639
Iteration 7154, loss = 0.00295573
Iteration 7155, loss = 0.00295512
Iteration 7156, loss = 0.00295464
Iteration 7157, loss = 0.00295420
Iteration 7158, loss = 0.00295350
Iteration 7159, loss = 0.00295288
Iteration 7160, loss = 0.00295244
Iteration 7161, loss = 0.00295170
Iteration 7162, loss = 0.00295108
Iteration 7163, loss = 0.00295055
Iteration 7164, loss = 0.00294989
Iteration 7165, loss = 0.00294927
Iteration 7166, loss = 0.00294868
Iteration 7167, loss = 0.00294804
Iteration 7168, loss = 0.00294753
Iteration 7169, loss = 0.00294688
Iteration 7170, loss = 0.00294652
Iteration 7171, loss = 0.00294578
Iteration 7172, loss = 0.00294521
Iteration 7173, loss = 0.00294467
Iteration 7174, loss = 0.00294404
Iteration 7175, loss = 0.00294339
Iteration 7176, loss = 0.00294280
Iteration 7177, loss = 0.00294217
Iteration 7178, loss = 0.00294168
Iteration 7179, loss = 0.00294106
Iteration 7180, loss = 0.00294026
Iteration 7181, loss = 0.00293967
Iteration 7182, loss = 0.00293903
Iteration 7183, loss = 0.00293868
Iteration 7184, loss = 0.00293803
Iteration 7185, loss = 0.00293724
Iteration 7186, loss = 0.00293676
Iteration 7187, loss = 0.00293610
Iteration 7188, loss = 0.00293548
Iteration 7189, loss = 0.00293494
Iteration 7190, loss = 0.00293432
Iteration 7191, loss = 0.00293391
Iteration 7192, loss = 0.00293310
Iteration 7193, loss = 0.00293250
Iteration 7194, loss = 0.00293194
Iteration 7195, loss = 0.00293136
Iteration 7196, loss = 0.00293082
Iteration 7197, loss = 0.00292998
Iteration 7198, loss = 0.00292929
Iteration 7199, loss = 0.00292882
Iteration 7200, loss = 0.00292806
Iteration 7201, loss = 0.00292743
Iteration 7202, loss = 0.00292689
Iteration 7203, loss = 0.00292617
Iteration 7204, loss = 0.00292551
Iteration 7205, loss = 0.00292492
Iteration 7206, loss = 0.00292423
Iteration 7207, loss = 0.00292354
Iteration 7208, loss = 0.00292299
Iteration 7209, loss = 0.00292250
Iteration 7210, loss = 0.00292213
Iteration 7211, loss = 0.00292128
Iteration 7212, loss = 0.00292084
Iteration 7213, loss = 0.00292015
Iteration 7214, loss = 0.00291953
Iteration 7215, loss = 0.00291901
Iteration 7216, loss = 0.00291846
Iteration 7217, loss = 0.00291790
Iteration 7218, loss = 0.00291736
Iteration 7219, loss = 0.00291678
Iteration 7220, loss = 0.00291629
Iteration 7221, loss = 0.00291568
Iteration 7222, loss = 0.00291517
Iteration 7223, loss = 0.00291460
Iteration 7224, loss = 0.00291405
Iteration 7225, loss = 0.00291357
Iteration 7226, loss = 0.00291315
Iteration 7227, loss = 0.00291252
Iteration 7228, loss = 0.00291197
Iteration 7229, loss = 0.00291145
Iteration 7230, loss = 0.00291093
Iteration 7231, loss = 0.00291041
Iteration 7232, loss = 0.00290987
Iteration 7233, loss = 0.00290933
Iteration 7234, loss = 0.00290875
Iteration 7235, loss = 0.00290815
Iteration 7236, loss = 0.00290750
Iteration 7237, loss = 0.00290702
Iteration 7238, loss = 0.00290640
Iteration 7239, loss = 0.00290578
Iteration 7240, loss = 0.00290522
Iteration 7241, loss = 0.00290469
Iteration 7242, loss = 0.00290412
Iteration 7243, loss = 0.00290365
Iteration 7244, loss = 0.00290330
Iteration 7245, loss = 0.00290252
Iteration 7246, loss = 0.00290202
Iteration 7247, loss = 0.00290154
Iteration 7248, loss = 0.00290087
Iteration 7249, loss = 0.00290051
Iteration 7250, loss = 0.00289972
Iteration 7251, loss = 0.00289916
Iteration 7252, loss = 0.00289859
Iteration 7253, loss = 0.00289809
Iteration 7254, loss = 0.00289755
Iteration 7255, loss = 0.00289695
Iteration 7256, loss = 0.00289636
Iteration 7257, loss = 0.00289588
Iteration 7258, loss = 0.00289560
Iteration 7259, loss = 0.00289490
Iteration 7260, loss = 0.00289435
Iteration 7261, loss = 0.00289373
Iteration 7262, loss = 0.00289339
Iteration 7263, loss = 0.00289261
Iteration 7264, loss = 0.00289201
Iteration 7265, loss = 0.00289155
Iteration 7266, loss = 0.00289095
Iteration 7267, loss = 0.00289035
Iteration 7268, loss = 0.00288983
Iteration 7269, loss = 0.00288929
Iteration 7270, loss = 0.00288868
Iteration 7271, loss = 0.00288816
Iteration 7272, loss = 0.00288770
Iteration 7273, loss = 0.00288713
Iteration 7274, loss = 0.00288661
Iteration 7275, loss = 0.00288601
Iteration 7276, loss = 0.00288552
Iteration 7277, loss = 0.00288520
Iteration 7278, loss = 0.00288441
Iteration 7279, loss = 0.00288394
Iteration 7280, loss = 0.00288331
Iteration 7281, loss = 0.00288269
Iteration 7282, loss = 0.00288200
Iteration 7283, loss = 0.00288163
Iteration 7284, loss = 0.00288090
Iteration 7285, loss = 0.00288037
Iteration 7286, loss = 0.00287970
Iteration 7287, loss = 0.00287913
Iteration 7288, loss = 0.00287866
Iteration 7289, loss = 0.00287829
Iteration 7290, loss = 0.00287751
Iteration 7291, loss = 0.00287723
Iteration 7292, loss = 0.00287667
Iteration 7293, loss = 0.00287589
Iteration 7294, loss = 0.00287529
Iteration 7295, loss = 0.00287466
Iteration 7296, loss = 0.00287403
Iteration 7297, loss = 0.00287351
Iteration 7298, loss = 0.00287284
Iteration 7299, loss = 0.00287223
Iteration 7300, loss = 0.00287165
Iteration 7301, loss = 0.00287113
Iteration 7302, loss = 0.00287066
Iteration 7303, loss = 0.00287012
Iteration 7304, loss = 0.00286974
Iteration 7305, loss = 0.00286903
Iteration 7306, loss = 0.00286844
Iteration 7307, loss = 0.00286789
Iteration 7308, loss = 0.00286727
Iteration 7309, loss = 0.00286703
Iteration 7310, loss = 0.00286632
Iteration 7311, loss = 0.00286576
Iteration 7312, loss = 0.00286528
Iteration 7313, loss = 0.00286440
Iteration 7314, loss = 0.00286388
Iteration 7315, loss = 0.00286315
Iteration 7316, loss = 0.00286269
Iteration 7317, loss = 0.00286234
Iteration 7318, loss = 0.00286139
Iteration 7319, loss = 0.00286078
Iteration 7320, loss = 0.00285999
Iteration 7321, loss = 0.00285947
Iteration 7322, loss = 0.00285884
Iteration 7323, loss = 0.00285833
Iteration 7324, loss = 0.00285770
Iteration 7325, loss = 0.00285712
Iteration 7326, loss = 0.00285667
Iteration 7327, loss = 0.00285602
Iteration 7328, loss = 0.00285542
Iteration 7329, loss = 0.00285486
Iteration 7330, loss = 0.00285425
Iteration 7331, loss = 0.00285364
Iteration 7332, loss = 0.00285310
Iteration 7333, loss = 0.00285232
Iteration 7334, loss = 0.00285163
Iteration 7335, loss = 0.00285112
Iteration 7336, loss = 0.00285070
Iteration 7337, loss = 0.00284999
Iteration 7338, loss = 0.00284928
Iteration 7339, loss = 0.00284887
Iteration 7340, loss = 0.00284825
Iteration 7341, loss = 0.00284770
Iteration 7342, loss = 0.00284695
Iteration 7343, loss = 0.00284650
Iteration 7344, loss = 0.00284580
Iteration 7345, loss = 0.00284555
Iteration 7346, loss = 0.00284513
Iteration 7347, loss = 0.00284428
Iteration 7348, loss = 0.00284372
Iteration 7349, loss = 0.00284321
Iteration 7350, loss = 0.00284271
Iteration 7351, loss = 0.00284227
Iteration 7352, loss = 0.00284175
Iteration 7353, loss = 0.00284127
Iteration 7354, loss = 0.00284075
Iteration 7355, loss = 0.00284033
Iteration 7356, loss = 0.00283967
Iteration 7357, loss = 0.00283928
Iteration 7358, loss = 0.00283869
Iteration 7359, loss = 0.00283810
Iteration 7360, loss = 0.00283759
Iteration 7361, loss = 0.00283707
Iteration 7362, loss = 0.00283657
Iteration 7363, loss = 0.00283614
Iteration 7364, loss = 0.00283551
Iteration 7365, loss = 0.00283501
Iteration 7366, loss = 0.00283437
Iteration 7367, loss = 0.00283376
Iteration 7368, loss = 0.00283314
Iteration 7369, loss = 0.00283272
Iteration 7370, loss = 0.00283216
Iteration 7371, loss = 0.00283178
Iteration 7372, loss = 0.00283099
Iteration 7373, loss = 0.00283058
Iteration 7374, loss = 0.00282984
Iteration 7375, loss = 0.00282942
Iteration 7376, loss = 0.00282877
Iteration 7377, loss = 0.00282823
Iteration 7378, loss = 0.00282759
Iteration 7379, loss = 0.00282717
Iteration 7380, loss = 0.00282653
Iteration 7381, loss = 0.00282580
Iteration 7382, loss = 0.00282557
Iteration 7383, loss = 0.00282504
Iteration 7384, loss = 0.00282433
Iteration 7385, loss = 0.00282372
Iteration 7386, loss = 0.00282326
Iteration 7387, loss = 0.00282267
Iteration 7388, loss = 0.00282207
Iteration 7389, loss = 0.00282151
Iteration 7390, loss = 0.00282109
Iteration 7391, loss = 0.00282047
Iteration 7392, loss = 0.00282006
Iteration 7393, loss = 0.00281945
Iteration 7394, loss = 0.00281908
Iteration 7395, loss = 0.00281846
Iteration 7396, loss = 0.00281795
Iteration 7397, loss = 0.00281744
Iteration 7398, loss = 0.00281702
Iteration 7399, loss = 0.00281652
Iteration 7400, loss = 0.00281586
Iteration 7401, loss = 0.00281539
Iteration 7402, loss = 0.00281495
Iteration 7403, loss = 0.00281434
Iteration 7404, loss = 0.00281381
Iteration 7405, loss = 0.00281332
Iteration 7406, loss = 0.00281280
Iteration 7407, loss = 0.00281234
Iteration 7408, loss = 0.00281194
Iteration 7409, loss = 0.00281117
Iteration 7410, loss = 0.00281057
Iteration 7411, loss = 0.00281013
Iteration 7412, loss = 0.00280961
Iteration 7413, loss = 0.00280894
Iteration 7414, loss = 0.00280847
Iteration 7415, loss = 0.00280761
Iteration 7416, loss = 0.00280702
Iteration 7417, loss = 0.00280647
Iteration 7418, loss = 0.00280579
Iteration 7419, loss = 0.00280512
Iteration 7420, loss = 0.00280446
Iteration 7421, loss = 0.00280381
Iteration 7422, loss = 0.00280331
Iteration 7423, loss = 0.00280275
Iteration 7424, loss = 0.00280217
Iteration 7425, loss = 0.00280148
Iteration 7426, loss = 0.00280090
Iteration 7427, loss = 0.00280031
Iteration 7428, loss = 0.00279994
Iteration 7429, loss = 0.00279938
Iteration 7430, loss = 0.00279882
Iteration 7431, loss = 0.00279812
Iteration 7432, loss = 0.00279750
Iteration 7433, loss = 0.00279690
Iteration 7434, loss = 0.00279632
Iteration 7435, loss = 0.00279593
Iteration 7436, loss = 0.00279527
Iteration 7437, loss = 0.00279488
Iteration 7438, loss = 0.00279428
Iteration 7439, loss = 0.00279378
Iteration 7440, loss = 0.00279321
Iteration 7441, loss = 0.00279264
Iteration 7442, loss = 0.00279209
Iteration 7443, loss = 0.00279153
Iteration 7444, loss = 0.00279101
Iteration 7445, loss = 0.00279048
Iteration 7446, loss = 0.00278998
Iteration 7447, loss = 0.00278943
Iteration 7448, loss = 0.00278902
Iteration 7449, loss = 0.00278846
Iteration 7450, loss = 0.00278801
Iteration 7451, loss = 0.00278754
Iteration 7452, loss = 0.00278716
Iteration 7453, loss = 0.00278658
Iteration 7454, loss = 0.00278630
Iteration 7455, loss = 0.00278574
Iteration 7456, loss = 0.00278535
Iteration 7457, loss = 0.00278475
Iteration 7458, loss = 0.00278444
Iteration 7459, loss = 0.00278407
Iteration 7460, loss = 0.00278341
Iteration 7461, loss = 0.00278310
Iteration 7462, loss = 0.00278256
Iteration 7463, loss = 0.00278188
Iteration 7464, loss = 0.00278135
Iteration 7465, loss = 0.00278079
Iteration 7466, loss = 0.00278032
Iteration 7467, loss = 0.00277987
Iteration 7468, loss = 0.00277944
Iteration 7469, loss = 0.00277883
Iteration 7470, loss = 0.00277824
Iteration 7471, loss = 0.00277777
Iteration 7472, loss = 0.00277717
Iteration 7473, loss = 0.00277666
Iteration 7474, loss = 0.00277623
Iteration 7475, loss = 0.00277577
Iteration 7476, loss = 0.00277527
Iteration 7477, loss = 0.00277480
Iteration 7478, loss = 0.00277433
Iteration 7479, loss = 0.00277375
Iteration 7480, loss = 0.00277319
Iteration 7481, loss = 0.00277262
Iteration 7482, loss = 0.00277209
Iteration 7483, loss = 0.00277180
Iteration 7484, loss = 0.00277114
Iteration 7485, loss = 0.00277054
Iteration 7486, loss = 0.00277012
Iteration 7487, loss = 0.00276955
Iteration 7488, loss = 0.00276901
Iteration 7489, loss = 0.00276851
Iteration 7490, loss = 0.00276804
Iteration 7491, loss = 0.00276751
Iteration 7492, loss = 0.00276714
Iteration 7493, loss = 0.00276654
Iteration 7494, loss = 0.00276602
Iteration 7495, loss = 0.00276559
Iteration 7496, loss = 0.00276510
Iteration 7497, loss = 0.00276471
Iteration 7498, loss = 0.00276415
Iteration 7499, loss = 0.00276371
Iteration 7500, loss = 0.00276312
Iteration 7501, loss = 0.00276252
Iteration 7502, loss = 0.00276211
Iteration 7503, loss = 0.00276159
Iteration 7504, loss = 0.00276099
Iteration 7505, loss = 0.00276041
Iteration 7506, loss = 0.00276001
Iteration 7507, loss = 0.00275940
Iteration 7508, loss = 0.00275886
Iteration 7509, loss = 0.00275830
Iteration 7510, loss = 0.00275771
Iteration 7511, loss = 0.00275727
Iteration 7512, loss = 0.00275662
Iteration 7513, loss = 0.00275612
Iteration 7514, loss = 0.00275559
Iteration 7515, loss = 0.00275516
Iteration 7516, loss = 0.00275465
Iteration 7517, loss = 0.00275421
Iteration 7518, loss = 0.00275353
Iteration 7519, loss = 0.00275300
Iteration 7520, loss = 0.00275249
Iteration 7521, loss = 0.00275195
Iteration 7522, loss = 0.00275141
Iteration 7523, loss = 0.00275100
Iteration 7524, loss = 0.00275043
Iteration 7525, loss = 0.00274989
Iteration 7526, loss = 0.00274946
Iteration 7527, loss = 0.00274897
Iteration 7528, loss = 0.00274839
Iteration 7529, loss = 0.00274802
Iteration 7530, loss = 0.00274741
Iteration 7531, loss = 0.00274691
Iteration 7532, loss = 0.00274648
Iteration 7533, loss = 0.00274601
Iteration 7534, loss = 0.00274571
Iteration 7535, loss = 0.00274522
Iteration 7536, loss = 0.00274447
Iteration 7537, loss = 0.00274397
Iteration 7538, loss = 0.00274334
Iteration 7539, loss = 0.00274286
Iteration 7540, loss = 0.00274231
Iteration 7541, loss = 0.00274179
Iteration 7542, loss = 0.00274127
Iteration 7543, loss = 0.00274085
Iteration 7544, loss = 0.00274027
Iteration 7545, loss = 0.00273981
Iteration 7546, loss = 0.00273958
Iteration 7547, loss = 0.00273894
Iteration 7548, loss = 0.00273855
Iteration 7549, loss = 0.00273785
Iteration 7550, loss = 0.00273731
Iteration 7551, loss = 0.00273673
Iteration 7552, loss = 0.00273630
Iteration 7553, loss = 0.00273575
Iteration 7554, loss = 0.00273540
Iteration 7555, loss = 0.00273476
Iteration 7556, loss = 0.00273423
Iteration 7557, loss = 0.00273371
Iteration 7558, loss = 0.00273323
Iteration 7559, loss = 0.00273274
Iteration 7560, loss = 0.00273217
Iteration 7561, loss = 0.00273180
Iteration 7562, loss = 0.00273138
Iteration 7563, loss = 0.00273075
Iteration 7564, loss = 0.00273030
Iteration 7565, loss = 0.00272979
Iteration 7566, loss = 0.00272931
Iteration 7567, loss = 0.00272905
Iteration 7568, loss = 0.00272846
Iteration 7569, loss = 0.00272783
Iteration 7570, loss = 0.00272731
Iteration 7571, loss = 0.00272681
Iteration 7572, loss = 0.00272637
Iteration 7573, loss = 0.00272595
Iteration 7574, loss = 0.00272535
Iteration 7575, loss = 0.00272484
Iteration 7576, loss = 0.00272440
Iteration 7577, loss = 0.00272411
Iteration 7578, loss = 0.00272348
Iteration 7579, loss = 0.00272308
Iteration 7580, loss = 0.00272241
Iteration 7581, loss = 0.00272191
Iteration 7582, loss = 0.00272146
Iteration 7583, loss = 0.00272099
Iteration 7584, loss = 0.00272043
Iteration 7585, loss = 0.00271990
Iteration 7586, loss = 0.00271934
Iteration 7587, loss = 0.00271886
Iteration 7588, loss = 0.00271832
Iteration 7589, loss = 0.00271771
Iteration 7590, loss = 0.00271723
Iteration 7591, loss = 0.00271683
Iteration 7592, loss = 0.00271612
Iteration 7593, loss = 0.00271581
Iteration 7594, loss = 0.00271504
Iteration 7595, loss = 0.00271456
Iteration 7596, loss = 0.00271403
Iteration 7597, loss = 0.00271355
Iteration 7598, loss = 0.00271297
Iteration 7599, loss = 0.00271246
Iteration 7600, loss = 0.00271199
Iteration 7601, loss = 0.00271153
Iteration 7602, loss = 0.00271106
Iteration 7603, loss = 0.00271076
Iteration 7604, loss = 0.00271011
Iteration 7605, loss = 0.00270981
Iteration 7606, loss = 0.00270915
Iteration 7607, loss = 0.00270865
Iteration 7608, loss = 0.00270821
Iteration 7609, loss = 0.00270772
Iteration 7610, loss = 0.00270723
Iteration 7611, loss = 0.00270671
Iteration 7612, loss = 0.00270623
Iteration 7613, loss = 0.00270597
Iteration 7614, loss = 0.00270527
Iteration 7615, loss = 0.00270481
Iteration 7616, loss = 0.00270431
Iteration 7617, loss = 0.00270379
Iteration 7618, loss = 0.00270332
Iteration 7619, loss = 0.00270283
Iteration 7620, loss = 0.00270241
Iteration 7621, loss = 0.00270199
Iteration 7622, loss = 0.00270165
Iteration 7623, loss = 0.00270116
Iteration 7624, loss = 0.00270066
Iteration 7625, loss = 0.00270043
Iteration 7626, loss = 0.00269985
Iteration 7627, loss = 0.00269941
Iteration 7628, loss = 0.00269892
Iteration 7629, loss = 0.00269846
Iteration 7630, loss = 0.00269792
Iteration 7631, loss = 0.00269741
Iteration 7632, loss = 0.00269697
Iteration 7633, loss = 0.00269621
Iteration 7634, loss = 0.00269565
Iteration 7635, loss = 0.00269518
Iteration 7636, loss = 0.00269468
Iteration 7637, loss = 0.00269415
Iteration 7638, loss = 0.00269377
Iteration 7639, loss = 0.00269297
Iteration 7640, loss = 0.00269240
Iteration 7641, loss = 0.00269190
Iteration 7642, loss = 0.00269147
Iteration 7643, loss = 0.00269075
Iteration 7644, loss = 0.00269026
Iteration 7645, loss = 0.00268972
Iteration 7646, loss = 0.00268919
Iteration 7647, loss = 0.00268863
Iteration 7648, loss = 0.00268809
Iteration 7649, loss = 0.00268761
Iteration 7650, loss = 0.00268708
Iteration 7651, loss = 0.00268660
Iteration 7652, loss = 0.00268603
Iteration 7653, loss = 0.00268550
Iteration 7654, loss = 0.00268500
Iteration 7655, loss = 0.00268459
Iteration 7656, loss = 0.00268407
Iteration 7657, loss = 0.00268340
Iteration 7658, loss = 0.00268312
Iteration 7659, loss = 0.00268235
Iteration 7660, loss = 0.00268199
Iteration 7661, loss = 0.00268151
Iteration 7662, loss = 0.00268088
Iteration 7663, loss = 0.00268039
Iteration 7664, loss = 0.00267990
Iteration 7665, loss = 0.00267993
Iteration 7666, loss = 0.00267905
Iteration 7667, loss = 0.00267863
Iteration 7668, loss = 0.00267820
Iteration 7669, loss = 0.00267758
Iteration 7670, loss = 0.00267710
Iteration 7671, loss = 0.00267652
Iteration 7672, loss = 0.00267592
Iteration 7673, loss = 0.00267557
Iteration 7674, loss = 0.00267498
Iteration 7675, loss = 0.00267439
Iteration 7676, loss = 0.00267389
Iteration 7677, loss = 0.00267346
Iteration 7678, loss = 0.00267291
Iteration 7679, loss = 0.00267250
Iteration 7680, loss = 0.00267214
Iteration 7681, loss = 0.00267158
Iteration 7682, loss = 0.00267091
Iteration 7683, loss = 0.00267042
Iteration 7684, loss = 0.00266990
Iteration 7685, loss = 0.00266941
Iteration 7686, loss = 0.00266891
Iteration 7687, loss = 0.00266841
Iteration 7688, loss = 0.00266802
Iteration 7689, loss = 0.00266748
Iteration 7690, loss = 0.00266699
Iteration 7691, loss = 0.00266655
Iteration 7692, loss = 0.00266609
Iteration 7693, loss = 0.00266563
Iteration 7694, loss = 0.00266522
Iteration 7695, loss = 0.00266475
Iteration 7696, loss = 0.00266434
Iteration 7697, loss = 0.00266388
Iteration 7698, loss = 0.00266352
Iteration 7699, loss = 0.00266308
Iteration 7700, loss = 0.00266269
Iteration 7701, loss = 0.00266230
Iteration 7702, loss = 0.00266234
Iteration 7703, loss = 0.00266151
Iteration 7704, loss = 0.00266098
Iteration 7705, loss = 0.00266055
Iteration 7706, loss = 0.00266008
Iteration 7707, loss = 0.00265960
Iteration 7708, loss = 0.00265957
Iteration 7709, loss = 0.00265873
Iteration 7710, loss = 0.00265829
Iteration 7711, loss = 0.00265777
Iteration 7712, loss = 0.00265727
Iteration 7713, loss = 0.00265684
Iteration 7714, loss = 0.00265625
Iteration 7715, loss = 0.00265578
Iteration 7716, loss = 0.00265532
Iteration 7717, loss = 0.00265486
Iteration 7718, loss = 0.00265440
Iteration 7719, loss = 0.00265393
Iteration 7720, loss = 0.00265352
Iteration 7721, loss = 0.00265359
Iteration 7722, loss = 0.00265261
Iteration 7723, loss = 0.00265222
Iteration 7724, loss = 0.00265164
Iteration 7725, loss = 0.00265117
Iteration 7726, loss = 0.00265062
Iteration 7727, loss = 0.00265009
Iteration 7728, loss = 0.00264946
Iteration 7729, loss = 0.00264933
Iteration 7730, loss = 0.00264841
Iteration 7731, loss = 0.00264775
Iteration 7732, loss = 0.00264739
Iteration 7733, loss = 0.00264676
Iteration 7734, loss = 0.00264628
Iteration 7735, loss = 0.00264584
Iteration 7736, loss = 0.00264533
Iteration 7737, loss = 0.00264500
Iteration 7738, loss = 0.00264456
Iteration 7739, loss = 0.00264407
Iteration 7740, loss = 0.00264371
Iteration 7741, loss = 0.00264328
Iteration 7742, loss = 0.00264300
Iteration 7743, loss = 0.00264242
Iteration 7744, loss = 0.00264198
Iteration 7745, loss = 0.00264129
Iteration 7746, loss = 0.00264084
Iteration 7747, loss = 0.00264045
Iteration 7748, loss = 0.00263976
Iteration 7749, loss = 0.00263923
Iteration 7750, loss = 0.00263876
Iteration 7751, loss = 0.00263813
Iteration 7752, loss = 0.00263794
Iteration 7753, loss = 0.00263716
Iteration 7754, loss = 0.00263660
Iteration 7755, loss = 0.00263614
Iteration 7756, loss = 0.00263583
Iteration 7757, loss = 0.00263514
Iteration 7758, loss = 0.00263462
Iteration 7759, loss = 0.00263425
Iteration 7760, loss = 0.00263368
Iteration 7761, loss = 0.00263317
Iteration 7762, loss = 0.00263275
Iteration 7763, loss = 0.00263218
Iteration 7764, loss = 0.00263177
Iteration 7765, loss = 0.00263121
Iteration 7766, loss = 0.00263064
Iteration 7767, loss = 0.00263008
Iteration 7768, loss = 0.00262958
Iteration 7769, loss = 0.00262910
Iteration 7770, loss = 0.00262851
Iteration 7771, loss = 0.00262796
Iteration 7772, loss = 0.00262740
Iteration 7773, loss = 0.00262681
Iteration 7774, loss = 0.00262634
Iteration 7775, loss = 0.00262599
Iteration 7776, loss = 0.00262532
Iteration 7777, loss = 0.00262501
Iteration 7778, loss = 0.00262437
Iteration 7779, loss = 0.00262389
Iteration 7780, loss = 0.00262347
Iteration 7781, loss = 0.00262297
Iteration 7782, loss = 0.00262251
Iteration 7783, loss = 0.00262196
Iteration 7784, loss = 0.00262146
Iteration 7785, loss = 0.00262115
Iteration 7786, loss = 0.00262047
Iteration 7787, loss = 0.00261985
Iteration 7788, loss = 0.00261944
Iteration 7789, loss = 0.00261886
Iteration 7790, loss = 0.00261838
Iteration 7791, loss = 0.00261781
Iteration 7792, loss = 0.00261750
Iteration 7793, loss = 0.00261701
Iteration 7794, loss = 0.00261656
Iteration 7795, loss = 0.00261598
Iteration 7796, loss = 0.00261568
Iteration 7797, loss = 0.00261495
Iteration 7798, loss = 0.00261448
Iteration 7799, loss = 0.00261393
Iteration 7800, loss = 0.00261347
Iteration 7801, loss = 0.00261303
Iteration 7802, loss = 0.00261260
Iteration 7803, loss = 0.00261202
Iteration 7804, loss = 0.00261179
Iteration 7805, loss = 0.00261107
Iteration 7806, loss = 0.00261066
Iteration 7807, loss = 0.00261015
Iteration 7808, loss = 0.00260962
Iteration 7809, loss = 0.00260921
Iteration 7810, loss = 0.00260875
Iteration 7811, loss = 0.00260834
Iteration 7812, loss = 0.00260781
Iteration 7813, loss = 0.00260737
Iteration 7814, loss = 0.00260685
Iteration 7815, loss = 0.00260634
Iteration 7816, loss = 0.00260587
Iteration 7817, loss = 0.00260550
Iteration 7818, loss = 0.00260494
Iteration 7819, loss = 0.00260446
Iteration 7820, loss = 0.00260408
Iteration 7821, loss = 0.00260348
Iteration 7822, loss = 0.00260299
Iteration 7823, loss = 0.00260253
Iteration 7824, loss = 0.00260202
Iteration 7825, loss = 0.00260163
Iteration 7826, loss = 0.00260099
Iteration 7827, loss = 0.00260061
Iteration 7828, loss = 0.00260019
Iteration 7829, loss = 0.00259985
Iteration 7830, loss = 0.00259930
Iteration 7831, loss = 0.00259884
Iteration 7832, loss = 0.00259838
Iteration 7833, loss = 0.00259816
Iteration 7834, loss = 0.00259743
Iteration 7835, loss = 0.00259732
Iteration 7836, loss = 0.00259649
Iteration 7837, loss = 0.00259596
Iteration 7838, loss = 0.00259543
Iteration 7839, loss = 0.00259522
Iteration 7840, loss = 0.00259474
Iteration 7841, loss = 0.00259391
Iteration 7842, loss = 0.00259339
Iteration 7843, loss = 0.00259291
Iteration 7844, loss = 0.00259253
Iteration 7845, loss = 0.00259194
Iteration 7846, loss = 0.00259131
Iteration 7847, loss = 0.00259083
Iteration 7848, loss = 0.00259035
Iteration 7849, loss = 0.00258982
Iteration 7850, loss = 0.00258964
Iteration 7851, loss = 0.00258897
Iteration 7852, loss = 0.00258848
Iteration 7853, loss = 0.00258783
Iteration 7854, loss = 0.00258749
Iteration 7855, loss = 0.00258700
Iteration 7856, loss = 0.00258648
Iteration 7857, loss = 0.00258625
Iteration 7858, loss = 0.00258558
Iteration 7859, loss = 0.00258502
Iteration 7860, loss = 0.00258450
Iteration 7861, loss = 0.00258404
Iteration 7862, loss = 0.00258354
Iteration 7863, loss = 0.00258305
Iteration 7864, loss = 0.00258262
Iteration 7865, loss = 0.00258209
Iteration 7866, loss = 0.00258165
Iteration 7867, loss = 0.00258119
Iteration 7868, loss = 0.00258084
Iteration 7869, loss = 0.00258032
Iteration 7870, loss = 0.00257992
Iteration 7871, loss = 0.00257971
Iteration 7872, loss = 0.00257933
Iteration 7873, loss = 0.00257871
Iteration 7874, loss = 0.00257826
Iteration 7875, loss = 0.00257806
Iteration 7876, loss = 0.00257739
Iteration 7877, loss = 0.00257704
Iteration 7878, loss = 0.00257666
Iteration 7879, loss = 0.00257622
Iteration 7880, loss = 0.00257579
Iteration 7881, loss = 0.00257547
Iteration 7882, loss = 0.00257532
Iteration 7883, loss = 0.00257452
Iteration 7884, loss = 0.00257404
Iteration 7885, loss = 0.00257340
Iteration 7886, loss = 0.00257294
Iteration 7887, loss = 0.00257243
Iteration 7888, loss = 0.00257202
Iteration 7889, loss = 0.00257148
Iteration 7890, loss = 0.00257101
Iteration 7891, loss = 0.00257075
Iteration 7892, loss = 0.00257021
Iteration 7893, loss = 0.00256971
Iteration 7894, loss = 0.00256920
Iteration 7895, loss = 0.00256873
Iteration 7896, loss = 0.00256824
Iteration 7897, loss = 0.00256798
Iteration 7898, loss = 0.00256743
Iteration 7899, loss = 0.00256692
Iteration 7900, loss = 0.00256653
Iteration 7901, loss = 0.00256615
Iteration 7902, loss = 0.00256585
Iteration 7903, loss = 0.00256536
Iteration 7904, loss = 0.00256489
Iteration 7905, loss = 0.00256448
Iteration 7906, loss = 0.00256406
Iteration 7907, loss = 0.00256375
Iteration 7908, loss = 0.00256315
Iteration 7909, loss = 0.00256275
Iteration 7910, loss = 0.00256252
Iteration 7911, loss = 0.00256187
Iteration 7912, loss = 0.00256151
Iteration 7913, loss = 0.00256090
Iteration 7914, loss = 0.00256036
Iteration 7915, loss = 0.00256021
Iteration 7916, loss = 0.00255939
Iteration 7917, loss = 0.00255890
Iteration 7918, loss = 0.00255832
Iteration 7919, loss = 0.00255785
Iteration 7920, loss = 0.00255747
Iteration 7921, loss = 0.00255687
Iteration 7922, loss = 0.00255633
Iteration 7923, loss = 0.00255604
Iteration 7924, loss = 0.00255541
Iteration 7925, loss = 0.00255498
Iteration 7926, loss = 0.00255460
Iteration 7927, loss = 0.00255410
Iteration 7928, loss = 0.00255401
Iteration 7929, loss = 0.00255330
Iteration 7930, loss = 0.00255281
Iteration 7931, loss = 0.00255241
Iteration 7932, loss = 0.00255191
Iteration 7933, loss = 0.00255150
Iteration 7934, loss = 0.00255100
Iteration 7935, loss = 0.00255047
Iteration 7936, loss = 0.00255008
Iteration 7937, loss = 0.00254951
Iteration 7938, loss = 0.00254908
Iteration 7939, loss = 0.00254847
Iteration 7940, loss = 0.00254797
Iteration 7941, loss = 0.00254764
Iteration 7942, loss = 0.00254714
Iteration 7943, loss = 0.00254660
Iteration 7944, loss = 0.00254611
Iteration 7945, loss = 0.00254550
Iteration 7946, loss = 0.00254518
Iteration 7947, loss = 0.00254476
Iteration 7948, loss = 0.00254416
Iteration 7949, loss = 0.00254368
Iteration 7950, loss = 0.00254331
Iteration 7951, loss = 0.00254275
Iteration 7952, loss = 0.00254229
Iteration 7953, loss = 0.00254182
Iteration 7954, loss = 0.00254134
Iteration 7955, loss = 0.00254085
Iteration 7956, loss = 0.00254048
Iteration 7957, loss = 0.00253994
Iteration 7958, loss = 0.00253954
Iteration 7959, loss = 0.00253903
Iteration 7960, loss = 0.00253856
Iteration 7961, loss = 0.00253815
Iteration 7962, loss = 0.00253772
Iteration 7963, loss = 0.00253728
Iteration 7964, loss = 0.00253689
Iteration 7965, loss = 0.00253650
Iteration 7966, loss = 0.00253604
Iteration 7967, loss = 0.00253560
Iteration 7968, loss = 0.00253547
Iteration 7969, loss = 0.00253493
Iteration 7970, loss = 0.00253451
Iteration 7971, loss = 0.00253410
Iteration 7972, loss = 0.00253365
Iteration 7973, loss = 0.00253328
Iteration 7974, loss = 0.00253284
Iteration 7975, loss = 0.00253237
Iteration 7976, loss = 0.00253188
Iteration 7977, loss = 0.00253134
Iteration 7978, loss = 0.00253117
Iteration 7979, loss = 0.00253039
Iteration 7980, loss = 0.00252990
Iteration 7981, loss = 0.00252943
Iteration 7982, loss = 0.00252880
Iteration 7983, loss = 0.00252822
Iteration 7984, loss = 0.00252786
Iteration 7985, loss = 0.00252746
Iteration 7986, loss = 0.00252702
Iteration 7987, loss = 0.00252673
Iteration 7988, loss = 0.00252610
Iteration 7989, loss = 0.00252564
Iteration 7990, loss = 0.00252522
Iteration 7991, loss = 0.00252480
Iteration 7992, loss = 0.00252439
Iteration 7993, loss = 0.00252400
Iteration 7994, loss = 0.00252357
Iteration 7995, loss = 0.00252322
Iteration 7996, loss = 0.00252274
Iteration 7997, loss = 0.00252235
Iteration 7998, loss = 0.00252192
Iteration 7999, loss = 0.00252152
Iteration 8000, loss = 0.00252110
Iteration 1, loss = 1.02709999
Iteration 2, loss = 1.02411093
Iteration 3, loss = 1.01930461
Iteration 4, loss = 1.01328347
Iteration 5, loss = 1.00622561
Iteration 6, loss = 0.99845165
Iteration 7, loss = 0.99018610
Iteration 8, loss = 0.98147679
Iteration 9, loss = 0.97239050
Iteration 10, loss = 0.96348596
Iteration 11, loss = 0.95416563
Iteration 12, loss = 0.94507336
Iteration 13, loss = 0.93597766
Iteration 14, loss = 0.92711378
Iteration 15, loss = 0.91831435
Iteration 16, loss = 0.90981434
Iteration 17, loss = 0.90121955
Iteration 18, loss = 0.89315869
Iteration 19, loss = 0.88525401
Iteration 20, loss = 0.87757669
Iteration 21, loss = 0.87004667
Iteration 22, loss = 0.86288703
Iteration 23, loss = 0.85575934
Iteration 24, loss = 0.84874449
Iteration 25, loss = 0.84198547
Iteration 26, loss = 0.83527794
Iteration 27, loss = 0.82864907
Iteration 28, loss = 0.82228373
Iteration 29, loss = 0.81622522
Iteration 30, loss = 0.81020688
Iteration 31, loss = 0.80437638
Iteration 32, loss = 0.79875539
Iteration 33, loss = 0.79318706
Iteration 34, loss = 0.78788388
Iteration 35, loss = 0.78260815
Iteration 36, loss = 0.77736127
Iteration 37, loss = 0.77254672
Iteration 38, loss = 0.76771553
Iteration 39, loss = 0.76302948
Iteration 40, loss = 0.75870005
Iteration 41, loss = 0.75436468
Iteration 42, loss = 0.75018198
Iteration 43, loss = 0.74627704
Iteration 44, loss = 0.74235443
Iteration 45, loss = 0.73854513
Iteration 46, loss = 0.73493454
Iteration 47, loss = 0.73125975
Iteration 48, loss = 0.72769798
Iteration 49, loss = 0.72425267
Iteration 50, loss = 0.72068940
Iteration 51, loss = 0.71733071
Iteration 52, loss = 0.71389590
Iteration 53, loss = 0.71060131
Iteration 54, loss = 0.70723778
Iteration 55, loss = 0.70400049
Iteration 56, loss = 0.70075595
Iteration 57, loss = 0.69740177
Iteration 58, loss = 0.69423922
Iteration 59, loss = 0.69094430
Iteration 60, loss = 0.68768263
Iteration 61, loss = 0.68442563
Iteration 62, loss = 0.68133267
Iteration 63, loss = 0.67823208
Iteration 64, loss = 0.67510893
Iteration 65, loss = 0.67218596
Iteration 66, loss = 0.66921741
Iteration 67, loss = 0.66626883
Iteration 68, loss = 0.66348618
Iteration 69, loss = 0.66054484
Iteration 70, loss = 0.65777253
Iteration 71, loss = 0.65487415
Iteration 72, loss = 0.65214519
Iteration 73, loss = 0.64930724
Iteration 74, loss = 0.64657588
Iteration 75, loss = 0.64383623
Iteration 76, loss = 0.64111136
Iteration 77, loss = 0.63842029
Iteration 78, loss = 0.63572863
Iteration 79, loss = 0.63307103
Iteration 80, loss = 0.63044780
Iteration 81, loss = 0.62781540
Iteration 82, loss = 0.62523378
Iteration 83, loss = 0.62270268
Iteration 84, loss = 0.62007821
Iteration 85, loss = 0.61761506
Iteration 86, loss = 0.61505227
Iteration 87, loss = 0.61253683
Iteration 88, loss = 0.61000104
Iteration 89, loss = 0.60752092
Iteration 90, loss = 0.60502438
Iteration 91, loss = 0.60250024
Iteration 92, loss = 0.60006265
Iteration 93, loss = 0.59764223
Iteration 94, loss = 0.59515999
Iteration 95, loss = 0.59272012
Iteration 96, loss = 0.59031473
Iteration 97, loss = 0.58788990
Iteration 98, loss = 0.58549344
Iteration 99, loss = 0.58308573
Iteration 100, loss = 0.58068541
Iteration 101, loss = 0.57833261
Iteration 102, loss = 0.57592009
Iteration 103, loss = 0.57357010
Iteration 104, loss = 0.57124342
Iteration 105, loss = 0.56889054
Iteration 106, loss = 0.56656016
Iteration 107, loss = 0.56425266
Iteration 108, loss = 0.56203976
Iteration 109, loss = 0.55972363
Iteration 110, loss = 0.55748153
Iteration 111, loss = 0.55527157
Iteration 112, loss = 0.55302701
Iteration 113, loss = 0.55086304
Iteration 114, loss = 0.54859731
Iteration 115, loss = 0.54640070
Iteration 116, loss = 0.54421332
Iteration 117, loss = 0.54195190
Iteration 118, loss = 0.53979984
Iteration 119, loss = 0.53754004
Iteration 120, loss = 0.53534277
Iteration 121, loss = 0.53318824
Iteration 122, loss = 0.53103790
Iteration 123, loss = 0.52890858
Iteration 124, loss = 0.52678926
Iteration 125, loss = 0.52467650
Iteration 126, loss = 0.52256329
Iteration 127, loss = 0.52047578
Iteration 128, loss = 0.51838336
Iteration 129, loss = 0.51629314
Iteration 130, loss = 0.51428101
Iteration 131, loss = 0.51226764
Iteration 132, loss = 0.51025513
Iteration 133, loss = 0.50827574
Iteration 134, loss = 0.50630541
Iteration 135, loss = 0.50431040
Iteration 136, loss = 0.50234112
Iteration 137, loss = 0.50032891
Iteration 138, loss = 0.49832514
Iteration 139, loss = 0.49632206
Iteration 140, loss = 0.49429306
Iteration 141, loss = 0.49227635
Iteration 142, loss = 0.49027168
Iteration 143, loss = 0.48827127
Iteration 144, loss = 0.48626895
Iteration 145, loss = 0.48426457
Iteration 146, loss = 0.48227057
Iteration 147, loss = 0.48028374
Iteration 148, loss = 0.47830719
Iteration 149, loss = 0.47627824
Iteration 150, loss = 0.47430108
Iteration 151, loss = 0.47230911
Iteration 152, loss = 0.47028973
Iteration 153, loss = 0.46827545
Iteration 154, loss = 0.46628023
Iteration 155, loss = 0.46432996
Iteration 156, loss = 0.46229582
Iteration 157, loss = 0.46032411
Iteration 158, loss = 0.45833322
Iteration 159, loss = 0.45633414
Iteration 160, loss = 0.45430057
Iteration 161, loss = 0.45229787
Iteration 162, loss = 0.45025819
Iteration 163, loss = 0.44820665
Iteration 164, loss = 0.44616644
Iteration 165, loss = 0.44412478
Iteration 166, loss = 0.44207677
Iteration 167, loss = 0.44003942
Iteration 168, loss = 0.43802799
Iteration 169, loss = 0.43598421
Iteration 170, loss = 0.43399426
Iteration 171, loss = 0.43196335
Iteration 172, loss = 0.42996692
Iteration 173, loss = 0.42797631
Iteration 174, loss = 0.42597825
Iteration 175, loss = 0.42397527
Iteration 176, loss = 0.42201627
Iteration 177, loss = 0.42003084
Iteration 178, loss = 0.41806111
Iteration 179, loss = 0.41607442
Iteration 180, loss = 0.41413146
Iteration 181, loss = 0.41210472
Iteration 182, loss = 0.41012998
Iteration 183, loss = 0.40817045
Iteration 184, loss = 0.40614311
Iteration 185, loss = 0.40417537
Iteration 186, loss = 0.40218600
Iteration 187, loss = 0.40017981
Iteration 188, loss = 0.39820879
Iteration 189, loss = 0.39623857
Iteration 190, loss = 0.39424178
Iteration 191, loss = 0.39229683
Iteration 192, loss = 0.39033357
Iteration 193, loss = 0.38839131
Iteration 194, loss = 0.38644634
Iteration 195, loss = 0.38453107
Iteration 196, loss = 0.38256736
Iteration 197, loss = 0.38066785
Iteration 198, loss = 0.37872106
Iteration 199, loss = 0.37681847
Iteration 200, loss = 0.37488581
Iteration 201, loss = 0.37297083
Iteration 202, loss = 0.37107776
Iteration 203, loss = 0.36916552
Iteration 204, loss = 0.36726990
Iteration 205, loss = 0.36536696
Iteration 206, loss = 0.36347975
Iteration 207, loss = 0.36154641
Iteration 208, loss = 0.35965187
Iteration 209, loss = 0.35772494
Iteration 210, loss = 0.35580809
Iteration 211, loss = 0.35389377
Iteration 212, loss = 0.35193454
Iteration 213, loss = 0.35003263
Iteration 214, loss = 0.34809295
Iteration 215, loss = 0.34616997
Iteration 216, loss = 0.34425295
Iteration 217, loss = 0.34234803
Iteration 218, loss = 0.34046140
Iteration 219, loss = 0.33857194
Iteration 220, loss = 0.33670367
Iteration 221, loss = 0.33484339
Iteration 222, loss = 0.33299376
Iteration 223, loss = 0.33115120
Iteration 224, loss = 0.32928616
Iteration 225, loss = 0.32746690
Iteration 226, loss = 0.32560601
Iteration 227, loss = 0.32376087
Iteration 228, loss = 0.32190756
Iteration 229, loss = 0.32006734
Iteration 230, loss = 0.31822396
Iteration 231, loss = 0.31641283
Iteration 232, loss = 0.31458224
Iteration 233, loss = 0.31275205
Iteration 234, loss = 0.31095663
Iteration 235, loss = 0.30916236
Iteration 236, loss = 0.30735827
Iteration 237, loss = 0.30556879
Iteration 238, loss = 0.30379617
Iteration 239, loss = 0.30202263
Iteration 240, loss = 0.30025006
Iteration 241, loss = 0.29849959
Iteration 242, loss = 0.29674717
Iteration 243, loss = 0.29499350
Iteration 244, loss = 0.29326500
Iteration 245, loss = 0.29154295
Iteration 246, loss = 0.28981238
Iteration 247, loss = 0.28812685
Iteration 248, loss = 0.28642661
Iteration 249, loss = 0.28474148
Iteration 250, loss = 0.28310294
Iteration 251, loss = 0.28145068
Iteration 252, loss = 0.27979873
Iteration 253, loss = 0.27817048
Iteration 254, loss = 0.27656278
Iteration 255, loss = 0.27494069
Iteration 256, loss = 0.27336054
Iteration 257, loss = 0.27175165
Iteration 258, loss = 0.27018486
Iteration 259, loss = 0.26860087
Iteration 260, loss = 0.26704076
Iteration 261, loss = 0.26546838
Iteration 262, loss = 0.26393188
Iteration 263, loss = 0.26238129
Iteration 264, loss = 0.26084025
Iteration 265, loss = 0.25932396
Iteration 266, loss = 0.25782239
Iteration 267, loss = 0.25631868
Iteration 268, loss = 0.25483221
Iteration 269, loss = 0.25336502
Iteration 270, loss = 0.25191167
Iteration 271, loss = 0.25045872
Iteration 272, loss = 0.24904088
Iteration 273, loss = 0.24760233
Iteration 274, loss = 0.24620331
Iteration 275, loss = 0.24479480
Iteration 276, loss = 0.24341046
Iteration 277, loss = 0.24202106
Iteration 278, loss = 0.24065172
Iteration 279, loss = 0.23930617
Iteration 280, loss = 0.23794451
Iteration 281, loss = 0.23659484
Iteration 282, loss = 0.23525439
Iteration 283, loss = 0.23392037
Iteration 284, loss = 0.23258469
Iteration 285, loss = 0.23124939
Iteration 286, loss = 0.22992535
Iteration 287, loss = 0.22861531
Iteration 288, loss = 0.22731297
Iteration 289, loss = 0.22601588
Iteration 290, loss = 0.22473510
Iteration 291, loss = 0.22345565
Iteration 292, loss = 0.22220065
Iteration 293, loss = 0.22093611
Iteration 294, loss = 0.21969104
Iteration 295, loss = 0.21846864
Iteration 296, loss = 0.21723033
Iteration 297, loss = 0.21601740
Iteration 298, loss = 0.21479179
Iteration 299, loss = 0.21360548
Iteration 300, loss = 0.21239518
Iteration 301, loss = 0.21120025
Iteration 302, loss = 0.21001603
Iteration 303, loss = 0.20885568
Iteration 304, loss = 0.20768852
Iteration 305, loss = 0.20654197
Iteration 306, loss = 0.20539378
Iteration 307, loss = 0.20426725
Iteration 308, loss = 0.20314804
Iteration 309, loss = 0.20203322
Iteration 310, loss = 0.20094005
Iteration 311, loss = 0.19984440
Iteration 312, loss = 0.19876991
Iteration 313, loss = 0.19769829
Iteration 314, loss = 0.19662761
Iteration 315, loss = 0.19556716
Iteration 316, loss = 0.19451233
Iteration 317, loss = 0.19346865
Iteration 318, loss = 0.19242929
Iteration 319, loss = 0.19140141
Iteration 320, loss = 0.19037440
Iteration 321, loss = 0.18935527
Iteration 322, loss = 0.18835348
Iteration 323, loss = 0.18736157
Iteration 324, loss = 0.18637810
Iteration 325, loss = 0.18538702
Iteration 326, loss = 0.18442131
Iteration 327, loss = 0.18346304
Iteration 328, loss = 0.18250741
Iteration 329, loss = 0.18155156
Iteration 330, loss = 0.18060824
Iteration 331, loss = 0.17965860
Iteration 332, loss = 0.17872117
Iteration 333, loss = 0.17779882
Iteration 334, loss = 0.17686542
Iteration 335, loss = 0.17594869
Iteration 336, loss = 0.17503618
Iteration 337, loss = 0.17411999
Iteration 338, loss = 0.17321498
Iteration 339, loss = 0.17231381
Iteration 340, loss = 0.17141500
Iteration 341, loss = 0.17053721
Iteration 342, loss = 0.16965259
Iteration 343, loss = 0.16879789
Iteration 344, loss = 0.16793419
Iteration 345, loss = 0.16708588
Iteration 346, loss = 0.16624416
Iteration 347, loss = 0.16539817
Iteration 348, loss = 0.16457445
Iteration 349, loss = 0.16373022
Iteration 350, loss = 0.16290835
Iteration 351, loss = 0.16208846
Iteration 352, loss = 0.16128047
Iteration 353, loss = 0.16048706
Iteration 354, loss = 0.15969263
Iteration 355, loss = 0.15891164
Iteration 356, loss = 0.15814615
Iteration 357, loss = 0.15737699
Iteration 358, loss = 0.15661477
Iteration 359, loss = 0.15585978
Iteration 360, loss = 0.15510822
Iteration 361, loss = 0.15436757
Iteration 362, loss = 0.15363230
Iteration 363, loss = 0.15289838
Iteration 364, loss = 0.15217636
Iteration 365, loss = 0.15146071
Iteration 366, loss = 0.15073650
Iteration 367, loss = 0.15003454
Iteration 368, loss = 0.14933383
Iteration 369, loss = 0.14864243
Iteration 370, loss = 0.14795389
Iteration 371, loss = 0.14727939
Iteration 372, loss = 0.14660102
Iteration 373, loss = 0.14593400
Iteration 374, loss = 0.14525665
Iteration 375, loss = 0.14458991
Iteration 376, loss = 0.14392828
Iteration 377, loss = 0.14327211
Iteration 378, loss = 0.14262624
Iteration 379, loss = 0.14197411
Iteration 380, loss = 0.14133863
Iteration 381, loss = 0.14070416
Iteration 382, loss = 0.14007558
Iteration 383, loss = 0.13945560
Iteration 384, loss = 0.13883038
Iteration 385, loss = 0.13822192
Iteration 386, loss = 0.13760628
Iteration 387, loss = 0.13699539
Iteration 388, loss = 0.13638548
Iteration 389, loss = 0.13578724
Iteration 390, loss = 0.13518740
Iteration 391, loss = 0.13459209
Iteration 392, loss = 0.13400053
Iteration 393, loss = 0.13341660
Iteration 394, loss = 0.13284316
Iteration 395, loss = 0.13227157
Iteration 396, loss = 0.13170457
Iteration 397, loss = 0.13115422
Iteration 398, loss = 0.13059769
Iteration 399, loss = 0.13004618
Iteration 400, loss = 0.12950010
Iteration 401, loss = 0.12895406
Iteration 402, loss = 0.12842420
Iteration 403, loss = 0.12788999
Iteration 404, loss = 0.12736552
Iteration 405, loss = 0.12683707
Iteration 406, loss = 0.12632349
Iteration 407, loss = 0.12580757
Iteration 408, loss = 0.12529574
Iteration 409, loss = 0.12478917
Iteration 410, loss = 0.12428692
Iteration 411, loss = 0.12379033
Iteration 412, loss = 0.12329670
Iteration 413, loss = 0.12281758
Iteration 414, loss = 0.12232995
Iteration 415, loss = 0.12184557
Iteration 416, loss = 0.12137149
Iteration 417, loss = 0.12089305
Iteration 418, loss = 0.12042756
Iteration 419, loss = 0.11995400
Iteration 420, loss = 0.11949089
Iteration 421, loss = 0.11902391
Iteration 422, loss = 0.11856174
Iteration 423, loss = 0.11810043
Iteration 424, loss = 0.11764535
Iteration 425, loss = 0.11718926
Iteration 426, loss = 0.11673945
Iteration 427, loss = 0.11629696
Iteration 428, loss = 0.11586077
Iteration 429, loss = 0.11542308
Iteration 430, loss = 0.11499383
Iteration 431, loss = 0.11457233
Iteration 432, loss = 0.11414811
Iteration 433, loss = 0.11372029
Iteration 434, loss = 0.11329459
Iteration 435, loss = 0.11288617
Iteration 436, loss = 0.11246569
Iteration 437, loss = 0.11205250
Iteration 438, loss = 0.11164130
Iteration 439, loss = 0.11123479
Iteration 440, loss = 0.11082153
Iteration 441, loss = 0.11042075
Iteration 442, loss = 0.11002412
Iteration 443, loss = 0.10963202
Iteration 444, loss = 0.10924364
Iteration 445, loss = 0.10885569
Iteration 446, loss = 0.10847302
Iteration 447, loss = 0.10809977
Iteration 448, loss = 0.10770671
Iteration 449, loss = 0.10732517
Iteration 450, loss = 0.10694891
Iteration 451, loss = 0.10656509
Iteration 452, loss = 0.10619741
Iteration 453, loss = 0.10582501
Iteration 454, loss = 0.10546112
Iteration 455, loss = 0.10510474
Iteration 456, loss = 0.10473272
Iteration 457, loss = 0.10437680
Iteration 458, loss = 0.10401331
Iteration 459, loss = 0.10365321
Iteration 460, loss = 0.10330595
Iteration 461, loss = 0.10295105
Iteration 462, loss = 0.10260474
Iteration 463, loss = 0.10226170
Iteration 464, loss = 0.10191968
Iteration 465, loss = 0.10158580
Iteration 466, loss = 0.10125332
Iteration 467, loss = 0.10092659
Iteration 468, loss = 0.10059612
Iteration 469, loss = 0.10026812
Iteration 470, loss = 0.09993805
Iteration 471, loss = 0.09961980
Iteration 472, loss = 0.09928863
Iteration 473, loss = 0.09896686
Iteration 474, loss = 0.09863969
Iteration 475, loss = 0.09831674
Iteration 476, loss = 0.09800351
Iteration 477, loss = 0.09768675
Iteration 478, loss = 0.09736857
Iteration 479, loss = 0.09705604
Iteration 480, loss = 0.09674912
Iteration 481, loss = 0.09644819
Iteration 482, loss = 0.09613189
Iteration 483, loss = 0.09583490
Iteration 484, loss = 0.09553243
Iteration 485, loss = 0.09523256
Iteration 486, loss = 0.09492838
Iteration 487, loss = 0.09462564
Iteration 488, loss = 0.09433865
Iteration 489, loss = 0.09404648
Iteration 490, loss = 0.09375190
Iteration 491, loss = 0.09347227
Iteration 492, loss = 0.09318534
Iteration 493, loss = 0.09290186
Iteration 494, loss = 0.09261866
Iteration 495, loss = 0.09233797
Iteration 496, loss = 0.09206899
Iteration 497, loss = 0.09178797
Iteration 498, loss = 0.09153093
Iteration 499, loss = 0.09123934
Iteration 500, loss = 0.09096189
Iteration 501, loss = 0.09070152
Iteration 502, loss = 0.09041906
Iteration 503, loss = 0.09015142
Iteration 504, loss = 0.08988277
Iteration 505, loss = 0.08962013
Iteration 506, loss = 0.08935530
Iteration 507, loss = 0.08909500
Iteration 508, loss = 0.08883947
Iteration 509, loss = 0.08858170
Iteration 510, loss = 0.08832391
Iteration 511, loss = 0.08807236
Iteration 512, loss = 0.08781618
Iteration 513, loss = 0.08757358
Iteration 514, loss = 0.08732911
Iteration 515, loss = 0.08707026
Iteration 516, loss = 0.08682112
Iteration 517, loss = 0.08657185
Iteration 518, loss = 0.08632439
Iteration 519, loss = 0.08607691
Iteration 520, loss = 0.08583261
Iteration 521, loss = 0.08559421
Iteration 522, loss = 0.08534680
Iteration 523, loss = 0.08511190
Iteration 524, loss = 0.08486881
Iteration 525, loss = 0.08463610
Iteration 526, loss = 0.08440573
Iteration 527, loss = 0.08417593
Iteration 528, loss = 0.08394493
Iteration 529, loss = 0.08371817
Iteration 530, loss = 0.08348637
Iteration 531, loss = 0.08326338
Iteration 532, loss = 0.08303788
Iteration 533, loss = 0.08281447
Iteration 534, loss = 0.08259508
Iteration 535, loss = 0.08237923
Iteration 536, loss = 0.08216035
Iteration 537, loss = 0.08194631
Iteration 538, loss = 0.08173327
Iteration 539, loss = 0.08152103
Iteration 540, loss = 0.08131052
Iteration 541, loss = 0.08110305
Iteration 542, loss = 0.08089370
Iteration 543, loss = 0.08068483
Iteration 544, loss = 0.08048273
Iteration 545, loss = 0.08027867
Iteration 546, loss = 0.08006948
Iteration 547, loss = 0.07986896
Iteration 548, loss = 0.07966650
Iteration 549, loss = 0.07946477
Iteration 550, loss = 0.07926428
Iteration 551, loss = 0.07906279
Iteration 552, loss = 0.07886506
Iteration 553, loss = 0.07866605
Iteration 554, loss = 0.07847440
Iteration 555, loss = 0.07827734
Iteration 556, loss = 0.07809009
Iteration 557, loss = 0.07789832
Iteration 558, loss = 0.07771443
Iteration 559, loss = 0.07751784
Iteration 560, loss = 0.07733360
Iteration 561, loss = 0.07714563
Iteration 562, loss = 0.07695575
Iteration 563, loss = 0.07677219
Iteration 564, loss = 0.07658367
Iteration 565, loss = 0.07640447
Iteration 566, loss = 0.07621911
Iteration 567, loss = 0.07603179
Iteration 568, loss = 0.07585174
Iteration 569, loss = 0.07567297
Iteration 570, loss = 0.07549356
Iteration 571, loss = 0.07531308
Iteration 572, loss = 0.07513497
Iteration 573, loss = 0.07496337
Iteration 574, loss = 0.07478541
Iteration 575, loss = 0.07460768
Iteration 576, loss = 0.07442925
Iteration 577, loss = 0.07426048
Iteration 578, loss = 0.07408527
Iteration 579, loss = 0.07391602
Iteration 580, loss = 0.07374256
Iteration 581, loss = 0.07357691
Iteration 582, loss = 0.07340643
Iteration 583, loss = 0.07323739
Iteration 584, loss = 0.07307072
Iteration 585, loss = 0.07291408
Iteration 586, loss = 0.07274168
Iteration 587, loss = 0.07257263
Iteration 588, loss = 0.07240562
Iteration 589, loss = 0.07224141
Iteration 590, loss = 0.07207360
Iteration 591, loss = 0.07191428
Iteration 592, loss = 0.07174660
Iteration 593, loss = 0.07158857
Iteration 594, loss = 0.07142866
Iteration 595, loss = 0.07126798
Iteration 596, loss = 0.07110713
Iteration 597, loss = 0.07095211
Iteration 598, loss = 0.07079508
Iteration 599, loss = 0.07064212
Iteration 600, loss = 0.07048670
Iteration 601, loss = 0.07033101
Iteration 602, loss = 0.07017927
Iteration 603, loss = 0.07002355
Iteration 604, loss = 0.06986942
Iteration 605, loss = 0.06971459
Iteration 606, loss = 0.06956193
Iteration 607, loss = 0.06940616
Iteration 608, loss = 0.06926077
Iteration 609, loss = 0.06910622
Iteration 610, loss = 0.06895793
Iteration 611, loss = 0.06880261
Iteration 612, loss = 0.06865268
Iteration 613, loss = 0.06850293
Iteration 614, loss = 0.06835576
Iteration 615, loss = 0.06820605
Iteration 616, loss = 0.06805549
Iteration 617, loss = 0.06791188
Iteration 618, loss = 0.06777165
Iteration 619, loss = 0.06762025
Iteration 620, loss = 0.06747404
Iteration 621, loss = 0.06733422
Iteration 622, loss = 0.06719577
Iteration 623, loss = 0.06706446
Iteration 624, loss = 0.06692249
Iteration 625, loss = 0.06678124
Iteration 626, loss = 0.06664183
Iteration 627, loss = 0.06650205
Iteration 628, loss = 0.06636124
Iteration 629, loss = 0.06622334
Iteration 630, loss = 0.06608599
Iteration 631, loss = 0.06594960
Iteration 632, loss = 0.06581884
Iteration 633, loss = 0.06568493
Iteration 634, loss = 0.06555635
Iteration 635, loss = 0.06542549
Iteration 636, loss = 0.06529475
Iteration 637, loss = 0.06516204
Iteration 638, loss = 0.06503100
Iteration 639, loss = 0.06489838
Iteration 640, loss = 0.06476750
Iteration 641, loss = 0.06463522
Iteration 642, loss = 0.06450962
Iteration 643, loss = 0.06437266
Iteration 644, loss = 0.06424566
Iteration 645, loss = 0.06411398
Iteration 646, loss = 0.06398273
Iteration 647, loss = 0.06385218
Iteration 648, loss = 0.06372544
Iteration 649, loss = 0.06360000
Iteration 650, loss = 0.06347571
Iteration 651, loss = 0.06335666
Iteration 652, loss = 0.06323219
Iteration 653, loss = 0.06311312
Iteration 654, loss = 0.06298874
Iteration 655, loss = 0.06287246
Iteration 656, loss = 0.06274754
Iteration 657, loss = 0.06262394
Iteration 658, loss = 0.06250376
Iteration 659, loss = 0.06238450
Iteration 660, loss = 0.06226363
Iteration 661, loss = 0.06214822
Iteration 662, loss = 0.06203154
Iteration 663, loss = 0.06191643
Iteration 664, loss = 0.06179642
Iteration 665, loss = 0.06168391
Iteration 666, loss = 0.06156887
Iteration 667, loss = 0.06145335
Iteration 668, loss = 0.06134047
Iteration 669, loss = 0.06122593
Iteration 670, loss = 0.06111120
Iteration 671, loss = 0.06099997
Iteration 672, loss = 0.06088443
Iteration 673, loss = 0.06077067
Iteration 674, loss = 0.06065834
Iteration 675, loss = 0.06054828
Iteration 676, loss = 0.06043462
Iteration 677, loss = 0.06032430
Iteration 678, loss = 0.06021107
Iteration 679, loss = 0.06011046
Iteration 680, loss = 0.05999630
Iteration 681, loss = 0.05988659
Iteration 682, loss = 0.05977764
Iteration 683, loss = 0.05966714
Iteration 684, loss = 0.05955716
Iteration 685, loss = 0.05944862
Iteration 686, loss = 0.05933669
Iteration 687, loss = 0.05923535
Iteration 688, loss = 0.05912289
Iteration 689, loss = 0.05901540
Iteration 690, loss = 0.05890896
Iteration 691, loss = 0.05879971
Iteration 692, loss = 0.05869834
Iteration 693, loss = 0.05858581
Iteration 694, loss = 0.05848410
Iteration 695, loss = 0.05837475
Iteration 696, loss = 0.05826973
Iteration 697, loss = 0.05816688
Iteration 698, loss = 0.05806432
Iteration 699, loss = 0.05796757
Iteration 700, loss = 0.05786252
Iteration 701, loss = 0.05776347
Iteration 702, loss = 0.05766331
Iteration 703, loss = 0.05756797
Iteration 704, loss = 0.05746077
Iteration 705, loss = 0.05736170
Iteration 706, loss = 0.05726793
Iteration 707, loss = 0.05717066
Iteration 708, loss = 0.05707192
Iteration 709, loss = 0.05697576
Iteration 710, loss = 0.05687853
Iteration 711, loss = 0.05678453
Iteration 712, loss = 0.05668769
Iteration 713, loss = 0.05658858
Iteration 714, loss = 0.05649581
Iteration 715, loss = 0.05639350
Iteration 716, loss = 0.05629851
Iteration 717, loss = 0.05619764
Iteration 718, loss = 0.05610036
Iteration 719, loss = 0.05601001
Iteration 720, loss = 0.05590562
Iteration 721, loss = 0.05580785
Iteration 722, loss = 0.05571187
Iteration 723, loss = 0.05561457
Iteration 724, loss = 0.05552131
Iteration 725, loss = 0.05542761
Iteration 726, loss = 0.05533062
Iteration 727, loss = 0.05523774
Iteration 728, loss = 0.05515043
Iteration 729, loss = 0.05505180
Iteration 730, loss = 0.05495938
Iteration 731, loss = 0.05486658
Iteration 732, loss = 0.05477303
Iteration 733, loss = 0.05468536
Iteration 734, loss = 0.05459269
Iteration 735, loss = 0.05450321
Iteration 736, loss = 0.05442054
Iteration 737, loss = 0.05432982
Iteration 738, loss = 0.05423938
Iteration 739, loss = 0.05415132
Iteration 740, loss = 0.05407025
Iteration 741, loss = 0.05397661
Iteration 742, loss = 0.05388454
Iteration 743, loss = 0.05379963
Iteration 744, loss = 0.05371004
Iteration 745, loss = 0.05362337
Iteration 746, loss = 0.05353701
Iteration 747, loss = 0.05344679
Iteration 748, loss = 0.05336278
Iteration 749, loss = 0.05327330
Iteration 750, loss = 0.05318921
Iteration 751, loss = 0.05310085
Iteration 752, loss = 0.05301357
Iteration 753, loss = 0.05293019
Iteration 754, loss = 0.05284647
Iteration 755, loss = 0.05276274
Iteration 756, loss = 0.05267994
Iteration 757, loss = 0.05259613
Iteration 758, loss = 0.05251693
Iteration 759, loss = 0.05243637
Iteration 760, loss = 0.05236199
Iteration 761, loss = 0.05227570
Iteration 762, loss = 0.05219870
Iteration 763, loss = 0.05211626
Iteration 764, loss = 0.05203554
Iteration 765, loss = 0.05195432
Iteration 766, loss = 0.05187562
Iteration 767, loss = 0.05179395
Iteration 768, loss = 0.05171664
Iteration 769, loss = 0.05163492
Iteration 770, loss = 0.05155442
Iteration 771, loss = 0.05147876
Iteration 772, loss = 0.05139572
Iteration 773, loss = 0.05131464
Iteration 774, loss = 0.05123627
Iteration 775, loss = 0.05115379
Iteration 776, loss = 0.05107620
Iteration 777, loss = 0.05099917
Iteration 778, loss = 0.05091991
Iteration 779, loss = 0.05084595
Iteration 780, loss = 0.05076701
Iteration 781, loss = 0.05068422
Iteration 782, loss = 0.05060717
Iteration 783, loss = 0.05052739
Iteration 784, loss = 0.05045017
Iteration 785, loss = 0.05036761
Iteration 786, loss = 0.05029339
Iteration 787, loss = 0.05021375
Iteration 788, loss = 0.05013611
Iteration 789, loss = 0.05005718
Iteration 790, loss = 0.04998352
Iteration 791, loss = 0.04990617
Iteration 792, loss = 0.04983163
Iteration 793, loss = 0.04975793
Iteration 794, loss = 0.04968057
Iteration 795, loss = 0.04960622
Iteration 796, loss = 0.04953423
Iteration 797, loss = 0.04946434
Iteration 798, loss = 0.04938818
Iteration 799, loss = 0.04931606
Iteration 800, loss = 0.04924534
Iteration 801, loss = 0.04916717
Iteration 802, loss = 0.04909388
Iteration 803, loss = 0.04902171
Iteration 804, loss = 0.04894931
Iteration 805, loss = 0.04887930
Iteration 806, loss = 0.04880837
Iteration 807, loss = 0.04873857
Iteration 808, loss = 0.04866867
Iteration 809, loss = 0.04859959
Iteration 810, loss = 0.04853056
Iteration 811, loss = 0.04846475
Iteration 812, loss = 0.04838766
Iteration 813, loss = 0.04831968
Iteration 814, loss = 0.04824862
Iteration 815, loss = 0.04817873
Iteration 816, loss = 0.04810523
Iteration 817, loss = 0.04803494
Iteration 818, loss = 0.04796824
Iteration 819, loss = 0.04789210
Iteration 820, loss = 0.04782458
Iteration 821, loss = 0.04775088
Iteration 822, loss = 0.04768300
Iteration 823, loss = 0.04761408
Iteration 824, loss = 0.04754576
Iteration 825, loss = 0.04747370
Iteration 826, loss = 0.04740547
Iteration 827, loss = 0.04734239
Iteration 828, loss = 0.04726554
Iteration 829, loss = 0.04720235
Iteration 830, loss = 0.04713420
Iteration 831, loss = 0.04706825
Iteration 832, loss = 0.04700376
Iteration 833, loss = 0.04693945
Iteration 834, loss = 0.04687330
Iteration 835, loss = 0.04680659
Iteration 836, loss = 0.04674212
Iteration 837, loss = 0.04667786
Iteration 838, loss = 0.04661079
Iteration 839, loss = 0.04654487
Iteration 840, loss = 0.04648212
Iteration 841, loss = 0.04641612
Iteration 842, loss = 0.04635153
Iteration 843, loss = 0.04628735
Iteration 844, loss = 0.04622403
Iteration 845, loss = 0.04616137
Iteration 846, loss = 0.04609793
Iteration 847, loss = 0.04603750
Iteration 848, loss = 0.04597440
Iteration 849, loss = 0.04590974
Iteration 850, loss = 0.04585314
Iteration 851, loss = 0.04578715
Iteration 852, loss = 0.04572479
Iteration 853, loss = 0.04566300
Iteration 854, loss = 0.04560065
Iteration 855, loss = 0.04553867
Iteration 856, loss = 0.04547464
Iteration 857, loss = 0.04541755
Iteration 858, loss = 0.04535489
Iteration 859, loss = 0.04529626
Iteration 860, loss = 0.04523463
Iteration 861, loss = 0.04517183
Iteration 862, loss = 0.04510704
Iteration 863, loss = 0.04504762
Iteration 864, loss = 0.04498407
Iteration 865, loss = 0.04491965
Iteration 866, loss = 0.04486132
Iteration 867, loss = 0.04480027
Iteration 868, loss = 0.04474038
Iteration 869, loss = 0.04468156
Iteration 870, loss = 0.04462583
Iteration 871, loss = 0.04456976
Iteration 872, loss = 0.04451201
Iteration 873, loss = 0.04444977
Iteration 874, loss = 0.04439257
Iteration 875, loss = 0.04433488
Iteration 876, loss = 0.04427395
Iteration 877, loss = 0.04422423
Iteration 878, loss = 0.04416002
Iteration 879, loss = 0.04410099
Iteration 880, loss = 0.04404192
Iteration 881, loss = 0.04398802
Iteration 882, loss = 0.04392735
Iteration 883, loss = 0.04386983
Iteration 884, loss = 0.04381006
Iteration 885, loss = 0.04375216
Iteration 886, loss = 0.04369388
Iteration 887, loss = 0.04363764
Iteration 888, loss = 0.04358096
Iteration 889, loss = 0.04352113
Iteration 890, loss = 0.04346227
Iteration 891, loss = 0.04340492
Iteration 892, loss = 0.04334609
Iteration 893, loss = 0.04328768
Iteration 894, loss = 0.04323183
Iteration 895, loss = 0.04317023
Iteration 896, loss = 0.04311297
Iteration 897, loss = 0.04305734
Iteration 898, loss = 0.04299790
Iteration 899, loss = 0.04294100
Iteration 900, loss = 0.04288358
Iteration 901, loss = 0.04282936
Iteration 902, loss = 0.04277351
Iteration 903, loss = 0.04271794
Iteration 904, loss = 0.04266611
Iteration 905, loss = 0.04260467
Iteration 906, loss = 0.04254972
Iteration 907, loss = 0.04249306
Iteration 908, loss = 0.04243931
Iteration 909, loss = 0.04238494
Iteration 910, loss = 0.04233129
Iteration 911, loss = 0.04227678
Iteration 912, loss = 0.04222521
Iteration 913, loss = 0.04217102
Iteration 914, loss = 0.04211796
Iteration 915, loss = 0.04206869
Iteration 916, loss = 0.04201391
Iteration 917, loss = 0.04196330
Iteration 918, loss = 0.04191099
Iteration 919, loss = 0.04185591
Iteration 920, loss = 0.04180439
Iteration 921, loss = 0.04175158
Iteration 922, loss = 0.04169600
Iteration 923, loss = 0.04164291
Iteration 924, loss = 0.04159110
Iteration 925, loss = 0.04153746
Iteration 926, loss = 0.04148309
Iteration 927, loss = 0.04143081
Iteration 928, loss = 0.04137799
Iteration 929, loss = 0.04132845
Iteration 930, loss = 0.04127275
Iteration 931, loss = 0.04121885
Iteration 932, loss = 0.04116489
Iteration 933, loss = 0.04111284
Iteration 934, loss = 0.04106329
Iteration 935, loss = 0.04101305
Iteration 936, loss = 0.04096208
Iteration 937, loss = 0.04091687
Iteration 938, loss = 0.04086551
Iteration 939, loss = 0.04081353
Iteration 940, loss = 0.04076341
Iteration 941, loss = 0.04070906
Iteration 942, loss = 0.04066067
Iteration 943, loss = 0.04060822
Iteration 944, loss = 0.04056143
Iteration 945, loss = 0.04050730
Iteration 946, loss = 0.04045744
Iteration 947, loss = 0.04041125
Iteration 948, loss = 0.04035932
Iteration 949, loss = 0.04030816
Iteration 950, loss = 0.04025792
Iteration 951, loss = 0.04020312
Iteration 952, loss = 0.04015241
Iteration 953, loss = 0.04010123
Iteration 954, loss = 0.04005127
Iteration 955, loss = 0.04000115
Iteration 956, loss = 0.03995408
Iteration 957, loss = 0.03990352
Iteration 958, loss = 0.03985504
Iteration 959, loss = 0.03980684
Iteration 960, loss = 0.03976094
Iteration 961, loss = 0.03970963
Iteration 962, loss = 0.03966203
Iteration 963, loss = 0.03961460
Iteration 964, loss = 0.03956778
Iteration 965, loss = 0.03952035
Iteration 966, loss = 0.03947275
Iteration 967, loss = 0.03942556
Iteration 968, loss = 0.03937971
Iteration 969, loss = 0.03932918
Iteration 970, loss = 0.03928234
Iteration 971, loss = 0.03923669
Iteration 972, loss = 0.03918674
Iteration 973, loss = 0.03913820
Iteration 974, loss = 0.03909331
Iteration 975, loss = 0.03904750
Iteration 976, loss = 0.03899976
Iteration 977, loss = 0.03895250
Iteration 978, loss = 0.03890642
Iteration 979, loss = 0.03885999
Iteration 980, loss = 0.03881565
Iteration 981, loss = 0.03877065
Iteration 982, loss = 0.03872367
Iteration 983, loss = 0.03867836
Iteration 984, loss = 0.03863369
Iteration 985, loss = 0.03858913
Iteration 986, loss = 0.03854246
Iteration 987, loss = 0.03849710
Iteration 988, loss = 0.03845337
Iteration 989, loss = 0.03840988
Iteration 990, loss = 0.03837007
Iteration 991, loss = 0.03832613
Iteration 992, loss = 0.03827795
Iteration 993, loss = 0.03823410
Iteration 994, loss = 0.03818803
Iteration 995, loss = 0.03814044
Iteration 996, loss = 0.03809681
Iteration 997, loss = 0.03805269
Iteration 998, loss = 0.03800787
Iteration 999, loss = 0.03796226
Iteration 1000, loss = 0.03791599
Iteration 1001, loss = 0.03787624
Iteration 1002, loss = 0.03782880
Iteration 1003, loss = 0.03778525
Iteration 1004, loss = 0.03774283
Iteration 1005, loss = 0.03770076
Iteration 1006, loss = 0.03765914
Iteration 1007, loss = 0.03761813
Iteration 1008, loss = 0.03757357
Iteration 1009, loss = 0.03753106
Iteration 1010, loss = 0.03748876
Iteration 1011, loss = 0.03744512
Iteration 1012, loss = 0.03740492
Iteration 1013, loss = 0.03735794
Iteration 1014, loss = 0.03731888
Iteration 1015, loss = 0.03727764
Iteration 1016, loss = 0.03723656
Iteration 1017, loss = 0.03719480
Iteration 1018, loss = 0.03715606
Iteration 1019, loss = 0.03711432
Iteration 1020, loss = 0.03707440
Iteration 1021, loss = 0.03703415
Iteration 1022, loss = 0.03699532
Iteration 1023, loss = 0.03694936
Iteration 1024, loss = 0.03690732
Iteration 1025, loss = 0.03686434
Iteration 1026, loss = 0.03682200
Iteration 1027, loss = 0.03678005
Iteration 1028, loss = 0.03673706
Iteration 1029, loss = 0.03670060
Iteration 1030, loss = 0.03665630
Iteration 1031, loss = 0.03661492
Iteration 1032, loss = 0.03657420
Iteration 1033, loss = 0.03653447
Iteration 1034, loss = 0.03649239
Iteration 1035, loss = 0.03645053
Iteration 1036, loss = 0.03640985
Iteration 1037, loss = 0.03637067
Iteration 1038, loss = 0.03632882
Iteration 1039, loss = 0.03629186
Iteration 1040, loss = 0.03624545
Iteration 1041, loss = 0.03620668
Iteration 1042, loss = 0.03616242
Iteration 1043, loss = 0.03612383
Iteration 1044, loss = 0.03608249
Iteration 1045, loss = 0.03604245
Iteration 1046, loss = 0.03600437
Iteration 1047, loss = 0.03596413
Iteration 1048, loss = 0.03592496
Iteration 1049, loss = 0.03588650
Iteration 1050, loss = 0.03584659
Iteration 1051, loss = 0.03580584
Iteration 1052, loss = 0.03576660
Iteration 1053, loss = 0.03572939
Iteration 1054, loss = 0.03568928
Iteration 1055, loss = 0.03564988
Iteration 1056, loss = 0.03561029
Iteration 1057, loss = 0.03557336
Iteration 1058, loss = 0.03553561
Iteration 1059, loss = 0.03549933
Iteration 1060, loss = 0.03546077
Iteration 1061, loss = 0.03542096
Iteration 1062, loss = 0.03538014
Iteration 1063, loss = 0.03534222
Iteration 1064, loss = 0.03530298
Iteration 1065, loss = 0.03526514
Iteration 1066, loss = 0.03522552
Iteration 1067, loss = 0.03518546
Iteration 1068, loss = 0.03515068
Iteration 1069, loss = 0.03511382
Iteration 1070, loss = 0.03507658
Iteration 1071, loss = 0.03504083
Iteration 1072, loss = 0.03500476
Iteration 1073, loss = 0.03496609
Iteration 1074, loss = 0.03493041
Iteration 1075, loss = 0.03489360
Iteration 1076, loss = 0.03485626
Iteration 1077, loss = 0.03482217
Iteration 1078, loss = 0.03478304
Iteration 1079, loss = 0.03474487
Iteration 1080, loss = 0.03470688
Iteration 1081, loss = 0.03466982
Iteration 1082, loss = 0.03463361
Iteration 1083, loss = 0.03459067
Iteration 1084, loss = 0.03455416
Iteration 1085, loss = 0.03451746
Iteration 1086, loss = 0.03447986
Iteration 1087, loss = 0.03444523
Iteration 1088, loss = 0.03440995
Iteration 1089, loss = 0.03437277
Iteration 1090, loss = 0.03433672
Iteration 1091, loss = 0.03430188
Iteration 1092, loss = 0.03426677
Iteration 1093, loss = 0.03423085
Iteration 1094, loss = 0.03419716
Iteration 1095, loss = 0.03415903
Iteration 1096, loss = 0.03412669
Iteration 1097, loss = 0.03409005
Iteration 1098, loss = 0.03405329
Iteration 1099, loss = 0.03401511
Iteration 1100, loss = 0.03398115
Iteration 1101, loss = 0.03394434
Iteration 1102, loss = 0.03390963
Iteration 1103, loss = 0.03387570
Iteration 1104, loss = 0.03384013
Iteration 1105, loss = 0.03380860
Iteration 1106, loss = 0.03377420
Iteration 1107, loss = 0.03374011
Iteration 1108, loss = 0.03370531
Iteration 1109, loss = 0.03367380
Iteration 1110, loss = 0.03364162
Iteration 1111, loss = 0.03360627
Iteration 1112, loss = 0.03357036
Iteration 1113, loss = 0.03353657
Iteration 1114, loss = 0.03349949
Iteration 1115, loss = 0.03346698
Iteration 1116, loss = 0.03343106
Iteration 1117, loss = 0.03339205
Iteration 1118, loss = 0.03336147
Iteration 1119, loss = 0.03332513
Iteration 1120, loss = 0.03329135
Iteration 1121, loss = 0.03325701
Iteration 1122, loss = 0.03322563
Iteration 1123, loss = 0.03319146
Iteration 1124, loss = 0.03315615
Iteration 1125, loss = 0.03312428
Iteration 1126, loss = 0.03309011
Iteration 1127, loss = 0.03305744
Iteration 1128, loss = 0.03302321
Iteration 1129, loss = 0.03299141
Iteration 1130, loss = 0.03295738
Iteration 1131, loss = 0.03292549
Iteration 1132, loss = 0.03289395
Iteration 1133, loss = 0.03285954
Iteration 1134, loss = 0.03282834
Iteration 1135, loss = 0.03279362
Iteration 1136, loss = 0.03276095
Iteration 1137, loss = 0.03272665
Iteration 1138, loss = 0.03269470
Iteration 1139, loss = 0.03266407
Iteration 1140, loss = 0.03263284
Iteration 1141, loss = 0.03260069
Iteration 1142, loss = 0.03256811
Iteration 1143, loss = 0.03253319
Iteration 1144, loss = 0.03250123
Iteration 1145, loss = 0.03246990
Iteration 1146, loss = 0.03244071
Iteration 1147, loss = 0.03241113
Iteration 1148, loss = 0.03237817
Iteration 1149, loss = 0.03234656
Iteration 1150, loss = 0.03231539
Iteration 1151, loss = 0.03228488
Iteration 1152, loss = 0.03225377
Iteration 1153, loss = 0.03222263
Iteration 1154, loss = 0.03219271
Iteration 1155, loss = 0.03216258
Iteration 1156, loss = 0.03213276
Iteration 1157, loss = 0.03210322
Iteration 1158, loss = 0.03207301
Iteration 1159, loss = 0.03204444
Iteration 1160, loss = 0.03201518
Iteration 1161, loss = 0.03198794
Iteration 1162, loss = 0.03195581
Iteration 1163, loss = 0.03192637
Iteration 1164, loss = 0.03189597
Iteration 1165, loss = 0.03186724
Iteration 1166, loss = 0.03183647
Iteration 1167, loss = 0.03180652
Iteration 1168, loss = 0.03177767
Iteration 1169, loss = 0.03174913
Iteration 1170, loss = 0.03171731
Iteration 1171, loss = 0.03168809
Iteration 1172, loss = 0.03165614
Iteration 1173, loss = 0.03161996
Iteration 1174, loss = 0.03158791
Iteration 1175, loss = 0.03155588
Iteration 1176, loss = 0.03152187
Iteration 1177, loss = 0.03148994
Iteration 1178, loss = 0.03145852
Iteration 1179, loss = 0.03142595
Iteration 1180, loss = 0.03139486
Iteration 1181, loss = 0.03136331
Iteration 1182, loss = 0.03133289
Iteration 1183, loss = 0.03130217
Iteration 1184, loss = 0.03127256
Iteration 1185, loss = 0.03124263
Iteration 1186, loss = 0.03121470
Iteration 1187, loss = 0.03118456
Iteration 1188, loss = 0.03115599
Iteration 1189, loss = 0.03112739
Iteration 1190, loss = 0.03109862
Iteration 1191, loss = 0.03107366
Iteration 1192, loss = 0.03104689
Iteration 1193, loss = 0.03101549
Iteration 1194, loss = 0.03098791
Iteration 1195, loss = 0.03095690
Iteration 1196, loss = 0.03092579
Iteration 1197, loss = 0.03089630
Iteration 1198, loss = 0.03086391
Iteration 1199, loss = 0.03083480
Iteration 1200, loss = 0.03080605
Iteration 1201, loss = 0.03077605
Iteration 1202, loss = 0.03074597
Iteration 1203, loss = 0.03071690
Iteration 1204, loss = 0.03068770
Iteration 1205, loss = 0.03065524
Iteration 1206, loss = 0.03062256
Iteration 1207, loss = 0.03059148
Iteration 1208, loss = 0.03056186
Iteration 1209, loss = 0.03053182
Iteration 1210, loss = 0.03050161
Iteration 1211, loss = 0.03046830
Iteration 1212, loss = 0.03044224
Iteration 1213, loss = 0.03040939
Iteration 1214, loss = 0.03038111
Iteration 1215, loss = 0.03035190
Iteration 1216, loss = 0.03032394
Iteration 1217, loss = 0.03029045
Iteration 1218, loss = 0.03026326
Iteration 1219, loss = 0.03023256
Iteration 1220, loss = 0.03020189
Iteration 1221, loss = 0.03017518
Iteration 1222, loss = 0.03014388
Iteration 1223, loss = 0.03011337
Iteration 1224, loss = 0.03008630
Iteration 1225, loss = 0.03005301
Iteration 1226, loss = 0.03002774
Iteration 1227, loss = 0.02999942
Iteration 1228, loss = 0.02996593
Iteration 1229, loss = 0.02993603
Iteration 1230, loss = 0.02990797
Iteration 1231, loss = 0.02987847
Iteration 1232, loss = 0.02984863
Iteration 1233, loss = 0.02982033
Iteration 1234, loss = 0.02979221
Iteration 1235, loss = 0.02976505
Iteration 1236, loss = 0.02973736
Iteration 1237, loss = 0.02971369
Iteration 1238, loss = 0.02968266
Iteration 1239, loss = 0.02965354
Iteration 1240, loss = 0.02962738
Iteration 1241, loss = 0.02959948
Iteration 1242, loss = 0.02956755
Iteration 1243, loss = 0.02954516
Iteration 1244, loss = 0.02951965
Iteration 1245, loss = 0.02948737
Iteration 1246, loss = 0.02945859
Iteration 1247, loss = 0.02943162
Iteration 1248, loss = 0.02940382
Iteration 1249, loss = 0.02937607
Iteration 1250, loss = 0.02935003
Iteration 1251, loss = 0.02932089
Iteration 1252, loss = 0.02929518
Iteration 1253, loss = 0.02926788
Iteration 1254, loss = 0.02924406
Iteration 1255, loss = 0.02921333
Iteration 1256, loss = 0.02918732
Iteration 1257, loss = 0.02915770
Iteration 1258, loss = 0.02912998
Iteration 1259, loss = 0.02910714
Iteration 1260, loss = 0.02907662
Iteration 1261, loss = 0.02905173
Iteration 1262, loss = 0.02902442
Iteration 1263, loss = 0.02899795
Iteration 1264, loss = 0.02897091
Iteration 1265, loss = 0.02894511
Iteration 1266, loss = 0.02891816
Iteration 1267, loss = 0.02889256
Iteration 1268, loss = 0.02886542
Iteration 1269, loss = 0.02883775
Iteration 1270, loss = 0.02881094
Iteration 1271, loss = 0.02878244
Iteration 1272, loss = 0.02875650
Iteration 1273, loss = 0.02873085
Iteration 1274, loss = 0.02870357
Iteration 1275, loss = 0.02867880
Iteration 1276, loss = 0.02865305
Iteration 1277, loss = 0.02862761
Iteration 1278, loss = 0.02860462
Iteration 1279, loss = 0.02857825
Iteration 1280, loss = 0.02855367
Iteration 1281, loss = 0.02852989
Iteration 1282, loss = 0.02850489
Iteration 1283, loss = 0.02848021
Iteration 1284, loss = 0.02845458
Iteration 1285, loss = 0.02843003
Iteration 1286, loss = 0.02840860
Iteration 1287, loss = 0.02838235
Iteration 1288, loss = 0.02835530
Iteration 1289, loss = 0.02833147
Iteration 1290, loss = 0.02830592
Iteration 1291, loss = 0.02828135
Iteration 1292, loss = 0.02825464
Iteration 1293, loss = 0.02822887
Iteration 1294, loss = 0.02820385
Iteration 1295, loss = 0.02817433
Iteration 1296, loss = 0.02815114
Iteration 1297, loss = 0.02811991
Iteration 1298, loss = 0.02809413
Iteration 1299, loss = 0.02806581
Iteration 1300, loss = 0.02803886
Iteration 1301, loss = 0.02801215
Iteration 1302, loss = 0.02798593
Iteration 1303, loss = 0.02796059
Iteration 1304, loss = 0.02793421
Iteration 1305, loss = 0.02790737
Iteration 1306, loss = 0.02788153
Iteration 1307, loss = 0.02785528
Iteration 1308, loss = 0.02782965
Iteration 1309, loss = 0.02780553
Iteration 1310, loss = 0.02778033
Iteration 1311, loss = 0.02775539
Iteration 1312, loss = 0.02773307
Iteration 1313, loss = 0.02770609
Iteration 1314, loss = 0.02767922
Iteration 1315, loss = 0.02765568
Iteration 1316, loss = 0.02763102
Iteration 1317, loss = 0.02760592
Iteration 1318, loss = 0.02758246
Iteration 1319, loss = 0.02755997
Iteration 1320, loss = 0.02753124
Iteration 1321, loss = 0.02750645
Iteration 1322, loss = 0.02747960
Iteration 1323, loss = 0.02745824
Iteration 1324, loss = 0.02743119
Iteration 1325, loss = 0.02740717
Iteration 1326, loss = 0.02738342
Iteration 1327, loss = 0.02736272
Iteration 1328, loss = 0.02733399
Iteration 1329, loss = 0.02730806
Iteration 1330, loss = 0.02728496
Iteration 1331, loss = 0.02726626
Iteration 1332, loss = 0.02723542
Iteration 1333, loss = 0.02720759
Iteration 1334, loss = 0.02718801
Iteration 1335, loss = 0.02716251
Iteration 1336, loss = 0.02713579
Iteration 1337, loss = 0.02711417
Iteration 1338, loss = 0.02708747
Iteration 1339, loss = 0.02706441
Iteration 1340, loss = 0.02704077
Iteration 1341, loss = 0.02701659
Iteration 1342, loss = 0.02699272
Iteration 1343, loss = 0.02696914
Iteration 1344, loss = 0.02695111
Iteration 1345, loss = 0.02692561
Iteration 1346, loss = 0.02690219
Iteration 1347, loss = 0.02688035
Iteration 1348, loss = 0.02685779
Iteration 1349, loss = 0.02683553
Iteration 1350, loss = 0.02681309
Iteration 1351, loss = 0.02678914
Iteration 1352, loss = 0.02676567
Iteration 1353, loss = 0.02674174
Iteration 1354, loss = 0.02671897
Iteration 1355, loss = 0.02669563
Iteration 1356, loss = 0.02667342
Iteration 1357, loss = 0.02665079
Iteration 1358, loss = 0.02662886
Iteration 1359, loss = 0.02660975
Iteration 1360, loss = 0.02658318
Iteration 1361, loss = 0.02656115
Iteration 1362, loss = 0.02653779
Iteration 1363, loss = 0.02651454
Iteration 1364, loss = 0.02649010
Iteration 1365, loss = 0.02646670
Iteration 1366, loss = 0.02644510
Iteration 1367, loss = 0.02642167
Iteration 1368, loss = 0.02639845
Iteration 1369, loss = 0.02637594
Iteration 1370, loss = 0.02635341
Iteration 1371, loss = 0.02633149
Iteration 1372, loss = 0.02630822
Iteration 1373, loss = 0.02628664
Iteration 1374, loss = 0.02626392
Iteration 1375, loss = 0.02624167
Iteration 1376, loss = 0.02622014
Iteration 1377, loss = 0.02619912
Iteration 1378, loss = 0.02618118
Iteration 1379, loss = 0.02615685
Iteration 1380, loss = 0.02613430
Iteration 1381, loss = 0.02611300
Iteration 1382, loss = 0.02609196
Iteration 1383, loss = 0.02606849
Iteration 1384, loss = 0.02604565
Iteration 1385, loss = 0.02602123
Iteration 1386, loss = 0.02599685
Iteration 1387, loss = 0.02597461
Iteration 1388, loss = 0.02595064
Iteration 1389, loss = 0.02592882
Iteration 1390, loss = 0.02590597
Iteration 1391, loss = 0.02588316
Iteration 1392, loss = 0.02586080
Iteration 1393, loss = 0.02583730
Iteration 1394, loss = 0.02581672
Iteration 1395, loss = 0.02579586
Iteration 1396, loss = 0.02577628
Iteration 1397, loss = 0.02575474
Iteration 1398, loss = 0.02573172
Iteration 1399, loss = 0.02571051
Iteration 1400, loss = 0.02568896
Iteration 1401, loss = 0.02566967
Iteration 1402, loss = 0.02564489
Iteration 1403, loss = 0.02562322
Iteration 1404, loss = 0.02560105
Iteration 1405, loss = 0.02558076
Iteration 1406, loss = 0.02555953
Iteration 1407, loss = 0.02553873
Iteration 1408, loss = 0.02551927
Iteration 1409, loss = 0.02549986
Iteration 1410, loss = 0.02547670
Iteration 1411, loss = 0.02545656
Iteration 1412, loss = 0.02543611
Iteration 1413, loss = 0.02541724
Iteration 1414, loss = 0.02539631
Iteration 1415, loss = 0.02537529
Iteration 1416, loss = 0.02535553
Iteration 1417, loss = 0.02533486
Iteration 1418, loss = 0.02531459
Iteration 1419, loss = 0.02529437
Iteration 1420, loss = 0.02527508
Iteration 1421, loss = 0.02525089
Iteration 1422, loss = 0.02522999
Iteration 1423, loss = 0.02520953
Iteration 1424, loss = 0.02518674
Iteration 1425, loss = 0.02516637
Iteration 1426, loss = 0.02514632
Iteration 1427, loss = 0.02512612
Iteration 1428, loss = 0.02510915
Iteration 1429, loss = 0.02508522
Iteration 1430, loss = 0.02506186
Iteration 1431, loss = 0.02504247
Iteration 1432, loss = 0.02501958
Iteration 1433, loss = 0.02499872
Iteration 1434, loss = 0.02497633
Iteration 1435, loss = 0.02496029
Iteration 1436, loss = 0.02493632
Iteration 1437, loss = 0.02491526
Iteration 1438, loss = 0.02489668
Iteration 1439, loss = 0.02487445
Iteration 1440, loss = 0.02485874
Iteration 1441, loss = 0.02483448
Iteration 1442, loss = 0.02481332
Iteration 1443, loss = 0.02479307
Iteration 1444, loss = 0.02477437
Iteration 1445, loss = 0.02475425
Iteration 1446, loss = 0.02473587
Iteration 1447, loss = 0.02471291
Iteration 1448, loss = 0.02469391
Iteration 1449, loss = 0.02467515
Iteration 1450, loss = 0.02465526
Iteration 1451, loss = 0.02463624
Iteration 1452, loss = 0.02461593
Iteration 1453, loss = 0.02459696
Iteration 1454, loss = 0.02457792
Iteration 1455, loss = 0.02455765
Iteration 1456, loss = 0.02453759
Iteration 1457, loss = 0.02451831
Iteration 1458, loss = 0.02449857
Iteration 1459, loss = 0.02447998
Iteration 1460, loss = 0.02445861
Iteration 1461, loss = 0.02443858
Iteration 1462, loss = 0.02441856
Iteration 1463, loss = 0.02440052
Iteration 1464, loss = 0.02437874
Iteration 1465, loss = 0.02435816
Iteration 1466, loss = 0.02433808
Iteration 1467, loss = 0.02431843
Iteration 1468, loss = 0.02429946
Iteration 1469, loss = 0.02428007
Iteration 1470, loss = 0.02425950
Iteration 1471, loss = 0.02424148
Iteration 1472, loss = 0.02421849
Iteration 1473, loss = 0.02419907
Iteration 1474, loss = 0.02418072
Iteration 1475, loss = 0.02416416
Iteration 1476, loss = 0.02414208
Iteration 1477, loss = 0.02412328
Iteration 1478, loss = 0.02410431
Iteration 1479, loss = 0.02408476
Iteration 1480, loss = 0.02406918
Iteration 1481, loss = 0.02404870
Iteration 1482, loss = 0.02403001
Iteration 1483, loss = 0.02400859
Iteration 1484, loss = 0.02398867
Iteration 1485, loss = 0.02397129
Iteration 1486, loss = 0.02395153
Iteration 1487, loss = 0.02393275
Iteration 1488, loss = 0.02391240
Iteration 1489, loss = 0.02389384
Iteration 1490, loss = 0.02387534
Iteration 1491, loss = 0.02385785
Iteration 1492, loss = 0.02383771
Iteration 1493, loss = 0.02381948
Iteration 1494, loss = 0.02380080
Iteration 1495, loss = 0.02378274
Iteration 1496, loss = 0.02376373
Iteration 1497, loss = 0.02374519
Iteration 1498, loss = 0.02372567
Iteration 1499, loss = 0.02370675
Iteration 1500, loss = 0.02368653
Iteration 1501, loss = 0.02366838
Iteration 1502, loss = 0.02364971
Iteration 1503, loss = 0.02363136
Iteration 1504, loss = 0.02361140
Iteration 1505, loss = 0.02359355
Iteration 1506, loss = 0.02357489
Iteration 1507, loss = 0.02355503
Iteration 1508, loss = 0.02353374
Iteration 1509, loss = 0.02351588
Iteration 1510, loss = 0.02349654
Iteration 1511, loss = 0.02347511
Iteration 1512, loss = 0.02345899
Iteration 1513, loss = 0.02343995
Iteration 1514, loss = 0.02342130
Iteration 1515, loss = 0.02340497
Iteration 1516, loss = 0.02338551
Iteration 1517, loss = 0.02336794
Iteration 1518, loss = 0.02334970
Iteration 1519, loss = 0.02333244
Iteration 1520, loss = 0.02331436
Iteration 1521, loss = 0.02329742
Iteration 1522, loss = 0.02327951
Iteration 1523, loss = 0.02326083
Iteration 1524, loss = 0.02324273
Iteration 1525, loss = 0.02322372
Iteration 1526, loss = 0.02320442
Iteration 1527, loss = 0.02318504
Iteration 1528, loss = 0.02316922
Iteration 1529, loss = 0.02314727
Iteration 1530, loss = 0.02313109
Iteration 1531, loss = 0.02311117
Iteration 1532, loss = 0.02309438
Iteration 1533, loss = 0.02307783
Iteration 1534, loss = 0.02305865
Iteration 1535, loss = 0.02304253
Iteration 1536, loss = 0.02302469
Iteration 1537, loss = 0.02300655
Iteration 1538, loss = 0.02299049
Iteration 1539, loss = 0.02297330
Iteration 1540, loss = 0.02295298
Iteration 1541, loss = 0.02293547
Iteration 1542, loss = 0.02291816
Iteration 1543, loss = 0.02290048
Iteration 1544, loss = 0.02288449
Iteration 1545, loss = 0.02286656
Iteration 1546, loss = 0.02284948
Iteration 1547, loss = 0.02283570
Iteration 1548, loss = 0.02281600
Iteration 1549, loss = 0.02279840
Iteration 1550, loss = 0.02278179
Iteration 1551, loss = 0.02276531
Iteration 1552, loss = 0.02274767
Iteration 1553, loss = 0.02273109
Iteration 1554, loss = 0.02271223
Iteration 1555, loss = 0.02269541
Iteration 1556, loss = 0.02267838
Iteration 1557, loss = 0.02266145
Iteration 1558, loss = 0.02264351
Iteration 1559, loss = 0.02262658
Iteration 1560, loss = 0.02261131
Iteration 1561, loss = 0.02259314
Iteration 1562, loss = 0.02257517
Iteration 1563, loss = 0.02255805
Iteration 1564, loss = 0.02254128
Iteration 1565, loss = 0.02252611
Iteration 1566, loss = 0.02250975
Iteration 1567, loss = 0.02249203
Iteration 1568, loss = 0.02247833
Iteration 1569, loss = 0.02245891
Iteration 1570, loss = 0.02244391
Iteration 1571, loss = 0.02242592
Iteration 1572, loss = 0.02240836
Iteration 1573, loss = 0.02238998
Iteration 1574, loss = 0.02237116
Iteration 1575, loss = 0.02235840
Iteration 1576, loss = 0.02233687
Iteration 1577, loss = 0.02232045
Iteration 1578, loss = 0.02230231
Iteration 1579, loss = 0.02228507
Iteration 1580, loss = 0.02226759
Iteration 1581, loss = 0.02225069
Iteration 1582, loss = 0.02223509
Iteration 1583, loss = 0.02221803
Iteration 1584, loss = 0.02220134
Iteration 1585, loss = 0.02218602
Iteration 1586, loss = 0.02216965
Iteration 1587, loss = 0.02215485
Iteration 1588, loss = 0.02213752
Iteration 1589, loss = 0.02212149
Iteration 1590, loss = 0.02210580
Iteration 1591, loss = 0.02209019
Iteration 1592, loss = 0.02207249
Iteration 1593, loss = 0.02205603
Iteration 1594, loss = 0.02204009
Iteration 1595, loss = 0.02202378
Iteration 1596, loss = 0.02201000
Iteration 1597, loss = 0.02199150
Iteration 1598, loss = 0.02197369
Iteration 1599, loss = 0.02195638
Iteration 1600, loss = 0.02194156
Iteration 1601, loss = 0.02192277
Iteration 1602, loss = 0.02190631
Iteration 1603, loss = 0.02188938
Iteration 1604, loss = 0.02187271
Iteration 1605, loss = 0.02185585
Iteration 1606, loss = 0.02184116
Iteration 1607, loss = 0.02182380
Iteration 1608, loss = 0.02180485
Iteration 1609, loss = 0.02178759
Iteration 1610, loss = 0.02177159
Iteration 1611, loss = 0.02175719
Iteration 1612, loss = 0.02173922
Iteration 1613, loss = 0.02172407
Iteration 1614, loss = 0.02170940
Iteration 1615, loss = 0.02169206
Iteration 1616, loss = 0.02167551
Iteration 1617, loss = 0.02166388
Iteration 1618, loss = 0.02164471
Iteration 1619, loss = 0.02162822
Iteration 1620, loss = 0.02161453
Iteration 1621, loss = 0.02159625
Iteration 1622, loss = 0.02157956
Iteration 1623, loss = 0.02156552
Iteration 1624, loss = 0.02154709
Iteration 1625, loss = 0.02153090
Iteration 1626, loss = 0.02151371
Iteration 1627, loss = 0.02149705
Iteration 1628, loss = 0.02148126
Iteration 1629, loss = 0.02146376
Iteration 1630, loss = 0.02144842
Iteration 1631, loss = 0.02143120
Iteration 1632, loss = 0.02141345
Iteration 1633, loss = 0.02139744
Iteration 1634, loss = 0.02138015
Iteration 1635, loss = 0.02136444
Iteration 1636, loss = 0.02134685
Iteration 1637, loss = 0.02133130
Iteration 1638, loss = 0.02131475
Iteration 1639, loss = 0.02129757
Iteration 1640, loss = 0.02128347
Iteration 1641, loss = 0.02126788
Iteration 1642, loss = 0.02125076
Iteration 1643, loss = 0.02123496
Iteration 1644, loss = 0.02121929
Iteration 1645, loss = 0.02120396
Iteration 1646, loss = 0.02118889
Iteration 1647, loss = 0.02117327
Iteration 1648, loss = 0.02115856
Iteration 1649, loss = 0.02114283
Iteration 1650, loss = 0.02112729
Iteration 1651, loss = 0.02111237
Iteration 1652, loss = 0.02109593
Iteration 1653, loss = 0.02108081
Iteration 1654, loss = 0.02106587
Iteration 1655, loss = 0.02105323
Iteration 1656, loss = 0.02103686
Iteration 1657, loss = 0.02102026
Iteration 1658, loss = 0.02100335
Iteration 1659, loss = 0.02098801
Iteration 1660, loss = 0.02097254
Iteration 1661, loss = 0.02095953
Iteration 1662, loss = 0.02094118
Iteration 1663, loss = 0.02092646
Iteration 1664, loss = 0.02091175
Iteration 1665, loss = 0.02089627
Iteration 1666, loss = 0.02088064
Iteration 1667, loss = 0.02086678
Iteration 1668, loss = 0.02085280
Iteration 1669, loss = 0.02083825
Iteration 1670, loss = 0.02082198
Iteration 1671, loss = 0.02080680
Iteration 1672, loss = 0.02079114
Iteration 1673, loss = 0.02077625
Iteration 1674, loss = 0.02076148
Iteration 1675, loss = 0.02074989
Iteration 1676, loss = 0.02073314
Iteration 1677, loss = 0.02071917
Iteration 1678, loss = 0.02070183
Iteration 1679, loss = 0.02068690
Iteration 1680, loss = 0.02067192
Iteration 1681, loss = 0.02065651
Iteration 1682, loss = 0.02064101
Iteration 1683, loss = 0.02062788
Iteration 1684, loss = 0.02061185
Iteration 1685, loss = 0.02059861
Iteration 1686, loss = 0.02058161
Iteration 1687, loss = 0.02056621
Iteration 1688, loss = 0.02055182
Iteration 1689, loss = 0.02053762
Iteration 1690, loss = 0.02052436
Iteration 1691, loss = 0.02050885
Iteration 1692, loss = 0.02049482
Iteration 1693, loss = 0.02047958
Iteration 1694, loss = 0.02046522
Iteration 1695, loss = 0.02045063
Iteration 1696, loss = 0.02043735
Iteration 1697, loss = 0.02042042
Iteration 1698, loss = 0.02040730
Iteration 1699, loss = 0.02039344
Iteration 1700, loss = 0.02037702
Iteration 1701, loss = 0.02036127
Iteration 1702, loss = 0.02034649
Iteration 1703, loss = 0.02033099
Iteration 1704, loss = 0.02031896
Iteration 1705, loss = 0.02030121
Iteration 1706, loss = 0.02028702
Iteration 1707, loss = 0.02027126
Iteration 1708, loss = 0.02025690
Iteration 1709, loss = 0.02024125
Iteration 1710, loss = 0.02022784
Iteration 1711, loss = 0.02021201
Iteration 1712, loss = 0.02019901
Iteration 1713, loss = 0.02018276
Iteration 1714, loss = 0.02016750
Iteration 1715, loss = 0.02015478
Iteration 1716, loss = 0.02014048
Iteration 1717, loss = 0.02012407
Iteration 1718, loss = 0.02011218
Iteration 1719, loss = 0.02009535
Iteration 1720, loss = 0.02008245
Iteration 1721, loss = 0.02006646
Iteration 1722, loss = 0.02005289
Iteration 1723, loss = 0.02003855
Iteration 1724, loss = 0.02002565
Iteration 1725, loss = 0.02001007
Iteration 1726, loss = 0.01999618
Iteration 1727, loss = 0.01998247
Iteration 1728, loss = 0.01996958
Iteration 1729, loss = 0.01995383
Iteration 1730, loss = 0.01993929
Iteration 1731, loss = 0.01992513
Iteration 1732, loss = 0.01991219
Iteration 1733, loss = 0.01989641
Iteration 1734, loss = 0.01988150
Iteration 1735, loss = 0.01986736
Iteration 1736, loss = 0.01985148
Iteration 1737, loss = 0.01983616
Iteration 1738, loss = 0.01982056
Iteration 1739, loss = 0.01980767
Iteration 1740, loss = 0.01979193
Iteration 1741, loss = 0.01977609
Iteration 1742, loss = 0.01976004
Iteration 1743, loss = 0.01974562
Iteration 1744, loss = 0.01973142
Iteration 1745, loss = 0.01971711
Iteration 1746, loss = 0.01970224
Iteration 1747, loss = 0.01968984
Iteration 1748, loss = 0.01967489
Iteration 1749, loss = 0.01966338
Iteration 1750, loss = 0.01964890
Iteration 1751, loss = 0.01963518
Iteration 1752, loss = 0.01962144
Iteration 1753, loss = 0.01960794
Iteration 1754, loss = 0.01959467
Iteration 1755, loss = 0.01958214
Iteration 1756, loss = 0.01957050
Iteration 1757, loss = 0.01955555
Iteration 1758, loss = 0.01954284
Iteration 1759, loss = 0.01953059
Iteration 1760, loss = 0.01951676
Iteration 1761, loss = 0.01950466
Iteration 1762, loss = 0.01949129
Iteration 1763, loss = 0.01947846
Iteration 1764, loss = 0.01946676
Iteration 1765, loss = 0.01945426
Iteration 1766, loss = 0.01944121
Iteration 1767, loss = 0.01942739
Iteration 1768, loss = 0.01941443
Iteration 1769, loss = 0.01940014
Iteration 1770, loss = 0.01938732
Iteration 1771, loss = 0.01937367
Iteration 1772, loss = 0.01935949
Iteration 1773, loss = 0.01934739
Iteration 1774, loss = 0.01933325
Iteration 1775, loss = 0.01931939
Iteration 1776, loss = 0.01930550
Iteration 1777, loss = 0.01929161
Iteration 1778, loss = 0.01927907
Iteration 1779, loss = 0.01926518
Iteration 1780, loss = 0.01925142
Iteration 1781, loss = 0.01923568
Iteration 1782, loss = 0.01921998
Iteration 1783, loss = 0.01920729
Iteration 1784, loss = 0.01919598
Iteration 1785, loss = 0.01917902
Iteration 1786, loss = 0.01916687
Iteration 1787, loss = 0.01915122
Iteration 1788, loss = 0.01913628
Iteration 1789, loss = 0.01912587
Iteration 1790, loss = 0.01911292
Iteration 1791, loss = 0.01910143
Iteration 1792, loss = 0.01908760
Iteration 1793, loss = 0.01907731
Iteration 1794, loss = 0.01906475
Iteration 1795, loss = 0.01905196
Iteration 1796, loss = 0.01904121
Iteration 1797, loss = 0.01902599
Iteration 1798, loss = 0.01901203
Iteration 1799, loss = 0.01899924
Iteration 1800, loss = 0.01898607
Iteration 1801, loss = 0.01897236
Iteration 1802, loss = 0.01895985
Iteration 1803, loss = 0.01894665
Iteration 1804, loss = 0.01893384
Iteration 1805, loss = 0.01892380
Iteration 1806, loss = 0.01890851
Iteration 1807, loss = 0.01889630
Iteration 1808, loss = 0.01888298
Iteration 1809, loss = 0.01887157
Iteration 1810, loss = 0.01885808
Iteration 1811, loss = 0.01884494
Iteration 1812, loss = 0.01883445
Iteration 1813, loss = 0.01882063
Iteration 1814, loss = 0.01880759
Iteration 1815, loss = 0.01879663
Iteration 1816, loss = 0.01878271
Iteration 1817, loss = 0.01877272
Iteration 1818, loss = 0.01875608
Iteration 1819, loss = 0.01874601
Iteration 1820, loss = 0.01873123
Iteration 1821, loss = 0.01872115
Iteration 1822, loss = 0.01870910
Iteration 1823, loss = 0.01869556
Iteration 1824, loss = 0.01868277
Iteration 1825, loss = 0.01867083
Iteration 1826, loss = 0.01865909
Iteration 1827, loss = 0.01864816
Iteration 1828, loss = 0.01863355
Iteration 1829, loss = 0.01862121
Iteration 1830, loss = 0.01860841
Iteration 1831, loss = 0.01859592
Iteration 1832, loss = 0.01858483
Iteration 1833, loss = 0.01857249
Iteration 1834, loss = 0.01856010
Iteration 1835, loss = 0.01854732
Iteration 1836, loss = 0.01853530
Iteration 1837, loss = 0.01852367
Iteration 1838, loss = 0.01851216
Iteration 1839, loss = 0.01850161
Iteration 1840, loss = 0.01849279
Iteration 1841, loss = 0.01847797
Iteration 1842, loss = 0.01846594
Iteration 1843, loss = 0.01845356
Iteration 1844, loss = 0.01844186
Iteration 1845, loss = 0.01842938
Iteration 1846, loss = 0.01841795
Iteration 1847, loss = 0.01840491
Iteration 1848, loss = 0.01839376
Iteration 1849, loss = 0.01838177
Iteration 1850, loss = 0.01836908
Iteration 1851, loss = 0.01835962
Iteration 1852, loss = 0.01834518
Iteration 1853, loss = 0.01833366
Iteration 1854, loss = 0.01832209
Iteration 1855, loss = 0.01830908
Iteration 1856, loss = 0.01829648
Iteration 1857, loss = 0.01828446
Iteration 1858, loss = 0.01827227
Iteration 1859, loss = 0.01825935
Iteration 1860, loss = 0.01824811
Iteration 1861, loss = 0.01823710
Iteration 1862, loss = 0.01822603
Iteration 1863, loss = 0.01821312
Iteration 1864, loss = 0.01820265
Iteration 1865, loss = 0.01819051
Iteration 1866, loss = 0.01817726
Iteration 1867, loss = 0.01816451
Iteration 1868, loss = 0.01815215
Iteration 1869, loss = 0.01813904
Iteration 1870, loss = 0.01812647
Iteration 1871, loss = 0.01811629
Iteration 1872, loss = 0.01810293
Iteration 1873, loss = 0.01808948
Iteration 1874, loss = 0.01807814
Iteration 1875, loss = 0.01806633
Iteration 1876, loss = 0.01805497
Iteration 1877, loss = 0.01804273
Iteration 1878, loss = 0.01803148
Iteration 1879, loss = 0.01802047
Iteration 1880, loss = 0.01800836
Iteration 1881, loss = 0.01799736
Iteration 1882, loss = 0.01798691
Iteration 1883, loss = 0.01797614
Iteration 1884, loss = 0.01796252
Iteration 1885, loss = 0.01795278
Iteration 1886, loss = 0.01793918
Iteration 1887, loss = 0.01792828
Iteration 1888, loss = 0.01791578
Iteration 1889, loss = 0.01790424
Iteration 1890, loss = 0.01789307
Iteration 1891, loss = 0.01788520
Iteration 1892, loss = 0.01787117
Iteration 1893, loss = 0.01785906
Iteration 1894, loss = 0.01785003
Iteration 1895, loss = 0.01783772
Iteration 1896, loss = 0.01782675
Iteration 1897, loss = 0.01781654
Iteration 1898, loss = 0.01780422
Iteration 1899, loss = 0.01779366
Iteration 1900, loss = 0.01778261
Iteration 1901, loss = 0.01777205
Iteration 1902, loss = 0.01776186
Iteration 1903, loss = 0.01775132
Iteration 1904, loss = 0.01774045
Iteration 1905, loss = 0.01772906
Iteration 1906, loss = 0.01771708
Iteration 1907, loss = 0.01770643
Iteration 1908, loss = 0.01769380
Iteration 1909, loss = 0.01768226
Iteration 1910, loss = 0.01766992
Iteration 1911, loss = 0.01765808
Iteration 1912, loss = 0.01764687
Iteration 1913, loss = 0.01763500
Iteration 1914, loss = 0.01762537
Iteration 1915, loss = 0.01761268
Iteration 1916, loss = 0.01760321
Iteration 1917, loss = 0.01759145
Iteration 1918, loss = 0.01758014
Iteration 1919, loss = 0.01756928
Iteration 1920, loss = 0.01755730
Iteration 1921, loss = 0.01754612
Iteration 1922, loss = 0.01753449
Iteration 1923, loss = 0.01752607
Iteration 1924, loss = 0.01751125
Iteration 1925, loss = 0.01750005
Iteration 1926, loss = 0.01748902
Iteration 1927, loss = 0.01747804
Iteration 1928, loss = 0.01746628
Iteration 1929, loss = 0.01745492
Iteration 1930, loss = 0.01744362
Iteration 1931, loss = 0.01743199
Iteration 1932, loss = 0.01742106
Iteration 1933, loss = 0.01740886
Iteration 1934, loss = 0.01739743
Iteration 1935, loss = 0.01738697
Iteration 1936, loss = 0.01737516
Iteration 1937, loss = 0.01736602
Iteration 1938, loss = 0.01735461
Iteration 1939, loss = 0.01734326
Iteration 1940, loss = 0.01733195
Iteration 1941, loss = 0.01732118
Iteration 1942, loss = 0.01730953
Iteration 1943, loss = 0.01729907
Iteration 1944, loss = 0.01728731
Iteration 1945, loss = 0.01727490
Iteration 1946, loss = 0.01726521
Iteration 1947, loss = 0.01725243
Iteration 1948, loss = 0.01724148
Iteration 1949, loss = 0.01722894
Iteration 1950, loss = 0.01721695
Iteration 1951, loss = 0.01720724
Iteration 1952, loss = 0.01719633
Iteration 1953, loss = 0.01718552
Iteration 1954, loss = 0.01717499
Iteration 1955, loss = 0.01716447
Iteration 1956, loss = 0.01715401
Iteration 1957, loss = 0.01714410
Iteration 1958, loss = 0.01713401
Iteration 1959, loss = 0.01712257
Iteration 1960, loss = 0.01711199
Iteration 1961, loss = 0.01710086
Iteration 1962, loss = 0.01709037
Iteration 1963, loss = 0.01707911
Iteration 1964, loss = 0.01706942
Iteration 1965, loss = 0.01705827
Iteration 1966, loss = 0.01704814
Iteration 1967, loss = 0.01703689
Iteration 1968, loss = 0.01702671
Iteration 1969, loss = 0.01701567
Iteration 1970, loss = 0.01700523
Iteration 1971, loss = 0.01699591
Iteration 1972, loss = 0.01698487
Iteration 1973, loss = 0.01697414
Iteration 1974, loss = 0.01696731
Iteration 1975, loss = 0.01695208
Iteration 1976, loss = 0.01694294
Iteration 1977, loss = 0.01693030
Iteration 1978, loss = 0.01691878
Iteration 1979, loss = 0.01690960
Iteration 1980, loss = 0.01689796
Iteration 1981, loss = 0.01688773
Iteration 1982, loss = 0.01687579
Iteration 1983, loss = 0.01686350
Iteration 1984, loss = 0.01685460
Iteration 1985, loss = 0.01684238
Iteration 1986, loss = 0.01683375
Iteration 1987, loss = 0.01682161
Iteration 1988, loss = 0.01681077
Iteration 1989, loss = 0.01680165
Iteration 1990, loss = 0.01679188
Iteration 1991, loss = 0.01678012
Iteration 1992, loss = 0.01677067
Iteration 1993, loss = 0.01675876
Iteration 1994, loss = 0.01674820
Iteration 1995, loss = 0.01673758
Iteration 1996, loss = 0.01672644
Iteration 1997, loss = 0.01671609
Iteration 1998, loss = 0.01670624
Iteration 1999, loss = 0.01669491
Iteration 2000, loss = 0.01668449
Iteration 2001, loss = 0.01667361
Iteration 2002, loss = 0.01666429
Iteration 2003, loss = 0.01665342
Iteration 2004, loss = 0.01664198
Iteration 2005, loss = 0.01663273
Iteration 2006, loss = 0.01662141
Iteration 2007, loss = 0.01661053
Iteration 2008, loss = 0.01660084
Iteration 2009, loss = 0.01659073
Iteration 2010, loss = 0.01658019
Iteration 2011, loss = 0.01657202
Iteration 2012, loss = 0.01656052
Iteration 2013, loss = 0.01655062
Iteration 2014, loss = 0.01654019
Iteration 2015, loss = 0.01652992
Iteration 2016, loss = 0.01651918
Iteration 2017, loss = 0.01651093
Iteration 2018, loss = 0.01650077
Iteration 2019, loss = 0.01648917
Iteration 2020, loss = 0.01647856
Iteration 2021, loss = 0.01646872
Iteration 2022, loss = 0.01645910
Iteration 2023, loss = 0.01644919
Iteration 2024, loss = 0.01643940
Iteration 2025, loss = 0.01643068
Iteration 2026, loss = 0.01642143
Iteration 2027, loss = 0.01641083
Iteration 2028, loss = 0.01640080
Iteration 2029, loss = 0.01639238
Iteration 2030, loss = 0.01638110
Iteration 2031, loss = 0.01637218
Iteration 2032, loss = 0.01636126
Iteration 2033, loss = 0.01635220
Iteration 2034, loss = 0.01634201
Iteration 2035, loss = 0.01633211
Iteration 2036, loss = 0.01632322
Iteration 2037, loss = 0.01631312
Iteration 2038, loss = 0.01630409
Iteration 2039, loss = 0.01629339
Iteration 2040, loss = 0.01628394
Iteration 2041, loss = 0.01627323
Iteration 2042, loss = 0.01626421
Iteration 2043, loss = 0.01625450
Iteration 2044, loss = 0.01624533
Iteration 2045, loss = 0.01623602
Iteration 2046, loss = 0.01622629
Iteration 2047, loss = 0.01621698
Iteration 2048, loss = 0.01620778
Iteration 2049, loss = 0.01619670
Iteration 2050, loss = 0.01618695
Iteration 2051, loss = 0.01617765
Iteration 2052, loss = 0.01616831
Iteration 2053, loss = 0.01615785
Iteration 2054, loss = 0.01614817
Iteration 2055, loss = 0.01613893
Iteration 2056, loss = 0.01612944
Iteration 2057, loss = 0.01611968
Iteration 2058, loss = 0.01611147
Iteration 2059, loss = 0.01610020
Iteration 2060, loss = 0.01608970
Iteration 2061, loss = 0.01607952
Iteration 2062, loss = 0.01606911
Iteration 2063, loss = 0.01605824
Iteration 2064, loss = 0.01604751
Iteration 2065, loss = 0.01603824
Iteration 2066, loss = 0.01602733
Iteration 2067, loss = 0.01601674
Iteration 2068, loss = 0.01601026
Iteration 2069, loss = 0.01599751
Iteration 2070, loss = 0.01598815
Iteration 2071, loss = 0.01597726
Iteration 2072, loss = 0.01596785
Iteration 2073, loss = 0.01595752
Iteration 2074, loss = 0.01594828
Iteration 2075, loss = 0.01593719
Iteration 2076, loss = 0.01592895
Iteration 2077, loss = 0.01591769
Iteration 2078, loss = 0.01590791
Iteration 2079, loss = 0.01590024
Iteration 2080, loss = 0.01589001
Iteration 2081, loss = 0.01588030
Iteration 2082, loss = 0.01587060
Iteration 2083, loss = 0.01586220
Iteration 2084, loss = 0.01585236
Iteration 2085, loss = 0.01584279
Iteration 2086, loss = 0.01583332
Iteration 2087, loss = 0.01582334
Iteration 2088, loss = 0.01581287
Iteration 2089, loss = 0.01580239
Iteration 2090, loss = 0.01579280
Iteration 2091, loss = 0.01578301
Iteration 2092, loss = 0.01577426
Iteration 2093, loss = 0.01576682
Iteration 2094, loss = 0.01575537
Iteration 2095, loss = 0.01574618
Iteration 2096, loss = 0.01573631
Iteration 2097, loss = 0.01572640
Iteration 2098, loss = 0.01571642
Iteration 2099, loss = 0.01570696
Iteration 2100, loss = 0.01569633
Iteration 2101, loss = 0.01569000
Iteration 2102, loss = 0.01567940
Iteration 2103, loss = 0.01566853
Iteration 2104, loss = 0.01566030
Iteration 2105, loss = 0.01565152
Iteration 2106, loss = 0.01564114
Iteration 2107, loss = 0.01563286
Iteration 2108, loss = 0.01562070
Iteration 2109, loss = 0.01561161
Iteration 2110, loss = 0.01560219
Iteration 2111, loss = 0.01559127
Iteration 2112, loss = 0.01558155
Iteration 2113, loss = 0.01557202
Iteration 2114, loss = 0.01556352
Iteration 2115, loss = 0.01555239
Iteration 2116, loss = 0.01554424
Iteration 2117, loss = 0.01553360
Iteration 2118, loss = 0.01552469
Iteration 2119, loss = 0.01551685
Iteration 2120, loss = 0.01550628
Iteration 2121, loss = 0.01549682
Iteration 2122, loss = 0.01548782
Iteration 2123, loss = 0.01547737
Iteration 2124, loss = 0.01546644
Iteration 2125, loss = 0.01545896
Iteration 2126, loss = 0.01545214
Iteration 2127, loss = 0.01544129
Iteration 2128, loss = 0.01543093
Iteration 2129, loss = 0.01542236
Iteration 2130, loss = 0.01541336
Iteration 2131, loss = 0.01540506
Iteration 2132, loss = 0.01539524
Iteration 2133, loss = 0.01538622
Iteration 2134, loss = 0.01537893
Iteration 2135, loss = 0.01536886
Iteration 2136, loss = 0.01536007
Iteration 2137, loss = 0.01535132
Iteration 2138, loss = 0.01534301
Iteration 2139, loss = 0.01533487
Iteration 2140, loss = 0.01532516
Iteration 2141, loss = 0.01531555
Iteration 2142, loss = 0.01530608
Iteration 2143, loss = 0.01529782
Iteration 2144, loss = 0.01529015
Iteration 2145, loss = 0.01527980
Iteration 2146, loss = 0.01527108
Iteration 2147, loss = 0.01526216
Iteration 2148, loss = 0.01525382
Iteration 2149, loss = 0.01524526
Iteration 2150, loss = 0.01523484
Iteration 2151, loss = 0.01522581
Iteration 2152, loss = 0.01521745
Iteration 2153, loss = 0.01520792
Iteration 2154, loss = 0.01519864
Iteration 2155, loss = 0.01518955
Iteration 2156, loss = 0.01518038
Iteration 2157, loss = 0.01517177
Iteration 2158, loss = 0.01516338
Iteration 2159, loss = 0.01515409
Iteration 2160, loss = 0.01514607
Iteration 2161, loss = 0.01513694
Iteration 2162, loss = 0.01512821
Iteration 2163, loss = 0.01511850
Iteration 2164, loss = 0.01511005
Iteration 2165, loss = 0.01510202
Iteration 2166, loss = 0.01509306
Iteration 2167, loss = 0.01508402
Iteration 2168, loss = 0.01507535
Iteration 2169, loss = 0.01506577
Iteration 2170, loss = 0.01505809
Iteration 2171, loss = 0.01504908
Iteration 2172, loss = 0.01504240
Iteration 2173, loss = 0.01503374
Iteration 2174, loss = 0.01502516
Iteration 2175, loss = 0.01501819
Iteration 2176, loss = 0.01500891
Iteration 2177, loss = 0.01500129
Iteration 2178, loss = 0.01499306
Iteration 2179, loss = 0.01498409
Iteration 2180, loss = 0.01497547
Iteration 2181, loss = 0.01496699
Iteration 2182, loss = 0.01495817
Iteration 2183, loss = 0.01495031
Iteration 2184, loss = 0.01494179
Iteration 2185, loss = 0.01493375
Iteration 2186, loss = 0.01492731
Iteration 2187, loss = 0.01491792
Iteration 2188, loss = 0.01491054
Iteration 2189, loss = 0.01490145
Iteration 2190, loss = 0.01489356
Iteration 2191, loss = 0.01488358
Iteration 2192, loss = 0.01487550
Iteration 2193, loss = 0.01486636
Iteration 2194, loss = 0.01485685
Iteration 2195, loss = 0.01485028
Iteration 2196, loss = 0.01484037
Iteration 2197, loss = 0.01483247
Iteration 2198, loss = 0.01482353
Iteration 2199, loss = 0.01481538
Iteration 2200, loss = 0.01480875
Iteration 2201, loss = 0.01479998
Iteration 2202, loss = 0.01479297
Iteration 2203, loss = 0.01478470
Iteration 2204, loss = 0.01477668
Iteration 2205, loss = 0.01477080
Iteration 2206, loss = 0.01476097
Iteration 2207, loss = 0.01475276
Iteration 2208, loss = 0.01474560
Iteration 2209, loss = 0.01473965
Iteration 2210, loss = 0.01473275
Iteration 2211, loss = 0.01472078
Iteration 2212, loss = 0.01471229
Iteration 2213, loss = 0.01470160
Iteration 2214, loss = 0.01469331
Iteration 2215, loss = 0.01468294
Iteration 2216, loss = 0.01467389
Iteration 2217, loss = 0.01466299
Iteration 2218, loss = 0.01465448
Iteration 2219, loss = 0.01464645
Iteration 2220, loss = 0.01463672
Iteration 2221, loss = 0.01462775
Iteration 2222, loss = 0.01461896
Iteration 2223, loss = 0.01460969
Iteration 2224, loss = 0.01460204
Iteration 2225, loss = 0.01459385
Iteration 2226, loss = 0.01458599
Iteration 2227, loss = 0.01457823
Iteration 2228, loss = 0.01456817
Iteration 2229, loss = 0.01456052
Iteration 2230, loss = 0.01455223
Iteration 2231, loss = 0.01454418
Iteration 2232, loss = 0.01453662
Iteration 2233, loss = 0.01452922
Iteration 2234, loss = 0.01451968
Iteration 2235, loss = 0.01451128
Iteration 2236, loss = 0.01450221
Iteration 2237, loss = 0.01449667
Iteration 2238, loss = 0.01448567
Iteration 2239, loss = 0.01447681
Iteration 2240, loss = 0.01446961
Iteration 2241, loss = 0.01446143
Iteration 2242, loss = 0.01445229
Iteration 2243, loss = 0.01444376
Iteration 2244, loss = 0.01443621
Iteration 2245, loss = 0.01442682
Iteration 2246, loss = 0.01441995
Iteration 2247, loss = 0.01441179
Iteration 2248, loss = 0.01440272
Iteration 2249, loss = 0.01439497
Iteration 2250, loss = 0.01438624
Iteration 2251, loss = 0.01437809
Iteration 2252, loss = 0.01436977
Iteration 2253, loss = 0.01436326
Iteration 2254, loss = 0.01435380
Iteration 2255, loss = 0.01434570
Iteration 2256, loss = 0.01433741
Iteration 2257, loss = 0.01432918
Iteration 2258, loss = 0.01432207
Iteration 2259, loss = 0.01431388
Iteration 2260, loss = 0.01430573
Iteration 2261, loss = 0.01429727
Iteration 2262, loss = 0.01428944
Iteration 2263, loss = 0.01428157
Iteration 2264, loss = 0.01427357
Iteration 2265, loss = 0.01426623
Iteration 2266, loss = 0.01425815
Iteration 2267, loss = 0.01425266
Iteration 2268, loss = 0.01424504
Iteration 2269, loss = 0.01423615
Iteration 2270, loss = 0.01422755
Iteration 2271, loss = 0.01422159
Iteration 2272, loss = 0.01421228
Iteration 2273, loss = 0.01420412
Iteration 2274, loss = 0.01419552
Iteration 2275, loss = 0.01418742
Iteration 2276, loss = 0.01418009
Iteration 2277, loss = 0.01416966
Iteration 2278, loss = 0.01416060
Iteration 2279, loss = 0.01415385
Iteration 2280, loss = 0.01414420
Iteration 2281, loss = 0.01413523
Iteration 2282, loss = 0.01412592
Iteration 2283, loss = 0.01411739
Iteration 2284, loss = 0.01410967
Iteration 2285, loss = 0.01410035
Iteration 2286, loss = 0.01409280
Iteration 2287, loss = 0.01408317
Iteration 2288, loss = 0.01407453
Iteration 2289, loss = 0.01406865
Iteration 2290, loss = 0.01406169
Iteration 2291, loss = 0.01405337
Iteration 2292, loss = 0.01404459
Iteration 2293, loss = 0.01403670
Iteration 2294, loss = 0.01402903
Iteration 2295, loss = 0.01402107
Iteration 2296, loss = 0.01401263
Iteration 2297, loss = 0.01400634
Iteration 2298, loss = 0.01399667
Iteration 2299, loss = 0.01398952
Iteration 2300, loss = 0.01398014
Iteration 2301, loss = 0.01397257
Iteration 2302, loss = 0.01396479
Iteration 2303, loss = 0.01395665
Iteration 2304, loss = 0.01394830
Iteration 2305, loss = 0.01394052
Iteration 2306, loss = 0.01393410
Iteration 2307, loss = 0.01392543
Iteration 2308, loss = 0.01391801
Iteration 2309, loss = 0.01390955
Iteration 2310, loss = 0.01390429
Iteration 2311, loss = 0.01389483
Iteration 2312, loss = 0.01388684
Iteration 2313, loss = 0.01388088
Iteration 2314, loss = 0.01387183
Iteration 2315, loss = 0.01386426
Iteration 2316, loss = 0.01385525
Iteration 2317, loss = 0.01384742
Iteration 2318, loss = 0.01383907
Iteration 2319, loss = 0.01383168
Iteration 2320, loss = 0.01382536
Iteration 2321, loss = 0.01381661
Iteration 2322, loss = 0.01380960
Iteration 2323, loss = 0.01380119
Iteration 2324, loss = 0.01379334
Iteration 2325, loss = 0.01378578
Iteration 2326, loss = 0.01377890
Iteration 2327, loss = 0.01377129
Iteration 2328, loss = 0.01376474
Iteration 2329, loss = 0.01375631
Iteration 2330, loss = 0.01374909
Iteration 2331, loss = 0.01374103
Iteration 2332, loss = 0.01373558
Iteration 2333, loss = 0.01372759
Iteration 2334, loss = 0.01372051
Iteration 2335, loss = 0.01371418
Iteration 2336, loss = 0.01370530
Iteration 2337, loss = 0.01369839
Iteration 2338, loss = 0.01369051
Iteration 2339, loss = 0.01368293
Iteration 2340, loss = 0.01367502
Iteration 2341, loss = 0.01366731
Iteration 2342, loss = 0.01366028
Iteration 2343, loss = 0.01365092
Iteration 2344, loss = 0.01364304
Iteration 2345, loss = 0.01363706
Iteration 2346, loss = 0.01362774
Iteration 2347, loss = 0.01361977
Iteration 2348, loss = 0.01361178
Iteration 2349, loss = 0.01360386
Iteration 2350, loss = 0.01359678
Iteration 2351, loss = 0.01358907
Iteration 2352, loss = 0.01358272
Iteration 2353, loss = 0.01357511
Iteration 2354, loss = 0.01356689
Iteration 2355, loss = 0.01356055
Iteration 2356, loss = 0.01355126
Iteration 2357, loss = 0.01354357
Iteration 2358, loss = 0.01353561
Iteration 2359, loss = 0.01352904
Iteration 2360, loss = 0.01351954
Iteration 2361, loss = 0.01350995
Iteration 2362, loss = 0.01350025
Iteration 2363, loss = 0.01349266
Iteration 2364, loss = 0.01348442
Iteration 2365, loss = 0.01347832
Iteration 2366, loss = 0.01346983
Iteration 2367, loss = 0.01346224
Iteration 2368, loss = 0.01345449
Iteration 2369, loss = 0.01344680
Iteration 2370, loss = 0.01343902
Iteration 2371, loss = 0.01343167
Iteration 2372, loss = 0.01342375
Iteration 2373, loss = 0.01341532
Iteration 2374, loss = 0.01340722
Iteration 2375, loss = 0.01339926
Iteration 2376, loss = 0.01339219
Iteration 2377, loss = 0.01338418
Iteration 2378, loss = 0.01337727
Iteration 2379, loss = 0.01336924
Iteration 2380, loss = 0.01336196
Iteration 2381, loss = 0.01335308
Iteration 2382, loss = 0.01334533
Iteration 2383, loss = 0.01333811
Iteration 2384, loss = 0.01333038
Iteration 2385, loss = 0.01332349
Iteration 2386, loss = 0.01331657
Iteration 2387, loss = 0.01330860
Iteration 2388, loss = 0.01330359
Iteration 2389, loss = 0.01329692
Iteration 2390, loss = 0.01328810
Iteration 2391, loss = 0.01327993
Iteration 2392, loss = 0.01327269
Iteration 2393, loss = 0.01326536
Iteration 2394, loss = 0.01325942
Iteration 2395, loss = 0.01325164
Iteration 2396, loss = 0.01324433
Iteration 2397, loss = 0.01323650
Iteration 2398, loss = 0.01322963
Iteration 2399, loss = 0.01322252
Iteration 2400, loss = 0.01321621
Iteration 2401, loss = 0.01320965
Iteration 2402, loss = 0.01320064
Iteration 2403, loss = 0.01319390
Iteration 2404, loss = 0.01318536
Iteration 2405, loss = 0.01317981
Iteration 2406, loss = 0.01317129
Iteration 2407, loss = 0.01316437
Iteration 2408, loss = 0.01315830
Iteration 2409, loss = 0.01315024
Iteration 2410, loss = 0.01314302
Iteration 2411, loss = 0.01313653
Iteration 2412, loss = 0.01312967
Iteration 2413, loss = 0.01312276
Iteration 2414, loss = 0.01311594
Iteration 2415, loss = 0.01311001
Iteration 2416, loss = 0.01310434
Iteration 2417, loss = 0.01309616
Iteration 2418, loss = 0.01309084
Iteration 2419, loss = 0.01308204
Iteration 2420, loss = 0.01307501
Iteration 2421, loss = 0.01306894
Iteration 2422, loss = 0.01306166
Iteration 2423, loss = 0.01305433
Iteration 2424, loss = 0.01304689
Iteration 2425, loss = 0.01304017
Iteration 2426, loss = 0.01303455
Iteration 2427, loss = 0.01302754
Iteration 2428, loss = 0.01302045
Iteration 2429, loss = 0.01301760
Iteration 2430, loss = 0.01300796
Iteration 2431, loss = 0.01300146
Iteration 2432, loss = 0.01299371
Iteration 2433, loss = 0.01298815
Iteration 2434, loss = 0.01297980
Iteration 2435, loss = 0.01297280
Iteration 2436, loss = 0.01296488
Iteration 2437, loss = 0.01295869
Iteration 2438, loss = 0.01295088
Iteration 2439, loss = 0.01294378
Iteration 2440, loss = 0.01293679
Iteration 2441, loss = 0.01293076
Iteration 2442, loss = 0.01292338
Iteration 2443, loss = 0.01291647
Iteration 2444, loss = 0.01291021
Iteration 2445, loss = 0.01290371
Iteration 2446, loss = 0.01289625
Iteration 2447, loss = 0.01288915
Iteration 2448, loss = 0.01288214
Iteration 2449, loss = 0.01287401
Iteration 2450, loss = 0.01286743
Iteration 2451, loss = 0.01286103
Iteration 2452, loss = 0.01285411
Iteration 2453, loss = 0.01284648
Iteration 2454, loss = 0.01283937
Iteration 2455, loss = 0.01283209
Iteration 2456, loss = 0.01282476
Iteration 2457, loss = 0.01281774
Iteration 2458, loss = 0.01281372
Iteration 2459, loss = 0.01280638
Iteration 2460, loss = 0.01279902
Iteration 2461, loss = 0.01279275
Iteration 2462, loss = 0.01278921
Iteration 2463, loss = 0.01277893
Iteration 2464, loss = 0.01277182
Iteration 2465, loss = 0.01276455
Iteration 2466, loss = 0.01275705
Iteration 2467, loss = 0.01274915
Iteration 2468, loss = 0.01274445
Iteration 2469, loss = 0.01273621
Iteration 2470, loss = 0.01272945
Iteration 2471, loss = 0.01272333
Iteration 2472, loss = 0.01271666
Iteration 2473, loss = 0.01271082
Iteration 2474, loss = 0.01270473
Iteration 2475, loss = 0.01269843
Iteration 2476, loss = 0.01269305
Iteration 2477, loss = 0.01268666
Iteration 2478, loss = 0.01267975
Iteration 2479, loss = 0.01267436
Iteration 2480, loss = 0.01266706
Iteration 2481, loss = 0.01266025
Iteration 2482, loss = 0.01265303
Iteration 2483, loss = 0.01264502
Iteration 2484, loss = 0.01263899
Iteration 2485, loss = 0.01263045
Iteration 2486, loss = 0.01262284
Iteration 2487, loss = 0.01261758
Iteration 2488, loss = 0.01260870
Iteration 2489, loss = 0.01260171
Iteration 2490, loss = 0.01259468
Iteration 2491, loss = 0.01258893
Iteration 2492, loss = 0.01257925
Iteration 2493, loss = 0.01257313
Iteration 2494, loss = 0.01256496
Iteration 2495, loss = 0.01255834
Iteration 2496, loss = 0.01255103
Iteration 2497, loss = 0.01254439
Iteration 2498, loss = 0.01253868
Iteration 2499, loss = 0.01253018
Iteration 2500, loss = 0.01252363
Iteration 2501, loss = 0.01251606
Iteration 2502, loss = 0.01250990
Iteration 2503, loss = 0.01250418
Iteration 2504, loss = 0.01249601
Iteration 2505, loss = 0.01249008
Iteration 2506, loss = 0.01248282
Iteration 2507, loss = 0.01247699
Iteration 2508, loss = 0.01246940
Iteration 2509, loss = 0.01246157
Iteration 2510, loss = 0.01245478
Iteration 2511, loss = 0.01244943
Iteration 2512, loss = 0.01244156
Iteration 2513, loss = 0.01243441
Iteration 2514, loss = 0.01242859
Iteration 2515, loss = 0.01242367
Iteration 2516, loss = 0.01241517
Iteration 2517, loss = 0.01240763
Iteration 2518, loss = 0.01240074
Iteration 2519, loss = 0.01239420
Iteration 2520, loss = 0.01238732
Iteration 2521, loss = 0.01238097
Iteration 2522, loss = 0.01237318
Iteration 2523, loss = 0.01236663
Iteration 2524, loss = 0.01235988
Iteration 2525, loss = 0.01235270
Iteration 2526, loss = 0.01234800
Iteration 2527, loss = 0.01233972
Iteration 2528, loss = 0.01233295
Iteration 2529, loss = 0.01232654
Iteration 2530, loss = 0.01231938
Iteration 2531, loss = 0.01231156
Iteration 2532, loss = 0.01230842
Iteration 2533, loss = 0.01230124
Iteration 2534, loss = 0.01229455
Iteration 2535, loss = 0.01228802
Iteration 2536, loss = 0.01228213
Iteration 2537, loss = 0.01227683
Iteration 2538, loss = 0.01227013
Iteration 2539, loss = 0.01226466
Iteration 2540, loss = 0.01225838
Iteration 2541, loss = 0.01225176
Iteration 2542, loss = 0.01224568
Iteration 2543, loss = 0.01223951
Iteration 2544, loss = 0.01223349
Iteration 2545, loss = 0.01222827
Iteration 2546, loss = 0.01222149
Iteration 2547, loss = 0.01221638
Iteration 2548, loss = 0.01220936
Iteration 2549, loss = 0.01220312
Iteration 2550, loss = 0.01219698
Iteration 2551, loss = 0.01219024
Iteration 2552, loss = 0.01218391
Iteration 2553, loss = 0.01217746
Iteration 2554, loss = 0.01217163
Iteration 2555, loss = 0.01216477
Iteration 2556, loss = 0.01215898
Iteration 2557, loss = 0.01215238
Iteration 2558, loss = 0.01214627
Iteration 2559, loss = 0.01214044
Iteration 2560, loss = 0.01213464
Iteration 2561, loss = 0.01212888
Iteration 2562, loss = 0.01212303
Iteration 2563, loss = 0.01211754
Iteration 2564, loss = 0.01211221
Iteration 2565, loss = 0.01210626
Iteration 2566, loss = 0.01209957
Iteration 2567, loss = 0.01209560
Iteration 2568, loss = 0.01208710
Iteration 2569, loss = 0.01208200
Iteration 2570, loss = 0.01207529
Iteration 2571, loss = 0.01206659
Iteration 2572, loss = 0.01206155
Iteration 2573, loss = 0.01205388
Iteration 2574, loss = 0.01204665
Iteration 2575, loss = 0.01204022
Iteration 2576, loss = 0.01203337
Iteration 2577, loss = 0.01202636
Iteration 2578, loss = 0.01201926
Iteration 2579, loss = 0.01201389
Iteration 2580, loss = 0.01200761
Iteration 2581, loss = 0.01199977
Iteration 2582, loss = 0.01199359
Iteration 2583, loss = 0.01198746
Iteration 2584, loss = 0.01198088
Iteration 2585, loss = 0.01197573
Iteration 2586, loss = 0.01196831
Iteration 2587, loss = 0.01196259
Iteration 2588, loss = 0.01195576
Iteration 2589, loss = 0.01195006
Iteration 2590, loss = 0.01194498
Iteration 2591, loss = 0.01193776
Iteration 2592, loss = 0.01193186
Iteration 2593, loss = 0.01192688
Iteration 2594, loss = 0.01192025
Iteration 2595, loss = 0.01191389
Iteration 2596, loss = 0.01190818
Iteration 2597, loss = 0.01190226
Iteration 2598, loss = 0.01189634
Iteration 2599, loss = 0.01189094
Iteration 2600, loss = 0.01188528
Iteration 2601, loss = 0.01187896
Iteration 2602, loss = 0.01187309
Iteration 2603, loss = 0.01186889
Iteration 2604, loss = 0.01186227
Iteration 2605, loss = 0.01185664
Iteration 2606, loss = 0.01185037
Iteration 2607, loss = 0.01184457
Iteration 2608, loss = 0.01183957
Iteration 2609, loss = 0.01183378
Iteration 2610, loss = 0.01182761
Iteration 2611, loss = 0.01182285
Iteration 2612, loss = 0.01181684
Iteration 2613, loss = 0.01181129
Iteration 2614, loss = 0.01180434
Iteration 2615, loss = 0.01179902
Iteration 2616, loss = 0.01179169
Iteration 2617, loss = 0.01178610
Iteration 2618, loss = 0.01177832
Iteration 2619, loss = 0.01177189
Iteration 2620, loss = 0.01176445
Iteration 2621, loss = 0.01175748
Iteration 2622, loss = 0.01175202
Iteration 2623, loss = 0.01174468
Iteration 2624, loss = 0.01173836
Iteration 2625, loss = 0.01173172
Iteration 2626, loss = 0.01172544
Iteration 2627, loss = 0.01171912
Iteration 2628, loss = 0.01171357
Iteration 2629, loss = 0.01170679
Iteration 2630, loss = 0.01170051
Iteration 2631, loss = 0.01169399
Iteration 2632, loss = 0.01168850
Iteration 2633, loss = 0.01168184
Iteration 2634, loss = 0.01167727
Iteration 2635, loss = 0.01166973
Iteration 2636, loss = 0.01166402
Iteration 2637, loss = 0.01165779
Iteration 2638, loss = 0.01165339
Iteration 2639, loss = 0.01164594
Iteration 2640, loss = 0.01164029
Iteration 2641, loss = 0.01163449
Iteration 2642, loss = 0.01162814
Iteration 2643, loss = 0.01162228
Iteration 2644, loss = 0.01161611
Iteration 2645, loss = 0.01161009
Iteration 2646, loss = 0.01160497
Iteration 2647, loss = 0.01159979
Iteration 2648, loss = 0.01159304
Iteration 2649, loss = 0.01158693
Iteration 2650, loss = 0.01158168
Iteration 2651, loss = 0.01157450
Iteration 2652, loss = 0.01156907
Iteration 2653, loss = 0.01156466
Iteration 2654, loss = 0.01155661
Iteration 2655, loss = 0.01155115
Iteration 2656, loss = 0.01154646
Iteration 2657, loss = 0.01153970
Iteration 2658, loss = 0.01153234
Iteration 2659, loss = 0.01152671
Iteration 2660, loss = 0.01151987
Iteration 2661, loss = 0.01151486
Iteration 2662, loss = 0.01150813
Iteration 2663, loss = 0.01150229
Iteration 2664, loss = 0.01149621
Iteration 2665, loss = 0.01149070
Iteration 2666, loss = 0.01148653
Iteration 2667, loss = 0.01147936
Iteration 2668, loss = 0.01147409
Iteration 2669, loss = 0.01146767
Iteration 2670, loss = 0.01146193
Iteration 2671, loss = 0.01145576
Iteration 2672, loss = 0.01145269
Iteration 2673, loss = 0.01144626
Iteration 2674, loss = 0.01144078
Iteration 2675, loss = 0.01143476
Iteration 2676, loss = 0.01142918
Iteration 2677, loss = 0.01142380
Iteration 2678, loss = 0.01141846
Iteration 2679, loss = 0.01141257
Iteration 2680, loss = 0.01140673
Iteration 2681, loss = 0.01140195
Iteration 2682, loss = 0.01139595
Iteration 2683, loss = 0.01139048
Iteration 2684, loss = 0.01138439
Iteration 2685, loss = 0.01137879
Iteration 2686, loss = 0.01137349
Iteration 2687, loss = 0.01136811
Iteration 2688, loss = 0.01136344
Iteration 2689, loss = 0.01135749
Iteration 2690, loss = 0.01135212
Iteration 2691, loss = 0.01134762
Iteration 2692, loss = 0.01134208
Iteration 2693, loss = 0.01133692
Iteration 2694, loss = 0.01133236
Iteration 2695, loss = 0.01132615
Iteration 2696, loss = 0.01132072
Iteration 2697, loss = 0.01131518
Iteration 2698, loss = 0.01130980
Iteration 2699, loss = 0.01130437
Iteration 2700, loss = 0.01129901
Iteration 2701, loss = 0.01129323
Iteration 2702, loss = 0.01128739
Iteration 2703, loss = 0.01128169
Iteration 2704, loss = 0.01127676
Iteration 2705, loss = 0.01127065
Iteration 2706, loss = 0.01126530
Iteration 2707, loss = 0.01125980
Iteration 2708, loss = 0.01125399
Iteration 2709, loss = 0.01124845
Iteration 2710, loss = 0.01124493
Iteration 2711, loss = 0.01123821
Iteration 2712, loss = 0.01123367
Iteration 2713, loss = 0.01122867
Iteration 2714, loss = 0.01122655
Iteration 2715, loss = 0.01122164
Iteration 2716, loss = 0.01121382
Iteration 2717, loss = 0.01120821
Iteration 2718, loss = 0.01120229
Iteration 2719, loss = 0.01119655
Iteration 2720, loss = 0.01119148
Iteration 2721, loss = 0.01118534
Iteration 2722, loss = 0.01117947
Iteration 2723, loss = 0.01117365
Iteration 2724, loss = 0.01116774
Iteration 2725, loss = 0.01116229
Iteration 2726, loss = 0.01115694
Iteration 2727, loss = 0.01115198
Iteration 2728, loss = 0.01114504
Iteration 2729, loss = 0.01114087
Iteration 2730, loss = 0.01113425
Iteration 2731, loss = 0.01112872
Iteration 2732, loss = 0.01112233
Iteration 2733, loss = 0.01111683
Iteration 2734, loss = 0.01111062
Iteration 2735, loss = 0.01110500
Iteration 2736, loss = 0.01109994
Iteration 2737, loss = 0.01109312
Iteration 2738, loss = 0.01108805
Iteration 2739, loss = 0.01108363
Iteration 2740, loss = 0.01107675
Iteration 2741, loss = 0.01107231
Iteration 2742, loss = 0.01106653
Iteration 2743, loss = 0.01106099
Iteration 2744, loss = 0.01105589
Iteration 2745, loss = 0.01105077
Iteration 2746, loss = 0.01104485
Iteration 2747, loss = 0.01104110
Iteration 2748, loss = 0.01103528
Iteration 2749, loss = 0.01102892
Iteration 2750, loss = 0.01102361
Iteration 2751, loss = 0.01101821
Iteration 2752, loss = 0.01101191
Iteration 2753, loss = 0.01100697
Iteration 2754, loss = 0.01100108
Iteration 2755, loss = 0.01099621
Iteration 2756, loss = 0.01099084
Iteration 2757, loss = 0.01098525
Iteration 2758, loss = 0.01097978
Iteration 2759, loss = 0.01097419
Iteration 2760, loss = 0.01097074
Iteration 2761, loss = 0.01096496
Iteration 2762, loss = 0.01095969
Iteration 2763, loss = 0.01095406
Iteration 2764, loss = 0.01094913
Iteration 2765, loss = 0.01094430
Iteration 2766, loss = 0.01093868
Iteration 2767, loss = 0.01093338
Iteration 2768, loss = 0.01092813
Iteration 2769, loss = 0.01092321
Iteration 2770, loss = 0.01091830
Iteration 2771, loss = 0.01091260
Iteration 2772, loss = 0.01090755
Iteration 2773, loss = 0.01090242
Iteration 2774, loss = 0.01089749
Iteration 2775, loss = 0.01089255
Iteration 2776, loss = 0.01088669
Iteration 2777, loss = 0.01088130
Iteration 2778, loss = 0.01087582
Iteration 2779, loss = 0.01087143
Iteration 2780, loss = 0.01086620
Iteration 2781, loss = 0.01086113
Iteration 2782, loss = 0.01085498
Iteration 2783, loss = 0.01084951
Iteration 2784, loss = 0.01084524
Iteration 2785, loss = 0.01083939
Iteration 2786, loss = 0.01083386
Iteration 2787, loss = 0.01082847
Iteration 2788, loss = 0.01082273
Iteration 2789, loss = 0.01081779
Iteration 2790, loss = 0.01081316
Iteration 2791, loss = 0.01080726
Iteration 2792, loss = 0.01080184
Iteration 2793, loss = 0.01079694
Iteration 2794, loss = 0.01079109
Iteration 2795, loss = 0.01078748
Iteration 2796, loss = 0.01078147
Iteration 2797, loss = 0.01077556
Iteration 2798, loss = 0.01077078
Iteration 2799, loss = 0.01076615
Iteration 2800, loss = 0.01076082
Iteration 2801, loss = 0.01075588
Iteration 2802, loss = 0.01075020
Iteration 2803, loss = 0.01074506
Iteration 2804, loss = 0.01073990
Iteration 2805, loss = 0.01073547
Iteration 2806, loss = 0.01072992
Iteration 2807, loss = 0.01072339
Iteration 2808, loss = 0.01071777
Iteration 2809, loss = 0.01071338
Iteration 2810, loss = 0.01070680
Iteration 2811, loss = 0.01070184
Iteration 2812, loss = 0.01069654
Iteration 2813, loss = 0.01069187
Iteration 2814, loss = 0.01068650
Iteration 2815, loss = 0.01068149
Iteration 2816, loss = 0.01067784
Iteration 2817, loss = 0.01067205
Iteration 2818, loss = 0.01066731
Iteration 2819, loss = 0.01066184
Iteration 2820, loss = 0.01065716
Iteration 2821, loss = 0.01065171
Iteration 2822, loss = 0.01064710
Iteration 2823, loss = 0.01064193
Iteration 2824, loss = 0.01063755
Iteration 2825, loss = 0.01063344
Iteration 2826, loss = 0.01063121
Iteration 2827, loss = 0.01062432
Iteration 2828, loss = 0.01061947
Iteration 2829, loss = 0.01061465
Iteration 2830, loss = 0.01061088
Iteration 2831, loss = 0.01060562
Iteration 2832, loss = 0.01060327
Iteration 2833, loss = 0.01059702
Iteration 2834, loss = 0.01059385
Iteration 2835, loss = 0.01058825
Iteration 2836, loss = 0.01058325
Iteration 2837, loss = 0.01057889
Iteration 2838, loss = 0.01057437
Iteration 2839, loss = 0.01057013
Iteration 2840, loss = 0.01056609
Iteration 2841, loss = 0.01056116
Iteration 2842, loss = 0.01055643
Iteration 2843, loss = 0.01055159
Iteration 2844, loss = 0.01054670
Iteration 2845, loss = 0.01054183
Iteration 2846, loss = 0.01053708
Iteration 2847, loss = 0.01053154
Iteration 2848, loss = 0.01052616
Iteration 2849, loss = 0.01052109
Iteration 2850, loss = 0.01051555
Iteration 2851, loss = 0.01051051
Iteration 2852, loss = 0.01050339
Iteration 2853, loss = 0.01049812
Iteration 2854, loss = 0.01049345
Iteration 2855, loss = 0.01048765
Iteration 2856, loss = 0.01048264
Iteration 2857, loss = 0.01047723
Iteration 2858, loss = 0.01047278
Iteration 2859, loss = 0.01046767
Iteration 2860, loss = 0.01046292
Iteration 2861, loss = 0.01045808
Iteration 2862, loss = 0.01045369
Iteration 2863, loss = 0.01044885
Iteration 2864, loss = 0.01044424
Iteration 2865, loss = 0.01044018
Iteration 2866, loss = 0.01043512
Iteration 2867, loss = 0.01043055
Iteration 2868, loss = 0.01042623
Iteration 2869, loss = 0.01042131
Iteration 2870, loss = 0.01041659
Iteration 2871, loss = 0.01041116
Iteration 2872, loss = 0.01040637
Iteration 2873, loss = 0.01040231
Iteration 2874, loss = 0.01039703
Iteration 2875, loss = 0.01039275
Iteration 2876, loss = 0.01038782
Iteration 2877, loss = 0.01038380
Iteration 2878, loss = 0.01037941
Iteration 2879, loss = 0.01037395
Iteration 2880, loss = 0.01036920
Iteration 2881, loss = 0.01036384
Iteration 2882, loss = 0.01035978
Iteration 2883, loss = 0.01035377
Iteration 2884, loss = 0.01035007
Iteration 2885, loss = 0.01034490
Iteration 2886, loss = 0.01034051
Iteration 2887, loss = 0.01033578
Iteration 2888, loss = 0.01033169
Iteration 2889, loss = 0.01032809
Iteration 2890, loss = 0.01032312
Iteration 2891, loss = 0.01031914
Iteration 2892, loss = 0.01031401
Iteration 2893, loss = 0.01030970
Iteration 2894, loss = 0.01030493
Iteration 2895, loss = 0.01030068
Iteration 2896, loss = 0.01029527
Iteration 2897, loss = 0.01029063
Iteration 2898, loss = 0.01028587
Iteration 2899, loss = 0.01028193
Iteration 2900, loss = 0.01027660
Iteration 2901, loss = 0.01027157
Iteration 2902, loss = 0.01026759
Iteration 2903, loss = 0.01026312
Iteration 2904, loss = 0.01025812
Iteration 2905, loss = 0.01025340
Iteration 2906, loss = 0.01024859
Iteration 2907, loss = 0.01024414
Iteration 2908, loss = 0.01023923
Iteration 2909, loss = 0.01023437
Iteration 2910, loss = 0.01022986
Iteration 2911, loss = 0.01022521
Iteration 2912, loss = 0.01022052
Iteration 2913, loss = 0.01021582
Iteration 2914, loss = 0.01021146
Iteration 2915, loss = 0.01020715
Iteration 2916, loss = 0.01020227
Iteration 2917, loss = 0.01019785
Iteration 2918, loss = 0.01019372
Iteration 2919, loss = 0.01018902
Iteration 2920, loss = 0.01018583
Iteration 2921, loss = 0.01018074
Iteration 2922, loss = 0.01017649
Iteration 2923, loss = 0.01017248
Iteration 2924, loss = 0.01016820
Iteration 2925, loss = 0.01016456
Iteration 2926, loss = 0.01015963
Iteration 2927, loss = 0.01015509
Iteration 2928, loss = 0.01015071
Iteration 2929, loss = 0.01014681
Iteration 2930, loss = 0.01014073
Iteration 2931, loss = 0.01013576
Iteration 2932, loss = 0.01013213
Iteration 2933, loss = 0.01012710
Iteration 2934, loss = 0.01012225
Iteration 2935, loss = 0.01011760
Iteration 2936, loss = 0.01011209
Iteration 2937, loss = 0.01010824
Iteration 2938, loss = 0.01010280
Iteration 2939, loss = 0.01009860
Iteration 2940, loss = 0.01009378
Iteration 2941, loss = 0.01008945
Iteration 2942, loss = 0.01008416
Iteration 2943, loss = 0.01007994
Iteration 2944, loss = 0.01007496
Iteration 2945, loss = 0.01007109
Iteration 2946, loss = 0.01006721
Iteration 2947, loss = 0.01006249
Iteration 2948, loss = 0.01005870
Iteration 2949, loss = 0.01005525
Iteration 2950, loss = 0.01005065
Iteration 2951, loss = 0.01004640
Iteration 2952, loss = 0.01004286
Iteration 2953, loss = 0.01003778
Iteration 2954, loss = 0.01003278
Iteration 2955, loss = 0.01002940
Iteration 2956, loss = 0.01002510
Iteration 2957, loss = 0.01001975
Iteration 2958, loss = 0.01001555
Iteration 2959, loss = 0.01001150
Iteration 2960, loss = 0.01000649
Iteration 2961, loss = 0.01000241
Iteration 2962, loss = 0.00999783
Iteration 2963, loss = 0.00999314
Iteration 2964, loss = 0.00998812
Iteration 2965, loss = 0.00998387
Iteration 2966, loss = 0.00997972
Iteration 2967, loss = 0.00997830
Iteration 2968, loss = 0.00997169
Iteration 2969, loss = 0.00996900
Iteration 2970, loss = 0.00996297
Iteration 2971, loss = 0.00995846
Iteration 2972, loss = 0.00995414
Iteration 2973, loss = 0.00994984
Iteration 2974, loss = 0.00994537
Iteration 2975, loss = 0.00994142
Iteration 2976, loss = 0.00993728
Iteration 2977, loss = 0.00993311
Iteration 2978, loss = 0.00992914
Iteration 2979, loss = 0.00992546
Iteration 2980, loss = 0.00992210
Iteration 2981, loss = 0.00991815
Iteration 2982, loss = 0.00991441
Iteration 2983, loss = 0.00991033
Iteration 2984, loss = 0.00990628
Iteration 2985, loss = 0.00990176
Iteration 2986, loss = 0.00989749
Iteration 2987, loss = 0.00989361
Iteration 2988, loss = 0.00988916
Iteration 2989, loss = 0.00988509
Iteration 2990, loss = 0.00988094
Iteration 2991, loss = 0.00987640
Iteration 2992, loss = 0.00987222
Iteration 2993, loss = 0.00986764
Iteration 2994, loss = 0.00986340
Iteration 2995, loss = 0.00985895
Iteration 2996, loss = 0.00985479
Iteration 2997, loss = 0.00984999
Iteration 2998, loss = 0.00984533
Iteration 2999, loss = 0.00984129
Iteration 3000, loss = 0.00983669
Iteration 3001, loss = 0.00983313
Iteration 3002, loss = 0.00982802
Iteration 3003, loss = 0.00982289
Iteration 3004, loss = 0.00981856
Iteration 3005, loss = 0.00981422
Iteration 3006, loss = 0.00980959
Iteration 3007, loss = 0.00980537
Iteration 3008, loss = 0.00980139
Iteration 3009, loss = 0.00979765
Iteration 3010, loss = 0.00979385
Iteration 3011, loss = 0.00979013
Iteration 3012, loss = 0.00978414
Iteration 3013, loss = 0.00977929
Iteration 3014, loss = 0.00977484
Iteration 3015, loss = 0.00977102
Iteration 3016, loss = 0.00976631
Iteration 3017, loss = 0.00976141
Iteration 3018, loss = 0.00975666
Iteration 3019, loss = 0.00975238
Iteration 3020, loss = 0.00974775
Iteration 3021, loss = 0.00974300
Iteration 3022, loss = 0.00973834
Iteration 3023, loss = 0.00973291
Iteration 3024, loss = 0.00972877
Iteration 3025, loss = 0.00972453
Iteration 3026, loss = 0.00972025
Iteration 3027, loss = 0.00971712
Iteration 3028, loss = 0.00971217
Iteration 3029, loss = 0.00970783
Iteration 3030, loss = 0.00970409
Iteration 3031, loss = 0.00970072
Iteration 3032, loss = 0.00969470
Iteration 3033, loss = 0.00969042
Iteration 3034, loss = 0.00968609
Iteration 3035, loss = 0.00968102
Iteration 3036, loss = 0.00967640
Iteration 3037, loss = 0.00967155
Iteration 3038, loss = 0.00966685
Iteration 3039, loss = 0.00966241
Iteration 3040, loss = 0.00965771
Iteration 3041, loss = 0.00965386
Iteration 3042, loss = 0.00964937
Iteration 3043, loss = 0.00964444
Iteration 3044, loss = 0.00964075
Iteration 3045, loss = 0.00963714
Iteration 3046, loss = 0.00963475
Iteration 3047, loss = 0.00962923
Iteration 3048, loss = 0.00962704
Iteration 3049, loss = 0.00962185
Iteration 3050, loss = 0.00961868
Iteration 3051, loss = 0.00961414
Iteration 3052, loss = 0.00961025
Iteration 3053, loss = 0.00960573
Iteration 3054, loss = 0.00960138
Iteration 3055, loss = 0.00959752
Iteration 3056, loss = 0.00959312
Iteration 3057, loss = 0.00958885
Iteration 3058, loss = 0.00958455
Iteration 3059, loss = 0.00957990
Iteration 3060, loss = 0.00957604
Iteration 3061, loss = 0.00957286
Iteration 3062, loss = 0.00956774
Iteration 3063, loss = 0.00956322
Iteration 3064, loss = 0.00955946
Iteration 3065, loss = 0.00955464
Iteration 3066, loss = 0.00955051
Iteration 3067, loss = 0.00954632
Iteration 3068, loss = 0.00954211
Iteration 3069, loss = 0.00953798
Iteration 3070, loss = 0.00953469
Iteration 3071, loss = 0.00952969
Iteration 3072, loss = 0.00952567
Iteration 3073, loss = 0.00952157
Iteration 3074, loss = 0.00951791
Iteration 3075, loss = 0.00951350
Iteration 3076, loss = 0.00950955
Iteration 3077, loss = 0.00950650
Iteration 3078, loss = 0.00950114
Iteration 3079, loss = 0.00949702
Iteration 3080, loss = 0.00949464
Iteration 3081, loss = 0.00948936
Iteration 3082, loss = 0.00948581
Iteration 3083, loss = 0.00948188
Iteration 3084, loss = 0.00947771
Iteration 3085, loss = 0.00947347
Iteration 3086, loss = 0.00947039
Iteration 3087, loss = 0.00946562
Iteration 3088, loss = 0.00946149
Iteration 3089, loss = 0.00945749
Iteration 3090, loss = 0.00945297
Iteration 3091, loss = 0.00944871
Iteration 3092, loss = 0.00944498
Iteration 3093, loss = 0.00944010
Iteration 3094, loss = 0.00943629
Iteration 3095, loss = 0.00943201
Iteration 3096, loss = 0.00942797
Iteration 3097, loss = 0.00942377
Iteration 3098, loss = 0.00941901
Iteration 3099, loss = 0.00941509
Iteration 3100, loss = 0.00941104
Iteration 3101, loss = 0.00940695
Iteration 3102, loss = 0.00940314
Iteration 3103, loss = 0.00939848
Iteration 3104, loss = 0.00939582
Iteration 3105, loss = 0.00939055
Iteration 3106, loss = 0.00938714
Iteration 3107, loss = 0.00938271
Iteration 3108, loss = 0.00937946
Iteration 3109, loss = 0.00937535
Iteration 3110, loss = 0.00937144
Iteration 3111, loss = 0.00936789
Iteration 3112, loss = 0.00936380
Iteration 3113, loss = 0.00935962
Iteration 3114, loss = 0.00935587
Iteration 3115, loss = 0.00935117
Iteration 3116, loss = 0.00934699
Iteration 3117, loss = 0.00934315
Iteration 3118, loss = 0.00933885
Iteration 3119, loss = 0.00933524
Iteration 3120, loss = 0.00933046
Iteration 3121, loss = 0.00932616
Iteration 3122, loss = 0.00932256
Iteration 3123, loss = 0.00931830
Iteration 3124, loss = 0.00931449
Iteration 3125, loss = 0.00931059
Iteration 3126, loss = 0.00930643
Iteration 3127, loss = 0.00930236
Iteration 3128, loss = 0.00929794
Iteration 3129, loss = 0.00929401
Iteration 3130, loss = 0.00928981
Iteration 3131, loss = 0.00928573
Iteration 3132, loss = 0.00928200
Iteration 3133, loss = 0.00927810
Iteration 3134, loss = 0.00927426
Iteration 3135, loss = 0.00927072
Iteration 3136, loss = 0.00926667
Iteration 3137, loss = 0.00926308
Iteration 3138, loss = 0.00926107
Iteration 3139, loss = 0.00925568
Iteration 3140, loss = 0.00925172
Iteration 3141, loss = 0.00924721
Iteration 3142, loss = 0.00924337
Iteration 3143, loss = 0.00923881
Iteration 3144, loss = 0.00923647
Iteration 3145, loss = 0.00923004
Iteration 3146, loss = 0.00922626
Iteration 3147, loss = 0.00922177
Iteration 3148, loss = 0.00921760
Iteration 3149, loss = 0.00921349
Iteration 3150, loss = 0.00920923
Iteration 3151, loss = 0.00920690
Iteration 3152, loss = 0.00920215
Iteration 3153, loss = 0.00919776
Iteration 3154, loss = 0.00919365
Iteration 3155, loss = 0.00919029
Iteration 3156, loss = 0.00918620
Iteration 3157, loss = 0.00918317
Iteration 3158, loss = 0.00917935
Iteration 3159, loss = 0.00917490
Iteration 3160, loss = 0.00917115
Iteration 3161, loss = 0.00916722
Iteration 3162, loss = 0.00916332
Iteration 3163, loss = 0.00915911
Iteration 3164, loss = 0.00915517
Iteration 3165, loss = 0.00915104
Iteration 3166, loss = 0.00914878
Iteration 3167, loss = 0.00914301
Iteration 3168, loss = 0.00914000
Iteration 3169, loss = 0.00913682
Iteration 3170, loss = 0.00913351
Iteration 3171, loss = 0.00912819
Iteration 3172, loss = 0.00912326
Iteration 3173, loss = 0.00911971
Iteration 3174, loss = 0.00911584
Iteration 3175, loss = 0.00911150
Iteration 3176, loss = 0.00910728
Iteration 3177, loss = 0.00910326
Iteration 3178, loss = 0.00909977
Iteration 3179, loss = 0.00909612
Iteration 3180, loss = 0.00909223
Iteration 3181, loss = 0.00908808
Iteration 3182, loss = 0.00908418
Iteration 3183, loss = 0.00908089
Iteration 3184, loss = 0.00907681
Iteration 3185, loss = 0.00907237
Iteration 3186, loss = 0.00906840
Iteration 3187, loss = 0.00906477
Iteration 3188, loss = 0.00906093
Iteration 3189, loss = 0.00905673
Iteration 3190, loss = 0.00905353
Iteration 3191, loss = 0.00904940
Iteration 3192, loss = 0.00904516
Iteration 3193, loss = 0.00904147
Iteration 3194, loss = 0.00903750
Iteration 3195, loss = 0.00903370
Iteration 3196, loss = 0.00903014
Iteration 3197, loss = 0.00902689
Iteration 3198, loss = 0.00902239
Iteration 3199, loss = 0.00901865
Iteration 3200, loss = 0.00901518
Iteration 3201, loss = 0.00901106
Iteration 3202, loss = 0.00900706
Iteration 3203, loss = 0.00900315
Iteration 3204, loss = 0.00899956
Iteration 3205, loss = 0.00899550
Iteration 3206, loss = 0.00899187
Iteration 3207, loss = 0.00898819
Iteration 3208, loss = 0.00898377
Iteration 3209, loss = 0.00898105
Iteration 3210, loss = 0.00897666
Iteration 3211, loss = 0.00897275
Iteration 3212, loss = 0.00896905
Iteration 3213, loss = 0.00896548
Iteration 3214, loss = 0.00896105
Iteration 3215, loss = 0.00895733
Iteration 3216, loss = 0.00895395
Iteration 3217, loss = 0.00895016
Iteration 3218, loss = 0.00894606
Iteration 3219, loss = 0.00894231
Iteration 3220, loss = 0.00893875
Iteration 3221, loss = 0.00893583
Iteration 3222, loss = 0.00893175
Iteration 3223, loss = 0.00892861
Iteration 3224, loss = 0.00892451
Iteration 3225, loss = 0.00892109
Iteration 3226, loss = 0.00891770
Iteration 3227, loss = 0.00891392
Iteration 3228, loss = 0.00891096
Iteration 3229, loss = 0.00890723
Iteration 3230, loss = 0.00890331
Iteration 3231, loss = 0.00889983
Iteration 3232, loss = 0.00889588
Iteration 3233, loss = 0.00889232
Iteration 3234, loss = 0.00888824
Iteration 3235, loss = 0.00888601
Iteration 3236, loss = 0.00888171
Iteration 3237, loss = 0.00887693
Iteration 3238, loss = 0.00887330
Iteration 3239, loss = 0.00887040
Iteration 3240, loss = 0.00886662
Iteration 3241, loss = 0.00886319
Iteration 3242, loss = 0.00885932
Iteration 3243, loss = 0.00885573
Iteration 3244, loss = 0.00885237
Iteration 3245, loss = 0.00884911
Iteration 3246, loss = 0.00884513
Iteration 3247, loss = 0.00884144
Iteration 3248, loss = 0.00883747
Iteration 3249, loss = 0.00883360
Iteration 3250, loss = 0.00882997
Iteration 3251, loss = 0.00882633
Iteration 3252, loss = 0.00882247
Iteration 3253, loss = 0.00881888
Iteration 3254, loss = 0.00881575
Iteration 3255, loss = 0.00881167
Iteration 3256, loss = 0.00880844
Iteration 3257, loss = 0.00880423
Iteration 3258, loss = 0.00880048
Iteration 3259, loss = 0.00879734
Iteration 3260, loss = 0.00879339
Iteration 3261, loss = 0.00878989
Iteration 3262, loss = 0.00878619
Iteration 3263, loss = 0.00878249
Iteration 3264, loss = 0.00877902
Iteration 3265, loss = 0.00877582
Iteration 3266, loss = 0.00877156
Iteration 3267, loss = 0.00876820
Iteration 3268, loss = 0.00876427
Iteration 3269, loss = 0.00876124
Iteration 3270, loss = 0.00875722
Iteration 3271, loss = 0.00875376
Iteration 3272, loss = 0.00874941
Iteration 3273, loss = 0.00874647
Iteration 3274, loss = 0.00874227
Iteration 3275, loss = 0.00873868
Iteration 3276, loss = 0.00873505
Iteration 3277, loss = 0.00873262
Iteration 3278, loss = 0.00872829
Iteration 3279, loss = 0.00872469
Iteration 3280, loss = 0.00872080
Iteration 3281, loss = 0.00871784
Iteration 3282, loss = 0.00871355
Iteration 3283, loss = 0.00871022
Iteration 3284, loss = 0.00870631
Iteration 3285, loss = 0.00870268
Iteration 3286, loss = 0.00869832
Iteration 3287, loss = 0.00869403
Iteration 3288, loss = 0.00869096
Iteration 3289, loss = 0.00868712
Iteration 3290, loss = 0.00868287
Iteration 3291, loss = 0.00867922
Iteration 3292, loss = 0.00867553
Iteration 3293, loss = 0.00867200
Iteration 3294, loss = 0.00866811
Iteration 3295, loss = 0.00866527
Iteration 3296, loss = 0.00866116
Iteration 3297, loss = 0.00865709
Iteration 3298, loss = 0.00865334
Iteration 3299, loss = 0.00865017
Iteration 3300, loss = 0.00864667
Iteration 3301, loss = 0.00864386
Iteration 3302, loss = 0.00863951
Iteration 3303, loss = 0.00863583
Iteration 3304, loss = 0.00863245
Iteration 3305, loss = 0.00862943
Iteration 3306, loss = 0.00862573
Iteration 3307, loss = 0.00862162
Iteration 3308, loss = 0.00861869
Iteration 3309, loss = 0.00861447
Iteration 3310, loss = 0.00861105
Iteration 3311, loss = 0.00860684
Iteration 3312, loss = 0.00860306
Iteration 3313, loss = 0.00859931
Iteration 3314, loss = 0.00859597
Iteration 3315, loss = 0.00859238
Iteration 3316, loss = 0.00858839
Iteration 3317, loss = 0.00858443
Iteration 3318, loss = 0.00858125
Iteration 3319, loss = 0.00857802
Iteration 3320, loss = 0.00857410
Iteration 3321, loss = 0.00857049
Iteration 3322, loss = 0.00856792
Iteration 3323, loss = 0.00856378
Iteration 3324, loss = 0.00856086
Iteration 3325, loss = 0.00855732
Iteration 3326, loss = 0.00855419
Iteration 3327, loss = 0.00855109
Iteration 3328, loss = 0.00854835
Iteration 3329, loss = 0.00854508
Iteration 3330, loss = 0.00854201
Iteration 3331, loss = 0.00853881
Iteration 3332, loss = 0.00853529
Iteration 3333, loss = 0.00853205
Iteration 3334, loss = 0.00852875
Iteration 3335, loss = 0.00852571
Iteration 3336, loss = 0.00852266
Iteration 3337, loss = 0.00852007
Iteration 3338, loss = 0.00851693
Iteration 3339, loss = 0.00851523
Iteration 3340, loss = 0.00851120
Iteration 3341, loss = 0.00850785
Iteration 3342, loss = 0.00850502
Iteration 3343, loss = 0.00850136
Iteration 3344, loss = 0.00849872
Iteration 3345, loss = 0.00849520
Iteration 3346, loss = 0.00849274
Iteration 3347, loss = 0.00848877
Iteration 3348, loss = 0.00848580
Iteration 3349, loss = 0.00848218
Iteration 3350, loss = 0.00847877
Iteration 3351, loss = 0.00847523
Iteration 3352, loss = 0.00847173
Iteration 3353, loss = 0.00846823
Iteration 3354, loss = 0.00846490
Iteration 3355, loss = 0.00846126
Iteration 3356, loss = 0.00845802
Iteration 3357, loss = 0.00845482
Iteration 3358, loss = 0.00845094
Iteration 3359, loss = 0.00844732
Iteration 3360, loss = 0.00844410
Iteration 3361, loss = 0.00844033
Iteration 3362, loss = 0.00843711
Iteration 3363, loss = 0.00843326
Iteration 3364, loss = 0.00843027
Iteration 3365, loss = 0.00842617
Iteration 3366, loss = 0.00842293
Iteration 3367, loss = 0.00841902
Iteration 3368, loss = 0.00841532
Iteration 3369, loss = 0.00841119
Iteration 3370, loss = 0.00840814
Iteration 3371, loss = 0.00840397
Iteration 3372, loss = 0.00840068
Iteration 3373, loss = 0.00839794
Iteration 3374, loss = 0.00839353
Iteration 3375, loss = 0.00839024
Iteration 3376, loss = 0.00838704
Iteration 3377, loss = 0.00838393
Iteration 3378, loss = 0.00838026
Iteration 3379, loss = 0.00837674
Iteration 3380, loss = 0.00837360
Iteration 3381, loss = 0.00836993
Iteration 3382, loss = 0.00836787
Iteration 3383, loss = 0.00836469
Iteration 3384, loss = 0.00836022
Iteration 3385, loss = 0.00835718
Iteration 3386, loss = 0.00835396
Iteration 3387, loss = 0.00835072
Iteration 3388, loss = 0.00834782
Iteration 3389, loss = 0.00834508
Iteration 3390, loss = 0.00834195
Iteration 3391, loss = 0.00833874
Iteration 3392, loss = 0.00833544
Iteration 3393, loss = 0.00833251
Iteration 3394, loss = 0.00832922
Iteration 3395, loss = 0.00832621
Iteration 3396, loss = 0.00832310
Iteration 3397, loss = 0.00832149
Iteration 3398, loss = 0.00831826
Iteration 3399, loss = 0.00831463
Iteration 3400, loss = 0.00831130
Iteration 3401, loss = 0.00830775
Iteration 3402, loss = 0.00830432
Iteration 3403, loss = 0.00830144
Iteration 3404, loss = 0.00829845
Iteration 3405, loss = 0.00829518
Iteration 3406, loss = 0.00829228
Iteration 3407, loss = 0.00828878
Iteration 3408, loss = 0.00828599
Iteration 3409, loss = 0.00828291
Iteration 3410, loss = 0.00828036
Iteration 3411, loss = 0.00827689
Iteration 3412, loss = 0.00827399
Iteration 3413, loss = 0.00827090
Iteration 3414, loss = 0.00826797
Iteration 3415, loss = 0.00826501
Iteration 3416, loss = 0.00826193
Iteration 3417, loss = 0.00825909
Iteration 3418, loss = 0.00825560
Iteration 3419, loss = 0.00825250
Iteration 3420, loss = 0.00824953
Iteration 3421, loss = 0.00824644
Iteration 3422, loss = 0.00824313
Iteration 3423, loss = 0.00824008
Iteration 3424, loss = 0.00823688
Iteration 3425, loss = 0.00823423
Iteration 3426, loss = 0.00823150
Iteration 3427, loss = 0.00822994
Iteration 3428, loss = 0.00822548
Iteration 3429, loss = 0.00822253
Iteration 3430, loss = 0.00822009
Iteration 3431, loss = 0.00821700
Iteration 3432, loss = 0.00821377
Iteration 3433, loss = 0.00821068
Iteration 3434, loss = 0.00820681
Iteration 3435, loss = 0.00820280
Iteration 3436, loss = 0.00819963
Iteration 3437, loss = 0.00819610
Iteration 3438, loss = 0.00819280
Iteration 3439, loss = 0.00818936
Iteration 3440, loss = 0.00818592
Iteration 3441, loss = 0.00818258
Iteration 3442, loss = 0.00817896
Iteration 3443, loss = 0.00817595
Iteration 3444, loss = 0.00817307
Iteration 3445, loss = 0.00817005
Iteration 3446, loss = 0.00816686
Iteration 3447, loss = 0.00816352
Iteration 3448, loss = 0.00816071
Iteration 3449, loss = 0.00815732
Iteration 3450, loss = 0.00815450
Iteration 3451, loss = 0.00815132
Iteration 3452, loss = 0.00814892
Iteration 3453, loss = 0.00814608
Iteration 3454, loss = 0.00814328
Iteration 3455, loss = 0.00814042
Iteration 3456, loss = 0.00813831
Iteration 3457, loss = 0.00813544
Iteration 3458, loss = 0.00813137
Iteration 3459, loss = 0.00812809
Iteration 3460, loss = 0.00812503
Iteration 3461, loss = 0.00812149
Iteration 3462, loss = 0.00811813
Iteration 3463, loss = 0.00811526
Iteration 3464, loss = 0.00811212
Iteration 3465, loss = 0.00810889
Iteration 3466, loss = 0.00810546
Iteration 3467, loss = 0.00810224
Iteration 3468, loss = 0.00809899
Iteration 3469, loss = 0.00809551
Iteration 3470, loss = 0.00809385
Iteration 3471, loss = 0.00808929
Iteration 3472, loss = 0.00808571
Iteration 3473, loss = 0.00808278
Iteration 3474, loss = 0.00807886
Iteration 3475, loss = 0.00807570
Iteration 3476, loss = 0.00807261
Iteration 3477, loss = 0.00806972
Iteration 3478, loss = 0.00806649
Iteration 3479, loss = 0.00806350
Iteration 3480, loss = 0.00806016
Iteration 3481, loss = 0.00805727
Iteration 3482, loss = 0.00805490
Iteration 3483, loss = 0.00805210
Iteration 3484, loss = 0.00804879
Iteration 3485, loss = 0.00804649
Iteration 3486, loss = 0.00804292
Iteration 3487, loss = 0.00804004
Iteration 3488, loss = 0.00803688
Iteration 3489, loss = 0.00803399
Iteration 3490, loss = 0.00803186
Iteration 3491, loss = 0.00802869
Iteration 3492, loss = 0.00802599
Iteration 3493, loss = 0.00802258
Iteration 3494, loss = 0.00801916
Iteration 3495, loss = 0.00801573
Iteration 3496, loss = 0.00801391
Iteration 3497, loss = 0.00800934
Iteration 3498, loss = 0.00800711
Iteration 3499, loss = 0.00800317
Iteration 3500, loss = 0.00799977
Iteration 3501, loss = 0.00799570
Iteration 3502, loss = 0.00799247
Iteration 3503, loss = 0.00798938
Iteration 3504, loss = 0.00798570
Iteration 3505, loss = 0.00798313
Iteration 3506, loss = 0.00797914
Iteration 3507, loss = 0.00797566
Iteration 3508, loss = 0.00797264
Iteration 3509, loss = 0.00796881
Iteration 3510, loss = 0.00796670
Iteration 3511, loss = 0.00796306
Iteration 3512, loss = 0.00795929
Iteration 3513, loss = 0.00795684
Iteration 3514, loss = 0.00795372
Iteration 3515, loss = 0.00795050
Iteration 3516, loss = 0.00794713
Iteration 3517, loss = 0.00794451
Iteration 3518, loss = 0.00794141
Iteration 3519, loss = 0.00793841
Iteration 3520, loss = 0.00793556
Iteration 3521, loss = 0.00793254
Iteration 3522, loss = 0.00792972
Iteration 3523, loss = 0.00792691
Iteration 3524, loss = 0.00792464
Iteration 3525, loss = 0.00792102
Iteration 3526, loss = 0.00791832
Iteration 3527, loss = 0.00791543
Iteration 3528, loss = 0.00791259
Iteration 3529, loss = 0.00790934
Iteration 3530, loss = 0.00790745
Iteration 3531, loss = 0.00790305
Iteration 3532, loss = 0.00790133
Iteration 3533, loss = 0.00789757
Iteration 3534, loss = 0.00789484
Iteration 3535, loss = 0.00789204
Iteration 3536, loss = 0.00788953
Iteration 3537, loss = 0.00788713
Iteration 3538, loss = 0.00788378
Iteration 3539, loss = 0.00788030
Iteration 3540, loss = 0.00787736
Iteration 3541, loss = 0.00787456
Iteration 3542, loss = 0.00787099
Iteration 3543, loss = 0.00786810
Iteration 3544, loss = 0.00786465
Iteration 3545, loss = 0.00786095
Iteration 3546, loss = 0.00785846
Iteration 3547, loss = 0.00785454
Iteration 3548, loss = 0.00785152
Iteration 3549, loss = 0.00784817
Iteration 3550, loss = 0.00784563
Iteration 3551, loss = 0.00784253
Iteration 3552, loss = 0.00783909
Iteration 3553, loss = 0.00783530
Iteration 3554, loss = 0.00783215
Iteration 3555, loss = 0.00782838
Iteration 3556, loss = 0.00782539
Iteration 3557, loss = 0.00782227
Iteration 3558, loss = 0.00781914
Iteration 3559, loss = 0.00781619
Iteration 3560, loss = 0.00781364
Iteration 3561, loss = 0.00781033
Iteration 3562, loss = 0.00780769
Iteration 3563, loss = 0.00780466
Iteration 3564, loss = 0.00780130
Iteration 3565, loss = 0.00779871
Iteration 3566, loss = 0.00779540
Iteration 3567, loss = 0.00779259
Iteration 3568, loss = 0.00778979
Iteration 3569, loss = 0.00778653
Iteration 3570, loss = 0.00778321
Iteration 3571, loss = 0.00778024
Iteration 3572, loss = 0.00777709
Iteration 3573, loss = 0.00777405
Iteration 3574, loss = 0.00777133
Iteration 3575, loss = 0.00776797
Iteration 3576, loss = 0.00776513
Iteration 3577, loss = 0.00776231
Iteration 3578, loss = 0.00775910
Iteration 3579, loss = 0.00775597
Iteration 3580, loss = 0.00775336
Iteration 3581, loss = 0.00775073
Iteration 3582, loss = 0.00774777
Iteration 3583, loss = 0.00774482
Iteration 3584, loss = 0.00774198
Iteration 3585, loss = 0.00773922
Iteration 3586, loss = 0.00773683
Iteration 3587, loss = 0.00773450
Iteration 3588, loss = 0.00773168
Iteration 3589, loss = 0.00772960
Iteration 3590, loss = 0.00772749
Iteration 3591, loss = 0.00772471
Iteration 3592, loss = 0.00772147
Iteration 3593, loss = 0.00771890
Iteration 3594, loss = 0.00771634
Iteration 3595, loss = 0.00771352
Iteration 3596, loss = 0.00771045
Iteration 3597, loss = 0.00770915
Iteration 3598, loss = 0.00770590
Iteration 3599, loss = 0.00770306
Iteration 3600, loss = 0.00770043
Iteration 3601, loss = 0.00769814
Iteration 3602, loss = 0.00769528
Iteration 3603, loss = 0.00769286
Iteration 3604, loss = 0.00769045
Iteration 3605, loss = 0.00768751
Iteration 3606, loss = 0.00768481
Iteration 3607, loss = 0.00768171
Iteration 3608, loss = 0.00767956
Iteration 3609, loss = 0.00767588
Iteration 3610, loss = 0.00767273
Iteration 3611, loss = 0.00766967
Iteration 3612, loss = 0.00766687
Iteration 3613, loss = 0.00766451
Iteration 3614, loss = 0.00766174
Iteration 3615, loss = 0.00765908
Iteration 3616, loss = 0.00765638
Iteration 3617, loss = 0.00765308
Iteration 3618, loss = 0.00765001
Iteration 3619, loss = 0.00764679
Iteration 3620, loss = 0.00764349
Iteration 3621, loss = 0.00764042
Iteration 3622, loss = 0.00763807
Iteration 3623, loss = 0.00763429
Iteration 3624, loss = 0.00763140
Iteration 3625, loss = 0.00762864
Iteration 3626, loss = 0.00762523
Iteration 3627, loss = 0.00762272
Iteration 3628, loss = 0.00762055
Iteration 3629, loss = 0.00761698
Iteration 3630, loss = 0.00761449
Iteration 3631, loss = 0.00761177
Iteration 3632, loss = 0.00760879
Iteration 3633, loss = 0.00760591
Iteration 3634, loss = 0.00760274
Iteration 3635, loss = 0.00759983
Iteration 3636, loss = 0.00759694
Iteration 3637, loss = 0.00759404
Iteration 3638, loss = 0.00759120
Iteration 3639, loss = 0.00758816
Iteration 3640, loss = 0.00758607
Iteration 3641, loss = 0.00758286
Iteration 3642, loss = 0.00758055
Iteration 3643, loss = 0.00757792
Iteration 3644, loss = 0.00757532
Iteration 3645, loss = 0.00757232
Iteration 3646, loss = 0.00756933
Iteration 3647, loss = 0.00756671
Iteration 3648, loss = 0.00756385
Iteration 3649, loss = 0.00756111
Iteration 3650, loss = 0.00755818
Iteration 3651, loss = 0.00755548
Iteration 3652, loss = 0.00755264
Iteration 3653, loss = 0.00755061
Iteration 3654, loss = 0.00754751
Iteration 3655, loss = 0.00754370
Iteration 3656, loss = 0.00754141
Iteration 3657, loss = 0.00753733
Iteration 3658, loss = 0.00753432
Iteration 3659, loss = 0.00753182
Iteration 3660, loss = 0.00752839
Iteration 3661, loss = 0.00752589
Iteration 3662, loss = 0.00752267
Iteration 3663, loss = 0.00751994
Iteration 3664, loss = 0.00751693
Iteration 3665, loss = 0.00751398
Iteration 3666, loss = 0.00751180
Iteration 3667, loss = 0.00750875
Iteration 3668, loss = 0.00750559
Iteration 3669, loss = 0.00750278
Iteration 3670, loss = 0.00750007
Iteration 3671, loss = 0.00749738
Iteration 3672, loss = 0.00749448
Iteration 3673, loss = 0.00749161
Iteration 3674, loss = 0.00748933
Iteration 3675, loss = 0.00748670
Iteration 3676, loss = 0.00748453
Iteration 3677, loss = 0.00748137
Iteration 3678, loss = 0.00747880
Iteration 3679, loss = 0.00747624
Iteration 3680, loss = 0.00747280
Iteration 3681, loss = 0.00747108
Iteration 3682, loss = 0.00746748
Iteration 3683, loss = 0.00746503
Iteration 3684, loss = 0.00746204
Iteration 3685, loss = 0.00745959
Iteration 3686, loss = 0.00745636
Iteration 3687, loss = 0.00745365
Iteration 3688, loss = 0.00745086
Iteration 3689, loss = 0.00744754
Iteration 3690, loss = 0.00744502
Iteration 3691, loss = 0.00744280
Iteration 3692, loss = 0.00744024
Iteration 3693, loss = 0.00743723
Iteration 3694, loss = 0.00743497
Iteration 3695, loss = 0.00743313
Iteration 3696, loss = 0.00743100
Iteration 3697, loss = 0.00742721
Iteration 3698, loss = 0.00742410
Iteration 3699, loss = 0.00742129
Iteration 3700, loss = 0.00741823
Iteration 3701, loss = 0.00741561
Iteration 3702, loss = 0.00741274
Iteration 3703, loss = 0.00740955
Iteration 3704, loss = 0.00740635
Iteration 3705, loss = 0.00740364
Iteration 3706, loss = 0.00740127
Iteration 3707, loss = 0.00739785
Iteration 3708, loss = 0.00739481
Iteration 3709, loss = 0.00739174
Iteration 3710, loss = 0.00738887
Iteration 3711, loss = 0.00738727
Iteration 3712, loss = 0.00738397
Iteration 3713, loss = 0.00738119
Iteration 3714, loss = 0.00737804
Iteration 3715, loss = 0.00737528
Iteration 3716, loss = 0.00737263
Iteration 3717, loss = 0.00736916
Iteration 3718, loss = 0.00736613
Iteration 3719, loss = 0.00736408
Iteration 3720, loss = 0.00736066
Iteration 3721, loss = 0.00735813
Iteration 3722, loss = 0.00735550
Iteration 3723, loss = 0.00735263
Iteration 3724, loss = 0.00734972
Iteration 3725, loss = 0.00734690
Iteration 3726, loss = 0.00734503
Iteration 3727, loss = 0.00734137
Iteration 3728, loss = 0.00733902
Iteration 3729, loss = 0.00733635
Iteration 3730, loss = 0.00733327
Iteration 3731, loss = 0.00733069
Iteration 3732, loss = 0.00732799
Iteration 3733, loss = 0.00732511
Iteration 3734, loss = 0.00732288
Iteration 3735, loss = 0.00731953
Iteration 3736, loss = 0.00731663
Iteration 3737, loss = 0.00731395
Iteration 3738, loss = 0.00731131
Iteration 3739, loss = 0.00730846
Iteration 3740, loss = 0.00730594
Iteration 3741, loss = 0.00730285
Iteration 3742, loss = 0.00730019
Iteration 3743, loss = 0.00729890
Iteration 3744, loss = 0.00729469
Iteration 3745, loss = 0.00729209
Iteration 3746, loss = 0.00728946
Iteration 3747, loss = 0.00728685
Iteration 3748, loss = 0.00728428
Iteration 3749, loss = 0.00728153
Iteration 3750, loss = 0.00727894
Iteration 3751, loss = 0.00727637
Iteration 3752, loss = 0.00727412
Iteration 3753, loss = 0.00727129
Iteration 3754, loss = 0.00726870
Iteration 3755, loss = 0.00726657
Iteration 3756, loss = 0.00726401
Iteration 3757, loss = 0.00726129
Iteration 3758, loss = 0.00725852
Iteration 3759, loss = 0.00725601
Iteration 3760, loss = 0.00725400
Iteration 3761, loss = 0.00725083
Iteration 3762, loss = 0.00724844
Iteration 3763, loss = 0.00724554
Iteration 3764, loss = 0.00724266
Iteration 3765, loss = 0.00724053
Iteration 3766, loss = 0.00723784
Iteration 3767, loss = 0.00723505
Iteration 3768, loss = 0.00723228
Iteration 3769, loss = 0.00722940
Iteration 3770, loss = 0.00722703
Iteration 3771, loss = 0.00722543
Iteration 3772, loss = 0.00722157
Iteration 3773, loss = 0.00721871
Iteration 3774, loss = 0.00721607
Iteration 3775, loss = 0.00721373
Iteration 3776, loss = 0.00721054
Iteration 3777, loss = 0.00720775
Iteration 3778, loss = 0.00720515
Iteration 3779, loss = 0.00720360
Iteration 3780, loss = 0.00720033
Iteration 3781, loss = 0.00719808
Iteration 3782, loss = 0.00719667
Iteration 3783, loss = 0.00719335
Iteration 3784, loss = 0.00719039
Iteration 3785, loss = 0.00718804
Iteration 3786, loss = 0.00718763
Iteration 3787, loss = 0.00718344
Iteration 3788, loss = 0.00718014
Iteration 3789, loss = 0.00717771
Iteration 3790, loss = 0.00717521
Iteration 3791, loss = 0.00717250
Iteration 3792, loss = 0.00716987
Iteration 3793, loss = 0.00716754
Iteration 3794, loss = 0.00716477
Iteration 3795, loss = 0.00716248
Iteration 3796, loss = 0.00715993
Iteration 3797, loss = 0.00715739
Iteration 3798, loss = 0.00715489
Iteration 3799, loss = 0.00715263
Iteration 3800, loss = 0.00715052
Iteration 3801, loss = 0.00714801
Iteration 3802, loss = 0.00714582
Iteration 3803, loss = 0.00714356
Iteration 3804, loss = 0.00714130
Iteration 3805, loss = 0.00713888
Iteration 3806, loss = 0.00713594
Iteration 3807, loss = 0.00713321
Iteration 3808, loss = 0.00713155
Iteration 3809, loss = 0.00712924
Iteration 3810, loss = 0.00712576
Iteration 3811, loss = 0.00712407
Iteration 3812, loss = 0.00712109
Iteration 3813, loss = 0.00711882
Iteration 3814, loss = 0.00711617
Iteration 3815, loss = 0.00711357
Iteration 3816, loss = 0.00711238
Iteration 3817, loss = 0.00710889
Iteration 3818, loss = 0.00710622
Iteration 3819, loss = 0.00710350
Iteration 3820, loss = 0.00710118
Iteration 3821, loss = 0.00709850
Iteration 3822, loss = 0.00709600
Iteration 3823, loss = 0.00709324
Iteration 3824, loss = 0.00709091
Iteration 3825, loss = 0.00708830
Iteration 3826, loss = 0.00708625
Iteration 3827, loss = 0.00708352
Iteration 3828, loss = 0.00708145
Iteration 3829, loss = 0.00707860
Iteration 3830, loss = 0.00707614
Iteration 3831, loss = 0.00707344
Iteration 3832, loss = 0.00707122
Iteration 3833, loss = 0.00706826
Iteration 3834, loss = 0.00706569
Iteration 3835, loss = 0.00706285
Iteration 3836, loss = 0.00706055
Iteration 3837, loss = 0.00705932
Iteration 3838, loss = 0.00705517
Iteration 3839, loss = 0.00705242
Iteration 3840, loss = 0.00704995
Iteration 3841, loss = 0.00704748
Iteration 3842, loss = 0.00704539
Iteration 3843, loss = 0.00704182
Iteration 3844, loss = 0.00703902
Iteration 3845, loss = 0.00703644
Iteration 3846, loss = 0.00703353
Iteration 3847, loss = 0.00703142
Iteration 3848, loss = 0.00702831
Iteration 3849, loss = 0.00702601
Iteration 3850, loss = 0.00702317
Iteration 3851, loss = 0.00702126
Iteration 3852, loss = 0.00701878
Iteration 3853, loss = 0.00701620
Iteration 3854, loss = 0.00701401
Iteration 3855, loss = 0.00701182
Iteration 3856, loss = 0.00700934
Iteration 3857, loss = 0.00700690
Iteration 3858, loss = 0.00700523
Iteration 3859, loss = 0.00700248
Iteration 3860, loss = 0.00700051
Iteration 3861, loss = 0.00699772
Iteration 3862, loss = 0.00699561
Iteration 3863, loss = 0.00699287
Iteration 3864, loss = 0.00699018
Iteration 3865, loss = 0.00698781
Iteration 3866, loss = 0.00698527
Iteration 3867, loss = 0.00698229
Iteration 3868, loss = 0.00698012
Iteration 3869, loss = 0.00697740
Iteration 3870, loss = 0.00697486
Iteration 3871, loss = 0.00697239
Iteration 3872, loss = 0.00696975
Iteration 3873, loss = 0.00696752
Iteration 3874, loss = 0.00696483
Iteration 3875, loss = 0.00696235
Iteration 3876, loss = 0.00696012
Iteration 3877, loss = 0.00695765
Iteration 3878, loss = 0.00695523
Iteration 3879, loss = 0.00695284
Iteration 3880, loss = 0.00695064
Iteration 3881, loss = 0.00694804
Iteration 3882, loss = 0.00694582
Iteration 3883, loss = 0.00694315
Iteration 3884, loss = 0.00694066
Iteration 3885, loss = 0.00693813
Iteration 3886, loss = 0.00693585
Iteration 3887, loss = 0.00693337
Iteration 3888, loss = 0.00693074
Iteration 3889, loss = 0.00692849
Iteration 3890, loss = 0.00692675
Iteration 3891, loss = 0.00692375
Iteration 3892, loss = 0.00692125
Iteration 3893, loss = 0.00691860
Iteration 3894, loss = 0.00691666
Iteration 3895, loss = 0.00691373
Iteration 3896, loss = 0.00691177
Iteration 3897, loss = 0.00690897
Iteration 3898, loss = 0.00690703
Iteration 3899, loss = 0.00690430
Iteration 3900, loss = 0.00690175
Iteration 3901, loss = 0.00689971
Iteration 3902, loss = 0.00689794
Iteration 3903, loss = 0.00689465
Iteration 3904, loss = 0.00689224
Iteration 3905, loss = 0.00689057
Iteration 3906, loss = 0.00688800
Iteration 3907, loss = 0.00688595
Iteration 3908, loss = 0.00688345
Iteration 3909, loss = 0.00688096
Iteration 3910, loss = 0.00687878
Iteration 3911, loss = 0.00687697
Iteration 3912, loss = 0.00687417
Iteration 3913, loss = 0.00687197
Iteration 3914, loss = 0.00686920
Iteration 3915, loss = 0.00686665
Iteration 3916, loss = 0.00686459
Iteration 3917, loss = 0.00686171
Iteration 3918, loss = 0.00685959
Iteration 3919, loss = 0.00685751
Iteration 3920, loss = 0.00685495
Iteration 3921, loss = 0.00685283
Iteration 3922, loss = 0.00685036
Iteration 3923, loss = 0.00684818
Iteration 3924, loss = 0.00684573
Iteration 3925, loss = 0.00684306
Iteration 3926, loss = 0.00684103
Iteration 3927, loss = 0.00683859
Iteration 3928, loss = 0.00683683
Iteration 3929, loss = 0.00683476
Iteration 3930, loss = 0.00683141
Iteration 3931, loss = 0.00682940
Iteration 3932, loss = 0.00682739
Iteration 3933, loss = 0.00682475
Iteration 3934, loss = 0.00682239
Iteration 3935, loss = 0.00682030
Iteration 3936, loss = 0.00681832
Iteration 3937, loss = 0.00681748
Iteration 3938, loss = 0.00681382
Iteration 3939, loss = 0.00681158
Iteration 3940, loss = 0.00680907
Iteration 3941, loss = 0.00680650
Iteration 3942, loss = 0.00680432
Iteration 3943, loss = 0.00680167
Iteration 3944, loss = 0.00679927
Iteration 3945, loss = 0.00679713
Iteration 3946, loss = 0.00679485
Iteration 3947, loss = 0.00679289
Iteration 3948, loss = 0.00679074
Iteration 3949, loss = 0.00678819
Iteration 3950, loss = 0.00678611
Iteration 3951, loss = 0.00678360
Iteration 3952, loss = 0.00678153
Iteration 3953, loss = 0.00677948
Iteration 3954, loss = 0.00677819
Iteration 3955, loss = 0.00677537
Iteration 3956, loss = 0.00677358
Iteration 3957, loss = 0.00677153
Iteration 3958, loss = 0.00676931
Iteration 3959, loss = 0.00676717
Iteration 3960, loss = 0.00676482
Iteration 3961, loss = 0.00676238
Iteration 3962, loss = 0.00675998
Iteration 3963, loss = 0.00675746
Iteration 3964, loss = 0.00675512
Iteration 3965, loss = 0.00675228
Iteration 3966, loss = 0.00675012
Iteration 3967, loss = 0.00674727
Iteration 3968, loss = 0.00674490
Iteration 3969, loss = 0.00674212
Iteration 3970, loss = 0.00673949
Iteration 3971, loss = 0.00673794
Iteration 3972, loss = 0.00673471
Iteration 3973, loss = 0.00673244
Iteration 3974, loss = 0.00673031
Iteration 3975, loss = 0.00672736
Iteration 3976, loss = 0.00672534
Iteration 3977, loss = 0.00672310
Iteration 3978, loss = 0.00672091
Iteration 3979, loss = 0.00671824
Iteration 3980, loss = 0.00671623
Iteration 3981, loss = 0.00671395
Iteration 3982, loss = 0.00671215
Iteration 3983, loss = 0.00670970
Iteration 3984, loss = 0.00670864
Iteration 3985, loss = 0.00670545
Iteration 3986, loss = 0.00670305
Iteration 3987, loss = 0.00670103
Iteration 3988, loss = 0.00669873
Iteration 3989, loss = 0.00669640
Iteration 3990, loss = 0.00669445
Iteration 3991, loss = 0.00669198
Iteration 3992, loss = 0.00668968
Iteration 3993, loss = 0.00668791
Iteration 3994, loss = 0.00668552
Iteration 3995, loss = 0.00668332
Iteration 3996, loss = 0.00668138
Iteration 3997, loss = 0.00667930
Iteration 3998, loss = 0.00667733
Iteration 3999, loss = 0.00667547
Iteration 4000, loss = 0.00667330
Iteration 4001, loss = 0.00667152
Iteration 4002, loss = 0.00666925
Iteration 4003, loss = 0.00666703
Iteration 4004, loss = 0.00666493
Iteration 4005, loss = 0.00666318
Iteration 4006, loss = 0.00666068
Iteration 4007, loss = 0.00665841
Iteration 4008, loss = 0.00665644
Iteration 4009, loss = 0.00665386
Iteration 4010, loss = 0.00665135
Iteration 4011, loss = 0.00664878
Iteration 4012, loss = 0.00664720
Iteration 4013, loss = 0.00664406
Iteration 4014, loss = 0.00664290
Iteration 4015, loss = 0.00663994
Iteration 4016, loss = 0.00663764
Iteration 4017, loss = 0.00663594
Iteration 4018, loss = 0.00663334
Iteration 4019, loss = 0.00663090
Iteration 4020, loss = 0.00662929
Iteration 4021, loss = 0.00662688
Iteration 4022, loss = 0.00662481
Iteration 4023, loss = 0.00662263
Iteration 4024, loss = 0.00662022
Iteration 4025, loss = 0.00661843
Iteration 4026, loss = 0.00661644
Iteration 4027, loss = 0.00661436
Iteration 4028, loss = 0.00661240
Iteration 4029, loss = 0.00661048
Iteration 4030, loss = 0.00660818
Iteration 4031, loss = 0.00660635
Iteration 4032, loss = 0.00660417
Iteration 4033, loss = 0.00660196
Iteration 4034, loss = 0.00660017
Iteration 4035, loss = 0.00659796
Iteration 4036, loss = 0.00659613
Iteration 4037, loss = 0.00659369
Iteration 4038, loss = 0.00659157
Iteration 4039, loss = 0.00658910
Iteration 4040, loss = 0.00658675
Iteration 4041, loss = 0.00658447
Iteration 4042, loss = 0.00658178
Iteration 4043, loss = 0.00657986
Iteration 4044, loss = 0.00657752
Iteration 4045, loss = 0.00657520
Iteration 4046, loss = 0.00657292
Iteration 4047, loss = 0.00657074
Iteration 4048, loss = 0.00656863
Iteration 4049, loss = 0.00656652
Iteration 4050, loss = 0.00656431
Iteration 4051, loss = 0.00656206
Iteration 4052, loss = 0.00656000
Iteration 4053, loss = 0.00655774
Iteration 4054, loss = 0.00655524
Iteration 4055, loss = 0.00655350
Iteration 4056, loss = 0.00655066
Iteration 4057, loss = 0.00654888
Iteration 4058, loss = 0.00654616
Iteration 4059, loss = 0.00654389
Iteration 4060, loss = 0.00654187
Iteration 4061, loss = 0.00653976
Iteration 4062, loss = 0.00653783
Iteration 4063, loss = 0.00653548
Iteration 4064, loss = 0.00653324
Iteration 4065, loss = 0.00653117
Iteration 4066, loss = 0.00652910
Iteration 4067, loss = 0.00652705
Iteration 4068, loss = 0.00652527
Iteration 4069, loss = 0.00652337
Iteration 4070, loss = 0.00652124
Iteration 4071, loss = 0.00651923
Iteration 4072, loss = 0.00651756
Iteration 4073, loss = 0.00651609
Iteration 4074, loss = 0.00651408
Iteration 4075, loss = 0.00651210
Iteration 4076, loss = 0.00650944
Iteration 4077, loss = 0.00650722
Iteration 4078, loss = 0.00650484
Iteration 4079, loss = 0.00650277
Iteration 4080, loss = 0.00650049
Iteration 4081, loss = 0.00649851
Iteration 4082, loss = 0.00649617
Iteration 4083, loss = 0.00649359
Iteration 4084, loss = 0.00649167
Iteration 4085, loss = 0.00648871
Iteration 4086, loss = 0.00648672
Iteration 4087, loss = 0.00648452
Iteration 4088, loss = 0.00648258
Iteration 4089, loss = 0.00648067
Iteration 4090, loss = 0.00647886
Iteration 4091, loss = 0.00647648
Iteration 4092, loss = 0.00647456
Iteration 4093, loss = 0.00647272
Iteration 4094, loss = 0.00647130
Iteration 4095, loss = 0.00646930
Iteration 4096, loss = 0.00646714
Iteration 4097, loss = 0.00646582
Iteration 4098, loss = 0.00646353
Iteration 4099, loss = 0.00646141
Iteration 4100, loss = 0.00645943
Iteration 4101, loss = 0.00645765
Iteration 4102, loss = 0.00645564
Iteration 4103, loss = 0.00645359
Iteration 4104, loss = 0.00645175
Iteration 4105, loss = 0.00644998
Iteration 4106, loss = 0.00644990
Iteration 4107, loss = 0.00644600
Iteration 4108, loss = 0.00644384
Iteration 4109, loss = 0.00644116
Iteration 4110, loss = 0.00643920
Iteration 4111, loss = 0.00643662
Iteration 4112, loss = 0.00643450
Iteration 4113, loss = 0.00643309
Iteration 4114, loss = 0.00643006
Iteration 4115, loss = 0.00642841
Iteration 4116, loss = 0.00642421
Iteration 4117, loss = 0.00642309
Iteration 4118, loss = 0.00642154
Iteration 4119, loss = 0.00641752
Iteration 4120, loss = 0.00641516
Iteration 4121, loss = 0.00641296
Iteration 4122, loss = 0.00641076
Iteration 4123, loss = 0.00640983
Iteration 4124, loss = 0.00640660
Iteration 4125, loss = 0.00640414
Iteration 4126, loss = 0.00640200
Iteration 4127, loss = 0.00639977
Iteration 4128, loss = 0.00639750
Iteration 4129, loss = 0.00639553
Iteration 4130, loss = 0.00639321
Iteration 4131, loss = 0.00639132
Iteration 4132, loss = 0.00638899
Iteration 4133, loss = 0.00638767
Iteration 4134, loss = 0.00638539
Iteration 4135, loss = 0.00638363
Iteration 4136, loss = 0.00638162
Iteration 4137, loss = 0.00637950
Iteration 4138, loss = 0.00637741
Iteration 4139, loss = 0.00637520
Iteration 4140, loss = 0.00637290
Iteration 4141, loss = 0.00637124
Iteration 4142, loss = 0.00636841
Iteration 4143, loss = 0.00636602
Iteration 4144, loss = 0.00636361
Iteration 4145, loss = 0.00636142
Iteration 4146, loss = 0.00635946
Iteration 4147, loss = 0.00635685
Iteration 4148, loss = 0.00635458
Iteration 4149, loss = 0.00635265
Iteration 4150, loss = 0.00635029
Iteration 4151, loss = 0.00634861
Iteration 4152, loss = 0.00634615
Iteration 4153, loss = 0.00634422
Iteration 4154, loss = 0.00634194
Iteration 4155, loss = 0.00634002
Iteration 4156, loss = 0.00633803
Iteration 4157, loss = 0.00633605
Iteration 4158, loss = 0.00633402
Iteration 4159, loss = 0.00633217
Iteration 4160, loss = 0.00633032
Iteration 4161, loss = 0.00632838
Iteration 4162, loss = 0.00632643
Iteration 4163, loss = 0.00632443
Iteration 4164, loss = 0.00632285
Iteration 4165, loss = 0.00632084
Iteration 4166, loss = 0.00631880
Iteration 4167, loss = 0.00631725
Iteration 4168, loss = 0.00631537
Iteration 4169, loss = 0.00631396
Iteration 4170, loss = 0.00631127
Iteration 4171, loss = 0.00630923
Iteration 4172, loss = 0.00630806
Iteration 4173, loss = 0.00630601
Iteration 4174, loss = 0.00630390
Iteration 4175, loss = 0.00630141
Iteration 4176, loss = 0.00629910
Iteration 4177, loss = 0.00629682
Iteration 4178, loss = 0.00629549
Iteration 4179, loss = 0.00629285
Iteration 4180, loss = 0.00629083
Iteration 4181, loss = 0.00628855
Iteration 4182, loss = 0.00628689
Iteration 4183, loss = 0.00628471
Iteration 4184, loss = 0.00628254
Iteration 4185, loss = 0.00628033
Iteration 4186, loss = 0.00627800
Iteration 4187, loss = 0.00627598
Iteration 4188, loss = 0.00627385
Iteration 4189, loss = 0.00627162
Iteration 4190, loss = 0.00626958
Iteration 4191, loss = 0.00626789
Iteration 4192, loss = 0.00626574
Iteration 4193, loss = 0.00626385
Iteration 4194, loss = 0.00626163
Iteration 4195, loss = 0.00625984
Iteration 4196, loss = 0.00625891
Iteration 4197, loss = 0.00625538
Iteration 4198, loss = 0.00625316
Iteration 4199, loss = 0.00625080
Iteration 4200, loss = 0.00624950
Iteration 4201, loss = 0.00624673
Iteration 4202, loss = 0.00624488
Iteration 4203, loss = 0.00624285
Iteration 4204, loss = 0.00624087
Iteration 4205, loss = 0.00623842
Iteration 4206, loss = 0.00623647
Iteration 4207, loss = 0.00623440
Iteration 4208, loss = 0.00623249
Iteration 4209, loss = 0.00623068
Iteration 4210, loss = 0.00622881
Iteration 4211, loss = 0.00622762
Iteration 4212, loss = 0.00622486
Iteration 4213, loss = 0.00622316
Iteration 4214, loss = 0.00622114
Iteration 4215, loss = 0.00621875
Iteration 4216, loss = 0.00621650
Iteration 4217, loss = 0.00621457
Iteration 4218, loss = 0.00621215
Iteration 4219, loss = 0.00621056
Iteration 4220, loss = 0.00620837
Iteration 4221, loss = 0.00620757
Iteration 4222, loss = 0.00620453
Iteration 4223, loss = 0.00620249
Iteration 4224, loss = 0.00620041
Iteration 4225, loss = 0.00619817
Iteration 4226, loss = 0.00619611
Iteration 4227, loss = 0.00619638
Iteration 4228, loss = 0.00619293
Iteration 4229, loss = 0.00619062
Iteration 4230, loss = 0.00618893
Iteration 4231, loss = 0.00618708
Iteration 4232, loss = 0.00618479
Iteration 4233, loss = 0.00618266
Iteration 4234, loss = 0.00618072
Iteration 4235, loss = 0.00617869
Iteration 4236, loss = 0.00617678
Iteration 4237, loss = 0.00617460
Iteration 4238, loss = 0.00617257
Iteration 4239, loss = 0.00617089
Iteration 4240, loss = 0.00616882
Iteration 4241, loss = 0.00616668
Iteration 4242, loss = 0.00616501
Iteration 4243, loss = 0.00616274
Iteration 4244, loss = 0.00616085
Iteration 4245, loss = 0.00615869
Iteration 4246, loss = 0.00615651
Iteration 4247, loss = 0.00615451
Iteration 4248, loss = 0.00615229
Iteration 4249, loss = 0.00615171
Iteration 4250, loss = 0.00614849
Iteration 4251, loss = 0.00614648
Iteration 4252, loss = 0.00614435
Iteration 4253, loss = 0.00614295
Iteration 4254, loss = 0.00614042
Iteration 4255, loss = 0.00613856
Iteration 4256, loss = 0.00613649
Iteration 4257, loss = 0.00613443
Iteration 4258, loss = 0.00613248
Iteration 4259, loss = 0.00613062
Iteration 4260, loss = 0.00612873
Iteration 4261, loss = 0.00612678
Iteration 4262, loss = 0.00612507
Iteration 4263, loss = 0.00612301
Iteration 4264, loss = 0.00612082
Iteration 4265, loss = 0.00611864
Iteration 4266, loss = 0.00611680
Iteration 4267, loss = 0.00611530
Iteration 4268, loss = 0.00611278
Iteration 4269, loss = 0.00611069
Iteration 4270, loss = 0.00610843
Iteration 4271, loss = 0.00610686
Iteration 4272, loss = 0.00610460
Iteration 4273, loss = 0.00610274
Iteration 4274, loss = 0.00610089
Iteration 4275, loss = 0.00609867
Iteration 4276, loss = 0.00609732
Iteration 4277, loss = 0.00609460
Iteration 4278, loss = 0.00609241
Iteration 4279, loss = 0.00609035
Iteration 4280, loss = 0.00608825
Iteration 4281, loss = 0.00608630
Iteration 4282, loss = 0.00608391
Iteration 4283, loss = 0.00608174
Iteration 4284, loss = 0.00608001
Iteration 4285, loss = 0.00607769
Iteration 4286, loss = 0.00607658
Iteration 4287, loss = 0.00607404
Iteration 4288, loss = 0.00607242
Iteration 4289, loss = 0.00607080
Iteration 4290, loss = 0.00606853
Iteration 4291, loss = 0.00606649
Iteration 4292, loss = 0.00606472
Iteration 4293, loss = 0.00606302
Iteration 4294, loss = 0.00606297
Iteration 4295, loss = 0.00606058
Iteration 4296, loss = 0.00605803
Iteration 4297, loss = 0.00605612
Iteration 4298, loss = 0.00605387
Iteration 4299, loss = 0.00605217
Iteration 4300, loss = 0.00605001
Iteration 4301, loss = 0.00604803
Iteration 4302, loss = 0.00604611
Iteration 4303, loss = 0.00604421
Iteration 4304, loss = 0.00604216
Iteration 4305, loss = 0.00604033
Iteration 4306, loss = 0.00603874
Iteration 4307, loss = 0.00603709
Iteration 4308, loss = 0.00603535
Iteration 4309, loss = 0.00603368
Iteration 4310, loss = 0.00603170
Iteration 4311, loss = 0.00602989
Iteration 4312, loss = 0.00602809
Iteration 4313, loss = 0.00602647
Iteration 4314, loss = 0.00602435
Iteration 4315, loss = 0.00602270
Iteration 4316, loss = 0.00602095
Iteration 4317, loss = 0.00601901
Iteration 4318, loss = 0.00601723
Iteration 4319, loss = 0.00601543
Iteration 4320, loss = 0.00601370
Iteration 4321, loss = 0.00601199
Iteration 4322, loss = 0.00601027
Iteration 4323, loss = 0.00600842
Iteration 4324, loss = 0.00600669
Iteration 4325, loss = 0.00600518
Iteration 4326, loss = 0.00600349
Iteration 4327, loss = 0.00600129
Iteration 4328, loss = 0.00599952
Iteration 4329, loss = 0.00599758
Iteration 4330, loss = 0.00599615
Iteration 4331, loss = 0.00599378
Iteration 4332, loss = 0.00599220
Iteration 4333, loss = 0.00598971
Iteration 4334, loss = 0.00598766
Iteration 4335, loss = 0.00598603
Iteration 4336, loss = 0.00598410
Iteration 4337, loss = 0.00598263
Iteration 4338, loss = 0.00598057
Iteration 4339, loss = 0.00597860
Iteration 4340, loss = 0.00597707
Iteration 4341, loss = 0.00597505
Iteration 4342, loss = 0.00597338
Iteration 4343, loss = 0.00597143
Iteration 4344, loss = 0.00596989
Iteration 4345, loss = 0.00596917
Iteration 4346, loss = 0.00596668
Iteration 4347, loss = 0.00596483
Iteration 4348, loss = 0.00596300
Iteration 4349, loss = 0.00596104
Iteration 4350, loss = 0.00595916
Iteration 4351, loss = 0.00595741
Iteration 4352, loss = 0.00595568
Iteration 4353, loss = 0.00595383
Iteration 4354, loss = 0.00595174
Iteration 4355, loss = 0.00595027
Iteration 4356, loss = 0.00594849
Iteration 4357, loss = 0.00594682
Iteration 4358, loss = 0.00594511
Iteration 4359, loss = 0.00594306
Iteration 4360, loss = 0.00594109
Iteration 4361, loss = 0.00593966
Iteration 4362, loss = 0.00593751
Iteration 4363, loss = 0.00593560
Iteration 4364, loss = 0.00593341
Iteration 4365, loss = 0.00593170
Iteration 4366, loss = 0.00592984
Iteration 4367, loss = 0.00592786
Iteration 4368, loss = 0.00592617
Iteration 4369, loss = 0.00592412
Iteration 4370, loss = 0.00592217
Iteration 4371, loss = 0.00592009
Iteration 4372, loss = 0.00591821
Iteration 4373, loss = 0.00591674
Iteration 4374, loss = 0.00591507
Iteration 4375, loss = 0.00591293
Iteration 4376, loss = 0.00591164
Iteration 4377, loss = 0.00590966
Iteration 4378, loss = 0.00590745
Iteration 4379, loss = 0.00590573
Iteration 4380, loss = 0.00590382
Iteration 4381, loss = 0.00590202
Iteration 4382, loss = 0.00590005
Iteration 4383, loss = 0.00589840
Iteration 4384, loss = 0.00589662
Iteration 4385, loss = 0.00589463
Iteration 4386, loss = 0.00589257
Iteration 4387, loss = 0.00589088
Iteration 4388, loss = 0.00588901
Iteration 4389, loss = 0.00588691
Iteration 4390, loss = 0.00588546
Iteration 4391, loss = 0.00588306
Iteration 4392, loss = 0.00588108
Iteration 4393, loss = 0.00587894
Iteration 4394, loss = 0.00587748
Iteration 4395, loss = 0.00587515
Iteration 4396, loss = 0.00587338
Iteration 4397, loss = 0.00587148
Iteration 4398, loss = 0.00586981
Iteration 4399, loss = 0.00586787
Iteration 4400, loss = 0.00586600
Iteration 4401, loss = 0.00586409
Iteration 4402, loss = 0.00586232
Iteration 4403, loss = 0.00586050
Iteration 4404, loss = 0.00585877
Iteration 4405, loss = 0.00585682
Iteration 4406, loss = 0.00585464
Iteration 4407, loss = 0.00585287
Iteration 4408, loss = 0.00585116
Iteration 4409, loss = 0.00584916
Iteration 4410, loss = 0.00584729
Iteration 4411, loss = 0.00584562
Iteration 4412, loss = 0.00584364
Iteration 4413, loss = 0.00584222
Iteration 4414, loss = 0.00584032
Iteration 4415, loss = 0.00583865
Iteration 4416, loss = 0.00583695
Iteration 4417, loss = 0.00583531
Iteration 4418, loss = 0.00583356
Iteration 4419, loss = 0.00583228
Iteration 4420, loss = 0.00583017
Iteration 4421, loss = 0.00582853
Iteration 4422, loss = 0.00582684
Iteration 4423, loss = 0.00582509
Iteration 4424, loss = 0.00582313
Iteration 4425, loss = 0.00582203
Iteration 4426, loss = 0.00581982
Iteration 4427, loss = 0.00581773
Iteration 4428, loss = 0.00581602
Iteration 4429, loss = 0.00581406
Iteration 4430, loss = 0.00581233
Iteration 4431, loss = 0.00581050
Iteration 4432, loss = 0.00580892
Iteration 4433, loss = 0.00580687
Iteration 4434, loss = 0.00580510
Iteration 4435, loss = 0.00580332
Iteration 4436, loss = 0.00580173
Iteration 4437, loss = 0.00579997
Iteration 4438, loss = 0.00579848
Iteration 4439, loss = 0.00579636
Iteration 4440, loss = 0.00579444
Iteration 4441, loss = 0.00579286
Iteration 4442, loss = 0.00579076
Iteration 4443, loss = 0.00578899
Iteration 4444, loss = 0.00578716
Iteration 4445, loss = 0.00578530
Iteration 4446, loss = 0.00578366
Iteration 4447, loss = 0.00578173
Iteration 4448, loss = 0.00578032
Iteration 4449, loss = 0.00577842
Iteration 4450, loss = 0.00577641
Iteration 4451, loss = 0.00577496
Iteration 4452, loss = 0.00577311
Iteration 4453, loss = 0.00577141
Iteration 4454, loss = 0.00576938
Iteration 4455, loss = 0.00576771
Iteration 4456, loss = 0.00576578
Iteration 4457, loss = 0.00576395
Iteration 4458, loss = 0.00576225
Iteration 4459, loss = 0.00576091
Iteration 4460, loss = 0.00575846
Iteration 4461, loss = 0.00575677
Iteration 4462, loss = 0.00575466
Iteration 4463, loss = 0.00575340
Iteration 4464, loss = 0.00575143
Iteration 4465, loss = 0.00574975
Iteration 4466, loss = 0.00574819
Iteration 4467, loss = 0.00574663
Iteration 4468, loss = 0.00574502
Iteration 4469, loss = 0.00574332
Iteration 4470, loss = 0.00574172
Iteration 4471, loss = 0.00573988
Iteration 4472, loss = 0.00573829
Iteration 4473, loss = 0.00573663
Iteration 4474, loss = 0.00573499
Iteration 4475, loss = 0.00573333
Iteration 4476, loss = 0.00573171
Iteration 4477, loss = 0.00572996
Iteration 4478, loss = 0.00572829
Iteration 4479, loss = 0.00572658
Iteration 4480, loss = 0.00572546
Iteration 4481, loss = 0.00572363
Iteration 4482, loss = 0.00572188
Iteration 4483, loss = 0.00572024
Iteration 4484, loss = 0.00571863
Iteration 4485, loss = 0.00571721
Iteration 4486, loss = 0.00571533
Iteration 4487, loss = 0.00571370
Iteration 4488, loss = 0.00571222
Iteration 4489, loss = 0.00571056
Iteration 4490, loss = 0.00570884
Iteration 4491, loss = 0.00570680
Iteration 4492, loss = 0.00570545
Iteration 4493, loss = 0.00570348
Iteration 4494, loss = 0.00570193
Iteration 4495, loss = 0.00570007
Iteration 4496, loss = 0.00569838
Iteration 4497, loss = 0.00569653
Iteration 4498, loss = 0.00569501
Iteration 4499, loss = 0.00569300
Iteration 4500, loss = 0.00569240
Iteration 4501, loss = 0.00568976
Iteration 4502, loss = 0.00568792
Iteration 4503, loss = 0.00568640
Iteration 4504, loss = 0.00568441
Iteration 4505, loss = 0.00568236
Iteration 4506, loss = 0.00568086
Iteration 4507, loss = 0.00567891
Iteration 4508, loss = 0.00567689
Iteration 4509, loss = 0.00567530
Iteration 4510, loss = 0.00567353
Iteration 4511, loss = 0.00567168
Iteration 4512, loss = 0.00566962
Iteration 4513, loss = 0.00566762
Iteration 4514, loss = 0.00566708
Iteration 4515, loss = 0.00566479
Iteration 4516, loss = 0.00566291
Iteration 4517, loss = 0.00566148
Iteration 4518, loss = 0.00565954
Iteration 4519, loss = 0.00565803
Iteration 4520, loss = 0.00565613
Iteration 4521, loss = 0.00565449
Iteration 4522, loss = 0.00565306
Iteration 4523, loss = 0.00565118
Iteration 4524, loss = 0.00564933
Iteration 4525, loss = 0.00564748
Iteration 4526, loss = 0.00564603
Iteration 4527, loss = 0.00564394
Iteration 4528, loss = 0.00564237
Iteration 4529, loss = 0.00564069
Iteration 4530, loss = 0.00563870
Iteration 4531, loss = 0.00563702
Iteration 4532, loss = 0.00563514
Iteration 4533, loss = 0.00563364
Iteration 4534, loss = 0.00563177
Iteration 4535, loss = 0.00563003
Iteration 4536, loss = 0.00562898
Iteration 4537, loss = 0.00562784
Iteration 4538, loss = 0.00562562
Iteration 4539, loss = 0.00562376
Iteration 4540, loss = 0.00562191
Iteration 4541, loss = 0.00562022
Iteration 4542, loss = 0.00561868
Iteration 4543, loss = 0.00561708
Iteration 4544, loss = 0.00561559
Iteration 4545, loss = 0.00561385
Iteration 4546, loss = 0.00561225
Iteration 4547, loss = 0.00561046
Iteration 4548, loss = 0.00560869
Iteration 4549, loss = 0.00560699
Iteration 4550, loss = 0.00560549
Iteration 4551, loss = 0.00560368
Iteration 4552, loss = 0.00560192
Iteration 4553, loss = 0.00560028
Iteration 4554, loss = 0.00559867
Iteration 4555, loss = 0.00559688
Iteration 4556, loss = 0.00559520
Iteration 4557, loss = 0.00559365
Iteration 4558, loss = 0.00559194
Iteration 4559, loss = 0.00559038
Iteration 4560, loss = 0.00558872
Iteration 4561, loss = 0.00558718
Iteration 4562, loss = 0.00558566
Iteration 4563, loss = 0.00558370
Iteration 4564, loss = 0.00558239
Iteration 4565, loss = 0.00558055
Iteration 4566, loss = 0.00557916
Iteration 4567, loss = 0.00557728
Iteration 4568, loss = 0.00557594
Iteration 4569, loss = 0.00557439
Iteration 4570, loss = 0.00557246
Iteration 4571, loss = 0.00557070
Iteration 4572, loss = 0.00556947
Iteration 4573, loss = 0.00556728
Iteration 4574, loss = 0.00556554
Iteration 4575, loss = 0.00556388
Iteration 4576, loss = 0.00556218
Iteration 4577, loss = 0.00555991
Iteration 4578, loss = 0.00555878
Iteration 4579, loss = 0.00555698
Iteration 4580, loss = 0.00555473
Iteration 4581, loss = 0.00555274
Iteration 4582, loss = 0.00555089
Iteration 4583, loss = 0.00554930
Iteration 4584, loss = 0.00554779
Iteration 4585, loss = 0.00554618
Iteration 4586, loss = 0.00554436
Iteration 4587, loss = 0.00554312
Iteration 4588, loss = 0.00554150
Iteration 4589, loss = 0.00554031
Iteration 4590, loss = 0.00553808
Iteration 4591, loss = 0.00553656
Iteration 4592, loss = 0.00553488
Iteration 4593, loss = 0.00553353
Iteration 4594, loss = 0.00553182
Iteration 4595, loss = 0.00553019
Iteration 4596, loss = 0.00552871
Iteration 4597, loss = 0.00552645
Iteration 4598, loss = 0.00552508
Iteration 4599, loss = 0.00552272
Iteration 4600, loss = 0.00552194
Iteration 4601, loss = 0.00552003
Iteration 4602, loss = 0.00551814
Iteration 4603, loss = 0.00551648
Iteration 4604, loss = 0.00551498
Iteration 4605, loss = 0.00551340
Iteration 4606, loss = 0.00551158
Iteration 4607, loss = 0.00551006
Iteration 4608, loss = 0.00550810
Iteration 4609, loss = 0.00550650
Iteration 4610, loss = 0.00550496
Iteration 4611, loss = 0.00550331
Iteration 4612, loss = 0.00550159
Iteration 4613, loss = 0.00550019
Iteration 4614, loss = 0.00549855
Iteration 4615, loss = 0.00549694
Iteration 4616, loss = 0.00549544
Iteration 4617, loss = 0.00549370
Iteration 4618, loss = 0.00549234
Iteration 4619, loss = 0.00549060
Iteration 4620, loss = 0.00548856
Iteration 4621, loss = 0.00548652
Iteration 4622, loss = 0.00548479
Iteration 4623, loss = 0.00548307
Iteration 4624, loss = 0.00548134
Iteration 4625, loss = 0.00547977
Iteration 4626, loss = 0.00547849
Iteration 4627, loss = 0.00547662
Iteration 4628, loss = 0.00547500
Iteration 4629, loss = 0.00547341
Iteration 4630, loss = 0.00547175
Iteration 4631, loss = 0.00547015
Iteration 4632, loss = 0.00546845
Iteration 4633, loss = 0.00546663
Iteration 4634, loss = 0.00546529
Iteration 4635, loss = 0.00546342
Iteration 4636, loss = 0.00546183
Iteration 4637, loss = 0.00546011
Iteration 4638, loss = 0.00545832
Iteration 4639, loss = 0.00545663
Iteration 4640, loss = 0.00545498
Iteration 4641, loss = 0.00545339
Iteration 4642, loss = 0.00545178
Iteration 4643, loss = 0.00545010
Iteration 4644, loss = 0.00544858
Iteration 4645, loss = 0.00544691
Iteration 4646, loss = 0.00544532
Iteration 4647, loss = 0.00544358
Iteration 4648, loss = 0.00544214
Iteration 4649, loss = 0.00544068
Iteration 4650, loss = 0.00543907
Iteration 4651, loss = 0.00543753
Iteration 4652, loss = 0.00543619
Iteration 4653, loss = 0.00543522
Iteration 4654, loss = 0.00543335
Iteration 4655, loss = 0.00543180
Iteration 4656, loss = 0.00543032
Iteration 4657, loss = 0.00542890
Iteration 4658, loss = 0.00542721
Iteration 4659, loss = 0.00542571
Iteration 4660, loss = 0.00542415
Iteration 4661, loss = 0.00542260
Iteration 4662, loss = 0.00542097
Iteration 4663, loss = 0.00541950
Iteration 4664, loss = 0.00541792
Iteration 4665, loss = 0.00541637
Iteration 4666, loss = 0.00541502
Iteration 4667, loss = 0.00541343
Iteration 4668, loss = 0.00541212
Iteration 4669, loss = 0.00541048
Iteration 4670, loss = 0.00540886
Iteration 4671, loss = 0.00540718
Iteration 4672, loss = 0.00540563
Iteration 4673, loss = 0.00540399
Iteration 4674, loss = 0.00540266
Iteration 4675, loss = 0.00540090
Iteration 4676, loss = 0.00539937
Iteration 4677, loss = 0.00539771
Iteration 4678, loss = 0.00539623
Iteration 4679, loss = 0.00539484
Iteration 4680, loss = 0.00539321
Iteration 4681, loss = 0.00539194
Iteration 4682, loss = 0.00539023
Iteration 4683, loss = 0.00538898
Iteration 4684, loss = 0.00538731
Iteration 4685, loss = 0.00538577
Iteration 4686, loss = 0.00538429
Iteration 4687, loss = 0.00538308
Iteration 4688, loss = 0.00538141
Iteration 4689, loss = 0.00538005
Iteration 4690, loss = 0.00537863
Iteration 4691, loss = 0.00537719
Iteration 4692, loss = 0.00537569
Iteration 4693, loss = 0.00537441
Iteration 4694, loss = 0.00537259
Iteration 4695, loss = 0.00537112
Iteration 4696, loss = 0.00536924
Iteration 4697, loss = 0.00536769
Iteration 4698, loss = 0.00536641
Iteration 4699, loss = 0.00536440
Iteration 4700, loss = 0.00536264
Iteration 4701, loss = 0.00536104
Iteration 4702, loss = 0.00535975
Iteration 4703, loss = 0.00535768
Iteration 4704, loss = 0.00535592
Iteration 4705, loss = 0.00535442
Iteration 4706, loss = 0.00535273
Iteration 4707, loss = 0.00535087
Iteration 4708, loss = 0.00534924
Iteration 4709, loss = 0.00534806
Iteration 4710, loss = 0.00534610
Iteration 4711, loss = 0.00534514
Iteration 4712, loss = 0.00534308
Iteration 4713, loss = 0.00534154
Iteration 4714, loss = 0.00534015
Iteration 4715, loss = 0.00533862
Iteration 4716, loss = 0.00533718
Iteration 4717, loss = 0.00533575
Iteration 4718, loss = 0.00533419
Iteration 4719, loss = 0.00533277
Iteration 4720, loss = 0.00533138
Iteration 4721, loss = 0.00533015
Iteration 4722, loss = 0.00532859
Iteration 4723, loss = 0.00532741
Iteration 4724, loss = 0.00532598
Iteration 4725, loss = 0.00532489
Iteration 4726, loss = 0.00532302
Iteration 4727, loss = 0.00532158
Iteration 4728, loss = 0.00532008
Iteration 4729, loss = 0.00531959
Iteration 4730, loss = 0.00531777
Iteration 4731, loss = 0.00531617
Iteration 4732, loss = 0.00531482
Iteration 4733, loss = 0.00531319
Iteration 4734, loss = 0.00531164
Iteration 4735, loss = 0.00531001
Iteration 4736, loss = 0.00530864
Iteration 4737, loss = 0.00530709
Iteration 4738, loss = 0.00530567
Iteration 4739, loss = 0.00530400
Iteration 4740, loss = 0.00530248
Iteration 4741, loss = 0.00530052
Iteration 4742, loss = 0.00529919
Iteration 4743, loss = 0.00529775
Iteration 4744, loss = 0.00529605
Iteration 4745, loss = 0.00529441
Iteration 4746, loss = 0.00529274
Iteration 4747, loss = 0.00529142
Iteration 4748, loss = 0.00529044
Iteration 4749, loss = 0.00528833
Iteration 4750, loss = 0.00528690
Iteration 4751, loss = 0.00528541
Iteration 4752, loss = 0.00528410
Iteration 4753, loss = 0.00528253
Iteration 4754, loss = 0.00528112
Iteration 4755, loss = 0.00527960
Iteration 4756, loss = 0.00527821
Iteration 4757, loss = 0.00527717
Iteration 4758, loss = 0.00527513
Iteration 4759, loss = 0.00527369
Iteration 4760, loss = 0.00527209
Iteration 4761, loss = 0.00527048
Iteration 4762, loss = 0.00526894
Iteration 4763, loss = 0.00526755
Iteration 4764, loss = 0.00526585
Iteration 4765, loss = 0.00526419
Iteration 4766, loss = 0.00526294
Iteration 4767, loss = 0.00526115
Iteration 4768, loss = 0.00525946
Iteration 4769, loss = 0.00525797
Iteration 4770, loss = 0.00525635
Iteration 4771, loss = 0.00525481
Iteration 4772, loss = 0.00525365
Iteration 4773, loss = 0.00525198
Iteration 4774, loss = 0.00525039
Iteration 4775, loss = 0.00524896
Iteration 4776, loss = 0.00524745
Iteration 4777, loss = 0.00524572
Iteration 4778, loss = 0.00524440
Iteration 4779, loss = 0.00524308
Iteration 4780, loss = 0.00524133
Iteration 4781, loss = 0.00523999
Iteration 4782, loss = 0.00523846
Iteration 4783, loss = 0.00523677
Iteration 4784, loss = 0.00523507
Iteration 4785, loss = 0.00523338
Iteration 4786, loss = 0.00523214
Iteration 4787, loss = 0.00523038
Iteration 4788, loss = 0.00522861
Iteration 4789, loss = 0.00522671
Iteration 4790, loss = 0.00522666
Iteration 4791, loss = 0.00522433
Iteration 4792, loss = 0.00522261
Iteration 4793, loss = 0.00522072
Iteration 4794, loss = 0.00521939
Iteration 4795, loss = 0.00521767
Iteration 4796, loss = 0.00521603
Iteration 4797, loss = 0.00521430
Iteration 4798, loss = 0.00521281
Iteration 4799, loss = 0.00521132
Iteration 4800, loss = 0.00520951
Iteration 4801, loss = 0.00520824
Iteration 4802, loss = 0.00520657
Iteration 4803, loss = 0.00520494
Iteration 4804, loss = 0.00520333
Iteration 4805, loss = 0.00520207
Iteration 4806, loss = 0.00520034
Iteration 4807, loss = 0.00519935
Iteration 4808, loss = 0.00519796
Iteration 4809, loss = 0.00519619
Iteration 4810, loss = 0.00519476
Iteration 4811, loss = 0.00519361
Iteration 4812, loss = 0.00519214
Iteration 4813, loss = 0.00519047
Iteration 4814, loss = 0.00518931
Iteration 4815, loss = 0.00518743
Iteration 4816, loss = 0.00518611
Iteration 4817, loss = 0.00518463
Iteration 4818, loss = 0.00518302
Iteration 4819, loss = 0.00518169
Iteration 4820, loss = 0.00518021
Iteration 4821, loss = 0.00517889
Iteration 4822, loss = 0.00517741
Iteration 4823, loss = 0.00517619
Iteration 4824, loss = 0.00517469
Iteration 4825, loss = 0.00517351
Iteration 4826, loss = 0.00517199
Iteration 4827, loss = 0.00517049
Iteration 4828, loss = 0.00516912
Iteration 4829, loss = 0.00516775
Iteration 4830, loss = 0.00516658
Iteration 4831, loss = 0.00516508
Iteration 4832, loss = 0.00516355
Iteration 4833, loss = 0.00516197
Iteration 4834, loss = 0.00516064
Iteration 4835, loss = 0.00515926
Iteration 4836, loss = 0.00515826
Iteration 4837, loss = 0.00515649
Iteration 4838, loss = 0.00515506
Iteration 4839, loss = 0.00515354
Iteration 4840, loss = 0.00515206
Iteration 4841, loss = 0.00515090
Iteration 4842, loss = 0.00514952
Iteration 4843, loss = 0.00514825
Iteration 4844, loss = 0.00514667
Iteration 4845, loss = 0.00514541
Iteration 4846, loss = 0.00514379
Iteration 4847, loss = 0.00514232
Iteration 4848, loss = 0.00514080
Iteration 4849, loss = 0.00513951
Iteration 4850, loss = 0.00513798
Iteration 4851, loss = 0.00513661
Iteration 4852, loss = 0.00513529
Iteration 4853, loss = 0.00513384
Iteration 4854, loss = 0.00513252
Iteration 4855, loss = 0.00513133
Iteration 4856, loss = 0.00512983
Iteration 4857, loss = 0.00512838
Iteration 4858, loss = 0.00512699
Iteration 4859, loss = 0.00512576
Iteration 4860, loss = 0.00512452
Iteration 4861, loss = 0.00512257
Iteration 4862, loss = 0.00512134
Iteration 4863, loss = 0.00511974
Iteration 4864, loss = 0.00511840
Iteration 4865, loss = 0.00511681
Iteration 4866, loss = 0.00511524
Iteration 4867, loss = 0.00511382
Iteration 4868, loss = 0.00511238
Iteration 4869, loss = 0.00511115
Iteration 4870, loss = 0.00510944
Iteration 4871, loss = 0.00510801
Iteration 4872, loss = 0.00510676
Iteration 4873, loss = 0.00510512
Iteration 4874, loss = 0.00510386
Iteration 4875, loss = 0.00510233
Iteration 4876, loss = 0.00510079
Iteration 4877, loss = 0.00509987
Iteration 4878, loss = 0.00509807
Iteration 4879, loss = 0.00509659
Iteration 4880, loss = 0.00509533
Iteration 4881, loss = 0.00509372
Iteration 4882, loss = 0.00509267
Iteration 4883, loss = 0.00509114
Iteration 4884, loss = 0.00508969
Iteration 4885, loss = 0.00508835
Iteration 4886, loss = 0.00508686
Iteration 4887, loss = 0.00508552
Iteration 4888, loss = 0.00508422
Iteration 4889, loss = 0.00508294
Iteration 4890, loss = 0.00508167
Iteration 4891, loss = 0.00508017
Iteration 4892, loss = 0.00507877
Iteration 4893, loss = 0.00507780
Iteration 4894, loss = 0.00507655
Iteration 4895, loss = 0.00507499
Iteration 4896, loss = 0.00507361
Iteration 4897, loss = 0.00507219
Iteration 4898, loss = 0.00507071
Iteration 4899, loss = 0.00506936
Iteration 4900, loss = 0.00506793
Iteration 4901, loss = 0.00506643
Iteration 4902, loss = 0.00506504
Iteration 4903, loss = 0.00506336
Iteration 4904, loss = 0.00506196
Iteration 4905, loss = 0.00506054
Iteration 4906, loss = 0.00505905
Iteration 4907, loss = 0.00505757
Iteration 4908, loss = 0.00505610
Iteration 4909, loss = 0.00505472
Iteration 4910, loss = 0.00505321
Iteration 4911, loss = 0.00505173
Iteration 4912, loss = 0.00505053
Iteration 4913, loss = 0.00504889
Iteration 4914, loss = 0.00504776
Iteration 4915, loss = 0.00504643
Iteration 4916, loss = 0.00504500
Iteration 4917, loss = 0.00504367
Iteration 4918, loss = 0.00504243
Iteration 4919, loss = 0.00504087
Iteration 4920, loss = 0.00503989
Iteration 4921, loss = 0.00503813
Iteration 4922, loss = 0.00503686
Iteration 4923, loss = 0.00503548
Iteration 4924, loss = 0.00503408
Iteration 4925, loss = 0.00503283
Iteration 4926, loss = 0.00503196
Iteration 4927, loss = 0.00503030
Iteration 4928, loss = 0.00502876
Iteration 4929, loss = 0.00502739
Iteration 4930, loss = 0.00502593
Iteration 4931, loss = 0.00502427
Iteration 4932, loss = 0.00502299
Iteration 4933, loss = 0.00502146
Iteration 4934, loss = 0.00502012
Iteration 4935, loss = 0.00501893
Iteration 4936, loss = 0.00501743
Iteration 4937, loss = 0.00501616
Iteration 4938, loss = 0.00501486
Iteration 4939, loss = 0.00501357
Iteration 4940, loss = 0.00501268
Iteration 4941, loss = 0.00501084
Iteration 4942, loss = 0.00500952
Iteration 4943, loss = 0.00500816
Iteration 4944, loss = 0.00500684
Iteration 4945, loss = 0.00500536
Iteration 4946, loss = 0.00500410
Iteration 4947, loss = 0.00500243
Iteration 4948, loss = 0.00500133
Iteration 4949, loss = 0.00499972
Iteration 4950, loss = 0.00499859
Iteration 4951, loss = 0.00499708
Iteration 4952, loss = 0.00499589
Iteration 4953, loss = 0.00499450
Iteration 4954, loss = 0.00499316
Iteration 4955, loss = 0.00499198
Iteration 4956, loss = 0.00499072
Iteration 4957, loss = 0.00498963
Iteration 4958, loss = 0.00498838
Iteration 4959, loss = 0.00498708
Iteration 4960, loss = 0.00498578
Iteration 4961, loss = 0.00498459
Iteration 4962, loss = 0.00498332
Iteration 4963, loss = 0.00498223
Iteration 4964, loss = 0.00498102
Iteration 4965, loss = 0.00497965
Iteration 4966, loss = 0.00497832
Iteration 4967, loss = 0.00497717
Iteration 4968, loss = 0.00497593
Iteration 4969, loss = 0.00497496
Iteration 4970, loss = 0.00497327
Iteration 4971, loss = 0.00497193
Iteration 4972, loss = 0.00497049
Iteration 4973, loss = 0.00496911
Iteration 4974, loss = 0.00496753
Iteration 4975, loss = 0.00496630
Iteration 4976, loss = 0.00496482
Iteration 4977, loss = 0.00496350
Iteration 4978, loss = 0.00496210
Iteration 4979, loss = 0.00496065
Iteration 4980, loss = 0.00495970
Iteration 4981, loss = 0.00495806
Iteration 4982, loss = 0.00495651
Iteration 4983, loss = 0.00495491
Iteration 4984, loss = 0.00495435
Iteration 4985, loss = 0.00495236
Iteration 4986, loss = 0.00495105
Iteration 4987, loss = 0.00494956
Iteration 4988, loss = 0.00494802
Iteration 4989, loss = 0.00494659
Iteration 4990, loss = 0.00494519
Iteration 4991, loss = 0.00494380
Iteration 4992, loss = 0.00494247
Iteration 4993, loss = 0.00494082
Iteration 4994, loss = 0.00493977
Iteration 4995, loss = 0.00493807
Iteration 4996, loss = 0.00493644
Iteration 4997, loss = 0.00493521
Iteration 4998, loss = 0.00493388
Iteration 4999, loss = 0.00493204
Iteration 5000, loss = 0.00493120
Iteration 5001, loss = 0.00492922
Iteration 5002, loss = 0.00492790
Iteration 5003, loss = 0.00492645
Iteration 5004, loss = 0.00492517
Iteration 5005, loss = 0.00492381
Iteration 5006, loss = 0.00492242
Iteration 5007, loss = 0.00492111
Iteration 5008, loss = 0.00491985
Iteration 5009, loss = 0.00491881
Iteration 5010, loss = 0.00491756
Iteration 5011, loss = 0.00491584
Iteration 5012, loss = 0.00491446
Iteration 5013, loss = 0.00491327
Iteration 5014, loss = 0.00491181
Iteration 5015, loss = 0.00491021
Iteration 5016, loss = 0.00490884
Iteration 5017, loss = 0.00490751
Iteration 5018, loss = 0.00490611
Iteration 5019, loss = 0.00490528
Iteration 5020, loss = 0.00490362
Iteration 5021, loss = 0.00490207
Iteration 5022, loss = 0.00490072
Iteration 5023, loss = 0.00489962
Iteration 5024, loss = 0.00489802
Iteration 5025, loss = 0.00489691
Iteration 5026, loss = 0.00489547
Iteration 5027, loss = 0.00489469
Iteration 5028, loss = 0.00489280
Iteration 5029, loss = 0.00489179
Iteration 5030, loss = 0.00489015
Iteration 5031, loss = 0.00488873
Iteration 5032, loss = 0.00488738
Iteration 5033, loss = 0.00488615
Iteration 5034, loss = 0.00488470
Iteration 5035, loss = 0.00488338
Iteration 5036, loss = 0.00488196
Iteration 5037, loss = 0.00488076
Iteration 5038, loss = 0.00487948
Iteration 5039, loss = 0.00487856
Iteration 5040, loss = 0.00487683
Iteration 5041, loss = 0.00487566
Iteration 5042, loss = 0.00487427
Iteration 5043, loss = 0.00487291
Iteration 5044, loss = 0.00487166
Iteration 5045, loss = 0.00487055
Iteration 5046, loss = 0.00486917
Iteration 5047, loss = 0.00486777
Iteration 5048, loss = 0.00486652
Iteration 5049, loss = 0.00486512
Iteration 5050, loss = 0.00486382
Iteration 5051, loss = 0.00486260
Iteration 5052, loss = 0.00486109
Iteration 5053, loss = 0.00486013
Iteration 5054, loss = 0.00485861
Iteration 5055, loss = 0.00485734
Iteration 5056, loss = 0.00485650
Iteration 5057, loss = 0.00485509
Iteration 5058, loss = 0.00485371
Iteration 5059, loss = 0.00485220
Iteration 5060, loss = 0.00485090
Iteration 5061, loss = 0.00484960
Iteration 5062, loss = 0.00484848
Iteration 5063, loss = 0.00484715
Iteration 5064, loss = 0.00484609
Iteration 5065, loss = 0.00484474
Iteration 5066, loss = 0.00484319
Iteration 5067, loss = 0.00484193
Iteration 5068, loss = 0.00484064
Iteration 5069, loss = 0.00483922
Iteration 5070, loss = 0.00483786
Iteration 5071, loss = 0.00483672
Iteration 5072, loss = 0.00483568
Iteration 5073, loss = 0.00483443
Iteration 5074, loss = 0.00483281
Iteration 5075, loss = 0.00483167
Iteration 5076, loss = 0.00483033
Iteration 5077, loss = 0.00482921
Iteration 5078, loss = 0.00482784
Iteration 5079, loss = 0.00482655
Iteration 5080, loss = 0.00482526
Iteration 5081, loss = 0.00482416
Iteration 5082, loss = 0.00482307
Iteration 5083, loss = 0.00482152
Iteration 5084, loss = 0.00482031
Iteration 5085, loss = 0.00481916
Iteration 5086, loss = 0.00481743
Iteration 5087, loss = 0.00481664
Iteration 5088, loss = 0.00481535
Iteration 5089, loss = 0.00481404
Iteration 5090, loss = 0.00481274
Iteration 5091, loss = 0.00481163
Iteration 5092, loss = 0.00481033
Iteration 5093, loss = 0.00480921
Iteration 5094, loss = 0.00480792
Iteration 5095, loss = 0.00480690
Iteration 5096, loss = 0.00480561
Iteration 5097, loss = 0.00480425
Iteration 5098, loss = 0.00480317
Iteration 5099, loss = 0.00480163
Iteration 5100, loss = 0.00480048
Iteration 5101, loss = 0.00479923
Iteration 5102, loss = 0.00479771
Iteration 5103, loss = 0.00479638
Iteration 5104, loss = 0.00479502
Iteration 5105, loss = 0.00479362
Iteration 5106, loss = 0.00479224
Iteration 5107, loss = 0.00479147
Iteration 5108, loss = 0.00478979
Iteration 5109, loss = 0.00478956
Iteration 5110, loss = 0.00478756
Iteration 5111, loss = 0.00478590
Iteration 5112, loss = 0.00478460
Iteration 5113, loss = 0.00478320
Iteration 5114, loss = 0.00478180
Iteration 5115, loss = 0.00478037
Iteration 5116, loss = 0.00477900
Iteration 5117, loss = 0.00477800
Iteration 5118, loss = 0.00477730
Iteration 5119, loss = 0.00477557
Iteration 5120, loss = 0.00477419
Iteration 5121, loss = 0.00477290
Iteration 5122, loss = 0.00477179
Iteration 5123, loss = 0.00477055
Iteration 5124, loss = 0.00476900
Iteration 5125, loss = 0.00476793
Iteration 5126, loss = 0.00476650
Iteration 5127, loss = 0.00476543
Iteration 5128, loss = 0.00476427
Iteration 5129, loss = 0.00476296
Iteration 5130, loss = 0.00476178
Iteration 5131, loss = 0.00476048
Iteration 5132, loss = 0.00475944
Iteration 5133, loss = 0.00475883
Iteration 5134, loss = 0.00475711
Iteration 5135, loss = 0.00475581
Iteration 5136, loss = 0.00475439
Iteration 5137, loss = 0.00475321
Iteration 5138, loss = 0.00475190
Iteration 5139, loss = 0.00475061
Iteration 5140, loss = 0.00474923
Iteration 5141, loss = 0.00474824
Iteration 5142, loss = 0.00474685
Iteration 5143, loss = 0.00474580
Iteration 5144, loss = 0.00474404
Iteration 5145, loss = 0.00474279
Iteration 5146, loss = 0.00474152
Iteration 5147, loss = 0.00474062
Iteration 5148, loss = 0.00473904
Iteration 5149, loss = 0.00473771
Iteration 5150, loss = 0.00473641
Iteration 5151, loss = 0.00473521
Iteration 5152, loss = 0.00473392
Iteration 5153, loss = 0.00473261
Iteration 5154, loss = 0.00473116
Iteration 5155, loss = 0.00473010
Iteration 5156, loss = 0.00472844
Iteration 5157, loss = 0.00472742
Iteration 5158, loss = 0.00472621
Iteration 5159, loss = 0.00472546
Iteration 5160, loss = 0.00472363
Iteration 5161, loss = 0.00472241
Iteration 5162, loss = 0.00472103
Iteration 5163, loss = 0.00471966
Iteration 5164, loss = 0.00471840
Iteration 5165, loss = 0.00471719
Iteration 5166, loss = 0.00471603
Iteration 5167, loss = 0.00471473
Iteration 5168, loss = 0.00471358
Iteration 5169, loss = 0.00471243
Iteration 5170, loss = 0.00471130
Iteration 5171, loss = 0.00470978
Iteration 5172, loss = 0.00470902
Iteration 5173, loss = 0.00470786
Iteration 5174, loss = 0.00470671
Iteration 5175, loss = 0.00470545
Iteration 5176, loss = 0.00470444
Iteration 5177, loss = 0.00470318
Iteration 5178, loss = 0.00470197
Iteration 5179, loss = 0.00470094
Iteration 5180, loss = 0.00469990
Iteration 5181, loss = 0.00469844
Iteration 5182, loss = 0.00469723
Iteration 5183, loss = 0.00469613
Iteration 5184, loss = 0.00469498
Iteration 5185, loss = 0.00469355
Iteration 5186, loss = 0.00469237
Iteration 5187, loss = 0.00469105
Iteration 5188, loss = 0.00468987
Iteration 5189, loss = 0.00468874
Iteration 5190, loss = 0.00468761
Iteration 5191, loss = 0.00468621
Iteration 5192, loss = 0.00468506
Iteration 5193, loss = 0.00468399
Iteration 5194, loss = 0.00468252
Iteration 5195, loss = 0.00468164
Iteration 5196, loss = 0.00468039
Iteration 5197, loss = 0.00467931
Iteration 5198, loss = 0.00467770
Iteration 5199, loss = 0.00467654
Iteration 5200, loss = 0.00467542
Iteration 5201, loss = 0.00467376
Iteration 5202, loss = 0.00467290
Iteration 5203, loss = 0.00467120
Iteration 5204, loss = 0.00467007
Iteration 5205, loss = 0.00466914
Iteration 5206, loss = 0.00466729
Iteration 5207, loss = 0.00466616
Iteration 5208, loss = 0.00466460
Iteration 5209, loss = 0.00466341
Iteration 5210, loss = 0.00466201
Iteration 5211, loss = 0.00466066
Iteration 5212, loss = 0.00465950
Iteration 5213, loss = 0.00465827
Iteration 5214, loss = 0.00465701
Iteration 5215, loss = 0.00465589
Iteration 5216, loss = 0.00465471
Iteration 5217, loss = 0.00465364
Iteration 5218, loss = 0.00465271
Iteration 5219, loss = 0.00465169
Iteration 5220, loss = 0.00465037
Iteration 5221, loss = 0.00464929
Iteration 5222, loss = 0.00464884
Iteration 5223, loss = 0.00464686
Iteration 5224, loss = 0.00464586
Iteration 5225, loss = 0.00464469
Iteration 5226, loss = 0.00464348
Iteration 5227, loss = 0.00464260
Iteration 5228, loss = 0.00464162
Iteration 5229, loss = 0.00464027
Iteration 5230, loss = 0.00463906
Iteration 5231, loss = 0.00463810
Iteration 5232, loss = 0.00463701
Iteration 5233, loss = 0.00463578
Iteration 5234, loss = 0.00463478
Iteration 5235, loss = 0.00463360
Iteration 5236, loss = 0.00463171
Iteration 5237, loss = 0.00463054
Iteration 5238, loss = 0.00462952
Iteration 5239, loss = 0.00462833
Iteration 5240, loss = 0.00462703
Iteration 5241, loss = 0.00462640
Iteration 5242, loss = 0.00462534
Iteration 5243, loss = 0.00462390
Iteration 5244, loss = 0.00462276
Iteration 5245, loss = 0.00462192
Iteration 5246, loss = 0.00462065
Iteration 5247, loss = 0.00461973
Iteration 5248, loss = 0.00461932
Iteration 5249, loss = 0.00461756
Iteration 5250, loss = 0.00461642
Iteration 5251, loss = 0.00461552
Iteration 5252, loss = 0.00461412
Iteration 5253, loss = 0.00461325
Iteration 5254, loss = 0.00461213
Iteration 5255, loss = 0.00461098
Iteration 5256, loss = 0.00460996
Iteration 5257, loss = 0.00460875
Iteration 5258, loss = 0.00460759
Iteration 5259, loss = 0.00460634
Iteration 5260, loss = 0.00460514
Iteration 5261, loss = 0.00460359
Iteration 5262, loss = 0.00460237
Iteration 5263, loss = 0.00460132
Iteration 5264, loss = 0.00460005
Iteration 5265, loss = 0.00459888
Iteration 5266, loss = 0.00459763
Iteration 5267, loss = 0.00459651
Iteration 5268, loss = 0.00459526
Iteration 5269, loss = 0.00459404
Iteration 5270, loss = 0.00459327
Iteration 5271, loss = 0.00459203
Iteration 5272, loss = 0.00459061
Iteration 5273, loss = 0.00458932
Iteration 5274, loss = 0.00458816
Iteration 5275, loss = 0.00458714
Iteration 5276, loss = 0.00458628
Iteration 5277, loss = 0.00458510
Iteration 5278, loss = 0.00458396
Iteration 5279, loss = 0.00458270
Iteration 5280, loss = 0.00458160
Iteration 5281, loss = 0.00458037
Iteration 5282, loss = 0.00457913
Iteration 5283, loss = 0.00457807
Iteration 5284, loss = 0.00457688
Iteration 5285, loss = 0.00457578
Iteration 5286, loss = 0.00457474
Iteration 5287, loss = 0.00457402
Iteration 5288, loss = 0.00457286
Iteration 5289, loss = 0.00457147
Iteration 5290, loss = 0.00457023
Iteration 5291, loss = 0.00456923
Iteration 5292, loss = 0.00456797
Iteration 5293, loss = 0.00456685
Iteration 5294, loss = 0.00456577
Iteration 5295, loss = 0.00456467
Iteration 5296, loss = 0.00456355
Iteration 5297, loss = 0.00456216
Iteration 5298, loss = 0.00456138
Iteration 5299, loss = 0.00456002
Iteration 5300, loss = 0.00455935
Iteration 5301, loss = 0.00455849
Iteration 5302, loss = 0.00455695
Iteration 5303, loss = 0.00455578
Iteration 5304, loss = 0.00455462
Iteration 5305, loss = 0.00455396
Iteration 5306, loss = 0.00455268
Iteration 5307, loss = 0.00455135
Iteration 5308, loss = 0.00454990
Iteration 5309, loss = 0.00454893
Iteration 5310, loss = 0.00454775
Iteration 5311, loss = 0.00454634
Iteration 5312, loss = 0.00454501
Iteration 5313, loss = 0.00454374
Iteration 5314, loss = 0.00454278
Iteration 5315, loss = 0.00454145
Iteration 5316, loss = 0.00454029
Iteration 5317, loss = 0.00453941
Iteration 5318, loss = 0.00453919
Iteration 5319, loss = 0.00453710
Iteration 5320, loss = 0.00453596
Iteration 5321, loss = 0.00453491
Iteration 5322, loss = 0.00453393
Iteration 5323, loss = 0.00453275
Iteration 5324, loss = 0.00453197
Iteration 5325, loss = 0.00453079
Iteration 5326, loss = 0.00453031
Iteration 5327, loss = 0.00452848
Iteration 5328, loss = 0.00452784
Iteration 5329, loss = 0.00452620
Iteration 5330, loss = 0.00452524
Iteration 5331, loss = 0.00452419
Iteration 5332, loss = 0.00452305
Iteration 5333, loss = 0.00452194
Iteration 5334, loss = 0.00452076
Iteration 5335, loss = 0.00451974
Iteration 5336, loss = 0.00451881
Iteration 5337, loss = 0.00451732
Iteration 5338, loss = 0.00451601
Iteration 5339, loss = 0.00451514
Iteration 5340, loss = 0.00451366
Iteration 5341, loss = 0.00451254
Iteration 5342, loss = 0.00451147
Iteration 5343, loss = 0.00451039
Iteration 5344, loss = 0.00450921
Iteration 5345, loss = 0.00450822
Iteration 5346, loss = 0.00450686
Iteration 5347, loss = 0.00450594
Iteration 5348, loss = 0.00450464
Iteration 5349, loss = 0.00450368
Iteration 5350, loss = 0.00450286
Iteration 5351, loss = 0.00450137
Iteration 5352, loss = 0.00450040
Iteration 5353, loss = 0.00449904
Iteration 5354, loss = 0.00449792
Iteration 5355, loss = 0.00449710
Iteration 5356, loss = 0.00449550
Iteration 5357, loss = 0.00449461
Iteration 5358, loss = 0.00449303
Iteration 5359, loss = 0.00449187
Iteration 5360, loss = 0.00449071
Iteration 5361, loss = 0.00448992
Iteration 5362, loss = 0.00448853
Iteration 5363, loss = 0.00448759
Iteration 5364, loss = 0.00448633
Iteration 5365, loss = 0.00448509
Iteration 5366, loss = 0.00448389
Iteration 5367, loss = 0.00448281
Iteration 5368, loss = 0.00448172
Iteration 5369, loss = 0.00448073
Iteration 5370, loss = 0.00447946
Iteration 5371, loss = 0.00447859
Iteration 5372, loss = 0.00447717
Iteration 5373, loss = 0.00447594
Iteration 5374, loss = 0.00447545
Iteration 5375, loss = 0.00447395
Iteration 5376, loss = 0.00447293
Iteration 5377, loss = 0.00447148
Iteration 5378, loss = 0.00447040
Iteration 5379, loss = 0.00446916
Iteration 5380, loss = 0.00446827
Iteration 5381, loss = 0.00446696
Iteration 5382, loss = 0.00446544
Iteration 5383, loss = 0.00446436
Iteration 5384, loss = 0.00446321
Iteration 5385, loss = 0.00446209
Iteration 5386, loss = 0.00446081
Iteration 5387, loss = 0.00445982
Iteration 5388, loss = 0.00445851
Iteration 5389, loss = 0.00445715
Iteration 5390, loss = 0.00445588
Iteration 5391, loss = 0.00445479
Iteration 5392, loss = 0.00445358
Iteration 5393, loss = 0.00445242
Iteration 5394, loss = 0.00445129
Iteration 5395, loss = 0.00445008
Iteration 5396, loss = 0.00444933
Iteration 5397, loss = 0.00444806
Iteration 5398, loss = 0.00444708
Iteration 5399, loss = 0.00444605
Iteration 5400, loss = 0.00444499
Iteration 5401, loss = 0.00444400
Iteration 5402, loss = 0.00444292
Iteration 5403, loss = 0.00444171
Iteration 5404, loss = 0.00444108
Iteration 5405, loss = 0.00443968
Iteration 5406, loss = 0.00443849
Iteration 5407, loss = 0.00443750
Iteration 5408, loss = 0.00443640
Iteration 5409, loss = 0.00443538
Iteration 5410, loss = 0.00443457
Iteration 5411, loss = 0.00443325
Iteration 5412, loss = 0.00443225
Iteration 5413, loss = 0.00443145
Iteration 5414, loss = 0.00442994
Iteration 5415, loss = 0.00442883
Iteration 5416, loss = 0.00442759
Iteration 5417, loss = 0.00442805
Iteration 5418, loss = 0.00442575
Iteration 5419, loss = 0.00442484
Iteration 5420, loss = 0.00442359
Iteration 5421, loss = 0.00442252
Iteration 5422, loss = 0.00442145
Iteration 5423, loss = 0.00442048
Iteration 5424, loss = 0.00441967
Iteration 5425, loss = 0.00441801
Iteration 5426, loss = 0.00441682
Iteration 5427, loss = 0.00441595
Iteration 5428, loss = 0.00441488
Iteration 5429, loss = 0.00441371
Iteration 5430, loss = 0.00441276
Iteration 5431, loss = 0.00441156
Iteration 5432, loss = 0.00441073
Iteration 5433, loss = 0.00440988
Iteration 5434, loss = 0.00440864
Iteration 5435, loss = 0.00440784
Iteration 5436, loss = 0.00440723
Iteration 5437, loss = 0.00440593
Iteration 5438, loss = 0.00440506
Iteration 5439, loss = 0.00440405
Iteration 5440, loss = 0.00440292
Iteration 5441, loss = 0.00440241
Iteration 5442, loss = 0.00440095
Iteration 5443, loss = 0.00440012
Iteration 5444, loss = 0.00439915
Iteration 5445, loss = 0.00439799
Iteration 5446, loss = 0.00439669
Iteration 5447, loss = 0.00439565
Iteration 5448, loss = 0.00439455
Iteration 5449, loss = 0.00439347
Iteration 5450, loss = 0.00439240
Iteration 5451, loss = 0.00439136
Iteration 5452, loss = 0.00439026
Iteration 5453, loss = 0.00438892
Iteration 5454, loss = 0.00438887
Iteration 5455, loss = 0.00438708
Iteration 5456, loss = 0.00438594
Iteration 5457, loss = 0.00438489
Iteration 5458, loss = 0.00438388
Iteration 5459, loss = 0.00438284
Iteration 5460, loss = 0.00438179
Iteration 5461, loss = 0.00438075
Iteration 5462, loss = 0.00437986
Iteration 5463, loss = 0.00437932
Iteration 5464, loss = 0.00437804
Iteration 5465, loss = 0.00437693
Iteration 5466, loss = 0.00437597
Iteration 5467, loss = 0.00437498
Iteration 5468, loss = 0.00437408
Iteration 5469, loss = 0.00437310
Iteration 5470, loss = 0.00437213
Iteration 5471, loss = 0.00437119
Iteration 5472, loss = 0.00437021
Iteration 5473, loss = 0.00436913
Iteration 5474, loss = 0.00436807
Iteration 5475, loss = 0.00436750
Iteration 5476, loss = 0.00436637
Iteration 5477, loss = 0.00436582
Iteration 5478, loss = 0.00436453
Iteration 5479, loss = 0.00436374
Iteration 5480, loss = 0.00436249
Iteration 5481, loss = 0.00436157
Iteration 5482, loss = 0.00436087
Iteration 5483, loss = 0.00435961
Iteration 5484, loss = 0.00435865
Iteration 5485, loss = 0.00435757
Iteration 5486, loss = 0.00435668
Iteration 5487, loss = 0.00435560
Iteration 5488, loss = 0.00435577
Iteration 5489, loss = 0.00435421
Iteration 5490, loss = 0.00435265
Iteration 5491, loss = 0.00435162
Iteration 5492, loss = 0.00435059
Iteration 5493, loss = 0.00434951
Iteration 5494, loss = 0.00434843
Iteration 5495, loss = 0.00434737
Iteration 5496, loss = 0.00434626
Iteration 5497, loss = 0.00434531
Iteration 5498, loss = 0.00434443
Iteration 5499, loss = 0.00434312
Iteration 5500, loss = 0.00434197
Iteration 5501, loss = 0.00434094
Iteration 5502, loss = 0.00433968
Iteration 5503, loss = 0.00433853
Iteration 5504, loss = 0.00433752
Iteration 5505, loss = 0.00433627
Iteration 5506, loss = 0.00433537
Iteration 5507, loss = 0.00433424
Iteration 5508, loss = 0.00433308
Iteration 5509, loss = 0.00433186
Iteration 5510, loss = 0.00433081
Iteration 5511, loss = 0.00432985
Iteration 5512, loss = 0.00432857
Iteration 5513, loss = 0.00432773
Iteration 5514, loss = 0.00432649
Iteration 5515, loss = 0.00432560
Iteration 5516, loss = 0.00432453
Iteration 5517, loss = 0.00432347
Iteration 5518, loss = 0.00432260
Iteration 5519, loss = 0.00432152
Iteration 5520, loss = 0.00432073
Iteration 5521, loss = 0.00431939
Iteration 5522, loss = 0.00431824
Iteration 5523, loss = 0.00431712
Iteration 5524, loss = 0.00431620
Iteration 5525, loss = 0.00431521
Iteration 5526, loss = 0.00431403
Iteration 5527, loss = 0.00431307
Iteration 5528, loss = 0.00431218
Iteration 5529, loss = 0.00431118
Iteration 5530, loss = 0.00431026
Iteration 5531, loss = 0.00430909
Iteration 5532, loss = 0.00430797
Iteration 5533, loss = 0.00430676
Iteration 5534, loss = 0.00430578
Iteration 5535, loss = 0.00430471
Iteration 5536, loss = 0.00430370
Iteration 5537, loss = 0.00430267
Iteration 5538, loss = 0.00430150
Iteration 5539, loss = 0.00430103
Iteration 5540, loss = 0.00429962
Iteration 5541, loss = 0.00429863
Iteration 5542, loss = 0.00429763
Iteration 5543, loss = 0.00429679
Iteration 5544, loss = 0.00429590
Iteration 5545, loss = 0.00429468
Iteration 5546, loss = 0.00429399
Iteration 5547, loss = 0.00429280
Iteration 5548, loss = 0.00429174
Iteration 5549, loss = 0.00429075
Iteration 5550, loss = 0.00428965
Iteration 5551, loss = 0.00428876
Iteration 5552, loss = 0.00428756
Iteration 5553, loss = 0.00428697
Iteration 5554, loss = 0.00428542
Iteration 5555, loss = 0.00428440
Iteration 5556, loss = 0.00428322
Iteration 5557, loss = 0.00428220
Iteration 5558, loss = 0.00428123
Iteration 5559, loss = 0.00428007
Iteration 5560, loss = 0.00427930
Iteration 5561, loss = 0.00427808
Iteration 5562, loss = 0.00427712
Iteration 5563, loss = 0.00427612
Iteration 5564, loss = 0.00427504
Iteration 5565, loss = 0.00427414
Iteration 5566, loss = 0.00427327
Iteration 5567, loss = 0.00427214
Iteration 5568, loss = 0.00427111
Iteration 5569, loss = 0.00427015
Iteration 5570, loss = 0.00426925
Iteration 5571, loss = 0.00426800
Iteration 5572, loss = 0.00426682
Iteration 5573, loss = 0.00426593
Iteration 5574, loss = 0.00426456
Iteration 5575, loss = 0.00426371
Iteration 5576, loss = 0.00426285
Iteration 5577, loss = 0.00426159
Iteration 5578, loss = 0.00426082
Iteration 5579, loss = 0.00426034
Iteration 5580, loss = 0.00425898
Iteration 5581, loss = 0.00425811
Iteration 5582, loss = 0.00425723
Iteration 5583, loss = 0.00425624
Iteration 5584, loss = 0.00425535
Iteration 5585, loss = 0.00425434
Iteration 5586, loss = 0.00425340
Iteration 5587, loss = 0.00425257
Iteration 5588, loss = 0.00425188
Iteration 5589, loss = 0.00425062
Iteration 5590, loss = 0.00424965
Iteration 5591, loss = 0.00424883
Iteration 5592, loss = 0.00424798
Iteration 5593, loss = 0.00424673
Iteration 5594, loss = 0.00424566
Iteration 5595, loss = 0.00424452
Iteration 5596, loss = 0.00424354
Iteration 5597, loss = 0.00424257
Iteration 5598, loss = 0.00424140
Iteration 5599, loss = 0.00424051
Iteration 5600, loss = 0.00423959
Iteration 5601, loss = 0.00423851
Iteration 5602, loss = 0.00423760
Iteration 5603, loss = 0.00423622
Iteration 5604, loss = 0.00423578
Iteration 5605, loss = 0.00423411
Iteration 5606, loss = 0.00423297
Iteration 5607, loss = 0.00423206
Iteration 5608, loss = 0.00423108
Iteration 5609, loss = 0.00423013
Iteration 5610, loss = 0.00422893
Iteration 5611, loss = 0.00422786
Iteration 5612, loss = 0.00422713
Iteration 5613, loss = 0.00422578
Iteration 5614, loss = 0.00422483
Iteration 5615, loss = 0.00422394
Iteration 5616, loss = 0.00422283
Iteration 5617, loss = 0.00422195
Iteration 5618, loss = 0.00422076
Iteration 5619, loss = 0.00421963
Iteration 5620, loss = 0.00421866
Iteration 5621, loss = 0.00421744
Iteration 5622, loss = 0.00421640
Iteration 5623, loss = 0.00421543
Iteration 5624, loss = 0.00421434
Iteration 5625, loss = 0.00421319
Iteration 5626, loss = 0.00421223
Iteration 5627, loss = 0.00421122
Iteration 5628, loss = 0.00421004
Iteration 5629, loss = 0.00420916
Iteration 5630, loss = 0.00420808
Iteration 5631, loss = 0.00420746
Iteration 5632, loss = 0.00420598
Iteration 5633, loss = 0.00420470
Iteration 5634, loss = 0.00420402
Iteration 5635, loss = 0.00420300
Iteration 5636, loss = 0.00420200
Iteration 5637, loss = 0.00420085
Iteration 5638, loss = 0.00420058
Iteration 5639, loss = 0.00419919
Iteration 5640, loss = 0.00419822
Iteration 5641, loss = 0.00419708
Iteration 5642, loss = 0.00419604
Iteration 5643, loss = 0.00419505
Iteration 5644, loss = 0.00419405
Iteration 5645, loss = 0.00419293
Iteration 5646, loss = 0.00419232
Iteration 5647, loss = 0.00419097
Iteration 5648, loss = 0.00418984
Iteration 5649, loss = 0.00418894
Iteration 5650, loss = 0.00418812
Iteration 5651, loss = 0.00418695
Iteration 5652, loss = 0.00418588
Iteration 5653, loss = 0.00418495
Iteration 5654, loss = 0.00418389
Iteration 5655, loss = 0.00418290
Iteration 5656, loss = 0.00418198
Iteration 5657, loss = 0.00418095
Iteration 5658, loss = 0.00418007
Iteration 5659, loss = 0.00417925
Iteration 5660, loss = 0.00417810
Iteration 5661, loss = 0.00417712
Iteration 5662, loss = 0.00417638
Iteration 5663, loss = 0.00417531
Iteration 5664, loss = 0.00417447
Iteration 5665, loss = 0.00417344
Iteration 5666, loss = 0.00417231
Iteration 5667, loss = 0.00417120
Iteration 5668, loss = 0.00417076
Iteration 5669, loss = 0.00416949
Iteration 5670, loss = 0.00416839
Iteration 5671, loss = 0.00416762
Iteration 5672, loss = 0.00416694
Iteration 5673, loss = 0.00416559
Iteration 5674, loss = 0.00416469
Iteration 5675, loss = 0.00416368
Iteration 5676, loss = 0.00416264
Iteration 5677, loss = 0.00416170
Iteration 5678, loss = 0.00416100
Iteration 5679, loss = 0.00415976
Iteration 5680, loss = 0.00415897
Iteration 5681, loss = 0.00415763
Iteration 5682, loss = 0.00415657
Iteration 5683, loss = 0.00415549
Iteration 5684, loss = 0.00415438
Iteration 5685, loss = 0.00415335
Iteration 5686, loss = 0.00415233
Iteration 5687, loss = 0.00415105
Iteration 5688, loss = 0.00415045
Iteration 5689, loss = 0.00414917
Iteration 5690, loss = 0.00414823
Iteration 5691, loss = 0.00414707
Iteration 5692, loss = 0.00414608
Iteration 5693, loss = 0.00414505
Iteration 5694, loss = 0.00414415
Iteration 5695, loss = 0.00414320
Iteration 5696, loss = 0.00414217
Iteration 5697, loss = 0.00414111
Iteration 5698, loss = 0.00414055
Iteration 5699, loss = 0.00413959
Iteration 5700, loss = 0.00413829
Iteration 5701, loss = 0.00413731
Iteration 5702, loss = 0.00413650
Iteration 5703, loss = 0.00413572
Iteration 5704, loss = 0.00413417
Iteration 5705, loss = 0.00413305
Iteration 5706, loss = 0.00413220
Iteration 5707, loss = 0.00413158
Iteration 5708, loss = 0.00413122
Iteration 5709, loss = 0.00412966
Iteration 5710, loss = 0.00412895
Iteration 5711, loss = 0.00412776
Iteration 5712, loss = 0.00412679
Iteration 5713, loss = 0.00412574
Iteration 5714, loss = 0.00412484
Iteration 5715, loss = 0.00412369
Iteration 5716, loss = 0.00412252
Iteration 5717, loss = 0.00412150
Iteration 5718, loss = 0.00412046
Iteration 5719, loss = 0.00411940
Iteration 5720, loss = 0.00411833
Iteration 5721, loss = 0.00411761
Iteration 5722, loss = 0.00411660
Iteration 5723, loss = 0.00411635
Iteration 5724, loss = 0.00411496
Iteration 5725, loss = 0.00411384
Iteration 5726, loss = 0.00411260
Iteration 5727, loss = 0.00411157
Iteration 5728, loss = 0.00411154
Iteration 5729, loss = 0.00410996
Iteration 5730, loss = 0.00410884
Iteration 5731, loss = 0.00410775
Iteration 5732, loss = 0.00410675
Iteration 5733, loss = 0.00410579
Iteration 5734, loss = 0.00410478
Iteration 5735, loss = 0.00410384
Iteration 5736, loss = 0.00410305
Iteration 5737, loss = 0.00410209
Iteration 5738, loss = 0.00410118
Iteration 5739, loss = 0.00410027
Iteration 5740, loss = 0.00409925
Iteration 5741, loss = 0.00409833
Iteration 5742, loss = 0.00409770
Iteration 5743, loss = 0.00409655
Iteration 5744, loss = 0.00409556
Iteration 5745, loss = 0.00409459
Iteration 5746, loss = 0.00409373
Iteration 5747, loss = 0.00409262
Iteration 5748, loss = 0.00409166
Iteration 5749, loss = 0.00409076
Iteration 5750, loss = 0.00409020
Iteration 5751, loss = 0.00408895
Iteration 5752, loss = 0.00408806
Iteration 5753, loss = 0.00408714
Iteration 5754, loss = 0.00408614
Iteration 5755, loss = 0.00408520
Iteration 5756, loss = 0.00408412
Iteration 5757, loss = 0.00408319
Iteration 5758, loss = 0.00408223
Iteration 5759, loss = 0.00408148
Iteration 5760, loss = 0.00408062
Iteration 5761, loss = 0.00407973
Iteration 5762, loss = 0.00407846
Iteration 5763, loss = 0.00407757
Iteration 5764, loss = 0.00407669
Iteration 5765, loss = 0.00407568
Iteration 5766, loss = 0.00407457
Iteration 5767, loss = 0.00407386
Iteration 5768, loss = 0.00407274
Iteration 5769, loss = 0.00407204
Iteration 5770, loss = 0.00407103
Iteration 5771, loss = 0.00407010
Iteration 5772, loss = 0.00406921
Iteration 5773, loss = 0.00406879
Iteration 5774, loss = 0.00406743
Iteration 5775, loss = 0.00406656
Iteration 5776, loss = 0.00406549
Iteration 5777, loss = 0.00406447
Iteration 5778, loss = 0.00406390
Iteration 5779, loss = 0.00406254
Iteration 5780, loss = 0.00406159
Iteration 5781, loss = 0.00406070
Iteration 5782, loss = 0.00405966
Iteration 5783, loss = 0.00405862
Iteration 5784, loss = 0.00405779
Iteration 5785, loss = 0.00405700
Iteration 5786, loss = 0.00405585
Iteration 5787, loss = 0.00405501
Iteration 5788, loss = 0.00405409
Iteration 5789, loss = 0.00405315
Iteration 5790, loss = 0.00405216
Iteration 5791, loss = 0.00405131
Iteration 5792, loss = 0.00405153
Iteration 5793, loss = 0.00404969
Iteration 5794, loss = 0.00404871
Iteration 5795, loss = 0.00404767
Iteration 5796, loss = 0.00404670
Iteration 5797, loss = 0.00404607
Iteration 5798, loss = 0.00404489
Iteration 5799, loss = 0.00404385
Iteration 5800, loss = 0.00404291
Iteration 5801, loss = 0.00404198
Iteration 5802, loss = 0.00404107
Iteration 5803, loss = 0.00404032
Iteration 5804, loss = 0.00403933
Iteration 5805, loss = 0.00403836
Iteration 5806, loss = 0.00403735
Iteration 5807, loss = 0.00403709
Iteration 5808, loss = 0.00403594
Iteration 5809, loss = 0.00403503
Iteration 5810, loss = 0.00403399
Iteration 5811, loss = 0.00403306
Iteration 5812, loss = 0.00403224
Iteration 5813, loss = 0.00403133
Iteration 5814, loss = 0.00403045
Iteration 5815, loss = 0.00402996
Iteration 5816, loss = 0.00402875
Iteration 5817, loss = 0.00402785
Iteration 5818, loss = 0.00402719
Iteration 5819, loss = 0.00402629
Iteration 5820, loss = 0.00402542
Iteration 5821, loss = 0.00402461
Iteration 5822, loss = 0.00402393
Iteration 5823, loss = 0.00402274
Iteration 5824, loss = 0.00402200
Iteration 5825, loss = 0.00402090
Iteration 5826, loss = 0.00402022
Iteration 5827, loss = 0.00401907
Iteration 5828, loss = 0.00401827
Iteration 5829, loss = 0.00401805
Iteration 5830, loss = 0.00401623
Iteration 5831, loss = 0.00401532
Iteration 5832, loss = 0.00401436
Iteration 5833, loss = 0.00401331
Iteration 5834, loss = 0.00401238
Iteration 5835, loss = 0.00401155
Iteration 5836, loss = 0.00401060
Iteration 5837, loss = 0.00400957
Iteration 5838, loss = 0.00400856
Iteration 5839, loss = 0.00400771
Iteration 5840, loss = 0.00400689
Iteration 5841, loss = 0.00400590
Iteration 5842, loss = 0.00400499
Iteration 5843, loss = 0.00400411
Iteration 5844, loss = 0.00400321
Iteration 5845, loss = 0.00400266
Iteration 5846, loss = 0.00400185
Iteration 5847, loss = 0.00400060
Iteration 5848, loss = 0.00399966
Iteration 5849, loss = 0.00399879
Iteration 5850, loss = 0.00399780
Iteration 5851, loss = 0.00399687
Iteration 5852, loss = 0.00399622
Iteration 5853, loss = 0.00399547
Iteration 5854, loss = 0.00399447
Iteration 5855, loss = 0.00399348
Iteration 5856, loss = 0.00399290
Iteration 5857, loss = 0.00399181
Iteration 5858, loss = 0.00399094
Iteration 5859, loss = 0.00399029
Iteration 5860, loss = 0.00398903
Iteration 5861, loss = 0.00398822
Iteration 5862, loss = 0.00398708
Iteration 5863, loss = 0.00398630
Iteration 5864, loss = 0.00398554
Iteration 5865, loss = 0.00398439
Iteration 5866, loss = 0.00398382
Iteration 5867, loss = 0.00398271
Iteration 5868, loss = 0.00398188
Iteration 5869, loss = 0.00398095
Iteration 5870, loss = 0.00398013
Iteration 5871, loss = 0.00397911
Iteration 5872, loss = 0.00397814
Iteration 5873, loss = 0.00397720
Iteration 5874, loss = 0.00397662
Iteration 5875, loss = 0.00397550
Iteration 5876, loss = 0.00397462
Iteration 5877, loss = 0.00397349
Iteration 5878, loss = 0.00397251
Iteration 5879, loss = 0.00397165
Iteration 5880, loss = 0.00397098
Iteration 5881, loss = 0.00396992
Iteration 5882, loss = 0.00396912
Iteration 5883, loss = 0.00396844
Iteration 5884, loss = 0.00396735
Iteration 5885, loss = 0.00396653
Iteration 5886, loss = 0.00396564
Iteration 5887, loss = 0.00396471
Iteration 5888, loss = 0.00396378
Iteration 5889, loss = 0.00396314
Iteration 5890, loss = 0.00396257
Iteration 5891, loss = 0.00396129
Iteration 5892, loss = 0.00396122
Iteration 5893, loss = 0.00395968
Iteration 5894, loss = 0.00395873
Iteration 5895, loss = 0.00395806
Iteration 5896, loss = 0.00395702
Iteration 5897, loss = 0.00395601
Iteration 5898, loss = 0.00395540
Iteration 5899, loss = 0.00395437
Iteration 5900, loss = 0.00395335
Iteration 5901, loss = 0.00395248
Iteration 5902, loss = 0.00395161
Iteration 5903, loss = 0.00395100
Iteration 5904, loss = 0.00394994
Iteration 5905, loss = 0.00394896
Iteration 5906, loss = 0.00394855
Iteration 5907, loss = 0.00394748
Iteration 5908, loss = 0.00394655
Iteration 5909, loss = 0.00394572
Iteration 5910, loss = 0.00394482
Iteration 5911, loss = 0.00394410
Iteration 5912, loss = 0.00394285
Iteration 5913, loss = 0.00394220
Iteration 5914, loss = 0.00394132
Iteration 5915, loss = 0.00394058
Iteration 5916, loss = 0.00393956
Iteration 5917, loss = 0.00393873
Iteration 5918, loss = 0.00393777
Iteration 5919, loss = 0.00393731
Iteration 5920, loss = 0.00393641
Iteration 5921, loss = 0.00393523
Iteration 5922, loss = 0.00393431
Iteration 5923, loss = 0.00393354
Iteration 5924, loss = 0.00393277
Iteration 5925, loss = 0.00393185
Iteration 5926, loss = 0.00393092
Iteration 5927, loss = 0.00393022
Iteration 5928, loss = 0.00392913
Iteration 5929, loss = 0.00392817
Iteration 5930, loss = 0.00392724
Iteration 5931, loss = 0.00392637
Iteration 5932, loss = 0.00392541
Iteration 5933, loss = 0.00392434
Iteration 5934, loss = 0.00392328
Iteration 5935, loss = 0.00392221
Iteration 5936, loss = 0.00392123
Iteration 5937, loss = 0.00392093
Iteration 5938, loss = 0.00391998
Iteration 5939, loss = 0.00391932
Iteration 5940, loss = 0.00391810
Iteration 5941, loss = 0.00391722
Iteration 5942, loss = 0.00391637
Iteration 5943, loss = 0.00391549
Iteration 5944, loss = 0.00391472
Iteration 5945, loss = 0.00391384
Iteration 5946, loss = 0.00391298
Iteration 5947, loss = 0.00391218
Iteration 5948, loss = 0.00391126
Iteration 5949, loss = 0.00391059
Iteration 5950, loss = 0.00390953
Iteration 5951, loss = 0.00390877
Iteration 5952, loss = 0.00390793
Iteration 5953, loss = 0.00390709
Iteration 5954, loss = 0.00390628
Iteration 5955, loss = 0.00390546
Iteration 5956, loss = 0.00390462
Iteration 5957, loss = 0.00390380
Iteration 5958, loss = 0.00390296
Iteration 5959, loss = 0.00390221
Iteration 5960, loss = 0.00390122
Iteration 5961, loss = 0.00390046
Iteration 5962, loss = 0.00389970
Iteration 5963, loss = 0.00389901
Iteration 5964, loss = 0.00389799
Iteration 5965, loss = 0.00389712
Iteration 5966, loss = 0.00389612
Iteration 5967, loss = 0.00389543
Iteration 5968, loss = 0.00389439
Iteration 5969, loss = 0.00389344
Iteration 5970, loss = 0.00389259
Iteration 5971, loss = 0.00389205
Iteration 5972, loss = 0.00389078
Iteration 5973, loss = 0.00388994
Iteration 5974, loss = 0.00388940
Iteration 5975, loss = 0.00388839
Iteration 5976, loss = 0.00388767
Iteration 5977, loss = 0.00388662
Iteration 5978, loss = 0.00388584
Iteration 5979, loss = 0.00388490
Iteration 5980, loss = 0.00388426
Iteration 5981, loss = 0.00388326
Iteration 5982, loss = 0.00388238
Iteration 5983, loss = 0.00388150
Iteration 5984, loss = 0.00388064
Iteration 5985, loss = 0.00388003
Iteration 5986, loss = 0.00387906
Iteration 5987, loss = 0.00387848
Iteration 5988, loss = 0.00387727
Iteration 5989, loss = 0.00387645
Iteration 5990, loss = 0.00387569
Iteration 5991, loss = 0.00387477
Iteration 5992, loss = 0.00387380
Iteration 5993, loss = 0.00387296
Iteration 5994, loss = 0.00387201
Iteration 5995, loss = 0.00387102
Iteration 5996, loss = 0.00387038
Iteration 5997, loss = 0.00386931
Iteration 5998, loss = 0.00386848
Iteration 5999, loss = 0.00386799
Iteration 6000, loss = 0.00386695
Iteration 6001, loss = 0.00386603
Iteration 6002, loss = 0.00386498
Iteration 6003, loss = 0.00386436
Iteration 6004, loss = 0.00386332
Iteration 6005, loss = 0.00386264
Iteration 6006, loss = 0.00386189
Iteration 6007, loss = 0.00386109
Iteration 6008, loss = 0.00386028
Iteration 6009, loss = 0.00385952
Iteration 6010, loss = 0.00385882
Iteration 6011, loss = 0.00385805
Iteration 6012, loss = 0.00385764
Iteration 6013, loss = 0.00385671
Iteration 6014, loss = 0.00385582
Iteration 6015, loss = 0.00385494
Iteration 6016, loss = 0.00385422
Iteration 6017, loss = 0.00385347
Iteration 6018, loss = 0.00385284
Iteration 6019, loss = 0.00385174
Iteration 6020, loss = 0.00385084
Iteration 6021, loss = 0.00384999
Iteration 6022, loss = 0.00384911
Iteration 6023, loss = 0.00384830
Iteration 6024, loss = 0.00384773
Iteration 6025, loss = 0.00384692
Iteration 6026, loss = 0.00384611
Iteration 6027, loss = 0.00384530
Iteration 6028, loss = 0.00384446
Iteration 6029, loss = 0.00384387
Iteration 6030, loss = 0.00384301
Iteration 6031, loss = 0.00384220
Iteration 6032, loss = 0.00384143
Iteration 6033, loss = 0.00384064
Iteration 6034, loss = 0.00383988
Iteration 6035, loss = 0.00383920
Iteration 6036, loss = 0.00383835
Iteration 6037, loss = 0.00383754
Iteration 6038, loss = 0.00383669
Iteration 6039, loss = 0.00383580
Iteration 6040, loss = 0.00383489
Iteration 6041, loss = 0.00383413
Iteration 6042, loss = 0.00383365
Iteration 6043, loss = 0.00383231
Iteration 6044, loss = 0.00383180
Iteration 6045, loss = 0.00383089
Iteration 6046, loss = 0.00382972
Iteration 6047, loss = 0.00382876
Iteration 6048, loss = 0.00382789
Iteration 6049, loss = 0.00382696
Iteration 6050, loss = 0.00382604
Iteration 6051, loss = 0.00382539
Iteration 6052, loss = 0.00382467
Iteration 6053, loss = 0.00382371
Iteration 6054, loss = 0.00382283
Iteration 6055, loss = 0.00382236
Iteration 6056, loss = 0.00382133
Iteration 6057, loss = 0.00382068
Iteration 6058, loss = 0.00382011
Iteration 6059, loss = 0.00381957
Iteration 6060, loss = 0.00381862
Iteration 6061, loss = 0.00381758
Iteration 6062, loss = 0.00381680
Iteration 6063, loss = 0.00381656
Iteration 6064, loss = 0.00381503
Iteration 6065, loss = 0.00381429
Iteration 6066, loss = 0.00381347
Iteration 6067, loss = 0.00381255
Iteration 6068, loss = 0.00381172
Iteration 6069, loss = 0.00381105
Iteration 6070, loss = 0.00381019
Iteration 6071, loss = 0.00380939
Iteration 6072, loss = 0.00380868
Iteration 6073, loss = 0.00380799
Iteration 6074, loss = 0.00380744
Iteration 6075, loss = 0.00380641
Iteration 6076, loss = 0.00380549
Iteration 6077, loss = 0.00380471
Iteration 6078, loss = 0.00380384
Iteration 6079, loss = 0.00380292
Iteration 6080, loss = 0.00380189
Iteration 6081, loss = 0.00380104
Iteration 6082, loss = 0.00380041
Iteration 6083, loss = 0.00379953
Iteration 6084, loss = 0.00379846
Iteration 6085, loss = 0.00379758
Iteration 6086, loss = 0.00379672
Iteration 6087, loss = 0.00379590
Iteration 6088, loss = 0.00379505
Iteration 6089, loss = 0.00379423
Iteration 6090, loss = 0.00379328
Iteration 6091, loss = 0.00379246
Iteration 6092, loss = 0.00379151
Iteration 6093, loss = 0.00379076
Iteration 6094, loss = 0.00378970
Iteration 6095, loss = 0.00378909
Iteration 6096, loss = 0.00378817
Iteration 6097, loss = 0.00378705
Iteration 6098, loss = 0.00378628
Iteration 6099, loss = 0.00378542
Iteration 6100, loss = 0.00378454
Iteration 6101, loss = 0.00378366
Iteration 6102, loss = 0.00378271
Iteration 6103, loss = 0.00378211
Iteration 6104, loss = 0.00378096
Iteration 6105, loss = 0.00378006
Iteration 6106, loss = 0.00377938
Iteration 6107, loss = 0.00377840
Iteration 6108, loss = 0.00377769
Iteration 6109, loss = 0.00377680
Iteration 6110, loss = 0.00377600
Iteration 6111, loss = 0.00377527
Iteration 6112, loss = 0.00377440
Iteration 6113, loss = 0.00377365
Iteration 6114, loss = 0.00377251
Iteration 6115, loss = 0.00377232
Iteration 6116, loss = 0.00377150
Iteration 6117, loss = 0.00377037
Iteration 6118, loss = 0.00376943
Iteration 6119, loss = 0.00376866
Iteration 6120, loss = 0.00376770
Iteration 6121, loss = 0.00376721
Iteration 6122, loss = 0.00376623
Iteration 6123, loss = 0.00376546
Iteration 6124, loss = 0.00376470
Iteration 6125, loss = 0.00376412
Iteration 6126, loss = 0.00376310
Iteration 6127, loss = 0.00376228
Iteration 6128, loss = 0.00376139
Iteration 6129, loss = 0.00376040
Iteration 6130, loss = 0.00375995
Iteration 6131, loss = 0.00375992
Iteration 6132, loss = 0.00375822
Iteration 6133, loss = 0.00375763
Iteration 6134, loss = 0.00375663
Iteration 6135, loss = 0.00375552
Iteration 6136, loss = 0.00375489
Iteration 6137, loss = 0.00375379
Iteration 6138, loss = 0.00375310
Iteration 6139, loss = 0.00375213
Iteration 6140, loss = 0.00375142
Iteration 6141, loss = 0.00375051
Iteration 6142, loss = 0.00374964
Iteration 6143, loss = 0.00374868
Iteration 6144, loss = 0.00374767
Iteration 6145, loss = 0.00374694
Iteration 6146, loss = 0.00374642
Iteration 6147, loss = 0.00374517
Iteration 6148, loss = 0.00374432
Iteration 6149, loss = 0.00374352
Iteration 6150, loss = 0.00374275
Iteration 6151, loss = 0.00374201
Iteration 6152, loss = 0.00374119
Iteration 6153, loss = 0.00374049
Iteration 6154, loss = 0.00373974
Iteration 6155, loss = 0.00373913
Iteration 6156, loss = 0.00373828
Iteration 6157, loss = 0.00373735
Iteration 6158, loss = 0.00373657
Iteration 6159, loss = 0.00373580
Iteration 6160, loss = 0.00373493
Iteration 6161, loss = 0.00373388
Iteration 6162, loss = 0.00373301
Iteration 6163, loss = 0.00373203
Iteration 6164, loss = 0.00373205
Iteration 6165, loss = 0.00373028
Iteration 6166, loss = 0.00372944
Iteration 6167, loss = 0.00372857
Iteration 6168, loss = 0.00372805
Iteration 6169, loss = 0.00372729
Iteration 6170, loss = 0.00372608
Iteration 6171, loss = 0.00372516
Iteration 6172, loss = 0.00372449
Iteration 6173, loss = 0.00372359
Iteration 6174, loss = 0.00372262
Iteration 6175, loss = 0.00372166
Iteration 6176, loss = 0.00372125
Iteration 6177, loss = 0.00372005
Iteration 6178, loss = 0.00371919
Iteration 6179, loss = 0.00371838
Iteration 6180, loss = 0.00371765
Iteration 6181, loss = 0.00371678
Iteration 6182, loss = 0.00371603
Iteration 6183, loss = 0.00371577
Iteration 6184, loss = 0.00371454
Iteration 6185, loss = 0.00371359
Iteration 6186, loss = 0.00371297
Iteration 6187, loss = 0.00371210
Iteration 6188, loss = 0.00371138
Iteration 6189, loss = 0.00371065
Iteration 6190, loss = 0.00370983
Iteration 6191, loss = 0.00370920
Iteration 6192, loss = 0.00370839
Iteration 6193, loss = 0.00370803
Iteration 6194, loss = 0.00370688
Iteration 6195, loss = 0.00370618
Iteration 6196, loss = 0.00370551
Iteration 6197, loss = 0.00370462
Iteration 6198, loss = 0.00370394
Iteration 6199, loss = 0.00370317
Iteration 6200, loss = 0.00370253
Iteration 6201, loss = 0.00370190
Iteration 6202, loss = 0.00370105
Iteration 6203, loss = 0.00370022
Iteration 6204, loss = 0.00369944
Iteration 6205, loss = 0.00369863
Iteration 6206, loss = 0.00369787
Iteration 6207, loss = 0.00369719
Iteration 6208, loss = 0.00369655
Iteration 6209, loss = 0.00369601
Iteration 6210, loss = 0.00369512
Iteration 6211, loss = 0.00369445
Iteration 6212, loss = 0.00369388
Iteration 6213, loss = 0.00369324
Iteration 6214, loss = 0.00369245
Iteration 6215, loss = 0.00369186
Iteration 6216, loss = 0.00369110
Iteration 6217, loss = 0.00369039
Iteration 6218, loss = 0.00368970
Iteration 6219, loss = 0.00368896
Iteration 6220, loss = 0.00368855
Iteration 6221, loss = 0.00368818
Iteration 6222, loss = 0.00368705
Iteration 6223, loss = 0.00368625
Iteration 6224, loss = 0.00368549
Iteration 6225, loss = 0.00368455
Iteration 6226, loss = 0.00368363
Iteration 6227, loss = 0.00368320
Iteration 6228, loss = 0.00368196
Iteration 6229, loss = 0.00368174
Iteration 6230, loss = 0.00368047
Iteration 6231, loss = 0.00367961
Iteration 6232, loss = 0.00367880
Iteration 6233, loss = 0.00367802
Iteration 6234, loss = 0.00367720
Iteration 6235, loss = 0.00367622
Iteration 6236, loss = 0.00367565
Iteration 6237, loss = 0.00367455
Iteration 6238, loss = 0.00367377
Iteration 6239, loss = 0.00367308
Iteration 6240, loss = 0.00367219
Iteration 6241, loss = 0.00367139
Iteration 6242, loss = 0.00367077
Iteration 6243, loss = 0.00366994
Iteration 6244, loss = 0.00366921
Iteration 6245, loss = 0.00366869
Iteration 6246, loss = 0.00366789
Iteration 6247, loss = 0.00366713
Iteration 6248, loss = 0.00366648
Iteration 6249, loss = 0.00366577
Iteration 6250, loss = 0.00366491
Iteration 6251, loss = 0.00366422
Iteration 6252, loss = 0.00366341
Iteration 6253, loss = 0.00366263
Iteration 6254, loss = 0.00366183
Iteration 6255, loss = 0.00366110
Iteration 6256, loss = 0.00366019
Iteration 6257, loss = 0.00365989
Iteration 6258, loss = 0.00365878
Iteration 6259, loss = 0.00365788
Iteration 6260, loss = 0.00365716
Iteration 6261, loss = 0.00365630
Iteration 6262, loss = 0.00365546
Iteration 6263, loss = 0.00365467
Iteration 6264, loss = 0.00365421
Iteration 6265, loss = 0.00365316
Iteration 6266, loss = 0.00365263
Iteration 6267, loss = 0.00365166
Iteration 6268, loss = 0.00365081
Iteration 6269, loss = 0.00365012
Iteration 6270, loss = 0.00364930
Iteration 6271, loss = 0.00364854
Iteration 6272, loss = 0.00364777
Iteration 6273, loss = 0.00364708
Iteration 6274, loss = 0.00364627
Iteration 6275, loss = 0.00364547
Iteration 6276, loss = 0.00364479
Iteration 6277, loss = 0.00364381
Iteration 6278, loss = 0.00364307
Iteration 6279, loss = 0.00364240
Iteration 6280, loss = 0.00364147
Iteration 6281, loss = 0.00364082
Iteration 6282, loss = 0.00364001
Iteration 6283, loss = 0.00363941
Iteration 6284, loss = 0.00363891
Iteration 6285, loss = 0.00363780
Iteration 6286, loss = 0.00363702
Iteration 6287, loss = 0.00363693
Iteration 6288, loss = 0.00363567
Iteration 6289, loss = 0.00363490
Iteration 6290, loss = 0.00363398
Iteration 6291, loss = 0.00363313
Iteration 6292, loss = 0.00363233
Iteration 6293, loss = 0.00363226
Iteration 6294, loss = 0.00363116
Iteration 6295, loss = 0.00363024
Iteration 6296, loss = 0.00362954
Iteration 6297, loss = 0.00362875
Iteration 6298, loss = 0.00362786
Iteration 6299, loss = 0.00362732
Iteration 6300, loss = 0.00362642
Iteration 6301, loss = 0.00362559
Iteration 6302, loss = 0.00362484
Iteration 6303, loss = 0.00362407
Iteration 6304, loss = 0.00362301
Iteration 6305, loss = 0.00362280
Iteration 6306, loss = 0.00362153
Iteration 6307, loss = 0.00362089
Iteration 6308, loss = 0.00362000
Iteration 6309, loss = 0.00361924
Iteration 6310, loss = 0.00361849
Iteration 6311, loss = 0.00361784
Iteration 6312, loss = 0.00361701
Iteration 6313, loss = 0.00361660
Iteration 6314, loss = 0.00361565
Iteration 6315, loss = 0.00361532
Iteration 6316, loss = 0.00361409
Iteration 6317, loss = 0.00361326
Iteration 6318, loss = 0.00361244
Iteration 6319, loss = 0.00361193
Iteration 6320, loss = 0.00361094
Iteration 6321, loss = 0.00361019
Iteration 6322, loss = 0.00360941
Iteration 6323, loss = 0.00360868
Iteration 6324, loss = 0.00360773
Iteration 6325, loss = 0.00360720
Iteration 6326, loss = 0.00360611
Iteration 6327, loss = 0.00360553
Iteration 6328, loss = 0.00360458
Iteration 6329, loss = 0.00360378
Iteration 6330, loss = 0.00360323
Iteration 6331, loss = 0.00360227
Iteration 6332, loss = 0.00360148
Iteration 6333, loss = 0.00360080
Iteration 6334, loss = 0.00360005
Iteration 6335, loss = 0.00359927
Iteration 6336, loss = 0.00359857
Iteration 6337, loss = 0.00359789
Iteration 6338, loss = 0.00359714
Iteration 6339, loss = 0.00359651
Iteration 6340, loss = 0.00359579
Iteration 6341, loss = 0.00359510
Iteration 6342, loss = 0.00359452
Iteration 6343, loss = 0.00359371
Iteration 6344, loss = 0.00359311
Iteration 6345, loss = 0.00359234
Iteration 6346, loss = 0.00359179
Iteration 6347, loss = 0.00359092
Iteration 6348, loss = 0.00359023
Iteration 6349, loss = 0.00358956
Iteration 6350, loss = 0.00358906
Iteration 6351, loss = 0.00358831
Iteration 6352, loss = 0.00358758
Iteration 6353, loss = 0.00358693
Iteration 6354, loss = 0.00358629
Iteration 6355, loss = 0.00358564
Iteration 6356, loss = 0.00358473
Iteration 6357, loss = 0.00358413
Iteration 6358, loss = 0.00358327
Iteration 6359, loss = 0.00358261
Iteration 6360, loss = 0.00358177
Iteration 6361, loss = 0.00358102
Iteration 6362, loss = 0.00358038
Iteration 6363, loss = 0.00357968
Iteration 6364, loss = 0.00357891
Iteration 6365, loss = 0.00357849
Iteration 6366, loss = 0.00357737
Iteration 6367, loss = 0.00357673
Iteration 6368, loss = 0.00357591
Iteration 6369, loss = 0.00357507
Iteration 6370, loss = 0.00357467
Iteration 6371, loss = 0.00357421
Iteration 6372, loss = 0.00357320
Iteration 6373, loss = 0.00357248
Iteration 6374, loss = 0.00357200
Iteration 6375, loss = 0.00357163
Iteration 6376, loss = 0.00357067
Iteration 6377, loss = 0.00357003
Iteration 6378, loss = 0.00356918
Iteration 6379, loss = 0.00356839
Iteration 6380, loss = 0.00356772
Iteration 6381, loss = 0.00356705
Iteration 6382, loss = 0.00356614
Iteration 6383, loss = 0.00356543
Iteration 6384, loss = 0.00356477
Iteration 6385, loss = 0.00356414
Iteration 6386, loss = 0.00356361
Iteration 6387, loss = 0.00356272
Iteration 6388, loss = 0.00356197
Iteration 6389, loss = 0.00356106
Iteration 6390, loss = 0.00356076
Iteration 6391, loss = 0.00356016
Iteration 6392, loss = 0.00355927
Iteration 6393, loss = 0.00355826
Iteration 6394, loss = 0.00355735
Iteration 6395, loss = 0.00355661
Iteration 6396, loss = 0.00355587
Iteration 6397, loss = 0.00355504
Iteration 6398, loss = 0.00355448
Iteration 6399, loss = 0.00355376
Iteration 6400, loss = 0.00355304
Iteration 6401, loss = 0.00355246
Iteration 6402, loss = 0.00355170
Iteration 6403, loss = 0.00355110
Iteration 6404, loss = 0.00355053
Iteration 6405, loss = 0.00354992
Iteration 6406, loss = 0.00354926
Iteration 6407, loss = 0.00354862
Iteration 6408, loss = 0.00354811
Iteration 6409, loss = 0.00354740
Iteration 6410, loss = 0.00354678
Iteration 6411, loss = 0.00354614
Iteration 6412, loss = 0.00354537
Iteration 6413, loss = 0.00354472
Iteration 6414, loss = 0.00354417
Iteration 6415, loss = 0.00354394
Iteration 6416, loss = 0.00354286
Iteration 6417, loss = 0.00354235
Iteration 6418, loss = 0.00354143
Iteration 6419, loss = 0.00354110
Iteration 6420, loss = 0.00353992
Iteration 6421, loss = 0.00353906
Iteration 6422, loss = 0.00353841
Iteration 6423, loss = 0.00353773
Iteration 6424, loss = 0.00353683
Iteration 6425, loss = 0.00353610
Iteration 6426, loss = 0.00353525
Iteration 6427, loss = 0.00353446
Iteration 6428, loss = 0.00353358
Iteration 6429, loss = 0.00353330
Iteration 6430, loss = 0.00353222
Iteration 6431, loss = 0.00353160
Iteration 6432, loss = 0.00353064
Iteration 6433, loss = 0.00352991
Iteration 6434, loss = 0.00352907
Iteration 6435, loss = 0.00352809
Iteration 6436, loss = 0.00352767
Iteration 6437, loss = 0.00352624
Iteration 6438, loss = 0.00352564
Iteration 6439, loss = 0.00352457
Iteration 6440, loss = 0.00352408
Iteration 6441, loss = 0.00352313
Iteration 6442, loss = 0.00352235
Iteration 6443, loss = 0.00352140
Iteration 6444, loss = 0.00352059
Iteration 6445, loss = 0.00351972
Iteration 6446, loss = 0.00351932
Iteration 6447, loss = 0.00351844
Iteration 6448, loss = 0.00351756
Iteration 6449, loss = 0.00351742
Iteration 6450, loss = 0.00351622
Iteration 6451, loss = 0.00351544
Iteration 6452, loss = 0.00351481
Iteration 6453, loss = 0.00351415
Iteration 6454, loss = 0.00351346
Iteration 6455, loss = 0.00351280
Iteration 6456, loss = 0.00351225
Iteration 6457, loss = 0.00351154
Iteration 6458, loss = 0.00351092
Iteration 6459, loss = 0.00351027
Iteration 6460, loss = 0.00350978
Iteration 6461, loss = 0.00350905
Iteration 6462, loss = 0.00350828
Iteration 6463, loss = 0.00350759
Iteration 6464, loss = 0.00350684
Iteration 6465, loss = 0.00350626
Iteration 6466, loss = 0.00350579
Iteration 6467, loss = 0.00350509
Iteration 6468, loss = 0.00350428
Iteration 6469, loss = 0.00350361
Iteration 6470, loss = 0.00350283
Iteration 6471, loss = 0.00350216
Iteration 6472, loss = 0.00350145
Iteration 6473, loss = 0.00350080
Iteration 6474, loss = 0.00350002
Iteration 6475, loss = 0.00349942
Iteration 6476, loss = 0.00349874
Iteration 6477, loss = 0.00349800
Iteration 6478, loss = 0.00349732
Iteration 6479, loss = 0.00349683
Iteration 6480, loss = 0.00349603
Iteration 6481, loss = 0.00349515
Iteration 6482, loss = 0.00349458
Iteration 6483, loss = 0.00349402
Iteration 6484, loss = 0.00349327
Iteration 6485, loss = 0.00349241
Iteration 6486, loss = 0.00349185
Iteration 6487, loss = 0.00349104
Iteration 6488, loss = 0.00349034
Iteration 6489, loss = 0.00348985
Iteration 6490, loss = 0.00348931
Iteration 6491, loss = 0.00348833
Iteration 6492, loss = 0.00348727
Iteration 6493, loss = 0.00348656
Iteration 6494, loss = 0.00348610
Iteration 6495, loss = 0.00348510
Iteration 6496, loss = 0.00348434
Iteration 6497, loss = 0.00348369
Iteration 6498, loss = 0.00348292
Iteration 6499, loss = 0.00348200
Iteration 6500, loss = 0.00348114
Iteration 6501, loss = 0.00348113
Iteration 6502, loss = 0.00347994
Iteration 6503, loss = 0.00347931
Iteration 6504, loss = 0.00347858
Iteration 6505, loss = 0.00347790
Iteration 6506, loss = 0.00347726
Iteration 6507, loss = 0.00347654
Iteration 6508, loss = 0.00347582
Iteration 6509, loss = 0.00347534
Iteration 6510, loss = 0.00347466
Iteration 6511, loss = 0.00347400
Iteration 6512, loss = 0.00347329
Iteration 6513, loss = 0.00347279
Iteration 6514, loss = 0.00347197
Iteration 6515, loss = 0.00347131
Iteration 6516, loss = 0.00347071
Iteration 6517, loss = 0.00347012
Iteration 6518, loss = 0.00346940
Iteration 6519, loss = 0.00346877
Iteration 6520, loss = 0.00346806
Iteration 6521, loss = 0.00346736
Iteration 6522, loss = 0.00346670
Iteration 6523, loss = 0.00346626
Iteration 6524, loss = 0.00346528
Iteration 6525, loss = 0.00346451
Iteration 6526, loss = 0.00346389
Iteration 6527, loss = 0.00346311
Iteration 6528, loss = 0.00346241
Iteration 6529, loss = 0.00346171
Iteration 6530, loss = 0.00346144
Iteration 6531, loss = 0.00346034
Iteration 6532, loss = 0.00345963
Iteration 6533, loss = 0.00345890
Iteration 6534, loss = 0.00345822
Iteration 6535, loss = 0.00345752
Iteration 6536, loss = 0.00345693
Iteration 6537, loss = 0.00345616
Iteration 6538, loss = 0.00345547
Iteration 6539, loss = 0.00345474
Iteration 6540, loss = 0.00345405
Iteration 6541, loss = 0.00345339
Iteration 6542, loss = 0.00345300
Iteration 6543, loss = 0.00345206
Iteration 6544, loss = 0.00345145
Iteration 6545, loss = 0.00345074
Iteration 6546, loss = 0.00345017
Iteration 6547, loss = 0.00344934
Iteration 6548, loss = 0.00344867
Iteration 6549, loss = 0.00344793
Iteration 6550, loss = 0.00344725
Iteration 6551, loss = 0.00344657
Iteration 6552, loss = 0.00344585
Iteration 6553, loss = 0.00344517
Iteration 6554, loss = 0.00344449
Iteration 6555, loss = 0.00344374
Iteration 6556, loss = 0.00344341
Iteration 6557, loss = 0.00344226
Iteration 6558, loss = 0.00344169
Iteration 6559, loss = 0.00344090
Iteration 6560, loss = 0.00344017
Iteration 6561, loss = 0.00343936
Iteration 6562, loss = 0.00343884
Iteration 6563, loss = 0.00343797
Iteration 6564, loss = 0.00343786
Iteration 6565, loss = 0.00343656
Iteration 6566, loss = 0.00343576
Iteration 6567, loss = 0.00343541
Iteration 6568, loss = 0.00343442
Iteration 6569, loss = 0.00343378
Iteration 6570, loss = 0.00343309
Iteration 6571, loss = 0.00343242
Iteration 6572, loss = 0.00343185
Iteration 6573, loss = 0.00343123
Iteration 6574, loss = 0.00343043
Iteration 6575, loss = 0.00342982
Iteration 6576, loss = 0.00342914
Iteration 6577, loss = 0.00342847
Iteration 6578, loss = 0.00342773
Iteration 6579, loss = 0.00342711
Iteration 6580, loss = 0.00342642
Iteration 6581, loss = 0.00342573
Iteration 6582, loss = 0.00342511
Iteration 6583, loss = 0.00342454
Iteration 6584, loss = 0.00342390
Iteration 6585, loss = 0.00342320
Iteration 6586, loss = 0.00342231
Iteration 6587, loss = 0.00342168
Iteration 6588, loss = 0.00342110
Iteration 6589, loss = 0.00342032
Iteration 6590, loss = 0.00341964
Iteration 6591, loss = 0.00341904
Iteration 6592, loss = 0.00341822
Iteration 6593, loss = 0.00341787
Iteration 6594, loss = 0.00341706
Iteration 6595, loss = 0.00341629
Iteration 6596, loss = 0.00341570
Iteration 6597, loss = 0.00341523
Iteration 6598, loss = 0.00341450
Iteration 6599, loss = 0.00341364
Iteration 6600, loss = 0.00341304
Iteration 6601, loss = 0.00341228
Iteration 6602, loss = 0.00341156
Iteration 6603, loss = 0.00341084
Iteration 6604, loss = 0.00341009
Iteration 6605, loss = 0.00340941
Iteration 6606, loss = 0.00340869
Iteration 6607, loss = 0.00340815
Iteration 6608, loss = 0.00340738
Iteration 6609, loss = 0.00340677
Iteration 6610, loss = 0.00340605
Iteration 6611, loss = 0.00340554
Iteration 6612, loss = 0.00340488
Iteration 6613, loss = 0.00340408
Iteration 6614, loss = 0.00340328
Iteration 6615, loss = 0.00340265
Iteration 6616, loss = 0.00340197
Iteration 6617, loss = 0.00340139
Iteration 6618, loss = 0.00340073
Iteration 6619, loss = 0.00340010
Iteration 6620, loss = 0.00339937
Iteration 6621, loss = 0.00339855
Iteration 6622, loss = 0.00339797
Iteration 6623, loss = 0.00339728
Iteration 6624, loss = 0.00339644
Iteration 6625, loss = 0.00339573
Iteration 6626, loss = 0.00339505
Iteration 6627, loss = 0.00339450
Iteration 6628, loss = 0.00339371
Iteration 6629, loss = 0.00339311
Iteration 6630, loss = 0.00339247
Iteration 6631, loss = 0.00339182
Iteration 6632, loss = 0.00339143
Iteration 6633, loss = 0.00339049
Iteration 6634, loss = 0.00338980
Iteration 6635, loss = 0.00338916
Iteration 6636, loss = 0.00338843
Iteration 6637, loss = 0.00338817
Iteration 6638, loss = 0.00338723
Iteration 6639, loss = 0.00338657
Iteration 6640, loss = 0.00338576
Iteration 6641, loss = 0.00338514
Iteration 6642, loss = 0.00338454
Iteration 6643, loss = 0.00338381
Iteration 6644, loss = 0.00338326
Iteration 6645, loss = 0.00338266
Iteration 6646, loss = 0.00338207
Iteration 6647, loss = 0.00338133
Iteration 6648, loss = 0.00338087
Iteration 6649, loss = 0.00338002
Iteration 6650, loss = 0.00337942
Iteration 6651, loss = 0.00337887
Iteration 6652, loss = 0.00337811
Iteration 6653, loss = 0.00337777
Iteration 6654, loss = 0.00337707
Iteration 6655, loss = 0.00337636
Iteration 6656, loss = 0.00337574
Iteration 6657, loss = 0.00337518
Iteration 6658, loss = 0.00337477
Iteration 6659, loss = 0.00337397
Iteration 6660, loss = 0.00337335
Iteration 6661, loss = 0.00337287
Iteration 6662, loss = 0.00337195
Iteration 6663, loss = 0.00337140
Iteration 6664, loss = 0.00337064
Iteration 6665, loss = 0.00336998
Iteration 6666, loss = 0.00336920
Iteration 6667, loss = 0.00336858
Iteration 6668, loss = 0.00336789
Iteration 6669, loss = 0.00336720
Iteration 6670, loss = 0.00336664
Iteration 6671, loss = 0.00336604
Iteration 6672, loss = 0.00336539
Iteration 6673, loss = 0.00336466
Iteration 6674, loss = 0.00336409
Iteration 6675, loss = 0.00336345
Iteration 6676, loss = 0.00336270
Iteration 6677, loss = 0.00336200
Iteration 6678, loss = 0.00336141
Iteration 6679, loss = 0.00336069
Iteration 6680, loss = 0.00335999
Iteration 6681, loss = 0.00335939
Iteration 6682, loss = 0.00335867
Iteration 6683, loss = 0.00335799
Iteration 6684, loss = 0.00335735
Iteration 6685, loss = 0.00335669
Iteration 6686, loss = 0.00335609
Iteration 6687, loss = 0.00335577
Iteration 6688, loss = 0.00335486
Iteration 6689, loss = 0.00335426
Iteration 6690, loss = 0.00335369
Iteration 6691, loss = 0.00335308
Iteration 6692, loss = 0.00335259
Iteration 6693, loss = 0.00335207
Iteration 6694, loss = 0.00335138
Iteration 6695, loss = 0.00335075
Iteration 6696, loss = 0.00335014
Iteration 6697, loss = 0.00334963
Iteration 6698, loss = 0.00334920
Iteration 6699, loss = 0.00334844
Iteration 6700, loss = 0.00334764
Iteration 6701, loss = 0.00334694
Iteration 6702, loss = 0.00334643
Iteration 6703, loss = 0.00334567
Iteration 6704, loss = 0.00334504
Iteration 6705, loss = 0.00334435
Iteration 6706, loss = 0.00334366
Iteration 6707, loss = 0.00334299
Iteration 6708, loss = 0.00334235
Iteration 6709, loss = 0.00334166
Iteration 6710, loss = 0.00334098
Iteration 6711, loss = 0.00334049
Iteration 6712, loss = 0.00333949
Iteration 6713, loss = 0.00333882
Iteration 6714, loss = 0.00333820
Iteration 6715, loss = 0.00333757
Iteration 6716, loss = 0.00333702
Iteration 6717, loss = 0.00333643
Iteration 6718, loss = 0.00333583
Iteration 6719, loss = 0.00333506
Iteration 6720, loss = 0.00333451
Iteration 6721, loss = 0.00333362
Iteration 6722, loss = 0.00333298
Iteration 6723, loss = 0.00333226
Iteration 6724, loss = 0.00333155
Iteration 6725, loss = 0.00333122
Iteration 6726, loss = 0.00333037
Iteration 6727, loss = 0.00332961
Iteration 6728, loss = 0.00332889
Iteration 6729, loss = 0.00332847
Iteration 6730, loss = 0.00332758
Iteration 6731, loss = 0.00332707
Iteration 6732, loss = 0.00332639
Iteration 6733, loss = 0.00332594
Iteration 6734, loss = 0.00332496
Iteration 6735, loss = 0.00332428
Iteration 6736, loss = 0.00332356
Iteration 6737, loss = 0.00332316
Iteration 6738, loss = 0.00332248
Iteration 6739, loss = 0.00332163
Iteration 6740, loss = 0.00332105
Iteration 6741, loss = 0.00332037
Iteration 6742, loss = 0.00331975
Iteration 6743, loss = 0.00331922
Iteration 6744, loss = 0.00331851
Iteration 6745, loss = 0.00331794
Iteration 6746, loss = 0.00331769
Iteration 6747, loss = 0.00331683
Iteration 6748, loss = 0.00331653
Iteration 6749, loss = 0.00331564
Iteration 6750, loss = 0.00331471
Iteration 6751, loss = 0.00331382
Iteration 6752, loss = 0.00331328
Iteration 6753, loss = 0.00331285
Iteration 6754, loss = 0.00331181
Iteration 6755, loss = 0.00331115
Iteration 6756, loss = 0.00331053
Iteration 6757, loss = 0.00330985
Iteration 6758, loss = 0.00330919
Iteration 6759, loss = 0.00330857
Iteration 6760, loss = 0.00330797
Iteration 6761, loss = 0.00330733
Iteration 6762, loss = 0.00330680
Iteration 6763, loss = 0.00330627
Iteration 6764, loss = 0.00330554
Iteration 6765, loss = 0.00330493
Iteration 6766, loss = 0.00330426
Iteration 6767, loss = 0.00330367
Iteration 6768, loss = 0.00330298
Iteration 6769, loss = 0.00330260
Iteration 6770, loss = 0.00330175
Iteration 6771, loss = 0.00330103
Iteration 6772, loss = 0.00330066
Iteration 6773, loss = 0.00329980
Iteration 6774, loss = 0.00329930
Iteration 6775, loss = 0.00329882
Iteration 6776, loss = 0.00329796
Iteration 6777, loss = 0.00329728
Iteration 6778, loss = 0.00329659
Iteration 6779, loss = 0.00329601
Iteration 6780, loss = 0.00329550
Iteration 6781, loss = 0.00329476
Iteration 6782, loss = 0.00329411
Iteration 6783, loss = 0.00329360
Iteration 6784, loss = 0.00329290
Iteration 6785, loss = 0.00329240
Iteration 6786, loss = 0.00329161
Iteration 6787, loss = 0.00329094
Iteration 6788, loss = 0.00329053
Iteration 6789, loss = 0.00328990
Iteration 6790, loss = 0.00328910
Iteration 6791, loss = 0.00328831
Iteration 6792, loss = 0.00328767
Iteration 6793, loss = 0.00328703
Iteration 6794, loss = 0.00328669
Iteration 6795, loss = 0.00328577
Iteration 6796, loss = 0.00328508
Iteration 6797, loss = 0.00328451
Iteration 6798, loss = 0.00328388
Iteration 6799, loss = 0.00328327
Iteration 6800, loss = 0.00328263
Iteration 6801, loss = 0.00328204
Iteration 6802, loss = 0.00328144
Iteration 6803, loss = 0.00328079
Iteration 6804, loss = 0.00328022
Iteration 6805, loss = 0.00327963
Iteration 6806, loss = 0.00327918
Iteration 6807, loss = 0.00327839
Iteration 6808, loss = 0.00327831
Iteration 6809, loss = 0.00327738
Iteration 6810, loss = 0.00327654
Iteration 6811, loss = 0.00327597
Iteration 6812, loss = 0.00327530
Iteration 6813, loss = 0.00327455
Iteration 6814, loss = 0.00327388
Iteration 6815, loss = 0.00327318
Iteration 6816, loss = 0.00327264
Iteration 6817, loss = 0.00327184
Iteration 6818, loss = 0.00327125
Iteration 6819, loss = 0.00327061
Iteration 6820, loss = 0.00327050
Iteration 6821, loss = 0.00326912
Iteration 6822, loss = 0.00326844
Iteration 6823, loss = 0.00326766
Iteration 6824, loss = 0.00326715
Iteration 6825, loss = 0.00326649
Iteration 6826, loss = 0.00326593
Iteration 6827, loss = 0.00326507
Iteration 6828, loss = 0.00326460
Iteration 6829, loss = 0.00326376
Iteration 6830, loss = 0.00326313
Iteration 6831, loss = 0.00326273
Iteration 6832, loss = 0.00326173
Iteration 6833, loss = 0.00326095
Iteration 6834, loss = 0.00326045
Iteration 6835, loss = 0.00325947
Iteration 6836, loss = 0.00325878
Iteration 6837, loss = 0.00325809
Iteration 6838, loss = 0.00325731
Iteration 6839, loss = 0.00325679
Iteration 6840, loss = 0.00325624
Iteration 6841, loss = 0.00325569
Iteration 6842, loss = 0.00325498
Iteration 6843, loss = 0.00325416
Iteration 6844, loss = 0.00325379
Iteration 6845, loss = 0.00325283
Iteration 6846, loss = 0.00325224
Iteration 6847, loss = 0.00325149
Iteration 6848, loss = 0.00325105
Iteration 6849, loss = 0.00325030
Iteration 6850, loss = 0.00324947
Iteration 6851, loss = 0.00324892
Iteration 6852, loss = 0.00324824
Iteration 6853, loss = 0.00324760
Iteration 6854, loss = 0.00324705
Iteration 6855, loss = 0.00324631
Iteration 6856, loss = 0.00324565
Iteration 6857, loss = 0.00324500
Iteration 6858, loss = 0.00324436
Iteration 6859, loss = 0.00324373
Iteration 6860, loss = 0.00324312
Iteration 6861, loss = 0.00324238
Iteration 6862, loss = 0.00324207
Iteration 6863, loss = 0.00324127
Iteration 6864, loss = 0.00324053
Iteration 6865, loss = 0.00323989
Iteration 6866, loss = 0.00323926
Iteration 6867, loss = 0.00323860
Iteration 6868, loss = 0.00323803
Iteration 6869, loss = 0.00323745
Iteration 6870, loss = 0.00323684
Iteration 6871, loss = 0.00323642
Iteration 6872, loss = 0.00323581
Iteration 6873, loss = 0.00323508
Iteration 6874, loss = 0.00323449
Iteration 6875, loss = 0.00323395
Iteration 6876, loss = 0.00323342
Iteration 6877, loss = 0.00323286
Iteration 6878, loss = 0.00323230
Iteration 6879, loss = 0.00323177
Iteration 6880, loss = 0.00323128
Iteration 6881, loss = 0.00323080
Iteration 6882, loss = 0.00323021
Iteration 6883, loss = 0.00322968
Iteration 6884, loss = 0.00322911
Iteration 6885, loss = 0.00322870
Iteration 6886, loss = 0.00322804
Iteration 6887, loss = 0.00322759
Iteration 6888, loss = 0.00322688
Iteration 6889, loss = 0.00322633
Iteration 6890, loss = 0.00322572
Iteration 6891, loss = 0.00322510
Iteration 6892, loss = 0.00322434
Iteration 6893, loss = 0.00322369
Iteration 6894, loss = 0.00322333
Iteration 6895, loss = 0.00322252
Iteration 6896, loss = 0.00322210
Iteration 6897, loss = 0.00322147
Iteration 6898, loss = 0.00322074
Iteration 6899, loss = 0.00322009
Iteration 6900, loss = 0.00321935
Iteration 6901, loss = 0.00321857
Iteration 6902, loss = 0.00321835
Iteration 6903, loss = 0.00321783
Iteration 6904, loss = 0.00321726
Iteration 6905, loss = 0.00321647
Iteration 6906, loss = 0.00321564
Iteration 6907, loss = 0.00321524
Iteration 6908, loss = 0.00321445
Iteration 6909, loss = 0.00321380
Iteration 6910, loss = 0.00321354
Iteration 6911, loss = 0.00321262
Iteration 6912, loss = 0.00321185
Iteration 6913, loss = 0.00321124
Iteration 6914, loss = 0.00321066
Iteration 6915, loss = 0.00320999
Iteration 6916, loss = 0.00320935
Iteration 6917, loss = 0.00320895
Iteration 6918, loss = 0.00320824
Iteration 6919, loss = 0.00320757
Iteration 6920, loss = 0.00320693
Iteration 6921, loss = 0.00320636
Iteration 6922, loss = 0.00320568
Iteration 6923, loss = 0.00320498
Iteration 6924, loss = 0.00320447
Iteration 6925, loss = 0.00320372
Iteration 6926, loss = 0.00320302
Iteration 6927, loss = 0.00320232
Iteration 6928, loss = 0.00320214
Iteration 6929, loss = 0.00320104
Iteration 6930, loss = 0.00320056
Iteration 6931, loss = 0.00319996
Iteration 6932, loss = 0.00319923
Iteration 6933, loss = 0.00319861
Iteration 6934, loss = 0.00319809
Iteration 6935, loss = 0.00319741
Iteration 6936, loss = 0.00319679
Iteration 6937, loss = 0.00319615
Iteration 6938, loss = 0.00319553
Iteration 6939, loss = 0.00319506
Iteration 6940, loss = 0.00319431
Iteration 6941, loss = 0.00319377
Iteration 6942, loss = 0.00319321
Iteration 6943, loss = 0.00319271
Iteration 6944, loss = 0.00319237
Iteration 6945, loss = 0.00319160
Iteration 6946, loss = 0.00319120
Iteration 6947, loss = 0.00319057
Iteration 6948, loss = 0.00318981
Iteration 6949, loss = 0.00318911
Iteration 6950, loss = 0.00318863
Iteration 6951, loss = 0.00318795
Iteration 6952, loss = 0.00318745
Iteration 6953, loss = 0.00318683
Iteration 6954, loss = 0.00318645
Iteration 6955, loss = 0.00318567
Iteration 6956, loss = 0.00318510
Iteration 6957, loss = 0.00318451
Iteration 6958, loss = 0.00318395
Iteration 6959, loss = 0.00318347
Iteration 6960, loss = 0.00318274
Iteration 6961, loss = 0.00318225
Iteration 6962, loss = 0.00318164
Iteration 6963, loss = 0.00318102
Iteration 6964, loss = 0.00318047
Iteration 6965, loss = 0.00318011
Iteration 6966, loss = 0.00317937
Iteration 6967, loss = 0.00317886
Iteration 6968, loss = 0.00317829
Iteration 6969, loss = 0.00317810
Iteration 6970, loss = 0.00317741
Iteration 6971, loss = 0.00317674
Iteration 6972, loss = 0.00317619
Iteration 6973, loss = 0.00317567
Iteration 6974, loss = 0.00317520
Iteration 6975, loss = 0.00317459
Iteration 6976, loss = 0.00317401
Iteration 6977, loss = 0.00317343
Iteration 6978, loss = 0.00317276
Iteration 6979, loss = 0.00317207
Iteration 6980, loss = 0.00317154
Iteration 6981, loss = 0.00317080
Iteration 6982, loss = 0.00317008
Iteration 6983, loss = 0.00316953
Iteration 6984, loss = 0.00316887
Iteration 6985, loss = 0.00316821
Iteration 6986, loss = 0.00316748
Iteration 6987, loss = 0.00316717
Iteration 6988, loss = 0.00316628
Iteration 6989, loss = 0.00316576
Iteration 6990, loss = 0.00316510
Iteration 6991, loss = 0.00316437
Iteration 6992, loss = 0.00316369
Iteration 6993, loss = 0.00316308
Iteration 6994, loss = 0.00316248
Iteration 6995, loss = 0.00316186
Iteration 6996, loss = 0.00316117
Iteration 6997, loss = 0.00316067
Iteration 6998, loss = 0.00316008
Iteration 6999, loss = 0.00315936
Iteration 7000, loss = 0.00315875
Iteration 7001, loss = 0.00315822
Iteration 7002, loss = 0.00315768
Iteration 7003, loss = 0.00315700
Iteration 7004, loss = 0.00315645
Iteration 7005, loss = 0.00315585
Iteration 7006, loss = 0.00315504
Iteration 7007, loss = 0.00315477
Iteration 7008, loss = 0.00315397
Iteration 7009, loss = 0.00315370
Iteration 7010, loss = 0.00315282
Iteration 7011, loss = 0.00315222
Iteration 7012, loss = 0.00315165
Iteration 7013, loss = 0.00315117
Iteration 7014, loss = 0.00315048
Iteration 7015, loss = 0.00315008
Iteration 7016, loss = 0.00314943
Iteration 7017, loss = 0.00314886
Iteration 7018, loss = 0.00314832
Iteration 7019, loss = 0.00314786
Iteration 7020, loss = 0.00314726
Iteration 7021, loss = 0.00314675
Iteration 7022, loss = 0.00314616
Iteration 7023, loss = 0.00314568
Iteration 7024, loss = 0.00314515
Iteration 7025, loss = 0.00314463
Iteration 7026, loss = 0.00314418
Iteration 7027, loss = 0.00314356
Iteration 7028, loss = 0.00314298
Iteration 7029, loss = 0.00314282
Iteration 7030, loss = 0.00314183
Iteration 7031, loss = 0.00314107
Iteration 7032, loss = 0.00314049
Iteration 7033, loss = 0.00314003
Iteration 7034, loss = 0.00313931
Iteration 7035, loss = 0.00313874
Iteration 7036, loss = 0.00313813
Iteration 7037, loss = 0.00313758
Iteration 7038, loss = 0.00313706
Iteration 7039, loss = 0.00313650
Iteration 7040, loss = 0.00313605
Iteration 7041, loss = 0.00313536
Iteration 7042, loss = 0.00313495
Iteration 7043, loss = 0.00313430
Iteration 7044, loss = 0.00313371
Iteration 7045, loss = 0.00313322
Iteration 7046, loss = 0.00313267
Iteration 7047, loss = 0.00313218
Iteration 7048, loss = 0.00313168
Iteration 7049, loss = 0.00313111
Iteration 7050, loss = 0.00313106
Iteration 7051, loss = 0.00312998
Iteration 7052, loss = 0.00312925
Iteration 7053, loss = 0.00312866
Iteration 7054, loss = 0.00312807
Iteration 7055, loss = 0.00312751
Iteration 7056, loss = 0.00312676
Iteration 7057, loss = 0.00312614
Iteration 7058, loss = 0.00312546
Iteration 7059, loss = 0.00312468
Iteration 7060, loss = 0.00312405
Iteration 7061, loss = 0.00312342
Iteration 7062, loss = 0.00312344
Iteration 7063, loss = 0.00312218
Iteration 7064, loss = 0.00312156
Iteration 7065, loss = 0.00312087
Iteration 7066, loss = 0.00312024
Iteration 7067, loss = 0.00311968
Iteration 7068, loss = 0.00311909
Iteration 7069, loss = 0.00311835
Iteration 7070, loss = 0.00311779
Iteration 7071, loss = 0.00311727
Iteration 7072, loss = 0.00311667
Iteration 7073, loss = 0.00311607
Iteration 7074, loss = 0.00311551
Iteration 7075, loss = 0.00311502
Iteration 7076, loss = 0.00311437
Iteration 7077, loss = 0.00311387
Iteration 7078, loss = 0.00311324
Iteration 7079, loss = 0.00311260
Iteration 7080, loss = 0.00311202
Iteration 7081, loss = 0.00311145
Iteration 7082, loss = 0.00311096
Iteration 7083, loss = 0.00311034
Iteration 7084, loss = 0.00310990
Iteration 7085, loss = 0.00310931
Iteration 7086, loss = 0.00310868
Iteration 7087, loss = 0.00310805
Iteration 7088, loss = 0.00310736
Iteration 7089, loss = 0.00310664
Iteration 7090, loss = 0.00310642
Iteration 7091, loss = 0.00310548
Iteration 7092, loss = 0.00310500
Iteration 7093, loss = 0.00310443
Iteration 7094, loss = 0.00310358
Iteration 7095, loss = 0.00310304
Iteration 7096, loss = 0.00310247
Iteration 7097, loss = 0.00310170
Iteration 7098, loss = 0.00310118
Iteration 7099, loss = 0.00310048
Iteration 7100, loss = 0.00309987
Iteration 7101, loss = 0.00309954
Iteration 7102, loss = 0.00309866
Iteration 7103, loss = 0.00309799
Iteration 7104, loss = 0.00309760
Iteration 7105, loss = 0.00309686
Iteration 7106, loss = 0.00309637
Iteration 7107, loss = 0.00309582
Iteration 7108, loss = 0.00309540
Iteration 7109, loss = 0.00309479
Iteration 7110, loss = 0.00309410
Iteration 7111, loss = 0.00309353
Iteration 7112, loss = 0.00309301
Iteration 7113, loss = 0.00309234
Iteration 7114, loss = 0.00309177
Iteration 7115, loss = 0.00309119
Iteration 7116, loss = 0.00309085
Iteration 7117, loss = 0.00309018
Iteration 7118, loss = 0.00308975
Iteration 7119, loss = 0.00308916
Iteration 7120, loss = 0.00308843
Iteration 7121, loss = 0.00308790
Iteration 7122, loss = 0.00308726
Iteration 7123, loss = 0.00308681
Iteration 7124, loss = 0.00308613
Iteration 7125, loss = 0.00308546
Iteration 7126, loss = 0.00308476
Iteration 7127, loss = 0.00308403
Iteration 7128, loss = 0.00308343
Iteration 7129, loss = 0.00308276
Iteration 7130, loss = 0.00308216
Iteration 7131, loss = 0.00308163
Iteration 7132, loss = 0.00308132
Iteration 7133, loss = 0.00308050
Iteration 7134, loss = 0.00307995
Iteration 7135, loss = 0.00307953
Iteration 7136, loss = 0.00307877
Iteration 7137, loss = 0.00307816
Iteration 7138, loss = 0.00307758
Iteration 7139, loss = 0.00307700
Iteration 7140, loss = 0.00307648
Iteration 7141, loss = 0.00307653
Iteration 7142, loss = 0.00307542
Iteration 7143, loss = 0.00307490
Iteration 7144, loss = 0.00307439
Iteration 7145, loss = 0.00307398
Iteration 7146, loss = 0.00307316
Iteration 7147, loss = 0.00307288
Iteration 7148, loss = 0.00307216
Iteration 7149, loss = 0.00307164
Iteration 7150, loss = 0.00307113
Iteration 7151, loss = 0.00307073
Iteration 7152, loss = 0.00307027
Iteration 7153, loss = 0.00306986
Iteration 7154, loss = 0.00306915
Iteration 7155, loss = 0.00306865
Iteration 7156, loss = 0.00306806
Iteration 7157, loss = 0.00306766
Iteration 7158, loss = 0.00306700
Iteration 7159, loss = 0.00306653
Iteration 7160, loss = 0.00306600
Iteration 7161, loss = 0.00306519
Iteration 7162, loss = 0.00306458
Iteration 7163, loss = 0.00306406
Iteration 7164, loss = 0.00306352
Iteration 7165, loss = 0.00306293
Iteration 7166, loss = 0.00306229
Iteration 7167, loss = 0.00306175
Iteration 7168, loss = 0.00306133
Iteration 7169, loss = 0.00306058
Iteration 7170, loss = 0.00306012
Iteration 7171, loss = 0.00305947
Iteration 7172, loss = 0.00305902
Iteration 7173, loss = 0.00305838
Iteration 7174, loss = 0.00305782
Iteration 7175, loss = 0.00305720
Iteration 7176, loss = 0.00305660
Iteration 7177, loss = 0.00305606
Iteration 7178, loss = 0.00305556
Iteration 7179, loss = 0.00305532
Iteration 7180, loss = 0.00305438
Iteration 7181, loss = 0.00305385
Iteration 7182, loss = 0.00305325
Iteration 7183, loss = 0.00305285
Iteration 7184, loss = 0.00305244
Iteration 7185, loss = 0.00305154
Iteration 7186, loss = 0.00305110
Iteration 7187, loss = 0.00305055
Iteration 7188, loss = 0.00304987
Iteration 7189, loss = 0.00304936
Iteration 7190, loss = 0.00304878
Iteration 7191, loss = 0.00304838
Iteration 7192, loss = 0.00304770
Iteration 7193, loss = 0.00304724
Iteration 7194, loss = 0.00304659
Iteration 7195, loss = 0.00304609
Iteration 7196, loss = 0.00304593
Iteration 7197, loss = 0.00304473
Iteration 7198, loss = 0.00304414
Iteration 7199, loss = 0.00304363
Iteration 7200, loss = 0.00304304
Iteration 7201, loss = 0.00304241
Iteration 7202, loss = 0.00304188
Iteration 7203, loss = 0.00304134
Iteration 7204, loss = 0.00304055
Iteration 7205, loss = 0.00303999
Iteration 7206, loss = 0.00303928
Iteration 7207, loss = 0.00303862
Iteration 7208, loss = 0.00303811
Iteration 7209, loss = 0.00303751
Iteration 7210, loss = 0.00303723
Iteration 7211, loss = 0.00303638
Iteration 7212, loss = 0.00303587
Iteration 7213, loss = 0.00303524
Iteration 7214, loss = 0.00303469
Iteration 7215, loss = 0.00303414
Iteration 7216, loss = 0.00303363
Iteration 7217, loss = 0.00303310
Iteration 7218, loss = 0.00303257
Iteration 7219, loss = 0.00303198
Iteration 7220, loss = 0.00303147
Iteration 7221, loss = 0.00303091
Iteration 7222, loss = 0.00303047
Iteration 7223, loss = 0.00302981
Iteration 7224, loss = 0.00302932
Iteration 7225, loss = 0.00302891
Iteration 7226, loss = 0.00302830
Iteration 7227, loss = 0.00302777
Iteration 7228, loss = 0.00302724
Iteration 7229, loss = 0.00302673
Iteration 7230, loss = 0.00302625
Iteration 7231, loss = 0.00302563
Iteration 7232, loss = 0.00302522
Iteration 7233, loss = 0.00302482
Iteration 7234, loss = 0.00302410
Iteration 7235, loss = 0.00302349
Iteration 7236, loss = 0.00302289
Iteration 7237, loss = 0.00302235
Iteration 7238, loss = 0.00302183
Iteration 7239, loss = 0.00302126
Iteration 7240, loss = 0.00302061
Iteration 7241, loss = 0.00302020
Iteration 7242, loss = 0.00301957
Iteration 7243, loss = 0.00301922
Iteration 7244, loss = 0.00301892
Iteration 7245, loss = 0.00301814
Iteration 7246, loss = 0.00301759
Iteration 7247, loss = 0.00301715
Iteration 7248, loss = 0.00301656
Iteration 7249, loss = 0.00301617
Iteration 7250, loss = 0.00301561
Iteration 7251, loss = 0.00301499
Iteration 7252, loss = 0.00301445
Iteration 7253, loss = 0.00301403
Iteration 7254, loss = 0.00301342
Iteration 7255, loss = 0.00301281
Iteration 7256, loss = 0.00301217
Iteration 7257, loss = 0.00301175
Iteration 7258, loss = 0.00301148
Iteration 7259, loss = 0.00301084
Iteration 7260, loss = 0.00301054
Iteration 7261, loss = 0.00300989
Iteration 7262, loss = 0.00300936
Iteration 7263, loss = 0.00300869
Iteration 7264, loss = 0.00300806
Iteration 7265, loss = 0.00300761
Iteration 7266, loss = 0.00300705
Iteration 7267, loss = 0.00300653
Iteration 7268, loss = 0.00300601
Iteration 7269, loss = 0.00300542
Iteration 7270, loss = 0.00300490
Iteration 7271, loss = 0.00300443
Iteration 7272, loss = 0.00300405
Iteration 7273, loss = 0.00300364
Iteration 7274, loss = 0.00300303
Iteration 7275, loss = 0.00300231
Iteration 7276, loss = 0.00300195
Iteration 7277, loss = 0.00300150
Iteration 7278, loss = 0.00300078
Iteration 7279, loss = 0.00300031
Iteration 7280, loss = 0.00299961
Iteration 7281, loss = 0.00299904
Iteration 7282, loss = 0.00299839
Iteration 7283, loss = 0.00299796
Iteration 7284, loss = 0.00299726
Iteration 7285, loss = 0.00299661
Iteration 7286, loss = 0.00299595
Iteration 7287, loss = 0.00299532
Iteration 7288, loss = 0.00299480
Iteration 7289, loss = 0.00299462
Iteration 7290, loss = 0.00299392
Iteration 7291, loss = 0.00299365
Iteration 7292, loss = 0.00299337
Iteration 7293, loss = 0.00299233
Iteration 7294, loss = 0.00299177
Iteration 7295, loss = 0.00299105
Iteration 7296, loss = 0.00299055
Iteration 7297, loss = 0.00298989
Iteration 7298, loss = 0.00298921
Iteration 7299, loss = 0.00298860
Iteration 7300, loss = 0.00298797
Iteration 7301, loss = 0.00298744
Iteration 7302, loss = 0.00298705
Iteration 7303, loss = 0.00298641
Iteration 7304, loss = 0.00298615
Iteration 7305, loss = 0.00298528
Iteration 7306, loss = 0.00298472
Iteration 7307, loss = 0.00298411
Iteration 7308, loss = 0.00298347
Iteration 7309, loss = 0.00298315
Iteration 7310, loss = 0.00298257
Iteration 7311, loss = 0.00298216
Iteration 7312, loss = 0.00298142
Iteration 7313, loss = 0.00298071
Iteration 7314, loss = 0.00298019
Iteration 7315, loss = 0.00297950
Iteration 7316, loss = 0.00297891
Iteration 7317, loss = 0.00297840
Iteration 7318, loss = 0.00297756
Iteration 7319, loss = 0.00297687
Iteration 7320, loss = 0.00297621
Iteration 7321, loss = 0.00297573
Iteration 7322, loss = 0.00297547
Iteration 7323, loss = 0.00297473
Iteration 7324, loss = 0.00297421
Iteration 7325, loss = 0.00297370
Iteration 7326, loss = 0.00297335
Iteration 7327, loss = 0.00297277
Iteration 7328, loss = 0.00297206
Iteration 7329, loss = 0.00297155
Iteration 7330, loss = 0.00297100
Iteration 7331, loss = 0.00297038
Iteration 7332, loss = 0.00296979
Iteration 7333, loss = 0.00296926
Iteration 7334, loss = 0.00296850
Iteration 7335, loss = 0.00296793
Iteration 7336, loss = 0.00296758
Iteration 7337, loss = 0.00296676
Iteration 7338, loss = 0.00296612
Iteration 7339, loss = 0.00296557
Iteration 7340, loss = 0.00296517
Iteration 7341, loss = 0.00296454
Iteration 7342, loss = 0.00296380
Iteration 7343, loss = 0.00296327
Iteration 7344, loss = 0.00296284
Iteration 7345, loss = 0.00296233
Iteration 7346, loss = 0.00296166
Iteration 7347, loss = 0.00296128
Iteration 7348, loss = 0.00296066
Iteration 7349, loss = 0.00296016
Iteration 7350, loss = 0.00295964
Iteration 7351, loss = 0.00295919
Iteration 7352, loss = 0.00295869
Iteration 7353, loss = 0.00295824
Iteration 7354, loss = 0.00295778
Iteration 7355, loss = 0.00295730
Iteration 7356, loss = 0.00295675
Iteration 7357, loss = 0.00295628
Iteration 7358, loss = 0.00295570
Iteration 7359, loss = 0.00295521
Iteration 7360, loss = 0.00295470
Iteration 7361, loss = 0.00295418
Iteration 7362, loss = 0.00295370
Iteration 7363, loss = 0.00295330
Iteration 7364, loss = 0.00295270
Iteration 7365, loss = 0.00295217
Iteration 7366, loss = 0.00295157
Iteration 7367, loss = 0.00295104
Iteration 7368, loss = 0.00295039
Iteration 7369, loss = 0.00295000
Iteration 7370, loss = 0.00294941
Iteration 7371, loss = 0.00294898
Iteration 7372, loss = 0.00294828
Iteration 7373, loss = 0.00294798
Iteration 7374, loss = 0.00294719
Iteration 7375, loss = 0.00294671
Iteration 7376, loss = 0.00294618
Iteration 7377, loss = 0.00294568
Iteration 7378, loss = 0.00294512
Iteration 7379, loss = 0.00294491
Iteration 7380, loss = 0.00294418
Iteration 7381, loss = 0.00294350
Iteration 7382, loss = 0.00294302
Iteration 7383, loss = 0.00294247
Iteration 7384, loss = 0.00294194
Iteration 7385, loss = 0.00294141
Iteration 7386, loss = 0.00294093
Iteration 7387, loss = 0.00294042
Iteration 7388, loss = 0.00293981
Iteration 7389, loss = 0.00293938
Iteration 7390, loss = 0.00293876
Iteration 7391, loss = 0.00293830
Iteration 7392, loss = 0.00293795
Iteration 7393, loss = 0.00293736
Iteration 7394, loss = 0.00293694
Iteration 7395, loss = 0.00293628
Iteration 7396, loss = 0.00293583
Iteration 7397, loss = 0.00293528
Iteration 7398, loss = 0.00293471
Iteration 7399, loss = 0.00293426
Iteration 7400, loss = 0.00293366
Iteration 7401, loss = 0.00293314
Iteration 7402, loss = 0.00293269
Iteration 7403, loss = 0.00293207
Iteration 7404, loss = 0.00293152
Iteration 7405, loss = 0.00293101
Iteration 7406, loss = 0.00293047
Iteration 7407, loss = 0.00293012
Iteration 7408, loss = 0.00292955
Iteration 7409, loss = 0.00292891
Iteration 7410, loss = 0.00292820
Iteration 7411, loss = 0.00292831
Iteration 7412, loss = 0.00292730
Iteration 7413, loss = 0.00292663
Iteration 7414, loss = 0.00292624
Iteration 7415, loss = 0.00292545
Iteration 7416, loss = 0.00292493
Iteration 7417, loss = 0.00292436
Iteration 7418, loss = 0.00292376
Iteration 7419, loss = 0.00292308
Iteration 7420, loss = 0.00292244
Iteration 7421, loss = 0.00292186
Iteration 7422, loss = 0.00292166
Iteration 7423, loss = 0.00292083
Iteration 7424, loss = 0.00292045
Iteration 7425, loss = 0.00291976
Iteration 7426, loss = 0.00291922
Iteration 7427, loss = 0.00291861
Iteration 7428, loss = 0.00291808
Iteration 7429, loss = 0.00291752
Iteration 7430, loss = 0.00291706
Iteration 7431, loss = 0.00291632
Iteration 7432, loss = 0.00291573
Iteration 7433, loss = 0.00291507
Iteration 7434, loss = 0.00291445
Iteration 7435, loss = 0.00291410
Iteration 7436, loss = 0.00291344
Iteration 7437, loss = 0.00291296
Iteration 7438, loss = 0.00291238
Iteration 7439, loss = 0.00291182
Iteration 7440, loss = 0.00291151
Iteration 7441, loss = 0.00291075
Iteration 7442, loss = 0.00291026
Iteration 7443, loss = 0.00290976
Iteration 7444, loss = 0.00290919
Iteration 7445, loss = 0.00290868
Iteration 7446, loss = 0.00290816
Iteration 7447, loss = 0.00290769
Iteration 7448, loss = 0.00290720
Iteration 7449, loss = 0.00290672
Iteration 7450, loss = 0.00290631
Iteration 7451, loss = 0.00290587
Iteration 7452, loss = 0.00290547
Iteration 7453, loss = 0.00290496
Iteration 7454, loss = 0.00290466
Iteration 7455, loss = 0.00290423
Iteration 7456, loss = 0.00290368
Iteration 7457, loss = 0.00290312
Iteration 7458, loss = 0.00290275
Iteration 7459, loss = 0.00290224
Iteration 7460, loss = 0.00290166
Iteration 7461, loss = 0.00290128
Iteration 7462, loss = 0.00290077
Iteration 7463, loss = 0.00290014
Iteration 7464, loss = 0.00289963
Iteration 7465, loss = 0.00289906
Iteration 7466, loss = 0.00289871
Iteration 7467, loss = 0.00289806
Iteration 7468, loss = 0.00289764
Iteration 7469, loss = 0.00289700
Iteration 7470, loss = 0.00289646
Iteration 7471, loss = 0.00289615
Iteration 7472, loss = 0.00289546
Iteration 7473, loss = 0.00289493
Iteration 7474, loss = 0.00289440
Iteration 7475, loss = 0.00289396
Iteration 7476, loss = 0.00289343
Iteration 7477, loss = 0.00289316
Iteration 7478, loss = 0.00289255
Iteration 7479, loss = 0.00289213
Iteration 7480, loss = 0.00289154
Iteration 7481, loss = 0.00289104
Iteration 7482, loss = 0.00289048
Iteration 7483, loss = 0.00289020
Iteration 7484, loss = 0.00288961
Iteration 7485, loss = 0.00288909
Iteration 7486, loss = 0.00288876
Iteration 7487, loss = 0.00288815
Iteration 7488, loss = 0.00288769
Iteration 7489, loss = 0.00288717
Iteration 7490, loss = 0.00288678
Iteration 7491, loss = 0.00288621
Iteration 7492, loss = 0.00288574
Iteration 7493, loss = 0.00288527
Iteration 7494, loss = 0.00288472
Iteration 7495, loss = 0.00288437
Iteration 7496, loss = 0.00288382
Iteration 7497, loss = 0.00288353
Iteration 7498, loss = 0.00288313
Iteration 7499, loss = 0.00288247
Iteration 7500, loss = 0.00288204
Iteration 7501, loss = 0.00288152
Iteration 7502, loss = 0.00288110
Iteration 7503, loss = 0.00288053
Iteration 7504, loss = 0.00287994
Iteration 7505, loss = 0.00287945
Iteration 7506, loss = 0.00287896
Iteration 7507, loss = 0.00287837
Iteration 7508, loss = 0.00287790
Iteration 7509, loss = 0.00287732
Iteration 7510, loss = 0.00287671
Iteration 7511, loss = 0.00287628
Iteration 7512, loss = 0.00287570
Iteration 7513, loss = 0.00287514
Iteration 7514, loss = 0.00287456
Iteration 7515, loss = 0.00287416
Iteration 7516, loss = 0.00287363
Iteration 7517, loss = 0.00287325
Iteration 7518, loss = 0.00287261
Iteration 7519, loss = 0.00287211
Iteration 7520, loss = 0.00287163
Iteration 7521, loss = 0.00287119
Iteration 7522, loss = 0.00287080
Iteration 7523, loss = 0.00287031
Iteration 7524, loss = 0.00286977
Iteration 7525, loss = 0.00286928
Iteration 7526, loss = 0.00286886
Iteration 7527, loss = 0.00286836
Iteration 7528, loss = 0.00286785
Iteration 7529, loss = 0.00286745
Iteration 7530, loss = 0.00286690
Iteration 7531, loss = 0.00286652
Iteration 7532, loss = 0.00286598
Iteration 7533, loss = 0.00286550
Iteration 7534, loss = 0.00286509
Iteration 7535, loss = 0.00286460
Iteration 7536, loss = 0.00286404
Iteration 7537, loss = 0.00286337
Iteration 7538, loss = 0.00286283
Iteration 7539, loss = 0.00286234
Iteration 7540, loss = 0.00286170
Iteration 7541, loss = 0.00286118
Iteration 7542, loss = 0.00286064
Iteration 7543, loss = 0.00286042
Iteration 7544, loss = 0.00285985
Iteration 7545, loss = 0.00285944
Iteration 7546, loss = 0.00285921
Iteration 7547, loss = 0.00285876
Iteration 7548, loss = 0.00285814
Iteration 7549, loss = 0.00285754
Iteration 7550, loss = 0.00285703
Iteration 7551, loss = 0.00285652
Iteration 7552, loss = 0.00285602
Iteration 7553, loss = 0.00285552
Iteration 7554, loss = 0.00285517
Iteration 7555, loss = 0.00285460
Iteration 7556, loss = 0.00285417
Iteration 7557, loss = 0.00285364
Iteration 7558, loss = 0.00285306
Iteration 7559, loss = 0.00285254
Iteration 7560, loss = 0.00285201
Iteration 7561, loss = 0.00285165
Iteration 7562, loss = 0.00285112
Iteration 7563, loss = 0.00285057
Iteration 7564, loss = 0.00285008
Iteration 7565, loss = 0.00284965
Iteration 7566, loss = 0.00284919
Iteration 7567, loss = 0.00284878
Iteration 7568, loss = 0.00284820
Iteration 7569, loss = 0.00284772
Iteration 7570, loss = 0.00284721
Iteration 7571, loss = 0.00284669
Iteration 7572, loss = 0.00284623
Iteration 7573, loss = 0.00284573
Iteration 7574, loss = 0.00284532
Iteration 7575, loss = 0.00284484
Iteration 7576, loss = 0.00284429
Iteration 7577, loss = 0.00284376
Iteration 7578, loss = 0.00284324
Iteration 7579, loss = 0.00284282
Iteration 7580, loss = 0.00284226
Iteration 7581, loss = 0.00284162
Iteration 7582, loss = 0.00284111
Iteration 7583, loss = 0.00284058
Iteration 7584, loss = 0.00284013
Iteration 7585, loss = 0.00283946
Iteration 7586, loss = 0.00283887
Iteration 7587, loss = 0.00283847
Iteration 7588, loss = 0.00283800
Iteration 7589, loss = 0.00283726
Iteration 7590, loss = 0.00283679
Iteration 7591, loss = 0.00283635
Iteration 7592, loss = 0.00283573
Iteration 7593, loss = 0.00283513
Iteration 7594, loss = 0.00283461
Iteration 7595, loss = 0.00283415
Iteration 7596, loss = 0.00283357
Iteration 7597, loss = 0.00283326
Iteration 7598, loss = 0.00283257
Iteration 7599, loss = 0.00283216
Iteration 7600, loss = 0.00283161
Iteration 7601, loss = 0.00283118
Iteration 7602, loss = 0.00283063
Iteration 7603, loss = 0.00283022
Iteration 7604, loss = 0.00282968
Iteration 7605, loss = 0.00282924
Iteration 7606, loss = 0.00282867
Iteration 7607, loss = 0.00282826
Iteration 7608, loss = 0.00282777
Iteration 7609, loss = 0.00282729
Iteration 7610, loss = 0.00282691
Iteration 7611, loss = 0.00282638
Iteration 7612, loss = 0.00282580
Iteration 7613, loss = 0.00282545
Iteration 7614, loss = 0.00282487
Iteration 7615, loss = 0.00282451
Iteration 7616, loss = 0.00282391
Iteration 7617, loss = 0.00282342
Iteration 7618, loss = 0.00282292
Iteration 7619, loss = 0.00282249
Iteration 7620, loss = 0.00282207
Iteration 7621, loss = 0.00282188
Iteration 7622, loss = 0.00282117
Iteration 7623, loss = 0.00282065
Iteration 7624, loss = 0.00282022
Iteration 7625, loss = 0.00282018
Iteration 7626, loss = 0.00281933
Iteration 7627, loss = 0.00281884
Iteration 7628, loss = 0.00281833
Iteration 7629, loss = 0.00281785
Iteration 7630, loss = 0.00281742
Iteration 7631, loss = 0.00281699
Iteration 7632, loss = 0.00281628
Iteration 7633, loss = 0.00281560
Iteration 7634, loss = 0.00281511
Iteration 7635, loss = 0.00281459
Iteration 7636, loss = 0.00281419
Iteration 7637, loss = 0.00281354
Iteration 7638, loss = 0.00281314
Iteration 7639, loss = 0.00281248
Iteration 7640, loss = 0.00281193
Iteration 7641, loss = 0.00281153
Iteration 7642, loss = 0.00281105
Iteration 7643, loss = 0.00281036
Iteration 7644, loss = 0.00281001
Iteration 7645, loss = 0.00280943
Iteration 7646, loss = 0.00280882
Iteration 7647, loss = 0.00280828
Iteration 7648, loss = 0.00280769
Iteration 7649, loss = 0.00280722
Iteration 7650, loss = 0.00280665
Iteration 7651, loss = 0.00280623
Iteration 7652, loss = 0.00280561
Iteration 7653, loss = 0.00280513
Iteration 7654, loss = 0.00280469
Iteration 7655, loss = 0.00280420
Iteration 7656, loss = 0.00280374
Iteration 7657, loss = 0.00280317
Iteration 7658, loss = 0.00280278
Iteration 7659, loss = 0.00280218
Iteration 7660, loss = 0.00280180
Iteration 7661, loss = 0.00280144
Iteration 7662, loss = 0.00280080
Iteration 7663, loss = 0.00280035
Iteration 7664, loss = 0.00279980
Iteration 7665, loss = 0.00279985
Iteration 7666, loss = 0.00279900
Iteration 7667, loss = 0.00279844
Iteration 7668, loss = 0.00279794
Iteration 7669, loss = 0.00279748
Iteration 7670, loss = 0.00279695
Iteration 7671, loss = 0.00279639
Iteration 7672, loss = 0.00279592
Iteration 7673, loss = 0.00279538
Iteration 7674, loss = 0.00279486
Iteration 7675, loss = 0.00279434
Iteration 7676, loss = 0.00279385
Iteration 7677, loss = 0.00279343
Iteration 7678, loss = 0.00279290
Iteration 7679, loss = 0.00279257
Iteration 7680, loss = 0.00279210
Iteration 7681, loss = 0.00279154
Iteration 7682, loss = 0.00279096
Iteration 7683, loss = 0.00279051
Iteration 7684, loss = 0.00279001
Iteration 7685, loss = 0.00278955
Iteration 7686, loss = 0.00278913
Iteration 7687, loss = 0.00278866
Iteration 7688, loss = 0.00278819
Iteration 7689, loss = 0.00278769
Iteration 7690, loss = 0.00278729
Iteration 7691, loss = 0.00278681
Iteration 7692, loss = 0.00278639
Iteration 7693, loss = 0.00278591
Iteration 7694, loss = 0.00278551
Iteration 7695, loss = 0.00278505
Iteration 7696, loss = 0.00278466
Iteration 7697, loss = 0.00278423
Iteration 7698, loss = 0.00278382
Iteration 7699, loss = 0.00278355
Iteration 7700, loss = 0.00278306
Iteration 7701, loss = 0.00278269
Iteration 7702, loss = 0.00278231
Iteration 7703, loss = 0.00278188
Iteration 7704, loss = 0.00278124
Iteration 7705, loss = 0.00278083
Iteration 7706, loss = 0.00278032
Iteration 7707, loss = 0.00277987
Iteration 7708, loss = 0.00278006
Iteration 7709, loss = 0.00277904
Iteration 7710, loss = 0.00277859
Iteration 7711, loss = 0.00277807
Iteration 7712, loss = 0.00277768
Iteration 7713, loss = 0.00277707
Iteration 7714, loss = 0.00277661
Iteration 7715, loss = 0.00277613
Iteration 7716, loss = 0.00277559
Iteration 7717, loss = 0.00277517
Iteration 7718, loss = 0.00277469
Iteration 7719, loss = 0.00277419
Iteration 7720, loss = 0.00277387
Iteration 7721, loss = 0.00277369
Iteration 7722, loss = 0.00277286
Iteration 7723, loss = 0.00277237
Iteration 7724, loss = 0.00277197
Iteration 7725, loss = 0.00277137
Iteration 7726, loss = 0.00277090
Iteration 7727, loss = 0.00277041
Iteration 7728, loss = 0.00276975
Iteration 7729, loss = 0.00276953
Iteration 7730, loss = 0.00276873
Iteration 7731, loss = 0.00276811
Iteration 7732, loss = 0.00276769
Iteration 7733, loss = 0.00276708
Iteration 7734, loss = 0.00276662
Iteration 7735, loss = 0.00276619
Iteration 7736, loss = 0.00276571
Iteration 7737, loss = 0.00276540
Iteration 7738, loss = 0.00276496
Iteration 7739, loss = 0.00276456
Iteration 7740, loss = 0.00276419
Iteration 7741, loss = 0.00276382
Iteration 7742, loss = 0.00276362
Iteration 7743, loss = 0.00276299
Iteration 7744, loss = 0.00276274
Iteration 7745, loss = 0.00276193
Iteration 7746, loss = 0.00276151
Iteration 7747, loss = 0.00276112
Iteration 7748, loss = 0.00276055
Iteration 7749, loss = 0.00276000
Iteration 7750, loss = 0.00275941
Iteration 7751, loss = 0.00275892
Iteration 7752, loss = 0.00275895
Iteration 7753, loss = 0.00275797
Iteration 7754, loss = 0.00275747
Iteration 7755, loss = 0.00275713
Iteration 7756, loss = 0.00275671
Iteration 7757, loss = 0.00275615
Iteration 7758, loss = 0.00275567
Iteration 7759, loss = 0.00275541
Iteration 7760, loss = 0.00275479
Iteration 7761, loss = 0.00275428
Iteration 7762, loss = 0.00275372
Iteration 7763, loss = 0.00275310
Iteration 7764, loss = 0.00275276
Iteration 7765, loss = 0.00275206
Iteration 7766, loss = 0.00275151
Iteration 7767, loss = 0.00275116
Iteration 7768, loss = 0.00275056
Iteration 7769, loss = 0.00275009
Iteration 7770, loss = 0.00274963
Iteration 7771, loss = 0.00274910
Iteration 7772, loss = 0.00274853
Iteration 7773, loss = 0.00274797
Iteration 7774, loss = 0.00274740
Iteration 7775, loss = 0.00274722
Iteration 7776, loss = 0.00274654
Iteration 7777, loss = 0.00274635
Iteration 7778, loss = 0.00274552
Iteration 7779, loss = 0.00274505
Iteration 7780, loss = 0.00274469
Iteration 7781, loss = 0.00274418
Iteration 7782, loss = 0.00274369
Iteration 7783, loss = 0.00274320
Iteration 7784, loss = 0.00274290
Iteration 7785, loss = 0.00274222
Iteration 7786, loss = 0.00274169
Iteration 7787, loss = 0.00274112
Iteration 7788, loss = 0.00274069
Iteration 7789, loss = 0.00274016
Iteration 7790, loss = 0.00273959
Iteration 7791, loss = 0.00273900
Iteration 7792, loss = 0.00273865
Iteration 7793, loss = 0.00273813
Iteration 7794, loss = 0.00273778
Iteration 7795, loss = 0.00273716
Iteration 7796, loss = 0.00273694
Iteration 7797, loss = 0.00273617
Iteration 7798, loss = 0.00273571
Iteration 7799, loss = 0.00273521
Iteration 7800, loss = 0.00273477
Iteration 7801, loss = 0.00273435
Iteration 7802, loss = 0.00273402
Iteration 7803, loss = 0.00273329
Iteration 7804, loss = 0.00273304
Iteration 7805, loss = 0.00273242
Iteration 7806, loss = 0.00273196
Iteration 7807, loss = 0.00273170
Iteration 7808, loss = 0.00273105
Iteration 7809, loss = 0.00273069
Iteration 7810, loss = 0.00273022
Iteration 7811, loss = 0.00272972
Iteration 7812, loss = 0.00272934
Iteration 7813, loss = 0.00272899
Iteration 7814, loss = 0.00272845
Iteration 7815, loss = 0.00272796
Iteration 7816, loss = 0.00272762
Iteration 7817, loss = 0.00272713
Iteration 7818, loss = 0.00272676
Iteration 7819, loss = 0.00272624
Iteration 7820, loss = 0.00272589
Iteration 7821, loss = 0.00272542
Iteration 7822, loss = 0.00272483
Iteration 7823, loss = 0.00272430
Iteration 7824, loss = 0.00272385
Iteration 7825, loss = 0.00272346
Iteration 7826, loss = 0.00272284
Iteration 7827, loss = 0.00272233
Iteration 7828, loss = 0.00272191
Iteration 7829, loss = 0.00272149
Iteration 7830, loss = 0.00272100
Iteration 7831, loss = 0.00272053
Iteration 7832, loss = 0.00272006
Iteration 7833, loss = 0.00271978
Iteration 7834, loss = 0.00271916
Iteration 7835, loss = 0.00271902
Iteration 7836, loss = 0.00271822
Iteration 7837, loss = 0.00271773
Iteration 7838, loss = 0.00271716
Iteration 7839, loss = 0.00271725
Iteration 7840, loss = 0.00271649
Iteration 7841, loss = 0.00271579
Iteration 7842, loss = 0.00271529
Iteration 7843, loss = 0.00271490
Iteration 7844, loss = 0.00271428
Iteration 7845, loss = 0.00271366
Iteration 7846, loss = 0.00271314
Iteration 7847, loss = 0.00271268
Iteration 7848, loss = 0.00271220
Iteration 7849, loss = 0.00271159
Iteration 7850, loss = 0.00271139
Iteration 7851, loss = 0.00271067
Iteration 7852, loss = 0.00271015
Iteration 7853, loss = 0.00270952
Iteration 7854, loss = 0.00270935
Iteration 7855, loss = 0.00270876
Iteration 7856, loss = 0.00270820
Iteration 7857, loss = 0.00270814
Iteration 7858, loss = 0.00270739
Iteration 7859, loss = 0.00270696
Iteration 7860, loss = 0.00270642
Iteration 7861, loss = 0.00270604
Iteration 7862, loss = 0.00270562
Iteration 7863, loss = 0.00270518
Iteration 7864, loss = 0.00270484
Iteration 7865, loss = 0.00270430
Iteration 7866, loss = 0.00270387
Iteration 7867, loss = 0.00270345
Iteration 7868, loss = 0.00270309
Iteration 7869, loss = 0.00270261
Iteration 7870, loss = 0.00270211
Iteration 7871, loss = 0.00270169
Iteration 7872, loss = 0.00270142
Iteration 7873, loss = 0.00270075
Iteration 7874, loss = 0.00270040
Iteration 7875, loss = 0.00270005
Iteration 7876, loss = 0.00269941
Iteration 7877, loss = 0.00269898
Iteration 7878, loss = 0.00269855
Iteration 7879, loss = 0.00269814
Iteration 7880, loss = 0.00269764
Iteration 7881, loss = 0.00269720
Iteration 7882, loss = 0.00269695
Iteration 7883, loss = 0.00269625
Iteration 7884, loss = 0.00269573
Iteration 7885, loss = 0.00269521
Iteration 7886, loss = 0.00269474
Iteration 7887, loss = 0.00269428
Iteration 7888, loss = 0.00269393
Iteration 7889, loss = 0.00269335
Iteration 7890, loss = 0.00269287
Iteration 7891, loss = 0.00269253
Iteration 7892, loss = 0.00269217
Iteration 7893, loss = 0.00269159
Iteration 7894, loss = 0.00269101
Iteration 7895, loss = 0.00269056
Iteration 7896, loss = 0.00269011
Iteration 7897, loss = 0.00268959
Iteration 7898, loss = 0.00268916
Iteration 7899, loss = 0.00268874
Iteration 7900, loss = 0.00268832
Iteration 7901, loss = 0.00268794
Iteration 7902, loss = 0.00268763
Iteration 7903, loss = 0.00268720
Iteration 7904, loss = 0.00268671
Iteration 7905, loss = 0.00268627
Iteration 7906, loss = 0.00268579
Iteration 7907, loss = 0.00268574
Iteration 7908, loss = 0.00268492
Iteration 7909, loss = 0.00268453
Iteration 7910, loss = 0.00268418
Iteration 7911, loss = 0.00268364
Iteration 7912, loss = 0.00268331
Iteration 7913, loss = 0.00268276
Iteration 7914, loss = 0.00268233
Iteration 7915, loss = 0.00268225
Iteration 7916, loss = 0.00268129
Iteration 7917, loss = 0.00268093
Iteration 7918, loss = 0.00268026
Iteration 7919, loss = 0.00267976
Iteration 7920, loss = 0.00267943
Iteration 7921, loss = 0.00267882
Iteration 7922, loss = 0.00267827
Iteration 7923, loss = 0.00267832
Iteration 7924, loss = 0.00267744
Iteration 7925, loss = 0.00267698
Iteration 7926, loss = 0.00267681
Iteration 7927, loss = 0.00267616
Iteration 7928, loss = 0.00267587
Iteration 7929, loss = 0.00267519
Iteration 7930, loss = 0.00267468
Iteration 7931, loss = 0.00267426
Iteration 7932, loss = 0.00267372
Iteration 7933, loss = 0.00267345
Iteration 7934, loss = 0.00267282
Iteration 7935, loss = 0.00267233
Iteration 7936, loss = 0.00267193
Iteration 7937, loss = 0.00267146
Iteration 7938, loss = 0.00267112
Iteration 7939, loss = 0.00267052
Iteration 7940, loss = 0.00267005
Iteration 7941, loss = 0.00266956
Iteration 7942, loss = 0.00266924
Iteration 7943, loss = 0.00266863
Iteration 7944, loss = 0.00266828
Iteration 7945, loss = 0.00266769
Iteration 7946, loss = 0.00266710
Iteration 7947, loss = 0.00266718
Iteration 7948, loss = 0.00266634
Iteration 7949, loss = 0.00266583
Iteration 7950, loss = 0.00266548
Iteration 7951, loss = 0.00266499
Iteration 7952, loss = 0.00266452
Iteration 7953, loss = 0.00266411
Iteration 7954, loss = 0.00266363
Iteration 7955, loss = 0.00266309
Iteration 7956, loss = 0.00266267
Iteration 7957, loss = 0.00266219
Iteration 7958, loss = 0.00266181
Iteration 7959, loss = 0.00266134
Iteration 7960, loss = 0.00266088
Iteration 7961, loss = 0.00266045
Iteration 7962, loss = 0.00266005
Iteration 7963, loss = 0.00265964
Iteration 7964, loss = 0.00265921
Iteration 7965, loss = 0.00265889
Iteration 7966, loss = 0.00265839
Iteration 7967, loss = 0.00265794
Iteration 7968, loss = 0.00265769
Iteration 7969, loss = 0.00265719
Iteration 7970, loss = 0.00265681
Iteration 7971, loss = 0.00265635
Iteration 7972, loss = 0.00265588
Iteration 7973, loss = 0.00265566
Iteration 7974, loss = 0.00265509
Iteration 7975, loss = 0.00265466
Iteration 7976, loss = 0.00265421
Iteration 7977, loss = 0.00265377
Iteration 7978, loss = 0.00265361
Iteration 7979, loss = 0.00265285
Iteration 7980, loss = 0.00265245
Iteration 7981, loss = 0.00265199
Iteration 7982, loss = 0.00265140
Iteration 7983, loss = 0.00265090
Iteration 7984, loss = 0.00265053
Iteration 7985, loss = 0.00265012
Iteration 7986, loss = 0.00264962
Iteration 7987, loss = 0.00264933
Iteration 7988, loss = 0.00264880
Iteration 7989, loss = 0.00264842
Iteration 7990, loss = 0.00264799
Iteration 7991, loss = 0.00264756
Iteration 7992, loss = 0.00264719
Iteration 7993, loss = 0.00264674
Iteration 7994, loss = 0.00264636
Iteration 7995, loss = 0.00264601
Iteration 7996, loss = 0.00264554
Iteration 7997, loss = 0.00264508
Iteration 7998, loss = 0.00264471
Iteration 7999, loss = 0.00264433
Iteration 8000, loss = 0.00264387
Iteration 1, loss = 1.03405397
Iteration 2, loss = 1.03092738
Iteration 3, loss = 1.02591808
Iteration 4, loss = 1.01959973
Iteration 5, loss = 1.01228054
Iteration 6, loss = 1.00428423
Iteration 7, loss = 0.99573087
Iteration 8, loss = 0.98695789
Iteration 9, loss = 0.97789539
Iteration 10, loss = 0.96867451
Iteration 11, loss = 0.95939687
Iteration 12, loss = 0.95011569
Iteration 13, loss = 0.94087278
Iteration 14, loss = 0.93181132
Iteration 15, loss = 0.92284435
Iteration 16, loss = 0.91413243
Iteration 17, loss = 0.90524882
Iteration 18, loss = 0.89702600
Iteration 19, loss = 0.88875335
Iteration 20, loss = 0.88088577
Iteration 21, loss = 0.87304847
Iteration 22, loss = 0.86549587
Iteration 23, loss = 0.85819801
Iteration 24, loss = 0.85102521
Iteration 25, loss = 0.84406787
Iteration 26, loss = 0.83720036
Iteration 27, loss = 0.83055886
Iteration 28, loss = 0.82407992
Iteration 29, loss = 0.81800124
Iteration 30, loss = 0.81198423
Iteration 31, loss = 0.80605609
Iteration 32, loss = 0.80044078
Iteration 33, loss = 0.79490537
Iteration 34, loss = 0.78957087
Iteration 35, loss = 0.78434741
Iteration 36, loss = 0.77910320
Iteration 37, loss = 0.77430973
Iteration 38, loss = 0.76941754
Iteration 39, loss = 0.76470232
Iteration 40, loss = 0.76028809
Iteration 41, loss = 0.75593366
Iteration 42, loss = 0.75168476
Iteration 43, loss = 0.74767097
Iteration 44, loss = 0.74371771
Iteration 45, loss = 0.73986400
Iteration 46, loss = 0.73615912
Iteration 47, loss = 0.73241831
Iteration 48, loss = 0.72878250
Iteration 49, loss = 0.72516339
Iteration 50, loss = 0.72159567
Iteration 51, loss = 0.71816732
Iteration 52, loss = 0.71467540
Iteration 53, loss = 0.71132474
Iteration 54, loss = 0.70789506
Iteration 55, loss = 0.70460342
Iteration 56, loss = 0.70128541
Iteration 57, loss = 0.69791647
Iteration 58, loss = 0.69467571
Iteration 59, loss = 0.69143790
Iteration 60, loss = 0.68815847
Iteration 61, loss = 0.68491364
Iteration 62, loss = 0.68188443
Iteration 63, loss = 0.67881353
Iteration 64, loss = 0.67570579
Iteration 65, loss = 0.67284629
Iteration 66, loss = 0.66988260
Iteration 67, loss = 0.66694398
Iteration 68, loss = 0.66415956
Iteration 69, loss = 0.66120044
Iteration 70, loss = 0.65844231
Iteration 71, loss = 0.65552965
Iteration 72, loss = 0.65278005
Iteration 73, loss = 0.64993692
Iteration 74, loss = 0.64723615
Iteration 75, loss = 0.64445022
Iteration 76, loss = 0.64177421
Iteration 77, loss = 0.63908470
Iteration 78, loss = 0.63642463
Iteration 79, loss = 0.63377489
Iteration 80, loss = 0.63115308
Iteration 81, loss = 0.62854508
Iteration 82, loss = 0.62594972
Iteration 83, loss = 0.62339925
Iteration 84, loss = 0.62076854
Iteration 85, loss = 0.61827916
Iteration 86, loss = 0.61567494
Iteration 87, loss = 0.61313996
Iteration 88, loss = 0.61059889
Iteration 89, loss = 0.60808783
Iteration 90, loss = 0.60553090
Iteration 91, loss = 0.60301449
Iteration 92, loss = 0.60053106
Iteration 93, loss = 0.59804460
Iteration 94, loss = 0.59553680
Iteration 95, loss = 0.59307131
Iteration 96, loss = 0.59062755
Iteration 97, loss = 0.58816346
Iteration 98, loss = 0.58572524
Iteration 99, loss = 0.58328052
Iteration 100, loss = 0.58087042
Iteration 101, loss = 0.57850968
Iteration 102, loss = 0.57610532
Iteration 103, loss = 0.57372262
Iteration 104, loss = 0.57141257
Iteration 105, loss = 0.56903580
Iteration 106, loss = 0.56671339
Iteration 107, loss = 0.56438730
Iteration 108, loss = 0.56213872
Iteration 109, loss = 0.55982037
Iteration 110, loss = 0.55754204
Iteration 111, loss = 0.55528064
Iteration 112, loss = 0.55299935
Iteration 113, loss = 0.55080818
Iteration 114, loss = 0.54847670
Iteration 115, loss = 0.54622981
Iteration 116, loss = 0.54399534
Iteration 117, loss = 0.54169152
Iteration 118, loss = 0.53948323
Iteration 119, loss = 0.53717530
Iteration 120, loss = 0.53492646
Iteration 121, loss = 0.53269987
Iteration 122, loss = 0.53049493
Iteration 123, loss = 0.52827072
Iteration 124, loss = 0.52606128
Iteration 125, loss = 0.52388394
Iteration 126, loss = 0.52172404
Iteration 127, loss = 0.51955974
Iteration 128, loss = 0.51743562
Iteration 129, loss = 0.51525857
Iteration 130, loss = 0.51316093
Iteration 131, loss = 0.51102793
Iteration 132, loss = 0.50892044
Iteration 133, loss = 0.50689137
Iteration 134, loss = 0.50483608
Iteration 135, loss = 0.50279278
Iteration 136, loss = 0.50078395
Iteration 137, loss = 0.49875647
Iteration 138, loss = 0.49671074
Iteration 139, loss = 0.49469800
Iteration 140, loss = 0.49263871
Iteration 141, loss = 0.49060421
Iteration 142, loss = 0.48856933
Iteration 143, loss = 0.48653678
Iteration 144, loss = 0.48449476
Iteration 145, loss = 0.48245228
Iteration 146, loss = 0.48042363
Iteration 147, loss = 0.47838130
Iteration 148, loss = 0.47635817
Iteration 149, loss = 0.47427773
Iteration 150, loss = 0.47224756
Iteration 151, loss = 0.47020233
Iteration 152, loss = 0.46813479
Iteration 153, loss = 0.46608711
Iteration 154, loss = 0.46404807
Iteration 155, loss = 0.46205430
Iteration 156, loss = 0.45999077
Iteration 157, loss = 0.45797582
Iteration 158, loss = 0.45594168
Iteration 159, loss = 0.45389570
Iteration 160, loss = 0.45180340
Iteration 161, loss = 0.44975410
Iteration 162, loss = 0.44766173
Iteration 163, loss = 0.44557295
Iteration 164, loss = 0.44349921
Iteration 165, loss = 0.44142720
Iteration 166, loss = 0.43933640
Iteration 167, loss = 0.43727408
Iteration 168, loss = 0.43522230
Iteration 169, loss = 0.43314412
Iteration 170, loss = 0.43111123
Iteration 171, loss = 0.42904540
Iteration 172, loss = 0.42700140
Iteration 173, loss = 0.42496326
Iteration 174, loss = 0.42293415
Iteration 175, loss = 0.42087769
Iteration 176, loss = 0.41887883
Iteration 177, loss = 0.41684585
Iteration 178, loss = 0.41482723
Iteration 179, loss = 0.41280001
Iteration 180, loss = 0.41080414
Iteration 181, loss = 0.40872956
Iteration 182, loss = 0.40671609
Iteration 183, loss = 0.40470108
Iteration 184, loss = 0.40262478
Iteration 185, loss = 0.40059082
Iteration 186, loss = 0.39856658
Iteration 187, loss = 0.39650609
Iteration 188, loss = 0.39448363
Iteration 189, loss = 0.39249492
Iteration 190, loss = 0.39046370
Iteration 191, loss = 0.38849468
Iteration 192, loss = 0.38652500
Iteration 193, loss = 0.38455140
Iteration 194, loss = 0.38258329
Iteration 195, loss = 0.38065995
Iteration 196, loss = 0.37865975
Iteration 197, loss = 0.37672865
Iteration 198, loss = 0.37476495
Iteration 199, loss = 0.37282087
Iteration 200, loss = 0.37086516
Iteration 201, loss = 0.36893205
Iteration 202, loss = 0.36700585
Iteration 203, loss = 0.36508267
Iteration 204, loss = 0.36316870
Iteration 205, loss = 0.36124677
Iteration 206, loss = 0.35935385
Iteration 207, loss = 0.35742259
Iteration 208, loss = 0.35550420
Iteration 209, loss = 0.35358020
Iteration 210, loss = 0.35164434
Iteration 211, loss = 0.34971443
Iteration 212, loss = 0.34775304
Iteration 213, loss = 0.34582219
Iteration 214, loss = 0.34386939
Iteration 215, loss = 0.34191437
Iteration 216, loss = 0.33996640
Iteration 217, loss = 0.33802419
Iteration 218, loss = 0.33609451
Iteration 219, loss = 0.33416051
Iteration 220, loss = 0.33224895
Iteration 221, loss = 0.33035791
Iteration 222, loss = 0.32846331
Iteration 223, loss = 0.32659385
Iteration 224, loss = 0.32470121
Iteration 225, loss = 0.32284696
Iteration 226, loss = 0.32096738
Iteration 227, loss = 0.31908744
Iteration 228, loss = 0.31721305
Iteration 229, loss = 0.31535078
Iteration 230, loss = 0.31347464
Iteration 231, loss = 0.31164907
Iteration 232, loss = 0.30979271
Iteration 233, loss = 0.30794889
Iteration 234, loss = 0.30613170
Iteration 235, loss = 0.30431949
Iteration 236, loss = 0.30250423
Iteration 237, loss = 0.30070142
Iteration 238, loss = 0.29891261
Iteration 239, loss = 0.29711866
Iteration 240, loss = 0.29532673
Iteration 241, loss = 0.29355068
Iteration 242, loss = 0.29178149
Iteration 243, loss = 0.28999882
Iteration 244, loss = 0.28823585
Iteration 245, loss = 0.28649069
Iteration 246, loss = 0.28473489
Iteration 247, loss = 0.28302894
Iteration 248, loss = 0.28129010
Iteration 249, loss = 0.27957907
Iteration 250, loss = 0.27791400
Iteration 251, loss = 0.27624425
Iteration 252, loss = 0.27457082
Iteration 253, loss = 0.27291878
Iteration 254, loss = 0.27128986
Iteration 255, loss = 0.26965518
Iteration 256, loss = 0.26804832
Iteration 257, loss = 0.26641579
Iteration 258, loss = 0.26482931
Iteration 259, loss = 0.26322967
Iteration 260, loss = 0.26164156
Iteration 261, loss = 0.26005230
Iteration 262, loss = 0.25849246
Iteration 263, loss = 0.25691914
Iteration 264, loss = 0.25535946
Iteration 265, loss = 0.25382460
Iteration 266, loss = 0.25229759
Iteration 267, loss = 0.25077102
Iteration 268, loss = 0.24926234
Iteration 269, loss = 0.24777145
Iteration 270, loss = 0.24629296
Iteration 271, loss = 0.24482194
Iteration 272, loss = 0.24338126
Iteration 273, loss = 0.24191999
Iteration 274, loss = 0.24049311
Iteration 275, loss = 0.23906547
Iteration 276, loss = 0.23765768
Iteration 277, loss = 0.23624638
Iteration 278, loss = 0.23485035
Iteration 279, loss = 0.23349154
Iteration 280, loss = 0.23210352
Iteration 281, loss = 0.23075539
Iteration 282, loss = 0.22939360
Iteration 283, loss = 0.22805448
Iteration 284, loss = 0.22671074
Iteration 285, loss = 0.22537633
Iteration 286, loss = 0.22405381
Iteration 287, loss = 0.22274027
Iteration 288, loss = 0.22143806
Iteration 289, loss = 0.22014117
Iteration 290, loss = 0.21884720
Iteration 291, loss = 0.21756733
Iteration 292, loss = 0.21630657
Iteration 293, loss = 0.21504027
Iteration 294, loss = 0.21378403
Iteration 295, loss = 0.21256513
Iteration 296, loss = 0.21132050
Iteration 297, loss = 0.21010739
Iteration 298, loss = 0.20887849
Iteration 299, loss = 0.20769052
Iteration 300, loss = 0.20648354
Iteration 301, loss = 0.20528327
Iteration 302, loss = 0.20409242
Iteration 303, loss = 0.20292811
Iteration 304, loss = 0.20175552
Iteration 305, loss = 0.20060457
Iteration 306, loss = 0.19946149
Iteration 307, loss = 0.19833169
Iteration 308, loss = 0.19720929
Iteration 309, loss = 0.19610200
Iteration 310, loss = 0.19500959
Iteration 311, loss = 0.19391812
Iteration 312, loss = 0.19284897
Iteration 313, loss = 0.19178033
Iteration 314, loss = 0.19071486
Iteration 315, loss = 0.18966367
Iteration 316, loss = 0.18861395
Iteration 317, loss = 0.18758322
Iteration 318, loss = 0.18654886
Iteration 319, loss = 0.18553334
Iteration 320, loss = 0.18451464
Iteration 321, loss = 0.18350591
Iteration 322, loss = 0.18251146
Iteration 323, loss = 0.18152682
Iteration 324, loss = 0.18054904
Iteration 325, loss = 0.17956625
Iteration 326, loss = 0.17860130
Iteration 327, loss = 0.17764945
Iteration 328, loss = 0.17669657
Iteration 329, loss = 0.17574730
Iteration 330, loss = 0.17481610
Iteration 331, loss = 0.17387712
Iteration 332, loss = 0.17295042
Iteration 333, loss = 0.17204492
Iteration 334, loss = 0.17113330
Iteration 335, loss = 0.17023307
Iteration 336, loss = 0.16934756
Iteration 337, loss = 0.16845087
Iteration 338, loss = 0.16756797
Iteration 339, loss = 0.16668639
Iteration 340, loss = 0.16580129
Iteration 341, loss = 0.16493048
Iteration 342, loss = 0.16405770
Iteration 343, loss = 0.16320911
Iteration 344, loss = 0.16234816
Iteration 345, loss = 0.16151105
Iteration 346, loss = 0.16067381
Iteration 347, loss = 0.15984141
Iteration 348, loss = 0.15901700
Iteration 349, loss = 0.15818349
Iteration 350, loss = 0.15736680
Iteration 351, loss = 0.15655317
Iteration 352, loss = 0.15574402
Iteration 353, loss = 0.15495790
Iteration 354, loss = 0.15416762
Iteration 355, loss = 0.15339319
Iteration 356, loss = 0.15263197
Iteration 357, loss = 0.15187687
Iteration 358, loss = 0.15112174
Iteration 359, loss = 0.15037899
Iteration 360, loss = 0.14964206
Iteration 361, loss = 0.14891444
Iteration 362, loss = 0.14818699
Iteration 363, loss = 0.14746599
Iteration 364, loss = 0.14674959
Iteration 365, loss = 0.14603955
Iteration 366, loss = 0.14532776
Iteration 367, loss = 0.14464045
Iteration 368, loss = 0.14394602
Iteration 369, loss = 0.14326250
Iteration 370, loss = 0.14258648
Iteration 371, loss = 0.14191854
Iteration 372, loss = 0.14125875
Iteration 373, loss = 0.14059625
Iteration 374, loss = 0.13993515
Iteration 375, loss = 0.13927957
Iteration 376, loss = 0.13863286
Iteration 377, loss = 0.13799045
Iteration 378, loss = 0.13734792
Iteration 379, loss = 0.13671213
Iteration 380, loss = 0.13608186
Iteration 381, loss = 0.13546114
Iteration 382, loss = 0.13484402
Iteration 383, loss = 0.13423170
Iteration 384, loss = 0.13361422
Iteration 385, loss = 0.13301401
Iteration 386, loss = 0.13241254
Iteration 387, loss = 0.13180832
Iteration 388, loss = 0.13120755
Iteration 389, loss = 0.13062180
Iteration 390, loss = 0.13003173
Iteration 391, loss = 0.12944887
Iteration 392, loss = 0.12887015
Iteration 393, loss = 0.12830118
Iteration 394, loss = 0.12773867
Iteration 395, loss = 0.12717176
Iteration 396, loss = 0.12662037
Iteration 397, loss = 0.12607474
Iteration 398, loss = 0.12552598
Iteration 399, loss = 0.12498531
Iteration 400, loss = 0.12444885
Iteration 401, loss = 0.12391258
Iteration 402, loss = 0.12338845
Iteration 403, loss = 0.12286275
Iteration 404, loss = 0.12234350
Iteration 405, loss = 0.12182690
Iteration 406, loss = 0.12131830
Iteration 407, loss = 0.12081217
Iteration 408, loss = 0.12030489
Iteration 409, loss = 0.11980782
Iteration 410, loss = 0.11931120
Iteration 411, loss = 0.11881719
Iteration 412, loss = 0.11833016
Iteration 413, loss = 0.11785347
Iteration 414, loss = 0.11737459
Iteration 415, loss = 0.11689432
Iteration 416, loss = 0.11642979
Iteration 417, loss = 0.11595745
Iteration 418, loss = 0.11549875
Iteration 419, loss = 0.11503370
Iteration 420, loss = 0.11457630
Iteration 421, loss = 0.11411931
Iteration 422, loss = 0.11366809
Iteration 423, loss = 0.11321213
Iteration 424, loss = 0.11276691
Iteration 425, loss = 0.11231861
Iteration 426, loss = 0.11187916
Iteration 427, loss = 0.11144138
Iteration 428, loss = 0.11101308
Iteration 429, loss = 0.11058377
Iteration 430, loss = 0.11015997
Iteration 431, loss = 0.10974573
Iteration 432, loss = 0.10933069
Iteration 433, loss = 0.10890809
Iteration 434, loss = 0.10848925
Iteration 435, loss = 0.10808569
Iteration 436, loss = 0.10767148
Iteration 437, loss = 0.10726592
Iteration 438, loss = 0.10685901
Iteration 439, loss = 0.10646390
Iteration 440, loss = 0.10605848
Iteration 441, loss = 0.10566369
Iteration 442, loss = 0.10527552
Iteration 443, loss = 0.10488945
Iteration 444, loss = 0.10450707
Iteration 445, loss = 0.10412428
Iteration 446, loss = 0.10374862
Iteration 447, loss = 0.10337948
Iteration 448, loss = 0.10299809
Iteration 449, loss = 0.10261945
Iteration 450, loss = 0.10224779
Iteration 451, loss = 0.10187708
Iteration 452, loss = 0.10151353
Iteration 453, loss = 0.10115242
Iteration 454, loss = 0.10079293
Iteration 455, loss = 0.10044193
Iteration 456, loss = 0.10008178
Iteration 457, loss = 0.09972873
Iteration 458, loss = 0.09937384
Iteration 459, loss = 0.09902029
Iteration 460, loss = 0.09868084
Iteration 461, loss = 0.09832993
Iteration 462, loss = 0.09799287
Iteration 463, loss = 0.09765815
Iteration 464, loss = 0.09732549
Iteration 465, loss = 0.09699402
Iteration 466, loss = 0.09667259
Iteration 467, loss = 0.09634481
Iteration 468, loss = 0.09602344
Iteration 469, loss = 0.09570619
Iteration 470, loss = 0.09537918
Iteration 471, loss = 0.09506393
Iteration 472, loss = 0.09474379
Iteration 473, loss = 0.09442454
Iteration 474, loss = 0.09410655
Iteration 475, loss = 0.09378953
Iteration 476, loss = 0.09348391
Iteration 477, loss = 0.09316918
Iteration 478, loss = 0.09285851
Iteration 479, loss = 0.09255286
Iteration 480, loss = 0.09225441
Iteration 481, loss = 0.09195435
Iteration 482, loss = 0.09164929
Iteration 483, loss = 0.09136200
Iteration 484, loss = 0.09106556
Iteration 485, loss = 0.09076779
Iteration 486, loss = 0.09047682
Iteration 487, loss = 0.09018117
Iteration 488, loss = 0.08989933
Iteration 489, loss = 0.08961518
Iteration 490, loss = 0.08932931
Iteration 491, loss = 0.08905661
Iteration 492, loss = 0.08877848
Iteration 493, loss = 0.08850680
Iteration 494, loss = 0.08823397
Iteration 495, loss = 0.08796567
Iteration 496, loss = 0.08769987
Iteration 497, loss = 0.08742601
Iteration 498, loss = 0.08717611
Iteration 499, loss = 0.08689427
Iteration 500, loss = 0.08662475
Iteration 501, loss = 0.08636807
Iteration 502, loss = 0.08609787
Iteration 503, loss = 0.08583916
Iteration 504, loss = 0.08557717
Iteration 505, loss = 0.08532174
Iteration 506, loss = 0.08506543
Iteration 507, loss = 0.08481383
Iteration 508, loss = 0.08456819
Iteration 509, loss = 0.08431849
Iteration 510, loss = 0.08407250
Iteration 511, loss = 0.08382938
Iteration 512, loss = 0.08358394
Iteration 513, loss = 0.08335532
Iteration 514, loss = 0.08311343
Iteration 515, loss = 0.08286508
Iteration 516, loss = 0.08262520
Iteration 517, loss = 0.08238174
Iteration 518, loss = 0.08214020
Iteration 519, loss = 0.08189984
Iteration 520, loss = 0.08166343
Iteration 521, loss = 0.08142845
Iteration 522, loss = 0.08118892
Iteration 523, loss = 0.08095964
Iteration 524, loss = 0.08072584
Iteration 525, loss = 0.08050050
Iteration 526, loss = 0.08027773
Iteration 527, loss = 0.08005096
Iteration 528, loss = 0.07982680
Iteration 529, loss = 0.07960956
Iteration 530, loss = 0.07938450
Iteration 531, loss = 0.07916871
Iteration 532, loss = 0.07895156
Iteration 533, loss = 0.07873600
Iteration 534, loss = 0.07852602
Iteration 535, loss = 0.07831472
Iteration 536, loss = 0.07810589
Iteration 537, loss = 0.07789877
Iteration 538, loss = 0.07769137
Iteration 539, loss = 0.07748832
Iteration 540, loss = 0.07728554
Iteration 541, loss = 0.07708383
Iteration 542, loss = 0.07688601
Iteration 543, loss = 0.07668264
Iteration 544, loss = 0.07649155
Iteration 545, loss = 0.07629098
Iteration 546, loss = 0.07608975
Iteration 547, loss = 0.07589741
Iteration 548, loss = 0.07569757
Iteration 549, loss = 0.07550582
Iteration 550, loss = 0.07531016
Iteration 551, loss = 0.07511548
Iteration 552, loss = 0.07492644
Iteration 553, loss = 0.07473234
Iteration 554, loss = 0.07454720
Iteration 555, loss = 0.07435805
Iteration 556, loss = 0.07417780
Iteration 557, loss = 0.07398953
Iteration 558, loss = 0.07380532
Iteration 559, loss = 0.07361712
Iteration 560, loss = 0.07343942
Iteration 561, loss = 0.07325241
Iteration 562, loss = 0.07307299
Iteration 563, loss = 0.07288946
Iteration 564, loss = 0.07270723
Iteration 565, loss = 0.07253140
Iteration 566, loss = 0.07235297
Iteration 567, loss = 0.07217074
Iteration 568, loss = 0.07199567
Iteration 569, loss = 0.07182027
Iteration 570, loss = 0.07164594
Iteration 571, loss = 0.07147399
Iteration 572, loss = 0.07130127
Iteration 573, loss = 0.07114257
Iteration 574, loss = 0.07096811
Iteration 575, loss = 0.07080052
Iteration 576, loss = 0.07062736
Iteration 577, loss = 0.07046381
Iteration 578, loss = 0.07029618
Iteration 579, loss = 0.07013471
Iteration 580, loss = 0.06996652
Iteration 581, loss = 0.06980509
Iteration 582, loss = 0.06964324
Iteration 583, loss = 0.06948009
Iteration 584, loss = 0.06931862
Iteration 585, loss = 0.06917155
Iteration 586, loss = 0.06899984
Iteration 587, loss = 0.06884285
Iteration 588, loss = 0.06868397
Iteration 589, loss = 0.06852522
Iteration 590, loss = 0.06836826
Iteration 591, loss = 0.06821515
Iteration 592, loss = 0.06805471
Iteration 593, loss = 0.06790196
Iteration 594, loss = 0.06774884
Iteration 595, loss = 0.06759572
Iteration 596, loss = 0.06744328
Iteration 597, loss = 0.06729281
Iteration 598, loss = 0.06714496
Iteration 599, loss = 0.06699773
Iteration 600, loss = 0.06685073
Iteration 601, loss = 0.06670311
Iteration 602, loss = 0.06655615
Iteration 603, loss = 0.06640772
Iteration 604, loss = 0.06625945
Iteration 605, loss = 0.06611141
Iteration 606, loss = 0.06596386
Iteration 607, loss = 0.06581523
Iteration 608, loss = 0.06567452
Iteration 609, loss = 0.06552769
Iteration 610, loss = 0.06538273
Iteration 611, loss = 0.06523518
Iteration 612, loss = 0.06508844
Iteration 613, loss = 0.06494536
Iteration 614, loss = 0.06480305
Iteration 615, loss = 0.06466174
Iteration 616, loss = 0.06451757
Iteration 617, loss = 0.06437578
Iteration 618, loss = 0.06424112
Iteration 619, loss = 0.06409653
Iteration 620, loss = 0.06395839
Iteration 621, loss = 0.06382421
Iteration 622, loss = 0.06368669
Iteration 623, loss = 0.06355760
Iteration 624, loss = 0.06342615
Iteration 625, loss = 0.06328716
Iteration 626, loss = 0.06315189
Iteration 627, loss = 0.06301707
Iteration 628, loss = 0.06288285
Iteration 629, loss = 0.06275182
Iteration 630, loss = 0.06262032
Iteration 631, loss = 0.06249087
Iteration 632, loss = 0.06236416
Iteration 633, loss = 0.06223914
Iteration 634, loss = 0.06211300
Iteration 635, loss = 0.06199215
Iteration 636, loss = 0.06186479
Iteration 637, loss = 0.06173535
Iteration 638, loss = 0.06161002
Iteration 639, loss = 0.06148545
Iteration 640, loss = 0.06136206
Iteration 641, loss = 0.06123577
Iteration 642, loss = 0.06111741
Iteration 643, loss = 0.06098994
Iteration 644, loss = 0.06086720
Iteration 645, loss = 0.06074498
Iteration 646, loss = 0.06062074
Iteration 647, loss = 0.06049703
Iteration 648, loss = 0.06037809
Iteration 649, loss = 0.06025965
Iteration 650, loss = 0.06014243
Iteration 651, loss = 0.06002967
Iteration 652, loss = 0.05991075
Iteration 653, loss = 0.05979670
Iteration 654, loss = 0.05967829
Iteration 655, loss = 0.05956652
Iteration 656, loss = 0.05944643
Iteration 657, loss = 0.05932739
Iteration 658, loss = 0.05921035
Iteration 659, loss = 0.05909588
Iteration 660, loss = 0.05897690
Iteration 661, loss = 0.05886667
Iteration 662, loss = 0.05875137
Iteration 663, loss = 0.05864189
Iteration 664, loss = 0.05852641
Iteration 665, loss = 0.05841566
Iteration 666, loss = 0.05830751
Iteration 667, loss = 0.05819548
Iteration 668, loss = 0.05808794
Iteration 669, loss = 0.05798079
Iteration 670, loss = 0.05786920
Iteration 671, loss = 0.05776042
Iteration 672, loss = 0.05765148
Iteration 673, loss = 0.05754349
Iteration 674, loss = 0.05743799
Iteration 675, loss = 0.05733423
Iteration 676, loss = 0.05722744
Iteration 677, loss = 0.05712329
Iteration 678, loss = 0.05701590
Iteration 679, loss = 0.05691949
Iteration 680, loss = 0.05681233
Iteration 681, loss = 0.05670636
Iteration 682, loss = 0.05660303
Iteration 683, loss = 0.05649864
Iteration 684, loss = 0.05639439
Iteration 685, loss = 0.05628873
Iteration 686, loss = 0.05618454
Iteration 687, loss = 0.05608605
Iteration 688, loss = 0.05598067
Iteration 689, loss = 0.05587919
Iteration 690, loss = 0.05577806
Iteration 691, loss = 0.05567566
Iteration 692, loss = 0.05557847
Iteration 693, loss = 0.05547403
Iteration 694, loss = 0.05537844
Iteration 695, loss = 0.05527544
Iteration 696, loss = 0.05517883
Iteration 697, loss = 0.05508134
Iteration 698, loss = 0.05498516
Iteration 699, loss = 0.05489415
Iteration 700, loss = 0.05479415
Iteration 701, loss = 0.05470029
Iteration 702, loss = 0.05460499
Iteration 703, loss = 0.05451568
Iteration 704, loss = 0.05441345
Iteration 705, loss = 0.05431899
Iteration 706, loss = 0.05422866
Iteration 707, loss = 0.05413541
Iteration 708, loss = 0.05404125
Iteration 709, loss = 0.05394973
Iteration 710, loss = 0.05385726
Iteration 711, loss = 0.05376896
Iteration 712, loss = 0.05367553
Iteration 713, loss = 0.05358410
Iteration 714, loss = 0.05349291
Iteration 715, loss = 0.05339850
Iteration 716, loss = 0.05330722
Iteration 717, loss = 0.05321033
Iteration 718, loss = 0.05312000
Iteration 719, loss = 0.05302799
Iteration 720, loss = 0.05293106
Iteration 721, loss = 0.05284100
Iteration 722, loss = 0.05274982
Iteration 723, loss = 0.05265899
Iteration 724, loss = 0.05257186
Iteration 725, loss = 0.05248163
Iteration 726, loss = 0.05239111
Iteration 727, loss = 0.05230360
Iteration 728, loss = 0.05222011
Iteration 729, loss = 0.05212687
Iteration 730, loss = 0.05204122
Iteration 731, loss = 0.05195259
Iteration 732, loss = 0.05186391
Iteration 733, loss = 0.05177967
Iteration 734, loss = 0.05169287
Iteration 735, loss = 0.05160729
Iteration 736, loss = 0.05152613
Iteration 737, loss = 0.05144006
Iteration 738, loss = 0.05135230
Iteration 739, loss = 0.05126999
Iteration 740, loss = 0.05118765
Iteration 741, loss = 0.05110204
Iteration 742, loss = 0.05101727
Iteration 743, loss = 0.05093710
Iteration 744, loss = 0.05085428
Iteration 745, loss = 0.05077568
Iteration 746, loss = 0.05069471
Iteration 747, loss = 0.05061131
Iteration 748, loss = 0.05053292
Iteration 749, loss = 0.05045169
Iteration 750, loss = 0.05037266
Iteration 751, loss = 0.05028912
Iteration 752, loss = 0.05021058
Iteration 753, loss = 0.05013087
Iteration 754, loss = 0.05005478
Iteration 755, loss = 0.04997517
Iteration 756, loss = 0.04989823
Iteration 757, loss = 0.04981929
Iteration 758, loss = 0.04974290
Iteration 759, loss = 0.04966671
Iteration 760, loss = 0.04959604
Iteration 761, loss = 0.04951805
Iteration 762, loss = 0.04944358
Iteration 763, loss = 0.04936655
Iteration 764, loss = 0.04929150
Iteration 765, loss = 0.04921522
Iteration 766, loss = 0.04914244
Iteration 767, loss = 0.04906461
Iteration 768, loss = 0.04899144
Iteration 769, loss = 0.04891448
Iteration 770, loss = 0.04884060
Iteration 771, loss = 0.04876947
Iteration 772, loss = 0.04869359
Iteration 773, loss = 0.04861721
Iteration 774, loss = 0.04854474
Iteration 775, loss = 0.04846779
Iteration 776, loss = 0.04839747
Iteration 777, loss = 0.04832563
Iteration 778, loss = 0.04825097
Iteration 779, loss = 0.04818275
Iteration 780, loss = 0.04810798
Iteration 781, loss = 0.04803221
Iteration 782, loss = 0.04795869
Iteration 783, loss = 0.04788378
Iteration 784, loss = 0.04781026
Iteration 785, loss = 0.04773387
Iteration 786, loss = 0.04766207
Iteration 787, loss = 0.04759206
Iteration 788, loss = 0.04751735
Iteration 789, loss = 0.04744276
Iteration 790, loss = 0.04737356
Iteration 791, loss = 0.04730462
Iteration 792, loss = 0.04723443
Iteration 793, loss = 0.04716411
Iteration 794, loss = 0.04709488
Iteration 795, loss = 0.04702609
Iteration 796, loss = 0.04695683
Iteration 797, loss = 0.04689627
Iteration 798, loss = 0.04682471
Iteration 799, loss = 0.04675559
Iteration 800, loss = 0.04669106
Iteration 801, loss = 0.04662131
Iteration 802, loss = 0.04655432
Iteration 803, loss = 0.04648720
Iteration 804, loss = 0.04642053
Iteration 805, loss = 0.04635547
Iteration 806, loss = 0.04628978
Iteration 807, loss = 0.04622554
Iteration 808, loss = 0.04615941
Iteration 809, loss = 0.04609647
Iteration 810, loss = 0.04603149
Iteration 811, loss = 0.04597040
Iteration 812, loss = 0.04589929
Iteration 813, loss = 0.04583356
Iteration 814, loss = 0.04576993
Iteration 815, loss = 0.04570906
Iteration 816, loss = 0.04563930
Iteration 817, loss = 0.04557357
Iteration 818, loss = 0.04551008
Iteration 819, loss = 0.04544229
Iteration 820, loss = 0.04537890
Iteration 821, loss = 0.04531162
Iteration 822, loss = 0.04524869
Iteration 823, loss = 0.04518623
Iteration 824, loss = 0.04512031
Iteration 825, loss = 0.04505540
Iteration 826, loss = 0.04499260
Iteration 827, loss = 0.04492967
Iteration 828, loss = 0.04486271
Iteration 829, loss = 0.04480237
Iteration 830, loss = 0.04473781
Iteration 831, loss = 0.04467490
Iteration 832, loss = 0.04461419
Iteration 833, loss = 0.04455293
Iteration 834, loss = 0.04449335
Iteration 835, loss = 0.04442985
Iteration 836, loss = 0.04437030
Iteration 837, loss = 0.04430938
Iteration 838, loss = 0.04424840
Iteration 839, loss = 0.04418601
Iteration 840, loss = 0.04412912
Iteration 841, loss = 0.04406593
Iteration 842, loss = 0.04400584
Iteration 843, loss = 0.04394662
Iteration 844, loss = 0.04388881
Iteration 845, loss = 0.04382936
Iteration 846, loss = 0.04377094
Iteration 847, loss = 0.04371424
Iteration 848, loss = 0.04365612
Iteration 849, loss = 0.04359940
Iteration 850, loss = 0.04354282
Iteration 851, loss = 0.04348430
Iteration 852, loss = 0.04342624
Iteration 853, loss = 0.04336855
Iteration 854, loss = 0.04331233
Iteration 855, loss = 0.04325413
Iteration 856, loss = 0.04319689
Iteration 857, loss = 0.04314379
Iteration 858, loss = 0.04308512
Iteration 859, loss = 0.04303129
Iteration 860, loss = 0.04297350
Iteration 861, loss = 0.04291622
Iteration 862, loss = 0.04285656
Iteration 863, loss = 0.04279890
Iteration 864, loss = 0.04273945
Iteration 865, loss = 0.04268194
Iteration 866, loss = 0.04262779
Iteration 867, loss = 0.04257192
Iteration 868, loss = 0.04251587
Iteration 869, loss = 0.04246174
Iteration 870, loss = 0.04240822
Iteration 871, loss = 0.04235792
Iteration 872, loss = 0.04230254
Iteration 873, loss = 0.04224629
Iteration 874, loss = 0.04219247
Iteration 875, loss = 0.04213872
Iteration 876, loss = 0.04208132
Iteration 877, loss = 0.04203508
Iteration 878, loss = 0.04197752
Iteration 879, loss = 0.04192308
Iteration 880, loss = 0.04186856
Iteration 881, loss = 0.04182061
Iteration 882, loss = 0.04176290
Iteration 883, loss = 0.04170998
Iteration 884, loss = 0.04165602
Iteration 885, loss = 0.04160247
Iteration 886, loss = 0.04154821
Iteration 887, loss = 0.04149695
Iteration 888, loss = 0.04144295
Iteration 889, loss = 0.04138851
Iteration 890, loss = 0.04133836
Iteration 891, loss = 0.04128178
Iteration 892, loss = 0.04122772
Iteration 893, loss = 0.04117380
Iteration 894, loss = 0.04112284
Iteration 895, loss = 0.04106503
Iteration 896, loss = 0.04101176
Iteration 897, loss = 0.04095856
Iteration 898, loss = 0.04090550
Iteration 899, loss = 0.04085264
Iteration 900, loss = 0.04079872
Iteration 901, loss = 0.04074792
Iteration 902, loss = 0.04069561
Iteration 903, loss = 0.04064352
Iteration 904, loss = 0.04059493
Iteration 905, loss = 0.04053664
Iteration 906, loss = 0.04048599
Iteration 907, loss = 0.04043284
Iteration 908, loss = 0.04038308
Iteration 909, loss = 0.04033263
Iteration 910, loss = 0.04028302
Iteration 911, loss = 0.04023173
Iteration 912, loss = 0.04018359
Iteration 913, loss = 0.04013135
Iteration 914, loss = 0.04008052
Iteration 915, loss = 0.04003403
Iteration 916, loss = 0.03997972
Iteration 917, loss = 0.03993304
Iteration 918, loss = 0.03988185
Iteration 919, loss = 0.03983274
Iteration 920, loss = 0.03978498
Iteration 921, loss = 0.03973605
Iteration 922, loss = 0.03968563
Iteration 923, loss = 0.03963630
Iteration 924, loss = 0.03958838
Iteration 925, loss = 0.03953935
Iteration 926, loss = 0.03949010
Iteration 927, loss = 0.03943993
Iteration 928, loss = 0.03939130
Iteration 929, loss = 0.03934472
Iteration 930, loss = 0.03929215
Iteration 931, loss = 0.03924171
Iteration 932, loss = 0.03919371
Iteration 933, loss = 0.03914237
Iteration 934, loss = 0.03909740
Iteration 935, loss = 0.03905198
Iteration 936, loss = 0.03900239
Iteration 937, loss = 0.03896196
Iteration 938, loss = 0.03891233
Iteration 939, loss = 0.03886431
Iteration 940, loss = 0.03881892
Iteration 941, loss = 0.03877185
Iteration 942, loss = 0.03872730
Iteration 943, loss = 0.03868026
Iteration 944, loss = 0.03863624
Iteration 945, loss = 0.03858866
Iteration 946, loss = 0.03854236
Iteration 947, loss = 0.03849957
Iteration 948, loss = 0.03845454
Iteration 949, loss = 0.03840483
Iteration 950, loss = 0.03835873
Iteration 951, loss = 0.03830809
Iteration 952, loss = 0.03826154
Iteration 953, loss = 0.03821412
Iteration 954, loss = 0.03816627
Iteration 955, loss = 0.03812190
Iteration 956, loss = 0.03807771
Iteration 957, loss = 0.03803098
Iteration 958, loss = 0.03798574
Iteration 959, loss = 0.03794288
Iteration 960, loss = 0.03789911
Iteration 961, loss = 0.03785368
Iteration 962, loss = 0.03781103
Iteration 963, loss = 0.03776654
Iteration 964, loss = 0.03772273
Iteration 965, loss = 0.03767991
Iteration 966, loss = 0.03763788
Iteration 967, loss = 0.03759567
Iteration 968, loss = 0.03755384
Iteration 969, loss = 0.03751060
Iteration 970, loss = 0.03746872
Iteration 971, loss = 0.03742959
Iteration 972, loss = 0.03738530
Iteration 973, loss = 0.03734107
Iteration 974, loss = 0.03729983
Iteration 975, loss = 0.03725783
Iteration 976, loss = 0.03721447
Iteration 977, loss = 0.03716992
Iteration 978, loss = 0.03712809
Iteration 979, loss = 0.03708591
Iteration 980, loss = 0.03704592
Iteration 981, loss = 0.03700753
Iteration 982, loss = 0.03696389
Iteration 983, loss = 0.03692397
Iteration 984, loss = 0.03688348
Iteration 985, loss = 0.03684371
Iteration 986, loss = 0.03680085
Iteration 987, loss = 0.03676040
Iteration 988, loss = 0.03672102
Iteration 989, loss = 0.03668334
Iteration 990, loss = 0.03664727
Iteration 991, loss = 0.03660750
Iteration 992, loss = 0.03656688
Iteration 993, loss = 0.03652786
Iteration 994, loss = 0.03648513
Iteration 995, loss = 0.03644282
Iteration 996, loss = 0.03640443
Iteration 997, loss = 0.03636342
Iteration 998, loss = 0.03632351
Iteration 999, loss = 0.03628354
Iteration 1000, loss = 0.03624206
Iteration 1001, loss = 0.03620554
Iteration 1002, loss = 0.03616349
Iteration 1003, loss = 0.03612370
Iteration 1004, loss = 0.03608648
Iteration 1005, loss = 0.03604916
Iteration 1006, loss = 0.03601187
Iteration 1007, loss = 0.03597442
Iteration 1008, loss = 0.03593461
Iteration 1009, loss = 0.03589607
Iteration 1010, loss = 0.03585928
Iteration 1011, loss = 0.03582007
Iteration 1012, loss = 0.03578355
Iteration 1013, loss = 0.03574397
Iteration 1014, loss = 0.03570729
Iteration 1015, loss = 0.03567236
Iteration 1016, loss = 0.03563605
Iteration 1017, loss = 0.03559896
Iteration 1018, loss = 0.03556417
Iteration 1019, loss = 0.03552813
Iteration 1020, loss = 0.03549199
Iteration 1021, loss = 0.03545763
Iteration 1022, loss = 0.03542286
Iteration 1023, loss = 0.03538118
Iteration 1024, loss = 0.03534469
Iteration 1025, loss = 0.03530618
Iteration 1026, loss = 0.03526707
Iteration 1027, loss = 0.03522920
Iteration 1028, loss = 0.03519225
Iteration 1029, loss = 0.03515786
Iteration 1030, loss = 0.03512002
Iteration 1031, loss = 0.03508290
Iteration 1032, loss = 0.03504715
Iteration 1033, loss = 0.03501136
Iteration 1034, loss = 0.03497329
Iteration 1035, loss = 0.03493702
Iteration 1036, loss = 0.03490029
Iteration 1037, loss = 0.03486436
Iteration 1038, loss = 0.03482721
Iteration 1039, loss = 0.03479170
Iteration 1040, loss = 0.03475253
Iteration 1041, loss = 0.03471752
Iteration 1042, loss = 0.03467749
Iteration 1043, loss = 0.03464322
Iteration 1044, loss = 0.03460695
Iteration 1045, loss = 0.03456980
Iteration 1046, loss = 0.03453571
Iteration 1047, loss = 0.03449887
Iteration 1048, loss = 0.03446314
Iteration 1049, loss = 0.03442818
Iteration 1050, loss = 0.03439196
Iteration 1051, loss = 0.03435640
Iteration 1052, loss = 0.03432176
Iteration 1053, loss = 0.03428910
Iteration 1054, loss = 0.03425297
Iteration 1055, loss = 0.03421896
Iteration 1056, loss = 0.03418341
Iteration 1057, loss = 0.03415052
Iteration 1058, loss = 0.03411595
Iteration 1059, loss = 0.03408027
Iteration 1060, loss = 0.03404608
Iteration 1061, loss = 0.03401079
Iteration 1062, loss = 0.03397464
Iteration 1063, loss = 0.03393729
Iteration 1064, loss = 0.03390391
Iteration 1065, loss = 0.03386887
Iteration 1066, loss = 0.03383196
Iteration 1067, loss = 0.03379538
Iteration 1068, loss = 0.03376368
Iteration 1069, loss = 0.03372755
Iteration 1070, loss = 0.03369256
Iteration 1071, loss = 0.03366029
Iteration 1072, loss = 0.03362514
Iteration 1073, loss = 0.03358990
Iteration 1074, loss = 0.03355765
Iteration 1075, loss = 0.03352291
Iteration 1076, loss = 0.03348852
Iteration 1077, loss = 0.03345733
Iteration 1078, loss = 0.03342029
Iteration 1079, loss = 0.03338486
Iteration 1080, loss = 0.03334917
Iteration 1081, loss = 0.03331552
Iteration 1082, loss = 0.03328413
Iteration 1083, loss = 0.03324389
Iteration 1084, loss = 0.03321066
Iteration 1085, loss = 0.03317734
Iteration 1086, loss = 0.03314221
Iteration 1087, loss = 0.03311158
Iteration 1088, loss = 0.03308102
Iteration 1089, loss = 0.03304669
Iteration 1090, loss = 0.03301524
Iteration 1091, loss = 0.03298525
Iteration 1092, loss = 0.03295270
Iteration 1093, loss = 0.03292078
Iteration 1094, loss = 0.03289300
Iteration 1095, loss = 0.03285882
Iteration 1096, loss = 0.03282959
Iteration 1097, loss = 0.03279609
Iteration 1098, loss = 0.03276504
Iteration 1099, loss = 0.03273210
Iteration 1100, loss = 0.03270060
Iteration 1101, loss = 0.03266766
Iteration 1102, loss = 0.03263593
Iteration 1103, loss = 0.03260331
Iteration 1104, loss = 0.03257129
Iteration 1105, loss = 0.03254232
Iteration 1106, loss = 0.03250995
Iteration 1107, loss = 0.03247873
Iteration 1108, loss = 0.03244947
Iteration 1109, loss = 0.03241813
Iteration 1110, loss = 0.03239005
Iteration 1111, loss = 0.03235772
Iteration 1112, loss = 0.03232678
Iteration 1113, loss = 0.03229602
Iteration 1114, loss = 0.03226423
Iteration 1115, loss = 0.03223494
Iteration 1116, loss = 0.03220186
Iteration 1117, loss = 0.03216744
Iteration 1118, loss = 0.03213924
Iteration 1119, loss = 0.03210635
Iteration 1120, loss = 0.03207644
Iteration 1121, loss = 0.03204409
Iteration 1122, loss = 0.03201622
Iteration 1123, loss = 0.03198486
Iteration 1124, loss = 0.03195116
Iteration 1125, loss = 0.03192146
Iteration 1126, loss = 0.03189035
Iteration 1127, loss = 0.03185920
Iteration 1128, loss = 0.03182898
Iteration 1129, loss = 0.03180072
Iteration 1130, loss = 0.03176802
Iteration 1131, loss = 0.03173825
Iteration 1132, loss = 0.03170776
Iteration 1133, loss = 0.03167601
Iteration 1134, loss = 0.03165094
Iteration 1135, loss = 0.03161628
Iteration 1136, loss = 0.03158515
Iteration 1137, loss = 0.03155529
Iteration 1138, loss = 0.03152587
Iteration 1139, loss = 0.03149730
Iteration 1140, loss = 0.03146947
Iteration 1141, loss = 0.03143885
Iteration 1142, loss = 0.03141127
Iteration 1143, loss = 0.03137916
Iteration 1144, loss = 0.03135172
Iteration 1145, loss = 0.03132326
Iteration 1146, loss = 0.03129608
Iteration 1147, loss = 0.03127063
Iteration 1148, loss = 0.03123981
Iteration 1149, loss = 0.03121199
Iteration 1150, loss = 0.03118351
Iteration 1151, loss = 0.03115511
Iteration 1152, loss = 0.03112727
Iteration 1153, loss = 0.03109686
Iteration 1154, loss = 0.03107087
Iteration 1155, loss = 0.03104225
Iteration 1156, loss = 0.03101549
Iteration 1157, loss = 0.03098834
Iteration 1158, loss = 0.03096128
Iteration 1159, loss = 0.03093519
Iteration 1160, loss = 0.03090829
Iteration 1161, loss = 0.03088218
Iteration 1162, loss = 0.03085384
Iteration 1163, loss = 0.03082755
Iteration 1164, loss = 0.03079950
Iteration 1165, loss = 0.03077238
Iteration 1166, loss = 0.03074543
Iteration 1167, loss = 0.03071798
Iteration 1168, loss = 0.03068930
Iteration 1169, loss = 0.03066189
Iteration 1170, loss = 0.03063450
Iteration 1171, loss = 0.03060783
Iteration 1172, loss = 0.03057797
Iteration 1173, loss = 0.03054602
Iteration 1174, loss = 0.03051586
Iteration 1175, loss = 0.03048856
Iteration 1176, loss = 0.03045865
Iteration 1177, loss = 0.03042981
Iteration 1178, loss = 0.03040192
Iteration 1179, loss = 0.03037184
Iteration 1180, loss = 0.03034414
Iteration 1181, loss = 0.03031569
Iteration 1182, loss = 0.03028763
Iteration 1183, loss = 0.03025972
Iteration 1184, loss = 0.03023282
Iteration 1185, loss = 0.03020541
Iteration 1186, loss = 0.03018116
Iteration 1187, loss = 0.03015137
Iteration 1188, loss = 0.03012645
Iteration 1189, loss = 0.03010004
Iteration 1190, loss = 0.03007590
Iteration 1191, loss = 0.03005165
Iteration 1192, loss = 0.03002711
Iteration 1193, loss = 0.02999977
Iteration 1194, loss = 0.02997378
Iteration 1195, loss = 0.02994664
Iteration 1196, loss = 0.02991649
Iteration 1197, loss = 0.02988910
Iteration 1198, loss = 0.02985956
Iteration 1199, loss = 0.02983402
Iteration 1200, loss = 0.02980627
Iteration 1201, loss = 0.02977769
Iteration 1202, loss = 0.02975004
Iteration 1203, loss = 0.02972570
Iteration 1204, loss = 0.02969400
Iteration 1205, loss = 0.02966467
Iteration 1206, loss = 0.02963618
Iteration 1207, loss = 0.02960677
Iteration 1208, loss = 0.02958186
Iteration 1209, loss = 0.02955237
Iteration 1210, loss = 0.02952488
Iteration 1211, loss = 0.02949554
Iteration 1212, loss = 0.02947096
Iteration 1213, loss = 0.02944197
Iteration 1214, loss = 0.02941546
Iteration 1215, loss = 0.02938798
Iteration 1216, loss = 0.02936543
Iteration 1217, loss = 0.02933391
Iteration 1218, loss = 0.02930847
Iteration 1219, loss = 0.02928136
Iteration 1220, loss = 0.02925363
Iteration 1221, loss = 0.02922800
Iteration 1222, loss = 0.02920142
Iteration 1223, loss = 0.02917300
Iteration 1224, loss = 0.02914722
Iteration 1225, loss = 0.02911716
Iteration 1226, loss = 0.02909492
Iteration 1227, loss = 0.02906696
Iteration 1228, loss = 0.02903797
Iteration 1229, loss = 0.02901178
Iteration 1230, loss = 0.02898550
Iteration 1231, loss = 0.02895996
Iteration 1232, loss = 0.02893415
Iteration 1233, loss = 0.02890812
Iteration 1234, loss = 0.02888373
Iteration 1235, loss = 0.02885821
Iteration 1236, loss = 0.02883347
Iteration 1237, loss = 0.02881040
Iteration 1238, loss = 0.02878418
Iteration 1239, loss = 0.02875749
Iteration 1240, loss = 0.02873241
Iteration 1241, loss = 0.02870573
Iteration 1242, loss = 0.02867736
Iteration 1243, loss = 0.02865822
Iteration 1244, loss = 0.02863205
Iteration 1245, loss = 0.02860223
Iteration 1246, loss = 0.02857608
Iteration 1247, loss = 0.02855021
Iteration 1248, loss = 0.02852438
Iteration 1249, loss = 0.02849843
Iteration 1250, loss = 0.02847352
Iteration 1251, loss = 0.02844619
Iteration 1252, loss = 0.02842356
Iteration 1253, loss = 0.02839789
Iteration 1254, loss = 0.02837618
Iteration 1255, loss = 0.02834785
Iteration 1256, loss = 0.02832318
Iteration 1257, loss = 0.02829750
Iteration 1258, loss = 0.02827266
Iteration 1259, loss = 0.02825188
Iteration 1260, loss = 0.02822418
Iteration 1261, loss = 0.02820176
Iteration 1262, loss = 0.02817721
Iteration 1263, loss = 0.02815216
Iteration 1264, loss = 0.02812730
Iteration 1265, loss = 0.02810333
Iteration 1266, loss = 0.02807826
Iteration 1267, loss = 0.02805334
Iteration 1268, loss = 0.02802795
Iteration 1269, loss = 0.02800351
Iteration 1270, loss = 0.02797867
Iteration 1271, loss = 0.02795266
Iteration 1272, loss = 0.02792969
Iteration 1273, loss = 0.02790528
Iteration 1274, loss = 0.02788104
Iteration 1275, loss = 0.02785832
Iteration 1276, loss = 0.02783448
Iteration 1277, loss = 0.02781198
Iteration 1278, loss = 0.02779040
Iteration 1279, loss = 0.02776607
Iteration 1280, loss = 0.02774378
Iteration 1281, loss = 0.02772258
Iteration 1282, loss = 0.02769778
Iteration 1283, loss = 0.02767468
Iteration 1284, loss = 0.02765110
Iteration 1285, loss = 0.02762840
Iteration 1286, loss = 0.02760853
Iteration 1287, loss = 0.02758467
Iteration 1288, loss = 0.02755993
Iteration 1289, loss = 0.02753983
Iteration 1290, loss = 0.02751411
Iteration 1291, loss = 0.02749047
Iteration 1292, loss = 0.02746684
Iteration 1293, loss = 0.02744259
Iteration 1294, loss = 0.02742083
Iteration 1295, loss = 0.02739386
Iteration 1296, loss = 0.02737321
Iteration 1297, loss = 0.02734493
Iteration 1298, loss = 0.02732081
Iteration 1299, loss = 0.02729500
Iteration 1300, loss = 0.02727097
Iteration 1301, loss = 0.02724584
Iteration 1302, loss = 0.02722234
Iteration 1303, loss = 0.02719958
Iteration 1304, loss = 0.02717433
Iteration 1305, loss = 0.02714889
Iteration 1306, loss = 0.02712628
Iteration 1307, loss = 0.02710121
Iteration 1308, loss = 0.02707701
Iteration 1309, loss = 0.02705259
Iteration 1310, loss = 0.02702974
Iteration 1311, loss = 0.02700574
Iteration 1312, loss = 0.02698593
Iteration 1313, loss = 0.02695959
Iteration 1314, loss = 0.02693544
Iteration 1315, loss = 0.02691257
Iteration 1316, loss = 0.02689064
Iteration 1317, loss = 0.02686612
Iteration 1318, loss = 0.02684444
Iteration 1319, loss = 0.02682530
Iteration 1320, loss = 0.02679842
Iteration 1321, loss = 0.02677498
Iteration 1322, loss = 0.02675099
Iteration 1323, loss = 0.02673091
Iteration 1324, loss = 0.02670647
Iteration 1325, loss = 0.02668460
Iteration 1326, loss = 0.02666211
Iteration 1327, loss = 0.02664127
Iteration 1328, loss = 0.02661663
Iteration 1329, loss = 0.02659105
Iteration 1330, loss = 0.02656924
Iteration 1331, loss = 0.02655075
Iteration 1332, loss = 0.02652331
Iteration 1333, loss = 0.02649782
Iteration 1334, loss = 0.02648106
Iteration 1335, loss = 0.02645658
Iteration 1336, loss = 0.02643412
Iteration 1337, loss = 0.02641540
Iteration 1338, loss = 0.02638987
Iteration 1339, loss = 0.02636792
Iteration 1340, loss = 0.02634640
Iteration 1341, loss = 0.02632361
Iteration 1342, loss = 0.02630196
Iteration 1343, loss = 0.02628020
Iteration 1344, loss = 0.02626187
Iteration 1345, loss = 0.02623871
Iteration 1346, loss = 0.02621611
Iteration 1347, loss = 0.02619724
Iteration 1348, loss = 0.02617452
Iteration 1349, loss = 0.02615240
Iteration 1350, loss = 0.02613113
Iteration 1351, loss = 0.02610869
Iteration 1352, loss = 0.02608662
Iteration 1353, loss = 0.02606410
Iteration 1354, loss = 0.02604275
Iteration 1355, loss = 0.02602117
Iteration 1356, loss = 0.02600122
Iteration 1357, loss = 0.02597952
Iteration 1358, loss = 0.02595998
Iteration 1359, loss = 0.02594021
Iteration 1360, loss = 0.02591781
Iteration 1361, loss = 0.02589691
Iteration 1362, loss = 0.02587677
Iteration 1363, loss = 0.02585505
Iteration 1364, loss = 0.02583383
Iteration 1365, loss = 0.02581317
Iteration 1366, loss = 0.02579260
Iteration 1367, loss = 0.02576987
Iteration 1368, loss = 0.02574827
Iteration 1369, loss = 0.02572886
Iteration 1370, loss = 0.02570670
Iteration 1371, loss = 0.02568661
Iteration 1372, loss = 0.02566589
Iteration 1373, loss = 0.02564470
Iteration 1374, loss = 0.02562515
Iteration 1375, loss = 0.02560476
Iteration 1376, loss = 0.02558504
Iteration 1377, loss = 0.02556613
Iteration 1378, loss = 0.02554981
Iteration 1379, loss = 0.02552616
Iteration 1380, loss = 0.02550508
Iteration 1381, loss = 0.02548424
Iteration 1382, loss = 0.02546478
Iteration 1383, loss = 0.02544190
Iteration 1384, loss = 0.02541948
Iteration 1385, loss = 0.02539809
Iteration 1386, loss = 0.02537383
Iteration 1387, loss = 0.02535406
Iteration 1388, loss = 0.02533086
Iteration 1389, loss = 0.02530815
Iteration 1390, loss = 0.02528787
Iteration 1391, loss = 0.02526618
Iteration 1392, loss = 0.02524516
Iteration 1393, loss = 0.02522351
Iteration 1394, loss = 0.02520433
Iteration 1395, loss = 0.02518444
Iteration 1396, loss = 0.02516486
Iteration 1397, loss = 0.02514595
Iteration 1398, loss = 0.02512451
Iteration 1399, loss = 0.02510516
Iteration 1400, loss = 0.02508546
Iteration 1401, loss = 0.02506733
Iteration 1402, loss = 0.02504600
Iteration 1403, loss = 0.02502612
Iteration 1404, loss = 0.02500668
Iteration 1405, loss = 0.02498712
Iteration 1406, loss = 0.02496753
Iteration 1407, loss = 0.02494831
Iteration 1408, loss = 0.02493222
Iteration 1409, loss = 0.02491197
Iteration 1410, loss = 0.02489183
Iteration 1411, loss = 0.02487360
Iteration 1412, loss = 0.02485460
Iteration 1413, loss = 0.02483696
Iteration 1414, loss = 0.02481855
Iteration 1415, loss = 0.02479815
Iteration 1416, loss = 0.02477964
Iteration 1417, loss = 0.02476055
Iteration 1418, loss = 0.02474239
Iteration 1419, loss = 0.02472244
Iteration 1420, loss = 0.02470391
Iteration 1421, loss = 0.02468304
Iteration 1422, loss = 0.02466293
Iteration 1423, loss = 0.02464639
Iteration 1424, loss = 0.02462325
Iteration 1425, loss = 0.02460410
Iteration 1426, loss = 0.02458588
Iteration 1427, loss = 0.02456699
Iteration 1428, loss = 0.02455132
Iteration 1429, loss = 0.02452864
Iteration 1430, loss = 0.02450653
Iteration 1431, loss = 0.02448870
Iteration 1432, loss = 0.02446704
Iteration 1433, loss = 0.02444775
Iteration 1434, loss = 0.02442780
Iteration 1435, loss = 0.02441009
Iteration 1436, loss = 0.02438845
Iteration 1437, loss = 0.02436883
Iteration 1438, loss = 0.02435179
Iteration 1439, loss = 0.02433100
Iteration 1440, loss = 0.02431648
Iteration 1441, loss = 0.02429411
Iteration 1442, loss = 0.02427366
Iteration 1443, loss = 0.02425495
Iteration 1444, loss = 0.02423724
Iteration 1445, loss = 0.02421730
Iteration 1446, loss = 0.02420011
Iteration 1447, loss = 0.02417761
Iteration 1448, loss = 0.02416015
Iteration 1449, loss = 0.02414160
Iteration 1450, loss = 0.02412252
Iteration 1451, loss = 0.02410574
Iteration 1452, loss = 0.02408517
Iteration 1453, loss = 0.02406738
Iteration 1454, loss = 0.02404852
Iteration 1455, loss = 0.02402909
Iteration 1456, loss = 0.02401124
Iteration 1457, loss = 0.02399253
Iteration 1458, loss = 0.02397373
Iteration 1459, loss = 0.02395563
Iteration 1460, loss = 0.02393709
Iteration 1461, loss = 0.02391857
Iteration 1462, loss = 0.02389943
Iteration 1463, loss = 0.02388133
Iteration 1464, loss = 0.02386241
Iteration 1465, loss = 0.02384290
Iteration 1466, loss = 0.02382544
Iteration 1467, loss = 0.02380627
Iteration 1468, loss = 0.02378710
Iteration 1469, loss = 0.02376943
Iteration 1470, loss = 0.02375059
Iteration 1471, loss = 0.02373361
Iteration 1472, loss = 0.02371224
Iteration 1473, loss = 0.02369335
Iteration 1474, loss = 0.02367537
Iteration 1475, loss = 0.02365853
Iteration 1476, loss = 0.02363810
Iteration 1477, loss = 0.02362020
Iteration 1478, loss = 0.02360198
Iteration 1479, loss = 0.02358321
Iteration 1480, loss = 0.02356689
Iteration 1481, loss = 0.02354907
Iteration 1482, loss = 0.02353239
Iteration 1483, loss = 0.02351189
Iteration 1484, loss = 0.02349184
Iteration 1485, loss = 0.02347640
Iteration 1486, loss = 0.02345660
Iteration 1487, loss = 0.02343914
Iteration 1488, loss = 0.02341977
Iteration 1489, loss = 0.02340251
Iteration 1490, loss = 0.02338455
Iteration 1491, loss = 0.02336703
Iteration 1492, loss = 0.02334962
Iteration 1493, loss = 0.02333165
Iteration 1494, loss = 0.02331395
Iteration 1495, loss = 0.02329625
Iteration 1496, loss = 0.02327851
Iteration 1497, loss = 0.02326098
Iteration 1498, loss = 0.02324224
Iteration 1499, loss = 0.02322431
Iteration 1500, loss = 0.02320457
Iteration 1501, loss = 0.02318720
Iteration 1502, loss = 0.02316890
Iteration 1503, loss = 0.02315202
Iteration 1504, loss = 0.02313272
Iteration 1505, loss = 0.02311681
Iteration 1506, loss = 0.02309810
Iteration 1507, loss = 0.02307907
Iteration 1508, loss = 0.02305982
Iteration 1509, loss = 0.02304274
Iteration 1510, loss = 0.02302598
Iteration 1511, loss = 0.02300627
Iteration 1512, loss = 0.02299172
Iteration 1513, loss = 0.02297343
Iteration 1514, loss = 0.02295623
Iteration 1515, loss = 0.02294060
Iteration 1516, loss = 0.02292345
Iteration 1517, loss = 0.02290690
Iteration 1518, loss = 0.02289062
Iteration 1519, loss = 0.02287424
Iteration 1520, loss = 0.02285919
Iteration 1521, loss = 0.02284311
Iteration 1522, loss = 0.02282551
Iteration 1523, loss = 0.02280866
Iteration 1524, loss = 0.02279217
Iteration 1525, loss = 0.02277381
Iteration 1526, loss = 0.02275695
Iteration 1527, loss = 0.02273888
Iteration 1528, loss = 0.02272305
Iteration 1529, loss = 0.02270375
Iteration 1530, loss = 0.02268807
Iteration 1531, loss = 0.02266927
Iteration 1532, loss = 0.02265351
Iteration 1533, loss = 0.02263933
Iteration 1534, loss = 0.02261925
Iteration 1535, loss = 0.02260364
Iteration 1536, loss = 0.02258701
Iteration 1537, loss = 0.02256984
Iteration 1538, loss = 0.02255481
Iteration 1539, loss = 0.02253837
Iteration 1540, loss = 0.02251982
Iteration 1541, loss = 0.02250430
Iteration 1542, loss = 0.02248789
Iteration 1543, loss = 0.02247173
Iteration 1544, loss = 0.02245721
Iteration 1545, loss = 0.02244014
Iteration 1546, loss = 0.02242445
Iteration 1547, loss = 0.02241089
Iteration 1548, loss = 0.02239252
Iteration 1549, loss = 0.02237595
Iteration 1550, loss = 0.02236017
Iteration 1551, loss = 0.02234411
Iteration 1552, loss = 0.02232780
Iteration 1553, loss = 0.02231191
Iteration 1554, loss = 0.02229439
Iteration 1555, loss = 0.02227804
Iteration 1556, loss = 0.02226328
Iteration 1557, loss = 0.02224531
Iteration 1558, loss = 0.02222873
Iteration 1559, loss = 0.02221242
Iteration 1560, loss = 0.02219736
Iteration 1561, loss = 0.02218068
Iteration 1562, loss = 0.02216311
Iteration 1563, loss = 0.02214646
Iteration 1564, loss = 0.02213005
Iteration 1565, loss = 0.02211500
Iteration 1566, loss = 0.02209852
Iteration 1567, loss = 0.02208097
Iteration 1568, loss = 0.02206719
Iteration 1569, loss = 0.02204911
Iteration 1570, loss = 0.02203555
Iteration 1571, loss = 0.02201851
Iteration 1572, loss = 0.02200225
Iteration 1573, loss = 0.02198518
Iteration 1574, loss = 0.02196921
Iteration 1575, loss = 0.02195511
Iteration 1576, loss = 0.02193667
Iteration 1577, loss = 0.02192168
Iteration 1578, loss = 0.02190465
Iteration 1579, loss = 0.02188738
Iteration 1580, loss = 0.02187101
Iteration 1581, loss = 0.02185495
Iteration 1582, loss = 0.02184026
Iteration 1583, loss = 0.02182323
Iteration 1584, loss = 0.02180801
Iteration 1585, loss = 0.02179348
Iteration 1586, loss = 0.02177816
Iteration 1587, loss = 0.02176469
Iteration 1588, loss = 0.02174725
Iteration 1589, loss = 0.02173254
Iteration 1590, loss = 0.02171801
Iteration 1591, loss = 0.02170208
Iteration 1592, loss = 0.02168514
Iteration 1593, loss = 0.02166910
Iteration 1594, loss = 0.02165343
Iteration 1595, loss = 0.02163730
Iteration 1596, loss = 0.02162338
Iteration 1597, loss = 0.02160597
Iteration 1598, loss = 0.02158985
Iteration 1599, loss = 0.02157186
Iteration 1600, loss = 0.02155987
Iteration 1601, loss = 0.02154070
Iteration 1602, loss = 0.02152464
Iteration 1603, loss = 0.02150832
Iteration 1604, loss = 0.02149199
Iteration 1605, loss = 0.02147585
Iteration 1606, loss = 0.02146148
Iteration 1607, loss = 0.02144576
Iteration 1608, loss = 0.02142832
Iteration 1609, loss = 0.02141215
Iteration 1610, loss = 0.02139650
Iteration 1611, loss = 0.02138228
Iteration 1612, loss = 0.02136656
Iteration 1613, loss = 0.02135295
Iteration 1614, loss = 0.02133800
Iteration 1615, loss = 0.02132282
Iteration 1616, loss = 0.02130751
Iteration 1617, loss = 0.02129677
Iteration 1618, loss = 0.02127923
Iteration 1619, loss = 0.02126214
Iteration 1620, loss = 0.02124770
Iteration 1621, loss = 0.02123159
Iteration 1622, loss = 0.02121528
Iteration 1623, loss = 0.02120031
Iteration 1624, loss = 0.02118356
Iteration 1625, loss = 0.02116778
Iteration 1626, loss = 0.02115363
Iteration 1627, loss = 0.02113697
Iteration 1628, loss = 0.02112221
Iteration 1629, loss = 0.02110601
Iteration 1630, loss = 0.02109103
Iteration 1631, loss = 0.02107658
Iteration 1632, loss = 0.02105968
Iteration 1633, loss = 0.02104359
Iteration 1634, loss = 0.02102829
Iteration 1635, loss = 0.02101141
Iteration 1636, loss = 0.02099470
Iteration 1637, loss = 0.02098014
Iteration 1638, loss = 0.02096330
Iteration 1639, loss = 0.02094729
Iteration 1640, loss = 0.02093200
Iteration 1641, loss = 0.02091541
Iteration 1642, loss = 0.02089985
Iteration 1643, loss = 0.02088389
Iteration 1644, loss = 0.02086871
Iteration 1645, loss = 0.02085426
Iteration 1646, loss = 0.02083874
Iteration 1647, loss = 0.02082303
Iteration 1648, loss = 0.02081100
Iteration 1649, loss = 0.02079338
Iteration 1650, loss = 0.02078035
Iteration 1651, loss = 0.02076521
Iteration 1652, loss = 0.02075037
Iteration 1653, loss = 0.02073617
Iteration 1654, loss = 0.02072212
Iteration 1655, loss = 0.02071230
Iteration 1656, loss = 0.02069533
Iteration 1657, loss = 0.02067794
Iteration 1658, loss = 0.02066220
Iteration 1659, loss = 0.02064869
Iteration 1660, loss = 0.02063285
Iteration 1661, loss = 0.02061919
Iteration 1662, loss = 0.02060342
Iteration 1663, loss = 0.02058910
Iteration 1664, loss = 0.02057491
Iteration 1665, loss = 0.02056128
Iteration 1666, loss = 0.02054668
Iteration 1667, loss = 0.02053434
Iteration 1668, loss = 0.02052157
Iteration 1669, loss = 0.02050683
Iteration 1670, loss = 0.02049274
Iteration 1671, loss = 0.02047908
Iteration 1672, loss = 0.02046521
Iteration 1673, loss = 0.02045218
Iteration 1674, loss = 0.02043945
Iteration 1675, loss = 0.02042767
Iteration 1676, loss = 0.02041249
Iteration 1677, loss = 0.02040029
Iteration 1678, loss = 0.02038423
Iteration 1679, loss = 0.02037074
Iteration 1680, loss = 0.02035527
Iteration 1681, loss = 0.02034130
Iteration 1682, loss = 0.02032738
Iteration 1683, loss = 0.02031486
Iteration 1684, loss = 0.02029863
Iteration 1685, loss = 0.02028508
Iteration 1686, loss = 0.02027118
Iteration 1687, loss = 0.02025607
Iteration 1688, loss = 0.02024209
Iteration 1689, loss = 0.02022866
Iteration 1690, loss = 0.02021661
Iteration 1691, loss = 0.02020144
Iteration 1692, loss = 0.02018806
Iteration 1693, loss = 0.02017415
Iteration 1694, loss = 0.02016007
Iteration 1695, loss = 0.02014634
Iteration 1696, loss = 0.02013394
Iteration 1697, loss = 0.02011910
Iteration 1698, loss = 0.02010555
Iteration 1699, loss = 0.02009282
Iteration 1700, loss = 0.02007667
Iteration 1701, loss = 0.02006237
Iteration 1702, loss = 0.02005021
Iteration 1703, loss = 0.02003411
Iteration 1704, loss = 0.02002398
Iteration 1705, loss = 0.02000783
Iteration 1706, loss = 0.01999530
Iteration 1707, loss = 0.01997946
Iteration 1708, loss = 0.01996647
Iteration 1709, loss = 0.01995126
Iteration 1710, loss = 0.01993936
Iteration 1711, loss = 0.01992456
Iteration 1712, loss = 0.01991139
Iteration 1713, loss = 0.01989704
Iteration 1714, loss = 0.01988299
Iteration 1715, loss = 0.01987062
Iteration 1716, loss = 0.01985795
Iteration 1717, loss = 0.01984129
Iteration 1718, loss = 0.01983234
Iteration 1719, loss = 0.01981512
Iteration 1720, loss = 0.01980151
Iteration 1721, loss = 0.01978702
Iteration 1722, loss = 0.01977471
Iteration 1723, loss = 0.01976140
Iteration 1724, loss = 0.01974862
Iteration 1725, loss = 0.01973298
Iteration 1726, loss = 0.01971969
Iteration 1727, loss = 0.01970724
Iteration 1728, loss = 0.01969482
Iteration 1729, loss = 0.01968036
Iteration 1730, loss = 0.01966635
Iteration 1731, loss = 0.01965261
Iteration 1732, loss = 0.01963985
Iteration 1733, loss = 0.01962605
Iteration 1734, loss = 0.01961328
Iteration 1735, loss = 0.01959843
Iteration 1736, loss = 0.01958493
Iteration 1737, loss = 0.01957121
Iteration 1738, loss = 0.01955695
Iteration 1739, loss = 0.01954440
Iteration 1740, loss = 0.01953036
Iteration 1741, loss = 0.01951552
Iteration 1742, loss = 0.01950142
Iteration 1743, loss = 0.01948789
Iteration 1744, loss = 0.01947525
Iteration 1745, loss = 0.01946172
Iteration 1746, loss = 0.01944766
Iteration 1747, loss = 0.01943572
Iteration 1748, loss = 0.01942085
Iteration 1749, loss = 0.01941093
Iteration 1750, loss = 0.01939555
Iteration 1751, loss = 0.01938326
Iteration 1752, loss = 0.01937052
Iteration 1753, loss = 0.01935695
Iteration 1754, loss = 0.01934439
Iteration 1755, loss = 0.01933190
Iteration 1756, loss = 0.01932001
Iteration 1757, loss = 0.01930660
Iteration 1758, loss = 0.01929452
Iteration 1759, loss = 0.01928225
Iteration 1760, loss = 0.01926898
Iteration 1761, loss = 0.01925768
Iteration 1762, loss = 0.01924452
Iteration 1763, loss = 0.01923198
Iteration 1764, loss = 0.01922097
Iteration 1765, loss = 0.01920795
Iteration 1766, loss = 0.01919549
Iteration 1767, loss = 0.01918137
Iteration 1768, loss = 0.01916842
Iteration 1769, loss = 0.01915533
Iteration 1770, loss = 0.01914231
Iteration 1771, loss = 0.01912965
Iteration 1772, loss = 0.01911684
Iteration 1773, loss = 0.01910422
Iteration 1774, loss = 0.01909215
Iteration 1775, loss = 0.01907829
Iteration 1776, loss = 0.01906524
Iteration 1777, loss = 0.01905223
Iteration 1778, loss = 0.01904038
Iteration 1779, loss = 0.01902723
Iteration 1780, loss = 0.01901555
Iteration 1781, loss = 0.01899911
Iteration 1782, loss = 0.01898346
Iteration 1783, loss = 0.01897323
Iteration 1784, loss = 0.01896031
Iteration 1785, loss = 0.01894549
Iteration 1786, loss = 0.01893249
Iteration 1787, loss = 0.01891870
Iteration 1788, loss = 0.01890416
Iteration 1789, loss = 0.01889226
Iteration 1790, loss = 0.01888055
Iteration 1791, loss = 0.01887070
Iteration 1792, loss = 0.01885798
Iteration 1793, loss = 0.01884760
Iteration 1794, loss = 0.01883406
Iteration 1795, loss = 0.01882101
Iteration 1796, loss = 0.01880956
Iteration 1797, loss = 0.01879670
Iteration 1798, loss = 0.01878371
Iteration 1799, loss = 0.01877195
Iteration 1800, loss = 0.01875800
Iteration 1801, loss = 0.01874471
Iteration 1802, loss = 0.01873256
Iteration 1803, loss = 0.01871996
Iteration 1804, loss = 0.01870676
Iteration 1805, loss = 0.01869774
Iteration 1806, loss = 0.01868198
Iteration 1807, loss = 0.01866964
Iteration 1808, loss = 0.01865772
Iteration 1809, loss = 0.01864548
Iteration 1810, loss = 0.01863334
Iteration 1811, loss = 0.01862034
Iteration 1812, loss = 0.01860902
Iteration 1813, loss = 0.01859556
Iteration 1814, loss = 0.01858258
Iteration 1815, loss = 0.01857123
Iteration 1816, loss = 0.01855929
Iteration 1817, loss = 0.01854855
Iteration 1818, loss = 0.01853365
Iteration 1819, loss = 0.01852348
Iteration 1820, loss = 0.01850874
Iteration 1821, loss = 0.01849840
Iteration 1822, loss = 0.01848668
Iteration 1823, loss = 0.01847428
Iteration 1824, loss = 0.01846263
Iteration 1825, loss = 0.01845071
Iteration 1826, loss = 0.01844016
Iteration 1827, loss = 0.01842869
Iteration 1828, loss = 0.01841491
Iteration 1829, loss = 0.01840277
Iteration 1830, loss = 0.01839105
Iteration 1831, loss = 0.01837926
Iteration 1832, loss = 0.01836889
Iteration 1833, loss = 0.01835805
Iteration 1834, loss = 0.01834559
Iteration 1835, loss = 0.01833410
Iteration 1836, loss = 0.01832296
Iteration 1837, loss = 0.01831295
Iteration 1838, loss = 0.01830180
Iteration 1839, loss = 0.01829094
Iteration 1840, loss = 0.01828383
Iteration 1841, loss = 0.01826923
Iteration 1842, loss = 0.01825800
Iteration 1843, loss = 0.01824557
Iteration 1844, loss = 0.01823420
Iteration 1845, loss = 0.01822173
Iteration 1846, loss = 0.01821035
Iteration 1847, loss = 0.01819886
Iteration 1848, loss = 0.01818896
Iteration 1849, loss = 0.01817655
Iteration 1850, loss = 0.01816532
Iteration 1851, loss = 0.01815620
Iteration 1852, loss = 0.01814305
Iteration 1853, loss = 0.01813160
Iteration 1854, loss = 0.01812094
Iteration 1855, loss = 0.01810855
Iteration 1856, loss = 0.01809628
Iteration 1857, loss = 0.01808504
Iteration 1858, loss = 0.01807356
Iteration 1859, loss = 0.01806234
Iteration 1860, loss = 0.01805050
Iteration 1861, loss = 0.01804149
Iteration 1862, loss = 0.01802945
Iteration 1863, loss = 0.01801860
Iteration 1864, loss = 0.01800792
Iteration 1865, loss = 0.01799503
Iteration 1866, loss = 0.01798329
Iteration 1867, loss = 0.01797115
Iteration 1868, loss = 0.01795951
Iteration 1869, loss = 0.01794672
Iteration 1870, loss = 0.01793398
Iteration 1871, loss = 0.01792440
Iteration 1872, loss = 0.01791215
Iteration 1873, loss = 0.01789904
Iteration 1874, loss = 0.01788807
Iteration 1875, loss = 0.01787773
Iteration 1876, loss = 0.01786608
Iteration 1877, loss = 0.01785557
Iteration 1878, loss = 0.01784520
Iteration 1879, loss = 0.01783428
Iteration 1880, loss = 0.01782363
Iteration 1881, loss = 0.01781240
Iteration 1882, loss = 0.01780213
Iteration 1883, loss = 0.01779259
Iteration 1884, loss = 0.01778019
Iteration 1885, loss = 0.01777149
Iteration 1886, loss = 0.01775820
Iteration 1887, loss = 0.01774844
Iteration 1888, loss = 0.01773712
Iteration 1889, loss = 0.01772595
Iteration 1890, loss = 0.01771714
Iteration 1891, loss = 0.01770733
Iteration 1892, loss = 0.01769442
Iteration 1893, loss = 0.01768291
Iteration 1894, loss = 0.01767234
Iteration 1895, loss = 0.01766231
Iteration 1896, loss = 0.01765166
Iteration 1897, loss = 0.01764144
Iteration 1898, loss = 0.01763049
Iteration 1899, loss = 0.01762041
Iteration 1900, loss = 0.01761044
Iteration 1901, loss = 0.01760034
Iteration 1902, loss = 0.01759068
Iteration 1903, loss = 0.01758068
Iteration 1904, loss = 0.01757012
Iteration 1905, loss = 0.01756015
Iteration 1906, loss = 0.01754772
Iteration 1907, loss = 0.01753727
Iteration 1908, loss = 0.01752483
Iteration 1909, loss = 0.01751401
Iteration 1910, loss = 0.01750161
Iteration 1911, loss = 0.01749097
Iteration 1912, loss = 0.01748039
Iteration 1913, loss = 0.01746903
Iteration 1914, loss = 0.01745963
Iteration 1915, loss = 0.01744705
Iteration 1916, loss = 0.01743725
Iteration 1917, loss = 0.01742638
Iteration 1918, loss = 0.01741628
Iteration 1919, loss = 0.01740495
Iteration 1920, loss = 0.01739391
Iteration 1921, loss = 0.01738284
Iteration 1922, loss = 0.01737155
Iteration 1923, loss = 0.01736164
Iteration 1924, loss = 0.01734821
Iteration 1925, loss = 0.01733719
Iteration 1926, loss = 0.01732528
Iteration 1927, loss = 0.01731370
Iteration 1928, loss = 0.01730248
Iteration 1929, loss = 0.01729150
Iteration 1930, loss = 0.01728014
Iteration 1931, loss = 0.01726900
Iteration 1932, loss = 0.01725835
Iteration 1933, loss = 0.01724790
Iteration 1934, loss = 0.01723592
Iteration 1935, loss = 0.01722679
Iteration 1936, loss = 0.01721490
Iteration 1937, loss = 0.01720607
Iteration 1938, loss = 0.01719588
Iteration 1939, loss = 0.01718365
Iteration 1940, loss = 0.01717354
Iteration 1941, loss = 0.01716277
Iteration 1942, loss = 0.01715245
Iteration 1943, loss = 0.01714106
Iteration 1944, loss = 0.01713305
Iteration 1945, loss = 0.01711948
Iteration 1946, loss = 0.01710933
Iteration 1947, loss = 0.01709778
Iteration 1948, loss = 0.01708608
Iteration 1949, loss = 0.01707439
Iteration 1950, loss = 0.01706281
Iteration 1951, loss = 0.01705397
Iteration 1952, loss = 0.01704241
Iteration 1953, loss = 0.01703197
Iteration 1954, loss = 0.01702162
Iteration 1955, loss = 0.01701135
Iteration 1956, loss = 0.01700128
Iteration 1957, loss = 0.01699136
Iteration 1958, loss = 0.01698205
Iteration 1959, loss = 0.01697093
Iteration 1960, loss = 0.01696085
Iteration 1961, loss = 0.01695043
Iteration 1962, loss = 0.01694079
Iteration 1963, loss = 0.01692922
Iteration 1964, loss = 0.01691978
Iteration 1965, loss = 0.01691060
Iteration 1966, loss = 0.01690002
Iteration 1967, loss = 0.01688975
Iteration 1968, loss = 0.01687933
Iteration 1969, loss = 0.01686807
Iteration 1970, loss = 0.01685924
Iteration 1971, loss = 0.01684796
Iteration 1972, loss = 0.01683828
Iteration 1973, loss = 0.01682803
Iteration 1974, loss = 0.01682191
Iteration 1975, loss = 0.01680599
Iteration 1976, loss = 0.01679738
Iteration 1977, loss = 0.01678415
Iteration 1978, loss = 0.01677355
Iteration 1979, loss = 0.01676383
Iteration 1980, loss = 0.01675209
Iteration 1981, loss = 0.01674244
Iteration 1982, loss = 0.01673024
Iteration 1983, loss = 0.01671809
Iteration 1984, loss = 0.01670704
Iteration 1985, loss = 0.01669603
Iteration 1986, loss = 0.01668796
Iteration 1987, loss = 0.01667590
Iteration 1988, loss = 0.01666481
Iteration 1989, loss = 0.01665588
Iteration 1990, loss = 0.01664570
Iteration 1991, loss = 0.01663545
Iteration 1992, loss = 0.01662527
Iteration 1993, loss = 0.01661384
Iteration 1994, loss = 0.01660314
Iteration 1995, loss = 0.01659282
Iteration 1996, loss = 0.01658200
Iteration 1997, loss = 0.01657189
Iteration 1998, loss = 0.01656233
Iteration 1999, loss = 0.01655144
Iteration 2000, loss = 0.01654036
Iteration 2001, loss = 0.01653042
Iteration 2002, loss = 0.01651991
Iteration 2003, loss = 0.01650979
Iteration 2004, loss = 0.01650014
Iteration 2005, loss = 0.01649187
Iteration 2006, loss = 0.01648049
Iteration 2007, loss = 0.01647034
Iteration 2008, loss = 0.01646164
Iteration 2009, loss = 0.01645190
Iteration 2010, loss = 0.01644214
Iteration 2011, loss = 0.01643523
Iteration 2012, loss = 0.01642422
Iteration 2013, loss = 0.01641414
Iteration 2014, loss = 0.01640513
Iteration 2015, loss = 0.01639417
Iteration 2016, loss = 0.01638395
Iteration 2017, loss = 0.01637626
Iteration 2018, loss = 0.01636544
Iteration 2019, loss = 0.01635424
Iteration 2020, loss = 0.01634459
Iteration 2021, loss = 0.01633456
Iteration 2022, loss = 0.01632510
Iteration 2023, loss = 0.01631554
Iteration 2024, loss = 0.01630607
Iteration 2025, loss = 0.01629717
Iteration 2026, loss = 0.01628862
Iteration 2027, loss = 0.01627759
Iteration 2028, loss = 0.01626792
Iteration 2029, loss = 0.01625962
Iteration 2030, loss = 0.01624821
Iteration 2031, loss = 0.01623946
Iteration 2032, loss = 0.01622851
Iteration 2033, loss = 0.01621937
Iteration 2034, loss = 0.01620986
Iteration 2035, loss = 0.01620065
Iteration 2036, loss = 0.01619160
Iteration 2037, loss = 0.01618184
Iteration 2038, loss = 0.01617411
Iteration 2039, loss = 0.01616375
Iteration 2040, loss = 0.01615419
Iteration 2041, loss = 0.01614450
Iteration 2042, loss = 0.01613634
Iteration 2043, loss = 0.01612679
Iteration 2044, loss = 0.01611795
Iteration 2045, loss = 0.01610906
Iteration 2046, loss = 0.01609974
Iteration 2047, loss = 0.01609155
Iteration 2048, loss = 0.01608229
Iteration 2049, loss = 0.01607181
Iteration 2050, loss = 0.01606200
Iteration 2051, loss = 0.01605389
Iteration 2052, loss = 0.01604373
Iteration 2053, loss = 0.01603446
Iteration 2054, loss = 0.01602548
Iteration 2055, loss = 0.01601661
Iteration 2056, loss = 0.01600773
Iteration 2057, loss = 0.01599831
Iteration 2058, loss = 0.01599007
Iteration 2059, loss = 0.01597968
Iteration 2060, loss = 0.01596930
Iteration 2061, loss = 0.01596000
Iteration 2062, loss = 0.01594981
Iteration 2063, loss = 0.01594034
Iteration 2064, loss = 0.01592917
Iteration 2065, loss = 0.01591925
Iteration 2066, loss = 0.01590929
Iteration 2067, loss = 0.01589857
Iteration 2068, loss = 0.01589254
Iteration 2069, loss = 0.01587999
Iteration 2070, loss = 0.01587103
Iteration 2071, loss = 0.01586063
Iteration 2072, loss = 0.01585105
Iteration 2073, loss = 0.01584253
Iteration 2074, loss = 0.01583241
Iteration 2075, loss = 0.01582195
Iteration 2076, loss = 0.01581344
Iteration 2077, loss = 0.01580299
Iteration 2078, loss = 0.01579344
Iteration 2079, loss = 0.01578579
Iteration 2080, loss = 0.01577539
Iteration 2081, loss = 0.01576589
Iteration 2082, loss = 0.01575655
Iteration 2083, loss = 0.01574774
Iteration 2084, loss = 0.01573870
Iteration 2085, loss = 0.01572964
Iteration 2086, loss = 0.01572088
Iteration 2087, loss = 0.01571152
Iteration 2088, loss = 0.01570112
Iteration 2089, loss = 0.01569236
Iteration 2090, loss = 0.01568254
Iteration 2091, loss = 0.01567393
Iteration 2092, loss = 0.01566468
Iteration 2093, loss = 0.01565567
Iteration 2094, loss = 0.01564607
Iteration 2095, loss = 0.01563677
Iteration 2096, loss = 0.01562729
Iteration 2097, loss = 0.01561858
Iteration 2098, loss = 0.01560936
Iteration 2099, loss = 0.01559994
Iteration 2100, loss = 0.01559091
Iteration 2101, loss = 0.01558275
Iteration 2102, loss = 0.01557341
Iteration 2103, loss = 0.01556313
Iteration 2104, loss = 0.01555460
Iteration 2105, loss = 0.01554621
Iteration 2106, loss = 0.01553703
Iteration 2107, loss = 0.01552762
Iteration 2108, loss = 0.01551812
Iteration 2109, loss = 0.01550911
Iteration 2110, loss = 0.01549992
Iteration 2111, loss = 0.01549029
Iteration 2112, loss = 0.01548132
Iteration 2113, loss = 0.01547245
Iteration 2114, loss = 0.01546409
Iteration 2115, loss = 0.01545475
Iteration 2116, loss = 0.01544505
Iteration 2117, loss = 0.01543574
Iteration 2118, loss = 0.01542748
Iteration 2119, loss = 0.01541955
Iteration 2120, loss = 0.01540878
Iteration 2121, loss = 0.01539995
Iteration 2122, loss = 0.01538992
Iteration 2123, loss = 0.01538117
Iteration 2124, loss = 0.01537063
Iteration 2125, loss = 0.01536335
Iteration 2126, loss = 0.01535652
Iteration 2127, loss = 0.01534690
Iteration 2128, loss = 0.01533715
Iteration 2129, loss = 0.01532904
Iteration 2130, loss = 0.01532072
Iteration 2131, loss = 0.01531249
Iteration 2132, loss = 0.01530363
Iteration 2133, loss = 0.01529464
Iteration 2134, loss = 0.01528746
Iteration 2135, loss = 0.01527852
Iteration 2136, loss = 0.01527042
Iteration 2137, loss = 0.01526140
Iteration 2138, loss = 0.01525400
Iteration 2139, loss = 0.01524510
Iteration 2140, loss = 0.01523636
Iteration 2141, loss = 0.01522707
Iteration 2142, loss = 0.01521812
Iteration 2143, loss = 0.01521044
Iteration 2144, loss = 0.01520144
Iteration 2145, loss = 0.01519315
Iteration 2146, loss = 0.01518359
Iteration 2147, loss = 0.01517509
Iteration 2148, loss = 0.01516609
Iteration 2149, loss = 0.01515737
Iteration 2150, loss = 0.01514794
Iteration 2151, loss = 0.01513852
Iteration 2152, loss = 0.01512958
Iteration 2153, loss = 0.01511929
Iteration 2154, loss = 0.01511078
Iteration 2155, loss = 0.01510124
Iteration 2156, loss = 0.01509227
Iteration 2157, loss = 0.01508345
Iteration 2158, loss = 0.01507435
Iteration 2159, loss = 0.01506586
Iteration 2160, loss = 0.01505784
Iteration 2161, loss = 0.01504880
Iteration 2162, loss = 0.01504046
Iteration 2163, loss = 0.01503093
Iteration 2164, loss = 0.01502198
Iteration 2165, loss = 0.01501445
Iteration 2166, loss = 0.01500580
Iteration 2167, loss = 0.01499787
Iteration 2168, loss = 0.01498814
Iteration 2169, loss = 0.01497906
Iteration 2170, loss = 0.01497067
Iteration 2171, loss = 0.01496172
Iteration 2172, loss = 0.01495549
Iteration 2173, loss = 0.01494650
Iteration 2174, loss = 0.01493758
Iteration 2175, loss = 0.01493064
Iteration 2176, loss = 0.01492185
Iteration 2177, loss = 0.01491425
Iteration 2178, loss = 0.01490583
Iteration 2179, loss = 0.01489829
Iteration 2180, loss = 0.01488921
Iteration 2181, loss = 0.01488137
Iteration 2182, loss = 0.01487332
Iteration 2183, loss = 0.01486521
Iteration 2184, loss = 0.01485651
Iteration 2185, loss = 0.01484949
Iteration 2186, loss = 0.01484232
Iteration 2187, loss = 0.01483302
Iteration 2188, loss = 0.01482608
Iteration 2189, loss = 0.01481672
Iteration 2190, loss = 0.01480872
Iteration 2191, loss = 0.01479894
Iteration 2192, loss = 0.01479067
Iteration 2193, loss = 0.01478196
Iteration 2194, loss = 0.01477247
Iteration 2195, loss = 0.01476505
Iteration 2196, loss = 0.01475686
Iteration 2197, loss = 0.01474906
Iteration 2198, loss = 0.01474085
Iteration 2199, loss = 0.01473254
Iteration 2200, loss = 0.01472768
Iteration 2201, loss = 0.01471899
Iteration 2202, loss = 0.01471205
Iteration 2203, loss = 0.01470432
Iteration 2204, loss = 0.01469558
Iteration 2205, loss = 0.01468847
Iteration 2206, loss = 0.01467886
Iteration 2207, loss = 0.01467039
Iteration 2208, loss = 0.01466302
Iteration 2209, loss = 0.01465589
Iteration 2210, loss = 0.01464849
Iteration 2211, loss = 0.01463807
Iteration 2212, loss = 0.01463011
Iteration 2213, loss = 0.01461986
Iteration 2214, loss = 0.01461106
Iteration 2215, loss = 0.01460153
Iteration 2216, loss = 0.01459230
Iteration 2217, loss = 0.01458174
Iteration 2218, loss = 0.01457363
Iteration 2219, loss = 0.01456662
Iteration 2220, loss = 0.01455574
Iteration 2221, loss = 0.01454776
Iteration 2222, loss = 0.01453937
Iteration 2223, loss = 0.01453017
Iteration 2224, loss = 0.01452271
Iteration 2225, loss = 0.01451401
Iteration 2226, loss = 0.01450566
Iteration 2227, loss = 0.01449929
Iteration 2228, loss = 0.01448944
Iteration 2229, loss = 0.01448121
Iteration 2230, loss = 0.01447325
Iteration 2231, loss = 0.01446541
Iteration 2232, loss = 0.01445794
Iteration 2233, loss = 0.01444985
Iteration 2234, loss = 0.01444105
Iteration 2235, loss = 0.01443305
Iteration 2236, loss = 0.01442353
Iteration 2237, loss = 0.01441652
Iteration 2238, loss = 0.01440665
Iteration 2239, loss = 0.01439830
Iteration 2240, loss = 0.01438977
Iteration 2241, loss = 0.01438189
Iteration 2242, loss = 0.01437304
Iteration 2243, loss = 0.01436444
Iteration 2244, loss = 0.01435668
Iteration 2245, loss = 0.01434796
Iteration 2246, loss = 0.01434034
Iteration 2247, loss = 0.01433235
Iteration 2248, loss = 0.01432400
Iteration 2249, loss = 0.01431619
Iteration 2250, loss = 0.01430820
Iteration 2251, loss = 0.01430041
Iteration 2252, loss = 0.01429262
Iteration 2253, loss = 0.01428529
Iteration 2254, loss = 0.01427676
Iteration 2255, loss = 0.01426911
Iteration 2256, loss = 0.01426097
Iteration 2257, loss = 0.01425308
Iteration 2258, loss = 0.01424615
Iteration 2259, loss = 0.01423710
Iteration 2260, loss = 0.01422947
Iteration 2261, loss = 0.01422113
Iteration 2262, loss = 0.01421355
Iteration 2263, loss = 0.01420528
Iteration 2264, loss = 0.01419776
Iteration 2265, loss = 0.01419058
Iteration 2266, loss = 0.01418222
Iteration 2267, loss = 0.01417497
Iteration 2268, loss = 0.01416787
Iteration 2269, loss = 0.01415965
Iteration 2270, loss = 0.01415162
Iteration 2271, loss = 0.01414506
Iteration 2272, loss = 0.01413608
Iteration 2273, loss = 0.01412836
Iteration 2274, loss = 0.01412055
Iteration 2275, loss = 0.01411143
Iteration 2276, loss = 0.01410485
Iteration 2277, loss = 0.01409476
Iteration 2278, loss = 0.01408561
Iteration 2279, loss = 0.01408017
Iteration 2280, loss = 0.01407120
Iteration 2281, loss = 0.01406195
Iteration 2282, loss = 0.01405326
Iteration 2283, loss = 0.01404447
Iteration 2284, loss = 0.01403717
Iteration 2285, loss = 0.01402767
Iteration 2286, loss = 0.01402020
Iteration 2287, loss = 0.01401142
Iteration 2288, loss = 0.01400278
Iteration 2289, loss = 0.01399627
Iteration 2290, loss = 0.01398962
Iteration 2291, loss = 0.01398128
Iteration 2292, loss = 0.01397299
Iteration 2293, loss = 0.01396568
Iteration 2294, loss = 0.01395836
Iteration 2295, loss = 0.01395054
Iteration 2296, loss = 0.01394239
Iteration 2297, loss = 0.01393526
Iteration 2298, loss = 0.01392631
Iteration 2299, loss = 0.01391882
Iteration 2300, loss = 0.01391101
Iteration 2301, loss = 0.01390329
Iteration 2302, loss = 0.01389559
Iteration 2303, loss = 0.01388799
Iteration 2304, loss = 0.01388055
Iteration 2305, loss = 0.01387280
Iteration 2306, loss = 0.01386780
Iteration 2307, loss = 0.01385793
Iteration 2308, loss = 0.01385096
Iteration 2309, loss = 0.01384233
Iteration 2310, loss = 0.01383604
Iteration 2311, loss = 0.01382734
Iteration 2312, loss = 0.01381926
Iteration 2313, loss = 0.01381383
Iteration 2314, loss = 0.01380462
Iteration 2315, loss = 0.01379782
Iteration 2316, loss = 0.01378886
Iteration 2317, loss = 0.01378067
Iteration 2318, loss = 0.01377257
Iteration 2319, loss = 0.01376554
Iteration 2320, loss = 0.01375957
Iteration 2321, loss = 0.01374988
Iteration 2322, loss = 0.01374244
Iteration 2323, loss = 0.01373456
Iteration 2324, loss = 0.01372689
Iteration 2325, loss = 0.01371906
Iteration 2326, loss = 0.01371164
Iteration 2327, loss = 0.01370443
Iteration 2328, loss = 0.01369773
Iteration 2329, loss = 0.01368992
Iteration 2330, loss = 0.01368362
Iteration 2331, loss = 0.01367514
Iteration 2332, loss = 0.01366988
Iteration 2333, loss = 0.01366126
Iteration 2334, loss = 0.01365364
Iteration 2335, loss = 0.01364643
Iteration 2336, loss = 0.01363889
Iteration 2337, loss = 0.01363203
Iteration 2338, loss = 0.01362469
Iteration 2339, loss = 0.01361691
Iteration 2340, loss = 0.01360921
Iteration 2341, loss = 0.01360176
Iteration 2342, loss = 0.01359409
Iteration 2343, loss = 0.01358553
Iteration 2344, loss = 0.01357840
Iteration 2345, loss = 0.01357206
Iteration 2346, loss = 0.01356299
Iteration 2347, loss = 0.01355493
Iteration 2348, loss = 0.01354730
Iteration 2349, loss = 0.01354011
Iteration 2350, loss = 0.01353347
Iteration 2351, loss = 0.01352568
Iteration 2352, loss = 0.01351953
Iteration 2353, loss = 0.01351175
Iteration 2354, loss = 0.01350410
Iteration 2355, loss = 0.01349752
Iteration 2356, loss = 0.01348817
Iteration 2357, loss = 0.01348043
Iteration 2358, loss = 0.01347338
Iteration 2359, loss = 0.01346579
Iteration 2360, loss = 0.01345794
Iteration 2361, loss = 0.01345012
Iteration 2362, loss = 0.01344203
Iteration 2363, loss = 0.01343488
Iteration 2364, loss = 0.01342760
Iteration 2365, loss = 0.01342082
Iteration 2366, loss = 0.01341353
Iteration 2367, loss = 0.01340595
Iteration 2368, loss = 0.01339884
Iteration 2369, loss = 0.01339188
Iteration 2370, loss = 0.01338417
Iteration 2371, loss = 0.01337777
Iteration 2372, loss = 0.01337060
Iteration 2373, loss = 0.01336261
Iteration 2374, loss = 0.01335456
Iteration 2375, loss = 0.01334673
Iteration 2376, loss = 0.01334048
Iteration 2377, loss = 0.01333184
Iteration 2378, loss = 0.01332469
Iteration 2379, loss = 0.01331709
Iteration 2380, loss = 0.01330964
Iteration 2381, loss = 0.01330201
Iteration 2382, loss = 0.01329472
Iteration 2383, loss = 0.01328784
Iteration 2384, loss = 0.01328055
Iteration 2385, loss = 0.01327426
Iteration 2386, loss = 0.01326740
Iteration 2387, loss = 0.01325978
Iteration 2388, loss = 0.01325438
Iteration 2389, loss = 0.01324802
Iteration 2390, loss = 0.01323937
Iteration 2391, loss = 0.01323219
Iteration 2392, loss = 0.01322549
Iteration 2393, loss = 0.01321877
Iteration 2394, loss = 0.01321249
Iteration 2395, loss = 0.01320491
Iteration 2396, loss = 0.01319806
Iteration 2397, loss = 0.01319092
Iteration 2398, loss = 0.01318446
Iteration 2399, loss = 0.01317786
Iteration 2400, loss = 0.01317175
Iteration 2401, loss = 0.01316498
Iteration 2402, loss = 0.01315643
Iteration 2403, loss = 0.01315027
Iteration 2404, loss = 0.01314182
Iteration 2405, loss = 0.01313672
Iteration 2406, loss = 0.01312827
Iteration 2407, loss = 0.01312145
Iteration 2408, loss = 0.01311546
Iteration 2409, loss = 0.01310770
Iteration 2410, loss = 0.01309998
Iteration 2411, loss = 0.01309327
Iteration 2412, loss = 0.01308644
Iteration 2413, loss = 0.01307975
Iteration 2414, loss = 0.01307296
Iteration 2415, loss = 0.01306579
Iteration 2416, loss = 0.01306151
Iteration 2417, loss = 0.01305263
Iteration 2418, loss = 0.01304709
Iteration 2419, loss = 0.01303877
Iteration 2420, loss = 0.01303193
Iteration 2421, loss = 0.01302511
Iteration 2422, loss = 0.01301818
Iteration 2423, loss = 0.01301277
Iteration 2424, loss = 0.01300484
Iteration 2425, loss = 0.01299823
Iteration 2426, loss = 0.01299355
Iteration 2427, loss = 0.01298584
Iteration 2428, loss = 0.01297858
Iteration 2429, loss = 0.01297577
Iteration 2430, loss = 0.01296652
Iteration 2431, loss = 0.01295933
Iteration 2432, loss = 0.01295205
Iteration 2433, loss = 0.01294543
Iteration 2434, loss = 0.01293792
Iteration 2435, loss = 0.01293148
Iteration 2436, loss = 0.01292350
Iteration 2437, loss = 0.01291756
Iteration 2438, loss = 0.01291013
Iteration 2439, loss = 0.01290372
Iteration 2440, loss = 0.01289659
Iteration 2441, loss = 0.01289076
Iteration 2442, loss = 0.01288351
Iteration 2443, loss = 0.01287694
Iteration 2444, loss = 0.01287052
Iteration 2445, loss = 0.01286371
Iteration 2446, loss = 0.01285680
Iteration 2447, loss = 0.01284986
Iteration 2448, loss = 0.01284287
Iteration 2449, loss = 0.01283562
Iteration 2450, loss = 0.01282900
Iteration 2451, loss = 0.01282317
Iteration 2452, loss = 0.01281627
Iteration 2453, loss = 0.01280987
Iteration 2454, loss = 0.01280233
Iteration 2455, loss = 0.01279521
Iteration 2456, loss = 0.01278854
Iteration 2457, loss = 0.01278198
Iteration 2458, loss = 0.01277765
Iteration 2459, loss = 0.01276974
Iteration 2460, loss = 0.01276353
Iteration 2461, loss = 0.01275706
Iteration 2462, loss = 0.01275250
Iteration 2463, loss = 0.01274382
Iteration 2464, loss = 0.01273653
Iteration 2465, loss = 0.01273008
Iteration 2466, loss = 0.01272286
Iteration 2467, loss = 0.01271494
Iteration 2468, loss = 0.01270990
Iteration 2469, loss = 0.01270175
Iteration 2470, loss = 0.01269598
Iteration 2471, loss = 0.01268915
Iteration 2472, loss = 0.01268327
Iteration 2473, loss = 0.01267762
Iteration 2474, loss = 0.01267166
Iteration 2475, loss = 0.01266521
Iteration 2476, loss = 0.01266026
Iteration 2477, loss = 0.01265359
Iteration 2478, loss = 0.01264681
Iteration 2479, loss = 0.01264117
Iteration 2480, loss = 0.01263424
Iteration 2481, loss = 0.01262744
Iteration 2482, loss = 0.01262051
Iteration 2483, loss = 0.01261266
Iteration 2484, loss = 0.01260738
Iteration 2485, loss = 0.01259920
Iteration 2486, loss = 0.01259211
Iteration 2487, loss = 0.01258648
Iteration 2488, loss = 0.01257849
Iteration 2489, loss = 0.01257225
Iteration 2490, loss = 0.01256568
Iteration 2491, loss = 0.01256097
Iteration 2492, loss = 0.01255141
Iteration 2493, loss = 0.01254544
Iteration 2494, loss = 0.01253734
Iteration 2495, loss = 0.01253093
Iteration 2496, loss = 0.01252420
Iteration 2497, loss = 0.01251802
Iteration 2498, loss = 0.01251222
Iteration 2499, loss = 0.01250395
Iteration 2500, loss = 0.01249779
Iteration 2501, loss = 0.01249050
Iteration 2502, loss = 0.01248484
Iteration 2503, loss = 0.01247866
Iteration 2504, loss = 0.01247063
Iteration 2505, loss = 0.01246456
Iteration 2506, loss = 0.01245765
Iteration 2507, loss = 0.01245180
Iteration 2508, loss = 0.01244458
Iteration 2509, loss = 0.01243736
Iteration 2510, loss = 0.01243023
Iteration 2511, loss = 0.01242420
Iteration 2512, loss = 0.01241654
Iteration 2513, loss = 0.01240965
Iteration 2514, loss = 0.01240311
Iteration 2515, loss = 0.01239687
Iteration 2516, loss = 0.01239005
Iteration 2517, loss = 0.01238321
Iteration 2518, loss = 0.01237574
Iteration 2519, loss = 0.01236997
Iteration 2520, loss = 0.01236277
Iteration 2521, loss = 0.01235716
Iteration 2522, loss = 0.01234996
Iteration 2523, loss = 0.01234397
Iteration 2524, loss = 0.01233683
Iteration 2525, loss = 0.01233021
Iteration 2526, loss = 0.01232552
Iteration 2527, loss = 0.01231792
Iteration 2528, loss = 0.01231146
Iteration 2529, loss = 0.01230519
Iteration 2530, loss = 0.01229816
Iteration 2531, loss = 0.01229062
Iteration 2532, loss = 0.01228702
Iteration 2533, loss = 0.01227995
Iteration 2534, loss = 0.01227330
Iteration 2535, loss = 0.01226696
Iteration 2536, loss = 0.01226082
Iteration 2537, loss = 0.01225599
Iteration 2538, loss = 0.01224858
Iteration 2539, loss = 0.01224259
Iteration 2540, loss = 0.01223638
Iteration 2541, loss = 0.01222989
Iteration 2542, loss = 0.01222395
Iteration 2543, loss = 0.01221780
Iteration 2544, loss = 0.01221166
Iteration 2545, loss = 0.01220739
Iteration 2546, loss = 0.01220067
Iteration 2547, loss = 0.01219561
Iteration 2548, loss = 0.01218887
Iteration 2549, loss = 0.01218305
Iteration 2550, loss = 0.01217671
Iteration 2551, loss = 0.01217078
Iteration 2552, loss = 0.01216440
Iteration 2553, loss = 0.01215849
Iteration 2554, loss = 0.01215270
Iteration 2555, loss = 0.01214719
Iteration 2556, loss = 0.01214095
Iteration 2557, loss = 0.01213488
Iteration 2558, loss = 0.01212882
Iteration 2559, loss = 0.01212288
Iteration 2560, loss = 0.01211717
Iteration 2561, loss = 0.01211155
Iteration 2562, loss = 0.01210604
Iteration 2563, loss = 0.01210123
Iteration 2564, loss = 0.01209588
Iteration 2565, loss = 0.01208964
Iteration 2566, loss = 0.01208386
Iteration 2567, loss = 0.01207976
Iteration 2568, loss = 0.01207173
Iteration 2569, loss = 0.01206598
Iteration 2570, loss = 0.01206029
Iteration 2571, loss = 0.01205180
Iteration 2572, loss = 0.01204702
Iteration 2573, loss = 0.01203914
Iteration 2574, loss = 0.01203249
Iteration 2575, loss = 0.01202624
Iteration 2576, loss = 0.01201878
Iteration 2577, loss = 0.01201254
Iteration 2578, loss = 0.01200546
Iteration 2579, loss = 0.01199980
Iteration 2580, loss = 0.01199443
Iteration 2581, loss = 0.01198676
Iteration 2582, loss = 0.01197966
Iteration 2583, loss = 0.01197307
Iteration 2584, loss = 0.01196702
Iteration 2585, loss = 0.01196319
Iteration 2586, loss = 0.01195504
Iteration 2587, loss = 0.01194931
Iteration 2588, loss = 0.01194239
Iteration 2589, loss = 0.01193695
Iteration 2590, loss = 0.01193182
Iteration 2591, loss = 0.01192494
Iteration 2592, loss = 0.01191951
Iteration 2593, loss = 0.01191549
Iteration 2594, loss = 0.01190813
Iteration 2595, loss = 0.01190222
Iteration 2596, loss = 0.01189677
Iteration 2597, loss = 0.01189061
Iteration 2598, loss = 0.01188482
Iteration 2599, loss = 0.01187907
Iteration 2600, loss = 0.01187366
Iteration 2601, loss = 0.01186690
Iteration 2602, loss = 0.01186175
Iteration 2603, loss = 0.01185636
Iteration 2604, loss = 0.01185097
Iteration 2605, loss = 0.01184561
Iteration 2606, loss = 0.01183953
Iteration 2607, loss = 0.01183409
Iteration 2608, loss = 0.01182933
Iteration 2609, loss = 0.01182370
Iteration 2610, loss = 0.01181743
Iteration 2611, loss = 0.01181225
Iteration 2612, loss = 0.01180644
Iteration 2613, loss = 0.01180099
Iteration 2614, loss = 0.01179478
Iteration 2615, loss = 0.01178919
Iteration 2616, loss = 0.01178250
Iteration 2617, loss = 0.01177715
Iteration 2618, loss = 0.01177032
Iteration 2619, loss = 0.01176491
Iteration 2620, loss = 0.01175810
Iteration 2621, loss = 0.01175232
Iteration 2622, loss = 0.01174620
Iteration 2623, loss = 0.01174045
Iteration 2624, loss = 0.01173408
Iteration 2625, loss = 0.01172902
Iteration 2626, loss = 0.01172246
Iteration 2627, loss = 0.01171644
Iteration 2628, loss = 0.01171064
Iteration 2629, loss = 0.01170434
Iteration 2630, loss = 0.01169847
Iteration 2631, loss = 0.01169126
Iteration 2632, loss = 0.01168627
Iteration 2633, loss = 0.01167909
Iteration 2634, loss = 0.01167346
Iteration 2635, loss = 0.01166651
Iteration 2636, loss = 0.01166048
Iteration 2637, loss = 0.01165422
Iteration 2638, loss = 0.01164988
Iteration 2639, loss = 0.01164238
Iteration 2640, loss = 0.01163659
Iteration 2641, loss = 0.01163038
Iteration 2642, loss = 0.01162414
Iteration 2643, loss = 0.01161825
Iteration 2644, loss = 0.01161194
Iteration 2645, loss = 0.01160620
Iteration 2646, loss = 0.01160093
Iteration 2647, loss = 0.01159535
Iteration 2648, loss = 0.01158959
Iteration 2649, loss = 0.01158384
Iteration 2650, loss = 0.01157839
Iteration 2651, loss = 0.01157158
Iteration 2652, loss = 0.01156571
Iteration 2653, loss = 0.01156047
Iteration 2654, loss = 0.01155363
Iteration 2655, loss = 0.01154857
Iteration 2656, loss = 0.01154269
Iteration 2657, loss = 0.01153740
Iteration 2658, loss = 0.01153080
Iteration 2659, loss = 0.01152549
Iteration 2660, loss = 0.01151895
Iteration 2661, loss = 0.01151337
Iteration 2662, loss = 0.01150771
Iteration 2663, loss = 0.01150226
Iteration 2664, loss = 0.01149679
Iteration 2665, loss = 0.01149121
Iteration 2666, loss = 0.01148649
Iteration 2667, loss = 0.01148017
Iteration 2668, loss = 0.01147500
Iteration 2669, loss = 0.01146949
Iteration 2670, loss = 0.01146334
Iteration 2671, loss = 0.01145766
Iteration 2672, loss = 0.01145407
Iteration 2673, loss = 0.01144815
Iteration 2674, loss = 0.01144314
Iteration 2675, loss = 0.01143657
Iteration 2676, loss = 0.01143111
Iteration 2677, loss = 0.01142570
Iteration 2678, loss = 0.01142044
Iteration 2679, loss = 0.01141454
Iteration 2680, loss = 0.01140887
Iteration 2681, loss = 0.01140399
Iteration 2682, loss = 0.01139890
Iteration 2683, loss = 0.01139394
Iteration 2684, loss = 0.01138741
Iteration 2685, loss = 0.01138217
Iteration 2686, loss = 0.01137685
Iteration 2687, loss = 0.01137160
Iteration 2688, loss = 0.01136726
Iteration 2689, loss = 0.01136158
Iteration 2690, loss = 0.01135611
Iteration 2691, loss = 0.01135187
Iteration 2692, loss = 0.01134624
Iteration 2693, loss = 0.01134111
Iteration 2694, loss = 0.01133790
Iteration 2695, loss = 0.01133094
Iteration 2696, loss = 0.01132533
Iteration 2697, loss = 0.01132015
Iteration 2698, loss = 0.01131475
Iteration 2699, loss = 0.01130950
Iteration 2700, loss = 0.01130410
Iteration 2701, loss = 0.01129835
Iteration 2702, loss = 0.01129252
Iteration 2703, loss = 0.01128687
Iteration 2704, loss = 0.01128215
Iteration 2705, loss = 0.01127614
Iteration 2706, loss = 0.01127135
Iteration 2707, loss = 0.01126584
Iteration 2708, loss = 0.01126046
Iteration 2709, loss = 0.01125588
Iteration 2710, loss = 0.01125134
Iteration 2711, loss = 0.01124529
Iteration 2712, loss = 0.01124044
Iteration 2713, loss = 0.01123581
Iteration 2714, loss = 0.01123469
Iteration 2715, loss = 0.01122897
Iteration 2716, loss = 0.01122210
Iteration 2717, loss = 0.01121648
Iteration 2718, loss = 0.01121089
Iteration 2719, loss = 0.01120513
Iteration 2720, loss = 0.01120061
Iteration 2721, loss = 0.01119419
Iteration 2722, loss = 0.01118860
Iteration 2723, loss = 0.01118289
Iteration 2724, loss = 0.01117755
Iteration 2725, loss = 0.01117202
Iteration 2726, loss = 0.01116649
Iteration 2727, loss = 0.01116058
Iteration 2728, loss = 0.01115461
Iteration 2729, loss = 0.01115044
Iteration 2730, loss = 0.01114417
Iteration 2731, loss = 0.01113867
Iteration 2732, loss = 0.01113221
Iteration 2733, loss = 0.01112654
Iteration 2734, loss = 0.01112022
Iteration 2735, loss = 0.01111416
Iteration 2736, loss = 0.01110974
Iteration 2737, loss = 0.01110234
Iteration 2738, loss = 0.01109801
Iteration 2739, loss = 0.01109318
Iteration 2740, loss = 0.01108594
Iteration 2741, loss = 0.01108138
Iteration 2742, loss = 0.01107583
Iteration 2743, loss = 0.01107021
Iteration 2744, loss = 0.01106504
Iteration 2745, loss = 0.01106052
Iteration 2746, loss = 0.01105465
Iteration 2747, loss = 0.01105067
Iteration 2748, loss = 0.01104642
Iteration 2749, loss = 0.01103956
Iteration 2750, loss = 0.01103397
Iteration 2751, loss = 0.01102902
Iteration 2752, loss = 0.01102304
Iteration 2753, loss = 0.01101831
Iteration 2754, loss = 0.01101246
Iteration 2755, loss = 0.01100756
Iteration 2756, loss = 0.01100235
Iteration 2757, loss = 0.01099637
Iteration 2758, loss = 0.01099105
Iteration 2759, loss = 0.01098520
Iteration 2760, loss = 0.01098169
Iteration 2761, loss = 0.01097519
Iteration 2762, loss = 0.01096995
Iteration 2763, loss = 0.01096437
Iteration 2764, loss = 0.01095984
Iteration 2765, loss = 0.01095497
Iteration 2766, loss = 0.01094932
Iteration 2767, loss = 0.01094448
Iteration 2768, loss = 0.01093918
Iteration 2769, loss = 0.01093436
Iteration 2770, loss = 0.01092937
Iteration 2771, loss = 0.01092386
Iteration 2772, loss = 0.01091890
Iteration 2773, loss = 0.01091373
Iteration 2774, loss = 0.01090909
Iteration 2775, loss = 0.01090441
Iteration 2776, loss = 0.01089889
Iteration 2777, loss = 0.01089387
Iteration 2778, loss = 0.01088875
Iteration 2779, loss = 0.01088444
Iteration 2780, loss = 0.01087931
Iteration 2781, loss = 0.01087573
Iteration 2782, loss = 0.01086932
Iteration 2783, loss = 0.01086374
Iteration 2784, loss = 0.01085924
Iteration 2785, loss = 0.01085401
Iteration 2786, loss = 0.01084821
Iteration 2787, loss = 0.01084296
Iteration 2788, loss = 0.01083765
Iteration 2789, loss = 0.01083240
Iteration 2790, loss = 0.01082753
Iteration 2791, loss = 0.01082213
Iteration 2792, loss = 0.01081664
Iteration 2793, loss = 0.01081150
Iteration 2794, loss = 0.01080566
Iteration 2795, loss = 0.01080114
Iteration 2796, loss = 0.01079564
Iteration 2797, loss = 0.01079097
Iteration 2798, loss = 0.01078606
Iteration 2799, loss = 0.01078149
Iteration 2800, loss = 0.01077611
Iteration 2801, loss = 0.01077185
Iteration 2802, loss = 0.01076618
Iteration 2803, loss = 0.01076094
Iteration 2804, loss = 0.01075571
Iteration 2805, loss = 0.01075142
Iteration 2806, loss = 0.01074538
Iteration 2807, loss = 0.01073965
Iteration 2808, loss = 0.01073365
Iteration 2809, loss = 0.01072869
Iteration 2810, loss = 0.01072259
Iteration 2811, loss = 0.01071921
Iteration 2812, loss = 0.01071291
Iteration 2813, loss = 0.01070869
Iteration 2814, loss = 0.01070234
Iteration 2815, loss = 0.01069759
Iteration 2816, loss = 0.01069458
Iteration 2817, loss = 0.01068776
Iteration 2818, loss = 0.01068313
Iteration 2819, loss = 0.01067793
Iteration 2820, loss = 0.01067369
Iteration 2821, loss = 0.01066831
Iteration 2822, loss = 0.01066369
Iteration 2823, loss = 0.01065876
Iteration 2824, loss = 0.01065416
Iteration 2825, loss = 0.01064996
Iteration 2826, loss = 0.01064726
Iteration 2827, loss = 0.01064107
Iteration 2828, loss = 0.01063651
Iteration 2829, loss = 0.01063211
Iteration 2830, loss = 0.01062779
Iteration 2831, loss = 0.01062351
Iteration 2832, loss = 0.01062108
Iteration 2833, loss = 0.01061516
Iteration 2834, loss = 0.01061177
Iteration 2835, loss = 0.01060708
Iteration 2836, loss = 0.01060182
Iteration 2837, loss = 0.01059743
Iteration 2838, loss = 0.01059308
Iteration 2839, loss = 0.01058880
Iteration 2840, loss = 0.01058535
Iteration 2841, loss = 0.01058009
Iteration 2842, loss = 0.01057498
Iteration 2843, loss = 0.01057025
Iteration 2844, loss = 0.01056598
Iteration 2845, loss = 0.01056089
Iteration 2846, loss = 0.01055603
Iteration 2847, loss = 0.01055042
Iteration 2848, loss = 0.01054532
Iteration 2849, loss = 0.01054055
Iteration 2850, loss = 0.01053512
Iteration 2851, loss = 0.01052948
Iteration 2852, loss = 0.01052314
Iteration 2853, loss = 0.01051852
Iteration 2854, loss = 0.01051420
Iteration 2855, loss = 0.01050783
Iteration 2856, loss = 0.01050263
Iteration 2857, loss = 0.01049711
Iteration 2858, loss = 0.01049299
Iteration 2859, loss = 0.01048739
Iteration 2860, loss = 0.01048231
Iteration 2861, loss = 0.01047759
Iteration 2862, loss = 0.01047370
Iteration 2863, loss = 0.01046869
Iteration 2864, loss = 0.01046479
Iteration 2865, loss = 0.01045995
Iteration 2866, loss = 0.01045530
Iteration 2867, loss = 0.01045102
Iteration 2868, loss = 0.01044628
Iteration 2869, loss = 0.01044182
Iteration 2870, loss = 0.01043713
Iteration 2871, loss = 0.01043221
Iteration 2872, loss = 0.01042740
Iteration 2873, loss = 0.01042296
Iteration 2874, loss = 0.01041843
Iteration 2875, loss = 0.01041465
Iteration 2876, loss = 0.01040912
Iteration 2877, loss = 0.01040548
Iteration 2878, loss = 0.01040097
Iteration 2879, loss = 0.01039625
Iteration 2880, loss = 0.01039160
Iteration 2881, loss = 0.01038633
Iteration 2882, loss = 0.01038197
Iteration 2883, loss = 0.01037643
Iteration 2884, loss = 0.01037261
Iteration 2885, loss = 0.01036735
Iteration 2886, loss = 0.01036303
Iteration 2887, loss = 0.01035848
Iteration 2888, loss = 0.01035407
Iteration 2889, loss = 0.01035018
Iteration 2890, loss = 0.01034562
Iteration 2891, loss = 0.01034240
Iteration 2892, loss = 0.01033657
Iteration 2893, loss = 0.01033333
Iteration 2894, loss = 0.01032707
Iteration 2895, loss = 0.01032331
Iteration 2896, loss = 0.01031861
Iteration 2897, loss = 0.01031371
Iteration 2898, loss = 0.01030973
Iteration 2899, loss = 0.01030550
Iteration 2900, loss = 0.01030083
Iteration 2901, loss = 0.01029558
Iteration 2902, loss = 0.01029124
Iteration 2903, loss = 0.01028737
Iteration 2904, loss = 0.01028211
Iteration 2905, loss = 0.01027736
Iteration 2906, loss = 0.01027283
Iteration 2907, loss = 0.01026804
Iteration 2908, loss = 0.01026348
Iteration 2909, loss = 0.01025869
Iteration 2910, loss = 0.01025418
Iteration 2911, loss = 0.01025011
Iteration 2912, loss = 0.01024519
Iteration 2913, loss = 0.01024034
Iteration 2914, loss = 0.01023635
Iteration 2915, loss = 0.01023146
Iteration 2916, loss = 0.01022671
Iteration 2917, loss = 0.01022281
Iteration 2918, loss = 0.01021828
Iteration 2919, loss = 0.01021377
Iteration 2920, loss = 0.01021005
Iteration 2921, loss = 0.01020571
Iteration 2922, loss = 0.01020128
Iteration 2923, loss = 0.01019783
Iteration 2924, loss = 0.01019334
Iteration 2925, loss = 0.01019051
Iteration 2926, loss = 0.01018516
Iteration 2927, loss = 0.01018044
Iteration 2928, loss = 0.01017618
Iteration 2929, loss = 0.01017215
Iteration 2930, loss = 0.01016633
Iteration 2931, loss = 0.01016110
Iteration 2932, loss = 0.01015756
Iteration 2933, loss = 0.01015234
Iteration 2934, loss = 0.01014790
Iteration 2935, loss = 0.01014307
Iteration 2936, loss = 0.01013756
Iteration 2937, loss = 0.01013342
Iteration 2938, loss = 0.01012806
Iteration 2939, loss = 0.01012472
Iteration 2940, loss = 0.01011898
Iteration 2941, loss = 0.01011489
Iteration 2942, loss = 0.01010988
Iteration 2943, loss = 0.01010551
Iteration 2944, loss = 0.01010089
Iteration 2945, loss = 0.01009662
Iteration 2946, loss = 0.01009326
Iteration 2947, loss = 0.01008836
Iteration 2948, loss = 0.01008431
Iteration 2949, loss = 0.01008098
Iteration 2950, loss = 0.01007641
Iteration 2951, loss = 0.01007208
Iteration 2952, loss = 0.01006825
Iteration 2953, loss = 0.01006348
Iteration 2954, loss = 0.01005858
Iteration 2955, loss = 0.01005457
Iteration 2956, loss = 0.01005044
Iteration 2957, loss = 0.01004531
Iteration 2958, loss = 0.01004108
Iteration 2959, loss = 0.01003653
Iteration 2960, loss = 0.01003222
Iteration 2961, loss = 0.01002820
Iteration 2962, loss = 0.01002382
Iteration 2963, loss = 0.01001926
Iteration 2964, loss = 0.01001461
Iteration 2965, loss = 0.01001069
Iteration 2966, loss = 0.01000690
Iteration 2967, loss = 0.01000499
Iteration 2968, loss = 0.00999895
Iteration 2969, loss = 0.00999580
Iteration 2970, loss = 0.00999039
Iteration 2971, loss = 0.00998599
Iteration 2972, loss = 0.00998158
Iteration 2973, loss = 0.00997739
Iteration 2974, loss = 0.00997295
Iteration 2975, loss = 0.00996886
Iteration 2976, loss = 0.00996469
Iteration 2977, loss = 0.00996073
Iteration 2978, loss = 0.00995688
Iteration 2979, loss = 0.00995328
Iteration 2980, loss = 0.00994958
Iteration 2981, loss = 0.00994594
Iteration 2982, loss = 0.00994289
Iteration 2983, loss = 0.00993864
Iteration 2984, loss = 0.00993450
Iteration 2985, loss = 0.00993006
Iteration 2986, loss = 0.00992600
Iteration 2987, loss = 0.00992211
Iteration 2988, loss = 0.00991782
Iteration 2989, loss = 0.00991375
Iteration 2990, loss = 0.00990946
Iteration 2991, loss = 0.00990537
Iteration 2992, loss = 0.00990108
Iteration 2993, loss = 0.00989646
Iteration 2994, loss = 0.00989213
Iteration 2995, loss = 0.00988777
Iteration 2996, loss = 0.00988374
Iteration 2997, loss = 0.00987945
Iteration 2998, loss = 0.00987445
Iteration 2999, loss = 0.00987014
Iteration 3000, loss = 0.00986557
Iteration 3001, loss = 0.00986331
Iteration 3002, loss = 0.00985709
Iteration 3003, loss = 0.00985254
Iteration 3004, loss = 0.00984821
Iteration 3005, loss = 0.00984380
Iteration 3006, loss = 0.00983928
Iteration 3007, loss = 0.00983535
Iteration 3008, loss = 0.00983138
Iteration 3009, loss = 0.00982784
Iteration 3010, loss = 0.00982466
Iteration 3011, loss = 0.00981964
Iteration 3012, loss = 0.00981385
Iteration 3013, loss = 0.00980961
Iteration 3014, loss = 0.00980484
Iteration 3015, loss = 0.00980128
Iteration 3016, loss = 0.00979718
Iteration 3017, loss = 0.00979242
Iteration 3018, loss = 0.00978723
Iteration 3019, loss = 0.00978275
Iteration 3020, loss = 0.00977832
Iteration 3021, loss = 0.00977351
Iteration 3022, loss = 0.00976880
Iteration 3023, loss = 0.00976311
Iteration 3024, loss = 0.00975907
Iteration 3025, loss = 0.00975454
Iteration 3026, loss = 0.00975087
Iteration 3027, loss = 0.00974677
Iteration 3028, loss = 0.00974135
Iteration 3029, loss = 0.00973711
Iteration 3030, loss = 0.00973308
Iteration 3031, loss = 0.00972961
Iteration 3032, loss = 0.00972464
Iteration 3033, loss = 0.00972006
Iteration 3034, loss = 0.00971537
Iteration 3035, loss = 0.00971107
Iteration 3036, loss = 0.00970620
Iteration 3037, loss = 0.00970181
Iteration 3038, loss = 0.00969691
Iteration 3039, loss = 0.00969206
Iteration 3040, loss = 0.00968776
Iteration 3041, loss = 0.00968326
Iteration 3042, loss = 0.00967847
Iteration 3043, loss = 0.00967344
Iteration 3044, loss = 0.00966939
Iteration 3045, loss = 0.00966540
Iteration 3046, loss = 0.00966181
Iteration 3047, loss = 0.00965672
Iteration 3048, loss = 0.00965422
Iteration 3049, loss = 0.00964905
Iteration 3050, loss = 0.00964549
Iteration 3051, loss = 0.00964103
Iteration 3052, loss = 0.00963722
Iteration 3053, loss = 0.00963274
Iteration 3054, loss = 0.00962864
Iteration 3055, loss = 0.00962455
Iteration 3056, loss = 0.00962049
Iteration 3057, loss = 0.00961624
Iteration 3058, loss = 0.00961216
Iteration 3059, loss = 0.00960795
Iteration 3060, loss = 0.00960459
Iteration 3061, loss = 0.00960164
Iteration 3062, loss = 0.00959692
Iteration 3063, loss = 0.00959244
Iteration 3064, loss = 0.00958856
Iteration 3065, loss = 0.00958417
Iteration 3066, loss = 0.00958006
Iteration 3067, loss = 0.00957604
Iteration 3068, loss = 0.00957203
Iteration 3069, loss = 0.00956839
Iteration 3070, loss = 0.00956435
Iteration 3071, loss = 0.00956024
Iteration 3072, loss = 0.00955680
Iteration 3073, loss = 0.00955233
Iteration 3074, loss = 0.00954874
Iteration 3075, loss = 0.00954416
Iteration 3076, loss = 0.00954030
Iteration 3077, loss = 0.00953718
Iteration 3078, loss = 0.00953179
Iteration 3079, loss = 0.00952761
Iteration 3080, loss = 0.00952469
Iteration 3081, loss = 0.00952016
Iteration 3082, loss = 0.00951645
Iteration 3083, loss = 0.00951331
Iteration 3084, loss = 0.00950880
Iteration 3085, loss = 0.00950465
Iteration 3086, loss = 0.00950171
Iteration 3087, loss = 0.00949715
Iteration 3088, loss = 0.00949301
Iteration 3089, loss = 0.00948968
Iteration 3090, loss = 0.00948505
Iteration 3091, loss = 0.00948144
Iteration 3092, loss = 0.00947699
Iteration 3093, loss = 0.00947305
Iteration 3094, loss = 0.00946927
Iteration 3095, loss = 0.00946520
Iteration 3096, loss = 0.00946089
Iteration 3097, loss = 0.00945653
Iteration 3098, loss = 0.00945183
Iteration 3099, loss = 0.00944758
Iteration 3100, loss = 0.00944359
Iteration 3101, loss = 0.00943966
Iteration 3102, loss = 0.00943554
Iteration 3103, loss = 0.00943101
Iteration 3104, loss = 0.00942765
Iteration 3105, loss = 0.00942262
Iteration 3106, loss = 0.00941938
Iteration 3107, loss = 0.00941484
Iteration 3108, loss = 0.00941166
Iteration 3109, loss = 0.00940705
Iteration 3110, loss = 0.00940309
Iteration 3111, loss = 0.00939998
Iteration 3112, loss = 0.00939549
Iteration 3113, loss = 0.00939156
Iteration 3114, loss = 0.00938763
Iteration 3115, loss = 0.00938317
Iteration 3116, loss = 0.00937899
Iteration 3117, loss = 0.00937531
Iteration 3118, loss = 0.00937111
Iteration 3119, loss = 0.00936771
Iteration 3120, loss = 0.00936312
Iteration 3121, loss = 0.00935885
Iteration 3122, loss = 0.00935508
Iteration 3123, loss = 0.00935109
Iteration 3124, loss = 0.00934696
Iteration 3125, loss = 0.00934330
Iteration 3126, loss = 0.00933935
Iteration 3127, loss = 0.00933508
Iteration 3128, loss = 0.00933087
Iteration 3129, loss = 0.00932726
Iteration 3130, loss = 0.00932293
Iteration 3131, loss = 0.00931885
Iteration 3132, loss = 0.00931506
Iteration 3133, loss = 0.00931126
Iteration 3134, loss = 0.00930704
Iteration 3135, loss = 0.00930349
Iteration 3136, loss = 0.00929925
Iteration 3137, loss = 0.00929543
Iteration 3138, loss = 0.00929340
Iteration 3139, loss = 0.00928807
Iteration 3140, loss = 0.00928387
Iteration 3141, loss = 0.00927979
Iteration 3142, loss = 0.00927575
Iteration 3143, loss = 0.00927156
Iteration 3144, loss = 0.00926893
Iteration 3145, loss = 0.00926316
Iteration 3146, loss = 0.00925913
Iteration 3147, loss = 0.00925489
Iteration 3148, loss = 0.00925066
Iteration 3149, loss = 0.00924672
Iteration 3150, loss = 0.00924281
Iteration 3151, loss = 0.00924028
Iteration 3152, loss = 0.00923540
Iteration 3153, loss = 0.00923121
Iteration 3154, loss = 0.00922779
Iteration 3155, loss = 0.00922382
Iteration 3156, loss = 0.00921982
Iteration 3157, loss = 0.00921655
Iteration 3158, loss = 0.00921258
Iteration 3159, loss = 0.00920851
Iteration 3160, loss = 0.00920469
Iteration 3161, loss = 0.00920076
Iteration 3162, loss = 0.00919683
Iteration 3163, loss = 0.00919238
Iteration 3164, loss = 0.00918825
Iteration 3165, loss = 0.00918409
Iteration 3166, loss = 0.00918132
Iteration 3167, loss = 0.00917627
Iteration 3168, loss = 0.00917276
Iteration 3169, loss = 0.00916939
Iteration 3170, loss = 0.00916650
Iteration 3171, loss = 0.00916082
Iteration 3172, loss = 0.00915625
Iteration 3173, loss = 0.00915291
Iteration 3174, loss = 0.00914924
Iteration 3175, loss = 0.00914559
Iteration 3176, loss = 0.00914090
Iteration 3177, loss = 0.00913692
Iteration 3178, loss = 0.00913353
Iteration 3179, loss = 0.00912934
Iteration 3180, loss = 0.00912558
Iteration 3181, loss = 0.00912222
Iteration 3182, loss = 0.00911732
Iteration 3183, loss = 0.00911397
Iteration 3184, loss = 0.00910929
Iteration 3185, loss = 0.00910549
Iteration 3186, loss = 0.00910131
Iteration 3187, loss = 0.00909786
Iteration 3188, loss = 0.00909349
Iteration 3189, loss = 0.00908936
Iteration 3190, loss = 0.00908582
Iteration 3191, loss = 0.00908142
Iteration 3192, loss = 0.00907751
Iteration 3193, loss = 0.00907356
Iteration 3194, loss = 0.00907003
Iteration 3195, loss = 0.00906604
Iteration 3196, loss = 0.00906246
Iteration 3197, loss = 0.00905914
Iteration 3198, loss = 0.00905493
Iteration 3199, loss = 0.00905097
Iteration 3200, loss = 0.00904807
Iteration 3201, loss = 0.00904397
Iteration 3202, loss = 0.00903990
Iteration 3203, loss = 0.00903629
Iteration 3204, loss = 0.00903248
Iteration 3205, loss = 0.00902877
Iteration 3206, loss = 0.00902503
Iteration 3207, loss = 0.00902139
Iteration 3208, loss = 0.00901711
Iteration 3209, loss = 0.00901525
Iteration 3210, loss = 0.00901032
Iteration 3211, loss = 0.00900647
Iteration 3212, loss = 0.00900251
Iteration 3213, loss = 0.00899875
Iteration 3214, loss = 0.00899425
Iteration 3215, loss = 0.00899044
Iteration 3216, loss = 0.00898670
Iteration 3217, loss = 0.00898255
Iteration 3218, loss = 0.00897824
Iteration 3219, loss = 0.00897496
Iteration 3220, loss = 0.00897126
Iteration 3221, loss = 0.00896829
Iteration 3222, loss = 0.00896395
Iteration 3223, loss = 0.00896089
Iteration 3224, loss = 0.00895705
Iteration 3225, loss = 0.00895369
Iteration 3226, loss = 0.00895002
Iteration 3227, loss = 0.00894616
Iteration 3228, loss = 0.00894300
Iteration 3229, loss = 0.00893940
Iteration 3230, loss = 0.00893572
Iteration 3231, loss = 0.00893184
Iteration 3232, loss = 0.00892841
Iteration 3233, loss = 0.00892469
Iteration 3234, loss = 0.00892067
Iteration 3235, loss = 0.00891756
Iteration 3236, loss = 0.00891377
Iteration 3237, loss = 0.00890951
Iteration 3238, loss = 0.00890501
Iteration 3239, loss = 0.00890215
Iteration 3240, loss = 0.00889837
Iteration 3241, loss = 0.00889465
Iteration 3242, loss = 0.00889039
Iteration 3243, loss = 0.00888666
Iteration 3244, loss = 0.00888300
Iteration 3245, loss = 0.00887954
Iteration 3246, loss = 0.00887564
Iteration 3247, loss = 0.00887193
Iteration 3248, loss = 0.00886758
Iteration 3249, loss = 0.00886400
Iteration 3250, loss = 0.00886021
Iteration 3251, loss = 0.00885653
Iteration 3252, loss = 0.00885269
Iteration 3253, loss = 0.00884894
Iteration 3254, loss = 0.00884565
Iteration 3255, loss = 0.00884215
Iteration 3256, loss = 0.00883827
Iteration 3257, loss = 0.00883454
Iteration 3258, loss = 0.00883077
Iteration 3259, loss = 0.00882783
Iteration 3260, loss = 0.00882417
Iteration 3261, loss = 0.00882052
Iteration 3262, loss = 0.00881691
Iteration 3263, loss = 0.00881302
Iteration 3264, loss = 0.00880960
Iteration 3265, loss = 0.00880617
Iteration 3266, loss = 0.00880255
Iteration 3267, loss = 0.00879904
Iteration 3268, loss = 0.00879500
Iteration 3269, loss = 0.00879126
Iteration 3270, loss = 0.00878794
Iteration 3271, loss = 0.00878447
Iteration 3272, loss = 0.00878059
Iteration 3273, loss = 0.00877777
Iteration 3274, loss = 0.00877334
Iteration 3275, loss = 0.00877002
Iteration 3276, loss = 0.00876630
Iteration 3277, loss = 0.00876351
Iteration 3278, loss = 0.00876009
Iteration 3279, loss = 0.00875621
Iteration 3280, loss = 0.00875229
Iteration 3281, loss = 0.00874919
Iteration 3282, loss = 0.00874530
Iteration 3283, loss = 0.00874165
Iteration 3284, loss = 0.00873827
Iteration 3285, loss = 0.00873437
Iteration 3286, loss = 0.00873051
Iteration 3287, loss = 0.00872683
Iteration 3288, loss = 0.00872384
Iteration 3289, loss = 0.00872000
Iteration 3290, loss = 0.00871646
Iteration 3291, loss = 0.00871240
Iteration 3292, loss = 0.00870871
Iteration 3293, loss = 0.00870530
Iteration 3294, loss = 0.00870136
Iteration 3295, loss = 0.00869844
Iteration 3296, loss = 0.00869455
Iteration 3297, loss = 0.00869039
Iteration 3298, loss = 0.00868658
Iteration 3299, loss = 0.00868307
Iteration 3300, loss = 0.00867958
Iteration 3301, loss = 0.00867619
Iteration 3302, loss = 0.00867206
Iteration 3303, loss = 0.00866870
Iteration 3304, loss = 0.00866520
Iteration 3305, loss = 0.00866168
Iteration 3306, loss = 0.00865817
Iteration 3307, loss = 0.00865429
Iteration 3308, loss = 0.00865095
Iteration 3309, loss = 0.00864711
Iteration 3310, loss = 0.00864359
Iteration 3311, loss = 0.00863988
Iteration 3312, loss = 0.00863664
Iteration 3313, loss = 0.00863314
Iteration 3314, loss = 0.00862981
Iteration 3315, loss = 0.00862637
Iteration 3316, loss = 0.00862308
Iteration 3317, loss = 0.00861917
Iteration 3318, loss = 0.00861593
Iteration 3319, loss = 0.00861238
Iteration 3320, loss = 0.00860894
Iteration 3321, loss = 0.00860498
Iteration 3322, loss = 0.00860233
Iteration 3323, loss = 0.00859836
Iteration 3324, loss = 0.00859495
Iteration 3325, loss = 0.00859161
Iteration 3326, loss = 0.00858802
Iteration 3327, loss = 0.00858513
Iteration 3328, loss = 0.00858252
Iteration 3329, loss = 0.00857894
Iteration 3330, loss = 0.00857580
Iteration 3331, loss = 0.00857258
Iteration 3332, loss = 0.00856918
Iteration 3333, loss = 0.00856584
Iteration 3334, loss = 0.00856254
Iteration 3335, loss = 0.00855927
Iteration 3336, loss = 0.00855624
Iteration 3337, loss = 0.00855327
Iteration 3338, loss = 0.00855031
Iteration 3339, loss = 0.00854849
Iteration 3340, loss = 0.00854464
Iteration 3341, loss = 0.00854123
Iteration 3342, loss = 0.00853817
Iteration 3343, loss = 0.00853486
Iteration 3344, loss = 0.00853173
Iteration 3345, loss = 0.00852848
Iteration 3346, loss = 0.00852555
Iteration 3347, loss = 0.00852171
Iteration 3348, loss = 0.00851872
Iteration 3349, loss = 0.00851526
Iteration 3350, loss = 0.00851181
Iteration 3351, loss = 0.00850817
Iteration 3352, loss = 0.00850454
Iteration 3353, loss = 0.00850138
Iteration 3354, loss = 0.00849772
Iteration 3355, loss = 0.00849421
Iteration 3356, loss = 0.00849130
Iteration 3357, loss = 0.00848770
Iteration 3358, loss = 0.00848349
Iteration 3359, loss = 0.00848014
Iteration 3360, loss = 0.00847637
Iteration 3361, loss = 0.00847257
Iteration 3362, loss = 0.00846989
Iteration 3363, loss = 0.00846571
Iteration 3364, loss = 0.00846270
Iteration 3365, loss = 0.00845874
Iteration 3366, loss = 0.00845541
Iteration 3367, loss = 0.00845215
Iteration 3368, loss = 0.00844846
Iteration 3369, loss = 0.00844441
Iteration 3370, loss = 0.00844066
Iteration 3371, loss = 0.00843740
Iteration 3372, loss = 0.00843289
Iteration 3373, loss = 0.00843045
Iteration 3374, loss = 0.00842612
Iteration 3375, loss = 0.00842258
Iteration 3376, loss = 0.00841949
Iteration 3377, loss = 0.00841595
Iteration 3378, loss = 0.00841221
Iteration 3379, loss = 0.00840857
Iteration 3380, loss = 0.00840524
Iteration 3381, loss = 0.00840127
Iteration 3382, loss = 0.00839873
Iteration 3383, loss = 0.00839580
Iteration 3384, loss = 0.00839139
Iteration 3385, loss = 0.00838816
Iteration 3386, loss = 0.00838480
Iteration 3387, loss = 0.00838165
Iteration 3388, loss = 0.00837844
Iteration 3389, loss = 0.00837574
Iteration 3390, loss = 0.00837274
Iteration 3391, loss = 0.00836919
Iteration 3392, loss = 0.00836615
Iteration 3393, loss = 0.00836315
Iteration 3394, loss = 0.00835990
Iteration 3395, loss = 0.00835674
Iteration 3396, loss = 0.00835360
Iteration 3397, loss = 0.00835217
Iteration 3398, loss = 0.00834911
Iteration 3399, loss = 0.00834495
Iteration 3400, loss = 0.00834161
Iteration 3401, loss = 0.00833845
Iteration 3402, loss = 0.00833502
Iteration 3403, loss = 0.00833181
Iteration 3404, loss = 0.00832866
Iteration 3405, loss = 0.00832576
Iteration 3406, loss = 0.00832240
Iteration 3407, loss = 0.00831883
Iteration 3408, loss = 0.00831581
Iteration 3409, loss = 0.00831274
Iteration 3410, loss = 0.00830984
Iteration 3411, loss = 0.00830692
Iteration 3412, loss = 0.00830358
Iteration 3413, loss = 0.00830056
Iteration 3414, loss = 0.00829769
Iteration 3415, loss = 0.00829499
Iteration 3416, loss = 0.00829207
Iteration 3417, loss = 0.00828939
Iteration 3418, loss = 0.00828551
Iteration 3419, loss = 0.00828221
Iteration 3420, loss = 0.00827937
Iteration 3421, loss = 0.00827597
Iteration 3422, loss = 0.00827298
Iteration 3423, loss = 0.00826990
Iteration 3424, loss = 0.00826688
Iteration 3425, loss = 0.00826420
Iteration 3426, loss = 0.00826220
Iteration 3427, loss = 0.00826016
Iteration 3428, loss = 0.00825597
Iteration 3429, loss = 0.00825257
Iteration 3430, loss = 0.00825001
Iteration 3431, loss = 0.00824685
Iteration 3432, loss = 0.00824371
Iteration 3433, loss = 0.00823975
Iteration 3434, loss = 0.00823626
Iteration 3435, loss = 0.00823216
Iteration 3436, loss = 0.00822948
Iteration 3437, loss = 0.00822520
Iteration 3438, loss = 0.00822207
Iteration 3439, loss = 0.00821823
Iteration 3440, loss = 0.00821500
Iteration 3441, loss = 0.00821167
Iteration 3442, loss = 0.00820842
Iteration 3443, loss = 0.00820531
Iteration 3444, loss = 0.00820216
Iteration 3445, loss = 0.00819932
Iteration 3446, loss = 0.00819631
Iteration 3447, loss = 0.00819312
Iteration 3448, loss = 0.00819012
Iteration 3449, loss = 0.00818740
Iteration 3450, loss = 0.00818431
Iteration 3451, loss = 0.00818167
Iteration 3452, loss = 0.00817890
Iteration 3453, loss = 0.00817621
Iteration 3454, loss = 0.00817343
Iteration 3455, loss = 0.00817048
Iteration 3456, loss = 0.00816898
Iteration 3457, loss = 0.00816529
Iteration 3458, loss = 0.00816153
Iteration 3459, loss = 0.00815833
Iteration 3460, loss = 0.00815496
Iteration 3461, loss = 0.00815159
Iteration 3462, loss = 0.00814846
Iteration 3463, loss = 0.00814561
Iteration 3464, loss = 0.00814237
Iteration 3465, loss = 0.00813870
Iteration 3466, loss = 0.00813610
Iteration 3467, loss = 0.00813245
Iteration 3468, loss = 0.00812895
Iteration 3469, loss = 0.00812544
Iteration 3470, loss = 0.00812326
Iteration 3471, loss = 0.00811895
Iteration 3472, loss = 0.00811542
Iteration 3473, loss = 0.00811331
Iteration 3474, loss = 0.00810874
Iteration 3475, loss = 0.00810565
Iteration 3476, loss = 0.00810245
Iteration 3477, loss = 0.00809909
Iteration 3478, loss = 0.00809627
Iteration 3479, loss = 0.00809318
Iteration 3480, loss = 0.00808998
Iteration 3481, loss = 0.00808722
Iteration 3482, loss = 0.00808412
Iteration 3483, loss = 0.00808165
Iteration 3484, loss = 0.00807847
Iteration 3485, loss = 0.00807656
Iteration 3486, loss = 0.00807336
Iteration 3487, loss = 0.00807021
Iteration 3488, loss = 0.00806740
Iteration 3489, loss = 0.00806450
Iteration 3490, loss = 0.00806240
Iteration 3491, loss = 0.00805971
Iteration 3492, loss = 0.00805670
Iteration 3493, loss = 0.00805331
Iteration 3494, loss = 0.00805042
Iteration 3495, loss = 0.00804721
Iteration 3496, loss = 0.00804432
Iteration 3497, loss = 0.00804089
Iteration 3498, loss = 0.00803875
Iteration 3499, loss = 0.00803511
Iteration 3500, loss = 0.00803153
Iteration 3501, loss = 0.00802717
Iteration 3502, loss = 0.00802366
Iteration 3503, loss = 0.00802088
Iteration 3504, loss = 0.00801690
Iteration 3505, loss = 0.00801416
Iteration 3506, loss = 0.00800997
Iteration 3507, loss = 0.00800636
Iteration 3508, loss = 0.00800297
Iteration 3509, loss = 0.00799922
Iteration 3510, loss = 0.00799691
Iteration 3511, loss = 0.00799291
Iteration 3512, loss = 0.00798931
Iteration 3513, loss = 0.00798636
Iteration 3514, loss = 0.00798351
Iteration 3515, loss = 0.00798015
Iteration 3516, loss = 0.00797702
Iteration 3517, loss = 0.00797378
Iteration 3518, loss = 0.00797102
Iteration 3519, loss = 0.00796793
Iteration 3520, loss = 0.00796512
Iteration 3521, loss = 0.00796185
Iteration 3522, loss = 0.00795920
Iteration 3523, loss = 0.00795612
Iteration 3524, loss = 0.00795368
Iteration 3525, loss = 0.00795024
Iteration 3526, loss = 0.00794745
Iteration 3527, loss = 0.00794463
Iteration 3528, loss = 0.00794143
Iteration 3529, loss = 0.00793808
Iteration 3530, loss = 0.00793569
Iteration 3531, loss = 0.00793165
Iteration 3532, loss = 0.00792951
Iteration 3533, loss = 0.00792609
Iteration 3534, loss = 0.00792309
Iteration 3535, loss = 0.00792034
Iteration 3536, loss = 0.00791833
Iteration 3537, loss = 0.00791571
Iteration 3538, loss = 0.00791220
Iteration 3539, loss = 0.00790850
Iteration 3540, loss = 0.00790548
Iteration 3541, loss = 0.00790268
Iteration 3542, loss = 0.00789915
Iteration 3543, loss = 0.00789592
Iteration 3544, loss = 0.00789260
Iteration 3545, loss = 0.00788887
Iteration 3546, loss = 0.00788613
Iteration 3547, loss = 0.00788254
Iteration 3548, loss = 0.00787936
Iteration 3549, loss = 0.00787576
Iteration 3550, loss = 0.00787277
Iteration 3551, loss = 0.00786926
Iteration 3552, loss = 0.00786628
Iteration 3553, loss = 0.00786164
Iteration 3554, loss = 0.00785847
Iteration 3555, loss = 0.00785486
Iteration 3556, loss = 0.00785180
Iteration 3557, loss = 0.00784827
Iteration 3558, loss = 0.00784497
Iteration 3559, loss = 0.00784194
Iteration 3560, loss = 0.00783887
Iteration 3561, loss = 0.00783588
Iteration 3562, loss = 0.00783326
Iteration 3563, loss = 0.00783006
Iteration 3564, loss = 0.00782668
Iteration 3565, loss = 0.00782376
Iteration 3566, loss = 0.00782048
Iteration 3567, loss = 0.00781753
Iteration 3568, loss = 0.00781464
Iteration 3569, loss = 0.00781179
Iteration 3570, loss = 0.00780774
Iteration 3571, loss = 0.00780471
Iteration 3572, loss = 0.00780195
Iteration 3573, loss = 0.00779824
Iteration 3574, loss = 0.00779532
Iteration 3575, loss = 0.00779216
Iteration 3576, loss = 0.00778901
Iteration 3577, loss = 0.00778680
Iteration 3578, loss = 0.00778321
Iteration 3579, loss = 0.00777989
Iteration 3580, loss = 0.00777725
Iteration 3581, loss = 0.00777425
Iteration 3582, loss = 0.00777149
Iteration 3583, loss = 0.00776845
Iteration 3584, loss = 0.00776579
Iteration 3585, loss = 0.00776300
Iteration 3586, loss = 0.00776035
Iteration 3587, loss = 0.00775790
Iteration 3588, loss = 0.00775550
Iteration 3589, loss = 0.00775311
Iteration 3590, loss = 0.00775068
Iteration 3591, loss = 0.00774777
Iteration 3592, loss = 0.00774515
Iteration 3593, loss = 0.00774243
Iteration 3594, loss = 0.00773965
Iteration 3595, loss = 0.00773687
Iteration 3596, loss = 0.00773460
Iteration 3597, loss = 0.00773308
Iteration 3598, loss = 0.00773002
Iteration 3599, loss = 0.00772720
Iteration 3600, loss = 0.00772495
Iteration 3601, loss = 0.00772284
Iteration 3602, loss = 0.00772012
Iteration 3603, loss = 0.00771774
Iteration 3604, loss = 0.00771558
Iteration 3605, loss = 0.00771223
Iteration 3606, loss = 0.00770936
Iteration 3607, loss = 0.00770626
Iteration 3608, loss = 0.00770380
Iteration 3609, loss = 0.00770070
Iteration 3610, loss = 0.00769744
Iteration 3611, loss = 0.00769483
Iteration 3612, loss = 0.00769194
Iteration 3613, loss = 0.00768894
Iteration 3614, loss = 0.00768633
Iteration 3615, loss = 0.00768341
Iteration 3616, loss = 0.00768101
Iteration 3617, loss = 0.00767733
Iteration 3618, loss = 0.00767422
Iteration 3619, loss = 0.00767095
Iteration 3620, loss = 0.00766755
Iteration 3621, loss = 0.00766433
Iteration 3622, loss = 0.00766160
Iteration 3623, loss = 0.00765779
Iteration 3624, loss = 0.00765583
Iteration 3625, loss = 0.00765198
Iteration 3626, loss = 0.00764879
Iteration 3627, loss = 0.00764637
Iteration 3628, loss = 0.00764344
Iteration 3629, loss = 0.00764033
Iteration 3630, loss = 0.00763792
Iteration 3631, loss = 0.00763493
Iteration 3632, loss = 0.00763206
Iteration 3633, loss = 0.00763033
Iteration 3634, loss = 0.00762629
Iteration 3635, loss = 0.00762345
Iteration 3636, loss = 0.00762045
Iteration 3637, loss = 0.00761748
Iteration 3638, loss = 0.00761546
Iteration 3639, loss = 0.00761197
Iteration 3640, loss = 0.00760923
Iteration 3641, loss = 0.00760638
Iteration 3642, loss = 0.00760395
Iteration 3643, loss = 0.00760100
Iteration 3644, loss = 0.00759842
Iteration 3645, loss = 0.00759538
Iteration 3646, loss = 0.00759250
Iteration 3647, loss = 0.00758972
Iteration 3648, loss = 0.00758704
Iteration 3649, loss = 0.00758422
Iteration 3650, loss = 0.00758105
Iteration 3651, loss = 0.00757811
Iteration 3652, loss = 0.00757568
Iteration 3653, loss = 0.00757278
Iteration 3654, loss = 0.00756972
Iteration 3655, loss = 0.00756560
Iteration 3656, loss = 0.00756270
Iteration 3657, loss = 0.00755954
Iteration 3658, loss = 0.00755603
Iteration 3659, loss = 0.00755338
Iteration 3660, loss = 0.00755036
Iteration 3661, loss = 0.00754751
Iteration 3662, loss = 0.00754440
Iteration 3663, loss = 0.00754192
Iteration 3664, loss = 0.00753887
Iteration 3665, loss = 0.00753587
Iteration 3666, loss = 0.00753376
Iteration 3667, loss = 0.00753050
Iteration 3668, loss = 0.00752781
Iteration 3669, loss = 0.00752452
Iteration 3670, loss = 0.00752168
Iteration 3671, loss = 0.00751901
Iteration 3672, loss = 0.00751602
Iteration 3673, loss = 0.00751311
Iteration 3674, loss = 0.00751071
Iteration 3675, loss = 0.00750801
Iteration 3676, loss = 0.00750531
Iteration 3677, loss = 0.00750247
Iteration 3678, loss = 0.00750008
Iteration 3679, loss = 0.00749695
Iteration 3680, loss = 0.00749388
Iteration 3681, loss = 0.00749140
Iteration 3682, loss = 0.00748834
Iteration 3683, loss = 0.00748565
Iteration 3684, loss = 0.00748284
Iteration 3685, loss = 0.00748038
Iteration 3686, loss = 0.00747688
Iteration 3687, loss = 0.00747411
Iteration 3688, loss = 0.00747124
Iteration 3689, loss = 0.00746868
Iteration 3690, loss = 0.00746544
Iteration 3691, loss = 0.00746321
Iteration 3692, loss = 0.00746047
Iteration 3693, loss = 0.00745760
Iteration 3694, loss = 0.00745525
Iteration 3695, loss = 0.00745347
Iteration 3696, loss = 0.00745138
Iteration 3697, loss = 0.00744765
Iteration 3698, loss = 0.00744423
Iteration 3699, loss = 0.00744181
Iteration 3700, loss = 0.00743832
Iteration 3701, loss = 0.00743562
Iteration 3702, loss = 0.00743253
Iteration 3703, loss = 0.00742956
Iteration 3704, loss = 0.00742611
Iteration 3705, loss = 0.00742350
Iteration 3706, loss = 0.00742093
Iteration 3707, loss = 0.00741768
Iteration 3708, loss = 0.00741431
Iteration 3709, loss = 0.00741140
Iteration 3710, loss = 0.00740845
Iteration 3711, loss = 0.00740629
Iteration 3712, loss = 0.00740312
Iteration 3713, loss = 0.00740024
Iteration 3714, loss = 0.00739710
Iteration 3715, loss = 0.00739423
Iteration 3716, loss = 0.00739144
Iteration 3717, loss = 0.00738798
Iteration 3718, loss = 0.00738498
Iteration 3719, loss = 0.00738307
Iteration 3720, loss = 0.00737930
Iteration 3721, loss = 0.00737664
Iteration 3722, loss = 0.00737408
Iteration 3723, loss = 0.00737124
Iteration 3724, loss = 0.00736829
Iteration 3725, loss = 0.00736584
Iteration 3726, loss = 0.00736370
Iteration 3727, loss = 0.00735979
Iteration 3728, loss = 0.00735745
Iteration 3729, loss = 0.00735431
Iteration 3730, loss = 0.00735161
Iteration 3731, loss = 0.00734855
Iteration 3732, loss = 0.00734615
Iteration 3733, loss = 0.00734335
Iteration 3734, loss = 0.00734069
Iteration 3735, loss = 0.00733784
Iteration 3736, loss = 0.00733504
Iteration 3737, loss = 0.00733238
Iteration 3738, loss = 0.00732936
Iteration 3739, loss = 0.00732635
Iteration 3740, loss = 0.00732376
Iteration 3741, loss = 0.00732064
Iteration 3742, loss = 0.00731793
Iteration 3743, loss = 0.00731568
Iteration 3744, loss = 0.00731226
Iteration 3745, loss = 0.00730979
Iteration 3746, loss = 0.00730689
Iteration 3747, loss = 0.00730412
Iteration 3748, loss = 0.00730148
Iteration 3749, loss = 0.00729870
Iteration 3750, loss = 0.00729606
Iteration 3751, loss = 0.00729341
Iteration 3752, loss = 0.00729165
Iteration 3753, loss = 0.00728834
Iteration 3754, loss = 0.00728575
Iteration 3755, loss = 0.00728348
Iteration 3756, loss = 0.00728071
Iteration 3757, loss = 0.00727799
Iteration 3758, loss = 0.00727503
Iteration 3759, loss = 0.00727269
Iteration 3760, loss = 0.00727083
Iteration 3761, loss = 0.00726744
Iteration 3762, loss = 0.00726523
Iteration 3763, loss = 0.00726234
Iteration 3764, loss = 0.00725974
Iteration 3765, loss = 0.00725713
Iteration 3766, loss = 0.00725473
Iteration 3767, loss = 0.00725212
Iteration 3768, loss = 0.00724934
Iteration 3769, loss = 0.00724635
Iteration 3770, loss = 0.00724449
Iteration 3771, loss = 0.00724184
Iteration 3772, loss = 0.00723857
Iteration 3773, loss = 0.00723542
Iteration 3774, loss = 0.00723327
Iteration 3775, loss = 0.00723064
Iteration 3776, loss = 0.00722742
Iteration 3777, loss = 0.00722486
Iteration 3778, loss = 0.00722218
Iteration 3779, loss = 0.00722026
Iteration 3780, loss = 0.00721728
Iteration 3781, loss = 0.00721442
Iteration 3782, loss = 0.00721245
Iteration 3783, loss = 0.00720927
Iteration 3784, loss = 0.00720628
Iteration 3785, loss = 0.00720387
Iteration 3786, loss = 0.00720283
Iteration 3787, loss = 0.00719864
Iteration 3788, loss = 0.00719561
Iteration 3789, loss = 0.00719278
Iteration 3790, loss = 0.00719018
Iteration 3791, loss = 0.00718736
Iteration 3792, loss = 0.00718477
Iteration 3793, loss = 0.00718254
Iteration 3794, loss = 0.00717957
Iteration 3795, loss = 0.00717701
Iteration 3796, loss = 0.00717432
Iteration 3797, loss = 0.00717168
Iteration 3798, loss = 0.00716903
Iteration 3799, loss = 0.00716677
Iteration 3800, loss = 0.00716439
Iteration 3801, loss = 0.00716176
Iteration 3802, loss = 0.00715991
Iteration 3803, loss = 0.00715704
Iteration 3804, loss = 0.00715457
Iteration 3805, loss = 0.00715250
Iteration 3806, loss = 0.00715015
Iteration 3807, loss = 0.00714690
Iteration 3808, loss = 0.00714489
Iteration 3809, loss = 0.00714273
Iteration 3810, loss = 0.00713899
Iteration 3811, loss = 0.00713725
Iteration 3812, loss = 0.00713399
Iteration 3813, loss = 0.00713159
Iteration 3814, loss = 0.00712884
Iteration 3815, loss = 0.00712589
Iteration 3816, loss = 0.00712486
Iteration 3817, loss = 0.00712081
Iteration 3818, loss = 0.00711797
Iteration 3819, loss = 0.00711518
Iteration 3820, loss = 0.00711309
Iteration 3821, loss = 0.00711002
Iteration 3822, loss = 0.00710746
Iteration 3823, loss = 0.00710479
Iteration 3824, loss = 0.00710237
Iteration 3825, loss = 0.00709990
Iteration 3826, loss = 0.00709851
Iteration 3827, loss = 0.00709562
Iteration 3828, loss = 0.00709310
Iteration 3829, loss = 0.00709084
Iteration 3830, loss = 0.00708814
Iteration 3831, loss = 0.00708571
Iteration 3832, loss = 0.00708353
Iteration 3833, loss = 0.00708065
Iteration 3834, loss = 0.00707806
Iteration 3835, loss = 0.00707547
Iteration 3836, loss = 0.00707304
Iteration 3837, loss = 0.00707132
Iteration 3838, loss = 0.00706751
Iteration 3839, loss = 0.00706495
Iteration 3840, loss = 0.00706265
Iteration 3841, loss = 0.00705937
Iteration 3842, loss = 0.00705713
Iteration 3843, loss = 0.00705383
Iteration 3844, loss = 0.00705091
Iteration 3845, loss = 0.00704837
Iteration 3846, loss = 0.00704522
Iteration 3847, loss = 0.00704307
Iteration 3848, loss = 0.00704063
Iteration 3849, loss = 0.00703820
Iteration 3850, loss = 0.00703521
Iteration 3851, loss = 0.00703340
Iteration 3852, loss = 0.00703079
Iteration 3853, loss = 0.00702857
Iteration 3854, loss = 0.00702607
Iteration 3855, loss = 0.00702375
Iteration 3856, loss = 0.00702133
Iteration 3857, loss = 0.00701905
Iteration 3858, loss = 0.00701665
Iteration 3859, loss = 0.00701421
Iteration 3860, loss = 0.00701192
Iteration 3861, loss = 0.00700943
Iteration 3862, loss = 0.00700758
Iteration 3863, loss = 0.00700468
Iteration 3864, loss = 0.00700201
Iteration 3865, loss = 0.00699957
Iteration 3866, loss = 0.00699740
Iteration 3867, loss = 0.00699438
Iteration 3868, loss = 0.00699195
Iteration 3869, loss = 0.00698957
Iteration 3870, loss = 0.00698669
Iteration 3871, loss = 0.00698414
Iteration 3872, loss = 0.00698163
Iteration 3873, loss = 0.00697915
Iteration 3874, loss = 0.00697672
Iteration 3875, loss = 0.00697410
Iteration 3876, loss = 0.00697169
Iteration 3877, loss = 0.00696915
Iteration 3878, loss = 0.00696652
Iteration 3879, loss = 0.00696489
Iteration 3880, loss = 0.00696212
Iteration 3881, loss = 0.00695932
Iteration 3882, loss = 0.00695702
Iteration 3883, loss = 0.00695440
Iteration 3884, loss = 0.00695196
Iteration 3885, loss = 0.00694910
Iteration 3886, loss = 0.00694680
Iteration 3887, loss = 0.00694429
Iteration 3888, loss = 0.00694157
Iteration 3889, loss = 0.00693915
Iteration 3890, loss = 0.00693706
Iteration 3891, loss = 0.00693425
Iteration 3892, loss = 0.00693209
Iteration 3893, loss = 0.00692940
Iteration 3894, loss = 0.00692721
Iteration 3895, loss = 0.00692427
Iteration 3896, loss = 0.00692201
Iteration 3897, loss = 0.00691943
Iteration 3898, loss = 0.00691709
Iteration 3899, loss = 0.00691446
Iteration 3900, loss = 0.00691199
Iteration 3901, loss = 0.00690981
Iteration 3902, loss = 0.00690791
Iteration 3903, loss = 0.00690485
Iteration 3904, loss = 0.00690228
Iteration 3905, loss = 0.00690048
Iteration 3906, loss = 0.00689766
Iteration 3907, loss = 0.00689618
Iteration 3908, loss = 0.00689330
Iteration 3909, loss = 0.00689076
Iteration 3910, loss = 0.00688877
Iteration 3911, loss = 0.00688668
Iteration 3912, loss = 0.00688344
Iteration 3913, loss = 0.00688123
Iteration 3914, loss = 0.00687833
Iteration 3915, loss = 0.00687565
Iteration 3916, loss = 0.00687349
Iteration 3917, loss = 0.00687070
Iteration 3918, loss = 0.00686834
Iteration 3919, loss = 0.00686592
Iteration 3920, loss = 0.00686356
Iteration 3921, loss = 0.00686157
Iteration 3922, loss = 0.00685890
Iteration 3923, loss = 0.00685678
Iteration 3924, loss = 0.00685405
Iteration 3925, loss = 0.00685148
Iteration 3926, loss = 0.00684906
Iteration 3927, loss = 0.00684654
Iteration 3928, loss = 0.00684525
Iteration 3929, loss = 0.00684235
Iteration 3930, loss = 0.00683946
Iteration 3931, loss = 0.00683752
Iteration 3932, loss = 0.00683486
Iteration 3933, loss = 0.00683246
Iteration 3934, loss = 0.00683003
Iteration 3935, loss = 0.00682784
Iteration 3936, loss = 0.00682577
Iteration 3937, loss = 0.00682479
Iteration 3938, loss = 0.00682089
Iteration 3939, loss = 0.00681854
Iteration 3940, loss = 0.00681559
Iteration 3941, loss = 0.00681349
Iteration 3942, loss = 0.00681114
Iteration 3943, loss = 0.00680858
Iteration 3944, loss = 0.00680586
Iteration 3945, loss = 0.00680349
Iteration 3946, loss = 0.00680124
Iteration 3947, loss = 0.00679910
Iteration 3948, loss = 0.00679671
Iteration 3949, loss = 0.00679405
Iteration 3950, loss = 0.00679216
Iteration 3951, loss = 0.00678958
Iteration 3952, loss = 0.00678750
Iteration 3953, loss = 0.00678525
Iteration 3954, loss = 0.00678388
Iteration 3955, loss = 0.00678118
Iteration 3956, loss = 0.00677919
Iteration 3957, loss = 0.00677702
Iteration 3958, loss = 0.00677459
Iteration 3959, loss = 0.00677237
Iteration 3960, loss = 0.00677077
Iteration 3961, loss = 0.00676772
Iteration 3962, loss = 0.00676540
Iteration 3963, loss = 0.00676278
Iteration 3964, loss = 0.00676056
Iteration 3965, loss = 0.00675787
Iteration 3966, loss = 0.00675551
Iteration 3967, loss = 0.00675292
Iteration 3968, loss = 0.00675027
Iteration 3969, loss = 0.00674741
Iteration 3970, loss = 0.00674488
Iteration 3971, loss = 0.00674348
Iteration 3972, loss = 0.00674008
Iteration 3973, loss = 0.00673793
Iteration 3974, loss = 0.00673581
Iteration 3975, loss = 0.00673276
Iteration 3976, loss = 0.00673041
Iteration 3977, loss = 0.00672846
Iteration 3978, loss = 0.00672577
Iteration 3979, loss = 0.00672327
Iteration 3980, loss = 0.00672122
Iteration 3981, loss = 0.00671902
Iteration 3982, loss = 0.00671711
Iteration 3983, loss = 0.00671477
Iteration 3984, loss = 0.00671335
Iteration 3985, loss = 0.00671036
Iteration 3986, loss = 0.00670788
Iteration 3987, loss = 0.00670567
Iteration 3988, loss = 0.00670358
Iteration 3989, loss = 0.00670107
Iteration 3990, loss = 0.00669903
Iteration 3991, loss = 0.00669643
Iteration 3992, loss = 0.00669403
Iteration 3993, loss = 0.00669202
Iteration 3994, loss = 0.00668966
Iteration 3995, loss = 0.00668732
Iteration 3996, loss = 0.00668543
Iteration 3997, loss = 0.00668315
Iteration 3998, loss = 0.00668122
Iteration 3999, loss = 0.00667935
Iteration 4000, loss = 0.00667696
Iteration 4001, loss = 0.00667500
Iteration 4002, loss = 0.00667275
Iteration 4003, loss = 0.00667060
Iteration 4004, loss = 0.00666847
Iteration 4005, loss = 0.00666650
Iteration 4006, loss = 0.00666401
Iteration 4007, loss = 0.00666182
Iteration 4008, loss = 0.00665953
Iteration 4009, loss = 0.00665699
Iteration 4010, loss = 0.00665449
Iteration 4011, loss = 0.00665184
Iteration 4012, loss = 0.00665037
Iteration 4013, loss = 0.00664718
Iteration 4014, loss = 0.00664557
Iteration 4015, loss = 0.00664318
Iteration 4016, loss = 0.00664102
Iteration 4017, loss = 0.00663920
Iteration 4018, loss = 0.00663662
Iteration 4019, loss = 0.00663415
Iteration 4020, loss = 0.00663243
Iteration 4021, loss = 0.00663007
Iteration 4022, loss = 0.00662814
Iteration 4023, loss = 0.00662590
Iteration 4024, loss = 0.00662336
Iteration 4025, loss = 0.00662136
Iteration 4026, loss = 0.00661938
Iteration 4027, loss = 0.00661691
Iteration 4028, loss = 0.00661511
Iteration 4029, loss = 0.00661310
Iteration 4030, loss = 0.00661072
Iteration 4031, loss = 0.00660873
Iteration 4032, loss = 0.00660651
Iteration 4033, loss = 0.00660428
Iteration 4034, loss = 0.00660308
Iteration 4035, loss = 0.00660018
Iteration 4036, loss = 0.00659829
Iteration 4037, loss = 0.00659552
Iteration 4038, loss = 0.00659311
Iteration 4039, loss = 0.00659114
Iteration 4040, loss = 0.00658874
Iteration 4041, loss = 0.00658669
Iteration 4042, loss = 0.00658390
Iteration 4043, loss = 0.00658175
Iteration 4044, loss = 0.00657945
Iteration 4045, loss = 0.00657726
Iteration 4046, loss = 0.00657495
Iteration 4047, loss = 0.00657268
Iteration 4048, loss = 0.00657055
Iteration 4049, loss = 0.00656851
Iteration 4050, loss = 0.00656616
Iteration 4051, loss = 0.00656397
Iteration 4052, loss = 0.00656171
Iteration 4053, loss = 0.00655947
Iteration 4054, loss = 0.00655694
Iteration 4055, loss = 0.00655494
Iteration 4056, loss = 0.00655234
Iteration 4057, loss = 0.00655090
Iteration 4058, loss = 0.00654790
Iteration 4059, loss = 0.00654548
Iteration 4060, loss = 0.00654354
Iteration 4061, loss = 0.00654119
Iteration 4062, loss = 0.00653892
Iteration 4063, loss = 0.00653667
Iteration 4064, loss = 0.00653464
Iteration 4065, loss = 0.00653238
Iteration 4066, loss = 0.00653029
Iteration 4067, loss = 0.00652824
Iteration 4068, loss = 0.00652622
Iteration 4069, loss = 0.00652422
Iteration 4070, loss = 0.00652205
Iteration 4071, loss = 0.00652005
Iteration 4072, loss = 0.00651814
Iteration 4073, loss = 0.00651707
Iteration 4074, loss = 0.00651497
Iteration 4075, loss = 0.00651242
Iteration 4076, loss = 0.00651000
Iteration 4077, loss = 0.00650771
Iteration 4078, loss = 0.00650564
Iteration 4079, loss = 0.00650332
Iteration 4080, loss = 0.00650103
Iteration 4081, loss = 0.00649887
Iteration 4082, loss = 0.00649678
Iteration 4083, loss = 0.00649393
Iteration 4084, loss = 0.00649220
Iteration 4085, loss = 0.00648967
Iteration 4086, loss = 0.00648720
Iteration 4087, loss = 0.00648507
Iteration 4088, loss = 0.00648291
Iteration 4089, loss = 0.00648063
Iteration 4090, loss = 0.00647877
Iteration 4091, loss = 0.00647626
Iteration 4092, loss = 0.00647463
Iteration 4093, loss = 0.00647276
Iteration 4094, loss = 0.00647100
Iteration 4095, loss = 0.00646887
Iteration 4096, loss = 0.00646652
Iteration 4097, loss = 0.00646616
Iteration 4098, loss = 0.00646311
Iteration 4099, loss = 0.00646091
Iteration 4100, loss = 0.00645878
Iteration 4101, loss = 0.00645698
Iteration 4102, loss = 0.00645488
Iteration 4103, loss = 0.00645273
Iteration 4104, loss = 0.00645082
Iteration 4105, loss = 0.00644884
Iteration 4106, loss = 0.00644753
Iteration 4107, loss = 0.00644459
Iteration 4108, loss = 0.00644235
Iteration 4109, loss = 0.00643973
Iteration 4110, loss = 0.00643795
Iteration 4111, loss = 0.00643504
Iteration 4112, loss = 0.00643283
Iteration 4113, loss = 0.00643085
Iteration 4114, loss = 0.00642828
Iteration 4115, loss = 0.00642629
Iteration 4116, loss = 0.00642238
Iteration 4117, loss = 0.00642081
Iteration 4118, loss = 0.00641915
Iteration 4119, loss = 0.00641530
Iteration 4120, loss = 0.00641284
Iteration 4121, loss = 0.00641080
Iteration 4122, loss = 0.00640868
Iteration 4123, loss = 0.00640750
Iteration 4124, loss = 0.00640412
Iteration 4125, loss = 0.00640192
Iteration 4126, loss = 0.00639941
Iteration 4127, loss = 0.00639731
Iteration 4128, loss = 0.00639512
Iteration 4129, loss = 0.00639315
Iteration 4130, loss = 0.00639079
Iteration 4131, loss = 0.00638899
Iteration 4132, loss = 0.00638679
Iteration 4133, loss = 0.00638509
Iteration 4134, loss = 0.00638289
Iteration 4135, loss = 0.00638083
Iteration 4136, loss = 0.00637891
Iteration 4137, loss = 0.00637684
Iteration 4138, loss = 0.00637466
Iteration 4139, loss = 0.00637249
Iteration 4140, loss = 0.00637013
Iteration 4141, loss = 0.00636823
Iteration 4142, loss = 0.00636550
Iteration 4143, loss = 0.00636324
Iteration 4144, loss = 0.00636087
Iteration 4145, loss = 0.00635863
Iteration 4146, loss = 0.00635651
Iteration 4147, loss = 0.00635388
Iteration 4148, loss = 0.00635182
Iteration 4149, loss = 0.00635010
Iteration 4150, loss = 0.00634747
Iteration 4151, loss = 0.00634620
Iteration 4152, loss = 0.00634336
Iteration 4153, loss = 0.00634121
Iteration 4154, loss = 0.00633890
Iteration 4155, loss = 0.00633695
Iteration 4156, loss = 0.00633469
Iteration 4157, loss = 0.00633264
Iteration 4158, loss = 0.00633042
Iteration 4159, loss = 0.00632845
Iteration 4160, loss = 0.00632662
Iteration 4161, loss = 0.00632480
Iteration 4162, loss = 0.00632249
Iteration 4163, loss = 0.00632063
Iteration 4164, loss = 0.00631872
Iteration 4165, loss = 0.00631658
Iteration 4166, loss = 0.00631457
Iteration 4167, loss = 0.00631292
Iteration 4168, loss = 0.00631110
Iteration 4169, loss = 0.00630924
Iteration 4170, loss = 0.00630693
Iteration 4171, loss = 0.00630498
Iteration 4172, loss = 0.00630354
Iteration 4173, loss = 0.00630128
Iteration 4174, loss = 0.00629934
Iteration 4175, loss = 0.00629689
Iteration 4176, loss = 0.00629454
Iteration 4177, loss = 0.00629251
Iteration 4178, loss = 0.00629099
Iteration 4179, loss = 0.00628794
Iteration 4180, loss = 0.00628563
Iteration 4181, loss = 0.00628352
Iteration 4182, loss = 0.00628179
Iteration 4183, loss = 0.00627955
Iteration 4184, loss = 0.00627698
Iteration 4185, loss = 0.00627493
Iteration 4186, loss = 0.00627251
Iteration 4187, loss = 0.00627040
Iteration 4188, loss = 0.00626812
Iteration 4189, loss = 0.00626615
Iteration 4190, loss = 0.00626393
Iteration 4191, loss = 0.00626200
Iteration 4192, loss = 0.00626001
Iteration 4193, loss = 0.00625778
Iteration 4194, loss = 0.00625567
Iteration 4195, loss = 0.00625387
Iteration 4196, loss = 0.00625313
Iteration 4197, loss = 0.00624925
Iteration 4198, loss = 0.00624701
Iteration 4199, loss = 0.00624467
Iteration 4200, loss = 0.00624291
Iteration 4201, loss = 0.00624029
Iteration 4202, loss = 0.00623803
Iteration 4203, loss = 0.00623632
Iteration 4204, loss = 0.00623457
Iteration 4205, loss = 0.00623194
Iteration 4206, loss = 0.00622968
Iteration 4207, loss = 0.00622770
Iteration 4208, loss = 0.00622575
Iteration 4209, loss = 0.00622396
Iteration 4210, loss = 0.00622201
Iteration 4211, loss = 0.00622063
Iteration 4212, loss = 0.00621801
Iteration 4213, loss = 0.00621609
Iteration 4214, loss = 0.00621460
Iteration 4215, loss = 0.00621189
Iteration 4216, loss = 0.00621002
Iteration 4217, loss = 0.00620767
Iteration 4218, loss = 0.00620530
Iteration 4219, loss = 0.00620324
Iteration 4220, loss = 0.00620110
Iteration 4221, loss = 0.00619993
Iteration 4222, loss = 0.00619726
Iteration 4223, loss = 0.00619519
Iteration 4224, loss = 0.00619305
Iteration 4225, loss = 0.00619083
Iteration 4226, loss = 0.00618907
Iteration 4227, loss = 0.00618926
Iteration 4228, loss = 0.00618543
Iteration 4229, loss = 0.00618326
Iteration 4230, loss = 0.00618165
Iteration 4231, loss = 0.00617969
Iteration 4232, loss = 0.00617796
Iteration 4233, loss = 0.00617549
Iteration 4234, loss = 0.00617346
Iteration 4235, loss = 0.00617145
Iteration 4236, loss = 0.00616963
Iteration 4237, loss = 0.00616737
Iteration 4238, loss = 0.00616538
Iteration 4239, loss = 0.00616418
Iteration 4240, loss = 0.00616165
Iteration 4241, loss = 0.00615961
Iteration 4242, loss = 0.00615799
Iteration 4243, loss = 0.00615547
Iteration 4244, loss = 0.00615360
Iteration 4245, loss = 0.00615148
Iteration 4246, loss = 0.00614938
Iteration 4247, loss = 0.00614723
Iteration 4248, loss = 0.00614520
Iteration 4249, loss = 0.00614366
Iteration 4250, loss = 0.00614110
Iteration 4251, loss = 0.00613907
Iteration 4252, loss = 0.00613691
Iteration 4253, loss = 0.00613500
Iteration 4254, loss = 0.00613289
Iteration 4255, loss = 0.00613081
Iteration 4256, loss = 0.00612866
Iteration 4257, loss = 0.00612652
Iteration 4258, loss = 0.00612452
Iteration 4259, loss = 0.00612266
Iteration 4260, loss = 0.00612070
Iteration 4261, loss = 0.00611863
Iteration 4262, loss = 0.00611712
Iteration 4263, loss = 0.00611517
Iteration 4264, loss = 0.00611297
Iteration 4265, loss = 0.00611124
Iteration 4266, loss = 0.00610910
Iteration 4267, loss = 0.00610711
Iteration 4268, loss = 0.00610476
Iteration 4269, loss = 0.00610281
Iteration 4270, loss = 0.00610065
Iteration 4271, loss = 0.00609848
Iteration 4272, loss = 0.00609622
Iteration 4273, loss = 0.00609430
Iteration 4274, loss = 0.00609253
Iteration 4275, loss = 0.00609026
Iteration 4276, loss = 0.00608838
Iteration 4277, loss = 0.00608561
Iteration 4278, loss = 0.00608343
Iteration 4279, loss = 0.00608136
Iteration 4280, loss = 0.00607938
Iteration 4281, loss = 0.00607730
Iteration 4282, loss = 0.00607505
Iteration 4283, loss = 0.00607299
Iteration 4284, loss = 0.00607079
Iteration 4285, loss = 0.00606862
Iteration 4286, loss = 0.00606760
Iteration 4287, loss = 0.00606474
Iteration 4288, loss = 0.00606298
Iteration 4289, loss = 0.00606175
Iteration 4290, loss = 0.00605903
Iteration 4291, loss = 0.00605709
Iteration 4292, loss = 0.00605492
Iteration 4293, loss = 0.00605356
Iteration 4294, loss = 0.00605292
Iteration 4295, loss = 0.00605019
Iteration 4296, loss = 0.00604810
Iteration 4297, loss = 0.00604605
Iteration 4298, loss = 0.00604381
Iteration 4299, loss = 0.00604219
Iteration 4300, loss = 0.00604010
Iteration 4301, loss = 0.00603795
Iteration 4302, loss = 0.00603611
Iteration 4303, loss = 0.00603406
Iteration 4304, loss = 0.00603207
Iteration 4305, loss = 0.00603033
Iteration 4306, loss = 0.00602844
Iteration 4307, loss = 0.00602686
Iteration 4308, loss = 0.00602502
Iteration 4309, loss = 0.00602357
Iteration 4310, loss = 0.00602157
Iteration 4311, loss = 0.00601970
Iteration 4312, loss = 0.00601805
Iteration 4313, loss = 0.00601618
Iteration 4314, loss = 0.00601420
Iteration 4315, loss = 0.00601230
Iteration 4316, loss = 0.00601050
Iteration 4317, loss = 0.00600878
Iteration 4318, loss = 0.00600685
Iteration 4319, loss = 0.00600500
Iteration 4320, loss = 0.00600323
Iteration 4321, loss = 0.00600140
Iteration 4322, loss = 0.00599967
Iteration 4323, loss = 0.00599791
Iteration 4324, loss = 0.00599614
Iteration 4325, loss = 0.00599467
Iteration 4326, loss = 0.00599294
Iteration 4327, loss = 0.00599057
Iteration 4328, loss = 0.00598864
Iteration 4329, loss = 0.00598673
Iteration 4330, loss = 0.00598514
Iteration 4331, loss = 0.00598287
Iteration 4332, loss = 0.00598142
Iteration 4333, loss = 0.00597891
Iteration 4334, loss = 0.00597674
Iteration 4335, loss = 0.00597485
Iteration 4336, loss = 0.00597309
Iteration 4337, loss = 0.00597165
Iteration 4338, loss = 0.00596950
Iteration 4339, loss = 0.00596754
Iteration 4340, loss = 0.00596597
Iteration 4341, loss = 0.00596376
Iteration 4342, loss = 0.00596194
Iteration 4343, loss = 0.00596018
Iteration 4344, loss = 0.00595848
Iteration 4345, loss = 0.00595768
Iteration 4346, loss = 0.00595514
Iteration 4347, loss = 0.00595319
Iteration 4348, loss = 0.00595134
Iteration 4349, loss = 0.00594945
Iteration 4350, loss = 0.00594760
Iteration 4351, loss = 0.00594553
Iteration 4352, loss = 0.00594392
Iteration 4353, loss = 0.00594190
Iteration 4354, loss = 0.00593993
Iteration 4355, loss = 0.00593832
Iteration 4356, loss = 0.00593640
Iteration 4357, loss = 0.00593456
Iteration 4358, loss = 0.00593313
Iteration 4359, loss = 0.00593083
Iteration 4360, loss = 0.00592877
Iteration 4361, loss = 0.00592721
Iteration 4362, loss = 0.00592497
Iteration 4363, loss = 0.00592289
Iteration 4364, loss = 0.00592091
Iteration 4365, loss = 0.00591913
Iteration 4366, loss = 0.00591708
Iteration 4367, loss = 0.00591515
Iteration 4368, loss = 0.00591357
Iteration 4369, loss = 0.00591149
Iteration 4370, loss = 0.00590962
Iteration 4371, loss = 0.00590743
Iteration 4372, loss = 0.00590571
Iteration 4373, loss = 0.00590382
Iteration 4374, loss = 0.00590202
Iteration 4375, loss = 0.00589972
Iteration 4376, loss = 0.00589855
Iteration 4377, loss = 0.00589656
Iteration 4378, loss = 0.00589422
Iteration 4379, loss = 0.00589255
Iteration 4380, loss = 0.00589109
Iteration 4381, loss = 0.00588878
Iteration 4382, loss = 0.00588690
Iteration 4383, loss = 0.00588525
Iteration 4384, loss = 0.00588354
Iteration 4385, loss = 0.00588161
Iteration 4386, loss = 0.00587940
Iteration 4387, loss = 0.00587753
Iteration 4388, loss = 0.00587581
Iteration 4389, loss = 0.00587345
Iteration 4390, loss = 0.00587169
Iteration 4391, loss = 0.00586969
Iteration 4392, loss = 0.00586754
Iteration 4393, loss = 0.00586565
Iteration 4394, loss = 0.00586447
Iteration 4395, loss = 0.00586177
Iteration 4396, loss = 0.00585984
Iteration 4397, loss = 0.00585795
Iteration 4398, loss = 0.00585624
Iteration 4399, loss = 0.00585423
Iteration 4400, loss = 0.00585230
Iteration 4401, loss = 0.00585042
Iteration 4402, loss = 0.00584878
Iteration 4403, loss = 0.00584728
Iteration 4404, loss = 0.00584503
Iteration 4405, loss = 0.00584339
Iteration 4406, loss = 0.00584099
Iteration 4407, loss = 0.00583914
Iteration 4408, loss = 0.00583730
Iteration 4409, loss = 0.00583533
Iteration 4410, loss = 0.00583357
Iteration 4411, loss = 0.00583189
Iteration 4412, loss = 0.00582993
Iteration 4413, loss = 0.00582840
Iteration 4414, loss = 0.00582643
Iteration 4415, loss = 0.00582471
Iteration 4416, loss = 0.00582289
Iteration 4417, loss = 0.00582127
Iteration 4418, loss = 0.00581966
Iteration 4419, loss = 0.00581815
Iteration 4420, loss = 0.00581610
Iteration 4421, loss = 0.00581439
Iteration 4422, loss = 0.00581300
Iteration 4423, loss = 0.00581094
Iteration 4424, loss = 0.00580905
Iteration 4425, loss = 0.00580782
Iteration 4426, loss = 0.00580548
Iteration 4427, loss = 0.00580352
Iteration 4428, loss = 0.00580177
Iteration 4429, loss = 0.00579964
Iteration 4430, loss = 0.00579791
Iteration 4431, loss = 0.00579626
Iteration 4432, loss = 0.00579455
Iteration 4433, loss = 0.00579257
Iteration 4434, loss = 0.00579086
Iteration 4435, loss = 0.00578899
Iteration 4436, loss = 0.00578734
Iteration 4437, loss = 0.00578614
Iteration 4438, loss = 0.00578395
Iteration 4439, loss = 0.00578178
Iteration 4440, loss = 0.00577981
Iteration 4441, loss = 0.00577819
Iteration 4442, loss = 0.00577592
Iteration 4443, loss = 0.00577406
Iteration 4444, loss = 0.00577204
Iteration 4445, loss = 0.00577027
Iteration 4446, loss = 0.00576884
Iteration 4447, loss = 0.00576648
Iteration 4448, loss = 0.00576502
Iteration 4449, loss = 0.00576291
Iteration 4450, loss = 0.00576098
Iteration 4451, loss = 0.00575936
Iteration 4452, loss = 0.00575736
Iteration 4453, loss = 0.00575589
Iteration 4454, loss = 0.00575363
Iteration 4455, loss = 0.00575207
Iteration 4456, loss = 0.00574998
Iteration 4457, loss = 0.00574815
Iteration 4458, loss = 0.00574622
Iteration 4459, loss = 0.00574541
Iteration 4460, loss = 0.00574238
Iteration 4461, loss = 0.00574067
Iteration 4462, loss = 0.00573845
Iteration 4463, loss = 0.00573780
Iteration 4464, loss = 0.00573498
Iteration 4465, loss = 0.00573388
Iteration 4466, loss = 0.00573164
Iteration 4467, loss = 0.00573025
Iteration 4468, loss = 0.00572815
Iteration 4469, loss = 0.00572638
Iteration 4470, loss = 0.00572476
Iteration 4471, loss = 0.00572303
Iteration 4472, loss = 0.00572118
Iteration 4473, loss = 0.00571949
Iteration 4474, loss = 0.00571777
Iteration 4475, loss = 0.00571617
Iteration 4476, loss = 0.00571467
Iteration 4477, loss = 0.00571286
Iteration 4478, loss = 0.00571118
Iteration 4479, loss = 0.00570976
Iteration 4480, loss = 0.00570845
Iteration 4481, loss = 0.00570676
Iteration 4482, loss = 0.00570506
Iteration 4483, loss = 0.00570336
Iteration 4484, loss = 0.00570167
Iteration 4485, loss = 0.00570021
Iteration 4486, loss = 0.00569827
Iteration 4487, loss = 0.00569654
Iteration 4488, loss = 0.00569496
Iteration 4489, loss = 0.00569325
Iteration 4490, loss = 0.00569151
Iteration 4491, loss = 0.00568966
Iteration 4492, loss = 0.00568806
Iteration 4493, loss = 0.00568623
Iteration 4494, loss = 0.00568460
Iteration 4495, loss = 0.00568264
Iteration 4496, loss = 0.00568089
Iteration 4497, loss = 0.00567907
Iteration 4498, loss = 0.00567812
Iteration 4499, loss = 0.00567583
Iteration 4500, loss = 0.00567523
Iteration 4501, loss = 0.00567247
Iteration 4502, loss = 0.00567067
Iteration 4503, loss = 0.00566895
Iteration 4504, loss = 0.00566718
Iteration 4505, loss = 0.00566476
Iteration 4506, loss = 0.00566326
Iteration 4507, loss = 0.00566141
Iteration 4508, loss = 0.00565940
Iteration 4509, loss = 0.00565770
Iteration 4510, loss = 0.00565611
Iteration 4511, loss = 0.00565399
Iteration 4512, loss = 0.00565192
Iteration 4513, loss = 0.00564969
Iteration 4514, loss = 0.00564912
Iteration 4515, loss = 0.00564687
Iteration 4516, loss = 0.00564466
Iteration 4517, loss = 0.00564297
Iteration 4518, loss = 0.00564135
Iteration 4519, loss = 0.00563959
Iteration 4520, loss = 0.00563793
Iteration 4521, loss = 0.00563620
Iteration 4522, loss = 0.00563486
Iteration 4523, loss = 0.00563294
Iteration 4524, loss = 0.00563126
Iteration 4525, loss = 0.00562913
Iteration 4526, loss = 0.00562795
Iteration 4527, loss = 0.00562567
Iteration 4528, loss = 0.00562457
Iteration 4529, loss = 0.00562266
Iteration 4530, loss = 0.00562065
Iteration 4531, loss = 0.00561899
Iteration 4532, loss = 0.00561731
Iteration 4533, loss = 0.00561572
Iteration 4534, loss = 0.00561399
Iteration 4535, loss = 0.00561261
Iteration 4536, loss = 0.00561168
Iteration 4537, loss = 0.00560989
Iteration 4538, loss = 0.00560807
Iteration 4539, loss = 0.00560612
Iteration 4540, loss = 0.00560442
Iteration 4541, loss = 0.00560292
Iteration 4542, loss = 0.00560105
Iteration 4543, loss = 0.00559943
Iteration 4544, loss = 0.00559788
Iteration 4545, loss = 0.00559622
Iteration 4546, loss = 0.00559459
Iteration 4547, loss = 0.00559288
Iteration 4548, loss = 0.00559090
Iteration 4549, loss = 0.00558950
Iteration 4550, loss = 0.00558784
Iteration 4551, loss = 0.00558595
Iteration 4552, loss = 0.00558408
Iteration 4553, loss = 0.00558230
Iteration 4554, loss = 0.00558083
Iteration 4555, loss = 0.00557896
Iteration 4556, loss = 0.00557731
Iteration 4557, loss = 0.00557563
Iteration 4558, loss = 0.00557406
Iteration 4559, loss = 0.00557252
Iteration 4560, loss = 0.00557086
Iteration 4561, loss = 0.00556927
Iteration 4562, loss = 0.00556807
Iteration 4563, loss = 0.00556603
Iteration 4564, loss = 0.00556451
Iteration 4565, loss = 0.00556287
Iteration 4566, loss = 0.00556162
Iteration 4567, loss = 0.00555954
Iteration 4568, loss = 0.00555813
Iteration 4569, loss = 0.00555622
Iteration 4570, loss = 0.00555436
Iteration 4571, loss = 0.00555262
Iteration 4572, loss = 0.00555096
Iteration 4573, loss = 0.00554904
Iteration 4574, loss = 0.00554751
Iteration 4575, loss = 0.00554580
Iteration 4576, loss = 0.00554435
Iteration 4577, loss = 0.00554160
Iteration 4578, loss = 0.00554069
Iteration 4579, loss = 0.00553872
Iteration 4580, loss = 0.00553631
Iteration 4581, loss = 0.00553444
Iteration 4582, loss = 0.00553268
Iteration 4583, loss = 0.00553120
Iteration 4584, loss = 0.00552969
Iteration 4585, loss = 0.00552801
Iteration 4586, loss = 0.00552632
Iteration 4587, loss = 0.00552485
Iteration 4588, loss = 0.00552326
Iteration 4589, loss = 0.00552223
Iteration 4590, loss = 0.00551990
Iteration 4591, loss = 0.00551827
Iteration 4592, loss = 0.00551656
Iteration 4593, loss = 0.00551500
Iteration 4594, loss = 0.00551337
Iteration 4595, loss = 0.00551199
Iteration 4596, loss = 0.00551019
Iteration 4597, loss = 0.00550773
Iteration 4598, loss = 0.00550633
Iteration 4599, loss = 0.00550391
Iteration 4600, loss = 0.00550275
Iteration 4601, loss = 0.00550144
Iteration 4602, loss = 0.00549951
Iteration 4603, loss = 0.00549775
Iteration 4604, loss = 0.00549605
Iteration 4605, loss = 0.00549448
Iteration 4606, loss = 0.00549320
Iteration 4607, loss = 0.00549133
Iteration 4608, loss = 0.00548950
Iteration 4609, loss = 0.00548784
Iteration 4610, loss = 0.00548630
Iteration 4611, loss = 0.00548457
Iteration 4612, loss = 0.00548279
Iteration 4613, loss = 0.00548157
Iteration 4614, loss = 0.00547960
Iteration 4615, loss = 0.00547783
Iteration 4616, loss = 0.00547654
Iteration 4617, loss = 0.00547472
Iteration 4618, loss = 0.00547306
Iteration 4619, loss = 0.00547125
Iteration 4620, loss = 0.00546941
Iteration 4621, loss = 0.00546721
Iteration 4622, loss = 0.00546541
Iteration 4623, loss = 0.00546368
Iteration 4624, loss = 0.00546182
Iteration 4625, loss = 0.00546020
Iteration 4626, loss = 0.00545849
Iteration 4627, loss = 0.00545682
Iteration 4628, loss = 0.00545522
Iteration 4629, loss = 0.00545381
Iteration 4630, loss = 0.00545235
Iteration 4631, loss = 0.00545064
Iteration 4632, loss = 0.00544911
Iteration 4633, loss = 0.00544751
Iteration 4634, loss = 0.00544597
Iteration 4635, loss = 0.00544446
Iteration 4636, loss = 0.00544296
Iteration 4637, loss = 0.00544110
Iteration 4638, loss = 0.00543962
Iteration 4639, loss = 0.00543801
Iteration 4640, loss = 0.00543625
Iteration 4641, loss = 0.00543458
Iteration 4642, loss = 0.00543300
Iteration 4643, loss = 0.00543117
Iteration 4644, loss = 0.00542989
Iteration 4645, loss = 0.00542796
Iteration 4646, loss = 0.00542626
Iteration 4647, loss = 0.00542458
Iteration 4648, loss = 0.00542313
Iteration 4649, loss = 0.00542157
Iteration 4650, loss = 0.00542014
Iteration 4651, loss = 0.00541847
Iteration 4652, loss = 0.00541715
Iteration 4653, loss = 0.00541575
Iteration 4654, loss = 0.00541438
Iteration 4655, loss = 0.00541250
Iteration 4656, loss = 0.00541111
Iteration 4657, loss = 0.00540948
Iteration 4658, loss = 0.00540773
Iteration 4659, loss = 0.00540614
Iteration 4660, loss = 0.00540452
Iteration 4661, loss = 0.00540304
Iteration 4662, loss = 0.00540122
Iteration 4663, loss = 0.00539965
Iteration 4664, loss = 0.00539820
Iteration 4665, loss = 0.00539626
Iteration 4666, loss = 0.00539498
Iteration 4667, loss = 0.00539317
Iteration 4668, loss = 0.00539179
Iteration 4669, loss = 0.00539033
Iteration 4670, loss = 0.00538829
Iteration 4671, loss = 0.00538665
Iteration 4672, loss = 0.00538507
Iteration 4673, loss = 0.00538346
Iteration 4674, loss = 0.00538175
Iteration 4675, loss = 0.00538007
Iteration 4676, loss = 0.00537856
Iteration 4677, loss = 0.00537710
Iteration 4678, loss = 0.00537538
Iteration 4679, loss = 0.00537395
Iteration 4680, loss = 0.00537241
Iteration 4681, loss = 0.00537088
Iteration 4682, loss = 0.00536933
Iteration 4683, loss = 0.00536790
Iteration 4684, loss = 0.00536633
Iteration 4685, loss = 0.00536477
Iteration 4686, loss = 0.00536332
Iteration 4687, loss = 0.00536200
Iteration 4688, loss = 0.00536044
Iteration 4689, loss = 0.00535905
Iteration 4690, loss = 0.00535756
Iteration 4691, loss = 0.00535622
Iteration 4692, loss = 0.00535466
Iteration 4693, loss = 0.00535379
Iteration 4694, loss = 0.00535155
Iteration 4695, loss = 0.00534987
Iteration 4696, loss = 0.00534813
Iteration 4697, loss = 0.00534648
Iteration 4698, loss = 0.00534519
Iteration 4699, loss = 0.00534319
Iteration 4700, loss = 0.00534127
Iteration 4701, loss = 0.00533992
Iteration 4702, loss = 0.00533826
Iteration 4703, loss = 0.00533643
Iteration 4704, loss = 0.00533460
Iteration 4705, loss = 0.00533300
Iteration 4706, loss = 0.00533138
Iteration 4707, loss = 0.00532961
Iteration 4708, loss = 0.00532806
Iteration 4709, loss = 0.00532657
Iteration 4710, loss = 0.00532482
Iteration 4711, loss = 0.00532346
Iteration 4712, loss = 0.00532169
Iteration 4713, loss = 0.00532016
Iteration 4714, loss = 0.00531872
Iteration 4715, loss = 0.00531703
Iteration 4716, loss = 0.00531564
Iteration 4717, loss = 0.00531404
Iteration 4718, loss = 0.00531263
Iteration 4719, loss = 0.00531110
Iteration 4720, loss = 0.00530958
Iteration 4721, loss = 0.00530825
Iteration 4722, loss = 0.00530681
Iteration 4723, loss = 0.00530549
Iteration 4724, loss = 0.00530416
Iteration 4725, loss = 0.00530262
Iteration 4726, loss = 0.00530096
Iteration 4727, loss = 0.00529970
Iteration 4728, loss = 0.00529825
Iteration 4729, loss = 0.00529756
Iteration 4730, loss = 0.00529555
Iteration 4731, loss = 0.00529409
Iteration 4732, loss = 0.00529286
Iteration 4733, loss = 0.00529108
Iteration 4734, loss = 0.00528950
Iteration 4735, loss = 0.00528784
Iteration 4736, loss = 0.00528639
Iteration 4737, loss = 0.00528480
Iteration 4738, loss = 0.00528319
Iteration 4739, loss = 0.00528157
Iteration 4740, loss = 0.00528010
Iteration 4741, loss = 0.00527865
Iteration 4742, loss = 0.00527649
Iteration 4743, loss = 0.00527450
Iteration 4744, loss = 0.00527296
Iteration 4745, loss = 0.00527106
Iteration 4746, loss = 0.00526955
Iteration 4747, loss = 0.00526788
Iteration 4748, loss = 0.00526670
Iteration 4749, loss = 0.00526463
Iteration 4750, loss = 0.00526318
Iteration 4751, loss = 0.00526170
Iteration 4752, loss = 0.00526033
Iteration 4753, loss = 0.00525871
Iteration 4754, loss = 0.00525722
Iteration 4755, loss = 0.00525578
Iteration 4756, loss = 0.00525443
Iteration 4757, loss = 0.00525372
Iteration 4758, loss = 0.00525136
Iteration 4759, loss = 0.00524980
Iteration 4760, loss = 0.00524833
Iteration 4761, loss = 0.00524673
Iteration 4762, loss = 0.00524507
Iteration 4763, loss = 0.00524387
Iteration 4764, loss = 0.00524195
Iteration 4765, loss = 0.00524011
Iteration 4766, loss = 0.00523883
Iteration 4767, loss = 0.00523723
Iteration 4768, loss = 0.00523545
Iteration 4769, loss = 0.00523427
Iteration 4770, loss = 0.00523251
Iteration 4771, loss = 0.00523107
Iteration 4772, loss = 0.00522956
Iteration 4773, loss = 0.00522819
Iteration 4774, loss = 0.00522659
Iteration 4775, loss = 0.00522510
Iteration 4776, loss = 0.00522347
Iteration 4777, loss = 0.00522181
Iteration 4778, loss = 0.00522049
Iteration 4779, loss = 0.00521922
Iteration 4780, loss = 0.00521743
Iteration 4781, loss = 0.00521593
Iteration 4782, loss = 0.00521429
Iteration 4783, loss = 0.00521286
Iteration 4784, loss = 0.00521094
Iteration 4785, loss = 0.00520924
Iteration 4786, loss = 0.00520787
Iteration 4787, loss = 0.00520613
Iteration 4788, loss = 0.00520426
Iteration 4789, loss = 0.00520230
Iteration 4790, loss = 0.00520186
Iteration 4791, loss = 0.00520010
Iteration 4792, loss = 0.00519821
Iteration 4793, loss = 0.00519628
Iteration 4794, loss = 0.00519513
Iteration 4795, loss = 0.00519350
Iteration 4796, loss = 0.00519186
Iteration 4797, loss = 0.00519019
Iteration 4798, loss = 0.00518869
Iteration 4799, loss = 0.00518702
Iteration 4800, loss = 0.00518529
Iteration 4801, loss = 0.00518397
Iteration 4802, loss = 0.00518239
Iteration 4803, loss = 0.00518076
Iteration 4804, loss = 0.00517911
Iteration 4805, loss = 0.00517788
Iteration 4806, loss = 0.00517613
Iteration 4807, loss = 0.00517489
Iteration 4808, loss = 0.00517340
Iteration 4809, loss = 0.00517182
Iteration 4810, loss = 0.00517047
Iteration 4811, loss = 0.00516887
Iteration 4812, loss = 0.00516763
Iteration 4813, loss = 0.00516578
Iteration 4814, loss = 0.00516445
Iteration 4815, loss = 0.00516274
Iteration 4816, loss = 0.00516127
Iteration 4817, loss = 0.00515970
Iteration 4818, loss = 0.00515802
Iteration 4819, loss = 0.00515654
Iteration 4820, loss = 0.00515498
Iteration 4821, loss = 0.00515353
Iteration 4822, loss = 0.00515214
Iteration 4823, loss = 0.00515089
Iteration 4824, loss = 0.00514905
Iteration 4825, loss = 0.00514769
Iteration 4826, loss = 0.00514641
Iteration 4827, loss = 0.00514475
Iteration 4828, loss = 0.00514334
Iteration 4829, loss = 0.00514209
Iteration 4830, loss = 0.00514096
Iteration 4831, loss = 0.00513931
Iteration 4832, loss = 0.00513783
Iteration 4833, loss = 0.00513642
Iteration 4834, loss = 0.00513509
Iteration 4835, loss = 0.00513370
Iteration 4836, loss = 0.00513263
Iteration 4837, loss = 0.00513099
Iteration 4838, loss = 0.00512950
Iteration 4839, loss = 0.00512808
Iteration 4840, loss = 0.00512652
Iteration 4841, loss = 0.00512517
Iteration 4842, loss = 0.00512378
Iteration 4843, loss = 0.00512271
Iteration 4844, loss = 0.00512078
Iteration 4845, loss = 0.00511955
Iteration 4846, loss = 0.00511780
Iteration 4847, loss = 0.00511625
Iteration 4848, loss = 0.00511475
Iteration 4849, loss = 0.00511338
Iteration 4850, loss = 0.00511196
Iteration 4851, loss = 0.00511046
Iteration 4852, loss = 0.00510907
Iteration 4853, loss = 0.00510760
Iteration 4854, loss = 0.00510629
Iteration 4855, loss = 0.00510482
Iteration 4856, loss = 0.00510352
Iteration 4857, loss = 0.00510226
Iteration 4858, loss = 0.00510056
Iteration 4859, loss = 0.00509937
Iteration 4860, loss = 0.00509806
Iteration 4861, loss = 0.00509615
Iteration 4862, loss = 0.00509478
Iteration 4863, loss = 0.00509314
Iteration 4864, loss = 0.00509187
Iteration 4865, loss = 0.00509034
Iteration 4866, loss = 0.00508876
Iteration 4867, loss = 0.00508708
Iteration 4868, loss = 0.00508553
Iteration 4869, loss = 0.00508406
Iteration 4870, loss = 0.00508238
Iteration 4871, loss = 0.00508092
Iteration 4872, loss = 0.00507958
Iteration 4873, loss = 0.00507799
Iteration 4874, loss = 0.00507646
Iteration 4875, loss = 0.00507512
Iteration 4876, loss = 0.00507353
Iteration 4877, loss = 0.00507261
Iteration 4878, loss = 0.00507079
Iteration 4879, loss = 0.00506933
Iteration 4880, loss = 0.00506797
Iteration 4881, loss = 0.00506643
Iteration 4882, loss = 0.00506545
Iteration 4883, loss = 0.00506379
Iteration 4884, loss = 0.00506236
Iteration 4885, loss = 0.00506126
Iteration 4886, loss = 0.00505958
Iteration 4887, loss = 0.00505823
Iteration 4888, loss = 0.00505694
Iteration 4889, loss = 0.00505567
Iteration 4890, loss = 0.00505423
Iteration 4891, loss = 0.00505271
Iteration 4892, loss = 0.00505129
Iteration 4893, loss = 0.00505045
Iteration 4894, loss = 0.00504899
Iteration 4895, loss = 0.00504765
Iteration 4896, loss = 0.00504612
Iteration 4897, loss = 0.00504463
Iteration 4898, loss = 0.00504336
Iteration 4899, loss = 0.00504185
Iteration 4900, loss = 0.00504066
Iteration 4901, loss = 0.00503894
Iteration 4902, loss = 0.00503760
Iteration 4903, loss = 0.00503608
Iteration 4904, loss = 0.00503468
Iteration 4905, loss = 0.00503306
Iteration 4906, loss = 0.00503168
Iteration 4907, loss = 0.00503025
Iteration 4908, loss = 0.00502851
Iteration 4909, loss = 0.00502737
Iteration 4910, loss = 0.00502577
Iteration 4911, loss = 0.00502408
Iteration 4912, loss = 0.00502276
Iteration 4913, loss = 0.00502137
Iteration 4914, loss = 0.00501996
Iteration 4915, loss = 0.00501869
Iteration 4916, loss = 0.00501735
Iteration 4917, loss = 0.00501615
Iteration 4918, loss = 0.00501458
Iteration 4919, loss = 0.00501301
Iteration 4920, loss = 0.00501192
Iteration 4921, loss = 0.00501014
Iteration 4922, loss = 0.00500879
Iteration 4923, loss = 0.00500742
Iteration 4924, loss = 0.00500601
Iteration 4925, loss = 0.00500471
Iteration 4926, loss = 0.00500414
Iteration 4927, loss = 0.00500200
Iteration 4928, loss = 0.00500040
Iteration 4929, loss = 0.00499890
Iteration 4930, loss = 0.00499765
Iteration 4931, loss = 0.00499586
Iteration 4932, loss = 0.00499456
Iteration 4933, loss = 0.00499314
Iteration 4934, loss = 0.00499158
Iteration 4935, loss = 0.00499029
Iteration 4936, loss = 0.00498896
Iteration 4937, loss = 0.00498762
Iteration 4938, loss = 0.00498621
Iteration 4939, loss = 0.00498490
Iteration 4940, loss = 0.00498363
Iteration 4941, loss = 0.00498210
Iteration 4942, loss = 0.00498071
Iteration 4943, loss = 0.00497927
Iteration 4944, loss = 0.00497834
Iteration 4945, loss = 0.00497648
Iteration 4946, loss = 0.00497512
Iteration 4947, loss = 0.00497347
Iteration 4948, loss = 0.00497230
Iteration 4949, loss = 0.00497077
Iteration 4950, loss = 0.00496973
Iteration 4951, loss = 0.00496797
Iteration 4952, loss = 0.00496665
Iteration 4953, loss = 0.00496539
Iteration 4954, loss = 0.00496399
Iteration 4955, loss = 0.00496293
Iteration 4956, loss = 0.00496154
Iteration 4957, loss = 0.00496030
Iteration 4958, loss = 0.00495917
Iteration 4959, loss = 0.00495784
Iteration 4960, loss = 0.00495661
Iteration 4961, loss = 0.00495529
Iteration 4962, loss = 0.00495394
Iteration 4963, loss = 0.00495282
Iteration 4964, loss = 0.00495154
Iteration 4965, loss = 0.00495016
Iteration 4966, loss = 0.00494874
Iteration 4967, loss = 0.00494748
Iteration 4968, loss = 0.00494637
Iteration 4969, loss = 0.00494512
Iteration 4970, loss = 0.00494384
Iteration 4971, loss = 0.00494258
Iteration 4972, loss = 0.00494080
Iteration 4973, loss = 0.00493938
Iteration 4974, loss = 0.00493783
Iteration 4975, loss = 0.00493664
Iteration 4976, loss = 0.00493501
Iteration 4977, loss = 0.00493379
Iteration 4978, loss = 0.00493239
Iteration 4979, loss = 0.00493073
Iteration 4980, loss = 0.00492963
Iteration 4981, loss = 0.00492793
Iteration 4982, loss = 0.00492632
Iteration 4983, loss = 0.00492495
Iteration 4984, loss = 0.00492424
Iteration 4985, loss = 0.00492227
Iteration 4986, loss = 0.00492071
Iteration 4987, loss = 0.00491933
Iteration 4988, loss = 0.00491777
Iteration 4989, loss = 0.00491642
Iteration 4990, loss = 0.00491528
Iteration 4991, loss = 0.00491352
Iteration 4992, loss = 0.00491208
Iteration 4993, loss = 0.00491059
Iteration 4994, loss = 0.00490938
Iteration 4995, loss = 0.00490779
Iteration 4996, loss = 0.00490630
Iteration 4997, loss = 0.00490516
Iteration 4998, loss = 0.00490322
Iteration 4999, loss = 0.00490160
Iteration 5000, loss = 0.00490048
Iteration 5001, loss = 0.00489881
Iteration 5002, loss = 0.00489761
Iteration 5003, loss = 0.00489601
Iteration 5004, loss = 0.00489446
Iteration 5005, loss = 0.00489319
Iteration 5006, loss = 0.00489179
Iteration 5007, loss = 0.00489044
Iteration 5008, loss = 0.00488907
Iteration 5009, loss = 0.00488775
Iteration 5010, loss = 0.00488672
Iteration 5011, loss = 0.00488495
Iteration 5012, loss = 0.00488360
Iteration 5013, loss = 0.00488228
Iteration 5014, loss = 0.00488083
Iteration 5015, loss = 0.00487936
Iteration 5016, loss = 0.00487794
Iteration 5017, loss = 0.00487664
Iteration 5018, loss = 0.00487513
Iteration 5019, loss = 0.00487392
Iteration 5020, loss = 0.00487236
Iteration 5021, loss = 0.00487096
Iteration 5022, loss = 0.00486950
Iteration 5023, loss = 0.00486813
Iteration 5024, loss = 0.00486663
Iteration 5025, loss = 0.00486535
Iteration 5026, loss = 0.00486384
Iteration 5027, loss = 0.00486268
Iteration 5028, loss = 0.00486100
Iteration 5029, loss = 0.00485965
Iteration 5030, loss = 0.00485829
Iteration 5031, loss = 0.00485692
Iteration 5032, loss = 0.00485553
Iteration 5033, loss = 0.00485444
Iteration 5034, loss = 0.00485287
Iteration 5035, loss = 0.00485155
Iteration 5036, loss = 0.00485020
Iteration 5037, loss = 0.00484890
Iteration 5038, loss = 0.00484777
Iteration 5039, loss = 0.00484665
Iteration 5040, loss = 0.00484522
Iteration 5041, loss = 0.00484384
Iteration 5042, loss = 0.00484235
Iteration 5043, loss = 0.00484118
Iteration 5044, loss = 0.00483992
Iteration 5045, loss = 0.00483851
Iteration 5046, loss = 0.00483723
Iteration 5047, loss = 0.00483611
Iteration 5048, loss = 0.00483459
Iteration 5049, loss = 0.00483335
Iteration 5050, loss = 0.00483200
Iteration 5051, loss = 0.00483081
Iteration 5052, loss = 0.00482930
Iteration 5053, loss = 0.00482799
Iteration 5054, loss = 0.00482672
Iteration 5055, loss = 0.00482549
Iteration 5056, loss = 0.00482472
Iteration 5057, loss = 0.00482291
Iteration 5058, loss = 0.00482152
Iteration 5059, loss = 0.00482020
Iteration 5060, loss = 0.00481898
Iteration 5061, loss = 0.00481762
Iteration 5062, loss = 0.00481649
Iteration 5063, loss = 0.00481516
Iteration 5064, loss = 0.00481406
Iteration 5065, loss = 0.00481268
Iteration 5066, loss = 0.00481125
Iteration 5067, loss = 0.00481025
Iteration 5068, loss = 0.00480864
Iteration 5069, loss = 0.00480726
Iteration 5070, loss = 0.00480591
Iteration 5071, loss = 0.00480482
Iteration 5072, loss = 0.00480348
Iteration 5073, loss = 0.00480241
Iteration 5074, loss = 0.00480108
Iteration 5075, loss = 0.00479962
Iteration 5076, loss = 0.00479829
Iteration 5077, loss = 0.00479708
Iteration 5078, loss = 0.00479619
Iteration 5079, loss = 0.00479446
Iteration 5080, loss = 0.00479315
Iteration 5081, loss = 0.00479196
Iteration 5082, loss = 0.00479071
Iteration 5083, loss = 0.00478934
Iteration 5084, loss = 0.00478796
Iteration 5085, loss = 0.00478706
Iteration 5086, loss = 0.00478527
Iteration 5087, loss = 0.00478382
Iteration 5088, loss = 0.00478321
Iteration 5089, loss = 0.00478150
Iteration 5090, loss = 0.00478018
Iteration 5091, loss = 0.00477907
Iteration 5092, loss = 0.00477775
Iteration 5093, loss = 0.00477657
Iteration 5094, loss = 0.00477534
Iteration 5095, loss = 0.00477428
Iteration 5096, loss = 0.00477308
Iteration 5097, loss = 0.00477184
Iteration 5098, loss = 0.00477053
Iteration 5099, loss = 0.00476886
Iteration 5100, loss = 0.00476800
Iteration 5101, loss = 0.00476675
Iteration 5102, loss = 0.00476510
Iteration 5103, loss = 0.00476362
Iteration 5104, loss = 0.00476228
Iteration 5105, loss = 0.00476096
Iteration 5106, loss = 0.00475950
Iteration 5107, loss = 0.00475840
Iteration 5108, loss = 0.00475687
Iteration 5109, loss = 0.00475627
Iteration 5110, loss = 0.00475437
Iteration 5111, loss = 0.00475281
Iteration 5112, loss = 0.00475142
Iteration 5113, loss = 0.00475005
Iteration 5114, loss = 0.00474866
Iteration 5115, loss = 0.00474727
Iteration 5116, loss = 0.00474579
Iteration 5117, loss = 0.00474483
Iteration 5118, loss = 0.00474393
Iteration 5119, loss = 0.00474232
Iteration 5120, loss = 0.00474086
Iteration 5121, loss = 0.00473960
Iteration 5122, loss = 0.00473837
Iteration 5123, loss = 0.00473718
Iteration 5124, loss = 0.00473568
Iteration 5125, loss = 0.00473466
Iteration 5126, loss = 0.00473306
Iteration 5127, loss = 0.00473197
Iteration 5128, loss = 0.00473083
Iteration 5129, loss = 0.00472951
Iteration 5130, loss = 0.00472819
Iteration 5131, loss = 0.00472686
Iteration 5132, loss = 0.00472577
Iteration 5133, loss = 0.00472488
Iteration 5134, loss = 0.00472319
Iteration 5135, loss = 0.00472203
Iteration 5136, loss = 0.00472035
Iteration 5137, loss = 0.00471919
Iteration 5138, loss = 0.00471781
Iteration 5139, loss = 0.00471652
Iteration 5140, loss = 0.00471504
Iteration 5141, loss = 0.00471384
Iteration 5142, loss = 0.00471266
Iteration 5143, loss = 0.00471128
Iteration 5144, loss = 0.00470964
Iteration 5145, loss = 0.00470831
Iteration 5146, loss = 0.00470685
Iteration 5147, loss = 0.00470585
Iteration 5148, loss = 0.00470443
Iteration 5149, loss = 0.00470306
Iteration 5150, loss = 0.00470181
Iteration 5151, loss = 0.00470075
Iteration 5152, loss = 0.00469922
Iteration 5153, loss = 0.00469803
Iteration 5154, loss = 0.00469665
Iteration 5155, loss = 0.00469520
Iteration 5156, loss = 0.00469386
Iteration 5157, loss = 0.00469247
Iteration 5158, loss = 0.00469160
Iteration 5159, loss = 0.00469039
Iteration 5160, loss = 0.00468856
Iteration 5161, loss = 0.00468728
Iteration 5162, loss = 0.00468589
Iteration 5163, loss = 0.00468445
Iteration 5164, loss = 0.00468320
Iteration 5165, loss = 0.00468183
Iteration 5166, loss = 0.00468061
Iteration 5167, loss = 0.00467931
Iteration 5168, loss = 0.00467807
Iteration 5169, loss = 0.00467694
Iteration 5170, loss = 0.00467584
Iteration 5171, loss = 0.00467440
Iteration 5172, loss = 0.00467328
Iteration 5173, loss = 0.00467211
Iteration 5174, loss = 0.00467095
Iteration 5175, loss = 0.00466968
Iteration 5176, loss = 0.00466890
Iteration 5177, loss = 0.00466749
Iteration 5178, loss = 0.00466609
Iteration 5179, loss = 0.00466481
Iteration 5180, loss = 0.00466356
Iteration 5181, loss = 0.00466218
Iteration 5182, loss = 0.00466098
Iteration 5183, loss = 0.00466001
Iteration 5184, loss = 0.00465858
Iteration 5185, loss = 0.00465716
Iteration 5186, loss = 0.00465597
Iteration 5187, loss = 0.00465462
Iteration 5188, loss = 0.00465331
Iteration 5189, loss = 0.00465219
Iteration 5190, loss = 0.00465104
Iteration 5191, loss = 0.00464969
Iteration 5192, loss = 0.00464848
Iteration 5193, loss = 0.00464711
Iteration 5194, loss = 0.00464573
Iteration 5195, loss = 0.00464470
Iteration 5196, loss = 0.00464348
Iteration 5197, loss = 0.00464254
Iteration 5198, loss = 0.00464098
Iteration 5199, loss = 0.00463957
Iteration 5200, loss = 0.00463846
Iteration 5201, loss = 0.00463680
Iteration 5202, loss = 0.00463569
Iteration 5203, loss = 0.00463416
Iteration 5204, loss = 0.00463323
Iteration 5205, loss = 0.00463187
Iteration 5206, loss = 0.00463023
Iteration 5207, loss = 0.00462883
Iteration 5208, loss = 0.00462741
Iteration 5209, loss = 0.00462659
Iteration 5210, loss = 0.00462480
Iteration 5211, loss = 0.00462354
Iteration 5212, loss = 0.00462221
Iteration 5213, loss = 0.00462088
Iteration 5214, loss = 0.00461959
Iteration 5215, loss = 0.00461846
Iteration 5216, loss = 0.00461742
Iteration 5217, loss = 0.00461610
Iteration 5218, loss = 0.00461520
Iteration 5219, loss = 0.00461390
Iteration 5220, loss = 0.00461268
Iteration 5221, loss = 0.00461155
Iteration 5222, loss = 0.00461093
Iteration 5223, loss = 0.00460904
Iteration 5224, loss = 0.00460811
Iteration 5225, loss = 0.00460681
Iteration 5226, loss = 0.00460542
Iteration 5227, loss = 0.00460456
Iteration 5228, loss = 0.00460310
Iteration 5229, loss = 0.00460188
Iteration 5230, loss = 0.00460069
Iteration 5231, loss = 0.00459952
Iteration 5232, loss = 0.00459818
Iteration 5233, loss = 0.00459687
Iteration 5234, loss = 0.00459588
Iteration 5235, loss = 0.00459456
Iteration 5236, loss = 0.00459251
Iteration 5237, loss = 0.00459133
Iteration 5238, loss = 0.00459054
Iteration 5239, loss = 0.00458874
Iteration 5240, loss = 0.00458758
Iteration 5241, loss = 0.00458681
Iteration 5242, loss = 0.00458574
Iteration 5243, loss = 0.00458414
Iteration 5244, loss = 0.00458285
Iteration 5245, loss = 0.00458177
Iteration 5246, loss = 0.00458047
Iteration 5247, loss = 0.00457948
Iteration 5248, loss = 0.00457872
Iteration 5249, loss = 0.00457715
Iteration 5250, loss = 0.00457613
Iteration 5251, loss = 0.00457499
Iteration 5252, loss = 0.00457355
Iteration 5253, loss = 0.00457249
Iteration 5254, loss = 0.00457128
Iteration 5255, loss = 0.00457006
Iteration 5256, loss = 0.00456899
Iteration 5257, loss = 0.00456771
Iteration 5258, loss = 0.00456643
Iteration 5259, loss = 0.00456517
Iteration 5260, loss = 0.00456403
Iteration 5261, loss = 0.00456273
Iteration 5262, loss = 0.00456134
Iteration 5263, loss = 0.00456005
Iteration 5264, loss = 0.00455891
Iteration 5265, loss = 0.00455755
Iteration 5266, loss = 0.00455628
Iteration 5267, loss = 0.00455518
Iteration 5268, loss = 0.00455384
Iteration 5269, loss = 0.00455236
Iteration 5270, loss = 0.00455162
Iteration 5271, loss = 0.00455051
Iteration 5272, loss = 0.00454891
Iteration 5273, loss = 0.00454762
Iteration 5274, loss = 0.00454638
Iteration 5275, loss = 0.00454531
Iteration 5276, loss = 0.00454427
Iteration 5277, loss = 0.00454305
Iteration 5278, loss = 0.00454194
Iteration 5279, loss = 0.00454033
Iteration 5280, loss = 0.00453921
Iteration 5281, loss = 0.00453808
Iteration 5282, loss = 0.00453676
Iteration 5283, loss = 0.00453560
Iteration 5284, loss = 0.00453431
Iteration 5285, loss = 0.00453315
Iteration 5286, loss = 0.00453201
Iteration 5287, loss = 0.00453110
Iteration 5288, loss = 0.00452987
Iteration 5289, loss = 0.00452853
Iteration 5290, loss = 0.00452733
Iteration 5291, loss = 0.00452633
Iteration 5292, loss = 0.00452493
Iteration 5293, loss = 0.00452382
Iteration 5294, loss = 0.00452259
Iteration 5295, loss = 0.00452172
Iteration 5296, loss = 0.00452026
Iteration 5297, loss = 0.00451866
Iteration 5298, loss = 0.00451815
Iteration 5299, loss = 0.00451653
Iteration 5300, loss = 0.00451551
Iteration 5301, loss = 0.00451417
Iteration 5302, loss = 0.00451269
Iteration 5303, loss = 0.00451155
Iteration 5304, loss = 0.00451022
Iteration 5305, loss = 0.00450912
Iteration 5306, loss = 0.00450801
Iteration 5307, loss = 0.00450659
Iteration 5308, loss = 0.00450516
Iteration 5309, loss = 0.00450396
Iteration 5310, loss = 0.00450269
Iteration 5311, loss = 0.00450151
Iteration 5312, loss = 0.00450003
Iteration 5313, loss = 0.00449881
Iteration 5314, loss = 0.00449777
Iteration 5315, loss = 0.00449642
Iteration 5316, loss = 0.00449521
Iteration 5317, loss = 0.00449421
Iteration 5318, loss = 0.00449342
Iteration 5319, loss = 0.00449164
Iteration 5320, loss = 0.00449057
Iteration 5321, loss = 0.00448938
Iteration 5322, loss = 0.00448815
Iteration 5323, loss = 0.00448712
Iteration 5324, loss = 0.00448596
Iteration 5325, loss = 0.00448486
Iteration 5326, loss = 0.00448403
Iteration 5327, loss = 0.00448253
Iteration 5328, loss = 0.00448155
Iteration 5329, loss = 0.00448007
Iteration 5330, loss = 0.00447899
Iteration 5331, loss = 0.00447778
Iteration 5332, loss = 0.00447661
Iteration 5333, loss = 0.00447554
Iteration 5334, loss = 0.00447432
Iteration 5335, loss = 0.00447328
Iteration 5336, loss = 0.00447226
Iteration 5337, loss = 0.00447074
Iteration 5338, loss = 0.00446962
Iteration 5339, loss = 0.00446842
Iteration 5340, loss = 0.00446706
Iteration 5341, loss = 0.00446602
Iteration 5342, loss = 0.00446483
Iteration 5343, loss = 0.00446370
Iteration 5344, loss = 0.00446233
Iteration 5345, loss = 0.00446150
Iteration 5346, loss = 0.00445993
Iteration 5347, loss = 0.00445884
Iteration 5348, loss = 0.00445735
Iteration 5349, loss = 0.00445633
Iteration 5350, loss = 0.00445560
Iteration 5351, loss = 0.00445401
Iteration 5352, loss = 0.00445273
Iteration 5353, loss = 0.00445147
Iteration 5354, loss = 0.00445033
Iteration 5355, loss = 0.00444912
Iteration 5356, loss = 0.00444786
Iteration 5357, loss = 0.00444676
Iteration 5358, loss = 0.00444548
Iteration 5359, loss = 0.00444440
Iteration 5360, loss = 0.00444329
Iteration 5361, loss = 0.00444228
Iteration 5362, loss = 0.00444128
Iteration 5363, loss = 0.00444008
Iteration 5364, loss = 0.00443919
Iteration 5365, loss = 0.00443794
Iteration 5366, loss = 0.00443684
Iteration 5367, loss = 0.00443606
Iteration 5368, loss = 0.00443468
Iteration 5369, loss = 0.00443391
Iteration 5370, loss = 0.00443257
Iteration 5371, loss = 0.00443169
Iteration 5372, loss = 0.00443036
Iteration 5373, loss = 0.00442918
Iteration 5374, loss = 0.00442843
Iteration 5375, loss = 0.00442694
Iteration 5376, loss = 0.00442609
Iteration 5377, loss = 0.00442472
Iteration 5378, loss = 0.00442362
Iteration 5379, loss = 0.00442239
Iteration 5380, loss = 0.00442144
Iteration 5381, loss = 0.00442036
Iteration 5382, loss = 0.00441881
Iteration 5383, loss = 0.00441778
Iteration 5384, loss = 0.00441656
Iteration 5385, loss = 0.00441537
Iteration 5386, loss = 0.00441421
Iteration 5387, loss = 0.00441293
Iteration 5388, loss = 0.00441167
Iteration 5389, loss = 0.00441047
Iteration 5390, loss = 0.00440922
Iteration 5391, loss = 0.00440820
Iteration 5392, loss = 0.00440676
Iteration 5393, loss = 0.00440555
Iteration 5394, loss = 0.00440429
Iteration 5395, loss = 0.00440310
Iteration 5396, loss = 0.00440205
Iteration 5397, loss = 0.00440073
Iteration 5398, loss = 0.00439958
Iteration 5399, loss = 0.00439851
Iteration 5400, loss = 0.00439772
Iteration 5401, loss = 0.00439628
Iteration 5402, loss = 0.00439523
Iteration 5403, loss = 0.00439392
Iteration 5404, loss = 0.00439313
Iteration 5405, loss = 0.00439180
Iteration 5406, loss = 0.00439055
Iteration 5407, loss = 0.00438946
Iteration 5408, loss = 0.00438838
Iteration 5409, loss = 0.00438728
Iteration 5410, loss = 0.00438638
Iteration 5411, loss = 0.00438513
Iteration 5412, loss = 0.00438406
Iteration 5413, loss = 0.00438317
Iteration 5414, loss = 0.00438187
Iteration 5415, loss = 0.00438067
Iteration 5416, loss = 0.00437949
Iteration 5417, loss = 0.00437959
Iteration 5418, loss = 0.00437764
Iteration 5419, loss = 0.00437670
Iteration 5420, loss = 0.00437516
Iteration 5421, loss = 0.00437393
Iteration 5422, loss = 0.00437273
Iteration 5423, loss = 0.00437146
Iteration 5424, loss = 0.00437077
Iteration 5425, loss = 0.00436896
Iteration 5426, loss = 0.00436785
Iteration 5427, loss = 0.00436689
Iteration 5428, loss = 0.00436580
Iteration 5429, loss = 0.00436450
Iteration 5430, loss = 0.00436357
Iteration 5431, loss = 0.00436220
Iteration 5432, loss = 0.00436146
Iteration 5433, loss = 0.00436022
Iteration 5434, loss = 0.00435907
Iteration 5435, loss = 0.00435798
Iteration 5436, loss = 0.00435730
Iteration 5437, loss = 0.00435582
Iteration 5438, loss = 0.00435478
Iteration 5439, loss = 0.00435392
Iteration 5440, loss = 0.00435253
Iteration 5441, loss = 0.00435206
Iteration 5442, loss = 0.00435038
Iteration 5443, loss = 0.00434936
Iteration 5444, loss = 0.00434824
Iteration 5445, loss = 0.00434699
Iteration 5446, loss = 0.00434578
Iteration 5447, loss = 0.00434469
Iteration 5448, loss = 0.00434353
Iteration 5449, loss = 0.00434245
Iteration 5450, loss = 0.00434123
Iteration 5451, loss = 0.00434017
Iteration 5452, loss = 0.00433907
Iteration 5453, loss = 0.00433777
Iteration 5454, loss = 0.00433741
Iteration 5455, loss = 0.00433578
Iteration 5456, loss = 0.00433461
Iteration 5457, loss = 0.00433360
Iteration 5458, loss = 0.00433240
Iteration 5459, loss = 0.00433122
Iteration 5460, loss = 0.00433006
Iteration 5461, loss = 0.00432889
Iteration 5462, loss = 0.00432800
Iteration 5463, loss = 0.00432741
Iteration 5464, loss = 0.00432597
Iteration 5465, loss = 0.00432482
Iteration 5466, loss = 0.00432372
Iteration 5467, loss = 0.00432277
Iteration 5468, loss = 0.00432187
Iteration 5469, loss = 0.00432077
Iteration 5470, loss = 0.00431968
Iteration 5471, loss = 0.00431864
Iteration 5472, loss = 0.00431754
Iteration 5473, loss = 0.00431652
Iteration 5474, loss = 0.00431550
Iteration 5475, loss = 0.00431481
Iteration 5476, loss = 0.00431368
Iteration 5477, loss = 0.00431339
Iteration 5478, loss = 0.00431174
Iteration 5479, loss = 0.00431077
Iteration 5480, loss = 0.00430958
Iteration 5481, loss = 0.00430861
Iteration 5482, loss = 0.00430796
Iteration 5483, loss = 0.00430656
Iteration 5484, loss = 0.00430566
Iteration 5485, loss = 0.00430444
Iteration 5486, loss = 0.00430350
Iteration 5487, loss = 0.00430235
Iteration 5488, loss = 0.00430267
Iteration 5489, loss = 0.00430059
Iteration 5490, loss = 0.00429929
Iteration 5491, loss = 0.00429818
Iteration 5492, loss = 0.00429709
Iteration 5493, loss = 0.00429599
Iteration 5494, loss = 0.00429490
Iteration 5495, loss = 0.00429380
Iteration 5496, loss = 0.00429268
Iteration 5497, loss = 0.00429170
Iteration 5498, loss = 0.00429064
Iteration 5499, loss = 0.00428953
Iteration 5500, loss = 0.00428814
Iteration 5501, loss = 0.00428707
Iteration 5502, loss = 0.00428591
Iteration 5503, loss = 0.00428472
Iteration 5504, loss = 0.00428357
Iteration 5505, loss = 0.00428240
Iteration 5506, loss = 0.00428141
Iteration 5507, loss = 0.00428043
Iteration 5508, loss = 0.00427912
Iteration 5509, loss = 0.00427789
Iteration 5510, loss = 0.00427685
Iteration 5511, loss = 0.00427566
Iteration 5512, loss = 0.00427455
Iteration 5513, loss = 0.00427350
Iteration 5514, loss = 0.00427237
Iteration 5515, loss = 0.00427133
Iteration 5516, loss = 0.00427037
Iteration 5517, loss = 0.00426920
Iteration 5518, loss = 0.00426827
Iteration 5519, loss = 0.00426713
Iteration 5520, loss = 0.00426633
Iteration 5521, loss = 0.00426493
Iteration 5522, loss = 0.00426361
Iteration 5523, loss = 0.00426253
Iteration 5524, loss = 0.00426190
Iteration 5525, loss = 0.00426053
Iteration 5526, loss = 0.00425944
Iteration 5527, loss = 0.00425849
Iteration 5528, loss = 0.00425734
Iteration 5529, loss = 0.00425633
Iteration 5530, loss = 0.00425536
Iteration 5531, loss = 0.00425421
Iteration 5532, loss = 0.00425326
Iteration 5533, loss = 0.00425204
Iteration 5534, loss = 0.00425097
Iteration 5535, loss = 0.00424983
Iteration 5536, loss = 0.00424873
Iteration 5537, loss = 0.00424760
Iteration 5538, loss = 0.00424648
Iteration 5539, loss = 0.00424565
Iteration 5540, loss = 0.00424443
Iteration 5541, loss = 0.00424342
Iteration 5542, loss = 0.00424248
Iteration 5543, loss = 0.00424155
Iteration 5544, loss = 0.00424036
Iteration 5545, loss = 0.00423928
Iteration 5546, loss = 0.00423845
Iteration 5547, loss = 0.00423718
Iteration 5548, loss = 0.00423610
Iteration 5549, loss = 0.00423496
Iteration 5550, loss = 0.00423371
Iteration 5551, loss = 0.00423279
Iteration 5552, loss = 0.00423157
Iteration 5553, loss = 0.00423094
Iteration 5554, loss = 0.00422932
Iteration 5555, loss = 0.00422816
Iteration 5556, loss = 0.00422698
Iteration 5557, loss = 0.00422588
Iteration 5558, loss = 0.00422474
Iteration 5559, loss = 0.00422373
Iteration 5560, loss = 0.00422264
Iteration 5561, loss = 0.00422139
Iteration 5562, loss = 0.00422038
Iteration 5563, loss = 0.00421940
Iteration 5564, loss = 0.00421830
Iteration 5565, loss = 0.00421732
Iteration 5566, loss = 0.00421643
Iteration 5567, loss = 0.00421514
Iteration 5568, loss = 0.00421407
Iteration 5569, loss = 0.00421318
Iteration 5570, loss = 0.00421215
Iteration 5571, loss = 0.00421097
Iteration 5572, loss = 0.00420983
Iteration 5573, loss = 0.00420913
Iteration 5574, loss = 0.00420767
Iteration 5575, loss = 0.00420669
Iteration 5576, loss = 0.00420581
Iteration 5577, loss = 0.00420455
Iteration 5578, loss = 0.00420385
Iteration 5579, loss = 0.00420314
Iteration 5580, loss = 0.00420173
Iteration 5581, loss = 0.00420082
Iteration 5582, loss = 0.00419983
Iteration 5583, loss = 0.00419879
Iteration 5584, loss = 0.00419791
Iteration 5585, loss = 0.00419678
Iteration 5586, loss = 0.00419584
Iteration 5587, loss = 0.00419489
Iteration 5588, loss = 0.00419427
Iteration 5589, loss = 0.00419291
Iteration 5590, loss = 0.00419182
Iteration 5591, loss = 0.00419082
Iteration 5592, loss = 0.00419038
Iteration 5593, loss = 0.00418892
Iteration 5594, loss = 0.00418776
Iteration 5595, loss = 0.00418662
Iteration 5596, loss = 0.00418580
Iteration 5597, loss = 0.00418451
Iteration 5598, loss = 0.00418334
Iteration 5599, loss = 0.00418237
Iteration 5600, loss = 0.00418149
Iteration 5601, loss = 0.00418025
Iteration 5602, loss = 0.00417907
Iteration 5603, loss = 0.00417775
Iteration 5604, loss = 0.00417739
Iteration 5605, loss = 0.00417569
Iteration 5606, loss = 0.00417443
Iteration 5607, loss = 0.00417353
Iteration 5608, loss = 0.00417238
Iteration 5609, loss = 0.00417138
Iteration 5610, loss = 0.00417006
Iteration 5611, loss = 0.00416889
Iteration 5612, loss = 0.00416817
Iteration 5613, loss = 0.00416671
Iteration 5614, loss = 0.00416559
Iteration 5615, loss = 0.00416481
Iteration 5616, loss = 0.00416346
Iteration 5617, loss = 0.00416282
Iteration 5618, loss = 0.00416115
Iteration 5619, loss = 0.00416014
Iteration 5620, loss = 0.00415915
Iteration 5621, loss = 0.00415776
Iteration 5622, loss = 0.00415671
Iteration 5623, loss = 0.00415555
Iteration 5624, loss = 0.00415457
Iteration 5625, loss = 0.00415337
Iteration 5626, loss = 0.00415232
Iteration 5627, loss = 0.00415121
Iteration 5628, loss = 0.00415007
Iteration 5629, loss = 0.00414907
Iteration 5630, loss = 0.00414811
Iteration 5631, loss = 0.00414698
Iteration 5632, loss = 0.00414571
Iteration 5633, loss = 0.00414460
Iteration 5634, loss = 0.00414338
Iteration 5635, loss = 0.00414245
Iteration 5636, loss = 0.00414129
Iteration 5637, loss = 0.00414018
Iteration 5638, loss = 0.00413933
Iteration 5639, loss = 0.00413800
Iteration 5640, loss = 0.00413706
Iteration 5641, loss = 0.00413594
Iteration 5642, loss = 0.00413468
Iteration 5643, loss = 0.00413381
Iteration 5644, loss = 0.00413279
Iteration 5645, loss = 0.00413143
Iteration 5646, loss = 0.00413052
Iteration 5647, loss = 0.00412938
Iteration 5648, loss = 0.00412825
Iteration 5649, loss = 0.00412713
Iteration 5650, loss = 0.00412654
Iteration 5651, loss = 0.00412515
Iteration 5652, loss = 0.00412426
Iteration 5653, loss = 0.00412298
Iteration 5654, loss = 0.00412198
Iteration 5655, loss = 0.00412101
Iteration 5656, loss = 0.00412002
Iteration 5657, loss = 0.00411904
Iteration 5658, loss = 0.00411804
Iteration 5659, loss = 0.00411714
Iteration 5660, loss = 0.00411600
Iteration 5661, loss = 0.00411507
Iteration 5662, loss = 0.00411417
Iteration 5663, loss = 0.00411303
Iteration 5664, loss = 0.00411189
Iteration 5665, loss = 0.00411123
Iteration 5666, loss = 0.00410995
Iteration 5667, loss = 0.00410890
Iteration 5668, loss = 0.00410818
Iteration 5669, loss = 0.00410710
Iteration 5670, loss = 0.00410610
Iteration 5671, loss = 0.00410503
Iteration 5672, loss = 0.00410463
Iteration 5673, loss = 0.00410302
Iteration 5674, loss = 0.00410203
Iteration 5675, loss = 0.00410101
Iteration 5676, loss = 0.00409993
Iteration 5677, loss = 0.00409900
Iteration 5678, loss = 0.00409803
Iteration 5679, loss = 0.00409685
Iteration 5680, loss = 0.00409624
Iteration 5681, loss = 0.00409479
Iteration 5682, loss = 0.00409358
Iteration 5683, loss = 0.00409229
Iteration 5684, loss = 0.00409123
Iteration 5685, loss = 0.00409017
Iteration 5686, loss = 0.00408901
Iteration 5687, loss = 0.00408768
Iteration 5688, loss = 0.00408728
Iteration 5689, loss = 0.00408567
Iteration 5690, loss = 0.00408461
Iteration 5691, loss = 0.00408347
Iteration 5692, loss = 0.00408245
Iteration 5693, loss = 0.00408139
Iteration 5694, loss = 0.00408043
Iteration 5695, loss = 0.00407938
Iteration 5696, loss = 0.00407839
Iteration 5697, loss = 0.00407716
Iteration 5698, loss = 0.00407658
Iteration 5699, loss = 0.00407527
Iteration 5700, loss = 0.00407417
Iteration 5701, loss = 0.00407311
Iteration 5702, loss = 0.00407227
Iteration 5703, loss = 0.00407141
Iteration 5704, loss = 0.00406993
Iteration 5705, loss = 0.00406872
Iteration 5706, loss = 0.00406782
Iteration 5707, loss = 0.00406703
Iteration 5708, loss = 0.00406654
Iteration 5709, loss = 0.00406512
Iteration 5710, loss = 0.00406432
Iteration 5711, loss = 0.00406306
Iteration 5712, loss = 0.00406195
Iteration 5713, loss = 0.00406097
Iteration 5714, loss = 0.00406002
Iteration 5715, loss = 0.00405889
Iteration 5716, loss = 0.00405769
Iteration 5717, loss = 0.00405657
Iteration 5718, loss = 0.00405544
Iteration 5719, loss = 0.00405443
Iteration 5720, loss = 0.00405325
Iteration 5721, loss = 0.00405280
Iteration 5722, loss = 0.00405143
Iteration 5723, loss = 0.00405100
Iteration 5724, loss = 0.00404968
Iteration 5725, loss = 0.00404848
Iteration 5726, loss = 0.00404714
Iteration 5727, loss = 0.00404626
Iteration 5728, loss = 0.00404609
Iteration 5729, loss = 0.00404448
Iteration 5730, loss = 0.00404354
Iteration 5731, loss = 0.00404232
Iteration 5732, loss = 0.00404162
Iteration 5733, loss = 0.00404051
Iteration 5734, loss = 0.00403935
Iteration 5735, loss = 0.00403835
Iteration 5736, loss = 0.00403741
Iteration 5737, loss = 0.00403661
Iteration 5738, loss = 0.00403548
Iteration 5739, loss = 0.00403449
Iteration 5740, loss = 0.00403348
Iteration 5741, loss = 0.00403240
Iteration 5742, loss = 0.00403174
Iteration 5743, loss = 0.00403049
Iteration 5744, loss = 0.00402953
Iteration 5745, loss = 0.00402844
Iteration 5746, loss = 0.00402740
Iteration 5747, loss = 0.00402638
Iteration 5748, loss = 0.00402537
Iteration 5749, loss = 0.00402443
Iteration 5750, loss = 0.00402382
Iteration 5751, loss = 0.00402260
Iteration 5752, loss = 0.00402162
Iteration 5753, loss = 0.00402085
Iteration 5754, loss = 0.00401968
Iteration 5755, loss = 0.00401869
Iteration 5756, loss = 0.00401773
Iteration 5757, loss = 0.00401667
Iteration 5758, loss = 0.00401570
Iteration 5759, loss = 0.00401472
Iteration 5760, loss = 0.00401362
Iteration 5761, loss = 0.00401285
Iteration 5762, loss = 0.00401165
Iteration 5763, loss = 0.00401098
Iteration 5764, loss = 0.00400968
Iteration 5765, loss = 0.00400868
Iteration 5766, loss = 0.00400767
Iteration 5767, loss = 0.00400690
Iteration 5768, loss = 0.00400579
Iteration 5769, loss = 0.00400501
Iteration 5770, loss = 0.00400399
Iteration 5771, loss = 0.00400300
Iteration 5772, loss = 0.00400210
Iteration 5773, loss = 0.00400162
Iteration 5774, loss = 0.00400023
Iteration 5775, loss = 0.00399940
Iteration 5776, loss = 0.00399845
Iteration 5777, loss = 0.00399733
Iteration 5778, loss = 0.00399715
Iteration 5779, loss = 0.00399549
Iteration 5780, loss = 0.00399450
Iteration 5781, loss = 0.00399345
Iteration 5782, loss = 0.00399244
Iteration 5783, loss = 0.00399135
Iteration 5784, loss = 0.00399033
Iteration 5785, loss = 0.00398948
Iteration 5786, loss = 0.00398834
Iteration 5787, loss = 0.00398760
Iteration 5788, loss = 0.00398641
Iteration 5789, loss = 0.00398552
Iteration 5790, loss = 0.00398451
Iteration 5791, loss = 0.00398337
Iteration 5792, loss = 0.00398300
Iteration 5793, loss = 0.00398154
Iteration 5794, loss = 0.00398050
Iteration 5795, loss = 0.00397943
Iteration 5796, loss = 0.00397849
Iteration 5797, loss = 0.00397766
Iteration 5798, loss = 0.00397641
Iteration 5799, loss = 0.00397536
Iteration 5800, loss = 0.00397446
Iteration 5801, loss = 0.00397336
Iteration 5802, loss = 0.00397225
Iteration 5803, loss = 0.00397137
Iteration 5804, loss = 0.00397040
Iteration 5805, loss = 0.00396953
Iteration 5806, loss = 0.00396843
Iteration 5807, loss = 0.00396806
Iteration 5808, loss = 0.00396682
Iteration 5809, loss = 0.00396598
Iteration 5810, loss = 0.00396496
Iteration 5811, loss = 0.00396389
Iteration 5812, loss = 0.00396316
Iteration 5813, loss = 0.00396213
Iteration 5814, loss = 0.00396124
Iteration 5815, loss = 0.00396061
Iteration 5816, loss = 0.00395948
Iteration 5817, loss = 0.00395846
Iteration 5818, loss = 0.00395771
Iteration 5819, loss = 0.00395688
Iteration 5820, loss = 0.00395584
Iteration 5821, loss = 0.00395501
Iteration 5822, loss = 0.00395429
Iteration 5823, loss = 0.00395303
Iteration 5824, loss = 0.00395238
Iteration 5825, loss = 0.00395118
Iteration 5826, loss = 0.00395031
Iteration 5827, loss = 0.00394917
Iteration 5828, loss = 0.00394854
Iteration 5829, loss = 0.00394780
Iteration 5830, loss = 0.00394613
Iteration 5831, loss = 0.00394505
Iteration 5832, loss = 0.00394416
Iteration 5833, loss = 0.00394308
Iteration 5834, loss = 0.00394211
Iteration 5835, loss = 0.00394117
Iteration 5836, loss = 0.00394016
Iteration 5837, loss = 0.00393919
Iteration 5838, loss = 0.00393818
Iteration 5839, loss = 0.00393731
Iteration 5840, loss = 0.00393637
Iteration 5841, loss = 0.00393536
Iteration 5842, loss = 0.00393440
Iteration 5843, loss = 0.00393353
Iteration 5844, loss = 0.00393249
Iteration 5845, loss = 0.00393173
Iteration 5846, loss = 0.00393081
Iteration 5847, loss = 0.00392964
Iteration 5848, loss = 0.00392866
Iteration 5849, loss = 0.00392780
Iteration 5850, loss = 0.00392675
Iteration 5851, loss = 0.00392579
Iteration 5852, loss = 0.00392508
Iteration 5853, loss = 0.00392411
Iteration 5854, loss = 0.00392319
Iteration 5855, loss = 0.00392210
Iteration 5856, loss = 0.00392137
Iteration 5857, loss = 0.00392052
Iteration 5858, loss = 0.00391939
Iteration 5859, loss = 0.00391871
Iteration 5860, loss = 0.00391771
Iteration 5861, loss = 0.00391655
Iteration 5862, loss = 0.00391559
Iteration 5863, loss = 0.00391468
Iteration 5864, loss = 0.00391385
Iteration 5865, loss = 0.00391277
Iteration 5866, loss = 0.00391194
Iteration 5867, loss = 0.00391105
Iteration 5868, loss = 0.00391003
Iteration 5869, loss = 0.00390909
Iteration 5870, loss = 0.00390846
Iteration 5871, loss = 0.00390711
Iteration 5872, loss = 0.00390612
Iteration 5873, loss = 0.00390512
Iteration 5874, loss = 0.00390438
Iteration 5875, loss = 0.00390320
Iteration 5876, loss = 0.00390259
Iteration 5877, loss = 0.00390142
Iteration 5878, loss = 0.00390037
Iteration 5879, loss = 0.00389945
Iteration 5880, loss = 0.00389847
Iteration 5881, loss = 0.00389764
Iteration 5882, loss = 0.00389654
Iteration 5883, loss = 0.00389589
Iteration 5884, loss = 0.00389467
Iteration 5885, loss = 0.00389383
Iteration 5886, loss = 0.00389288
Iteration 5887, loss = 0.00389200
Iteration 5888, loss = 0.00389097
Iteration 5889, loss = 0.00389038
Iteration 5890, loss = 0.00388933
Iteration 5891, loss = 0.00388837
Iteration 5892, loss = 0.00388816
Iteration 5893, loss = 0.00388665
Iteration 5894, loss = 0.00388575
Iteration 5895, loss = 0.00388484
Iteration 5896, loss = 0.00388379
Iteration 5897, loss = 0.00388288
Iteration 5898, loss = 0.00388198
Iteration 5899, loss = 0.00388103
Iteration 5900, loss = 0.00388012
Iteration 5901, loss = 0.00387929
Iteration 5902, loss = 0.00387836
Iteration 5903, loss = 0.00387753
Iteration 5904, loss = 0.00387660
Iteration 5905, loss = 0.00387560
Iteration 5906, loss = 0.00387504
Iteration 5907, loss = 0.00387400
Iteration 5908, loss = 0.00387306
Iteration 5909, loss = 0.00387214
Iteration 5910, loss = 0.00387136
Iteration 5911, loss = 0.00387036
Iteration 5912, loss = 0.00386915
Iteration 5913, loss = 0.00386859
Iteration 5914, loss = 0.00386746
Iteration 5915, loss = 0.00386658
Iteration 5916, loss = 0.00386554
Iteration 5917, loss = 0.00386466
Iteration 5918, loss = 0.00386366
Iteration 5919, loss = 0.00386315
Iteration 5920, loss = 0.00386193
Iteration 5921, loss = 0.00386094
Iteration 5922, loss = 0.00386005
Iteration 5923, loss = 0.00385912
Iteration 5924, loss = 0.00385829
Iteration 5925, loss = 0.00385720
Iteration 5926, loss = 0.00385629
Iteration 5927, loss = 0.00385558
Iteration 5928, loss = 0.00385440
Iteration 5929, loss = 0.00385341
Iteration 5930, loss = 0.00385245
Iteration 5931, loss = 0.00385159
Iteration 5932, loss = 0.00385052
Iteration 5933, loss = 0.00384941
Iteration 5934, loss = 0.00384834
Iteration 5935, loss = 0.00384726
Iteration 5936, loss = 0.00384610
Iteration 5937, loss = 0.00384550
Iteration 5938, loss = 0.00384452
Iteration 5939, loss = 0.00384364
Iteration 5940, loss = 0.00384246
Iteration 5941, loss = 0.00384150
Iteration 5942, loss = 0.00384062
Iteration 5943, loss = 0.00383974
Iteration 5944, loss = 0.00383899
Iteration 5945, loss = 0.00383801
Iteration 5946, loss = 0.00383721
Iteration 5947, loss = 0.00383629
Iteration 5948, loss = 0.00383551
Iteration 5949, loss = 0.00383451
Iteration 5950, loss = 0.00383366
Iteration 5951, loss = 0.00383301
Iteration 5952, loss = 0.00383199
Iteration 5953, loss = 0.00383100
Iteration 5954, loss = 0.00383009
Iteration 5955, loss = 0.00382923
Iteration 5956, loss = 0.00382830
Iteration 5957, loss = 0.00382741
Iteration 5958, loss = 0.00382646
Iteration 5959, loss = 0.00382584
Iteration 5960, loss = 0.00382464
Iteration 5961, loss = 0.00382387
Iteration 5962, loss = 0.00382305
Iteration 5963, loss = 0.00382235
Iteration 5964, loss = 0.00382131
Iteration 5965, loss = 0.00382042
Iteration 5966, loss = 0.00381945
Iteration 5967, loss = 0.00381868
Iteration 5968, loss = 0.00381786
Iteration 5969, loss = 0.00381676
Iteration 5970, loss = 0.00381593
Iteration 5971, loss = 0.00381539
Iteration 5972, loss = 0.00381423
Iteration 5973, loss = 0.00381347
Iteration 5974, loss = 0.00381277
Iteration 5975, loss = 0.00381187
Iteration 5976, loss = 0.00381090
Iteration 5977, loss = 0.00381004
Iteration 5978, loss = 0.00380920
Iteration 5979, loss = 0.00380826
Iteration 5980, loss = 0.00380753
Iteration 5981, loss = 0.00380640
Iteration 5982, loss = 0.00380546
Iteration 5983, loss = 0.00380458
Iteration 5984, loss = 0.00380361
Iteration 5985, loss = 0.00380292
Iteration 5986, loss = 0.00380190
Iteration 5987, loss = 0.00380123
Iteration 5988, loss = 0.00379997
Iteration 5989, loss = 0.00379899
Iteration 5990, loss = 0.00379828
Iteration 5991, loss = 0.00379721
Iteration 5992, loss = 0.00379621
Iteration 5993, loss = 0.00379538
Iteration 5994, loss = 0.00379444
Iteration 5995, loss = 0.00379349
Iteration 5996, loss = 0.00379282
Iteration 5997, loss = 0.00379186
Iteration 5998, loss = 0.00379101
Iteration 5999, loss = 0.00379031
Iteration 6000, loss = 0.00378935
Iteration 6001, loss = 0.00378839
Iteration 6002, loss = 0.00378743
Iteration 6003, loss = 0.00378665
Iteration 6004, loss = 0.00378566
Iteration 6005, loss = 0.00378492
Iteration 6006, loss = 0.00378400
Iteration 6007, loss = 0.00378308
Iteration 6008, loss = 0.00378214
Iteration 6009, loss = 0.00378136
Iteration 6010, loss = 0.00378055
Iteration 6011, loss = 0.00377971
Iteration 6012, loss = 0.00377912
Iteration 6013, loss = 0.00377816
Iteration 6014, loss = 0.00377725
Iteration 6015, loss = 0.00377624
Iteration 6016, loss = 0.00377540
Iteration 6017, loss = 0.00377445
Iteration 6018, loss = 0.00377386
Iteration 6019, loss = 0.00377270
Iteration 6020, loss = 0.00377175
Iteration 6021, loss = 0.00377084
Iteration 6022, loss = 0.00376996
Iteration 6023, loss = 0.00376913
Iteration 6024, loss = 0.00376857
Iteration 6025, loss = 0.00376744
Iteration 6026, loss = 0.00376664
Iteration 6027, loss = 0.00376581
Iteration 6028, loss = 0.00376499
Iteration 6029, loss = 0.00376412
Iteration 6030, loss = 0.00376339
Iteration 6031, loss = 0.00376251
Iteration 6032, loss = 0.00376173
Iteration 6033, loss = 0.00376078
Iteration 6034, loss = 0.00375991
Iteration 6035, loss = 0.00375913
Iteration 6036, loss = 0.00375815
Iteration 6037, loss = 0.00375722
Iteration 6038, loss = 0.00375633
Iteration 6039, loss = 0.00375533
Iteration 6040, loss = 0.00375432
Iteration 6041, loss = 0.00375383
Iteration 6042, loss = 0.00375291
Iteration 6043, loss = 0.00375162
Iteration 6044, loss = 0.00375102
Iteration 6045, loss = 0.00375002
Iteration 6046, loss = 0.00374898
Iteration 6047, loss = 0.00374796
Iteration 6048, loss = 0.00374706
Iteration 6049, loss = 0.00374611
Iteration 6050, loss = 0.00374521
Iteration 6051, loss = 0.00374462
Iteration 6052, loss = 0.00374361
Iteration 6053, loss = 0.00374275
Iteration 6054, loss = 0.00374176
Iteration 6055, loss = 0.00374093
Iteration 6056, loss = 0.00374007
Iteration 6057, loss = 0.00373932
Iteration 6058, loss = 0.00373849
Iteration 6059, loss = 0.00373799
Iteration 6060, loss = 0.00373684
Iteration 6061, loss = 0.00373584
Iteration 6062, loss = 0.00373494
Iteration 6063, loss = 0.00373430
Iteration 6064, loss = 0.00373308
Iteration 6065, loss = 0.00373230
Iteration 6066, loss = 0.00373137
Iteration 6067, loss = 0.00373042
Iteration 6068, loss = 0.00372953
Iteration 6069, loss = 0.00372880
Iteration 6070, loss = 0.00372798
Iteration 6071, loss = 0.00372699
Iteration 6072, loss = 0.00372622
Iteration 6073, loss = 0.00372538
Iteration 6074, loss = 0.00372462
Iteration 6075, loss = 0.00372382
Iteration 6076, loss = 0.00372292
Iteration 6077, loss = 0.00372218
Iteration 6078, loss = 0.00372123
Iteration 6079, loss = 0.00372030
Iteration 6080, loss = 0.00371936
Iteration 6081, loss = 0.00371856
Iteration 6082, loss = 0.00371775
Iteration 6083, loss = 0.00371690
Iteration 6084, loss = 0.00371589
Iteration 6085, loss = 0.00371496
Iteration 6086, loss = 0.00371416
Iteration 6087, loss = 0.00371327
Iteration 6088, loss = 0.00371240
Iteration 6089, loss = 0.00371153
Iteration 6090, loss = 0.00371064
Iteration 6091, loss = 0.00370969
Iteration 6092, loss = 0.00370871
Iteration 6093, loss = 0.00370804
Iteration 6094, loss = 0.00370704
Iteration 6095, loss = 0.00370660
Iteration 6096, loss = 0.00370535
Iteration 6097, loss = 0.00370435
Iteration 6098, loss = 0.00370358
Iteration 6099, loss = 0.00370272
Iteration 6100, loss = 0.00370187
Iteration 6101, loss = 0.00370106
Iteration 6102, loss = 0.00370021
Iteration 6103, loss = 0.00369967
Iteration 6104, loss = 0.00369857
Iteration 6105, loss = 0.00369769
Iteration 6106, loss = 0.00369680
Iteration 6107, loss = 0.00369593
Iteration 6108, loss = 0.00369513
Iteration 6109, loss = 0.00369419
Iteration 6110, loss = 0.00369331
Iteration 6111, loss = 0.00369248
Iteration 6112, loss = 0.00369162
Iteration 6113, loss = 0.00369080
Iteration 6114, loss = 0.00368997
Iteration 6115, loss = 0.00368949
Iteration 6116, loss = 0.00368859
Iteration 6117, loss = 0.00368762
Iteration 6118, loss = 0.00368678
Iteration 6119, loss = 0.00368602
Iteration 6120, loss = 0.00368510
Iteration 6121, loss = 0.00368454
Iteration 6122, loss = 0.00368349
Iteration 6123, loss = 0.00368275
Iteration 6124, loss = 0.00368196
Iteration 6125, loss = 0.00368132
Iteration 6126, loss = 0.00368032
Iteration 6127, loss = 0.00367952
Iteration 6128, loss = 0.00367855
Iteration 6129, loss = 0.00367770
Iteration 6130, loss = 0.00367708
Iteration 6131, loss = 0.00367709
Iteration 6132, loss = 0.00367543
Iteration 6133, loss = 0.00367485
Iteration 6134, loss = 0.00367372
Iteration 6135, loss = 0.00367267
Iteration 6136, loss = 0.00367196
Iteration 6137, loss = 0.00367089
Iteration 6138, loss = 0.00367030
Iteration 6139, loss = 0.00366930
Iteration 6140, loss = 0.00366852
Iteration 6141, loss = 0.00366762
Iteration 6142, loss = 0.00366701
Iteration 6143, loss = 0.00366587
Iteration 6144, loss = 0.00366514
Iteration 6145, loss = 0.00366412
Iteration 6146, loss = 0.00366355
Iteration 6147, loss = 0.00366257
Iteration 6148, loss = 0.00366164
Iteration 6149, loss = 0.00366077
Iteration 6150, loss = 0.00365998
Iteration 6151, loss = 0.00365915
Iteration 6152, loss = 0.00365843
Iteration 6153, loss = 0.00365758
Iteration 6154, loss = 0.00365683
Iteration 6155, loss = 0.00365610
Iteration 6156, loss = 0.00365541
Iteration 6157, loss = 0.00365433
Iteration 6158, loss = 0.00365335
Iteration 6159, loss = 0.00365272
Iteration 6160, loss = 0.00365188
Iteration 6161, loss = 0.00365079
Iteration 6162, loss = 0.00364984
Iteration 6163, loss = 0.00364883
Iteration 6164, loss = 0.00364857
Iteration 6165, loss = 0.00364718
Iteration 6166, loss = 0.00364615
Iteration 6167, loss = 0.00364526
Iteration 6168, loss = 0.00364458
Iteration 6169, loss = 0.00364378
Iteration 6170, loss = 0.00364268
Iteration 6171, loss = 0.00364169
Iteration 6172, loss = 0.00364081
Iteration 6173, loss = 0.00364002
Iteration 6174, loss = 0.00363898
Iteration 6175, loss = 0.00363799
Iteration 6176, loss = 0.00363758
Iteration 6177, loss = 0.00363641
Iteration 6178, loss = 0.00363546
Iteration 6179, loss = 0.00363455
Iteration 6180, loss = 0.00363397
Iteration 6181, loss = 0.00363275
Iteration 6182, loss = 0.00363236
Iteration 6183, loss = 0.00363163
Iteration 6184, loss = 0.00363054
Iteration 6185, loss = 0.00362950
Iteration 6186, loss = 0.00362872
Iteration 6187, loss = 0.00362786
Iteration 6188, loss = 0.00362718
Iteration 6189, loss = 0.00362629
Iteration 6190, loss = 0.00362550
Iteration 6191, loss = 0.00362491
Iteration 6192, loss = 0.00362401
Iteration 6193, loss = 0.00362351
Iteration 6194, loss = 0.00362241
Iteration 6195, loss = 0.00362180
Iteration 6196, loss = 0.00362090
Iteration 6197, loss = 0.00362006
Iteration 6198, loss = 0.00361937
Iteration 6199, loss = 0.00361855
Iteration 6200, loss = 0.00361767
Iteration 6201, loss = 0.00361694
Iteration 6202, loss = 0.00361614
Iteration 6203, loss = 0.00361534
Iteration 6204, loss = 0.00361454
Iteration 6205, loss = 0.00361376
Iteration 6206, loss = 0.00361299
Iteration 6207, loss = 0.00361235
Iteration 6208, loss = 0.00361156
Iteration 6209, loss = 0.00361089
Iteration 6210, loss = 0.00361015
Iteration 6211, loss = 0.00360944
Iteration 6212, loss = 0.00360877
Iteration 6213, loss = 0.00360806
Iteration 6214, loss = 0.00360727
Iteration 6215, loss = 0.00360654
Iteration 6216, loss = 0.00360593
Iteration 6217, loss = 0.00360529
Iteration 6218, loss = 0.00360446
Iteration 6219, loss = 0.00360371
Iteration 6220, loss = 0.00360317
Iteration 6221, loss = 0.00360255
Iteration 6222, loss = 0.00360166
Iteration 6223, loss = 0.00360089
Iteration 6224, loss = 0.00360003
Iteration 6225, loss = 0.00359904
Iteration 6226, loss = 0.00359807
Iteration 6227, loss = 0.00359761
Iteration 6228, loss = 0.00359632
Iteration 6229, loss = 0.00359584
Iteration 6230, loss = 0.00359470
Iteration 6231, loss = 0.00359377
Iteration 6232, loss = 0.00359294
Iteration 6233, loss = 0.00359210
Iteration 6234, loss = 0.00359134
Iteration 6235, loss = 0.00359023
Iteration 6236, loss = 0.00358946
Iteration 6237, loss = 0.00358855
Iteration 6238, loss = 0.00358772
Iteration 6239, loss = 0.00358697
Iteration 6240, loss = 0.00358604
Iteration 6241, loss = 0.00358524
Iteration 6242, loss = 0.00358453
Iteration 6243, loss = 0.00358369
Iteration 6244, loss = 0.00358289
Iteration 6245, loss = 0.00358220
Iteration 6246, loss = 0.00358141
Iteration 6247, loss = 0.00358061
Iteration 6248, loss = 0.00357997
Iteration 6249, loss = 0.00357909
Iteration 6250, loss = 0.00357825
Iteration 6251, loss = 0.00357751
Iteration 6252, loss = 0.00357682
Iteration 6253, loss = 0.00357590
Iteration 6254, loss = 0.00357503
Iteration 6255, loss = 0.00357421
Iteration 6256, loss = 0.00357332
Iteration 6257, loss = 0.00357280
Iteration 6258, loss = 0.00357175
Iteration 6259, loss = 0.00357084
Iteration 6260, loss = 0.00357004
Iteration 6261, loss = 0.00356918
Iteration 6262, loss = 0.00356830
Iteration 6263, loss = 0.00356739
Iteration 6264, loss = 0.00356680
Iteration 6265, loss = 0.00356592
Iteration 6266, loss = 0.00356550
Iteration 6267, loss = 0.00356437
Iteration 6268, loss = 0.00356362
Iteration 6269, loss = 0.00356283
Iteration 6270, loss = 0.00356206
Iteration 6271, loss = 0.00356126
Iteration 6272, loss = 0.00356044
Iteration 6273, loss = 0.00355969
Iteration 6274, loss = 0.00355887
Iteration 6275, loss = 0.00355811
Iteration 6276, loss = 0.00355735
Iteration 6277, loss = 0.00355654
Iteration 6278, loss = 0.00355573
Iteration 6279, loss = 0.00355501
Iteration 6280, loss = 0.00355417
Iteration 6281, loss = 0.00355345
Iteration 6282, loss = 0.00355267
Iteration 6283, loss = 0.00355194
Iteration 6284, loss = 0.00355158
Iteration 6285, loss = 0.00355043
Iteration 6286, loss = 0.00354961
Iteration 6287, loss = 0.00354935
Iteration 6288, loss = 0.00354819
Iteration 6289, loss = 0.00354730
Iteration 6290, loss = 0.00354634
Iteration 6291, loss = 0.00354551
Iteration 6292, loss = 0.00354485
Iteration 6293, loss = 0.00354444
Iteration 6294, loss = 0.00354361
Iteration 6295, loss = 0.00354254
Iteration 6296, loss = 0.00354183
Iteration 6297, loss = 0.00354109
Iteration 6298, loss = 0.00354015
Iteration 6299, loss = 0.00353941
Iteration 6300, loss = 0.00353857
Iteration 6301, loss = 0.00353769
Iteration 6302, loss = 0.00353688
Iteration 6303, loss = 0.00353617
Iteration 6304, loss = 0.00353519
Iteration 6305, loss = 0.00353465
Iteration 6306, loss = 0.00353359
Iteration 6307, loss = 0.00353272
Iteration 6308, loss = 0.00353202
Iteration 6309, loss = 0.00353103
Iteration 6310, loss = 0.00353036
Iteration 6311, loss = 0.00352943
Iteration 6312, loss = 0.00352870
Iteration 6313, loss = 0.00352814
Iteration 6314, loss = 0.00352711
Iteration 6315, loss = 0.00352675
Iteration 6316, loss = 0.00352547
Iteration 6317, loss = 0.00352451
Iteration 6318, loss = 0.00352375
Iteration 6319, loss = 0.00352304
Iteration 6320, loss = 0.00352210
Iteration 6321, loss = 0.00352121
Iteration 6322, loss = 0.00352041
Iteration 6323, loss = 0.00351940
Iteration 6324, loss = 0.00351879
Iteration 6325, loss = 0.00351803
Iteration 6326, loss = 0.00351699
Iteration 6327, loss = 0.00351634
Iteration 6328, loss = 0.00351546
Iteration 6329, loss = 0.00351462
Iteration 6330, loss = 0.00351387
Iteration 6331, loss = 0.00351300
Iteration 6332, loss = 0.00351213
Iteration 6333, loss = 0.00351131
Iteration 6334, loss = 0.00351064
Iteration 6335, loss = 0.00350974
Iteration 6336, loss = 0.00350905
Iteration 6337, loss = 0.00350824
Iteration 6338, loss = 0.00350749
Iteration 6339, loss = 0.00350686
Iteration 6340, loss = 0.00350593
Iteration 6341, loss = 0.00350521
Iteration 6342, loss = 0.00350456
Iteration 6343, loss = 0.00350376
Iteration 6344, loss = 0.00350305
Iteration 6345, loss = 0.00350240
Iteration 6346, loss = 0.00350181
Iteration 6347, loss = 0.00350078
Iteration 6348, loss = 0.00350011
Iteration 6349, loss = 0.00349941
Iteration 6350, loss = 0.00349893
Iteration 6351, loss = 0.00349820
Iteration 6352, loss = 0.00349738
Iteration 6353, loss = 0.00349667
Iteration 6354, loss = 0.00349601
Iteration 6355, loss = 0.00349520
Iteration 6356, loss = 0.00349439
Iteration 6357, loss = 0.00349375
Iteration 6358, loss = 0.00349291
Iteration 6359, loss = 0.00349217
Iteration 6360, loss = 0.00349137
Iteration 6361, loss = 0.00349060
Iteration 6362, loss = 0.00348993
Iteration 6363, loss = 0.00348922
Iteration 6364, loss = 0.00348846
Iteration 6365, loss = 0.00348788
Iteration 6366, loss = 0.00348707
Iteration 6367, loss = 0.00348625
Iteration 6368, loss = 0.00348557
Iteration 6369, loss = 0.00348486
Iteration 6370, loss = 0.00348419
Iteration 6371, loss = 0.00348371
Iteration 6372, loss = 0.00348289
Iteration 6373, loss = 0.00348216
Iteration 6374, loss = 0.00348138
Iteration 6375, loss = 0.00348102
Iteration 6376, loss = 0.00348017
Iteration 6377, loss = 0.00347952
Iteration 6378, loss = 0.00347869
Iteration 6379, loss = 0.00347788
Iteration 6380, loss = 0.00347714
Iteration 6381, loss = 0.00347647
Iteration 6382, loss = 0.00347577
Iteration 6383, loss = 0.00347489
Iteration 6384, loss = 0.00347420
Iteration 6385, loss = 0.00347345
Iteration 6386, loss = 0.00347277
Iteration 6387, loss = 0.00347212
Iteration 6388, loss = 0.00347138
Iteration 6389, loss = 0.00347051
Iteration 6390, loss = 0.00346999
Iteration 6391, loss = 0.00346926
Iteration 6392, loss = 0.00346835
Iteration 6393, loss = 0.00346747
Iteration 6394, loss = 0.00346660
Iteration 6395, loss = 0.00346575
Iteration 6396, loss = 0.00346495
Iteration 6397, loss = 0.00346410
Iteration 6398, loss = 0.00346358
Iteration 6399, loss = 0.00346270
Iteration 6400, loss = 0.00346207
Iteration 6401, loss = 0.00346136
Iteration 6402, loss = 0.00346076
Iteration 6403, loss = 0.00345997
Iteration 6404, loss = 0.00345950
Iteration 6405, loss = 0.00345883
Iteration 6406, loss = 0.00345813
Iteration 6407, loss = 0.00345747
Iteration 6408, loss = 0.00345714
Iteration 6409, loss = 0.00345629
Iteration 6410, loss = 0.00345568
Iteration 6411, loss = 0.00345496
Iteration 6412, loss = 0.00345425
Iteration 6413, loss = 0.00345367
Iteration 6414, loss = 0.00345300
Iteration 6415, loss = 0.00345259
Iteration 6416, loss = 0.00345164
Iteration 6417, loss = 0.00345099
Iteration 6418, loss = 0.00345016
Iteration 6419, loss = 0.00344979
Iteration 6420, loss = 0.00344859
Iteration 6421, loss = 0.00344764
Iteration 6422, loss = 0.00344707
Iteration 6423, loss = 0.00344665
Iteration 6424, loss = 0.00344530
Iteration 6425, loss = 0.00344459
Iteration 6426, loss = 0.00344367
Iteration 6427, loss = 0.00344283
Iteration 6428, loss = 0.00344194
Iteration 6429, loss = 0.00344172
Iteration 6430, loss = 0.00344052
Iteration 6431, loss = 0.00343980
Iteration 6432, loss = 0.00343883
Iteration 6433, loss = 0.00343799
Iteration 6434, loss = 0.00343719
Iteration 6435, loss = 0.00343619
Iteration 6436, loss = 0.00343539
Iteration 6437, loss = 0.00343419
Iteration 6438, loss = 0.00343369
Iteration 6439, loss = 0.00343255
Iteration 6440, loss = 0.00343194
Iteration 6441, loss = 0.00343100
Iteration 6442, loss = 0.00343022
Iteration 6443, loss = 0.00342919
Iteration 6444, loss = 0.00342840
Iteration 6445, loss = 0.00342752
Iteration 6446, loss = 0.00342688
Iteration 6447, loss = 0.00342594
Iteration 6448, loss = 0.00342505
Iteration 6449, loss = 0.00342452
Iteration 6450, loss = 0.00342366
Iteration 6451, loss = 0.00342282
Iteration 6452, loss = 0.00342218
Iteration 6453, loss = 0.00342147
Iteration 6454, loss = 0.00342081
Iteration 6455, loss = 0.00342008
Iteration 6456, loss = 0.00341946
Iteration 6457, loss = 0.00341876
Iteration 6458, loss = 0.00341809
Iteration 6459, loss = 0.00341740
Iteration 6460, loss = 0.00341677
Iteration 6461, loss = 0.00341608
Iteration 6462, loss = 0.00341531
Iteration 6463, loss = 0.00341460
Iteration 6464, loss = 0.00341383
Iteration 6465, loss = 0.00341314
Iteration 6466, loss = 0.00341271
Iteration 6467, loss = 0.00341202
Iteration 6468, loss = 0.00341117
Iteration 6469, loss = 0.00341046
Iteration 6470, loss = 0.00340961
Iteration 6471, loss = 0.00340894
Iteration 6472, loss = 0.00340838
Iteration 6473, loss = 0.00340743
Iteration 6474, loss = 0.00340670
Iteration 6475, loss = 0.00340608
Iteration 6476, loss = 0.00340539
Iteration 6477, loss = 0.00340460
Iteration 6478, loss = 0.00340380
Iteration 6479, loss = 0.00340316
Iteration 6480, loss = 0.00340239
Iteration 6481, loss = 0.00340170
Iteration 6482, loss = 0.00340112
Iteration 6483, loss = 0.00340039
Iteration 6484, loss = 0.00339956
Iteration 6485, loss = 0.00339879
Iteration 6486, loss = 0.00339815
Iteration 6487, loss = 0.00339737
Iteration 6488, loss = 0.00339662
Iteration 6489, loss = 0.00339616
Iteration 6490, loss = 0.00339524
Iteration 6491, loss = 0.00339443
Iteration 6492, loss = 0.00339341
Iteration 6493, loss = 0.00339256
Iteration 6494, loss = 0.00339221
Iteration 6495, loss = 0.00339122
Iteration 6496, loss = 0.00339028
Iteration 6497, loss = 0.00338956
Iteration 6498, loss = 0.00338906
Iteration 6499, loss = 0.00338799
Iteration 6500, loss = 0.00338721
Iteration 6501, loss = 0.00338699
Iteration 6502, loss = 0.00338592
Iteration 6503, loss = 0.00338517
Iteration 6504, loss = 0.00338448
Iteration 6505, loss = 0.00338381
Iteration 6506, loss = 0.00338313
Iteration 6507, loss = 0.00338243
Iteration 6508, loss = 0.00338167
Iteration 6509, loss = 0.00338117
Iteration 6510, loss = 0.00338041
Iteration 6511, loss = 0.00337982
Iteration 6512, loss = 0.00337919
Iteration 6513, loss = 0.00337850
Iteration 6514, loss = 0.00337772
Iteration 6515, loss = 0.00337699
Iteration 6516, loss = 0.00337646
Iteration 6517, loss = 0.00337576
Iteration 6518, loss = 0.00337499
Iteration 6519, loss = 0.00337437
Iteration 6520, loss = 0.00337367
Iteration 6521, loss = 0.00337290
Iteration 6522, loss = 0.00337210
Iteration 6523, loss = 0.00337182
Iteration 6524, loss = 0.00337071
Iteration 6525, loss = 0.00336996
Iteration 6526, loss = 0.00336936
Iteration 6527, loss = 0.00336854
Iteration 6528, loss = 0.00336781
Iteration 6529, loss = 0.00336710
Iteration 6530, loss = 0.00336648
Iteration 6531, loss = 0.00336569
Iteration 6532, loss = 0.00336485
Iteration 6533, loss = 0.00336419
Iteration 6534, loss = 0.00336350
Iteration 6535, loss = 0.00336271
Iteration 6536, loss = 0.00336213
Iteration 6537, loss = 0.00336142
Iteration 6538, loss = 0.00336065
Iteration 6539, loss = 0.00335980
Iteration 6540, loss = 0.00335909
Iteration 6541, loss = 0.00335841
Iteration 6542, loss = 0.00335786
Iteration 6543, loss = 0.00335703
Iteration 6544, loss = 0.00335640
Iteration 6545, loss = 0.00335564
Iteration 6546, loss = 0.00335504
Iteration 6547, loss = 0.00335426
Iteration 6548, loss = 0.00335348
Iteration 6549, loss = 0.00335276
Iteration 6550, loss = 0.00335205
Iteration 6551, loss = 0.00335135
Iteration 6552, loss = 0.00335059
Iteration 6553, loss = 0.00334993
Iteration 6554, loss = 0.00334917
Iteration 6555, loss = 0.00334845
Iteration 6556, loss = 0.00334805
Iteration 6557, loss = 0.00334702
Iteration 6558, loss = 0.00334622
Iteration 6559, loss = 0.00334557
Iteration 6560, loss = 0.00334467
Iteration 6561, loss = 0.00334389
Iteration 6562, loss = 0.00334320
Iteration 6563, loss = 0.00334237
Iteration 6564, loss = 0.00334211
Iteration 6565, loss = 0.00334087
Iteration 6566, loss = 0.00333999
Iteration 6567, loss = 0.00333950
Iteration 6568, loss = 0.00333856
Iteration 6569, loss = 0.00333778
Iteration 6570, loss = 0.00333709
Iteration 6571, loss = 0.00333636
Iteration 6572, loss = 0.00333578
Iteration 6573, loss = 0.00333501
Iteration 6574, loss = 0.00333411
Iteration 6575, loss = 0.00333344
Iteration 6576, loss = 0.00333270
Iteration 6577, loss = 0.00333197
Iteration 6578, loss = 0.00333120
Iteration 6579, loss = 0.00333048
Iteration 6580, loss = 0.00332988
Iteration 6581, loss = 0.00332917
Iteration 6582, loss = 0.00332833
Iteration 6583, loss = 0.00332765
Iteration 6584, loss = 0.00332687
Iteration 6585, loss = 0.00332615
Iteration 6586, loss = 0.00332529
Iteration 6587, loss = 0.00332467
Iteration 6588, loss = 0.00332405
Iteration 6589, loss = 0.00332323
Iteration 6590, loss = 0.00332253
Iteration 6591, loss = 0.00332188
Iteration 6592, loss = 0.00332115
Iteration 6593, loss = 0.00332058
Iteration 6594, loss = 0.00331980
Iteration 6595, loss = 0.00331922
Iteration 6596, loss = 0.00331850
Iteration 6597, loss = 0.00331780
Iteration 6598, loss = 0.00331715
Iteration 6599, loss = 0.00331626
Iteration 6600, loss = 0.00331561
Iteration 6601, loss = 0.00331497
Iteration 6602, loss = 0.00331413
Iteration 6603, loss = 0.00331342
Iteration 6604, loss = 0.00331261
Iteration 6605, loss = 0.00331210
Iteration 6606, loss = 0.00331127
Iteration 6607, loss = 0.00331053
Iteration 6608, loss = 0.00330980
Iteration 6609, loss = 0.00330906
Iteration 6610, loss = 0.00330834
Iteration 6611, loss = 0.00330792
Iteration 6612, loss = 0.00330716
Iteration 6613, loss = 0.00330634
Iteration 6614, loss = 0.00330553
Iteration 6615, loss = 0.00330486
Iteration 6616, loss = 0.00330417
Iteration 6617, loss = 0.00330351
Iteration 6618, loss = 0.00330277
Iteration 6619, loss = 0.00330218
Iteration 6620, loss = 0.00330130
Iteration 6621, loss = 0.00330052
Iteration 6622, loss = 0.00329981
Iteration 6623, loss = 0.00329914
Iteration 6624, loss = 0.00329834
Iteration 6625, loss = 0.00329768
Iteration 6626, loss = 0.00329691
Iteration 6627, loss = 0.00329638
Iteration 6628, loss = 0.00329557
Iteration 6629, loss = 0.00329490
Iteration 6630, loss = 0.00329432
Iteration 6631, loss = 0.00329356
Iteration 6632, loss = 0.00329324
Iteration 6633, loss = 0.00329226
Iteration 6634, loss = 0.00329148
Iteration 6635, loss = 0.00329104
Iteration 6636, loss = 0.00329012
Iteration 6637, loss = 0.00328991
Iteration 6638, loss = 0.00328885
Iteration 6639, loss = 0.00328820
Iteration 6640, loss = 0.00328737
Iteration 6641, loss = 0.00328670
Iteration 6642, loss = 0.00328605
Iteration 6643, loss = 0.00328532
Iteration 6644, loss = 0.00328463
Iteration 6645, loss = 0.00328397
Iteration 6646, loss = 0.00328348
Iteration 6647, loss = 0.00328272
Iteration 6648, loss = 0.00328205
Iteration 6649, loss = 0.00328131
Iteration 6650, loss = 0.00328067
Iteration 6651, loss = 0.00327998
Iteration 6652, loss = 0.00327923
Iteration 6653, loss = 0.00327878
Iteration 6654, loss = 0.00327808
Iteration 6655, loss = 0.00327748
Iteration 6656, loss = 0.00327675
Iteration 6657, loss = 0.00327619
Iteration 6658, loss = 0.00327574
Iteration 6659, loss = 0.00327487
Iteration 6660, loss = 0.00327424
Iteration 6661, loss = 0.00327378
Iteration 6662, loss = 0.00327280
Iteration 6663, loss = 0.00327218
Iteration 6664, loss = 0.00327158
Iteration 6665, loss = 0.00327112
Iteration 6666, loss = 0.00327021
Iteration 6667, loss = 0.00326949
Iteration 6668, loss = 0.00326889
Iteration 6669, loss = 0.00326812
Iteration 6670, loss = 0.00326753
Iteration 6671, loss = 0.00326696
Iteration 6672, loss = 0.00326624
Iteration 6673, loss = 0.00326547
Iteration 6674, loss = 0.00326490
Iteration 6675, loss = 0.00326428
Iteration 6676, loss = 0.00326359
Iteration 6677, loss = 0.00326290
Iteration 6678, loss = 0.00326224
Iteration 6679, loss = 0.00326172
Iteration 6680, loss = 0.00326090
Iteration 6681, loss = 0.00326024
Iteration 6682, loss = 0.00325956
Iteration 6683, loss = 0.00325890
Iteration 6684, loss = 0.00325824
Iteration 6685, loss = 0.00325754
Iteration 6686, loss = 0.00325690
Iteration 6687, loss = 0.00325655
Iteration 6688, loss = 0.00325580
Iteration 6689, loss = 0.00325498
Iteration 6690, loss = 0.00325434
Iteration 6691, loss = 0.00325367
Iteration 6692, loss = 0.00325312
Iteration 6693, loss = 0.00325242
Iteration 6694, loss = 0.00325184
Iteration 6695, loss = 0.00325117
Iteration 6696, loss = 0.00325052
Iteration 6697, loss = 0.00324992
Iteration 6698, loss = 0.00324948
Iteration 6699, loss = 0.00324867
Iteration 6700, loss = 0.00324790
Iteration 6701, loss = 0.00324712
Iteration 6702, loss = 0.00324651
Iteration 6703, loss = 0.00324583
Iteration 6704, loss = 0.00324519
Iteration 6705, loss = 0.00324447
Iteration 6706, loss = 0.00324374
Iteration 6707, loss = 0.00324319
Iteration 6708, loss = 0.00324241
Iteration 6709, loss = 0.00324173
Iteration 6710, loss = 0.00324103
Iteration 6711, loss = 0.00324054
Iteration 6712, loss = 0.00323966
Iteration 6713, loss = 0.00323893
Iteration 6714, loss = 0.00323826
Iteration 6715, loss = 0.00323759
Iteration 6716, loss = 0.00323698
Iteration 6717, loss = 0.00323642
Iteration 6718, loss = 0.00323568
Iteration 6719, loss = 0.00323511
Iteration 6720, loss = 0.00323447
Iteration 6721, loss = 0.00323373
Iteration 6722, loss = 0.00323301
Iteration 6723, loss = 0.00323230
Iteration 6724, loss = 0.00323170
Iteration 6725, loss = 0.00323117
Iteration 6726, loss = 0.00323033
Iteration 6727, loss = 0.00322966
Iteration 6728, loss = 0.00322893
Iteration 6729, loss = 0.00322829
Iteration 6730, loss = 0.00322756
Iteration 6731, loss = 0.00322692
Iteration 6732, loss = 0.00322625
Iteration 6733, loss = 0.00322559
Iteration 6734, loss = 0.00322477
Iteration 6735, loss = 0.00322409
Iteration 6736, loss = 0.00322330
Iteration 6737, loss = 0.00322295
Iteration 6738, loss = 0.00322218
Iteration 6739, loss = 0.00322136
Iteration 6740, loss = 0.00322073
Iteration 6741, loss = 0.00322008
Iteration 6742, loss = 0.00321937
Iteration 6743, loss = 0.00321872
Iteration 6744, loss = 0.00321813
Iteration 6745, loss = 0.00321752
Iteration 6746, loss = 0.00321726
Iteration 6747, loss = 0.00321651
Iteration 6748, loss = 0.00321583
Iteration 6749, loss = 0.00321498
Iteration 6750, loss = 0.00321419
Iteration 6751, loss = 0.00321333
Iteration 6752, loss = 0.00321264
Iteration 6753, loss = 0.00321224
Iteration 6754, loss = 0.00321125
Iteration 6755, loss = 0.00321043
Iteration 6756, loss = 0.00320980
Iteration 6757, loss = 0.00320918
Iteration 6758, loss = 0.00320848
Iteration 6759, loss = 0.00320787
Iteration 6760, loss = 0.00320725
Iteration 6761, loss = 0.00320663
Iteration 6762, loss = 0.00320609
Iteration 6763, loss = 0.00320537
Iteration 6764, loss = 0.00320467
Iteration 6765, loss = 0.00320407
Iteration 6766, loss = 0.00320342
Iteration 6767, loss = 0.00320268
Iteration 6768, loss = 0.00320200
Iteration 6769, loss = 0.00320180
Iteration 6770, loss = 0.00320073
Iteration 6771, loss = 0.00320003
Iteration 6772, loss = 0.00319949
Iteration 6773, loss = 0.00319874
Iteration 6774, loss = 0.00319814
Iteration 6775, loss = 0.00319766
Iteration 6776, loss = 0.00319683
Iteration 6777, loss = 0.00319616
Iteration 6778, loss = 0.00319546
Iteration 6779, loss = 0.00319488
Iteration 6780, loss = 0.00319430
Iteration 6781, loss = 0.00319356
Iteration 6782, loss = 0.00319291
Iteration 6783, loss = 0.00319227
Iteration 6784, loss = 0.00319165
Iteration 6785, loss = 0.00319111
Iteration 6786, loss = 0.00319038
Iteration 6787, loss = 0.00318974
Iteration 6788, loss = 0.00318923
Iteration 6789, loss = 0.00318865
Iteration 6790, loss = 0.00318771
Iteration 6791, loss = 0.00318696
Iteration 6792, loss = 0.00318633
Iteration 6793, loss = 0.00318568
Iteration 6794, loss = 0.00318511
Iteration 6795, loss = 0.00318441
Iteration 6796, loss = 0.00318372
Iteration 6797, loss = 0.00318314
Iteration 6798, loss = 0.00318239
Iteration 6799, loss = 0.00318179
Iteration 6800, loss = 0.00318114
Iteration 6801, loss = 0.00318051
Iteration 6802, loss = 0.00317985
Iteration 6803, loss = 0.00317925
Iteration 6804, loss = 0.00317867
Iteration 6805, loss = 0.00317801
Iteration 6806, loss = 0.00317749
Iteration 6807, loss = 0.00317672
Iteration 6808, loss = 0.00317662
Iteration 6809, loss = 0.00317567
Iteration 6810, loss = 0.00317482
Iteration 6811, loss = 0.00317431
Iteration 6812, loss = 0.00317344
Iteration 6813, loss = 0.00317280
Iteration 6814, loss = 0.00317215
Iteration 6815, loss = 0.00317158
Iteration 6816, loss = 0.00317084
Iteration 6817, loss = 0.00316996
Iteration 6818, loss = 0.00316913
Iteration 6819, loss = 0.00316850
Iteration 6820, loss = 0.00316824
Iteration 6821, loss = 0.00316705
Iteration 6822, loss = 0.00316649
Iteration 6823, loss = 0.00316564
Iteration 6824, loss = 0.00316501
Iteration 6825, loss = 0.00316436
Iteration 6826, loss = 0.00316369
Iteration 6827, loss = 0.00316295
Iteration 6828, loss = 0.00316239
Iteration 6829, loss = 0.00316156
Iteration 6830, loss = 0.00316083
Iteration 6831, loss = 0.00316023
Iteration 6832, loss = 0.00315942
Iteration 6833, loss = 0.00315866
Iteration 6834, loss = 0.00315802
Iteration 6835, loss = 0.00315724
Iteration 6836, loss = 0.00315658
Iteration 6837, loss = 0.00315594
Iteration 6838, loss = 0.00315545
Iteration 6839, loss = 0.00315443
Iteration 6840, loss = 0.00315406
Iteration 6841, loss = 0.00315340
Iteration 6842, loss = 0.00315271
Iteration 6843, loss = 0.00315188
Iteration 6844, loss = 0.00315136
Iteration 6845, loss = 0.00315061
Iteration 6846, loss = 0.00314985
Iteration 6847, loss = 0.00314920
Iteration 6848, loss = 0.00314863
Iteration 6849, loss = 0.00314784
Iteration 6850, loss = 0.00314717
Iteration 6851, loss = 0.00314655
Iteration 6852, loss = 0.00314587
Iteration 6853, loss = 0.00314524
Iteration 6854, loss = 0.00314463
Iteration 6855, loss = 0.00314397
Iteration 6856, loss = 0.00314340
Iteration 6857, loss = 0.00314265
Iteration 6858, loss = 0.00314204
Iteration 6859, loss = 0.00314137
Iteration 6860, loss = 0.00314082
Iteration 6861, loss = 0.00314007
Iteration 6862, loss = 0.00313953
Iteration 6863, loss = 0.00313883
Iteration 6864, loss = 0.00313807
Iteration 6865, loss = 0.00313746
Iteration 6866, loss = 0.00313684
Iteration 6867, loss = 0.00313619
Iteration 6868, loss = 0.00313563
Iteration 6869, loss = 0.00313493
Iteration 6870, loss = 0.00313440
Iteration 6871, loss = 0.00313392
Iteration 6872, loss = 0.00313324
Iteration 6873, loss = 0.00313249
Iteration 6874, loss = 0.00313189
Iteration 6875, loss = 0.00313125
Iteration 6876, loss = 0.00313077
Iteration 6877, loss = 0.00313011
Iteration 6878, loss = 0.00312950
Iteration 6879, loss = 0.00312891
Iteration 6880, loss = 0.00312837
Iteration 6881, loss = 0.00312781
Iteration 6882, loss = 0.00312731
Iteration 6883, loss = 0.00312666
Iteration 6884, loss = 0.00312608
Iteration 6885, loss = 0.00312582
Iteration 6886, loss = 0.00312502
Iteration 6887, loss = 0.00312452
Iteration 6888, loss = 0.00312393
Iteration 6889, loss = 0.00312321
Iteration 6890, loss = 0.00312265
Iteration 6891, loss = 0.00312186
Iteration 6892, loss = 0.00312117
Iteration 6893, loss = 0.00312042
Iteration 6894, loss = 0.00311992
Iteration 6895, loss = 0.00311914
Iteration 6896, loss = 0.00311858
Iteration 6897, loss = 0.00311806
Iteration 6898, loss = 0.00311727
Iteration 6899, loss = 0.00311657
Iteration 6900, loss = 0.00311582
Iteration 6901, loss = 0.00311504
Iteration 6902, loss = 0.00311502
Iteration 6903, loss = 0.00311410
Iteration 6904, loss = 0.00311342
Iteration 6905, loss = 0.00311289
Iteration 6906, loss = 0.00311212
Iteration 6907, loss = 0.00311167
Iteration 6908, loss = 0.00311095
Iteration 6909, loss = 0.00311036
Iteration 6910, loss = 0.00310989
Iteration 6911, loss = 0.00310927
Iteration 6912, loss = 0.00310855
Iteration 6913, loss = 0.00310792
Iteration 6914, loss = 0.00310727
Iteration 6915, loss = 0.00310673
Iteration 6916, loss = 0.00310603
Iteration 6917, loss = 0.00310570
Iteration 6918, loss = 0.00310492
Iteration 6919, loss = 0.00310434
Iteration 6920, loss = 0.00310355
Iteration 6921, loss = 0.00310292
Iteration 6922, loss = 0.00310229
Iteration 6923, loss = 0.00310158
Iteration 6924, loss = 0.00310089
Iteration 6925, loss = 0.00310020
Iteration 6926, loss = 0.00309945
Iteration 6927, loss = 0.00309870
Iteration 6928, loss = 0.00309826
Iteration 6929, loss = 0.00309740
Iteration 6930, loss = 0.00309683
Iteration 6931, loss = 0.00309617
Iteration 6932, loss = 0.00309548
Iteration 6933, loss = 0.00309491
Iteration 6934, loss = 0.00309423
Iteration 6935, loss = 0.00309361
Iteration 6936, loss = 0.00309299
Iteration 6937, loss = 0.00309238
Iteration 6938, loss = 0.00309176
Iteration 6939, loss = 0.00309119
Iteration 6940, loss = 0.00309051
Iteration 6941, loss = 0.00308995
Iteration 6942, loss = 0.00308935
Iteration 6943, loss = 0.00308879
Iteration 6944, loss = 0.00308855
Iteration 6945, loss = 0.00308766
Iteration 6946, loss = 0.00308726
Iteration 6947, loss = 0.00308659
Iteration 6948, loss = 0.00308589
Iteration 6949, loss = 0.00308513
Iteration 6950, loss = 0.00308470
Iteration 6951, loss = 0.00308396
Iteration 6952, loss = 0.00308344
Iteration 6953, loss = 0.00308279
Iteration 6954, loss = 0.00308225
Iteration 6955, loss = 0.00308172
Iteration 6956, loss = 0.00308103
Iteration 6957, loss = 0.00308043
Iteration 6958, loss = 0.00307981
Iteration 6959, loss = 0.00307930
Iteration 6960, loss = 0.00307857
Iteration 6961, loss = 0.00307798
Iteration 6962, loss = 0.00307738
Iteration 6963, loss = 0.00307676
Iteration 6964, loss = 0.00307618
Iteration 6965, loss = 0.00307582
Iteration 6966, loss = 0.00307507
Iteration 6967, loss = 0.00307449
Iteration 6968, loss = 0.00307383
Iteration 6969, loss = 0.00307378
Iteration 6970, loss = 0.00307300
Iteration 6971, loss = 0.00307230
Iteration 6972, loss = 0.00307168
Iteration 6973, loss = 0.00307118
Iteration 6974, loss = 0.00307066
Iteration 6975, loss = 0.00307000
Iteration 6976, loss = 0.00306944
Iteration 6977, loss = 0.00306875
Iteration 6978, loss = 0.00306806
Iteration 6979, loss = 0.00306739
Iteration 6980, loss = 0.00306688
Iteration 6981, loss = 0.00306614
Iteration 6982, loss = 0.00306542
Iteration 6983, loss = 0.00306473
Iteration 6984, loss = 0.00306416
Iteration 6985, loss = 0.00306351
Iteration 6986, loss = 0.00306271
Iteration 6987, loss = 0.00306226
Iteration 6988, loss = 0.00306139
Iteration 6989, loss = 0.00306078
Iteration 6990, loss = 0.00306011
Iteration 6991, loss = 0.00305941
Iteration 6992, loss = 0.00305876
Iteration 6993, loss = 0.00305812
Iteration 6994, loss = 0.00305752
Iteration 6995, loss = 0.00305695
Iteration 6996, loss = 0.00305626
Iteration 6997, loss = 0.00305562
Iteration 6998, loss = 0.00305503
Iteration 6999, loss = 0.00305435
Iteration 7000, loss = 0.00305366
Iteration 7001, loss = 0.00305317
Iteration 7002, loss = 0.00305254
Iteration 7003, loss = 0.00305186
Iteration 7004, loss = 0.00305124
Iteration 7005, loss = 0.00305072
Iteration 7006, loss = 0.00304988
Iteration 7007, loss = 0.00304942
Iteration 7008, loss = 0.00304872
Iteration 7009, loss = 0.00304831
Iteration 7010, loss = 0.00304758
Iteration 7011, loss = 0.00304701
Iteration 7012, loss = 0.00304646
Iteration 7013, loss = 0.00304589
Iteration 7014, loss = 0.00304525
Iteration 7015, loss = 0.00304471
Iteration 7016, loss = 0.00304414
Iteration 7017, loss = 0.00304361
Iteration 7018, loss = 0.00304308
Iteration 7019, loss = 0.00304257
Iteration 7020, loss = 0.00304199
Iteration 7021, loss = 0.00304145
Iteration 7022, loss = 0.00304092
Iteration 7023, loss = 0.00304045
Iteration 7024, loss = 0.00303995
Iteration 7025, loss = 0.00303936
Iteration 7026, loss = 0.00303902
Iteration 7027, loss = 0.00303820
Iteration 7028, loss = 0.00303770
Iteration 7029, loss = 0.00303727
Iteration 7030, loss = 0.00303656
Iteration 7031, loss = 0.00303573
Iteration 7032, loss = 0.00303514
Iteration 7033, loss = 0.00303466
Iteration 7034, loss = 0.00303392
Iteration 7035, loss = 0.00303331
Iteration 7036, loss = 0.00303272
Iteration 7037, loss = 0.00303220
Iteration 7038, loss = 0.00303159
Iteration 7039, loss = 0.00303102
Iteration 7040, loss = 0.00303054
Iteration 7041, loss = 0.00302989
Iteration 7042, loss = 0.00302939
Iteration 7043, loss = 0.00302881
Iteration 7044, loss = 0.00302830
Iteration 7045, loss = 0.00302770
Iteration 7046, loss = 0.00302711
Iteration 7047, loss = 0.00302660
Iteration 7048, loss = 0.00302616
Iteration 7049, loss = 0.00302550
Iteration 7050, loss = 0.00302507
Iteration 7051, loss = 0.00302437
Iteration 7052, loss = 0.00302368
Iteration 7053, loss = 0.00302310
Iteration 7054, loss = 0.00302247
Iteration 7055, loss = 0.00302189
Iteration 7056, loss = 0.00302112
Iteration 7057, loss = 0.00302066
Iteration 7058, loss = 0.00301988
Iteration 7059, loss = 0.00301917
Iteration 7060, loss = 0.00301850
Iteration 7061, loss = 0.00301804
Iteration 7062, loss = 0.00301766
Iteration 7063, loss = 0.00301673
Iteration 7064, loss = 0.00301598
Iteration 7065, loss = 0.00301532
Iteration 7066, loss = 0.00301473
Iteration 7067, loss = 0.00301412
Iteration 7068, loss = 0.00301351
Iteration 7069, loss = 0.00301288
Iteration 7070, loss = 0.00301230
Iteration 7071, loss = 0.00301177
Iteration 7072, loss = 0.00301127
Iteration 7073, loss = 0.00301068
Iteration 7074, loss = 0.00301001
Iteration 7075, loss = 0.00300942
Iteration 7076, loss = 0.00300894
Iteration 7077, loss = 0.00300832
Iteration 7078, loss = 0.00300780
Iteration 7079, loss = 0.00300708
Iteration 7080, loss = 0.00300647
Iteration 7081, loss = 0.00300585
Iteration 7082, loss = 0.00300527
Iteration 7083, loss = 0.00300466
Iteration 7084, loss = 0.00300432
Iteration 7085, loss = 0.00300355
Iteration 7086, loss = 0.00300296
Iteration 7087, loss = 0.00300238
Iteration 7088, loss = 0.00300158
Iteration 7089, loss = 0.00300090
Iteration 7090, loss = 0.00300044
Iteration 7091, loss = 0.00299969
Iteration 7092, loss = 0.00299933
Iteration 7093, loss = 0.00299871
Iteration 7094, loss = 0.00299783
Iteration 7095, loss = 0.00299716
Iteration 7096, loss = 0.00299657
Iteration 7097, loss = 0.00299582
Iteration 7098, loss = 0.00299537
Iteration 7099, loss = 0.00299461
Iteration 7100, loss = 0.00299397
Iteration 7101, loss = 0.00299347
Iteration 7102, loss = 0.00299272
Iteration 7103, loss = 0.00299207
Iteration 7104, loss = 0.00299146
Iteration 7105, loss = 0.00299087
Iteration 7106, loss = 0.00299029
Iteration 7107, loss = 0.00298963
Iteration 7108, loss = 0.00298918
Iteration 7109, loss = 0.00298843
Iteration 7110, loss = 0.00298792
Iteration 7111, loss = 0.00298729
Iteration 7112, loss = 0.00298675
Iteration 7113, loss = 0.00298625
Iteration 7114, loss = 0.00298556
Iteration 7115, loss = 0.00298495
Iteration 7116, loss = 0.00298458
Iteration 7117, loss = 0.00298378
Iteration 7118, loss = 0.00298346
Iteration 7119, loss = 0.00298272
Iteration 7120, loss = 0.00298207
Iteration 7121, loss = 0.00298146
Iteration 7122, loss = 0.00298074
Iteration 7123, loss = 0.00298015
Iteration 7124, loss = 0.00297953
Iteration 7125, loss = 0.00297878
Iteration 7126, loss = 0.00297820
Iteration 7127, loss = 0.00297764
Iteration 7128, loss = 0.00297688
Iteration 7129, loss = 0.00297625
Iteration 7130, loss = 0.00297562
Iteration 7131, loss = 0.00297507
Iteration 7132, loss = 0.00297456
Iteration 7133, loss = 0.00297389
Iteration 7134, loss = 0.00297332
Iteration 7135, loss = 0.00297282
Iteration 7136, loss = 0.00297213
Iteration 7137, loss = 0.00297151
Iteration 7138, loss = 0.00297093
Iteration 7139, loss = 0.00297032
Iteration 7140, loss = 0.00296972
Iteration 7141, loss = 0.00296972
Iteration 7142, loss = 0.00296863
Iteration 7143, loss = 0.00296803
Iteration 7144, loss = 0.00296748
Iteration 7145, loss = 0.00296694
Iteration 7146, loss = 0.00296622
Iteration 7147, loss = 0.00296578
Iteration 7148, loss = 0.00296518
Iteration 7149, loss = 0.00296464
Iteration 7150, loss = 0.00296413
Iteration 7151, loss = 0.00296369
Iteration 7152, loss = 0.00296322
Iteration 7153, loss = 0.00296271
Iteration 7154, loss = 0.00296211
Iteration 7155, loss = 0.00296160
Iteration 7156, loss = 0.00296100
Iteration 7157, loss = 0.00296065
Iteration 7158, loss = 0.00295995
Iteration 7159, loss = 0.00295944
Iteration 7160, loss = 0.00295907
Iteration 7161, loss = 0.00295812
Iteration 7162, loss = 0.00295750
Iteration 7163, loss = 0.00295698
Iteration 7164, loss = 0.00295635
Iteration 7165, loss = 0.00295567
Iteration 7166, loss = 0.00295499
Iteration 7167, loss = 0.00295457
Iteration 7168, loss = 0.00295381
Iteration 7169, loss = 0.00295319
Iteration 7170, loss = 0.00295260
Iteration 7171, loss = 0.00295196
Iteration 7172, loss = 0.00295154
Iteration 7173, loss = 0.00295086
Iteration 7174, loss = 0.00295030
Iteration 7175, loss = 0.00294968
Iteration 7176, loss = 0.00294899
Iteration 7177, loss = 0.00294853
Iteration 7178, loss = 0.00294789
Iteration 7179, loss = 0.00294737
Iteration 7180, loss = 0.00294658
Iteration 7181, loss = 0.00294601
Iteration 7182, loss = 0.00294539
Iteration 7183, loss = 0.00294481
Iteration 7184, loss = 0.00294441
Iteration 7185, loss = 0.00294353
Iteration 7186, loss = 0.00294308
Iteration 7187, loss = 0.00294256
Iteration 7188, loss = 0.00294182
Iteration 7189, loss = 0.00294125
Iteration 7190, loss = 0.00294066
Iteration 7191, loss = 0.00294008
Iteration 7192, loss = 0.00293945
Iteration 7193, loss = 0.00293897
Iteration 7194, loss = 0.00293838
Iteration 7195, loss = 0.00293791
Iteration 7196, loss = 0.00293755
Iteration 7197, loss = 0.00293658
Iteration 7198, loss = 0.00293618
Iteration 7199, loss = 0.00293555
Iteration 7200, loss = 0.00293493
Iteration 7201, loss = 0.00293433
Iteration 7202, loss = 0.00293377
Iteration 7203, loss = 0.00293317
Iteration 7204, loss = 0.00293251
Iteration 7205, loss = 0.00293184
Iteration 7206, loss = 0.00293115
Iteration 7207, loss = 0.00293062
Iteration 7208, loss = 0.00293023
Iteration 7209, loss = 0.00292968
Iteration 7210, loss = 0.00292915
Iteration 7211, loss = 0.00292834
Iteration 7212, loss = 0.00292778
Iteration 7213, loss = 0.00292716
Iteration 7214, loss = 0.00292663
Iteration 7215, loss = 0.00292600
Iteration 7216, loss = 0.00292546
Iteration 7217, loss = 0.00292485
Iteration 7218, loss = 0.00292431
Iteration 7219, loss = 0.00292371
Iteration 7220, loss = 0.00292318
Iteration 7221, loss = 0.00292258
Iteration 7222, loss = 0.00292207
Iteration 7223, loss = 0.00292147
Iteration 7224, loss = 0.00292094
Iteration 7225, loss = 0.00292041
Iteration 7226, loss = 0.00291995
Iteration 7227, loss = 0.00291939
Iteration 7228, loss = 0.00291881
Iteration 7229, loss = 0.00291826
Iteration 7230, loss = 0.00291766
Iteration 7231, loss = 0.00291710
Iteration 7232, loss = 0.00291661
Iteration 7233, loss = 0.00291592
Iteration 7234, loss = 0.00291532
Iteration 7235, loss = 0.00291472
Iteration 7236, loss = 0.00291418
Iteration 7237, loss = 0.00291360
Iteration 7238, loss = 0.00291304
Iteration 7239, loss = 0.00291247
Iteration 7240, loss = 0.00291202
Iteration 7241, loss = 0.00291140
Iteration 7242, loss = 0.00291089
Iteration 7243, loss = 0.00291037
Iteration 7244, loss = 0.00291021
Iteration 7245, loss = 0.00290940
Iteration 7246, loss = 0.00290879
Iteration 7247, loss = 0.00290834
Iteration 7248, loss = 0.00290765
Iteration 7249, loss = 0.00290720
Iteration 7250, loss = 0.00290670
Iteration 7251, loss = 0.00290598
Iteration 7252, loss = 0.00290539
Iteration 7253, loss = 0.00290486
Iteration 7254, loss = 0.00290438
Iteration 7255, loss = 0.00290360
Iteration 7256, loss = 0.00290296
Iteration 7257, loss = 0.00290252
Iteration 7258, loss = 0.00290206
Iteration 7259, loss = 0.00290146
Iteration 7260, loss = 0.00290099
Iteration 7261, loss = 0.00290039
Iteration 7262, loss = 0.00289969
Iteration 7263, loss = 0.00289908
Iteration 7264, loss = 0.00289852
Iteration 7265, loss = 0.00289796
Iteration 7266, loss = 0.00289737
Iteration 7267, loss = 0.00289675
Iteration 7268, loss = 0.00289623
Iteration 7269, loss = 0.00289567
Iteration 7270, loss = 0.00289513
Iteration 7271, loss = 0.00289457
Iteration 7272, loss = 0.00289416
Iteration 7273, loss = 0.00289388
Iteration 7274, loss = 0.00289317
Iteration 7275, loss = 0.00289247
Iteration 7276, loss = 0.00289212
Iteration 7277, loss = 0.00289165
Iteration 7278, loss = 0.00289093
Iteration 7279, loss = 0.00289041
Iteration 7280, loss = 0.00288964
Iteration 7281, loss = 0.00288927
Iteration 7282, loss = 0.00288842
Iteration 7283, loss = 0.00288820
Iteration 7284, loss = 0.00288729
Iteration 7285, loss = 0.00288668
Iteration 7286, loss = 0.00288596
Iteration 7287, loss = 0.00288527
Iteration 7288, loss = 0.00288466
Iteration 7289, loss = 0.00288441
Iteration 7290, loss = 0.00288365
Iteration 7291, loss = 0.00288339
Iteration 7292, loss = 0.00288290
Iteration 7293, loss = 0.00288201
Iteration 7294, loss = 0.00288139
Iteration 7295, loss = 0.00288080
Iteration 7296, loss = 0.00288019
Iteration 7297, loss = 0.00287974
Iteration 7298, loss = 0.00287905
Iteration 7299, loss = 0.00287840
Iteration 7300, loss = 0.00287783
Iteration 7301, loss = 0.00287728
Iteration 7302, loss = 0.00287679
Iteration 7303, loss = 0.00287628
Iteration 7304, loss = 0.00287597
Iteration 7305, loss = 0.00287514
Iteration 7306, loss = 0.00287460
Iteration 7307, loss = 0.00287401
Iteration 7308, loss = 0.00287337
Iteration 7309, loss = 0.00287317
Iteration 7310, loss = 0.00287243
Iteration 7311, loss = 0.00287193
Iteration 7312, loss = 0.00287130
Iteration 7313, loss = 0.00287064
Iteration 7314, loss = 0.00287004
Iteration 7315, loss = 0.00286942
Iteration 7316, loss = 0.00286878
Iteration 7317, loss = 0.00286841
Iteration 7318, loss = 0.00286768
Iteration 7319, loss = 0.00286708
Iteration 7320, loss = 0.00286657
Iteration 7321, loss = 0.00286594
Iteration 7322, loss = 0.00286559
Iteration 7323, loss = 0.00286487
Iteration 7324, loss = 0.00286437
Iteration 7325, loss = 0.00286379
Iteration 7326, loss = 0.00286350
Iteration 7327, loss = 0.00286282
Iteration 7328, loss = 0.00286222
Iteration 7329, loss = 0.00286168
Iteration 7330, loss = 0.00286095
Iteration 7331, loss = 0.00286042
Iteration 7332, loss = 0.00285981
Iteration 7333, loss = 0.00285939
Iteration 7334, loss = 0.00285878
Iteration 7335, loss = 0.00285820
Iteration 7336, loss = 0.00285769
Iteration 7337, loss = 0.00285709
Iteration 7338, loss = 0.00285649
Iteration 7339, loss = 0.00285587
Iteration 7340, loss = 0.00285580
Iteration 7341, loss = 0.00285485
Iteration 7342, loss = 0.00285427
Iteration 7343, loss = 0.00285373
Iteration 7344, loss = 0.00285326
Iteration 7345, loss = 0.00285270
Iteration 7346, loss = 0.00285213
Iteration 7347, loss = 0.00285155
Iteration 7348, loss = 0.00285100
Iteration 7349, loss = 0.00285048
Iteration 7350, loss = 0.00285003
Iteration 7351, loss = 0.00284945
Iteration 7352, loss = 0.00284891
Iteration 7353, loss = 0.00284845
Iteration 7354, loss = 0.00284798
Iteration 7355, loss = 0.00284748
Iteration 7356, loss = 0.00284694
Iteration 7357, loss = 0.00284643
Iteration 7358, loss = 0.00284580
Iteration 7359, loss = 0.00284531
Iteration 7360, loss = 0.00284479
Iteration 7361, loss = 0.00284424
Iteration 7362, loss = 0.00284377
Iteration 7363, loss = 0.00284324
Iteration 7364, loss = 0.00284267
Iteration 7365, loss = 0.00284221
Iteration 7366, loss = 0.00284170
Iteration 7367, loss = 0.00284104
Iteration 7368, loss = 0.00284041
Iteration 7369, loss = 0.00284008
Iteration 7370, loss = 0.00283941
Iteration 7371, loss = 0.00283896
Iteration 7372, loss = 0.00283840
Iteration 7373, loss = 0.00283788
Iteration 7374, loss = 0.00283734
Iteration 7375, loss = 0.00283683
Iteration 7376, loss = 0.00283627
Iteration 7377, loss = 0.00283580
Iteration 7378, loss = 0.00283518
Iteration 7379, loss = 0.00283484
Iteration 7380, loss = 0.00283420
Iteration 7381, loss = 0.00283354
Iteration 7382, loss = 0.00283307
Iteration 7383, loss = 0.00283249
Iteration 7384, loss = 0.00283199
Iteration 7385, loss = 0.00283144
Iteration 7386, loss = 0.00283085
Iteration 7387, loss = 0.00283036
Iteration 7388, loss = 0.00282972
Iteration 7389, loss = 0.00282936
Iteration 7390, loss = 0.00282863
Iteration 7391, loss = 0.00282811
Iteration 7392, loss = 0.00282770
Iteration 7393, loss = 0.00282708
Iteration 7394, loss = 0.00282675
Iteration 7395, loss = 0.00282591
Iteration 7396, loss = 0.00282555
Iteration 7397, loss = 0.00282485
Iteration 7398, loss = 0.00282420
Iteration 7399, loss = 0.00282380
Iteration 7400, loss = 0.00282314
Iteration 7401, loss = 0.00282249
Iteration 7402, loss = 0.00282198
Iteration 7403, loss = 0.00282139
Iteration 7404, loss = 0.00282079
Iteration 7405, loss = 0.00282024
Iteration 7406, loss = 0.00281963
Iteration 7407, loss = 0.00281936
Iteration 7408, loss = 0.00281866
Iteration 7409, loss = 0.00281808
Iteration 7410, loss = 0.00281748
Iteration 7411, loss = 0.00281742
Iteration 7412, loss = 0.00281647
Iteration 7413, loss = 0.00281590
Iteration 7414, loss = 0.00281543
Iteration 7415, loss = 0.00281472
Iteration 7416, loss = 0.00281422
Iteration 7417, loss = 0.00281361
Iteration 7418, loss = 0.00281306
Iteration 7419, loss = 0.00281242
Iteration 7420, loss = 0.00281186
Iteration 7421, loss = 0.00281134
Iteration 7422, loss = 0.00281089
Iteration 7423, loss = 0.00281026
Iteration 7424, loss = 0.00280979
Iteration 7425, loss = 0.00280916
Iteration 7426, loss = 0.00280867
Iteration 7427, loss = 0.00280806
Iteration 7428, loss = 0.00280747
Iteration 7429, loss = 0.00280707
Iteration 7430, loss = 0.00280648
Iteration 7431, loss = 0.00280588
Iteration 7432, loss = 0.00280524
Iteration 7433, loss = 0.00280480
Iteration 7434, loss = 0.00280417
Iteration 7435, loss = 0.00280401
Iteration 7436, loss = 0.00280329
Iteration 7437, loss = 0.00280305
Iteration 7438, loss = 0.00280244
Iteration 7439, loss = 0.00280187
Iteration 7440, loss = 0.00280168
Iteration 7441, loss = 0.00280097
Iteration 7442, loss = 0.00280040
Iteration 7443, loss = 0.00279983
Iteration 7444, loss = 0.00279920
Iteration 7445, loss = 0.00279867
Iteration 7446, loss = 0.00279819
Iteration 7447, loss = 0.00279756
Iteration 7448, loss = 0.00279706
Iteration 7449, loss = 0.00279652
Iteration 7450, loss = 0.00279601
Iteration 7451, loss = 0.00279555
Iteration 7452, loss = 0.00279509
Iteration 7453, loss = 0.00279461
Iteration 7454, loss = 0.00279416
Iteration 7455, loss = 0.00279373
Iteration 7456, loss = 0.00279326
Iteration 7457, loss = 0.00279270
Iteration 7458, loss = 0.00279223
Iteration 7459, loss = 0.00279176
Iteration 7460, loss = 0.00279118
Iteration 7461, loss = 0.00279076
Iteration 7462, loss = 0.00279028
Iteration 7463, loss = 0.00278974
Iteration 7464, loss = 0.00278927
Iteration 7465, loss = 0.00278872
Iteration 7466, loss = 0.00278824
Iteration 7467, loss = 0.00278775
Iteration 7468, loss = 0.00278722
Iteration 7469, loss = 0.00278674
Iteration 7470, loss = 0.00278621
Iteration 7471, loss = 0.00278574
Iteration 7472, loss = 0.00278518
Iteration 7473, loss = 0.00278462
Iteration 7474, loss = 0.00278405
Iteration 7475, loss = 0.00278358
Iteration 7476, loss = 0.00278298
Iteration 7477, loss = 0.00278251
Iteration 7478, loss = 0.00278200
Iteration 7479, loss = 0.00278145
Iteration 7480, loss = 0.00278091
Iteration 7481, loss = 0.00278035
Iteration 7482, loss = 0.00277984
Iteration 7483, loss = 0.00277949
Iteration 7484, loss = 0.00277879
Iteration 7485, loss = 0.00277822
Iteration 7486, loss = 0.00277771
Iteration 7487, loss = 0.00277715
Iteration 7488, loss = 0.00277665
Iteration 7489, loss = 0.00277608
Iteration 7490, loss = 0.00277558
Iteration 7491, loss = 0.00277507
Iteration 7492, loss = 0.00277452
Iteration 7493, loss = 0.00277403
Iteration 7494, loss = 0.00277359
Iteration 7495, loss = 0.00277314
Iteration 7496, loss = 0.00277264
Iteration 7497, loss = 0.00277229
Iteration 7498, loss = 0.00277179
Iteration 7499, loss = 0.00277120
Iteration 7500, loss = 0.00277080
Iteration 7501, loss = 0.00277038
Iteration 7502, loss = 0.00276988
Iteration 7503, loss = 0.00276934
Iteration 7504, loss = 0.00276881
Iteration 7505, loss = 0.00276834
Iteration 7506, loss = 0.00276784
Iteration 7507, loss = 0.00276731
Iteration 7508, loss = 0.00276672
Iteration 7509, loss = 0.00276618
Iteration 7510, loss = 0.00276558
Iteration 7511, loss = 0.00276508
Iteration 7512, loss = 0.00276451
Iteration 7513, loss = 0.00276399
Iteration 7514, loss = 0.00276340
Iteration 7515, loss = 0.00276304
Iteration 7516, loss = 0.00276233
Iteration 7517, loss = 0.00276184
Iteration 7518, loss = 0.00276130
Iteration 7519, loss = 0.00276081
Iteration 7520, loss = 0.00276030
Iteration 7521, loss = 0.00275985
Iteration 7522, loss = 0.00275943
Iteration 7523, loss = 0.00275892
Iteration 7524, loss = 0.00275838
Iteration 7525, loss = 0.00275783
Iteration 7526, loss = 0.00275746
Iteration 7527, loss = 0.00275687
Iteration 7528, loss = 0.00275633
Iteration 7529, loss = 0.00275587
Iteration 7530, loss = 0.00275538
Iteration 7531, loss = 0.00275495
Iteration 7532, loss = 0.00275446
Iteration 7533, loss = 0.00275395
Iteration 7534, loss = 0.00275353
Iteration 7535, loss = 0.00275313
Iteration 7536, loss = 0.00275248
Iteration 7537, loss = 0.00275190
Iteration 7538, loss = 0.00275130
Iteration 7539, loss = 0.00275074
Iteration 7540, loss = 0.00275010
Iteration 7541, loss = 0.00274959
Iteration 7542, loss = 0.00274914
Iteration 7543, loss = 0.00274872
Iteration 7544, loss = 0.00274813
Iteration 7545, loss = 0.00274762
Iteration 7546, loss = 0.00274724
Iteration 7547, loss = 0.00274713
Iteration 7548, loss = 0.00274626
Iteration 7549, loss = 0.00274570
Iteration 7550, loss = 0.00274517
Iteration 7551, loss = 0.00274465
Iteration 7552, loss = 0.00274417
Iteration 7553, loss = 0.00274368
Iteration 7554, loss = 0.00274322
Iteration 7555, loss = 0.00274272
Iteration 7556, loss = 0.00274223
Iteration 7557, loss = 0.00274167
Iteration 7558, loss = 0.00274113
Iteration 7559, loss = 0.00274061
Iteration 7560, loss = 0.00274008
Iteration 7561, loss = 0.00273979
Iteration 7562, loss = 0.00273912
Iteration 7563, loss = 0.00273858
Iteration 7564, loss = 0.00273806
Iteration 7565, loss = 0.00273768
Iteration 7566, loss = 0.00273710
Iteration 7567, loss = 0.00273678
Iteration 7568, loss = 0.00273615
Iteration 7569, loss = 0.00273563
Iteration 7570, loss = 0.00273512
Iteration 7571, loss = 0.00273463
Iteration 7572, loss = 0.00273418
Iteration 7573, loss = 0.00273378
Iteration 7574, loss = 0.00273321
Iteration 7575, loss = 0.00273279
Iteration 7576, loss = 0.00273221
Iteration 7577, loss = 0.00273167
Iteration 7578, loss = 0.00273115
Iteration 7579, loss = 0.00273067
Iteration 7580, loss = 0.00273018
Iteration 7581, loss = 0.00272964
Iteration 7582, loss = 0.00272910
Iteration 7583, loss = 0.00272857
Iteration 7584, loss = 0.00272810
Iteration 7585, loss = 0.00272755
Iteration 7586, loss = 0.00272693
Iteration 7587, loss = 0.00272639
Iteration 7588, loss = 0.00272608
Iteration 7589, loss = 0.00272540
Iteration 7590, loss = 0.00272490
Iteration 7591, loss = 0.00272461
Iteration 7592, loss = 0.00272389
Iteration 7593, loss = 0.00272330
Iteration 7594, loss = 0.00272275
Iteration 7595, loss = 0.00272235
Iteration 7596, loss = 0.00272176
Iteration 7597, loss = 0.00272143
Iteration 7598, loss = 0.00272071
Iteration 7599, loss = 0.00272027
Iteration 7600, loss = 0.00271971
Iteration 7601, loss = 0.00271926
Iteration 7602, loss = 0.00271876
Iteration 7603, loss = 0.00271835
Iteration 7604, loss = 0.00271781
Iteration 7605, loss = 0.00271734
Iteration 7606, loss = 0.00271683
Iteration 7607, loss = 0.00271631
Iteration 7608, loss = 0.00271587
Iteration 7609, loss = 0.00271532
Iteration 7610, loss = 0.00271490
Iteration 7611, loss = 0.00271435
Iteration 7612, loss = 0.00271382
Iteration 7613, loss = 0.00271344
Iteration 7614, loss = 0.00271285
Iteration 7615, loss = 0.00271253
Iteration 7616, loss = 0.00271185
Iteration 7617, loss = 0.00271132
Iteration 7618, loss = 0.00271094
Iteration 7619, loss = 0.00271046
Iteration 7620, loss = 0.00270994
Iteration 7621, loss = 0.00270969
Iteration 7622, loss = 0.00270909
Iteration 7623, loss = 0.00270854
Iteration 7624, loss = 0.00270801
Iteration 7625, loss = 0.00270798
Iteration 7626, loss = 0.00270712
Iteration 7627, loss = 0.00270662
Iteration 7628, loss = 0.00270610
Iteration 7629, loss = 0.00270559
Iteration 7630, loss = 0.00270515
Iteration 7631, loss = 0.00270479
Iteration 7632, loss = 0.00270412
Iteration 7633, loss = 0.00270343
Iteration 7634, loss = 0.00270292
Iteration 7635, loss = 0.00270239
Iteration 7636, loss = 0.00270189
Iteration 7637, loss = 0.00270129
Iteration 7638, loss = 0.00270085
Iteration 7639, loss = 0.00270033
Iteration 7640, loss = 0.00269982
Iteration 7641, loss = 0.00269942
Iteration 7642, loss = 0.00269885
Iteration 7643, loss = 0.00269826
Iteration 7644, loss = 0.00269780
Iteration 7645, loss = 0.00269730
Iteration 7646, loss = 0.00269662
Iteration 7647, loss = 0.00269605
Iteration 7648, loss = 0.00269549
Iteration 7649, loss = 0.00269501
Iteration 7650, loss = 0.00269444
Iteration 7651, loss = 0.00269409
Iteration 7652, loss = 0.00269340
Iteration 7653, loss = 0.00269300
Iteration 7654, loss = 0.00269237
Iteration 7655, loss = 0.00269192
Iteration 7656, loss = 0.00269150
Iteration 7657, loss = 0.00269083
Iteration 7658, loss = 0.00269030
Iteration 7659, loss = 0.00268976
Iteration 7660, loss = 0.00268924
Iteration 7661, loss = 0.00268889
Iteration 7662, loss = 0.00268823
Iteration 7663, loss = 0.00268776
Iteration 7664, loss = 0.00268733
Iteration 7665, loss = 0.00268705
Iteration 7666, loss = 0.00268634
Iteration 7667, loss = 0.00268584
Iteration 7668, loss = 0.00268536
Iteration 7669, loss = 0.00268487
Iteration 7670, loss = 0.00268433
Iteration 7671, loss = 0.00268380
Iteration 7672, loss = 0.00268337
Iteration 7673, loss = 0.00268283
Iteration 7674, loss = 0.00268228
Iteration 7675, loss = 0.00268181
Iteration 7676, loss = 0.00268142
Iteration 7677, loss = 0.00268087
Iteration 7678, loss = 0.00268036
Iteration 7679, loss = 0.00267990
Iteration 7680, loss = 0.00267952
Iteration 7681, loss = 0.00267884
Iteration 7682, loss = 0.00267836
Iteration 7683, loss = 0.00267789
Iteration 7684, loss = 0.00267740
Iteration 7685, loss = 0.00267691
Iteration 7686, loss = 0.00267647
Iteration 7687, loss = 0.00267601
Iteration 7688, loss = 0.00267551
Iteration 7689, loss = 0.00267508
Iteration 7690, loss = 0.00267461
Iteration 7691, loss = 0.00267413
Iteration 7692, loss = 0.00267374
Iteration 7693, loss = 0.00267327
Iteration 7694, loss = 0.00267286
Iteration 7695, loss = 0.00267241
Iteration 7696, loss = 0.00267199
Iteration 7697, loss = 0.00267160
Iteration 7698, loss = 0.00267105
Iteration 7699, loss = 0.00267082
Iteration 7700, loss = 0.00267032
Iteration 7701, loss = 0.00266984
Iteration 7702, loss = 0.00266946
Iteration 7703, loss = 0.00266894
Iteration 7704, loss = 0.00266843
Iteration 7705, loss = 0.00266790
Iteration 7706, loss = 0.00266738
Iteration 7707, loss = 0.00266693
Iteration 7708, loss = 0.00266707
Iteration 7709, loss = 0.00266608
Iteration 7710, loss = 0.00266561
Iteration 7711, loss = 0.00266509
Iteration 7712, loss = 0.00266467
Iteration 7713, loss = 0.00266414
Iteration 7714, loss = 0.00266360
Iteration 7715, loss = 0.00266309
Iteration 7716, loss = 0.00266262
Iteration 7717, loss = 0.00266215
Iteration 7718, loss = 0.00266169
Iteration 7719, loss = 0.00266122
Iteration 7720, loss = 0.00266089
Iteration 7721, loss = 0.00266045
Iteration 7722, loss = 0.00265969
Iteration 7723, loss = 0.00265928
Iteration 7724, loss = 0.00265868
Iteration 7725, loss = 0.00265828
Iteration 7726, loss = 0.00265768
Iteration 7727, loss = 0.00265709
Iteration 7728, loss = 0.00265663
Iteration 7729, loss = 0.00265619
Iteration 7730, loss = 0.00265548
Iteration 7731, loss = 0.00265485
Iteration 7732, loss = 0.00265441
Iteration 7733, loss = 0.00265391
Iteration 7734, loss = 0.00265348
Iteration 7735, loss = 0.00265306
Iteration 7736, loss = 0.00265252
Iteration 7737, loss = 0.00265211
Iteration 7738, loss = 0.00265166
Iteration 7739, loss = 0.00265121
Iteration 7740, loss = 0.00265077
Iteration 7741, loss = 0.00265033
Iteration 7742, loss = 0.00265033
Iteration 7743, loss = 0.00264968
Iteration 7744, loss = 0.00264915
Iteration 7745, loss = 0.00264860
Iteration 7746, loss = 0.00264815
Iteration 7747, loss = 0.00264769
Iteration 7748, loss = 0.00264721
Iteration 7749, loss = 0.00264671
Iteration 7750, loss = 0.00264616
Iteration 7751, loss = 0.00264565
Iteration 7752, loss = 0.00264542
Iteration 7753, loss = 0.00264472
Iteration 7754, loss = 0.00264426
Iteration 7755, loss = 0.00264381
Iteration 7756, loss = 0.00264354
Iteration 7757, loss = 0.00264278
Iteration 7758, loss = 0.00264234
Iteration 7759, loss = 0.00264227
Iteration 7760, loss = 0.00264148
Iteration 7761, loss = 0.00264105
Iteration 7762, loss = 0.00264039
Iteration 7763, loss = 0.00263985
Iteration 7764, loss = 0.00263949
Iteration 7765, loss = 0.00263885
Iteration 7766, loss = 0.00263831
Iteration 7767, loss = 0.00263808
Iteration 7768, loss = 0.00263737
Iteration 7769, loss = 0.00263693
Iteration 7770, loss = 0.00263638
Iteration 7771, loss = 0.00263599
Iteration 7772, loss = 0.00263538
Iteration 7773, loss = 0.00263477
Iteration 7774, loss = 0.00263423
Iteration 7775, loss = 0.00263378
Iteration 7776, loss = 0.00263325
Iteration 7777, loss = 0.00263318
Iteration 7778, loss = 0.00263227
Iteration 7779, loss = 0.00263176
Iteration 7780, loss = 0.00263136
Iteration 7781, loss = 0.00263086
Iteration 7782, loss = 0.00263031
Iteration 7783, loss = 0.00262991
Iteration 7784, loss = 0.00262928
Iteration 7785, loss = 0.00262878
Iteration 7786, loss = 0.00262827
Iteration 7787, loss = 0.00262767
Iteration 7788, loss = 0.00262735
Iteration 7789, loss = 0.00262670
Iteration 7790, loss = 0.00262619
Iteration 7791, loss = 0.00262561
Iteration 7792, loss = 0.00262527
Iteration 7793, loss = 0.00262466
Iteration 7794, loss = 0.00262423
Iteration 7795, loss = 0.00262374
Iteration 7796, loss = 0.00262355
Iteration 7797, loss = 0.00262280
Iteration 7798, loss = 0.00262232
Iteration 7799, loss = 0.00262187
Iteration 7800, loss = 0.00262145
Iteration 7801, loss = 0.00262100
Iteration 7802, loss = 0.00262054
Iteration 7803, loss = 0.00262002
Iteration 7804, loss = 0.00261970
Iteration 7805, loss = 0.00261915
Iteration 7806, loss = 0.00261873
Iteration 7807, loss = 0.00261838
Iteration 7808, loss = 0.00261784
Iteration 7809, loss = 0.00261741
Iteration 7810, loss = 0.00261696
Iteration 7811, loss = 0.00261649
Iteration 7812, loss = 0.00261609
Iteration 7813, loss = 0.00261579
Iteration 7814, loss = 0.00261529
Iteration 7815, loss = 0.00261475
Iteration 7816, loss = 0.00261432
Iteration 7817, loss = 0.00261393
Iteration 7818, loss = 0.00261338
Iteration 7819, loss = 0.00261277
Iteration 7820, loss = 0.00261251
Iteration 7821, loss = 0.00261184
Iteration 7822, loss = 0.00261143
Iteration 7823, loss = 0.00261090
Iteration 7824, loss = 0.00261032
Iteration 7825, loss = 0.00260985
Iteration 7826, loss = 0.00260949
Iteration 7827, loss = 0.00260883
Iteration 7828, loss = 0.00260832
Iteration 7829, loss = 0.00260793
Iteration 7830, loss = 0.00260744
Iteration 7831, loss = 0.00260700
Iteration 7832, loss = 0.00260654
Iteration 7833, loss = 0.00260626
Iteration 7834, loss = 0.00260571
Iteration 7835, loss = 0.00260532
Iteration 7836, loss = 0.00260480
Iteration 7837, loss = 0.00260429
Iteration 7838, loss = 0.00260376
Iteration 7839, loss = 0.00260370
Iteration 7840, loss = 0.00260302
Iteration 7841, loss = 0.00260232
Iteration 7842, loss = 0.00260185
Iteration 7843, loss = 0.00260139
Iteration 7844, loss = 0.00260082
Iteration 7845, loss = 0.00260027
Iteration 7846, loss = 0.00259994
Iteration 7847, loss = 0.00259929
Iteration 7848, loss = 0.00259896
Iteration 7849, loss = 0.00259827
Iteration 7850, loss = 0.00259794
Iteration 7851, loss = 0.00259742
Iteration 7852, loss = 0.00259660
Iteration 7853, loss = 0.00259604
Iteration 7854, loss = 0.00259586
Iteration 7855, loss = 0.00259529
Iteration 7856, loss = 0.00259468
Iteration 7857, loss = 0.00259431
Iteration 7858, loss = 0.00259375
Iteration 7859, loss = 0.00259332
Iteration 7860, loss = 0.00259277
Iteration 7861, loss = 0.00259232
Iteration 7862, loss = 0.00259189
Iteration 7863, loss = 0.00259145
Iteration 7864, loss = 0.00259101
Iteration 7865, loss = 0.00259047
Iteration 7866, loss = 0.00259006
Iteration 7867, loss = 0.00258961
Iteration 7868, loss = 0.00258930
Iteration 7869, loss = 0.00258871
Iteration 7870, loss = 0.00258828
Iteration 7871, loss = 0.00258788
Iteration 7872, loss = 0.00258752
Iteration 7873, loss = 0.00258692
Iteration 7874, loss = 0.00258654
Iteration 7875, loss = 0.00258631
Iteration 7876, loss = 0.00258553
Iteration 7877, loss = 0.00258525
Iteration 7878, loss = 0.00258465
Iteration 7879, loss = 0.00258430
Iteration 7880, loss = 0.00258374
Iteration 7881, loss = 0.00258337
Iteration 7882, loss = 0.00258304
Iteration 7883, loss = 0.00258239
Iteration 7884, loss = 0.00258195
Iteration 7885, loss = 0.00258129
Iteration 7886, loss = 0.00258087
Iteration 7887, loss = 0.00258041
Iteration 7888, loss = 0.00257993
Iteration 7889, loss = 0.00257947
Iteration 7890, loss = 0.00257897
Iteration 7891, loss = 0.00257849
Iteration 7892, loss = 0.00257826
Iteration 7893, loss = 0.00257762
Iteration 7894, loss = 0.00257707
Iteration 7895, loss = 0.00257660
Iteration 7896, loss = 0.00257613
Iteration 7897, loss = 0.00257560
Iteration 7898, loss = 0.00257519
Iteration 7899, loss = 0.00257474
Iteration 7900, loss = 0.00257428
Iteration 7901, loss = 0.00257387
Iteration 7902, loss = 0.00257359
Iteration 7903, loss = 0.00257323
Iteration 7904, loss = 0.00257258
Iteration 7905, loss = 0.00257217
Iteration 7906, loss = 0.00257171
Iteration 7907, loss = 0.00257161
Iteration 7908, loss = 0.00257085
Iteration 7909, loss = 0.00257048
Iteration 7910, loss = 0.00257001
Iteration 7911, loss = 0.00256952
Iteration 7912, loss = 0.00256923
Iteration 7913, loss = 0.00256866
Iteration 7914, loss = 0.00256821
Iteration 7915, loss = 0.00256793
Iteration 7916, loss = 0.00256723
Iteration 7917, loss = 0.00256679
Iteration 7918, loss = 0.00256625
Iteration 7919, loss = 0.00256575
Iteration 7920, loss = 0.00256545
Iteration 7921, loss = 0.00256485
Iteration 7922, loss = 0.00256435
Iteration 7923, loss = 0.00256418
Iteration 7924, loss = 0.00256348
Iteration 7925, loss = 0.00256300
Iteration 7926, loss = 0.00256256
Iteration 7927, loss = 0.00256210
Iteration 7928, loss = 0.00256193
Iteration 7929, loss = 0.00256109
Iteration 7930, loss = 0.00256056
Iteration 7931, loss = 0.00256018
Iteration 7932, loss = 0.00255958
Iteration 7933, loss = 0.00255919
Iteration 7934, loss = 0.00255867
Iteration 7935, loss = 0.00255817
Iteration 7936, loss = 0.00255774
Iteration 7937, loss = 0.00255733
Iteration 7938, loss = 0.00255695
Iteration 7939, loss = 0.00255638
Iteration 7940, loss = 0.00255588
Iteration 7941, loss = 0.00255549
Iteration 7942, loss = 0.00255520
Iteration 7943, loss = 0.00255457
Iteration 7944, loss = 0.00255416
Iteration 7945, loss = 0.00255364
Iteration 7946, loss = 0.00255308
Iteration 7947, loss = 0.00255301
Iteration 7948, loss = 0.00255228
Iteration 7949, loss = 0.00255177
Iteration 7950, loss = 0.00255138
Iteration 7951, loss = 0.00255095
Iteration 7952, loss = 0.00255052
Iteration 7953, loss = 0.00255005
Iteration 7954, loss = 0.00254971
Iteration 7955, loss = 0.00254920
Iteration 7956, loss = 0.00254869
Iteration 7957, loss = 0.00254832
Iteration 7958, loss = 0.00254785
Iteration 7959, loss = 0.00254742
Iteration 7960, loss = 0.00254692
Iteration 7961, loss = 0.00254642
Iteration 7962, loss = 0.00254598
Iteration 7963, loss = 0.00254560
Iteration 7964, loss = 0.00254509
Iteration 7965, loss = 0.00254469
Iteration 7966, loss = 0.00254426
Iteration 7967, loss = 0.00254378
Iteration 7968, loss = 0.00254349
Iteration 7969, loss = 0.00254302
Iteration 7970, loss = 0.00254257
Iteration 7971, loss = 0.00254216
Iteration 7972, loss = 0.00254167
Iteration 7973, loss = 0.00254162
Iteration 7974, loss = 0.00254086
Iteration 7975, loss = 0.00254045
Iteration 7976, loss = 0.00254005
Iteration 7977, loss = 0.00253956
Iteration 7978, loss = 0.00253945
Iteration 7979, loss = 0.00253864
Iteration 7980, loss = 0.00253827
Iteration 7981, loss = 0.00253771
Iteration 7982, loss = 0.00253719
Iteration 7983, loss = 0.00253674
Iteration 7984, loss = 0.00253637
Iteration 7985, loss = 0.00253598
Iteration 7986, loss = 0.00253550
Iteration 7987, loss = 0.00253518
Iteration 7988, loss = 0.00253468
Iteration 7989, loss = 0.00253417
Iteration 7990, loss = 0.00253370
Iteration 7991, loss = 0.00253327
Iteration 7992, loss = 0.00253283
Iteration 7993, loss = 0.00253239
Iteration 7994, loss = 0.00253201
Iteration 7995, loss = 0.00253159
Iteration 7996, loss = 0.00253113
Iteration 7997, loss = 0.00253066
Iteration 7998, loss = 0.00253027
Iteration 7999, loss = 0.00252986
Iteration 8000, loss = 0.00252941
Iteration 1, loss = 1.04050369
Iteration 2, loss = 1.03732877
Iteration 3, loss = 1.03228782
Iteration 4, loss = 1.02590172
Iteration 5, loss = 1.01841874
Iteration 6, loss = 1.01026513
Iteration 7, loss = 1.00150979
Iteration 8, loss = 0.99252671
Iteration 9, loss = 0.98316333
Iteration 10, loss = 0.97383231
Iteration 11, loss = 0.96430318
Iteration 12, loss = 0.95495240
Iteration 13, loss = 0.94546184
Iteration 14, loss = 0.93627053
Iteration 15, loss = 0.92715300
Iteration 16, loss = 0.91819068
Iteration 17, loss = 0.90923165
Iteration 18, loss = 0.90080869
Iteration 19, loss = 0.89245434
Iteration 20, loss = 0.88432965
Iteration 21, loss = 0.87639910
Iteration 22, loss = 0.86877096
Iteration 23, loss = 0.86124425
Iteration 24, loss = 0.85401993
Iteration 25, loss = 0.84695325
Iteration 26, loss = 0.83996555
Iteration 27, loss = 0.83325237
Iteration 28, loss = 0.82664748
Iteration 29, loss = 0.82048238
Iteration 30, loss = 0.81432739
Iteration 31, loss = 0.80834903
Iteration 32, loss = 0.80260595
Iteration 33, loss = 0.79695936
Iteration 34, loss = 0.79144282
Iteration 35, loss = 0.78617520
Iteration 36, loss = 0.78078628
Iteration 37, loss = 0.77586423
Iteration 38, loss = 0.77084430
Iteration 39, loss = 0.76602151
Iteration 40, loss = 0.76146554
Iteration 41, loss = 0.75703648
Iteration 42, loss = 0.75262616
Iteration 43, loss = 0.74855269
Iteration 44, loss = 0.74452170
Iteration 45, loss = 0.74059894
Iteration 46, loss = 0.73682554
Iteration 47, loss = 0.73300366
Iteration 48, loss = 0.72926156
Iteration 49, loss = 0.72558629
Iteration 50, loss = 0.72196533
Iteration 51, loss = 0.71841017
Iteration 52, loss = 0.71486730
Iteration 53, loss = 0.71142870
Iteration 54, loss = 0.70792348
Iteration 55, loss = 0.70454550
Iteration 56, loss = 0.70115835
Iteration 57, loss = 0.69770108
Iteration 58, loss = 0.69440466
Iteration 59, loss = 0.69110946
Iteration 60, loss = 0.68774565
Iteration 61, loss = 0.68449378
Iteration 62, loss = 0.68136257
Iteration 63, loss = 0.67824092
Iteration 64, loss = 0.67511654
Iteration 65, loss = 0.67214283
Iteration 66, loss = 0.66909436
Iteration 67, loss = 0.66608741
Iteration 68, loss = 0.66321437
Iteration 69, loss = 0.66018039
Iteration 70, loss = 0.65735621
Iteration 71, loss = 0.65440583
Iteration 72, loss = 0.65161792
Iteration 73, loss = 0.64876363
Iteration 74, loss = 0.64602723
Iteration 75, loss = 0.64320289
Iteration 76, loss = 0.64050173
Iteration 77, loss = 0.63777471
Iteration 78, loss = 0.63506111
Iteration 79, loss = 0.63238493
Iteration 80, loss = 0.62971096
Iteration 81, loss = 0.62703738
Iteration 82, loss = 0.62438276
Iteration 83, loss = 0.62174675
Iteration 84, loss = 0.61907970
Iteration 85, loss = 0.61653041
Iteration 86, loss = 0.61390528
Iteration 87, loss = 0.61135124
Iteration 88, loss = 0.60879018
Iteration 89, loss = 0.60627429
Iteration 90, loss = 0.60371012
Iteration 91, loss = 0.60122170
Iteration 92, loss = 0.59871606
Iteration 93, loss = 0.59624942
Iteration 94, loss = 0.59375331
Iteration 95, loss = 0.59128956
Iteration 96, loss = 0.58886827
Iteration 97, loss = 0.58645712
Iteration 98, loss = 0.58405157
Iteration 99, loss = 0.58166256
Iteration 100, loss = 0.57925645
Iteration 101, loss = 0.57689530
Iteration 102, loss = 0.57447861
Iteration 103, loss = 0.57209433
Iteration 104, loss = 0.56974594
Iteration 105, loss = 0.56734843
Iteration 106, loss = 0.56498641
Iteration 107, loss = 0.56264243
Iteration 108, loss = 0.56037006
Iteration 109, loss = 0.55802114
Iteration 110, loss = 0.55573070
Iteration 111, loss = 0.55343688
Iteration 112, loss = 0.55113215
Iteration 113, loss = 0.54890175
Iteration 114, loss = 0.54653680
Iteration 115, loss = 0.54425046
Iteration 116, loss = 0.54198359
Iteration 117, loss = 0.53964646
Iteration 118, loss = 0.53740245
Iteration 119, loss = 0.53507687
Iteration 120, loss = 0.53278699
Iteration 121, loss = 0.53056277
Iteration 122, loss = 0.52835134
Iteration 123, loss = 0.52615455
Iteration 124, loss = 0.52395858
Iteration 125, loss = 0.52179861
Iteration 126, loss = 0.51961305
Iteration 127, loss = 0.51745739
Iteration 128, loss = 0.51530896
Iteration 129, loss = 0.51315606
Iteration 130, loss = 0.51107925
Iteration 131, loss = 0.50895029
Iteration 132, loss = 0.50684954
Iteration 133, loss = 0.50478066
Iteration 134, loss = 0.50270586
Iteration 135, loss = 0.50061679
Iteration 136, loss = 0.49856002
Iteration 137, loss = 0.49648828
Iteration 138, loss = 0.49440478
Iteration 139, loss = 0.49234332
Iteration 140, loss = 0.49024394
Iteration 141, loss = 0.48816485
Iteration 142, loss = 0.48609262
Iteration 143, loss = 0.48401541
Iteration 144, loss = 0.48193948
Iteration 145, loss = 0.47986052
Iteration 146, loss = 0.47779161
Iteration 147, loss = 0.47571234
Iteration 148, loss = 0.47363991
Iteration 149, loss = 0.47152559
Iteration 150, loss = 0.46945036
Iteration 151, loss = 0.46735889
Iteration 152, loss = 0.46525647
Iteration 153, loss = 0.46317572
Iteration 154, loss = 0.46109560
Iteration 155, loss = 0.45905759
Iteration 156, loss = 0.45695587
Iteration 157, loss = 0.45489981
Iteration 158, loss = 0.45282023
Iteration 159, loss = 0.45072873
Iteration 160, loss = 0.44859285
Iteration 161, loss = 0.44651937
Iteration 162, loss = 0.44438360
Iteration 163, loss = 0.44226946
Iteration 164, loss = 0.44015986
Iteration 165, loss = 0.43806560
Iteration 166, loss = 0.43593927
Iteration 167, loss = 0.43384767
Iteration 168, loss = 0.43176160
Iteration 169, loss = 0.42964121
Iteration 170, loss = 0.42758691
Iteration 171, loss = 0.42546987
Iteration 172, loss = 0.42339242
Iteration 173, loss = 0.42131317
Iteration 174, loss = 0.41924299
Iteration 175, loss = 0.41715141
Iteration 176, loss = 0.41509943
Iteration 177, loss = 0.41302535
Iteration 178, loss = 0.41097269
Iteration 179, loss = 0.40889015
Iteration 180, loss = 0.40684336
Iteration 181, loss = 0.40473674
Iteration 182, loss = 0.40267031
Iteration 183, loss = 0.40059942
Iteration 184, loss = 0.39847800
Iteration 185, loss = 0.39639893
Iteration 186, loss = 0.39433036
Iteration 187, loss = 0.39223477
Iteration 188, loss = 0.39016703
Iteration 189, loss = 0.38812468
Iteration 190, loss = 0.38604845
Iteration 191, loss = 0.38402219
Iteration 192, loss = 0.38200042
Iteration 193, loss = 0.37997154
Iteration 194, loss = 0.37795590
Iteration 195, loss = 0.37597188
Iteration 196, loss = 0.37392099
Iteration 197, loss = 0.37193921
Iteration 198, loss = 0.36990943
Iteration 199, loss = 0.36791078
Iteration 200, loss = 0.36590515
Iteration 201, loss = 0.36389314
Iteration 202, loss = 0.36192431
Iteration 203, loss = 0.35993203
Iteration 204, loss = 0.35795379
Iteration 205, loss = 0.35597919
Iteration 206, loss = 0.35402330
Iteration 207, loss = 0.35203421
Iteration 208, loss = 0.35006349
Iteration 209, loss = 0.34807838
Iteration 210, loss = 0.34608904
Iteration 211, loss = 0.34409313
Iteration 212, loss = 0.34208148
Iteration 213, loss = 0.34009109
Iteration 214, loss = 0.33809939
Iteration 215, loss = 0.33608695
Iteration 216, loss = 0.33409292
Iteration 217, loss = 0.33210374
Iteration 218, loss = 0.33015139
Iteration 219, loss = 0.32816725
Iteration 220, loss = 0.32622936
Iteration 221, loss = 0.32428415
Iteration 222, loss = 0.32234212
Iteration 223, loss = 0.32042333
Iteration 224, loss = 0.31849088
Iteration 225, loss = 0.31658940
Iteration 226, loss = 0.31467258
Iteration 227, loss = 0.31276280
Iteration 228, loss = 0.31086811
Iteration 229, loss = 0.30897225
Iteration 230, loss = 0.30708511
Iteration 231, loss = 0.30522719
Iteration 232, loss = 0.30334901
Iteration 233, loss = 0.30148695
Iteration 234, loss = 0.29965071
Iteration 235, loss = 0.29781340
Iteration 236, loss = 0.29598066
Iteration 237, loss = 0.29416490
Iteration 238, loss = 0.29234873
Iteration 239, loss = 0.29053974
Iteration 240, loss = 0.28872911
Iteration 241, loss = 0.28694115
Iteration 242, loss = 0.28514634
Iteration 243, loss = 0.28335403
Iteration 244, loss = 0.28157526
Iteration 245, loss = 0.27980944
Iteration 246, loss = 0.27804301
Iteration 247, loss = 0.27630599
Iteration 248, loss = 0.27457524
Iteration 249, loss = 0.27285168
Iteration 250, loss = 0.27115841
Iteration 251, loss = 0.26947292
Iteration 252, loss = 0.26779688
Iteration 253, loss = 0.26611914
Iteration 254, loss = 0.26446943
Iteration 255, loss = 0.26282260
Iteration 256, loss = 0.26119016
Iteration 257, loss = 0.25954136
Iteration 258, loss = 0.25792686
Iteration 259, loss = 0.25630347
Iteration 260, loss = 0.25469762
Iteration 261, loss = 0.25308288
Iteration 262, loss = 0.25148034
Iteration 263, loss = 0.24987788
Iteration 264, loss = 0.24827459
Iteration 265, loss = 0.24669747
Iteration 266, loss = 0.24512185
Iteration 267, loss = 0.24356133
Iteration 268, loss = 0.24201633
Iteration 269, loss = 0.24049067
Iteration 270, loss = 0.23899141
Iteration 271, loss = 0.23749763
Iteration 272, loss = 0.23602659
Iteration 273, loss = 0.23453910
Iteration 274, loss = 0.23308794
Iteration 275, loss = 0.23162562
Iteration 276, loss = 0.23019575
Iteration 277, loss = 0.22875614
Iteration 278, loss = 0.22734781
Iteration 279, loss = 0.22596201
Iteration 280, loss = 0.22455825
Iteration 281, loss = 0.22318984
Iteration 282, loss = 0.22181868
Iteration 283, loss = 0.22046453
Iteration 284, loss = 0.21910926
Iteration 285, loss = 0.21776962
Iteration 286, loss = 0.21643458
Iteration 287, loss = 0.21511492
Iteration 288, loss = 0.21379611
Iteration 289, loss = 0.21249283
Iteration 290, loss = 0.21118838
Iteration 291, loss = 0.20990256
Iteration 292, loss = 0.20863082
Iteration 293, loss = 0.20735596
Iteration 294, loss = 0.20607892
Iteration 295, loss = 0.20485321
Iteration 296, loss = 0.20359467
Iteration 297, loss = 0.20238812
Iteration 298, loss = 0.20114116
Iteration 299, loss = 0.19994555
Iteration 300, loss = 0.19873478
Iteration 301, loss = 0.19752347
Iteration 302, loss = 0.19634024
Iteration 303, loss = 0.19517112
Iteration 304, loss = 0.19399926
Iteration 305, loss = 0.19284938
Iteration 306, loss = 0.19171146
Iteration 307, loss = 0.19058591
Iteration 308, loss = 0.18947349
Iteration 309, loss = 0.18836609
Iteration 310, loss = 0.18727788
Iteration 311, loss = 0.18618839
Iteration 312, loss = 0.18511530
Iteration 313, loss = 0.18404355
Iteration 314, loss = 0.18298204
Iteration 315, loss = 0.18192386
Iteration 316, loss = 0.18087305
Iteration 317, loss = 0.17983807
Iteration 318, loss = 0.17880307
Iteration 319, loss = 0.17778598
Iteration 320, loss = 0.17676578
Iteration 321, loss = 0.17575861
Iteration 322, loss = 0.17477004
Iteration 323, loss = 0.17377910
Iteration 324, loss = 0.17280309
Iteration 325, loss = 0.17182516
Iteration 326, loss = 0.17086325
Iteration 327, loss = 0.16990814
Iteration 328, loss = 0.16895586
Iteration 329, loss = 0.16801684
Iteration 330, loss = 0.16708164
Iteration 331, loss = 0.16615145
Iteration 332, loss = 0.16522887
Iteration 333, loss = 0.16432700
Iteration 334, loss = 0.16341680
Iteration 335, loss = 0.16251504
Iteration 336, loss = 0.16162549
Iteration 337, loss = 0.16072881
Iteration 338, loss = 0.15983848
Iteration 339, loss = 0.15895395
Iteration 340, loss = 0.15807015
Iteration 341, loss = 0.15720270
Iteration 342, loss = 0.15633458
Iteration 343, loss = 0.15549015
Iteration 344, loss = 0.15463831
Iteration 345, loss = 0.15380581
Iteration 346, loss = 0.15298315
Iteration 347, loss = 0.15215508
Iteration 348, loss = 0.15134302
Iteration 349, loss = 0.15052625
Iteration 350, loss = 0.14972578
Iteration 351, loss = 0.14892379
Iteration 352, loss = 0.14813079
Iteration 353, loss = 0.14735964
Iteration 354, loss = 0.14657907
Iteration 355, loss = 0.14581844
Iteration 356, loss = 0.14506419
Iteration 357, loss = 0.14432059
Iteration 358, loss = 0.14358161
Iteration 359, loss = 0.14284202
Iteration 360, loss = 0.14212132
Iteration 361, loss = 0.14139984
Iteration 362, loss = 0.14068271
Iteration 363, loss = 0.13997937
Iteration 364, loss = 0.13926950
Iteration 365, loss = 0.13857081
Iteration 366, loss = 0.13786939
Iteration 367, loss = 0.13717787
Iteration 368, loss = 0.13649772
Iteration 369, loss = 0.13582229
Iteration 370, loss = 0.13514633
Iteration 371, loss = 0.13448390
Iteration 372, loss = 0.13383269
Iteration 373, loss = 0.13317652
Iteration 374, loss = 0.13252539
Iteration 375, loss = 0.13187872
Iteration 376, loss = 0.13124028
Iteration 377, loss = 0.13060111
Iteration 378, loss = 0.12997480
Iteration 379, loss = 0.12934484
Iteration 380, loss = 0.12872069
Iteration 381, loss = 0.12810932
Iteration 382, loss = 0.12750092
Iteration 383, loss = 0.12689624
Iteration 384, loss = 0.12629191
Iteration 385, loss = 0.12569695
Iteration 386, loss = 0.12510675
Iteration 387, loss = 0.12451001
Iteration 388, loss = 0.12391522
Iteration 389, loss = 0.12334330
Iteration 390, loss = 0.12275818
Iteration 391, loss = 0.12218340
Iteration 392, loss = 0.12161695
Iteration 393, loss = 0.12105214
Iteration 394, loss = 0.12049616
Iteration 395, loss = 0.11994022
Iteration 396, loss = 0.11939457
Iteration 397, loss = 0.11885451
Iteration 398, loss = 0.11831431
Iteration 399, loss = 0.11778581
Iteration 400, loss = 0.11725576
Iteration 401, loss = 0.11673416
Iteration 402, loss = 0.11621832
Iteration 403, loss = 0.11570409
Iteration 404, loss = 0.11519437
Iteration 405, loss = 0.11469413
Iteration 406, loss = 0.11419531
Iteration 407, loss = 0.11370174
Iteration 408, loss = 0.11321119
Iteration 409, loss = 0.11272753
Iteration 410, loss = 0.11224629
Iteration 411, loss = 0.11176932
Iteration 412, loss = 0.11129538
Iteration 413, loss = 0.11083641
Iteration 414, loss = 0.11036463
Iteration 415, loss = 0.10989976
Iteration 416, loss = 0.10944370
Iteration 417, loss = 0.10898011
Iteration 418, loss = 0.10852954
Iteration 419, loss = 0.10807357
Iteration 420, loss = 0.10762607
Iteration 421, loss = 0.10717601
Iteration 422, loss = 0.10673385
Iteration 423, loss = 0.10629016
Iteration 424, loss = 0.10585013
Iteration 425, loss = 0.10541395
Iteration 426, loss = 0.10498587
Iteration 427, loss = 0.10456040
Iteration 428, loss = 0.10413897
Iteration 429, loss = 0.10372252
Iteration 430, loss = 0.10330900
Iteration 431, loss = 0.10290656
Iteration 432, loss = 0.10249898
Iteration 433, loss = 0.10209477
Iteration 434, loss = 0.10168632
Iteration 435, loss = 0.10129639
Iteration 436, loss = 0.10089371
Iteration 437, loss = 0.10050053
Iteration 438, loss = 0.10010838
Iteration 439, loss = 0.09972758
Iteration 440, loss = 0.09933345
Iteration 441, loss = 0.09894870
Iteration 442, loss = 0.09857293
Iteration 443, loss = 0.09819786
Iteration 444, loss = 0.09782734
Iteration 445, loss = 0.09745542
Iteration 446, loss = 0.09708904
Iteration 447, loss = 0.09673197
Iteration 448, loss = 0.09636299
Iteration 449, loss = 0.09600368
Iteration 450, loss = 0.09564293
Iteration 451, loss = 0.09528579
Iteration 452, loss = 0.09493370
Iteration 453, loss = 0.09458206
Iteration 454, loss = 0.09423641
Iteration 455, loss = 0.09389333
Iteration 456, loss = 0.09354737
Iteration 457, loss = 0.09320600
Iteration 458, loss = 0.09286497
Iteration 459, loss = 0.09252314
Iteration 460, loss = 0.09219635
Iteration 461, loss = 0.09185704
Iteration 462, loss = 0.09152813
Iteration 463, loss = 0.09120486
Iteration 464, loss = 0.09088448
Iteration 465, loss = 0.09056228
Iteration 466, loss = 0.09024893
Iteration 467, loss = 0.08992760
Iteration 468, loss = 0.08961621
Iteration 469, loss = 0.08930372
Iteration 470, loss = 0.08898617
Iteration 471, loss = 0.08867672
Iteration 472, loss = 0.08836575
Iteration 473, loss = 0.08805468
Iteration 474, loss = 0.08774280
Iteration 475, loss = 0.08743594
Iteration 476, loss = 0.08714020
Iteration 477, loss = 0.08683694
Iteration 478, loss = 0.08653241
Iteration 479, loss = 0.08623598
Iteration 480, loss = 0.08594429
Iteration 481, loss = 0.08565204
Iteration 482, loss = 0.08535364
Iteration 483, loss = 0.08507550
Iteration 484, loss = 0.08478206
Iteration 485, loss = 0.08448972
Iteration 486, loss = 0.08421209
Iteration 487, loss = 0.08392270
Iteration 488, loss = 0.08364759
Iteration 489, loss = 0.08337232
Iteration 490, loss = 0.08308891
Iteration 491, loss = 0.08282114
Iteration 492, loss = 0.08254955
Iteration 493, loss = 0.08228476
Iteration 494, loss = 0.08201843
Iteration 495, loss = 0.08175460
Iteration 496, loss = 0.08150097
Iteration 497, loss = 0.08123977
Iteration 498, loss = 0.08099441
Iteration 499, loss = 0.08072476
Iteration 500, loss = 0.08046560
Iteration 501, loss = 0.08021084
Iteration 502, loss = 0.07995418
Iteration 503, loss = 0.07970528
Iteration 504, loss = 0.07945279
Iteration 505, loss = 0.07920380
Iteration 506, loss = 0.07895862
Iteration 507, loss = 0.07871452
Iteration 508, loss = 0.07847738
Iteration 509, loss = 0.07823494
Iteration 510, loss = 0.07799836
Iteration 511, loss = 0.07776162
Iteration 512, loss = 0.07752368
Iteration 513, loss = 0.07730168
Iteration 514, loss = 0.07706857
Iteration 515, loss = 0.07683105
Iteration 516, loss = 0.07660464
Iteration 517, loss = 0.07636933
Iteration 518, loss = 0.07613719
Iteration 519, loss = 0.07590712
Iteration 520, loss = 0.07568262
Iteration 521, loss = 0.07545365
Iteration 522, loss = 0.07522741
Iteration 523, loss = 0.07500854
Iteration 524, loss = 0.07478617
Iteration 525, loss = 0.07456934
Iteration 526, loss = 0.07435921
Iteration 527, loss = 0.07413780
Iteration 528, loss = 0.07392057
Iteration 529, loss = 0.07371049
Iteration 530, loss = 0.07349436
Iteration 531, loss = 0.07328620
Iteration 532, loss = 0.07307678
Iteration 533, loss = 0.07286899
Iteration 534, loss = 0.07266512
Iteration 535, loss = 0.07246367
Iteration 536, loss = 0.07226153
Iteration 537, loss = 0.07206289
Iteration 538, loss = 0.07186485
Iteration 539, loss = 0.07166949
Iteration 540, loss = 0.07147467
Iteration 541, loss = 0.07128169
Iteration 542, loss = 0.07108920
Iteration 543, loss = 0.07089660
Iteration 544, loss = 0.07070995
Iteration 545, loss = 0.07051757
Iteration 546, loss = 0.07032510
Iteration 547, loss = 0.07014199
Iteration 548, loss = 0.06994793
Iteration 549, loss = 0.06976446
Iteration 550, loss = 0.06957659
Iteration 551, loss = 0.06939210
Iteration 552, loss = 0.06920890
Iteration 553, loss = 0.06902352
Iteration 554, loss = 0.06884407
Iteration 555, loss = 0.06866228
Iteration 556, loss = 0.06848648
Iteration 557, loss = 0.06830557
Iteration 558, loss = 0.06812940
Iteration 559, loss = 0.06794760
Iteration 560, loss = 0.06777480
Iteration 561, loss = 0.06759360
Iteration 562, loss = 0.06742097
Iteration 563, loss = 0.06724638
Iteration 564, loss = 0.06707038
Iteration 565, loss = 0.06690183
Iteration 566, loss = 0.06673094
Iteration 567, loss = 0.06655820
Iteration 568, loss = 0.06639162
Iteration 569, loss = 0.06622653
Iteration 570, loss = 0.06606042
Iteration 571, loss = 0.06589602
Iteration 572, loss = 0.06573277
Iteration 573, loss = 0.06558154
Iteration 574, loss = 0.06541314
Iteration 575, loss = 0.06525678
Iteration 576, loss = 0.06508840
Iteration 577, loss = 0.06493135
Iteration 578, loss = 0.06477070
Iteration 579, loss = 0.06461947
Iteration 580, loss = 0.06445827
Iteration 581, loss = 0.06430528
Iteration 582, loss = 0.06415078
Iteration 583, loss = 0.06399644
Iteration 584, loss = 0.06384282
Iteration 585, loss = 0.06369575
Iteration 586, loss = 0.06353254
Iteration 587, loss = 0.06339049
Iteration 588, loss = 0.06323391
Iteration 589, loss = 0.06308434
Iteration 590, loss = 0.06293090
Iteration 591, loss = 0.06278871
Iteration 592, loss = 0.06263863
Iteration 593, loss = 0.06249434
Iteration 594, loss = 0.06235135
Iteration 595, loss = 0.06220751
Iteration 596, loss = 0.06206702
Iteration 597, loss = 0.06192722
Iteration 598, loss = 0.06178742
Iteration 599, loss = 0.06165246
Iteration 600, loss = 0.06151416
Iteration 601, loss = 0.06137647
Iteration 602, loss = 0.06123887
Iteration 603, loss = 0.06109758
Iteration 604, loss = 0.06096013
Iteration 605, loss = 0.06082311
Iteration 606, loss = 0.06068137
Iteration 607, loss = 0.06053977
Iteration 608, loss = 0.06040336
Iteration 609, loss = 0.06026302
Iteration 610, loss = 0.06012753
Iteration 611, loss = 0.05998775
Iteration 612, loss = 0.05985270
Iteration 613, loss = 0.05971648
Iteration 614, loss = 0.05958239
Iteration 615, loss = 0.05945041
Iteration 616, loss = 0.05931609
Iteration 617, loss = 0.05918121
Iteration 618, loss = 0.05904850
Iteration 619, loss = 0.05891244
Iteration 620, loss = 0.05877813
Iteration 621, loss = 0.05865396
Iteration 622, loss = 0.05851965
Iteration 623, loss = 0.05839436
Iteration 624, loss = 0.05826812
Iteration 625, loss = 0.05813911
Iteration 626, loss = 0.05801170
Iteration 627, loss = 0.05788452
Iteration 628, loss = 0.05775989
Iteration 629, loss = 0.05763549
Iteration 630, loss = 0.05750878
Iteration 631, loss = 0.05738801
Iteration 632, loss = 0.05726598
Iteration 633, loss = 0.05714507
Iteration 634, loss = 0.05702534
Iteration 635, loss = 0.05690676
Iteration 636, loss = 0.05678490
Iteration 637, loss = 0.05666195
Iteration 638, loss = 0.05654090
Iteration 639, loss = 0.05642478
Iteration 640, loss = 0.05630298
Iteration 641, loss = 0.05618494
Iteration 642, loss = 0.05607095
Iteration 643, loss = 0.05594946
Iteration 644, loss = 0.05583481
Iteration 645, loss = 0.05571850
Iteration 646, loss = 0.05560213
Iteration 647, loss = 0.05548648
Iteration 648, loss = 0.05537533
Iteration 649, loss = 0.05526401
Iteration 650, loss = 0.05515471
Iteration 651, loss = 0.05504560
Iteration 652, loss = 0.05493865
Iteration 653, loss = 0.05483156
Iteration 654, loss = 0.05472164
Iteration 655, loss = 0.05461579
Iteration 656, loss = 0.05450600
Iteration 657, loss = 0.05439408
Iteration 658, loss = 0.05428361
Iteration 659, loss = 0.05417035
Iteration 660, loss = 0.05406161
Iteration 661, loss = 0.05395256
Iteration 662, loss = 0.05384259
Iteration 663, loss = 0.05374046
Iteration 664, loss = 0.05362745
Iteration 665, loss = 0.05352155
Iteration 666, loss = 0.05341709
Iteration 667, loss = 0.05331196
Iteration 668, loss = 0.05320947
Iteration 669, loss = 0.05311189
Iteration 670, loss = 0.05300406
Iteration 671, loss = 0.05290282
Iteration 672, loss = 0.05279900
Iteration 673, loss = 0.05269672
Iteration 674, loss = 0.05259673
Iteration 675, loss = 0.05249779
Iteration 676, loss = 0.05239549
Iteration 677, loss = 0.05229452
Iteration 678, loss = 0.05219248
Iteration 679, loss = 0.05209797
Iteration 680, loss = 0.05199795
Iteration 681, loss = 0.05189693
Iteration 682, loss = 0.05180286
Iteration 683, loss = 0.05170096
Iteration 684, loss = 0.05160421
Iteration 685, loss = 0.05150267
Iteration 686, loss = 0.05140661
Iteration 687, loss = 0.05131016
Iteration 688, loss = 0.05121296
Iteration 689, loss = 0.05111552
Iteration 690, loss = 0.05101899
Iteration 691, loss = 0.05092350
Iteration 692, loss = 0.05083433
Iteration 693, loss = 0.05073339
Iteration 694, loss = 0.05064256
Iteration 695, loss = 0.05054524
Iteration 696, loss = 0.05044976
Iteration 697, loss = 0.05035732
Iteration 698, loss = 0.05026548
Iteration 699, loss = 0.05017915
Iteration 700, loss = 0.05008243
Iteration 701, loss = 0.04999464
Iteration 702, loss = 0.04990247
Iteration 703, loss = 0.04981929
Iteration 704, loss = 0.04972174
Iteration 705, loss = 0.04963297
Iteration 706, loss = 0.04954922
Iteration 707, loss = 0.04945936
Iteration 708, loss = 0.04937198
Iteration 709, loss = 0.04928579
Iteration 710, loss = 0.04919901
Iteration 711, loss = 0.04911069
Iteration 712, loss = 0.04902322
Iteration 713, loss = 0.04893524
Iteration 714, loss = 0.04884979
Iteration 715, loss = 0.04876103
Iteration 716, loss = 0.04867257
Iteration 717, loss = 0.04858244
Iteration 718, loss = 0.04849590
Iteration 719, loss = 0.04840783
Iteration 720, loss = 0.04831636
Iteration 721, loss = 0.04823136
Iteration 722, loss = 0.04814302
Iteration 723, loss = 0.04805965
Iteration 724, loss = 0.04797515
Iteration 725, loss = 0.04788652
Iteration 726, loss = 0.04780248
Iteration 727, loss = 0.04771604
Iteration 728, loss = 0.04763497
Iteration 729, loss = 0.04754732
Iteration 730, loss = 0.04746527
Iteration 731, loss = 0.04737976
Iteration 732, loss = 0.04729623
Iteration 733, loss = 0.04721409
Iteration 734, loss = 0.04713192
Iteration 735, loss = 0.04705131
Iteration 736, loss = 0.04697372
Iteration 737, loss = 0.04689226
Iteration 738, loss = 0.04681190
Iteration 739, loss = 0.04673356
Iteration 740, loss = 0.04665805
Iteration 741, loss = 0.04657630
Iteration 742, loss = 0.04650084
Iteration 743, loss = 0.04641963
Iteration 744, loss = 0.04634455
Iteration 745, loss = 0.04627250
Iteration 746, loss = 0.04619383
Iteration 747, loss = 0.04611603
Iteration 748, loss = 0.04604238
Iteration 749, loss = 0.04596684
Iteration 750, loss = 0.04589408
Iteration 751, loss = 0.04581581
Iteration 752, loss = 0.04574314
Iteration 753, loss = 0.04567219
Iteration 754, loss = 0.04559746
Iteration 755, loss = 0.04552485
Iteration 756, loss = 0.04545256
Iteration 757, loss = 0.04537990
Iteration 758, loss = 0.04530796
Iteration 759, loss = 0.04523772
Iteration 760, loss = 0.04516678
Iteration 761, loss = 0.04509273
Iteration 762, loss = 0.04502101
Iteration 763, loss = 0.04495338
Iteration 764, loss = 0.04488029
Iteration 765, loss = 0.04480713
Iteration 766, loss = 0.04473730
Iteration 767, loss = 0.04466386
Iteration 768, loss = 0.04459387
Iteration 769, loss = 0.04452018
Iteration 770, loss = 0.04445124
Iteration 771, loss = 0.04437915
Iteration 772, loss = 0.04430887
Iteration 773, loss = 0.04423693
Iteration 774, loss = 0.04416850
Iteration 775, loss = 0.04409631
Iteration 776, loss = 0.04402923
Iteration 777, loss = 0.04396057
Iteration 778, loss = 0.04389034
Iteration 779, loss = 0.04382826
Iteration 780, loss = 0.04375778
Iteration 781, loss = 0.04368401
Iteration 782, loss = 0.04361565
Iteration 783, loss = 0.04354612
Iteration 784, loss = 0.04347595
Iteration 785, loss = 0.04340590
Iteration 786, loss = 0.04333781
Iteration 787, loss = 0.04327260
Iteration 788, loss = 0.04320264
Iteration 789, loss = 0.04313359
Iteration 790, loss = 0.04306864
Iteration 791, loss = 0.04300334
Iteration 792, loss = 0.04293904
Iteration 793, loss = 0.04287611
Iteration 794, loss = 0.04281002
Iteration 795, loss = 0.04274982
Iteration 796, loss = 0.04268367
Iteration 797, loss = 0.04262005
Iteration 798, loss = 0.04255494
Iteration 799, loss = 0.04249224
Iteration 800, loss = 0.04242836
Iteration 801, loss = 0.04236292
Iteration 802, loss = 0.04230032
Iteration 803, loss = 0.04223772
Iteration 804, loss = 0.04217533
Iteration 805, loss = 0.04211813
Iteration 806, loss = 0.04205419
Iteration 807, loss = 0.04199210
Iteration 808, loss = 0.04192953
Iteration 809, loss = 0.04186746
Iteration 810, loss = 0.04180764
Iteration 811, loss = 0.04175197
Iteration 812, loss = 0.04168238
Iteration 813, loss = 0.04161731
Iteration 814, loss = 0.04155507
Iteration 815, loss = 0.04149575
Iteration 816, loss = 0.04143136
Iteration 817, loss = 0.04136947
Iteration 818, loss = 0.04130886
Iteration 819, loss = 0.04124333
Iteration 820, loss = 0.04118696
Iteration 821, loss = 0.04111715
Iteration 822, loss = 0.04105839
Iteration 823, loss = 0.04100070
Iteration 824, loss = 0.04093453
Iteration 825, loss = 0.04087562
Iteration 826, loss = 0.04081648
Iteration 827, loss = 0.04076386
Iteration 828, loss = 0.04069880
Iteration 829, loss = 0.04064258
Iteration 830, loss = 0.04058377
Iteration 831, loss = 0.04052698
Iteration 832, loss = 0.04046905
Iteration 833, loss = 0.04041316
Iteration 834, loss = 0.04035936
Iteration 835, loss = 0.04029960
Iteration 836, loss = 0.04024528
Iteration 837, loss = 0.04018902
Iteration 838, loss = 0.04013149
Iteration 839, loss = 0.04007334
Iteration 840, loss = 0.04001919
Iteration 841, loss = 0.03995925
Iteration 842, loss = 0.03990250
Iteration 843, loss = 0.03984750
Iteration 844, loss = 0.03979076
Iteration 845, loss = 0.03973619
Iteration 846, loss = 0.03968230
Iteration 847, loss = 0.03962767
Iteration 848, loss = 0.03957451
Iteration 849, loss = 0.03952125
Iteration 850, loss = 0.03947070
Iteration 851, loss = 0.03941495
Iteration 852, loss = 0.03936007
Iteration 853, loss = 0.03930592
Iteration 854, loss = 0.03925277
Iteration 855, loss = 0.03919903
Iteration 856, loss = 0.03914399
Iteration 857, loss = 0.03909400
Iteration 858, loss = 0.03903981
Iteration 859, loss = 0.03898864
Iteration 860, loss = 0.03893564
Iteration 861, loss = 0.03888091
Iteration 862, loss = 0.03882719
Iteration 863, loss = 0.03877547
Iteration 864, loss = 0.03871802
Iteration 865, loss = 0.03866415
Iteration 866, loss = 0.03861289
Iteration 867, loss = 0.03856039
Iteration 868, loss = 0.03850848
Iteration 869, loss = 0.03845719
Iteration 870, loss = 0.03840770
Iteration 871, loss = 0.03835758
Iteration 872, loss = 0.03830838
Iteration 873, loss = 0.03825725
Iteration 874, loss = 0.03820796
Iteration 875, loss = 0.03815522
Iteration 876, loss = 0.03810432
Iteration 877, loss = 0.03805498
Iteration 878, loss = 0.03800002
Iteration 879, loss = 0.03795063
Iteration 880, loss = 0.03789778
Iteration 881, loss = 0.03785147
Iteration 882, loss = 0.03779704
Iteration 883, loss = 0.03774701
Iteration 884, loss = 0.03769607
Iteration 885, loss = 0.03764561
Iteration 886, loss = 0.03759531
Iteration 887, loss = 0.03754513
Iteration 888, loss = 0.03749634
Iteration 889, loss = 0.03744280
Iteration 890, loss = 0.03739662
Iteration 891, loss = 0.03734343
Iteration 892, loss = 0.03729159
Iteration 893, loss = 0.03724163
Iteration 894, loss = 0.03719306
Iteration 895, loss = 0.03713820
Iteration 896, loss = 0.03708806
Iteration 897, loss = 0.03703783
Iteration 898, loss = 0.03698677
Iteration 899, loss = 0.03693780
Iteration 900, loss = 0.03688609
Iteration 901, loss = 0.03683792
Iteration 902, loss = 0.03678953
Iteration 903, loss = 0.03674071
Iteration 904, loss = 0.03669352
Iteration 905, loss = 0.03664268
Iteration 906, loss = 0.03659479
Iteration 907, loss = 0.03654650
Iteration 908, loss = 0.03650078
Iteration 909, loss = 0.03645321
Iteration 910, loss = 0.03640500
Iteration 911, loss = 0.03635766
Iteration 912, loss = 0.03631344
Iteration 913, loss = 0.03626334
Iteration 914, loss = 0.03621593
Iteration 915, loss = 0.03617057
Iteration 916, loss = 0.03612162
Iteration 917, loss = 0.03608019
Iteration 918, loss = 0.03603143
Iteration 919, loss = 0.03598698
Iteration 920, loss = 0.03594075
Iteration 921, loss = 0.03589536
Iteration 922, loss = 0.03584978
Iteration 923, loss = 0.03580510
Iteration 924, loss = 0.03576028
Iteration 925, loss = 0.03571417
Iteration 926, loss = 0.03567034
Iteration 927, loss = 0.03562373
Iteration 928, loss = 0.03558035
Iteration 929, loss = 0.03553526
Iteration 930, loss = 0.03548748
Iteration 931, loss = 0.03544176
Iteration 932, loss = 0.03539861
Iteration 933, loss = 0.03535117
Iteration 934, loss = 0.03530864
Iteration 935, loss = 0.03526565
Iteration 936, loss = 0.03522169
Iteration 937, loss = 0.03518218
Iteration 938, loss = 0.03513856
Iteration 939, loss = 0.03509505
Iteration 940, loss = 0.03505390
Iteration 941, loss = 0.03501064
Iteration 942, loss = 0.03496870
Iteration 943, loss = 0.03492763
Iteration 944, loss = 0.03488745
Iteration 945, loss = 0.03484545
Iteration 946, loss = 0.03480401
Iteration 947, loss = 0.03476307
Iteration 948, loss = 0.03472457
Iteration 949, loss = 0.03468094
Iteration 950, loss = 0.03463919
Iteration 951, loss = 0.03459371
Iteration 952, loss = 0.03455231
Iteration 953, loss = 0.03451074
Iteration 954, loss = 0.03446681
Iteration 955, loss = 0.03442570
Iteration 956, loss = 0.03438878
Iteration 957, loss = 0.03434464
Iteration 958, loss = 0.03430181
Iteration 959, loss = 0.03426359
Iteration 960, loss = 0.03422053
Iteration 961, loss = 0.03417926
Iteration 962, loss = 0.03413828
Iteration 963, loss = 0.03409558
Iteration 964, loss = 0.03405394
Iteration 965, loss = 0.03401366
Iteration 966, loss = 0.03397499
Iteration 967, loss = 0.03393158
Iteration 968, loss = 0.03389232
Iteration 969, loss = 0.03385103
Iteration 970, loss = 0.03380831
Iteration 971, loss = 0.03377018
Iteration 972, loss = 0.03372989
Iteration 973, loss = 0.03368622
Iteration 974, loss = 0.03364691
Iteration 975, loss = 0.03360873
Iteration 976, loss = 0.03356947
Iteration 977, loss = 0.03352926
Iteration 978, loss = 0.03349013
Iteration 979, loss = 0.03345193
Iteration 980, loss = 0.03341484
Iteration 981, loss = 0.03337962
Iteration 982, loss = 0.03333720
Iteration 983, loss = 0.03329905
Iteration 984, loss = 0.03326011
Iteration 985, loss = 0.03322462
Iteration 986, loss = 0.03318424
Iteration 987, loss = 0.03314661
Iteration 988, loss = 0.03311000
Iteration 989, loss = 0.03307456
Iteration 990, loss = 0.03303668
Iteration 991, loss = 0.03300053
Iteration 992, loss = 0.03296346
Iteration 993, loss = 0.03292244
Iteration 994, loss = 0.03288682
Iteration 995, loss = 0.03284619
Iteration 996, loss = 0.03281045
Iteration 997, loss = 0.03277170
Iteration 998, loss = 0.03273444
Iteration 999, loss = 0.03269763
Iteration 1000, loss = 0.03266057
Iteration 1001, loss = 0.03262538
Iteration 1002, loss = 0.03258720
Iteration 1003, loss = 0.03255203
Iteration 1004, loss = 0.03251655
Iteration 1005, loss = 0.03248194
Iteration 1006, loss = 0.03244585
Iteration 1007, loss = 0.03241225
Iteration 1008, loss = 0.03237564
Iteration 1009, loss = 0.03233938
Iteration 1010, loss = 0.03230513
Iteration 1011, loss = 0.03227085
Iteration 1012, loss = 0.03223480
Iteration 1013, loss = 0.03219741
Iteration 1014, loss = 0.03215833
Iteration 1015, loss = 0.03212497
Iteration 1016, loss = 0.03209074
Iteration 1017, loss = 0.03205252
Iteration 1018, loss = 0.03201955
Iteration 1019, loss = 0.03198418
Iteration 1020, loss = 0.03194841
Iteration 1021, loss = 0.03191532
Iteration 1022, loss = 0.03188221
Iteration 1023, loss = 0.03184502
Iteration 1024, loss = 0.03181179
Iteration 1025, loss = 0.03177415
Iteration 1026, loss = 0.03173905
Iteration 1027, loss = 0.03170447
Iteration 1028, loss = 0.03166972
Iteration 1029, loss = 0.03163618
Iteration 1030, loss = 0.03160208
Iteration 1031, loss = 0.03156747
Iteration 1032, loss = 0.03153424
Iteration 1033, loss = 0.03150016
Iteration 1034, loss = 0.03146524
Iteration 1035, loss = 0.03142948
Iteration 1036, loss = 0.03139540
Iteration 1037, loss = 0.03135990
Iteration 1038, loss = 0.03132440
Iteration 1039, loss = 0.03128698
Iteration 1040, loss = 0.03125196
Iteration 1041, loss = 0.03122194
Iteration 1042, loss = 0.03118018
Iteration 1043, loss = 0.03114812
Iteration 1044, loss = 0.03111337
Iteration 1045, loss = 0.03107731
Iteration 1046, loss = 0.03104581
Iteration 1047, loss = 0.03101128
Iteration 1048, loss = 0.03097881
Iteration 1049, loss = 0.03094587
Iteration 1050, loss = 0.03091155
Iteration 1051, loss = 0.03087908
Iteration 1052, loss = 0.03084684
Iteration 1053, loss = 0.03081490
Iteration 1054, loss = 0.03078349
Iteration 1055, loss = 0.03075115
Iteration 1056, loss = 0.03071810
Iteration 1057, loss = 0.03068771
Iteration 1058, loss = 0.03065570
Iteration 1059, loss = 0.03062321
Iteration 1060, loss = 0.03059285
Iteration 1061, loss = 0.03055713
Iteration 1062, loss = 0.03052332
Iteration 1063, loss = 0.03048979
Iteration 1064, loss = 0.03045751
Iteration 1065, loss = 0.03042902
Iteration 1066, loss = 0.03039103
Iteration 1067, loss = 0.03035664
Iteration 1068, loss = 0.03032810
Iteration 1069, loss = 0.03029399
Iteration 1070, loss = 0.03026226
Iteration 1071, loss = 0.03023278
Iteration 1072, loss = 0.03020093
Iteration 1073, loss = 0.03017084
Iteration 1074, loss = 0.03014072
Iteration 1075, loss = 0.03010796
Iteration 1076, loss = 0.03007754
Iteration 1077, loss = 0.03004695
Iteration 1078, loss = 0.03001601
Iteration 1079, loss = 0.02998546
Iteration 1080, loss = 0.02995117
Iteration 1081, loss = 0.02991992
Iteration 1082, loss = 0.02989060
Iteration 1083, loss = 0.02985546
Iteration 1084, loss = 0.02982506
Iteration 1085, loss = 0.02979502
Iteration 1086, loss = 0.02976279
Iteration 1087, loss = 0.02973581
Iteration 1088, loss = 0.02970733
Iteration 1089, loss = 0.02967638
Iteration 1090, loss = 0.02964642
Iteration 1091, loss = 0.02961963
Iteration 1092, loss = 0.02958990
Iteration 1093, loss = 0.02956134
Iteration 1094, loss = 0.02953376
Iteration 1095, loss = 0.02950257
Iteration 1096, loss = 0.02947391
Iteration 1097, loss = 0.02944530
Iteration 1098, loss = 0.02941561
Iteration 1099, loss = 0.02938706
Iteration 1100, loss = 0.02935843
Iteration 1101, loss = 0.02932847
Iteration 1102, loss = 0.02929904
Iteration 1103, loss = 0.02927141
Iteration 1104, loss = 0.02923976
Iteration 1105, loss = 0.02921072
Iteration 1106, loss = 0.02918098
Iteration 1107, loss = 0.02915156
Iteration 1108, loss = 0.02912443
Iteration 1109, loss = 0.02909474
Iteration 1110, loss = 0.02906705
Iteration 1111, loss = 0.02903816
Iteration 1112, loss = 0.02901077
Iteration 1113, loss = 0.02898231
Iteration 1114, loss = 0.02895254
Iteration 1115, loss = 0.02892740
Iteration 1116, loss = 0.02889933
Iteration 1117, loss = 0.02887151
Iteration 1118, loss = 0.02884260
Iteration 1119, loss = 0.02881466
Iteration 1120, loss = 0.02878748
Iteration 1121, loss = 0.02875903
Iteration 1122, loss = 0.02873248
Iteration 1123, loss = 0.02870624
Iteration 1124, loss = 0.02867961
Iteration 1125, loss = 0.02865026
Iteration 1126, loss = 0.02862274
Iteration 1127, loss = 0.02859545
Iteration 1128, loss = 0.02856690
Iteration 1129, loss = 0.02853882
Iteration 1130, loss = 0.02850988
Iteration 1131, loss = 0.02848117
Iteration 1132, loss = 0.02845292
Iteration 1133, loss = 0.02842318
Iteration 1134, loss = 0.02839694
Iteration 1135, loss = 0.02836911
Iteration 1136, loss = 0.02834056
Iteration 1137, loss = 0.02831350
Iteration 1138, loss = 0.02828709
Iteration 1139, loss = 0.02826015
Iteration 1140, loss = 0.02823388
Iteration 1141, loss = 0.02820624
Iteration 1142, loss = 0.02818026
Iteration 1143, loss = 0.02815193
Iteration 1144, loss = 0.02812588
Iteration 1145, loss = 0.02810096
Iteration 1146, loss = 0.02807629
Iteration 1147, loss = 0.02805187
Iteration 1148, loss = 0.02802650
Iteration 1149, loss = 0.02800196
Iteration 1150, loss = 0.02797697
Iteration 1151, loss = 0.02795334
Iteration 1152, loss = 0.02792963
Iteration 1153, loss = 0.02790559
Iteration 1154, loss = 0.02788299
Iteration 1155, loss = 0.02785850
Iteration 1156, loss = 0.02783413
Iteration 1157, loss = 0.02781019
Iteration 1158, loss = 0.02778496
Iteration 1159, loss = 0.02776131
Iteration 1160, loss = 0.02773685
Iteration 1161, loss = 0.02771252
Iteration 1162, loss = 0.02768675
Iteration 1163, loss = 0.02766221
Iteration 1164, loss = 0.02763658
Iteration 1165, loss = 0.02761081
Iteration 1166, loss = 0.02758595
Iteration 1167, loss = 0.02756125
Iteration 1168, loss = 0.02753465
Iteration 1169, loss = 0.02751078
Iteration 1170, loss = 0.02748773
Iteration 1171, loss = 0.02746158
Iteration 1172, loss = 0.02743245
Iteration 1173, loss = 0.02740114
Iteration 1174, loss = 0.02737421
Iteration 1175, loss = 0.02734989
Iteration 1176, loss = 0.02732131
Iteration 1177, loss = 0.02729358
Iteration 1178, loss = 0.02726757
Iteration 1179, loss = 0.02724194
Iteration 1180, loss = 0.02721598
Iteration 1181, loss = 0.02718725
Iteration 1182, loss = 0.02716169
Iteration 1183, loss = 0.02713540
Iteration 1184, loss = 0.02711032
Iteration 1185, loss = 0.02708567
Iteration 1186, loss = 0.02706100
Iteration 1187, loss = 0.02703358
Iteration 1188, loss = 0.02700937
Iteration 1189, loss = 0.02698536
Iteration 1190, loss = 0.02696177
Iteration 1191, loss = 0.02693789
Iteration 1192, loss = 0.02691210
Iteration 1193, loss = 0.02688741
Iteration 1194, loss = 0.02686188
Iteration 1195, loss = 0.02683994
Iteration 1196, loss = 0.02681122
Iteration 1197, loss = 0.02678910
Iteration 1198, loss = 0.02676276
Iteration 1199, loss = 0.02673920
Iteration 1200, loss = 0.02671422
Iteration 1201, loss = 0.02668929
Iteration 1202, loss = 0.02666464
Iteration 1203, loss = 0.02664142
Iteration 1204, loss = 0.02661318
Iteration 1205, loss = 0.02658984
Iteration 1206, loss = 0.02656283
Iteration 1207, loss = 0.02653561
Iteration 1208, loss = 0.02651235
Iteration 1209, loss = 0.02648592
Iteration 1210, loss = 0.02645999
Iteration 1211, loss = 0.02643292
Iteration 1212, loss = 0.02641219
Iteration 1213, loss = 0.02638382
Iteration 1214, loss = 0.02636084
Iteration 1215, loss = 0.02633517
Iteration 1216, loss = 0.02631464
Iteration 1217, loss = 0.02628555
Iteration 1218, loss = 0.02626186
Iteration 1219, loss = 0.02623963
Iteration 1220, loss = 0.02621220
Iteration 1221, loss = 0.02618894
Iteration 1222, loss = 0.02616512
Iteration 1223, loss = 0.02614267
Iteration 1224, loss = 0.02611847
Iteration 1225, loss = 0.02609296
Iteration 1226, loss = 0.02607243
Iteration 1227, loss = 0.02604847
Iteration 1228, loss = 0.02602385
Iteration 1229, loss = 0.02600204
Iteration 1230, loss = 0.02597913
Iteration 1231, loss = 0.02595598
Iteration 1232, loss = 0.02593307
Iteration 1233, loss = 0.02590991
Iteration 1234, loss = 0.02588823
Iteration 1235, loss = 0.02586527
Iteration 1236, loss = 0.02584288
Iteration 1237, loss = 0.02582097
Iteration 1238, loss = 0.02580007
Iteration 1239, loss = 0.02577263
Iteration 1240, loss = 0.02574980
Iteration 1241, loss = 0.02572656
Iteration 1242, loss = 0.02570274
Iteration 1243, loss = 0.02567970
Iteration 1244, loss = 0.02565643
Iteration 1245, loss = 0.02563315
Iteration 1246, loss = 0.02561039
Iteration 1247, loss = 0.02558854
Iteration 1248, loss = 0.02556901
Iteration 1249, loss = 0.02554271
Iteration 1250, loss = 0.02552007
Iteration 1251, loss = 0.02549659
Iteration 1252, loss = 0.02547360
Iteration 1253, loss = 0.02545038
Iteration 1254, loss = 0.02543072
Iteration 1255, loss = 0.02540581
Iteration 1256, loss = 0.02538349
Iteration 1257, loss = 0.02535956
Iteration 1258, loss = 0.02533671
Iteration 1259, loss = 0.02531649
Iteration 1260, loss = 0.02529310
Iteration 1261, loss = 0.02527027
Iteration 1262, loss = 0.02524932
Iteration 1263, loss = 0.02522702
Iteration 1264, loss = 0.02520555
Iteration 1265, loss = 0.02518449
Iteration 1266, loss = 0.02516316
Iteration 1267, loss = 0.02514140
Iteration 1268, loss = 0.02511820
Iteration 1269, loss = 0.02509661
Iteration 1270, loss = 0.02507611
Iteration 1271, loss = 0.02505419
Iteration 1272, loss = 0.02503281
Iteration 1273, loss = 0.02501237
Iteration 1274, loss = 0.02499173
Iteration 1275, loss = 0.02497156
Iteration 1276, loss = 0.02495035
Iteration 1277, loss = 0.02492939
Iteration 1278, loss = 0.02491107
Iteration 1279, loss = 0.02488822
Iteration 1280, loss = 0.02486773
Iteration 1281, loss = 0.02484811
Iteration 1282, loss = 0.02482727
Iteration 1283, loss = 0.02480950
Iteration 1284, loss = 0.02478735
Iteration 1285, loss = 0.02476791
Iteration 1286, loss = 0.02474960
Iteration 1287, loss = 0.02472889
Iteration 1288, loss = 0.02471084
Iteration 1289, loss = 0.02468975
Iteration 1290, loss = 0.02466962
Iteration 1291, loss = 0.02464970
Iteration 1292, loss = 0.02462886
Iteration 1293, loss = 0.02460829
Iteration 1294, loss = 0.02458843
Iteration 1295, loss = 0.02456451
Iteration 1296, loss = 0.02454639
Iteration 1297, loss = 0.02452171
Iteration 1298, loss = 0.02449968
Iteration 1299, loss = 0.02447772
Iteration 1300, loss = 0.02445819
Iteration 1301, loss = 0.02443387
Iteration 1302, loss = 0.02441375
Iteration 1303, loss = 0.02439247
Iteration 1304, loss = 0.02437131
Iteration 1305, loss = 0.02434942
Iteration 1306, loss = 0.02433053
Iteration 1307, loss = 0.02430761
Iteration 1308, loss = 0.02428651
Iteration 1309, loss = 0.02426485
Iteration 1310, loss = 0.02424530
Iteration 1311, loss = 0.02422397
Iteration 1312, loss = 0.02420295
Iteration 1313, loss = 0.02418411
Iteration 1314, loss = 0.02416217
Iteration 1315, loss = 0.02414241
Iteration 1316, loss = 0.02412483
Iteration 1317, loss = 0.02410337
Iteration 1318, loss = 0.02408302
Iteration 1319, loss = 0.02406366
Iteration 1320, loss = 0.02404209
Iteration 1321, loss = 0.02402185
Iteration 1322, loss = 0.02400165
Iteration 1323, loss = 0.02398224
Iteration 1324, loss = 0.02396251
Iteration 1325, loss = 0.02394462
Iteration 1326, loss = 0.02392322
Iteration 1327, loss = 0.02390350
Iteration 1328, loss = 0.02388517
Iteration 1329, loss = 0.02386340
Iteration 1330, loss = 0.02384482
Iteration 1331, loss = 0.02382416
Iteration 1332, loss = 0.02380280
Iteration 1333, loss = 0.02378191
Iteration 1334, loss = 0.02376389
Iteration 1335, loss = 0.02374117
Iteration 1336, loss = 0.02372103
Iteration 1337, loss = 0.02370055
Iteration 1338, loss = 0.02368021
Iteration 1339, loss = 0.02366102
Iteration 1340, loss = 0.02364114
Iteration 1341, loss = 0.02362073
Iteration 1342, loss = 0.02360056
Iteration 1343, loss = 0.02358020
Iteration 1344, loss = 0.02356297
Iteration 1345, loss = 0.02354183
Iteration 1346, loss = 0.02352277
Iteration 1347, loss = 0.02350488
Iteration 1348, loss = 0.02348700
Iteration 1349, loss = 0.02346776
Iteration 1350, loss = 0.02344940
Iteration 1351, loss = 0.02343155
Iteration 1352, loss = 0.02341463
Iteration 1353, loss = 0.02339462
Iteration 1354, loss = 0.02337675
Iteration 1355, loss = 0.02335861
Iteration 1356, loss = 0.02334111
Iteration 1357, loss = 0.02332311
Iteration 1358, loss = 0.02330622
Iteration 1359, loss = 0.02328974
Iteration 1360, loss = 0.02327345
Iteration 1361, loss = 0.02325434
Iteration 1362, loss = 0.02323586
Iteration 1363, loss = 0.02321781
Iteration 1364, loss = 0.02319989
Iteration 1365, loss = 0.02318144
Iteration 1366, loss = 0.02316337
Iteration 1367, loss = 0.02314534
Iteration 1368, loss = 0.02312752
Iteration 1369, loss = 0.02311184
Iteration 1370, loss = 0.02309124
Iteration 1371, loss = 0.02307328
Iteration 1372, loss = 0.02305516
Iteration 1373, loss = 0.02303672
Iteration 1374, loss = 0.02301869
Iteration 1375, loss = 0.02300033
Iteration 1376, loss = 0.02298299
Iteration 1377, loss = 0.02296767
Iteration 1378, loss = 0.02294863
Iteration 1379, loss = 0.02292941
Iteration 1380, loss = 0.02291150
Iteration 1381, loss = 0.02289142
Iteration 1382, loss = 0.02287186
Iteration 1383, loss = 0.02285219
Iteration 1384, loss = 0.02283117
Iteration 1385, loss = 0.02281149
Iteration 1386, loss = 0.02279034
Iteration 1387, loss = 0.02277240
Iteration 1388, loss = 0.02275308
Iteration 1389, loss = 0.02273120
Iteration 1390, loss = 0.02271394
Iteration 1391, loss = 0.02269371
Iteration 1392, loss = 0.02267440
Iteration 1393, loss = 0.02265359
Iteration 1394, loss = 0.02263729
Iteration 1395, loss = 0.02261803
Iteration 1396, loss = 0.02260023
Iteration 1397, loss = 0.02258673
Iteration 1398, loss = 0.02256599
Iteration 1399, loss = 0.02254829
Iteration 1400, loss = 0.02253171
Iteration 1401, loss = 0.02251624
Iteration 1402, loss = 0.02249896
Iteration 1403, loss = 0.02248094
Iteration 1404, loss = 0.02246463
Iteration 1405, loss = 0.02244790
Iteration 1406, loss = 0.02243083
Iteration 1407, loss = 0.02241535
Iteration 1408, loss = 0.02239910
Iteration 1409, loss = 0.02238206
Iteration 1410, loss = 0.02236554
Iteration 1411, loss = 0.02234947
Iteration 1412, loss = 0.02233388
Iteration 1413, loss = 0.02231894
Iteration 1414, loss = 0.02230234
Iteration 1415, loss = 0.02228576
Iteration 1416, loss = 0.02227124
Iteration 1417, loss = 0.02225428
Iteration 1418, loss = 0.02223898
Iteration 1419, loss = 0.02222086
Iteration 1420, loss = 0.02220521
Iteration 1421, loss = 0.02218703
Iteration 1422, loss = 0.02216991
Iteration 1423, loss = 0.02215579
Iteration 1424, loss = 0.02213573
Iteration 1425, loss = 0.02211972
Iteration 1426, loss = 0.02210378
Iteration 1427, loss = 0.02208706
Iteration 1428, loss = 0.02207154
Iteration 1429, loss = 0.02205384
Iteration 1430, loss = 0.02203524
Iteration 1431, loss = 0.02201945
Iteration 1432, loss = 0.02200063
Iteration 1433, loss = 0.02198356
Iteration 1434, loss = 0.02196548
Iteration 1435, loss = 0.02195210
Iteration 1436, loss = 0.02193192
Iteration 1437, loss = 0.02191432
Iteration 1438, loss = 0.02189894
Iteration 1439, loss = 0.02188188
Iteration 1440, loss = 0.02186756
Iteration 1441, loss = 0.02184679
Iteration 1442, loss = 0.02182877
Iteration 1443, loss = 0.02181167
Iteration 1444, loss = 0.02179827
Iteration 1445, loss = 0.02177856
Iteration 1446, loss = 0.02176285
Iteration 1447, loss = 0.02174375
Iteration 1448, loss = 0.02172814
Iteration 1449, loss = 0.02171217
Iteration 1450, loss = 0.02169456
Iteration 1451, loss = 0.02167864
Iteration 1452, loss = 0.02166143
Iteration 1453, loss = 0.02164591
Iteration 1454, loss = 0.02162908
Iteration 1455, loss = 0.02161321
Iteration 1456, loss = 0.02159646
Iteration 1457, loss = 0.02157983
Iteration 1458, loss = 0.02156508
Iteration 1459, loss = 0.02154812
Iteration 1460, loss = 0.02152963
Iteration 1461, loss = 0.02151493
Iteration 1462, loss = 0.02149660
Iteration 1463, loss = 0.02147932
Iteration 1464, loss = 0.02146357
Iteration 1465, loss = 0.02144723
Iteration 1466, loss = 0.02143025
Iteration 1467, loss = 0.02141412
Iteration 1468, loss = 0.02139831
Iteration 1469, loss = 0.02138256
Iteration 1470, loss = 0.02136725
Iteration 1471, loss = 0.02135079
Iteration 1472, loss = 0.02133277
Iteration 1473, loss = 0.02131721
Iteration 1474, loss = 0.02130075
Iteration 1475, loss = 0.02128533
Iteration 1476, loss = 0.02126912
Iteration 1477, loss = 0.02125290
Iteration 1478, loss = 0.02123729
Iteration 1479, loss = 0.02122021
Iteration 1480, loss = 0.02120504
Iteration 1481, loss = 0.02119031
Iteration 1482, loss = 0.02117582
Iteration 1483, loss = 0.02115875
Iteration 1484, loss = 0.02114100
Iteration 1485, loss = 0.02112506
Iteration 1486, loss = 0.02110800
Iteration 1487, loss = 0.02109340
Iteration 1488, loss = 0.02107699
Iteration 1489, loss = 0.02106164
Iteration 1490, loss = 0.02104503
Iteration 1491, loss = 0.02102828
Iteration 1492, loss = 0.02101290
Iteration 1493, loss = 0.02099735
Iteration 1494, loss = 0.02098152
Iteration 1495, loss = 0.02096672
Iteration 1496, loss = 0.02095056
Iteration 1497, loss = 0.02093585
Iteration 1498, loss = 0.02091991
Iteration 1499, loss = 0.02090411
Iteration 1500, loss = 0.02088634
Iteration 1501, loss = 0.02087080
Iteration 1502, loss = 0.02085435
Iteration 1503, loss = 0.02084048
Iteration 1504, loss = 0.02082391
Iteration 1505, loss = 0.02081005
Iteration 1506, loss = 0.02079527
Iteration 1507, loss = 0.02078013
Iteration 1508, loss = 0.02076492
Iteration 1509, loss = 0.02074970
Iteration 1510, loss = 0.02073380
Iteration 1511, loss = 0.02071979
Iteration 1512, loss = 0.02070420
Iteration 1513, loss = 0.02069023
Iteration 1514, loss = 0.02067536
Iteration 1515, loss = 0.02066090
Iteration 1516, loss = 0.02064676
Iteration 1517, loss = 0.02063305
Iteration 1518, loss = 0.02061888
Iteration 1519, loss = 0.02060461
Iteration 1520, loss = 0.02059105
Iteration 1521, loss = 0.02057767
Iteration 1522, loss = 0.02056364
Iteration 1523, loss = 0.02054842
Iteration 1524, loss = 0.02053433
Iteration 1525, loss = 0.02051937
Iteration 1526, loss = 0.02050490
Iteration 1527, loss = 0.02048976
Iteration 1528, loss = 0.02047508
Iteration 1529, loss = 0.02045966
Iteration 1530, loss = 0.02044726
Iteration 1531, loss = 0.02043171
Iteration 1532, loss = 0.02041590
Iteration 1533, loss = 0.02040435
Iteration 1534, loss = 0.02038727
Iteration 1535, loss = 0.02037264
Iteration 1536, loss = 0.02035862
Iteration 1537, loss = 0.02034416
Iteration 1538, loss = 0.02033117
Iteration 1539, loss = 0.02031680
Iteration 1540, loss = 0.02030101
Iteration 1541, loss = 0.02028881
Iteration 1542, loss = 0.02027350
Iteration 1543, loss = 0.02025936
Iteration 1544, loss = 0.02024602
Iteration 1545, loss = 0.02023183
Iteration 1546, loss = 0.02021802
Iteration 1547, loss = 0.02020673
Iteration 1548, loss = 0.02019092
Iteration 1549, loss = 0.02017684
Iteration 1550, loss = 0.02016265
Iteration 1551, loss = 0.02014945
Iteration 1552, loss = 0.02013493
Iteration 1553, loss = 0.02012226
Iteration 1554, loss = 0.02010593
Iteration 1555, loss = 0.02009321
Iteration 1556, loss = 0.02008038
Iteration 1557, loss = 0.02006461
Iteration 1558, loss = 0.02004877
Iteration 1559, loss = 0.02003374
Iteration 1560, loss = 0.02001931
Iteration 1561, loss = 0.02000550
Iteration 1562, loss = 0.01998934
Iteration 1563, loss = 0.01997536
Iteration 1564, loss = 0.01996023
Iteration 1565, loss = 0.01994603
Iteration 1566, loss = 0.01993113
Iteration 1567, loss = 0.01991716
Iteration 1568, loss = 0.01990345
Iteration 1569, loss = 0.01988976
Iteration 1570, loss = 0.01987617
Iteration 1571, loss = 0.01986260
Iteration 1572, loss = 0.01984866
Iteration 1573, loss = 0.01983542
Iteration 1574, loss = 0.01982058
Iteration 1575, loss = 0.01980717
Iteration 1576, loss = 0.01979475
Iteration 1577, loss = 0.01977963
Iteration 1578, loss = 0.01976444
Iteration 1579, loss = 0.01974949
Iteration 1580, loss = 0.01973544
Iteration 1581, loss = 0.01972203
Iteration 1582, loss = 0.01970880
Iteration 1583, loss = 0.01969453
Iteration 1584, loss = 0.01968037
Iteration 1585, loss = 0.01966871
Iteration 1586, loss = 0.01965464
Iteration 1587, loss = 0.01964243
Iteration 1588, loss = 0.01962773
Iteration 1589, loss = 0.01961427
Iteration 1590, loss = 0.01960192
Iteration 1591, loss = 0.01958757
Iteration 1592, loss = 0.01957244
Iteration 1593, loss = 0.01955943
Iteration 1594, loss = 0.01954566
Iteration 1595, loss = 0.01953183
Iteration 1596, loss = 0.01951864
Iteration 1597, loss = 0.01950402
Iteration 1598, loss = 0.01948980
Iteration 1599, loss = 0.01947588
Iteration 1600, loss = 0.01946326
Iteration 1601, loss = 0.01944801
Iteration 1602, loss = 0.01943359
Iteration 1603, loss = 0.01942023
Iteration 1604, loss = 0.01940537
Iteration 1605, loss = 0.01939168
Iteration 1606, loss = 0.01937803
Iteration 1607, loss = 0.01936377
Iteration 1608, loss = 0.01935008
Iteration 1609, loss = 0.01933636
Iteration 1610, loss = 0.01932272
Iteration 1611, loss = 0.01930964
Iteration 1612, loss = 0.01929458
Iteration 1613, loss = 0.01928133
Iteration 1614, loss = 0.01927009
Iteration 1615, loss = 0.01925641
Iteration 1616, loss = 0.01924354
Iteration 1617, loss = 0.01923086
Iteration 1618, loss = 0.01921864
Iteration 1619, loss = 0.01920381
Iteration 1620, loss = 0.01919023
Iteration 1621, loss = 0.01917748
Iteration 1622, loss = 0.01916448
Iteration 1623, loss = 0.01915154
Iteration 1624, loss = 0.01913641
Iteration 1625, loss = 0.01912347
Iteration 1626, loss = 0.01911194
Iteration 1627, loss = 0.01909669
Iteration 1628, loss = 0.01908469
Iteration 1629, loss = 0.01907035
Iteration 1630, loss = 0.01905702
Iteration 1631, loss = 0.01904646
Iteration 1632, loss = 0.01903120
Iteration 1633, loss = 0.01901682
Iteration 1634, loss = 0.01900513
Iteration 1635, loss = 0.01899149
Iteration 1636, loss = 0.01897804
Iteration 1637, loss = 0.01896547
Iteration 1638, loss = 0.01895126
Iteration 1639, loss = 0.01893849
Iteration 1640, loss = 0.01892603
Iteration 1641, loss = 0.01891281
Iteration 1642, loss = 0.01890080
Iteration 1643, loss = 0.01888750
Iteration 1644, loss = 0.01887516
Iteration 1645, loss = 0.01886227
Iteration 1646, loss = 0.01885011
Iteration 1647, loss = 0.01883733
Iteration 1648, loss = 0.01882612
Iteration 1649, loss = 0.01881339
Iteration 1650, loss = 0.01880185
Iteration 1651, loss = 0.01878962
Iteration 1652, loss = 0.01877827
Iteration 1653, loss = 0.01876639
Iteration 1654, loss = 0.01875457
Iteration 1655, loss = 0.01874720
Iteration 1656, loss = 0.01873331
Iteration 1657, loss = 0.01871949
Iteration 1658, loss = 0.01870759
Iteration 1659, loss = 0.01869546
Iteration 1660, loss = 0.01868311
Iteration 1661, loss = 0.01867277
Iteration 1662, loss = 0.01865894
Iteration 1663, loss = 0.01864633
Iteration 1664, loss = 0.01863441
Iteration 1665, loss = 0.01862261
Iteration 1666, loss = 0.01861086
Iteration 1667, loss = 0.01860034
Iteration 1668, loss = 0.01858892
Iteration 1669, loss = 0.01857869
Iteration 1670, loss = 0.01856586
Iteration 1671, loss = 0.01855447
Iteration 1672, loss = 0.01854301
Iteration 1673, loss = 0.01853164
Iteration 1674, loss = 0.01851964
Iteration 1675, loss = 0.01850824
Iteration 1676, loss = 0.01850020
Iteration 1677, loss = 0.01848624
Iteration 1678, loss = 0.01847361
Iteration 1679, loss = 0.01846426
Iteration 1680, loss = 0.01845022
Iteration 1681, loss = 0.01843802
Iteration 1682, loss = 0.01842479
Iteration 1683, loss = 0.01841249
Iteration 1684, loss = 0.01840060
Iteration 1685, loss = 0.01838745
Iteration 1686, loss = 0.01837538
Iteration 1687, loss = 0.01836330
Iteration 1688, loss = 0.01835188
Iteration 1689, loss = 0.01833985
Iteration 1690, loss = 0.01832803
Iteration 1691, loss = 0.01831665
Iteration 1692, loss = 0.01830531
Iteration 1693, loss = 0.01829320
Iteration 1694, loss = 0.01828223
Iteration 1695, loss = 0.01827117
Iteration 1696, loss = 0.01826115
Iteration 1697, loss = 0.01824869
Iteration 1698, loss = 0.01823801
Iteration 1699, loss = 0.01822464
Iteration 1700, loss = 0.01821103
Iteration 1701, loss = 0.01820141
Iteration 1702, loss = 0.01818788
Iteration 1703, loss = 0.01817395
Iteration 1704, loss = 0.01816380
Iteration 1705, loss = 0.01815091
Iteration 1706, loss = 0.01814015
Iteration 1707, loss = 0.01812803
Iteration 1708, loss = 0.01811563
Iteration 1709, loss = 0.01810329
Iteration 1710, loss = 0.01809212
Iteration 1711, loss = 0.01807987
Iteration 1712, loss = 0.01806932
Iteration 1713, loss = 0.01805600
Iteration 1714, loss = 0.01804510
Iteration 1715, loss = 0.01803438
Iteration 1716, loss = 0.01802186
Iteration 1717, loss = 0.01801062
Iteration 1718, loss = 0.01799970
Iteration 1719, loss = 0.01798705
Iteration 1720, loss = 0.01797637
Iteration 1721, loss = 0.01796365
Iteration 1722, loss = 0.01795379
Iteration 1723, loss = 0.01794310
Iteration 1724, loss = 0.01793097
Iteration 1725, loss = 0.01791824
Iteration 1726, loss = 0.01790652
Iteration 1727, loss = 0.01789581
Iteration 1728, loss = 0.01788587
Iteration 1729, loss = 0.01787386
Iteration 1730, loss = 0.01786219
Iteration 1731, loss = 0.01785081
Iteration 1732, loss = 0.01783985
Iteration 1733, loss = 0.01782928
Iteration 1734, loss = 0.01782051
Iteration 1735, loss = 0.01780613
Iteration 1736, loss = 0.01779412
Iteration 1737, loss = 0.01778266
Iteration 1738, loss = 0.01777067
Iteration 1739, loss = 0.01775978
Iteration 1740, loss = 0.01774699
Iteration 1741, loss = 0.01773640
Iteration 1742, loss = 0.01772110
Iteration 1743, loss = 0.01770899
Iteration 1744, loss = 0.01769891
Iteration 1745, loss = 0.01768763
Iteration 1746, loss = 0.01767561
Iteration 1747, loss = 0.01766786
Iteration 1748, loss = 0.01765478
Iteration 1749, loss = 0.01764438
Iteration 1750, loss = 0.01763401
Iteration 1751, loss = 0.01762296
Iteration 1752, loss = 0.01761309
Iteration 1753, loss = 0.01760022
Iteration 1754, loss = 0.01758833
Iteration 1755, loss = 0.01757860
Iteration 1756, loss = 0.01756659
Iteration 1757, loss = 0.01755515
Iteration 1758, loss = 0.01754170
Iteration 1759, loss = 0.01753051
Iteration 1760, loss = 0.01751700
Iteration 1761, loss = 0.01750660
Iteration 1762, loss = 0.01749517
Iteration 1763, loss = 0.01748262
Iteration 1764, loss = 0.01747229
Iteration 1765, loss = 0.01746091
Iteration 1766, loss = 0.01745176
Iteration 1767, loss = 0.01743677
Iteration 1768, loss = 0.01742540
Iteration 1769, loss = 0.01741505
Iteration 1770, loss = 0.01740295
Iteration 1771, loss = 0.01739162
Iteration 1772, loss = 0.01738129
Iteration 1773, loss = 0.01736989
Iteration 1774, loss = 0.01736001
Iteration 1775, loss = 0.01734786
Iteration 1776, loss = 0.01733714
Iteration 1777, loss = 0.01732609
Iteration 1778, loss = 0.01731527
Iteration 1779, loss = 0.01730411
Iteration 1780, loss = 0.01729198
Iteration 1781, loss = 0.01727999
Iteration 1782, loss = 0.01726878
Iteration 1783, loss = 0.01725665
Iteration 1784, loss = 0.01724870
Iteration 1785, loss = 0.01723581
Iteration 1786, loss = 0.01722393
Iteration 1787, loss = 0.01721287
Iteration 1788, loss = 0.01720029
Iteration 1789, loss = 0.01719149
Iteration 1790, loss = 0.01717976
Iteration 1791, loss = 0.01717371
Iteration 1792, loss = 0.01715964
Iteration 1793, loss = 0.01715296
Iteration 1794, loss = 0.01714124
Iteration 1795, loss = 0.01712896
Iteration 1796, loss = 0.01712040
Iteration 1797, loss = 0.01710919
Iteration 1798, loss = 0.01709853
Iteration 1799, loss = 0.01708761
Iteration 1800, loss = 0.01707526
Iteration 1801, loss = 0.01706416
Iteration 1802, loss = 0.01705309
Iteration 1803, loss = 0.01704321
Iteration 1804, loss = 0.01703168
Iteration 1805, loss = 0.01702182
Iteration 1806, loss = 0.01701022
Iteration 1807, loss = 0.01699955
Iteration 1808, loss = 0.01698973
Iteration 1809, loss = 0.01698032
Iteration 1810, loss = 0.01696865
Iteration 1811, loss = 0.01695942
Iteration 1812, loss = 0.01694922
Iteration 1813, loss = 0.01693680
Iteration 1814, loss = 0.01692598
Iteration 1815, loss = 0.01691636
Iteration 1816, loss = 0.01690542
Iteration 1817, loss = 0.01689455
Iteration 1818, loss = 0.01688386
Iteration 1819, loss = 0.01687500
Iteration 1820, loss = 0.01686327
Iteration 1821, loss = 0.01685295
Iteration 1822, loss = 0.01684382
Iteration 1823, loss = 0.01683310
Iteration 1824, loss = 0.01682294
Iteration 1825, loss = 0.01681276
Iteration 1826, loss = 0.01680309
Iteration 1827, loss = 0.01679157
Iteration 1828, loss = 0.01678100
Iteration 1829, loss = 0.01677070
Iteration 1830, loss = 0.01676054
Iteration 1831, loss = 0.01675028
Iteration 1832, loss = 0.01674171
Iteration 1833, loss = 0.01673171
Iteration 1834, loss = 0.01672060
Iteration 1835, loss = 0.01671068
Iteration 1836, loss = 0.01670065
Iteration 1837, loss = 0.01669112
Iteration 1838, loss = 0.01668170
Iteration 1839, loss = 0.01667250
Iteration 1840, loss = 0.01666255
Iteration 1841, loss = 0.01665229
Iteration 1842, loss = 0.01664232
Iteration 1843, loss = 0.01663345
Iteration 1844, loss = 0.01662294
Iteration 1845, loss = 0.01661315
Iteration 1846, loss = 0.01660208
Iteration 1847, loss = 0.01659240
Iteration 1848, loss = 0.01658297
Iteration 1849, loss = 0.01657178
Iteration 1850, loss = 0.01656198
Iteration 1851, loss = 0.01655260
Iteration 1852, loss = 0.01654117
Iteration 1853, loss = 0.01653101
Iteration 1854, loss = 0.01652136
Iteration 1855, loss = 0.01651275
Iteration 1856, loss = 0.01650101
Iteration 1857, loss = 0.01649126
Iteration 1858, loss = 0.01648054
Iteration 1859, loss = 0.01646981
Iteration 1860, loss = 0.01645981
Iteration 1861, loss = 0.01644951
Iteration 1862, loss = 0.01643962
Iteration 1863, loss = 0.01642980
Iteration 1864, loss = 0.01641987
Iteration 1865, loss = 0.01640960
Iteration 1866, loss = 0.01640064
Iteration 1867, loss = 0.01639022
Iteration 1868, loss = 0.01637982
Iteration 1869, loss = 0.01636905
Iteration 1870, loss = 0.01635997
Iteration 1871, loss = 0.01635053
Iteration 1872, loss = 0.01634088
Iteration 1873, loss = 0.01633078
Iteration 1874, loss = 0.01632137
Iteration 1875, loss = 0.01631216
Iteration 1876, loss = 0.01630245
Iteration 1877, loss = 0.01629343
Iteration 1878, loss = 0.01628491
Iteration 1879, loss = 0.01627496
Iteration 1880, loss = 0.01626518
Iteration 1881, loss = 0.01625583
Iteration 1882, loss = 0.01624684
Iteration 1883, loss = 0.01623724
Iteration 1884, loss = 0.01622803
Iteration 1885, loss = 0.01621950
Iteration 1886, loss = 0.01620854
Iteration 1887, loss = 0.01620018
Iteration 1888, loss = 0.01618991
Iteration 1889, loss = 0.01618111
Iteration 1890, loss = 0.01617220
Iteration 1891, loss = 0.01616388
Iteration 1892, loss = 0.01615351
Iteration 1893, loss = 0.01614339
Iteration 1894, loss = 0.01613624
Iteration 1895, loss = 0.01612796
Iteration 1896, loss = 0.01611965
Iteration 1897, loss = 0.01611150
Iteration 1898, loss = 0.01610278
Iteration 1899, loss = 0.01609450
Iteration 1900, loss = 0.01608611
Iteration 1901, loss = 0.01607736
Iteration 1902, loss = 0.01606859
Iteration 1903, loss = 0.01605951
Iteration 1904, loss = 0.01604988
Iteration 1905, loss = 0.01604136
Iteration 1906, loss = 0.01603191
Iteration 1907, loss = 0.01602321
Iteration 1908, loss = 0.01601384
Iteration 1909, loss = 0.01600503
Iteration 1910, loss = 0.01599578
Iteration 1911, loss = 0.01598831
Iteration 1912, loss = 0.01597885
Iteration 1913, loss = 0.01597050
Iteration 1914, loss = 0.01596368
Iteration 1915, loss = 0.01595402
Iteration 1916, loss = 0.01594601
Iteration 1917, loss = 0.01593711
Iteration 1918, loss = 0.01593026
Iteration 1919, loss = 0.01591923
Iteration 1920, loss = 0.01590938
Iteration 1921, loss = 0.01590027
Iteration 1922, loss = 0.01588990
Iteration 1923, loss = 0.01588159
Iteration 1924, loss = 0.01586953
Iteration 1925, loss = 0.01586030
Iteration 1926, loss = 0.01585035
Iteration 1927, loss = 0.01583939
Iteration 1928, loss = 0.01582976
Iteration 1929, loss = 0.01581951
Iteration 1930, loss = 0.01580996
Iteration 1931, loss = 0.01579996
Iteration 1932, loss = 0.01579027
Iteration 1933, loss = 0.01578124
Iteration 1934, loss = 0.01577052
Iteration 1935, loss = 0.01576226
Iteration 1936, loss = 0.01575087
Iteration 1937, loss = 0.01574157
Iteration 1938, loss = 0.01573250
Iteration 1939, loss = 0.01572164
Iteration 1940, loss = 0.01571294
Iteration 1941, loss = 0.01570379
Iteration 1942, loss = 0.01569505
Iteration 1943, loss = 0.01568361
Iteration 1944, loss = 0.01567526
Iteration 1945, loss = 0.01566374
Iteration 1946, loss = 0.01565431
Iteration 1947, loss = 0.01564406
Iteration 1948, loss = 0.01563473
Iteration 1949, loss = 0.01562507
Iteration 1950, loss = 0.01561487
Iteration 1951, loss = 0.01560672
Iteration 1952, loss = 0.01559665
Iteration 1953, loss = 0.01558693
Iteration 1954, loss = 0.01557852
Iteration 1955, loss = 0.01556898
Iteration 1956, loss = 0.01556011
Iteration 1957, loss = 0.01555102
Iteration 1958, loss = 0.01554264
Iteration 1959, loss = 0.01553339
Iteration 1960, loss = 0.01552444
Iteration 1961, loss = 0.01551527
Iteration 1962, loss = 0.01550557
Iteration 1963, loss = 0.01549535
Iteration 1964, loss = 0.01548743
Iteration 1965, loss = 0.01547765
Iteration 1966, loss = 0.01546967
Iteration 1967, loss = 0.01546024
Iteration 1968, loss = 0.01545154
Iteration 1969, loss = 0.01544233
Iteration 1970, loss = 0.01543396
Iteration 1971, loss = 0.01542667
Iteration 1972, loss = 0.01541652
Iteration 1973, loss = 0.01540799
Iteration 1974, loss = 0.01540149
Iteration 1975, loss = 0.01539078
Iteration 1976, loss = 0.01538199
Iteration 1977, loss = 0.01537293
Iteration 1978, loss = 0.01536360
Iteration 1979, loss = 0.01535403
Iteration 1980, loss = 0.01534537
Iteration 1981, loss = 0.01533588
Iteration 1982, loss = 0.01532687
Iteration 1983, loss = 0.01531978
Iteration 1984, loss = 0.01531139
Iteration 1985, loss = 0.01530073
Iteration 1986, loss = 0.01529343
Iteration 1987, loss = 0.01528276
Iteration 1988, loss = 0.01527512
Iteration 1989, loss = 0.01526728
Iteration 1990, loss = 0.01525845
Iteration 1991, loss = 0.01525019
Iteration 1992, loss = 0.01524092
Iteration 1993, loss = 0.01523101
Iteration 1994, loss = 0.01522226
Iteration 1995, loss = 0.01521347
Iteration 1996, loss = 0.01520412
Iteration 1997, loss = 0.01519528
Iteration 1998, loss = 0.01518613
Iteration 1999, loss = 0.01517735
Iteration 2000, loss = 0.01516809
Iteration 2001, loss = 0.01516010
Iteration 2002, loss = 0.01515100
Iteration 2003, loss = 0.01514199
Iteration 2004, loss = 0.01513352
Iteration 2005, loss = 0.01512447
Iteration 2006, loss = 0.01511603
Iteration 2007, loss = 0.01510773
Iteration 2008, loss = 0.01510013
Iteration 2009, loss = 0.01509246
Iteration 2010, loss = 0.01508341
Iteration 2011, loss = 0.01507610
Iteration 2012, loss = 0.01506726
Iteration 2013, loss = 0.01506190
Iteration 2014, loss = 0.01505089
Iteration 2015, loss = 0.01504227
Iteration 2016, loss = 0.01503387
Iteration 2017, loss = 0.01502603
Iteration 2018, loss = 0.01501769
Iteration 2019, loss = 0.01500930
Iteration 2020, loss = 0.01500127
Iteration 2021, loss = 0.01499363
Iteration 2022, loss = 0.01498474
Iteration 2023, loss = 0.01497607
Iteration 2024, loss = 0.01496852
Iteration 2025, loss = 0.01495996
Iteration 2026, loss = 0.01495252
Iteration 2027, loss = 0.01494403
Iteration 2028, loss = 0.01493715
Iteration 2029, loss = 0.01492971
Iteration 2030, loss = 0.01492026
Iteration 2031, loss = 0.01491219
Iteration 2032, loss = 0.01490396
Iteration 2033, loss = 0.01489572
Iteration 2034, loss = 0.01488798
Iteration 2035, loss = 0.01488023
Iteration 2036, loss = 0.01487223
Iteration 2037, loss = 0.01486370
Iteration 2038, loss = 0.01485765
Iteration 2039, loss = 0.01485028
Iteration 2040, loss = 0.01484085
Iteration 2041, loss = 0.01483373
Iteration 2042, loss = 0.01482574
Iteration 2043, loss = 0.01481793
Iteration 2044, loss = 0.01480995
Iteration 2045, loss = 0.01480330
Iteration 2046, loss = 0.01479496
Iteration 2047, loss = 0.01478769
Iteration 2048, loss = 0.01478147
Iteration 2049, loss = 0.01477124
Iteration 2050, loss = 0.01476269
Iteration 2051, loss = 0.01475662
Iteration 2052, loss = 0.01474888
Iteration 2053, loss = 0.01474082
Iteration 2054, loss = 0.01473336
Iteration 2055, loss = 0.01472567
Iteration 2056, loss = 0.01471800
Iteration 2057, loss = 0.01471024
Iteration 2058, loss = 0.01470451
Iteration 2059, loss = 0.01469409
Iteration 2060, loss = 0.01468583
Iteration 2061, loss = 0.01467792
Iteration 2062, loss = 0.01466901
Iteration 2063, loss = 0.01466041
Iteration 2064, loss = 0.01465095
Iteration 2065, loss = 0.01464284
Iteration 2066, loss = 0.01463521
Iteration 2067, loss = 0.01462653
Iteration 2068, loss = 0.01462045
Iteration 2069, loss = 0.01461085
Iteration 2070, loss = 0.01460228
Iteration 2071, loss = 0.01459448
Iteration 2072, loss = 0.01458547
Iteration 2073, loss = 0.01457965
Iteration 2074, loss = 0.01456836
Iteration 2075, loss = 0.01456030
Iteration 2076, loss = 0.01455216
Iteration 2077, loss = 0.01454421
Iteration 2078, loss = 0.01453624
Iteration 2079, loss = 0.01452900
Iteration 2080, loss = 0.01451999
Iteration 2081, loss = 0.01451229
Iteration 2082, loss = 0.01450481
Iteration 2083, loss = 0.01449673
Iteration 2084, loss = 0.01448936
Iteration 2085, loss = 0.01448193
Iteration 2086, loss = 0.01447323
Iteration 2087, loss = 0.01446515
Iteration 2088, loss = 0.01445671
Iteration 2089, loss = 0.01444956
Iteration 2090, loss = 0.01444110
Iteration 2091, loss = 0.01443481
Iteration 2092, loss = 0.01442687
Iteration 2093, loss = 0.01441940
Iteration 2094, loss = 0.01441160
Iteration 2095, loss = 0.01440433
Iteration 2096, loss = 0.01439669
Iteration 2097, loss = 0.01438912
Iteration 2098, loss = 0.01438165
Iteration 2099, loss = 0.01437382
Iteration 2100, loss = 0.01436735
Iteration 2101, loss = 0.01435965
Iteration 2102, loss = 0.01435162
Iteration 2103, loss = 0.01434460
Iteration 2104, loss = 0.01433726
Iteration 2105, loss = 0.01433090
Iteration 2106, loss = 0.01432289
Iteration 2107, loss = 0.01431600
Iteration 2108, loss = 0.01430711
Iteration 2109, loss = 0.01430137
Iteration 2110, loss = 0.01429222
Iteration 2111, loss = 0.01428320
Iteration 2112, loss = 0.01427840
Iteration 2113, loss = 0.01426945
Iteration 2114, loss = 0.01426302
Iteration 2115, loss = 0.01425453
Iteration 2116, loss = 0.01424727
Iteration 2117, loss = 0.01423953
Iteration 2118, loss = 0.01423310
Iteration 2119, loss = 0.01422629
Iteration 2120, loss = 0.01421659
Iteration 2121, loss = 0.01420961
Iteration 2122, loss = 0.01420174
Iteration 2123, loss = 0.01419550
Iteration 2124, loss = 0.01418619
Iteration 2125, loss = 0.01417895
Iteration 2126, loss = 0.01417406
Iteration 2127, loss = 0.01416614
Iteration 2128, loss = 0.01415906
Iteration 2129, loss = 0.01415278
Iteration 2130, loss = 0.01414521
Iteration 2131, loss = 0.01413853
Iteration 2132, loss = 0.01413148
Iteration 2133, loss = 0.01412439
Iteration 2134, loss = 0.01411804
Iteration 2135, loss = 0.01411063
Iteration 2136, loss = 0.01410394
Iteration 2137, loss = 0.01409678
Iteration 2138, loss = 0.01409067
Iteration 2139, loss = 0.01408299
Iteration 2140, loss = 0.01407563
Iteration 2141, loss = 0.01406741
Iteration 2142, loss = 0.01406049
Iteration 2143, loss = 0.01405316
Iteration 2144, loss = 0.01404572
Iteration 2145, loss = 0.01403837
Iteration 2146, loss = 0.01403059
Iteration 2147, loss = 0.01402346
Iteration 2148, loss = 0.01401544
Iteration 2149, loss = 0.01400855
Iteration 2150, loss = 0.01400076
Iteration 2151, loss = 0.01399279
Iteration 2152, loss = 0.01398512
Iteration 2153, loss = 0.01397717
Iteration 2154, loss = 0.01397021
Iteration 2155, loss = 0.01396163
Iteration 2156, loss = 0.01395334
Iteration 2157, loss = 0.01394646
Iteration 2158, loss = 0.01393772
Iteration 2159, loss = 0.01393024
Iteration 2160, loss = 0.01392204
Iteration 2161, loss = 0.01391525
Iteration 2162, loss = 0.01390798
Iteration 2163, loss = 0.01390039
Iteration 2164, loss = 0.01389299
Iteration 2165, loss = 0.01388712
Iteration 2166, loss = 0.01387834
Iteration 2167, loss = 0.01387123
Iteration 2168, loss = 0.01386407
Iteration 2169, loss = 0.01385604
Iteration 2170, loss = 0.01384841
Iteration 2171, loss = 0.01384096
Iteration 2172, loss = 0.01383570
Iteration 2173, loss = 0.01382604
Iteration 2174, loss = 0.01381831
Iteration 2175, loss = 0.01381257
Iteration 2176, loss = 0.01380438
Iteration 2177, loss = 0.01379754
Iteration 2178, loss = 0.01379002
Iteration 2179, loss = 0.01378276
Iteration 2180, loss = 0.01377535
Iteration 2181, loss = 0.01376833
Iteration 2182, loss = 0.01376151
Iteration 2183, loss = 0.01375404
Iteration 2184, loss = 0.01374666
Iteration 2185, loss = 0.01374107
Iteration 2186, loss = 0.01373548
Iteration 2187, loss = 0.01372718
Iteration 2188, loss = 0.01372018
Iteration 2189, loss = 0.01371344
Iteration 2190, loss = 0.01370587
Iteration 2191, loss = 0.01369820
Iteration 2192, loss = 0.01369102
Iteration 2193, loss = 0.01368423
Iteration 2194, loss = 0.01367712
Iteration 2195, loss = 0.01367026
Iteration 2196, loss = 0.01366420
Iteration 2197, loss = 0.01365741
Iteration 2198, loss = 0.01365084
Iteration 2199, loss = 0.01364509
Iteration 2200, loss = 0.01364011
Iteration 2201, loss = 0.01363428
Iteration 2202, loss = 0.01363011
Iteration 2203, loss = 0.01362292
Iteration 2204, loss = 0.01361602
Iteration 2205, loss = 0.01361015
Iteration 2206, loss = 0.01360310
Iteration 2207, loss = 0.01359655
Iteration 2208, loss = 0.01359151
Iteration 2209, loss = 0.01358434
Iteration 2210, loss = 0.01357709
Iteration 2211, loss = 0.01356977
Iteration 2212, loss = 0.01356432
Iteration 2213, loss = 0.01355498
Iteration 2214, loss = 0.01354757
Iteration 2215, loss = 0.01354064
Iteration 2216, loss = 0.01353279
Iteration 2217, loss = 0.01352419
Iteration 2218, loss = 0.01351655
Iteration 2219, loss = 0.01351221
Iteration 2220, loss = 0.01350250
Iteration 2221, loss = 0.01349621
Iteration 2222, loss = 0.01348924
Iteration 2223, loss = 0.01348142
Iteration 2224, loss = 0.01347539
Iteration 2225, loss = 0.01346857
Iteration 2226, loss = 0.01346177
Iteration 2227, loss = 0.01345593
Iteration 2228, loss = 0.01344901
Iteration 2229, loss = 0.01344270
Iteration 2230, loss = 0.01343650
Iteration 2231, loss = 0.01343063
Iteration 2232, loss = 0.01342542
Iteration 2233, loss = 0.01341874
Iteration 2234, loss = 0.01340963
Iteration 2235, loss = 0.01340267
Iteration 2236, loss = 0.01339456
Iteration 2237, loss = 0.01339043
Iteration 2238, loss = 0.01338081
Iteration 2239, loss = 0.01337376
Iteration 2240, loss = 0.01336764
Iteration 2241, loss = 0.01336070
Iteration 2242, loss = 0.01335315
Iteration 2243, loss = 0.01334507
Iteration 2244, loss = 0.01333988
Iteration 2245, loss = 0.01333039
Iteration 2246, loss = 0.01332555
Iteration 2247, loss = 0.01331915
Iteration 2248, loss = 0.01331247
Iteration 2249, loss = 0.01330559
Iteration 2250, loss = 0.01329822
Iteration 2251, loss = 0.01329140
Iteration 2252, loss = 0.01328502
Iteration 2253, loss = 0.01327890
Iteration 2254, loss = 0.01327126
Iteration 2255, loss = 0.01326409
Iteration 2256, loss = 0.01325713
Iteration 2257, loss = 0.01325032
Iteration 2258, loss = 0.01324471
Iteration 2259, loss = 0.01323648
Iteration 2260, loss = 0.01323022
Iteration 2261, loss = 0.01322365
Iteration 2262, loss = 0.01321662
Iteration 2263, loss = 0.01320958
Iteration 2264, loss = 0.01320310
Iteration 2265, loss = 0.01319603
Iteration 2266, loss = 0.01318935
Iteration 2267, loss = 0.01318273
Iteration 2268, loss = 0.01317651
Iteration 2269, loss = 0.01316991
Iteration 2270, loss = 0.01316358
Iteration 2271, loss = 0.01315739
Iteration 2272, loss = 0.01315028
Iteration 2273, loss = 0.01314383
Iteration 2274, loss = 0.01313720
Iteration 2275, loss = 0.01313275
Iteration 2276, loss = 0.01312446
Iteration 2277, loss = 0.01311759
Iteration 2278, loss = 0.01311028
Iteration 2279, loss = 0.01310384
Iteration 2280, loss = 0.01309779
Iteration 2281, loss = 0.01309020
Iteration 2282, loss = 0.01308354
Iteration 2283, loss = 0.01307700
Iteration 2284, loss = 0.01307003
Iteration 2285, loss = 0.01306368
Iteration 2286, loss = 0.01305671
Iteration 2287, loss = 0.01305043
Iteration 2288, loss = 0.01304370
Iteration 2289, loss = 0.01303714
Iteration 2290, loss = 0.01303207
Iteration 2291, loss = 0.01302471
Iteration 2292, loss = 0.01301797
Iteration 2293, loss = 0.01301194
Iteration 2294, loss = 0.01300625
Iteration 2295, loss = 0.01299852
Iteration 2296, loss = 0.01299342
Iteration 2297, loss = 0.01298610
Iteration 2298, loss = 0.01297929
Iteration 2299, loss = 0.01297303
Iteration 2300, loss = 0.01296655
Iteration 2301, loss = 0.01296161
Iteration 2302, loss = 0.01295410
Iteration 2303, loss = 0.01294758
Iteration 2304, loss = 0.01294068
Iteration 2305, loss = 0.01293346
Iteration 2306, loss = 0.01292992
Iteration 2307, loss = 0.01292168
Iteration 2308, loss = 0.01291635
Iteration 2309, loss = 0.01290924
Iteration 2310, loss = 0.01290438
Iteration 2311, loss = 0.01289758
Iteration 2312, loss = 0.01289134
Iteration 2313, loss = 0.01288659
Iteration 2314, loss = 0.01287934
Iteration 2315, loss = 0.01287339
Iteration 2316, loss = 0.01286687
Iteration 2317, loss = 0.01285994
Iteration 2318, loss = 0.01285441
Iteration 2319, loss = 0.01284725
Iteration 2320, loss = 0.01284055
Iteration 2321, loss = 0.01283655
Iteration 2322, loss = 0.01282711
Iteration 2323, loss = 0.01281958
Iteration 2324, loss = 0.01281340
Iteration 2325, loss = 0.01280661
Iteration 2326, loss = 0.01279992
Iteration 2327, loss = 0.01279466
Iteration 2328, loss = 0.01278759
Iteration 2329, loss = 0.01278132
Iteration 2330, loss = 0.01277472
Iteration 2331, loss = 0.01276940
Iteration 2332, loss = 0.01276447
Iteration 2333, loss = 0.01275686
Iteration 2334, loss = 0.01275019
Iteration 2335, loss = 0.01274323
Iteration 2336, loss = 0.01273610
Iteration 2337, loss = 0.01273142
Iteration 2338, loss = 0.01272346
Iteration 2339, loss = 0.01271818
Iteration 2340, loss = 0.01271214
Iteration 2341, loss = 0.01270409
Iteration 2342, loss = 0.01269766
Iteration 2343, loss = 0.01269141
Iteration 2344, loss = 0.01268561
Iteration 2345, loss = 0.01267984
Iteration 2346, loss = 0.01267253
Iteration 2347, loss = 0.01266486
Iteration 2348, loss = 0.01265851
Iteration 2349, loss = 0.01265184
Iteration 2350, loss = 0.01264682
Iteration 2351, loss = 0.01264017
Iteration 2352, loss = 0.01263341
Iteration 2353, loss = 0.01262721
Iteration 2354, loss = 0.01261952
Iteration 2355, loss = 0.01261310
Iteration 2356, loss = 0.01260618
Iteration 2357, loss = 0.01259941
Iteration 2358, loss = 0.01259298
Iteration 2359, loss = 0.01258619
Iteration 2360, loss = 0.01257946
Iteration 2361, loss = 0.01257309
Iteration 2362, loss = 0.01256649
Iteration 2363, loss = 0.01256033
Iteration 2364, loss = 0.01255570
Iteration 2365, loss = 0.01255062
Iteration 2366, loss = 0.01254412
Iteration 2367, loss = 0.01253788
Iteration 2368, loss = 0.01253120
Iteration 2369, loss = 0.01252571
Iteration 2370, loss = 0.01251868
Iteration 2371, loss = 0.01251235
Iteration 2372, loss = 0.01250808
Iteration 2373, loss = 0.01250142
Iteration 2374, loss = 0.01249449
Iteration 2375, loss = 0.01248807
Iteration 2376, loss = 0.01248345
Iteration 2377, loss = 0.01247612
Iteration 2378, loss = 0.01247059
Iteration 2379, loss = 0.01246436
Iteration 2380, loss = 0.01245856
Iteration 2381, loss = 0.01245260
Iteration 2382, loss = 0.01244636
Iteration 2383, loss = 0.01244036
Iteration 2384, loss = 0.01243450
Iteration 2385, loss = 0.01242910
Iteration 2386, loss = 0.01242365
Iteration 2387, loss = 0.01241716
Iteration 2388, loss = 0.01241192
Iteration 2389, loss = 0.01240858
Iteration 2390, loss = 0.01240110
Iteration 2391, loss = 0.01239494
Iteration 2392, loss = 0.01238927
Iteration 2393, loss = 0.01238364
Iteration 2394, loss = 0.01237757
Iteration 2395, loss = 0.01237188
Iteration 2396, loss = 0.01236632
Iteration 2397, loss = 0.01236080
Iteration 2398, loss = 0.01235506
Iteration 2399, loss = 0.01234992
Iteration 2400, loss = 0.01234502
Iteration 2401, loss = 0.01233813
Iteration 2402, loss = 0.01233198
Iteration 2403, loss = 0.01232622
Iteration 2404, loss = 0.01231958
Iteration 2405, loss = 0.01231483
Iteration 2406, loss = 0.01230863
Iteration 2407, loss = 0.01230332
Iteration 2408, loss = 0.01229877
Iteration 2409, loss = 0.01229256
Iteration 2410, loss = 0.01228687
Iteration 2411, loss = 0.01228103
Iteration 2412, loss = 0.01227559
Iteration 2413, loss = 0.01226968
Iteration 2414, loss = 0.01226398
Iteration 2415, loss = 0.01225846
Iteration 2416, loss = 0.01225498
Iteration 2417, loss = 0.01224783
Iteration 2418, loss = 0.01224357
Iteration 2419, loss = 0.01223764
Iteration 2420, loss = 0.01223194
Iteration 2421, loss = 0.01222804
Iteration 2422, loss = 0.01222168
Iteration 2423, loss = 0.01221725
Iteration 2424, loss = 0.01221099
Iteration 2425, loss = 0.01220541
Iteration 2426, loss = 0.01220258
Iteration 2427, loss = 0.01219547
Iteration 2428, loss = 0.01218896
Iteration 2429, loss = 0.01218413
Iteration 2430, loss = 0.01217856
Iteration 2431, loss = 0.01217234
Iteration 2432, loss = 0.01216767
Iteration 2433, loss = 0.01216244
Iteration 2434, loss = 0.01215624
Iteration 2435, loss = 0.01215102
Iteration 2436, loss = 0.01214558
Iteration 2437, loss = 0.01214021
Iteration 2438, loss = 0.01213481
Iteration 2439, loss = 0.01212948
Iteration 2440, loss = 0.01212446
Iteration 2441, loss = 0.01211962
Iteration 2442, loss = 0.01211362
Iteration 2443, loss = 0.01210814
Iteration 2444, loss = 0.01210260
Iteration 2445, loss = 0.01209705
Iteration 2446, loss = 0.01209173
Iteration 2447, loss = 0.01208582
Iteration 2448, loss = 0.01207939
Iteration 2449, loss = 0.01207342
Iteration 2450, loss = 0.01206730
Iteration 2451, loss = 0.01206209
Iteration 2452, loss = 0.01205663
Iteration 2453, loss = 0.01205132
Iteration 2454, loss = 0.01204498
Iteration 2455, loss = 0.01203889
Iteration 2456, loss = 0.01203357
Iteration 2457, loss = 0.01202725
Iteration 2458, loss = 0.01202162
Iteration 2459, loss = 0.01201596
Iteration 2460, loss = 0.01201059
Iteration 2461, loss = 0.01200662
Iteration 2462, loss = 0.01200089
Iteration 2463, loss = 0.01199483
Iteration 2464, loss = 0.01198886
Iteration 2465, loss = 0.01198326
Iteration 2466, loss = 0.01197772
Iteration 2467, loss = 0.01196998
Iteration 2468, loss = 0.01196664
Iteration 2469, loss = 0.01195906
Iteration 2470, loss = 0.01195403
Iteration 2471, loss = 0.01194845
Iteration 2472, loss = 0.01194277
Iteration 2473, loss = 0.01193774
Iteration 2474, loss = 0.01193255
Iteration 2475, loss = 0.01192790
Iteration 2476, loss = 0.01192214
Iteration 2477, loss = 0.01191720
Iteration 2478, loss = 0.01191280
Iteration 2479, loss = 0.01190748
Iteration 2480, loss = 0.01190244
Iteration 2481, loss = 0.01189652
Iteration 2482, loss = 0.01189127
Iteration 2483, loss = 0.01188556
Iteration 2484, loss = 0.01188088
Iteration 2485, loss = 0.01187535
Iteration 2486, loss = 0.01186856
Iteration 2487, loss = 0.01186376
Iteration 2488, loss = 0.01185594
Iteration 2489, loss = 0.01185006
Iteration 2490, loss = 0.01184308
Iteration 2491, loss = 0.01183981
Iteration 2492, loss = 0.01183137
Iteration 2493, loss = 0.01182649
Iteration 2494, loss = 0.01181961
Iteration 2495, loss = 0.01181361
Iteration 2496, loss = 0.01180901
Iteration 2497, loss = 0.01180254
Iteration 2498, loss = 0.01179744
Iteration 2499, loss = 0.01179012
Iteration 2500, loss = 0.01178576
Iteration 2501, loss = 0.01177989
Iteration 2502, loss = 0.01177563
Iteration 2503, loss = 0.01176940
Iteration 2504, loss = 0.01176337
Iteration 2505, loss = 0.01175870
Iteration 2506, loss = 0.01175206
Iteration 2507, loss = 0.01174678
Iteration 2508, loss = 0.01174169
Iteration 2509, loss = 0.01173618
Iteration 2510, loss = 0.01173126
Iteration 2511, loss = 0.01172559
Iteration 2512, loss = 0.01172001
Iteration 2513, loss = 0.01171591
Iteration 2514, loss = 0.01170978
Iteration 2515, loss = 0.01170410
Iteration 2516, loss = 0.01169869
Iteration 2517, loss = 0.01169421
Iteration 2518, loss = 0.01168745
Iteration 2519, loss = 0.01168242
Iteration 2520, loss = 0.01167718
Iteration 2521, loss = 0.01167210
Iteration 2522, loss = 0.01166676
Iteration 2523, loss = 0.01166175
Iteration 2524, loss = 0.01165625
Iteration 2525, loss = 0.01165066
Iteration 2526, loss = 0.01164481
Iteration 2527, loss = 0.01163973
Iteration 2528, loss = 0.01163405
Iteration 2529, loss = 0.01163016
Iteration 2530, loss = 0.01162548
Iteration 2531, loss = 0.01161865
Iteration 2532, loss = 0.01161329
Iteration 2533, loss = 0.01160817
Iteration 2534, loss = 0.01160316
Iteration 2535, loss = 0.01159776
Iteration 2536, loss = 0.01159330
Iteration 2537, loss = 0.01158784
Iteration 2538, loss = 0.01158234
Iteration 2539, loss = 0.01157699
Iteration 2540, loss = 0.01157201
Iteration 2541, loss = 0.01156685
Iteration 2542, loss = 0.01156121
Iteration 2543, loss = 0.01155596
Iteration 2544, loss = 0.01155089
Iteration 2545, loss = 0.01154673
Iteration 2546, loss = 0.01154120
Iteration 2547, loss = 0.01153629
Iteration 2548, loss = 0.01153146
Iteration 2549, loss = 0.01152556
Iteration 2550, loss = 0.01152029
Iteration 2551, loss = 0.01151567
Iteration 2552, loss = 0.01150951
Iteration 2553, loss = 0.01150412
Iteration 2554, loss = 0.01149918
Iteration 2555, loss = 0.01149396
Iteration 2556, loss = 0.01148912
Iteration 2557, loss = 0.01148332
Iteration 2558, loss = 0.01147831
Iteration 2559, loss = 0.01147300
Iteration 2560, loss = 0.01146744
Iteration 2561, loss = 0.01146304
Iteration 2562, loss = 0.01145722
Iteration 2563, loss = 0.01145215
Iteration 2564, loss = 0.01144788
Iteration 2565, loss = 0.01144233
Iteration 2566, loss = 0.01143734
Iteration 2567, loss = 0.01143478
Iteration 2568, loss = 0.01142682
Iteration 2569, loss = 0.01142206
Iteration 2570, loss = 0.01141610
Iteration 2571, loss = 0.01140967
Iteration 2572, loss = 0.01140719
Iteration 2573, loss = 0.01140045
Iteration 2574, loss = 0.01139420
Iteration 2575, loss = 0.01138904
Iteration 2576, loss = 0.01138318
Iteration 2577, loss = 0.01137798
Iteration 2578, loss = 0.01137292
Iteration 2579, loss = 0.01136708
Iteration 2580, loss = 0.01136232
Iteration 2581, loss = 0.01135705
Iteration 2582, loss = 0.01135091
Iteration 2583, loss = 0.01134725
Iteration 2584, loss = 0.01134127
Iteration 2585, loss = 0.01133814
Iteration 2586, loss = 0.01133221
Iteration 2587, loss = 0.01132750
Iteration 2588, loss = 0.01132212
Iteration 2589, loss = 0.01131802
Iteration 2590, loss = 0.01131340
Iteration 2591, loss = 0.01130836
Iteration 2592, loss = 0.01130300
Iteration 2593, loss = 0.01130060
Iteration 2594, loss = 0.01129429
Iteration 2595, loss = 0.01129041
Iteration 2596, loss = 0.01128569
Iteration 2597, loss = 0.01128016
Iteration 2598, loss = 0.01127500
Iteration 2599, loss = 0.01126969
Iteration 2600, loss = 0.01126512
Iteration 2601, loss = 0.01125928
Iteration 2602, loss = 0.01125496
Iteration 2603, loss = 0.01124976
Iteration 2604, loss = 0.01124424
Iteration 2605, loss = 0.01123892
Iteration 2606, loss = 0.01123424
Iteration 2607, loss = 0.01122864
Iteration 2608, loss = 0.01122394
Iteration 2609, loss = 0.01121862
Iteration 2610, loss = 0.01121334
Iteration 2611, loss = 0.01120836
Iteration 2612, loss = 0.01120294
Iteration 2613, loss = 0.01119829
Iteration 2614, loss = 0.01119248
Iteration 2615, loss = 0.01118885
Iteration 2616, loss = 0.01118253
Iteration 2617, loss = 0.01117762
Iteration 2618, loss = 0.01117276
Iteration 2619, loss = 0.01116786
Iteration 2620, loss = 0.01116227
Iteration 2621, loss = 0.01115709
Iteration 2622, loss = 0.01115206
Iteration 2623, loss = 0.01114767
Iteration 2624, loss = 0.01114155
Iteration 2625, loss = 0.01113720
Iteration 2626, loss = 0.01113089
Iteration 2627, loss = 0.01112592
Iteration 2628, loss = 0.01112094
Iteration 2629, loss = 0.01111505
Iteration 2630, loss = 0.01111009
Iteration 2631, loss = 0.01110380
Iteration 2632, loss = 0.01110008
Iteration 2633, loss = 0.01109307
Iteration 2634, loss = 0.01108968
Iteration 2635, loss = 0.01108289
Iteration 2636, loss = 0.01107800
Iteration 2637, loss = 0.01107192
Iteration 2638, loss = 0.01106773
Iteration 2639, loss = 0.01106168
Iteration 2640, loss = 0.01105645
Iteration 2641, loss = 0.01105125
Iteration 2642, loss = 0.01104580
Iteration 2643, loss = 0.01104076
Iteration 2644, loss = 0.01103501
Iteration 2645, loss = 0.01102947
Iteration 2646, loss = 0.01102553
Iteration 2647, loss = 0.01101944
Iteration 2648, loss = 0.01101500
Iteration 2649, loss = 0.01100945
Iteration 2650, loss = 0.01100420
Iteration 2651, loss = 0.01099946
Iteration 2652, loss = 0.01099736
Iteration 2653, loss = 0.01098990
Iteration 2654, loss = 0.01098543
Iteration 2655, loss = 0.01098008
Iteration 2656, loss = 0.01097502
Iteration 2657, loss = 0.01097212
Iteration 2658, loss = 0.01096546
Iteration 2659, loss = 0.01096052
Iteration 2660, loss = 0.01095567
Iteration 2661, loss = 0.01095005
Iteration 2662, loss = 0.01094590
Iteration 2663, loss = 0.01094065
Iteration 2664, loss = 0.01093542
Iteration 2665, loss = 0.01093091
Iteration 2666, loss = 0.01092686
Iteration 2667, loss = 0.01092109
Iteration 2668, loss = 0.01091749
Iteration 2669, loss = 0.01091205
Iteration 2670, loss = 0.01090740
Iteration 2671, loss = 0.01090260
Iteration 2672, loss = 0.01089795
Iteration 2673, loss = 0.01089428
Iteration 2674, loss = 0.01089000
Iteration 2675, loss = 0.01088522
Iteration 2676, loss = 0.01088026
Iteration 2677, loss = 0.01087650
Iteration 2678, loss = 0.01087127
Iteration 2679, loss = 0.01086671
Iteration 2680, loss = 0.01086184
Iteration 2681, loss = 0.01085752
Iteration 2682, loss = 0.01085441
Iteration 2683, loss = 0.01084855
Iteration 2684, loss = 0.01084349
Iteration 2685, loss = 0.01083889
Iteration 2686, loss = 0.01083430
Iteration 2687, loss = 0.01082970
Iteration 2688, loss = 0.01082624
Iteration 2689, loss = 0.01082091
Iteration 2690, loss = 0.01081659
Iteration 2691, loss = 0.01081132
Iteration 2692, loss = 0.01080688
Iteration 2693, loss = 0.01080228
Iteration 2694, loss = 0.01079817
Iteration 2695, loss = 0.01079292
Iteration 2696, loss = 0.01078839
Iteration 2697, loss = 0.01078364
Iteration 2698, loss = 0.01077926
Iteration 2699, loss = 0.01077398
Iteration 2700, loss = 0.01076969
Iteration 2701, loss = 0.01076453
Iteration 2702, loss = 0.01075946
Iteration 2703, loss = 0.01075534
Iteration 2704, loss = 0.01075097
Iteration 2705, loss = 0.01074577
Iteration 2706, loss = 0.01074150
Iteration 2707, loss = 0.01073716
Iteration 2708, loss = 0.01073248
Iteration 2709, loss = 0.01072899
Iteration 2710, loss = 0.01072393
Iteration 2711, loss = 0.01071960
Iteration 2712, loss = 0.01071404
Iteration 2713, loss = 0.01070961
Iteration 2714, loss = 0.01070663
Iteration 2715, loss = 0.01070167
Iteration 2716, loss = 0.01069691
Iteration 2717, loss = 0.01069193
Iteration 2718, loss = 0.01068733
Iteration 2719, loss = 0.01068296
Iteration 2720, loss = 0.01067840
Iteration 2721, loss = 0.01067352
Iteration 2722, loss = 0.01066894
Iteration 2723, loss = 0.01066382
Iteration 2724, loss = 0.01065991
Iteration 2725, loss = 0.01065545
Iteration 2726, loss = 0.01065031
Iteration 2727, loss = 0.01064519
Iteration 2728, loss = 0.01063997
Iteration 2729, loss = 0.01063647
Iteration 2730, loss = 0.01063116
Iteration 2731, loss = 0.01062709
Iteration 2732, loss = 0.01062142
Iteration 2733, loss = 0.01061674
Iteration 2734, loss = 0.01061266
Iteration 2735, loss = 0.01060731
Iteration 2736, loss = 0.01060390
Iteration 2737, loss = 0.01059806
Iteration 2738, loss = 0.01059505
Iteration 2739, loss = 0.01059016
Iteration 2740, loss = 0.01058489
Iteration 2741, loss = 0.01058075
Iteration 2742, loss = 0.01057573
Iteration 2743, loss = 0.01057136
Iteration 2744, loss = 0.01056681
Iteration 2745, loss = 0.01056184
Iteration 2746, loss = 0.01055720
Iteration 2747, loss = 0.01055560
Iteration 2748, loss = 0.01054890
Iteration 2749, loss = 0.01054434
Iteration 2750, loss = 0.01054086
Iteration 2751, loss = 0.01053556
Iteration 2752, loss = 0.01053123
Iteration 2753, loss = 0.01052655
Iteration 2754, loss = 0.01052302
Iteration 2755, loss = 0.01051745
Iteration 2756, loss = 0.01051299
Iteration 2757, loss = 0.01050860
Iteration 2758, loss = 0.01050396
Iteration 2759, loss = 0.01049988
Iteration 2760, loss = 0.01049530
Iteration 2761, loss = 0.01049082
Iteration 2762, loss = 0.01048629
Iteration 2763, loss = 0.01048156
Iteration 2764, loss = 0.01047764
Iteration 2765, loss = 0.01047337
Iteration 2766, loss = 0.01046853
Iteration 2767, loss = 0.01046466
Iteration 2768, loss = 0.01046010
Iteration 2769, loss = 0.01045594
Iteration 2770, loss = 0.01045142
Iteration 2771, loss = 0.01044729
Iteration 2772, loss = 0.01044279
Iteration 2773, loss = 0.01043870
Iteration 2774, loss = 0.01043459
Iteration 2775, loss = 0.01043059
Iteration 2776, loss = 0.01042575
Iteration 2777, loss = 0.01042151
Iteration 2778, loss = 0.01041676
Iteration 2779, loss = 0.01041516
Iteration 2780, loss = 0.01040991
Iteration 2781, loss = 0.01040768
Iteration 2782, loss = 0.01040066
Iteration 2783, loss = 0.01039572
Iteration 2784, loss = 0.01039136
Iteration 2785, loss = 0.01038697
Iteration 2786, loss = 0.01038230
Iteration 2787, loss = 0.01037767
Iteration 2788, loss = 0.01037326
Iteration 2789, loss = 0.01036856
Iteration 2790, loss = 0.01036425
Iteration 2791, loss = 0.01035950
Iteration 2792, loss = 0.01035541
Iteration 2793, loss = 0.01035123
Iteration 2794, loss = 0.01034703
Iteration 2795, loss = 0.01034292
Iteration 2796, loss = 0.01033860
Iteration 2797, loss = 0.01033439
Iteration 2798, loss = 0.01033090
Iteration 2799, loss = 0.01032786
Iteration 2800, loss = 0.01032272
Iteration 2801, loss = 0.01031880
Iteration 2802, loss = 0.01031352
Iteration 2803, loss = 0.01030908
Iteration 2804, loss = 0.01030459
Iteration 2805, loss = 0.01030104
Iteration 2806, loss = 0.01029527
Iteration 2807, loss = 0.01029008
Iteration 2808, loss = 0.01028517
Iteration 2809, loss = 0.01028132
Iteration 2810, loss = 0.01027644
Iteration 2811, loss = 0.01027277
Iteration 2812, loss = 0.01026736
Iteration 2813, loss = 0.01026323
Iteration 2814, loss = 0.01025878
Iteration 2815, loss = 0.01025477
Iteration 2816, loss = 0.01025132
Iteration 2817, loss = 0.01024641
Iteration 2818, loss = 0.01024262
Iteration 2819, loss = 0.01023797
Iteration 2820, loss = 0.01023456
Iteration 2821, loss = 0.01023038
Iteration 2822, loss = 0.01022597
Iteration 2823, loss = 0.01022201
Iteration 2824, loss = 0.01021773
Iteration 2825, loss = 0.01021524
Iteration 2826, loss = 0.01021120
Iteration 2827, loss = 0.01020652
Iteration 2828, loss = 0.01020295
Iteration 2829, loss = 0.01019873
Iteration 2830, loss = 0.01019533
Iteration 2831, loss = 0.01019130
Iteration 2832, loss = 0.01018952
Iteration 2833, loss = 0.01018364
Iteration 2834, loss = 0.01018004
Iteration 2835, loss = 0.01017579
Iteration 2836, loss = 0.01017269
Iteration 2837, loss = 0.01016840
Iteration 2838, loss = 0.01016475
Iteration 2839, loss = 0.01016027
Iteration 2840, loss = 0.01015762
Iteration 2841, loss = 0.01015264
Iteration 2842, loss = 0.01014940
Iteration 2843, loss = 0.01014478
Iteration 2844, loss = 0.01014085
Iteration 2845, loss = 0.01013651
Iteration 2846, loss = 0.01013346
Iteration 2847, loss = 0.01012846
Iteration 2848, loss = 0.01012401
Iteration 2849, loss = 0.01011981
Iteration 2850, loss = 0.01011567
Iteration 2851, loss = 0.01011048
Iteration 2852, loss = 0.01010442
Iteration 2853, loss = 0.01010065
Iteration 2854, loss = 0.01009667
Iteration 2855, loss = 0.01009147
Iteration 2856, loss = 0.01008679
Iteration 2857, loss = 0.01008203
Iteration 2858, loss = 0.01007788
Iteration 2859, loss = 0.01007352
Iteration 2860, loss = 0.01006928
Iteration 2861, loss = 0.01006536
Iteration 2862, loss = 0.01006219
Iteration 2863, loss = 0.01005734
Iteration 2864, loss = 0.01005312
Iteration 2865, loss = 0.01004950
Iteration 2866, loss = 0.01004601
Iteration 2867, loss = 0.01004216
Iteration 2868, loss = 0.01003835
Iteration 2869, loss = 0.01003475
Iteration 2870, loss = 0.01003082
Iteration 2871, loss = 0.01002667
Iteration 2872, loss = 0.01002247
Iteration 2873, loss = 0.01001862
Iteration 2874, loss = 0.01001497
Iteration 2875, loss = 0.01001196
Iteration 2876, loss = 0.01000732
Iteration 2877, loss = 0.01000394
Iteration 2878, loss = 0.00999974
Iteration 2879, loss = 0.00999599
Iteration 2880, loss = 0.00999219
Iteration 2881, loss = 0.00998870
Iteration 2882, loss = 0.00998412
Iteration 2883, loss = 0.00998002
Iteration 2884, loss = 0.00997616
Iteration 2885, loss = 0.00997222
Iteration 2886, loss = 0.00996874
Iteration 2887, loss = 0.00996528
Iteration 2888, loss = 0.00996115
Iteration 2889, loss = 0.00995839
Iteration 2890, loss = 0.00995403
Iteration 2891, loss = 0.00995100
Iteration 2892, loss = 0.00994615
Iteration 2893, loss = 0.00994276
Iteration 2894, loss = 0.00993777
Iteration 2895, loss = 0.00993407
Iteration 2896, loss = 0.00992975
Iteration 2897, loss = 0.00992531
Iteration 2898, loss = 0.00992189
Iteration 2899, loss = 0.00991725
Iteration 2900, loss = 0.00991453
Iteration 2901, loss = 0.00990946
Iteration 2902, loss = 0.00990560
Iteration 2903, loss = 0.00990190
Iteration 2904, loss = 0.00989853
Iteration 2905, loss = 0.00989415
Iteration 2906, loss = 0.00989107
Iteration 2907, loss = 0.00988646
Iteration 2908, loss = 0.00988198
Iteration 2909, loss = 0.00987764
Iteration 2910, loss = 0.00987363
Iteration 2911, loss = 0.00986935
Iteration 2912, loss = 0.00986476
Iteration 2913, loss = 0.00985993
Iteration 2914, loss = 0.00985607
Iteration 2915, loss = 0.00985167
Iteration 2916, loss = 0.00984730
Iteration 2917, loss = 0.00984442
Iteration 2918, loss = 0.00983980
Iteration 2919, loss = 0.00983558
Iteration 2920, loss = 0.00983218
Iteration 2921, loss = 0.00982780
Iteration 2922, loss = 0.00982385
Iteration 2923, loss = 0.00982174
Iteration 2924, loss = 0.00981672
Iteration 2925, loss = 0.00981486
Iteration 2926, loss = 0.00980940
Iteration 2927, loss = 0.00980478
Iteration 2928, loss = 0.00980112
Iteration 2929, loss = 0.00979674
Iteration 2930, loss = 0.00979228
Iteration 2931, loss = 0.00978780
Iteration 2932, loss = 0.00978492
Iteration 2933, loss = 0.00978072
Iteration 2934, loss = 0.00977615
Iteration 2935, loss = 0.00977242
Iteration 2936, loss = 0.00976866
Iteration 2937, loss = 0.00976455
Iteration 2938, loss = 0.00976056
Iteration 2939, loss = 0.00975825
Iteration 2940, loss = 0.00975329
Iteration 2941, loss = 0.00974976
Iteration 2942, loss = 0.00974577
Iteration 2943, loss = 0.00974204
Iteration 2944, loss = 0.00973851
Iteration 2945, loss = 0.00973516
Iteration 2946, loss = 0.00973181
Iteration 2947, loss = 0.00972821
Iteration 2948, loss = 0.00972463
Iteration 2949, loss = 0.00972205
Iteration 2950, loss = 0.00971774
Iteration 2951, loss = 0.00971336
Iteration 2952, loss = 0.00971043
Iteration 2953, loss = 0.00970575
Iteration 2954, loss = 0.00970152
Iteration 2955, loss = 0.00969815
Iteration 2956, loss = 0.00969505
Iteration 2957, loss = 0.00969071
Iteration 2958, loss = 0.00968682
Iteration 2959, loss = 0.00968354
Iteration 2960, loss = 0.00967963
Iteration 2961, loss = 0.00967630
Iteration 2962, loss = 0.00967274
Iteration 2963, loss = 0.00966925
Iteration 2964, loss = 0.00966595
Iteration 2965, loss = 0.00966292
Iteration 2966, loss = 0.00965959
Iteration 2967, loss = 0.00965880
Iteration 2968, loss = 0.00965284
Iteration 2969, loss = 0.00965031
Iteration 2970, loss = 0.00964573
Iteration 2971, loss = 0.00964224
Iteration 2972, loss = 0.00963864
Iteration 2973, loss = 0.00963537
Iteration 2974, loss = 0.00963184
Iteration 2975, loss = 0.00962906
Iteration 2976, loss = 0.00962543
Iteration 2977, loss = 0.00962140
Iteration 2978, loss = 0.00961859
Iteration 2979, loss = 0.00961580
Iteration 2980, loss = 0.00961306
Iteration 2981, loss = 0.00960918
Iteration 2982, loss = 0.00960708
Iteration 2983, loss = 0.00960282
Iteration 2984, loss = 0.00959898
Iteration 2985, loss = 0.00959578
Iteration 2986, loss = 0.00959175
Iteration 2987, loss = 0.00958801
Iteration 2988, loss = 0.00958423
Iteration 2989, loss = 0.00958054
Iteration 2990, loss = 0.00957666
Iteration 2991, loss = 0.00957258
Iteration 2992, loss = 0.00957005
Iteration 2993, loss = 0.00956551
Iteration 2994, loss = 0.00956140
Iteration 2995, loss = 0.00955734
Iteration 2996, loss = 0.00955385
Iteration 2997, loss = 0.00955015
Iteration 2998, loss = 0.00954524
Iteration 2999, loss = 0.00954187
Iteration 3000, loss = 0.00953725
Iteration 3001, loss = 0.00953381
Iteration 3002, loss = 0.00952979
Iteration 3003, loss = 0.00952508
Iteration 3004, loss = 0.00952147
Iteration 3005, loss = 0.00951767
Iteration 3006, loss = 0.00951337
Iteration 3007, loss = 0.00950980
Iteration 3008, loss = 0.00950628
Iteration 3009, loss = 0.00950282
Iteration 3010, loss = 0.00949901
Iteration 3011, loss = 0.00949541
Iteration 3012, loss = 0.00949194
Iteration 3013, loss = 0.00948814
Iteration 3014, loss = 0.00948407
Iteration 3015, loss = 0.00948126
Iteration 3016, loss = 0.00947732
Iteration 3017, loss = 0.00947326
Iteration 3018, loss = 0.00946964
Iteration 3019, loss = 0.00946625
Iteration 3020, loss = 0.00946227
Iteration 3021, loss = 0.00945855
Iteration 3022, loss = 0.00945464
Iteration 3023, loss = 0.00944997
Iteration 3024, loss = 0.00944667
Iteration 3025, loss = 0.00944156
Iteration 3026, loss = 0.00943884
Iteration 3027, loss = 0.00943515
Iteration 3028, loss = 0.00942998
Iteration 3029, loss = 0.00942613
Iteration 3030, loss = 0.00942265
Iteration 3031, loss = 0.00941875
Iteration 3032, loss = 0.00941575
Iteration 3033, loss = 0.00941069
Iteration 3034, loss = 0.00940657
Iteration 3035, loss = 0.00940301
Iteration 3036, loss = 0.00939953
Iteration 3037, loss = 0.00939570
Iteration 3038, loss = 0.00939173
Iteration 3039, loss = 0.00938750
Iteration 3040, loss = 0.00938402
Iteration 3041, loss = 0.00937981
Iteration 3042, loss = 0.00937582
Iteration 3043, loss = 0.00937204
Iteration 3044, loss = 0.00936847
Iteration 3045, loss = 0.00936432
Iteration 3046, loss = 0.00936106
Iteration 3047, loss = 0.00935700
Iteration 3048, loss = 0.00935458
Iteration 3049, loss = 0.00935009
Iteration 3050, loss = 0.00934674
Iteration 3051, loss = 0.00934305
Iteration 3052, loss = 0.00933990
Iteration 3053, loss = 0.00933586
Iteration 3054, loss = 0.00933216
Iteration 3055, loss = 0.00932894
Iteration 3056, loss = 0.00932519
Iteration 3057, loss = 0.00932156
Iteration 3058, loss = 0.00931795
Iteration 3059, loss = 0.00931454
Iteration 3060, loss = 0.00931123
Iteration 3061, loss = 0.00930967
Iteration 3062, loss = 0.00930481
Iteration 3063, loss = 0.00930178
Iteration 3064, loss = 0.00929818
Iteration 3065, loss = 0.00929377
Iteration 3066, loss = 0.00929035
Iteration 3067, loss = 0.00928678
Iteration 3068, loss = 0.00928272
Iteration 3069, loss = 0.00927963
Iteration 3070, loss = 0.00927587
Iteration 3071, loss = 0.00927162
Iteration 3072, loss = 0.00926943
Iteration 3073, loss = 0.00926496
Iteration 3074, loss = 0.00926229
Iteration 3075, loss = 0.00925767
Iteration 3076, loss = 0.00925406
Iteration 3077, loss = 0.00925112
Iteration 3078, loss = 0.00924567
Iteration 3079, loss = 0.00924284
Iteration 3080, loss = 0.00923985
Iteration 3081, loss = 0.00923632
Iteration 3082, loss = 0.00923235
Iteration 3083, loss = 0.00923006
Iteration 3084, loss = 0.00922590
Iteration 3085, loss = 0.00922285
Iteration 3086, loss = 0.00921970
Iteration 3087, loss = 0.00921605
Iteration 3088, loss = 0.00921200
Iteration 3089, loss = 0.00920857
Iteration 3090, loss = 0.00920525
Iteration 3091, loss = 0.00920178
Iteration 3092, loss = 0.00919836
Iteration 3093, loss = 0.00919485
Iteration 3094, loss = 0.00919130
Iteration 3095, loss = 0.00918788
Iteration 3096, loss = 0.00918512
Iteration 3097, loss = 0.00918110
Iteration 3098, loss = 0.00917770
Iteration 3099, loss = 0.00917408
Iteration 3100, loss = 0.00917043
Iteration 3101, loss = 0.00916749
Iteration 3102, loss = 0.00916431
Iteration 3103, loss = 0.00916011
Iteration 3104, loss = 0.00915724
Iteration 3105, loss = 0.00915316
Iteration 3106, loss = 0.00915055
Iteration 3107, loss = 0.00914648
Iteration 3108, loss = 0.00914362
Iteration 3109, loss = 0.00913965
Iteration 3110, loss = 0.00913618
Iteration 3111, loss = 0.00913283
Iteration 3112, loss = 0.00912938
Iteration 3113, loss = 0.00912602
Iteration 3114, loss = 0.00912307
Iteration 3115, loss = 0.00911848
Iteration 3116, loss = 0.00911499
Iteration 3117, loss = 0.00911155
Iteration 3118, loss = 0.00910871
Iteration 3119, loss = 0.00910506
Iteration 3120, loss = 0.00910135
Iteration 3121, loss = 0.00909762
Iteration 3122, loss = 0.00909418
Iteration 3123, loss = 0.00909100
Iteration 3124, loss = 0.00908732
Iteration 3125, loss = 0.00908414
Iteration 3126, loss = 0.00908096
Iteration 3127, loss = 0.00907721
Iteration 3128, loss = 0.00907359
Iteration 3129, loss = 0.00907092
Iteration 3130, loss = 0.00906714
Iteration 3131, loss = 0.00906375
Iteration 3132, loss = 0.00906084
Iteration 3133, loss = 0.00905717
Iteration 3134, loss = 0.00905413
Iteration 3135, loss = 0.00905100
Iteration 3136, loss = 0.00904742
Iteration 3137, loss = 0.00904407
Iteration 3138, loss = 0.00904268
Iteration 3139, loss = 0.00903786
Iteration 3140, loss = 0.00903415
Iteration 3141, loss = 0.00903067
Iteration 3142, loss = 0.00902824
Iteration 3143, loss = 0.00902419
Iteration 3144, loss = 0.00902114
Iteration 3145, loss = 0.00901780
Iteration 3146, loss = 0.00901357
Iteration 3147, loss = 0.00900995
Iteration 3148, loss = 0.00900660
Iteration 3149, loss = 0.00900354
Iteration 3150, loss = 0.00900007
Iteration 3151, loss = 0.00899700
Iteration 3152, loss = 0.00899384
Iteration 3153, loss = 0.00899030
Iteration 3154, loss = 0.00898695
Iteration 3155, loss = 0.00898354
Iteration 3156, loss = 0.00897977
Iteration 3157, loss = 0.00897757
Iteration 3158, loss = 0.00897312
Iteration 3159, loss = 0.00896976
Iteration 3160, loss = 0.00896617
Iteration 3161, loss = 0.00896279
Iteration 3162, loss = 0.00895953
Iteration 3163, loss = 0.00895596
Iteration 3164, loss = 0.00895289
Iteration 3165, loss = 0.00894933
Iteration 3166, loss = 0.00894640
Iteration 3167, loss = 0.00894311
Iteration 3168, loss = 0.00893982
Iteration 3169, loss = 0.00893837
Iteration 3170, loss = 0.00893429
Iteration 3171, loss = 0.00893045
Iteration 3172, loss = 0.00892752
Iteration 3173, loss = 0.00892355
Iteration 3174, loss = 0.00892008
Iteration 3175, loss = 0.00891733
Iteration 3176, loss = 0.00891336
Iteration 3177, loss = 0.00891028
Iteration 3178, loss = 0.00890732
Iteration 3179, loss = 0.00890319
Iteration 3180, loss = 0.00890024
Iteration 3181, loss = 0.00889644
Iteration 3182, loss = 0.00889365
Iteration 3183, loss = 0.00888990
Iteration 3184, loss = 0.00888598
Iteration 3185, loss = 0.00888290
Iteration 3186, loss = 0.00887894
Iteration 3187, loss = 0.00887574
Iteration 3188, loss = 0.00887240
Iteration 3189, loss = 0.00886911
Iteration 3190, loss = 0.00886614
Iteration 3191, loss = 0.00886322
Iteration 3192, loss = 0.00885981
Iteration 3193, loss = 0.00885665
Iteration 3194, loss = 0.00885373
Iteration 3195, loss = 0.00885023
Iteration 3196, loss = 0.00884674
Iteration 3197, loss = 0.00884442
Iteration 3198, loss = 0.00884054
Iteration 3199, loss = 0.00883743
Iteration 3200, loss = 0.00883498
Iteration 3201, loss = 0.00883157
Iteration 3202, loss = 0.00882837
Iteration 3203, loss = 0.00882628
Iteration 3204, loss = 0.00882269
Iteration 3205, loss = 0.00881953
Iteration 3206, loss = 0.00881609
Iteration 3207, loss = 0.00881307
Iteration 3208, loss = 0.00880969
Iteration 3209, loss = 0.00880662
Iteration 3210, loss = 0.00880335
Iteration 3211, loss = 0.00880015
Iteration 3212, loss = 0.00879709
Iteration 3213, loss = 0.00879398
Iteration 3214, loss = 0.00879049
Iteration 3215, loss = 0.00878715
Iteration 3216, loss = 0.00878423
Iteration 3217, loss = 0.00878082
Iteration 3218, loss = 0.00877684
Iteration 3219, loss = 0.00877338
Iteration 3220, loss = 0.00877040
Iteration 3221, loss = 0.00876881
Iteration 3222, loss = 0.00876411
Iteration 3223, loss = 0.00876085
Iteration 3224, loss = 0.00875774
Iteration 3225, loss = 0.00875480
Iteration 3226, loss = 0.00875241
Iteration 3227, loss = 0.00874886
Iteration 3228, loss = 0.00874612
Iteration 3229, loss = 0.00874281
Iteration 3230, loss = 0.00874166
Iteration 3231, loss = 0.00873746
Iteration 3232, loss = 0.00873344
Iteration 3233, loss = 0.00873023
Iteration 3234, loss = 0.00872710
Iteration 3235, loss = 0.00872494
Iteration 3236, loss = 0.00872041
Iteration 3237, loss = 0.00871661
Iteration 3238, loss = 0.00871347
Iteration 3239, loss = 0.00871012
Iteration 3240, loss = 0.00870673
Iteration 3241, loss = 0.00870351
Iteration 3242, loss = 0.00870036
Iteration 3243, loss = 0.00869690
Iteration 3244, loss = 0.00869367
Iteration 3245, loss = 0.00869134
Iteration 3246, loss = 0.00868779
Iteration 3247, loss = 0.00868458
Iteration 3248, loss = 0.00868126
Iteration 3249, loss = 0.00867796
Iteration 3250, loss = 0.00867449
Iteration 3251, loss = 0.00867115
Iteration 3252, loss = 0.00866760
Iteration 3253, loss = 0.00866537
Iteration 3254, loss = 0.00866167
Iteration 3255, loss = 0.00865867
Iteration 3256, loss = 0.00865464
Iteration 3257, loss = 0.00865202
Iteration 3258, loss = 0.00864855
Iteration 3259, loss = 0.00864547
Iteration 3260, loss = 0.00864281
Iteration 3261, loss = 0.00863911
Iteration 3262, loss = 0.00863631
Iteration 3263, loss = 0.00863295
Iteration 3264, loss = 0.00863066
Iteration 3265, loss = 0.00862712
Iteration 3266, loss = 0.00862493
Iteration 3267, loss = 0.00862130
Iteration 3268, loss = 0.00861778
Iteration 3269, loss = 0.00861459
Iteration 3270, loss = 0.00861205
Iteration 3271, loss = 0.00860948
Iteration 3272, loss = 0.00860535
Iteration 3273, loss = 0.00860177
Iteration 3274, loss = 0.00859860
Iteration 3275, loss = 0.00859508
Iteration 3276, loss = 0.00859159
Iteration 3277, loss = 0.00859021
Iteration 3278, loss = 0.00858660
Iteration 3279, loss = 0.00858280
Iteration 3280, loss = 0.00857966
Iteration 3281, loss = 0.00857658
Iteration 3282, loss = 0.00857257
Iteration 3283, loss = 0.00857013
Iteration 3284, loss = 0.00856665
Iteration 3285, loss = 0.00856301
Iteration 3286, loss = 0.00855966
Iteration 3287, loss = 0.00855673
Iteration 3288, loss = 0.00855288
Iteration 3289, loss = 0.00855293
Iteration 3290, loss = 0.00854756
Iteration 3291, loss = 0.00854374
Iteration 3292, loss = 0.00854096
Iteration 3293, loss = 0.00853834
Iteration 3294, loss = 0.00853498
Iteration 3295, loss = 0.00853287
Iteration 3296, loss = 0.00852894
Iteration 3297, loss = 0.00852572
Iteration 3298, loss = 0.00852231
Iteration 3299, loss = 0.00851931
Iteration 3300, loss = 0.00851624
Iteration 3301, loss = 0.00851309
Iteration 3302, loss = 0.00850986
Iteration 3303, loss = 0.00850636
Iteration 3304, loss = 0.00850467
Iteration 3305, loss = 0.00850060
Iteration 3306, loss = 0.00849911
Iteration 3307, loss = 0.00849475
Iteration 3308, loss = 0.00849192
Iteration 3309, loss = 0.00848830
Iteration 3310, loss = 0.00848565
Iteration 3311, loss = 0.00848214
Iteration 3312, loss = 0.00847900
Iteration 3313, loss = 0.00847497
Iteration 3314, loss = 0.00847267
Iteration 3315, loss = 0.00846900
Iteration 3316, loss = 0.00846581
Iteration 3317, loss = 0.00846233
Iteration 3318, loss = 0.00845949
Iteration 3319, loss = 0.00845651
Iteration 3320, loss = 0.00845347
Iteration 3321, loss = 0.00845018
Iteration 3322, loss = 0.00844813
Iteration 3323, loss = 0.00844416
Iteration 3324, loss = 0.00844141
Iteration 3325, loss = 0.00843834
Iteration 3326, loss = 0.00843553
Iteration 3327, loss = 0.00843242
Iteration 3328, loss = 0.00842955
Iteration 3329, loss = 0.00842694
Iteration 3330, loss = 0.00842438
Iteration 3331, loss = 0.00842242
Iteration 3332, loss = 0.00841884
Iteration 3333, loss = 0.00841597
Iteration 3334, loss = 0.00841304
Iteration 3335, loss = 0.00841019
Iteration 3336, loss = 0.00840761
Iteration 3337, loss = 0.00840487
Iteration 3338, loss = 0.00840215
Iteration 3339, loss = 0.00839983
Iteration 3340, loss = 0.00839797
Iteration 3341, loss = 0.00839407
Iteration 3342, loss = 0.00839111
Iteration 3343, loss = 0.00838807
Iteration 3344, loss = 0.00838518
Iteration 3345, loss = 0.00838270
Iteration 3346, loss = 0.00838044
Iteration 3347, loss = 0.00837647
Iteration 3348, loss = 0.00837391
Iteration 3349, loss = 0.00837061
Iteration 3350, loss = 0.00836758
Iteration 3351, loss = 0.00836439
Iteration 3352, loss = 0.00836174
Iteration 3353, loss = 0.00835852
Iteration 3354, loss = 0.00835558
Iteration 3355, loss = 0.00835224
Iteration 3356, loss = 0.00834941
Iteration 3357, loss = 0.00834672
Iteration 3358, loss = 0.00834321
Iteration 3359, loss = 0.00834054
Iteration 3360, loss = 0.00833849
Iteration 3361, loss = 0.00833507
Iteration 3362, loss = 0.00833213
Iteration 3363, loss = 0.00832955
Iteration 3364, loss = 0.00832679
Iteration 3365, loss = 0.00832373
Iteration 3366, loss = 0.00832078
Iteration 3367, loss = 0.00832118
Iteration 3368, loss = 0.00831565
Iteration 3369, loss = 0.00831223
Iteration 3370, loss = 0.00830875
Iteration 3371, loss = 0.00830620
Iteration 3372, loss = 0.00830227
Iteration 3373, loss = 0.00830049
Iteration 3374, loss = 0.00829654
Iteration 3375, loss = 0.00829329
Iteration 3376, loss = 0.00829065
Iteration 3377, loss = 0.00828747
Iteration 3378, loss = 0.00828414
Iteration 3379, loss = 0.00828100
Iteration 3380, loss = 0.00827843
Iteration 3381, loss = 0.00827459
Iteration 3382, loss = 0.00827262
Iteration 3383, loss = 0.00826989
Iteration 3384, loss = 0.00826698
Iteration 3385, loss = 0.00826331
Iteration 3386, loss = 0.00826010
Iteration 3387, loss = 0.00825728
Iteration 3388, loss = 0.00825466
Iteration 3389, loss = 0.00825149
Iteration 3390, loss = 0.00824927
Iteration 3391, loss = 0.00824627
Iteration 3392, loss = 0.00824305
Iteration 3393, loss = 0.00824045
Iteration 3394, loss = 0.00823767
Iteration 3395, loss = 0.00823481
Iteration 3396, loss = 0.00823182
Iteration 3397, loss = 0.00823010
Iteration 3398, loss = 0.00822843
Iteration 3399, loss = 0.00822476
Iteration 3400, loss = 0.00822209
Iteration 3401, loss = 0.00821932
Iteration 3402, loss = 0.00821672
Iteration 3403, loss = 0.00821415
Iteration 3404, loss = 0.00821244
Iteration 3405, loss = 0.00820915
Iteration 3406, loss = 0.00820661
Iteration 3407, loss = 0.00820381
Iteration 3408, loss = 0.00820136
Iteration 3409, loss = 0.00819884
Iteration 3410, loss = 0.00819618
Iteration 3411, loss = 0.00819389
Iteration 3412, loss = 0.00819155
Iteration 3413, loss = 0.00818922
Iteration 3414, loss = 0.00818654
Iteration 3415, loss = 0.00818431
Iteration 3416, loss = 0.00818142
Iteration 3417, loss = 0.00817902
Iteration 3418, loss = 0.00817755
Iteration 3419, loss = 0.00817430
Iteration 3420, loss = 0.00817183
Iteration 3421, loss = 0.00816898
Iteration 3422, loss = 0.00816657
Iteration 3423, loss = 0.00816423
Iteration 3424, loss = 0.00816190
Iteration 3425, loss = 0.00815949
Iteration 3426, loss = 0.00815846
Iteration 3427, loss = 0.00815511
Iteration 3428, loss = 0.00815229
Iteration 3429, loss = 0.00814942
Iteration 3430, loss = 0.00814719
Iteration 3431, loss = 0.00814457
Iteration 3432, loss = 0.00814130
Iteration 3433, loss = 0.00813786
Iteration 3434, loss = 0.00813474
Iteration 3435, loss = 0.00813065
Iteration 3436, loss = 0.00812702
Iteration 3437, loss = 0.00812338
Iteration 3438, loss = 0.00812062
Iteration 3439, loss = 0.00811722
Iteration 3440, loss = 0.00811392
Iteration 3441, loss = 0.00811052
Iteration 3442, loss = 0.00810778
Iteration 3443, loss = 0.00810472
Iteration 3444, loss = 0.00810174
Iteration 3445, loss = 0.00809854
Iteration 3446, loss = 0.00809605
Iteration 3447, loss = 0.00809268
Iteration 3448, loss = 0.00809005
Iteration 3449, loss = 0.00808752
Iteration 3450, loss = 0.00808447
Iteration 3451, loss = 0.00808189
Iteration 3452, loss = 0.00807943
Iteration 3453, loss = 0.00807664
Iteration 3454, loss = 0.00807393
Iteration 3455, loss = 0.00807138
Iteration 3456, loss = 0.00806886
Iteration 3457, loss = 0.00806699
Iteration 3458, loss = 0.00806324
Iteration 3459, loss = 0.00806077
Iteration 3460, loss = 0.00805772
Iteration 3461, loss = 0.00805453
Iteration 3462, loss = 0.00805187
Iteration 3463, loss = 0.00804927
Iteration 3464, loss = 0.00804701
Iteration 3465, loss = 0.00804406
Iteration 3466, loss = 0.00804242
Iteration 3467, loss = 0.00803915
Iteration 3468, loss = 0.00803599
Iteration 3469, loss = 0.00803258
Iteration 3470, loss = 0.00803051
Iteration 3471, loss = 0.00802648
Iteration 3472, loss = 0.00802264
Iteration 3473, loss = 0.00802117
Iteration 3474, loss = 0.00801611
Iteration 3475, loss = 0.00801375
Iteration 3476, loss = 0.00801094
Iteration 3477, loss = 0.00800736
Iteration 3478, loss = 0.00800555
Iteration 3479, loss = 0.00800236
Iteration 3480, loss = 0.00799904
Iteration 3481, loss = 0.00799690
Iteration 3482, loss = 0.00799391
Iteration 3483, loss = 0.00799123
Iteration 3484, loss = 0.00798830
Iteration 3485, loss = 0.00798721
Iteration 3486, loss = 0.00798327
Iteration 3487, loss = 0.00798018
Iteration 3488, loss = 0.00797754
Iteration 3489, loss = 0.00797460
Iteration 3490, loss = 0.00797323
Iteration 3491, loss = 0.00796987
Iteration 3492, loss = 0.00796704
Iteration 3493, loss = 0.00796371
Iteration 3494, loss = 0.00796092
Iteration 3495, loss = 0.00795820
Iteration 3496, loss = 0.00795546
Iteration 3497, loss = 0.00795255
Iteration 3498, loss = 0.00795010
Iteration 3499, loss = 0.00794677
Iteration 3500, loss = 0.00794354
Iteration 3501, loss = 0.00794045
Iteration 3502, loss = 0.00793699
Iteration 3503, loss = 0.00793516
Iteration 3504, loss = 0.00793124
Iteration 3505, loss = 0.00792871
Iteration 3506, loss = 0.00792580
Iteration 3507, loss = 0.00792290
Iteration 3508, loss = 0.00792020
Iteration 3509, loss = 0.00791755
Iteration 3510, loss = 0.00791510
Iteration 3511, loss = 0.00791192
Iteration 3512, loss = 0.00790943
Iteration 3513, loss = 0.00790650
Iteration 3514, loss = 0.00790532
Iteration 3515, loss = 0.00790127
Iteration 3516, loss = 0.00789908
Iteration 3517, loss = 0.00789603
Iteration 3518, loss = 0.00789351
Iteration 3519, loss = 0.00789116
Iteration 3520, loss = 0.00788865
Iteration 3521, loss = 0.00788768
Iteration 3522, loss = 0.00788364
Iteration 3523, loss = 0.00788085
Iteration 3524, loss = 0.00787847
Iteration 3525, loss = 0.00787502
Iteration 3526, loss = 0.00787274
Iteration 3527, loss = 0.00787011
Iteration 3528, loss = 0.00786616
Iteration 3529, loss = 0.00786352
Iteration 3530, loss = 0.00786131
Iteration 3531, loss = 0.00785807
Iteration 3532, loss = 0.00785581
Iteration 3533, loss = 0.00785286
Iteration 3534, loss = 0.00785015
Iteration 3535, loss = 0.00784767
Iteration 3536, loss = 0.00784582
Iteration 3537, loss = 0.00784387
Iteration 3538, loss = 0.00784044
Iteration 3539, loss = 0.00783653
Iteration 3540, loss = 0.00783467
Iteration 3541, loss = 0.00783135
Iteration 3542, loss = 0.00782848
Iteration 3543, loss = 0.00782598
Iteration 3544, loss = 0.00782263
Iteration 3545, loss = 0.00781953
Iteration 3546, loss = 0.00781739
Iteration 3547, loss = 0.00781387
Iteration 3548, loss = 0.00781163
Iteration 3549, loss = 0.00780814
Iteration 3550, loss = 0.00780602
Iteration 3551, loss = 0.00780206
Iteration 3552, loss = 0.00780109
Iteration 3553, loss = 0.00779606
Iteration 3554, loss = 0.00779330
Iteration 3555, loss = 0.00779052
Iteration 3556, loss = 0.00778791
Iteration 3557, loss = 0.00778491
Iteration 3558, loss = 0.00778237
Iteration 3559, loss = 0.00777969
Iteration 3560, loss = 0.00777725
Iteration 3561, loss = 0.00777474
Iteration 3562, loss = 0.00777190
Iteration 3563, loss = 0.00776929
Iteration 3564, loss = 0.00776678
Iteration 3565, loss = 0.00776503
Iteration 3566, loss = 0.00776182
Iteration 3567, loss = 0.00775911
Iteration 3568, loss = 0.00775705
Iteration 3569, loss = 0.00775459
Iteration 3570, loss = 0.00775252
Iteration 3571, loss = 0.00774988
Iteration 3572, loss = 0.00774719
Iteration 3573, loss = 0.00774509
Iteration 3574, loss = 0.00774232
Iteration 3575, loss = 0.00773995
Iteration 3576, loss = 0.00773731
Iteration 3577, loss = 0.00773502
Iteration 3578, loss = 0.00773244
Iteration 3579, loss = 0.00772964
Iteration 3580, loss = 0.00772702
Iteration 3581, loss = 0.00772496
Iteration 3582, loss = 0.00772204
Iteration 3583, loss = 0.00771947
Iteration 3584, loss = 0.00771742
Iteration 3585, loss = 0.00771494
Iteration 3586, loss = 0.00771345
Iteration 3587, loss = 0.00771058
Iteration 3588, loss = 0.00770849
Iteration 3589, loss = 0.00770709
Iteration 3590, loss = 0.00770428
Iteration 3591, loss = 0.00770185
Iteration 3592, loss = 0.00769905
Iteration 3593, loss = 0.00769630
Iteration 3594, loss = 0.00769379
Iteration 3595, loss = 0.00769121
Iteration 3596, loss = 0.00768926
Iteration 3597, loss = 0.00768677
Iteration 3598, loss = 0.00768510
Iteration 3599, loss = 0.00768329
Iteration 3600, loss = 0.00768094
Iteration 3601, loss = 0.00767885
Iteration 3602, loss = 0.00767642
Iteration 3603, loss = 0.00767437
Iteration 3604, loss = 0.00767167
Iteration 3605, loss = 0.00766882
Iteration 3606, loss = 0.00766568
Iteration 3607, loss = 0.00766336
Iteration 3608, loss = 0.00766056
Iteration 3609, loss = 0.00765795
Iteration 3610, loss = 0.00765527
Iteration 3611, loss = 0.00765289
Iteration 3612, loss = 0.00765064
Iteration 3613, loss = 0.00764854
Iteration 3614, loss = 0.00764624
Iteration 3615, loss = 0.00764382
Iteration 3616, loss = 0.00764092
Iteration 3617, loss = 0.00763832
Iteration 3618, loss = 0.00763584
Iteration 3619, loss = 0.00763271
Iteration 3620, loss = 0.00762989
Iteration 3621, loss = 0.00762727
Iteration 3622, loss = 0.00762489
Iteration 3623, loss = 0.00762202
Iteration 3624, loss = 0.00761994
Iteration 3625, loss = 0.00761687
Iteration 3626, loss = 0.00761392
Iteration 3627, loss = 0.00761170
Iteration 3628, loss = 0.00760965
Iteration 3629, loss = 0.00760628
Iteration 3630, loss = 0.00760426
Iteration 3631, loss = 0.00760095
Iteration 3632, loss = 0.00759900
Iteration 3633, loss = 0.00759630
Iteration 3634, loss = 0.00759318
Iteration 3635, loss = 0.00759077
Iteration 3636, loss = 0.00758838
Iteration 3637, loss = 0.00758560
Iteration 3638, loss = 0.00758325
Iteration 3639, loss = 0.00758057
Iteration 3640, loss = 0.00757798
Iteration 3641, loss = 0.00757551
Iteration 3642, loss = 0.00757311
Iteration 3643, loss = 0.00757096
Iteration 3644, loss = 0.00756858
Iteration 3645, loss = 0.00756629
Iteration 3646, loss = 0.00756339
Iteration 3647, loss = 0.00756033
Iteration 3648, loss = 0.00755752
Iteration 3649, loss = 0.00755523
Iteration 3650, loss = 0.00755170
Iteration 3651, loss = 0.00754856
Iteration 3652, loss = 0.00754747
Iteration 3653, loss = 0.00754308
Iteration 3654, loss = 0.00754149
Iteration 3655, loss = 0.00753735
Iteration 3656, loss = 0.00753458
Iteration 3657, loss = 0.00753380
Iteration 3658, loss = 0.00752924
Iteration 3659, loss = 0.00752733
Iteration 3660, loss = 0.00752410
Iteration 3661, loss = 0.00752100
Iteration 3662, loss = 0.00751858
Iteration 3663, loss = 0.00751592
Iteration 3664, loss = 0.00751319
Iteration 3665, loss = 0.00751058
Iteration 3666, loss = 0.00750865
Iteration 3667, loss = 0.00750598
Iteration 3668, loss = 0.00750327
Iteration 3669, loss = 0.00750087
Iteration 3670, loss = 0.00749849
Iteration 3671, loss = 0.00749603
Iteration 3672, loss = 0.00749390
Iteration 3673, loss = 0.00749152
Iteration 3674, loss = 0.00748987
Iteration 3675, loss = 0.00748746
Iteration 3676, loss = 0.00748502
Iteration 3677, loss = 0.00748239
Iteration 3678, loss = 0.00747996
Iteration 3679, loss = 0.00747746
Iteration 3680, loss = 0.00747475
Iteration 3681, loss = 0.00747342
Iteration 3682, loss = 0.00746984
Iteration 3683, loss = 0.00746737
Iteration 3684, loss = 0.00746483
Iteration 3685, loss = 0.00746221
Iteration 3686, loss = 0.00745952
Iteration 3687, loss = 0.00745708
Iteration 3688, loss = 0.00745450
Iteration 3689, loss = 0.00745204
Iteration 3690, loss = 0.00744920
Iteration 3691, loss = 0.00744754
Iteration 3692, loss = 0.00744521
Iteration 3693, loss = 0.00744246
Iteration 3694, loss = 0.00744046
Iteration 3695, loss = 0.00743812
Iteration 3696, loss = 0.00743904
Iteration 3697, loss = 0.00743404
Iteration 3698, loss = 0.00743127
Iteration 3699, loss = 0.00742881
Iteration 3700, loss = 0.00742691
Iteration 3701, loss = 0.00742380
Iteration 3702, loss = 0.00742164
Iteration 3703, loss = 0.00741971
Iteration 3704, loss = 0.00741635
Iteration 3705, loss = 0.00741342
Iteration 3706, loss = 0.00741097
Iteration 3707, loss = 0.00740856
Iteration 3708, loss = 0.00740536
Iteration 3709, loss = 0.00740271
Iteration 3710, loss = 0.00740048
Iteration 3711, loss = 0.00739817
Iteration 3712, loss = 0.00739520
Iteration 3713, loss = 0.00739298
Iteration 3714, loss = 0.00739021
Iteration 3715, loss = 0.00738743
Iteration 3716, loss = 0.00738475
Iteration 3717, loss = 0.00738248
Iteration 3718, loss = 0.00737986
Iteration 3719, loss = 0.00737739
Iteration 3720, loss = 0.00737470
Iteration 3721, loss = 0.00737202
Iteration 3722, loss = 0.00737008
Iteration 3723, loss = 0.00736714
Iteration 3724, loss = 0.00736454
Iteration 3725, loss = 0.00736220
Iteration 3726, loss = 0.00735952
Iteration 3727, loss = 0.00735680
Iteration 3728, loss = 0.00735576
Iteration 3729, loss = 0.00735201
Iteration 3730, loss = 0.00734969
Iteration 3731, loss = 0.00734703
Iteration 3732, loss = 0.00734471
Iteration 3733, loss = 0.00734207
Iteration 3734, loss = 0.00734002
Iteration 3735, loss = 0.00733751
Iteration 3736, loss = 0.00733502
Iteration 3737, loss = 0.00733245
Iteration 3738, loss = 0.00733064
Iteration 3739, loss = 0.00732756
Iteration 3740, loss = 0.00732511
Iteration 3741, loss = 0.00732279
Iteration 3742, loss = 0.00732006
Iteration 3743, loss = 0.00731798
Iteration 3744, loss = 0.00731482
Iteration 3745, loss = 0.00731224
Iteration 3746, loss = 0.00730987
Iteration 3747, loss = 0.00730719
Iteration 3748, loss = 0.00730487
Iteration 3749, loss = 0.00730236
Iteration 3750, loss = 0.00729974
Iteration 3751, loss = 0.00729705
Iteration 3752, loss = 0.00729620
Iteration 3753, loss = 0.00729285
Iteration 3754, loss = 0.00729079
Iteration 3755, loss = 0.00728809
Iteration 3756, loss = 0.00728640
Iteration 3757, loss = 0.00728328
Iteration 3758, loss = 0.00728108
Iteration 3759, loss = 0.00727884
Iteration 3760, loss = 0.00727639
Iteration 3761, loss = 0.00727392
Iteration 3762, loss = 0.00727297
Iteration 3763, loss = 0.00726975
Iteration 3764, loss = 0.00726712
Iteration 3765, loss = 0.00726490
Iteration 3766, loss = 0.00726278
Iteration 3767, loss = 0.00726042
Iteration 3768, loss = 0.00725785
Iteration 3769, loss = 0.00725526
Iteration 3770, loss = 0.00725326
Iteration 3771, loss = 0.00725067
Iteration 3772, loss = 0.00724928
Iteration 3773, loss = 0.00724589
Iteration 3774, loss = 0.00724387
Iteration 3775, loss = 0.00724111
Iteration 3776, loss = 0.00723885
Iteration 3777, loss = 0.00723527
Iteration 3778, loss = 0.00723363
Iteration 3779, loss = 0.00723197
Iteration 3780, loss = 0.00722955
Iteration 3781, loss = 0.00722683
Iteration 3782, loss = 0.00722610
Iteration 3783, loss = 0.00722312
Iteration 3784, loss = 0.00721983
Iteration 3785, loss = 0.00721747
Iteration 3786, loss = 0.00721605
Iteration 3787, loss = 0.00721253
Iteration 3788, loss = 0.00720937
Iteration 3789, loss = 0.00720720
Iteration 3790, loss = 0.00720438
Iteration 3791, loss = 0.00720186
Iteration 3792, loss = 0.00719952
Iteration 3793, loss = 0.00719750
Iteration 3794, loss = 0.00719441
Iteration 3795, loss = 0.00719181
Iteration 3796, loss = 0.00718981
Iteration 3797, loss = 0.00718726
Iteration 3798, loss = 0.00718498
Iteration 3799, loss = 0.00718256
Iteration 3800, loss = 0.00718047
Iteration 3801, loss = 0.00717794
Iteration 3802, loss = 0.00717652
Iteration 3803, loss = 0.00717377
Iteration 3804, loss = 0.00717122
Iteration 3805, loss = 0.00716886
Iteration 3806, loss = 0.00716638
Iteration 3807, loss = 0.00716387
Iteration 3808, loss = 0.00716235
Iteration 3809, loss = 0.00715949
Iteration 3810, loss = 0.00715637
Iteration 3811, loss = 0.00715429
Iteration 3812, loss = 0.00715197
Iteration 3813, loss = 0.00714928
Iteration 3814, loss = 0.00714687
Iteration 3815, loss = 0.00714449
Iteration 3816, loss = 0.00714282
Iteration 3817, loss = 0.00714005
Iteration 3818, loss = 0.00713786
Iteration 3819, loss = 0.00713568
Iteration 3820, loss = 0.00713345
Iteration 3821, loss = 0.00713086
Iteration 3822, loss = 0.00712871
Iteration 3823, loss = 0.00712644
Iteration 3824, loss = 0.00712447
Iteration 3825, loss = 0.00712205
Iteration 3826, loss = 0.00712086
Iteration 3827, loss = 0.00711830
Iteration 3828, loss = 0.00711568
Iteration 3829, loss = 0.00711366
Iteration 3830, loss = 0.00711095
Iteration 3831, loss = 0.00710890
Iteration 3832, loss = 0.00710642
Iteration 3833, loss = 0.00710405
Iteration 3834, loss = 0.00710157
Iteration 3835, loss = 0.00709927
Iteration 3836, loss = 0.00709673
Iteration 3837, loss = 0.00709528
Iteration 3838, loss = 0.00709247
Iteration 3839, loss = 0.00708942
Iteration 3840, loss = 0.00708776
Iteration 3841, loss = 0.00708564
Iteration 3842, loss = 0.00708292
Iteration 3843, loss = 0.00708043
Iteration 3844, loss = 0.00707789
Iteration 3845, loss = 0.00707590
Iteration 3846, loss = 0.00707338
Iteration 3847, loss = 0.00707100
Iteration 3848, loss = 0.00706912
Iteration 3849, loss = 0.00706707
Iteration 3850, loss = 0.00706429
Iteration 3851, loss = 0.00706285
Iteration 3852, loss = 0.00706015
Iteration 3853, loss = 0.00705892
Iteration 3854, loss = 0.00705597
Iteration 3855, loss = 0.00705357
Iteration 3856, loss = 0.00705154
Iteration 3857, loss = 0.00704899
Iteration 3858, loss = 0.00704614
Iteration 3859, loss = 0.00704376
Iteration 3860, loss = 0.00704209
Iteration 3861, loss = 0.00703950
Iteration 3862, loss = 0.00703677
Iteration 3863, loss = 0.00703461
Iteration 3864, loss = 0.00703213
Iteration 3865, loss = 0.00702968
Iteration 3866, loss = 0.00702747
Iteration 3867, loss = 0.00702526
Iteration 3868, loss = 0.00702311
Iteration 3869, loss = 0.00702100
Iteration 3870, loss = 0.00701905
Iteration 3871, loss = 0.00701662
Iteration 3872, loss = 0.00701447
Iteration 3873, loss = 0.00701231
Iteration 3874, loss = 0.00700986
Iteration 3875, loss = 0.00700753
Iteration 3876, loss = 0.00700564
Iteration 3877, loss = 0.00700336
Iteration 3878, loss = 0.00700092
Iteration 3879, loss = 0.00699912
Iteration 3880, loss = 0.00699712
Iteration 3881, loss = 0.00699486
Iteration 3882, loss = 0.00699242
Iteration 3883, loss = 0.00699018
Iteration 3884, loss = 0.00698792
Iteration 3885, loss = 0.00698619
Iteration 3886, loss = 0.00698386
Iteration 3887, loss = 0.00698183
Iteration 3888, loss = 0.00697972
Iteration 3889, loss = 0.00697761
Iteration 3890, loss = 0.00697581
Iteration 3891, loss = 0.00697347
Iteration 3892, loss = 0.00697154
Iteration 3893, loss = 0.00696965
Iteration 3894, loss = 0.00696689
Iteration 3895, loss = 0.00696453
Iteration 3896, loss = 0.00696227
Iteration 3897, loss = 0.00695987
Iteration 3898, loss = 0.00695797
Iteration 3899, loss = 0.00695535
Iteration 3900, loss = 0.00695322
Iteration 3901, loss = 0.00695125
Iteration 3902, loss = 0.00694968
Iteration 3903, loss = 0.00694662
Iteration 3904, loss = 0.00694456
Iteration 3905, loss = 0.00694279
Iteration 3906, loss = 0.00694010
Iteration 3907, loss = 0.00693811
Iteration 3908, loss = 0.00693558
Iteration 3909, loss = 0.00693346
Iteration 3910, loss = 0.00693120
Iteration 3911, loss = 0.00692873
Iteration 3912, loss = 0.00692601
Iteration 3913, loss = 0.00692478
Iteration 3914, loss = 0.00692251
Iteration 3915, loss = 0.00691980
Iteration 3916, loss = 0.00691733
Iteration 3917, loss = 0.00691490
Iteration 3918, loss = 0.00691281
Iteration 3919, loss = 0.00691072
Iteration 3920, loss = 0.00690886
Iteration 3921, loss = 0.00690631
Iteration 3922, loss = 0.00690412
Iteration 3923, loss = 0.00690354
Iteration 3924, loss = 0.00689991
Iteration 3925, loss = 0.00689740
Iteration 3926, loss = 0.00689498
Iteration 3927, loss = 0.00689324
Iteration 3928, loss = 0.00689178
Iteration 3929, loss = 0.00688846
Iteration 3930, loss = 0.00688546
Iteration 3931, loss = 0.00688379
Iteration 3932, loss = 0.00688089
Iteration 3933, loss = 0.00687837
Iteration 3934, loss = 0.00687587
Iteration 3935, loss = 0.00687347
Iteration 3936, loss = 0.00687149
Iteration 3937, loss = 0.00687077
Iteration 3938, loss = 0.00686704
Iteration 3939, loss = 0.00686493
Iteration 3940, loss = 0.00686304
Iteration 3941, loss = 0.00686111
Iteration 3942, loss = 0.00685898
Iteration 3943, loss = 0.00685664
Iteration 3944, loss = 0.00685451
Iteration 3945, loss = 0.00685277
Iteration 3946, loss = 0.00685062
Iteration 3947, loss = 0.00684890
Iteration 3948, loss = 0.00684672
Iteration 3949, loss = 0.00684475
Iteration 3950, loss = 0.00684289
Iteration 3951, loss = 0.00684086
Iteration 3952, loss = 0.00683930
Iteration 3953, loss = 0.00683716
Iteration 3954, loss = 0.00683671
Iteration 3955, loss = 0.00683349
Iteration 3956, loss = 0.00683172
Iteration 3957, loss = 0.00683001
Iteration 3958, loss = 0.00682823
Iteration 3959, loss = 0.00682630
Iteration 3960, loss = 0.00682484
Iteration 3961, loss = 0.00682281
Iteration 3962, loss = 0.00682121
Iteration 3963, loss = 0.00681903
Iteration 3964, loss = 0.00681695
Iteration 3965, loss = 0.00681457
Iteration 3966, loss = 0.00681270
Iteration 3967, loss = 0.00681101
Iteration 3968, loss = 0.00680748
Iteration 3969, loss = 0.00680614
Iteration 3970, loss = 0.00680284
Iteration 3971, loss = 0.00680156
Iteration 3972, loss = 0.00679942
Iteration 3973, loss = 0.00679673
Iteration 3974, loss = 0.00679460
Iteration 3975, loss = 0.00679193
Iteration 3976, loss = 0.00678978
Iteration 3977, loss = 0.00678818
Iteration 3978, loss = 0.00678604
Iteration 3979, loss = 0.00678375
Iteration 3980, loss = 0.00678171
Iteration 3981, loss = 0.00677970
Iteration 3982, loss = 0.00677778
Iteration 3983, loss = 0.00677561
Iteration 3984, loss = 0.00677374
Iteration 3985, loss = 0.00677136
Iteration 3986, loss = 0.00676898
Iteration 3987, loss = 0.00676714
Iteration 3988, loss = 0.00676503
Iteration 3989, loss = 0.00676268
Iteration 3990, loss = 0.00676064
Iteration 3991, loss = 0.00675843
Iteration 3992, loss = 0.00675631
Iteration 3993, loss = 0.00675405
Iteration 3994, loss = 0.00675200
Iteration 3995, loss = 0.00674927
Iteration 3996, loss = 0.00674739
Iteration 3997, loss = 0.00674483
Iteration 3998, loss = 0.00674325
Iteration 3999, loss = 0.00674067
Iteration 4000, loss = 0.00673843
Iteration 4001, loss = 0.00673683
Iteration 4002, loss = 0.00673436
Iteration 4003, loss = 0.00673244
Iteration 4004, loss = 0.00673096
Iteration 4005, loss = 0.00672861
Iteration 4006, loss = 0.00672620
Iteration 4007, loss = 0.00672381
Iteration 4008, loss = 0.00672179
Iteration 4009, loss = 0.00672030
Iteration 4010, loss = 0.00671771
Iteration 4011, loss = 0.00671537
Iteration 4012, loss = 0.00671342
Iteration 4013, loss = 0.00671127
Iteration 4014, loss = 0.00670955
Iteration 4015, loss = 0.00670737
Iteration 4016, loss = 0.00670501
Iteration 4017, loss = 0.00670329
Iteration 4018, loss = 0.00670110
Iteration 4019, loss = 0.00669867
Iteration 4020, loss = 0.00669710
Iteration 4021, loss = 0.00669508
Iteration 4022, loss = 0.00669312
Iteration 4023, loss = 0.00669084
Iteration 4024, loss = 0.00668872
Iteration 4025, loss = 0.00668674
Iteration 4026, loss = 0.00668501
Iteration 4027, loss = 0.00668276
Iteration 4028, loss = 0.00668087
Iteration 4029, loss = 0.00667989
Iteration 4030, loss = 0.00667718
Iteration 4031, loss = 0.00667527
Iteration 4032, loss = 0.00667327
Iteration 4033, loss = 0.00667133
Iteration 4034, loss = 0.00666948
Iteration 4035, loss = 0.00666729
Iteration 4036, loss = 0.00666566
Iteration 4037, loss = 0.00666300
Iteration 4038, loss = 0.00666095
Iteration 4039, loss = 0.00665885
Iteration 4040, loss = 0.00665673
Iteration 4041, loss = 0.00665483
Iteration 4042, loss = 0.00665286
Iteration 4043, loss = 0.00665114
Iteration 4044, loss = 0.00664874
Iteration 4045, loss = 0.00664654
Iteration 4046, loss = 0.00664495
Iteration 4047, loss = 0.00664245
Iteration 4048, loss = 0.00664019
Iteration 4049, loss = 0.00663887
Iteration 4050, loss = 0.00663627
Iteration 4051, loss = 0.00663438
Iteration 4052, loss = 0.00663194
Iteration 4053, loss = 0.00662983
Iteration 4054, loss = 0.00662791
Iteration 4055, loss = 0.00662611
Iteration 4056, loss = 0.00662396
Iteration 4057, loss = 0.00662226
Iteration 4058, loss = 0.00661987
Iteration 4059, loss = 0.00661803
Iteration 4060, loss = 0.00661667
Iteration 4061, loss = 0.00661435
Iteration 4062, loss = 0.00661247
Iteration 4063, loss = 0.00661061
Iteration 4064, loss = 0.00660873
Iteration 4065, loss = 0.00660679
Iteration 4066, loss = 0.00660549
Iteration 4067, loss = 0.00660327
Iteration 4068, loss = 0.00660139
Iteration 4069, loss = 0.00659952
Iteration 4070, loss = 0.00659781
Iteration 4071, loss = 0.00659571
Iteration 4072, loss = 0.00659394
Iteration 4073, loss = 0.00659243
Iteration 4074, loss = 0.00659137
Iteration 4075, loss = 0.00658889
Iteration 4076, loss = 0.00658738
Iteration 4077, loss = 0.00658554
Iteration 4078, loss = 0.00658337
Iteration 4079, loss = 0.00658143
Iteration 4080, loss = 0.00657975
Iteration 4081, loss = 0.00657829
Iteration 4082, loss = 0.00657601
Iteration 4083, loss = 0.00657344
Iteration 4084, loss = 0.00657148
Iteration 4085, loss = 0.00656920
Iteration 4086, loss = 0.00656733
Iteration 4087, loss = 0.00656581
Iteration 4088, loss = 0.00656381
Iteration 4089, loss = 0.00656171
Iteration 4090, loss = 0.00655982
Iteration 4091, loss = 0.00655751
Iteration 4092, loss = 0.00655583
Iteration 4093, loss = 0.00655395
Iteration 4094, loss = 0.00655238
Iteration 4095, loss = 0.00655037
Iteration 4096, loss = 0.00654815
Iteration 4097, loss = 0.00654642
Iteration 4098, loss = 0.00654528
Iteration 4099, loss = 0.00654295
Iteration 4100, loss = 0.00654107
Iteration 4101, loss = 0.00653975
Iteration 4102, loss = 0.00653763
Iteration 4103, loss = 0.00653574
Iteration 4104, loss = 0.00653372
Iteration 4105, loss = 0.00653190
Iteration 4106, loss = 0.00653077
Iteration 4107, loss = 0.00652804
Iteration 4108, loss = 0.00652677
Iteration 4109, loss = 0.00652310
Iteration 4110, loss = 0.00652169
Iteration 4111, loss = 0.00651868
Iteration 4112, loss = 0.00651632
Iteration 4113, loss = 0.00651478
Iteration 4114, loss = 0.00651195
Iteration 4115, loss = 0.00650984
Iteration 4116, loss = 0.00650710
Iteration 4117, loss = 0.00650594
Iteration 4118, loss = 0.00650327
Iteration 4119, loss = 0.00650069
Iteration 4120, loss = 0.00649842
Iteration 4121, loss = 0.00649627
Iteration 4122, loss = 0.00649431
Iteration 4123, loss = 0.00649332
Iteration 4124, loss = 0.00649049
Iteration 4125, loss = 0.00648853
Iteration 4126, loss = 0.00648668
Iteration 4127, loss = 0.00648452
Iteration 4128, loss = 0.00648263
Iteration 4129, loss = 0.00648081
Iteration 4130, loss = 0.00647933
Iteration 4131, loss = 0.00647763
Iteration 4132, loss = 0.00647578
Iteration 4133, loss = 0.00647402
Iteration 4134, loss = 0.00647218
Iteration 4135, loss = 0.00647044
Iteration 4136, loss = 0.00646940
Iteration 4137, loss = 0.00646701
Iteration 4138, loss = 0.00646534
Iteration 4139, loss = 0.00646297
Iteration 4140, loss = 0.00646079
Iteration 4141, loss = 0.00646019
Iteration 4142, loss = 0.00645692
Iteration 4143, loss = 0.00645437
Iteration 4144, loss = 0.00645201
Iteration 4145, loss = 0.00645049
Iteration 4146, loss = 0.00644807
Iteration 4147, loss = 0.00644602
Iteration 4148, loss = 0.00644480
Iteration 4149, loss = 0.00644201
Iteration 4150, loss = 0.00644017
Iteration 4151, loss = 0.00643850
Iteration 4152, loss = 0.00643643
Iteration 4153, loss = 0.00643449
Iteration 4154, loss = 0.00643262
Iteration 4155, loss = 0.00643111
Iteration 4156, loss = 0.00642901
Iteration 4157, loss = 0.00642724
Iteration 4158, loss = 0.00642568
Iteration 4159, loss = 0.00642396
Iteration 4160, loss = 0.00642208
Iteration 4161, loss = 0.00642057
Iteration 4162, loss = 0.00641852
Iteration 4163, loss = 0.00641661
Iteration 4164, loss = 0.00641501
Iteration 4165, loss = 0.00641264
Iteration 4166, loss = 0.00641120
Iteration 4167, loss = 0.00640901
Iteration 4168, loss = 0.00640737
Iteration 4169, loss = 0.00640550
Iteration 4170, loss = 0.00640320
Iteration 4171, loss = 0.00640156
Iteration 4172, loss = 0.00639960
Iteration 4173, loss = 0.00639764
Iteration 4174, loss = 0.00639641
Iteration 4175, loss = 0.00639419
Iteration 4176, loss = 0.00639240
Iteration 4177, loss = 0.00639076
Iteration 4178, loss = 0.00638858
Iteration 4179, loss = 0.00638676
Iteration 4180, loss = 0.00638501
Iteration 4181, loss = 0.00638342
Iteration 4182, loss = 0.00638287
Iteration 4183, loss = 0.00638053
Iteration 4184, loss = 0.00637836
Iteration 4185, loss = 0.00637727
Iteration 4186, loss = 0.00637481
Iteration 4187, loss = 0.00637298
Iteration 4188, loss = 0.00637107
Iteration 4189, loss = 0.00636952
Iteration 4190, loss = 0.00636712
Iteration 4191, loss = 0.00636530
Iteration 4192, loss = 0.00636354
Iteration 4193, loss = 0.00636152
Iteration 4194, loss = 0.00635957
Iteration 4195, loss = 0.00635772
Iteration 4196, loss = 0.00635677
Iteration 4197, loss = 0.00635349
Iteration 4198, loss = 0.00635120
Iteration 4199, loss = 0.00634875
Iteration 4200, loss = 0.00634811
Iteration 4201, loss = 0.00634411
Iteration 4202, loss = 0.00634200
Iteration 4203, loss = 0.00634067
Iteration 4204, loss = 0.00633901
Iteration 4205, loss = 0.00633615
Iteration 4206, loss = 0.00633417
Iteration 4207, loss = 0.00633235
Iteration 4208, loss = 0.00633061
Iteration 4209, loss = 0.00632870
Iteration 4210, loss = 0.00632707
Iteration 4211, loss = 0.00632620
Iteration 4212, loss = 0.00632299
Iteration 4213, loss = 0.00632270
Iteration 4214, loss = 0.00632009
Iteration 4215, loss = 0.00631781
Iteration 4216, loss = 0.00631569
Iteration 4217, loss = 0.00631447
Iteration 4218, loss = 0.00631240
Iteration 4219, loss = 0.00631022
Iteration 4220, loss = 0.00630878
Iteration 4221, loss = 0.00630697
Iteration 4222, loss = 0.00630499
Iteration 4223, loss = 0.00630323
Iteration 4224, loss = 0.00630137
Iteration 4225, loss = 0.00629975
Iteration 4226, loss = 0.00629828
Iteration 4227, loss = 0.00629641
Iteration 4228, loss = 0.00629438
Iteration 4229, loss = 0.00629279
Iteration 4230, loss = 0.00629116
Iteration 4231, loss = 0.00628953
Iteration 4232, loss = 0.00628780
Iteration 4233, loss = 0.00628662
Iteration 4234, loss = 0.00628459
Iteration 4235, loss = 0.00628284
Iteration 4236, loss = 0.00628129
Iteration 4237, loss = 0.00627921
Iteration 4238, loss = 0.00627739
Iteration 4239, loss = 0.00627619
Iteration 4240, loss = 0.00627387
Iteration 4241, loss = 0.00627194
Iteration 4242, loss = 0.00627053
Iteration 4243, loss = 0.00626831
Iteration 4244, loss = 0.00626703
Iteration 4245, loss = 0.00626486
Iteration 4246, loss = 0.00626287
Iteration 4247, loss = 0.00626103
Iteration 4248, loss = 0.00625928
Iteration 4249, loss = 0.00625776
Iteration 4250, loss = 0.00625602
Iteration 4251, loss = 0.00625414
Iteration 4252, loss = 0.00625221
Iteration 4253, loss = 0.00625049
Iteration 4254, loss = 0.00624868
Iteration 4255, loss = 0.00624681
Iteration 4256, loss = 0.00624475
Iteration 4257, loss = 0.00624287
Iteration 4258, loss = 0.00624095
Iteration 4259, loss = 0.00623908
Iteration 4260, loss = 0.00623733
Iteration 4261, loss = 0.00623564
Iteration 4262, loss = 0.00623397
Iteration 4263, loss = 0.00623205
Iteration 4264, loss = 0.00623061
Iteration 4265, loss = 0.00622878
Iteration 4266, loss = 0.00622714
Iteration 4267, loss = 0.00622544
Iteration 4268, loss = 0.00622373
Iteration 4269, loss = 0.00622241
Iteration 4270, loss = 0.00622016
Iteration 4271, loss = 0.00621841
Iteration 4272, loss = 0.00621694
Iteration 4273, loss = 0.00621504
Iteration 4274, loss = 0.00621338
Iteration 4275, loss = 0.00621268
Iteration 4276, loss = 0.00620989
Iteration 4277, loss = 0.00620783
Iteration 4278, loss = 0.00620542
Iteration 4279, loss = 0.00620355
Iteration 4280, loss = 0.00620200
Iteration 4281, loss = 0.00619993
Iteration 4282, loss = 0.00619807
Iteration 4283, loss = 0.00619628
Iteration 4284, loss = 0.00619453
Iteration 4285, loss = 0.00619290
Iteration 4286, loss = 0.00619150
Iteration 4287, loss = 0.00618969
Iteration 4288, loss = 0.00618762
Iteration 4289, loss = 0.00618608
Iteration 4290, loss = 0.00618418
Iteration 4291, loss = 0.00618275
Iteration 4292, loss = 0.00618089
Iteration 4293, loss = 0.00617936
Iteration 4294, loss = 0.00618000
Iteration 4295, loss = 0.00617616
Iteration 4296, loss = 0.00617432
Iteration 4297, loss = 0.00617250
Iteration 4298, loss = 0.00617036
Iteration 4299, loss = 0.00616921
Iteration 4300, loss = 0.00616701
Iteration 4301, loss = 0.00616499
Iteration 4302, loss = 0.00616361
Iteration 4303, loss = 0.00616192
Iteration 4304, loss = 0.00616000
Iteration 4305, loss = 0.00615861
Iteration 4306, loss = 0.00615695
Iteration 4307, loss = 0.00615569
Iteration 4308, loss = 0.00615393
Iteration 4309, loss = 0.00615235
Iteration 4310, loss = 0.00615063
Iteration 4311, loss = 0.00614866
Iteration 4312, loss = 0.00614711
Iteration 4313, loss = 0.00614564
Iteration 4314, loss = 0.00614390
Iteration 4315, loss = 0.00614242
Iteration 4316, loss = 0.00614079
Iteration 4317, loss = 0.00613923
Iteration 4318, loss = 0.00613763
Iteration 4319, loss = 0.00613612
Iteration 4320, loss = 0.00613474
Iteration 4321, loss = 0.00613305
Iteration 4322, loss = 0.00613134
Iteration 4323, loss = 0.00613035
Iteration 4324, loss = 0.00612833
Iteration 4325, loss = 0.00612746
Iteration 4326, loss = 0.00612528
Iteration 4327, loss = 0.00612328
Iteration 4328, loss = 0.00612125
Iteration 4329, loss = 0.00611931
Iteration 4330, loss = 0.00611731
Iteration 4331, loss = 0.00611528
Iteration 4332, loss = 0.00611400
Iteration 4333, loss = 0.00611129
Iteration 4334, loss = 0.00610906
Iteration 4335, loss = 0.00610794
Iteration 4336, loss = 0.00610593
Iteration 4337, loss = 0.00610400
Iteration 4338, loss = 0.00610200
Iteration 4339, loss = 0.00609998
Iteration 4340, loss = 0.00609874
Iteration 4341, loss = 0.00609633
Iteration 4342, loss = 0.00609488
Iteration 4343, loss = 0.00609272
Iteration 4344, loss = 0.00609109
Iteration 4345, loss = 0.00608976
Iteration 4346, loss = 0.00608798
Iteration 4347, loss = 0.00608621
Iteration 4348, loss = 0.00608449
Iteration 4349, loss = 0.00608267
Iteration 4350, loss = 0.00608100
Iteration 4351, loss = 0.00607937
Iteration 4352, loss = 0.00607757
Iteration 4353, loss = 0.00607573
Iteration 4354, loss = 0.00607427
Iteration 4355, loss = 0.00607233
Iteration 4356, loss = 0.00607071
Iteration 4357, loss = 0.00606899
Iteration 4358, loss = 0.00606820
Iteration 4359, loss = 0.00606590
Iteration 4360, loss = 0.00606454
Iteration 4361, loss = 0.00606258
Iteration 4362, loss = 0.00606094
Iteration 4363, loss = 0.00605950
Iteration 4364, loss = 0.00605780
Iteration 4365, loss = 0.00605584
Iteration 4366, loss = 0.00605416
Iteration 4367, loss = 0.00605244
Iteration 4368, loss = 0.00605094
Iteration 4369, loss = 0.00604924
Iteration 4370, loss = 0.00604770
Iteration 4371, loss = 0.00604589
Iteration 4372, loss = 0.00604455
Iteration 4373, loss = 0.00604279
Iteration 4374, loss = 0.00604090
Iteration 4375, loss = 0.00603935
Iteration 4376, loss = 0.00603750
Iteration 4377, loss = 0.00603573
Iteration 4378, loss = 0.00603411
Iteration 4379, loss = 0.00603225
Iteration 4380, loss = 0.00603058
Iteration 4381, loss = 0.00602893
Iteration 4382, loss = 0.00602780
Iteration 4383, loss = 0.00602598
Iteration 4384, loss = 0.00602462
Iteration 4385, loss = 0.00602326
Iteration 4386, loss = 0.00602123
Iteration 4387, loss = 0.00601966
Iteration 4388, loss = 0.00601808
Iteration 4389, loss = 0.00601642
Iteration 4390, loss = 0.00601434
Iteration 4391, loss = 0.00601271
Iteration 4392, loss = 0.00601088
Iteration 4393, loss = 0.00600874
Iteration 4394, loss = 0.00600775
Iteration 4395, loss = 0.00600514
Iteration 4396, loss = 0.00600346
Iteration 4397, loss = 0.00600171
Iteration 4398, loss = 0.00600083
Iteration 4399, loss = 0.00599860
Iteration 4400, loss = 0.00599652
Iteration 4401, loss = 0.00599480
Iteration 4402, loss = 0.00599338
Iteration 4403, loss = 0.00599173
Iteration 4404, loss = 0.00598990
Iteration 4405, loss = 0.00598909
Iteration 4406, loss = 0.00598651
Iteration 4407, loss = 0.00598434
Iteration 4408, loss = 0.00598292
Iteration 4409, loss = 0.00598119
Iteration 4410, loss = 0.00597923
Iteration 4411, loss = 0.00597779
Iteration 4412, loss = 0.00597597
Iteration 4413, loss = 0.00597448
Iteration 4414, loss = 0.00597291
Iteration 4415, loss = 0.00597158
Iteration 4416, loss = 0.00596999
Iteration 4417, loss = 0.00596839
Iteration 4418, loss = 0.00596677
Iteration 4419, loss = 0.00596599
Iteration 4420, loss = 0.00596381
Iteration 4421, loss = 0.00596257
Iteration 4422, loss = 0.00596038
Iteration 4423, loss = 0.00595801
Iteration 4424, loss = 0.00595641
Iteration 4425, loss = 0.00595505
Iteration 4426, loss = 0.00595300
Iteration 4427, loss = 0.00595102
Iteration 4428, loss = 0.00594904
Iteration 4429, loss = 0.00594743
Iteration 4430, loss = 0.00594622
Iteration 4431, loss = 0.00594436
Iteration 4432, loss = 0.00594239
Iteration 4433, loss = 0.00594164
Iteration 4434, loss = 0.00593940
Iteration 4435, loss = 0.00593784
Iteration 4436, loss = 0.00593640
Iteration 4437, loss = 0.00593486
Iteration 4438, loss = 0.00593344
Iteration 4439, loss = 0.00593169
Iteration 4440, loss = 0.00593035
Iteration 4441, loss = 0.00592869
Iteration 4442, loss = 0.00592701
Iteration 4443, loss = 0.00592527
Iteration 4444, loss = 0.00592372
Iteration 4445, loss = 0.00592213
Iteration 4446, loss = 0.00592051
Iteration 4447, loss = 0.00591876
Iteration 4448, loss = 0.00591855
Iteration 4449, loss = 0.00591586
Iteration 4450, loss = 0.00591423
Iteration 4451, loss = 0.00591255
Iteration 4452, loss = 0.00591224
Iteration 4453, loss = 0.00590955
Iteration 4454, loss = 0.00590763
Iteration 4455, loss = 0.00590597
Iteration 4456, loss = 0.00590422
Iteration 4457, loss = 0.00590243
Iteration 4458, loss = 0.00590064
Iteration 4459, loss = 0.00589959
Iteration 4460, loss = 0.00589632
Iteration 4461, loss = 0.00589551
Iteration 4462, loss = 0.00589252
Iteration 4463, loss = 0.00589293
Iteration 4464, loss = 0.00588961
Iteration 4465, loss = 0.00588773
Iteration 4466, loss = 0.00588582
Iteration 4467, loss = 0.00588445
Iteration 4468, loss = 0.00588269
Iteration 4469, loss = 0.00588116
Iteration 4470, loss = 0.00587967
Iteration 4471, loss = 0.00587791
Iteration 4472, loss = 0.00587620
Iteration 4473, loss = 0.00587458
Iteration 4474, loss = 0.00587309
Iteration 4475, loss = 0.00587162
Iteration 4476, loss = 0.00587018
Iteration 4477, loss = 0.00586860
Iteration 4478, loss = 0.00586719
Iteration 4479, loss = 0.00586593
Iteration 4480, loss = 0.00586439
Iteration 4481, loss = 0.00586333
Iteration 4482, loss = 0.00586235
Iteration 4483, loss = 0.00586066
Iteration 4484, loss = 0.00585881
Iteration 4485, loss = 0.00585732
Iteration 4486, loss = 0.00585526
Iteration 4487, loss = 0.00585407
Iteration 4488, loss = 0.00585263
Iteration 4489, loss = 0.00585081
Iteration 4490, loss = 0.00584904
Iteration 4491, loss = 0.00584791
Iteration 4492, loss = 0.00584664
Iteration 4493, loss = 0.00584447
Iteration 4494, loss = 0.00584293
Iteration 4495, loss = 0.00584141
Iteration 4496, loss = 0.00583972
Iteration 4497, loss = 0.00583809
Iteration 4498, loss = 0.00583681
Iteration 4499, loss = 0.00583521
Iteration 4500, loss = 0.00583406
Iteration 4501, loss = 0.00583178
Iteration 4502, loss = 0.00583023
Iteration 4503, loss = 0.00582879
Iteration 4504, loss = 0.00582683
Iteration 4505, loss = 0.00582497
Iteration 4506, loss = 0.00582327
Iteration 4507, loss = 0.00582188
Iteration 4508, loss = 0.00582014
Iteration 4509, loss = 0.00581851
Iteration 4510, loss = 0.00581662
Iteration 4511, loss = 0.00581549
Iteration 4512, loss = 0.00581320
Iteration 4513, loss = 0.00581126
Iteration 4514, loss = 0.00581151
Iteration 4515, loss = 0.00580877
Iteration 4516, loss = 0.00580715
Iteration 4517, loss = 0.00580526
Iteration 4518, loss = 0.00580354
Iteration 4519, loss = 0.00580212
Iteration 4520, loss = 0.00580007
Iteration 4521, loss = 0.00579860
Iteration 4522, loss = 0.00579710
Iteration 4523, loss = 0.00579571
Iteration 4524, loss = 0.00579433
Iteration 4525, loss = 0.00579259
Iteration 4526, loss = 0.00579111
Iteration 4527, loss = 0.00578956
Iteration 4528, loss = 0.00578828
Iteration 4529, loss = 0.00578650
Iteration 4530, loss = 0.00578489
Iteration 4531, loss = 0.00578355
Iteration 4532, loss = 0.00578185
Iteration 4533, loss = 0.00578049
Iteration 4534, loss = 0.00577900
Iteration 4535, loss = 0.00577755
Iteration 4536, loss = 0.00577697
Iteration 4537, loss = 0.00577518
Iteration 4538, loss = 0.00577377
Iteration 4539, loss = 0.00577195
Iteration 4540, loss = 0.00577042
Iteration 4541, loss = 0.00576894
Iteration 4542, loss = 0.00576749
Iteration 4543, loss = 0.00576601
Iteration 4544, loss = 0.00576508
Iteration 4545, loss = 0.00576328
Iteration 4546, loss = 0.00576201
Iteration 4547, loss = 0.00576076
Iteration 4548, loss = 0.00575944
Iteration 4549, loss = 0.00575782
Iteration 4550, loss = 0.00575645
Iteration 4551, loss = 0.00575492
Iteration 4552, loss = 0.00575352
Iteration 4553, loss = 0.00575213
Iteration 4554, loss = 0.00575047
Iteration 4555, loss = 0.00574887
Iteration 4556, loss = 0.00574757
Iteration 4557, loss = 0.00574595
Iteration 4558, loss = 0.00574456
Iteration 4559, loss = 0.00574314
Iteration 4560, loss = 0.00574162
Iteration 4561, loss = 0.00574036
Iteration 4562, loss = 0.00573902
Iteration 4563, loss = 0.00573728
Iteration 4564, loss = 0.00573627
Iteration 4565, loss = 0.00573433
Iteration 4566, loss = 0.00573298
Iteration 4567, loss = 0.00573148
Iteration 4568, loss = 0.00573003
Iteration 4569, loss = 0.00572842
Iteration 4570, loss = 0.00572770
Iteration 4571, loss = 0.00572605
Iteration 4572, loss = 0.00572418
Iteration 4573, loss = 0.00572255
Iteration 4574, loss = 0.00572123
Iteration 4575, loss = 0.00571922
Iteration 4576, loss = 0.00571686
Iteration 4577, loss = 0.00571473
Iteration 4578, loss = 0.00571391
Iteration 4579, loss = 0.00571184
Iteration 4580, loss = 0.00571005
Iteration 4581, loss = 0.00570838
Iteration 4582, loss = 0.00570687
Iteration 4583, loss = 0.00570528
Iteration 4584, loss = 0.00570393
Iteration 4585, loss = 0.00570265
Iteration 4586, loss = 0.00570132
Iteration 4587, loss = 0.00570002
Iteration 4588, loss = 0.00569862
Iteration 4589, loss = 0.00569698
Iteration 4590, loss = 0.00569514
Iteration 4591, loss = 0.00569367
Iteration 4592, loss = 0.00569208
Iteration 4593, loss = 0.00569035
Iteration 4594, loss = 0.00568885
Iteration 4595, loss = 0.00568823
Iteration 4596, loss = 0.00568628
Iteration 4597, loss = 0.00568394
Iteration 4598, loss = 0.00568256
Iteration 4599, loss = 0.00568085
Iteration 4600, loss = 0.00567916
Iteration 4601, loss = 0.00567751
Iteration 4602, loss = 0.00567583
Iteration 4603, loss = 0.00567447
Iteration 4604, loss = 0.00567316
Iteration 4605, loss = 0.00567163
Iteration 4606, loss = 0.00567019
Iteration 4607, loss = 0.00566855
Iteration 4608, loss = 0.00566700
Iteration 4609, loss = 0.00566556
Iteration 4610, loss = 0.00566416
Iteration 4611, loss = 0.00566289
Iteration 4612, loss = 0.00566128
Iteration 4613, loss = 0.00566003
Iteration 4614, loss = 0.00565844
Iteration 4615, loss = 0.00565690
Iteration 4616, loss = 0.00565577
Iteration 4617, loss = 0.00565383
Iteration 4618, loss = 0.00565251
Iteration 4619, loss = 0.00565002
Iteration 4620, loss = 0.00564864
Iteration 4621, loss = 0.00564630
Iteration 4622, loss = 0.00564505
Iteration 4623, loss = 0.00564309
Iteration 4624, loss = 0.00564099
Iteration 4625, loss = 0.00563988
Iteration 4626, loss = 0.00563755
Iteration 4627, loss = 0.00563571
Iteration 4628, loss = 0.00563487
Iteration 4629, loss = 0.00563338
Iteration 4630, loss = 0.00563242
Iteration 4631, loss = 0.00563021
Iteration 4632, loss = 0.00562878
Iteration 4633, loss = 0.00562731
Iteration 4634, loss = 0.00562579
Iteration 4635, loss = 0.00562432
Iteration 4636, loss = 0.00562376
Iteration 4637, loss = 0.00562170
Iteration 4638, loss = 0.00562025
Iteration 4639, loss = 0.00561873
Iteration 4640, loss = 0.00561704
Iteration 4641, loss = 0.00561532
Iteration 4642, loss = 0.00561396
Iteration 4643, loss = 0.00561257
Iteration 4644, loss = 0.00561110
Iteration 4645, loss = 0.00560921
Iteration 4646, loss = 0.00560748
Iteration 4647, loss = 0.00560569
Iteration 4648, loss = 0.00560449
Iteration 4649, loss = 0.00560328
Iteration 4650, loss = 0.00560160
Iteration 4651, loss = 0.00560010
Iteration 4652, loss = 0.00559881
Iteration 4653, loss = 0.00559730
Iteration 4654, loss = 0.00559631
Iteration 4655, loss = 0.00559461
Iteration 4656, loss = 0.00559341
Iteration 4657, loss = 0.00559167
Iteration 4658, loss = 0.00559002
Iteration 4659, loss = 0.00558866
Iteration 4660, loss = 0.00558700
Iteration 4661, loss = 0.00558542
Iteration 4662, loss = 0.00558382
Iteration 4663, loss = 0.00558246
Iteration 4664, loss = 0.00558107
Iteration 4665, loss = 0.00557939
Iteration 4666, loss = 0.00557881
Iteration 4667, loss = 0.00557677
Iteration 4668, loss = 0.00557534
Iteration 4669, loss = 0.00557374
Iteration 4670, loss = 0.00557248
Iteration 4671, loss = 0.00557076
Iteration 4672, loss = 0.00556900
Iteration 4673, loss = 0.00556756
Iteration 4674, loss = 0.00556675
Iteration 4675, loss = 0.00556470
Iteration 4676, loss = 0.00556318
Iteration 4677, loss = 0.00556189
Iteration 4678, loss = 0.00556006
Iteration 4679, loss = 0.00555854
Iteration 4680, loss = 0.00555681
Iteration 4681, loss = 0.00555571
Iteration 4682, loss = 0.00555360
Iteration 4683, loss = 0.00555230
Iteration 4684, loss = 0.00555055
Iteration 4685, loss = 0.00554882
Iteration 4686, loss = 0.00554766
Iteration 4687, loss = 0.00554608
Iteration 4688, loss = 0.00554471
Iteration 4689, loss = 0.00554321
Iteration 4690, loss = 0.00554162
Iteration 4691, loss = 0.00554023
Iteration 4692, loss = 0.00553875
Iteration 4693, loss = 0.00553741
Iteration 4694, loss = 0.00553508
Iteration 4695, loss = 0.00553346
Iteration 4696, loss = 0.00553163
Iteration 4697, loss = 0.00553076
Iteration 4698, loss = 0.00552878
Iteration 4699, loss = 0.00552737
Iteration 4700, loss = 0.00552533
Iteration 4701, loss = 0.00552384
Iteration 4702, loss = 0.00552218
Iteration 4703, loss = 0.00552067
Iteration 4704, loss = 0.00551907
Iteration 4705, loss = 0.00551809
Iteration 4706, loss = 0.00551609
Iteration 4707, loss = 0.00551453
Iteration 4708, loss = 0.00551312
Iteration 4709, loss = 0.00551162
Iteration 4710, loss = 0.00550987
Iteration 4711, loss = 0.00550875
Iteration 4712, loss = 0.00550694
Iteration 4713, loss = 0.00550549
Iteration 4714, loss = 0.00550422
Iteration 4715, loss = 0.00550261
Iteration 4716, loss = 0.00550115
Iteration 4717, loss = 0.00549978
Iteration 4718, loss = 0.00549845
Iteration 4719, loss = 0.00549710
Iteration 4720, loss = 0.00549579
Iteration 4721, loss = 0.00549452
Iteration 4722, loss = 0.00549327
Iteration 4723, loss = 0.00549245
Iteration 4724, loss = 0.00549124
Iteration 4725, loss = 0.00548935
Iteration 4726, loss = 0.00548792
Iteration 4727, loss = 0.00548643
Iteration 4728, loss = 0.00548501
Iteration 4729, loss = 0.00548464
Iteration 4730, loss = 0.00548245
Iteration 4731, loss = 0.00548123
Iteration 4732, loss = 0.00547952
Iteration 4733, loss = 0.00547821
Iteration 4734, loss = 0.00547658
Iteration 4735, loss = 0.00547536
Iteration 4736, loss = 0.00547398
Iteration 4737, loss = 0.00547268
Iteration 4738, loss = 0.00547135
Iteration 4739, loss = 0.00546977
Iteration 4740, loss = 0.00546871
Iteration 4741, loss = 0.00546725
Iteration 4742, loss = 0.00546579
Iteration 4743, loss = 0.00546369
Iteration 4744, loss = 0.00546224
Iteration 4745, loss = 0.00546033
Iteration 4746, loss = 0.00545954
Iteration 4747, loss = 0.00545749
Iteration 4748, loss = 0.00545635
Iteration 4749, loss = 0.00545436
Iteration 4750, loss = 0.00545289
Iteration 4751, loss = 0.00545139
Iteration 4752, loss = 0.00545011
Iteration 4753, loss = 0.00544846
Iteration 4754, loss = 0.00544696
Iteration 4755, loss = 0.00544544
Iteration 4756, loss = 0.00544422
Iteration 4757, loss = 0.00544474
Iteration 4758, loss = 0.00544172
Iteration 4759, loss = 0.00544022
Iteration 4760, loss = 0.00543913
Iteration 4761, loss = 0.00543727
Iteration 4762, loss = 0.00543592
Iteration 4763, loss = 0.00543459
Iteration 4764, loss = 0.00543280
Iteration 4765, loss = 0.00543165
Iteration 4766, loss = 0.00543008
Iteration 4767, loss = 0.00542855
Iteration 4768, loss = 0.00542716
Iteration 4769, loss = 0.00542597
Iteration 4770, loss = 0.00542482
Iteration 4771, loss = 0.00542325
Iteration 4772, loss = 0.00542205
Iteration 4773, loss = 0.00542043
Iteration 4774, loss = 0.00541891
Iteration 4775, loss = 0.00541768
Iteration 4776, loss = 0.00541591
Iteration 4777, loss = 0.00541425
Iteration 4778, loss = 0.00541281
Iteration 4779, loss = 0.00541143
Iteration 4780, loss = 0.00540960
Iteration 4781, loss = 0.00540832
Iteration 4782, loss = 0.00540657
Iteration 4783, loss = 0.00540474
Iteration 4784, loss = 0.00540367
Iteration 4785, loss = 0.00540164
Iteration 4786, loss = 0.00540052
Iteration 4787, loss = 0.00539878
Iteration 4788, loss = 0.00539761
Iteration 4789, loss = 0.00539550
Iteration 4790, loss = 0.00539459
Iteration 4791, loss = 0.00539289
Iteration 4792, loss = 0.00539161
Iteration 4793, loss = 0.00538970
Iteration 4794, loss = 0.00538853
Iteration 4795, loss = 0.00538675
Iteration 4796, loss = 0.00538524
Iteration 4797, loss = 0.00538360
Iteration 4798, loss = 0.00538200
Iteration 4799, loss = 0.00538103
Iteration 4800, loss = 0.00537916
Iteration 4801, loss = 0.00537750
Iteration 4802, loss = 0.00537605
Iteration 4803, loss = 0.00537500
Iteration 4804, loss = 0.00537304
Iteration 4805, loss = 0.00537167
Iteration 4806, loss = 0.00536996
Iteration 4807, loss = 0.00536891
Iteration 4808, loss = 0.00536732
Iteration 4809, loss = 0.00536570
Iteration 4810, loss = 0.00536450
Iteration 4811, loss = 0.00536295
Iteration 4812, loss = 0.00536193
Iteration 4813, loss = 0.00536031
Iteration 4814, loss = 0.00535866
Iteration 4815, loss = 0.00535712
Iteration 4816, loss = 0.00535602
Iteration 4817, loss = 0.00535471
Iteration 4818, loss = 0.00535343
Iteration 4819, loss = 0.00535163
Iteration 4820, loss = 0.00534999
Iteration 4821, loss = 0.00534848
Iteration 4822, loss = 0.00534665
Iteration 4823, loss = 0.00534511
Iteration 4824, loss = 0.00534388
Iteration 4825, loss = 0.00534238
Iteration 4826, loss = 0.00534086
Iteration 4827, loss = 0.00533942
Iteration 4828, loss = 0.00533797
Iteration 4829, loss = 0.00533668
Iteration 4830, loss = 0.00533511
Iteration 4831, loss = 0.00533364
Iteration 4832, loss = 0.00533210
Iteration 4833, loss = 0.00533053
Iteration 4834, loss = 0.00532937
Iteration 4835, loss = 0.00532816
Iteration 4836, loss = 0.00532652
Iteration 4837, loss = 0.00532524
Iteration 4838, loss = 0.00532380
Iteration 4839, loss = 0.00532258
Iteration 4840, loss = 0.00532114
Iteration 4841, loss = 0.00531950
Iteration 4842, loss = 0.00531848
Iteration 4843, loss = 0.00531695
Iteration 4844, loss = 0.00531552
Iteration 4845, loss = 0.00531418
Iteration 4846, loss = 0.00531265
Iteration 4847, loss = 0.00531125
Iteration 4848, loss = 0.00530989
Iteration 4849, loss = 0.00530903
Iteration 4850, loss = 0.00530748
Iteration 4851, loss = 0.00530610
Iteration 4852, loss = 0.00530480
Iteration 4853, loss = 0.00530347
Iteration 4854, loss = 0.00530217
Iteration 4855, loss = 0.00530107
Iteration 4856, loss = 0.00529969
Iteration 4857, loss = 0.00529833
Iteration 4858, loss = 0.00529695
Iteration 4859, loss = 0.00529572
Iteration 4860, loss = 0.00529463
Iteration 4861, loss = 0.00529281
Iteration 4862, loss = 0.00529126
Iteration 4863, loss = 0.00528977
Iteration 4864, loss = 0.00528886
Iteration 4865, loss = 0.00528698
Iteration 4866, loss = 0.00528568
Iteration 4867, loss = 0.00528427
Iteration 4868, loss = 0.00528271
Iteration 4869, loss = 0.00528137
Iteration 4870, loss = 0.00527947
Iteration 4871, loss = 0.00527802
Iteration 4872, loss = 0.00527657
Iteration 4873, loss = 0.00527517
Iteration 4874, loss = 0.00527396
Iteration 4875, loss = 0.00527254
Iteration 4876, loss = 0.00527106
Iteration 4877, loss = 0.00527038
Iteration 4878, loss = 0.00526843
Iteration 4879, loss = 0.00526708
Iteration 4880, loss = 0.00526582
Iteration 4881, loss = 0.00526445
Iteration 4882, loss = 0.00526388
Iteration 4883, loss = 0.00526181
Iteration 4884, loss = 0.00526020
Iteration 4885, loss = 0.00525946
Iteration 4886, loss = 0.00525749
Iteration 4887, loss = 0.00525615
Iteration 4888, loss = 0.00525498
Iteration 4889, loss = 0.00525344
Iteration 4890, loss = 0.00525198
Iteration 4891, loss = 0.00525072
Iteration 4892, loss = 0.00524929
Iteration 4893, loss = 0.00524933
Iteration 4894, loss = 0.00524742
Iteration 4895, loss = 0.00524588
Iteration 4896, loss = 0.00524448
Iteration 4897, loss = 0.00524362
Iteration 4898, loss = 0.00524198
Iteration 4899, loss = 0.00524063
Iteration 4900, loss = 0.00523916
Iteration 4901, loss = 0.00523776
Iteration 4902, loss = 0.00523661
Iteration 4903, loss = 0.00523498
Iteration 4904, loss = 0.00523352
Iteration 4905, loss = 0.00523192
Iteration 4906, loss = 0.00523075
Iteration 4907, loss = 0.00522932
Iteration 4908, loss = 0.00522805
Iteration 4909, loss = 0.00522662
Iteration 4910, loss = 0.00522533
Iteration 4911, loss = 0.00522394
Iteration 4912, loss = 0.00522266
Iteration 4913, loss = 0.00522179
Iteration 4914, loss = 0.00522028
Iteration 4915, loss = 0.00521894
Iteration 4916, loss = 0.00521776
Iteration 4917, loss = 0.00521671
Iteration 4918, loss = 0.00521540
Iteration 4919, loss = 0.00521397
Iteration 4920, loss = 0.00521275
Iteration 4921, loss = 0.00521153
Iteration 4922, loss = 0.00521014
Iteration 4923, loss = 0.00520887
Iteration 4924, loss = 0.00520766
Iteration 4925, loss = 0.00520677
Iteration 4926, loss = 0.00520568
Iteration 4927, loss = 0.00520423
Iteration 4928, loss = 0.00520254
Iteration 4929, loss = 0.00520133
Iteration 4930, loss = 0.00520024
Iteration 4931, loss = 0.00519917
Iteration 4932, loss = 0.00519858
Iteration 4933, loss = 0.00519681
Iteration 4934, loss = 0.00519560
Iteration 4935, loss = 0.00519451
Iteration 4936, loss = 0.00519333
Iteration 4937, loss = 0.00519224
Iteration 4938, loss = 0.00519121
Iteration 4939, loss = 0.00519022
Iteration 4940, loss = 0.00518934
Iteration 4941, loss = 0.00518851
Iteration 4942, loss = 0.00518717
Iteration 4943, loss = 0.00518541
Iteration 4944, loss = 0.00518472
Iteration 4945, loss = 0.00518270
Iteration 4946, loss = 0.00518108
Iteration 4947, loss = 0.00517966
Iteration 4948, loss = 0.00517813
Iteration 4949, loss = 0.00517667
Iteration 4950, loss = 0.00517577
Iteration 4951, loss = 0.00517390
Iteration 4952, loss = 0.00517268
Iteration 4953, loss = 0.00517145
Iteration 4954, loss = 0.00517020
Iteration 4955, loss = 0.00516950
Iteration 4956, loss = 0.00516786
Iteration 4957, loss = 0.00516668
Iteration 4958, loss = 0.00516567
Iteration 4959, loss = 0.00516399
Iteration 4960, loss = 0.00516295
Iteration 4961, loss = 0.00516140
Iteration 4962, loss = 0.00516020
Iteration 4963, loss = 0.00515909
Iteration 4964, loss = 0.00515806
Iteration 4965, loss = 0.00515661
Iteration 4966, loss = 0.00515545
Iteration 4967, loss = 0.00515451
Iteration 4968, loss = 0.00515360
Iteration 4969, loss = 0.00515212
Iteration 4970, loss = 0.00515145
Iteration 4971, loss = 0.00514980
Iteration 4972, loss = 0.00514814
Iteration 4973, loss = 0.00514687
Iteration 4974, loss = 0.00514577
Iteration 4975, loss = 0.00514401
Iteration 4976, loss = 0.00514271
Iteration 4977, loss = 0.00514147
Iteration 4978, loss = 0.00514085
Iteration 4979, loss = 0.00513848
Iteration 4980, loss = 0.00513769
Iteration 4981, loss = 0.00513561
Iteration 4982, loss = 0.00513467
Iteration 4983, loss = 0.00513253
Iteration 4984, loss = 0.00513244
Iteration 4985, loss = 0.00513009
Iteration 4986, loss = 0.00512873
Iteration 4987, loss = 0.00512712
Iteration 4988, loss = 0.00512557
Iteration 4989, loss = 0.00512404
Iteration 4990, loss = 0.00512299
Iteration 4991, loss = 0.00512137
Iteration 4992, loss = 0.00511985
Iteration 4993, loss = 0.00511864
Iteration 4994, loss = 0.00511722
Iteration 4995, loss = 0.00511582
Iteration 4996, loss = 0.00511464
Iteration 4997, loss = 0.00511358
Iteration 4998, loss = 0.00511165
Iteration 4999, loss = 0.00511042
Iteration 5000, loss = 0.00510954
Iteration 5001, loss = 0.00510815
Iteration 5002, loss = 0.00510735
Iteration 5003, loss = 0.00510575
Iteration 5004, loss = 0.00510441
Iteration 5005, loss = 0.00510329
Iteration 5006, loss = 0.00510188
Iteration 5007, loss = 0.00510058
Iteration 5008, loss = 0.00509965
Iteration 5009, loss = 0.00509815
Iteration 5010, loss = 0.00509679
Iteration 5011, loss = 0.00509540
Iteration 5012, loss = 0.00509398
Iteration 5013, loss = 0.00509266
Iteration 5014, loss = 0.00509165
Iteration 5015, loss = 0.00508988
Iteration 5016, loss = 0.00508850
Iteration 5017, loss = 0.00508717
Iteration 5018, loss = 0.00508564
Iteration 5019, loss = 0.00508479
Iteration 5020, loss = 0.00508315
Iteration 5021, loss = 0.00508210
Iteration 5022, loss = 0.00508064
Iteration 5023, loss = 0.00507908
Iteration 5024, loss = 0.00507790
Iteration 5025, loss = 0.00507636
Iteration 5026, loss = 0.00507489
Iteration 5027, loss = 0.00507368
Iteration 5028, loss = 0.00507218
Iteration 5029, loss = 0.00507119
Iteration 5030, loss = 0.00506958
Iteration 5031, loss = 0.00506855
Iteration 5032, loss = 0.00506701
Iteration 5033, loss = 0.00506610
Iteration 5034, loss = 0.00506444
Iteration 5035, loss = 0.00506348
Iteration 5036, loss = 0.00506198
Iteration 5037, loss = 0.00506073
Iteration 5038, loss = 0.00505956
Iteration 5039, loss = 0.00505841
Iteration 5040, loss = 0.00505748
Iteration 5041, loss = 0.00505606
Iteration 5042, loss = 0.00505478
Iteration 5043, loss = 0.00505375
Iteration 5044, loss = 0.00505239
Iteration 5045, loss = 0.00505097
Iteration 5046, loss = 0.00504968
Iteration 5047, loss = 0.00504896
Iteration 5048, loss = 0.00504719
Iteration 5049, loss = 0.00504583
Iteration 5050, loss = 0.00504487
Iteration 5051, loss = 0.00504342
Iteration 5052, loss = 0.00504247
Iteration 5053, loss = 0.00504105
Iteration 5054, loss = 0.00503993
Iteration 5055, loss = 0.00503885
Iteration 5056, loss = 0.00503818
Iteration 5057, loss = 0.00503666
Iteration 5058, loss = 0.00503530
Iteration 5059, loss = 0.00503426
Iteration 5060, loss = 0.00503276
Iteration 5061, loss = 0.00503151
Iteration 5062, loss = 0.00503042
Iteration 5063, loss = 0.00502903
Iteration 5064, loss = 0.00502764
Iteration 5065, loss = 0.00502592
Iteration 5066, loss = 0.00502423
Iteration 5067, loss = 0.00502321
Iteration 5068, loss = 0.00502130
Iteration 5069, loss = 0.00502018
Iteration 5070, loss = 0.00501842
Iteration 5071, loss = 0.00501738
Iteration 5072, loss = 0.00501609
Iteration 5073, loss = 0.00501508
Iteration 5074, loss = 0.00501343
Iteration 5075, loss = 0.00501205
Iteration 5076, loss = 0.00501090
Iteration 5077, loss = 0.00500959
Iteration 5078, loss = 0.00500849
Iteration 5079, loss = 0.00500709
Iteration 5080, loss = 0.00500593
Iteration 5081, loss = 0.00500483
Iteration 5082, loss = 0.00500368
Iteration 5083, loss = 0.00500261
Iteration 5084, loss = 0.00500136
Iteration 5085, loss = 0.00500117
Iteration 5086, loss = 0.00499827
Iteration 5087, loss = 0.00499725
Iteration 5088, loss = 0.00499608
Iteration 5089, loss = 0.00499456
Iteration 5090, loss = 0.00499324
Iteration 5091, loss = 0.00499215
Iteration 5092, loss = 0.00499095
Iteration 5093, loss = 0.00498977
Iteration 5094, loss = 0.00498866
Iteration 5095, loss = 0.00498749
Iteration 5096, loss = 0.00498632
Iteration 5097, loss = 0.00498476
Iteration 5098, loss = 0.00498364
Iteration 5099, loss = 0.00498228
Iteration 5100, loss = 0.00498104
Iteration 5101, loss = 0.00498097
Iteration 5102, loss = 0.00497881
Iteration 5103, loss = 0.00497734
Iteration 5104, loss = 0.00497634
Iteration 5105, loss = 0.00497504
Iteration 5106, loss = 0.00497387
Iteration 5107, loss = 0.00497298
Iteration 5108, loss = 0.00497146
Iteration 5109, loss = 0.00497048
Iteration 5110, loss = 0.00496912
Iteration 5111, loss = 0.00496762
Iteration 5112, loss = 0.00496610
Iteration 5113, loss = 0.00496492
Iteration 5114, loss = 0.00496358
Iteration 5115, loss = 0.00496208
Iteration 5116, loss = 0.00496045
Iteration 5117, loss = 0.00495975
Iteration 5118, loss = 0.00495829
Iteration 5119, loss = 0.00495675
Iteration 5120, loss = 0.00495542
Iteration 5121, loss = 0.00495400
Iteration 5122, loss = 0.00495320
Iteration 5123, loss = 0.00495175
Iteration 5124, loss = 0.00495079
Iteration 5125, loss = 0.00494939
Iteration 5126, loss = 0.00494768
Iteration 5127, loss = 0.00494690
Iteration 5128, loss = 0.00494565
Iteration 5129, loss = 0.00494449
Iteration 5130, loss = 0.00494321
Iteration 5131, loss = 0.00494203
Iteration 5132, loss = 0.00494137
Iteration 5133, loss = 0.00493995
Iteration 5134, loss = 0.00493851
Iteration 5135, loss = 0.00493711
Iteration 5136, loss = 0.00493574
Iteration 5137, loss = 0.00493471
Iteration 5138, loss = 0.00493332
Iteration 5139, loss = 0.00493198
Iteration 5140, loss = 0.00493056
Iteration 5141, loss = 0.00492942
Iteration 5142, loss = 0.00492818
Iteration 5143, loss = 0.00492691
Iteration 5144, loss = 0.00492558
Iteration 5145, loss = 0.00492432
Iteration 5146, loss = 0.00492291
Iteration 5147, loss = 0.00492196
Iteration 5148, loss = 0.00492059
Iteration 5149, loss = 0.00491962
Iteration 5150, loss = 0.00491838
Iteration 5151, loss = 0.00491730
Iteration 5152, loss = 0.00491719
Iteration 5153, loss = 0.00491517
Iteration 5154, loss = 0.00491397
Iteration 5155, loss = 0.00491265
Iteration 5156, loss = 0.00491144
Iteration 5157, loss = 0.00491038
Iteration 5158, loss = 0.00490916
Iteration 5159, loss = 0.00490946
Iteration 5160, loss = 0.00490699
Iteration 5161, loss = 0.00490547
Iteration 5162, loss = 0.00490433
Iteration 5163, loss = 0.00490313
Iteration 5164, loss = 0.00490173
Iteration 5165, loss = 0.00490048
Iteration 5166, loss = 0.00489934
Iteration 5167, loss = 0.00489816
Iteration 5168, loss = 0.00489718
Iteration 5169, loss = 0.00489588
Iteration 5170, loss = 0.00489491
Iteration 5171, loss = 0.00489350
Iteration 5172, loss = 0.00489252
Iteration 5173, loss = 0.00489160
Iteration 5174, loss = 0.00489042
Iteration 5175, loss = 0.00488910
Iteration 5176, loss = 0.00488789
Iteration 5177, loss = 0.00488738
Iteration 5178, loss = 0.00488570
Iteration 5179, loss = 0.00488460
Iteration 5180, loss = 0.00488291
Iteration 5181, loss = 0.00488159
Iteration 5182, loss = 0.00488025
Iteration 5183, loss = 0.00487912
Iteration 5184, loss = 0.00487799
Iteration 5185, loss = 0.00487660
Iteration 5186, loss = 0.00487556
Iteration 5187, loss = 0.00487415
Iteration 5188, loss = 0.00487299
Iteration 5189, loss = 0.00487221
Iteration 5190, loss = 0.00487079
Iteration 5191, loss = 0.00486936
Iteration 5192, loss = 0.00486848
Iteration 5193, loss = 0.00486703
Iteration 5194, loss = 0.00486565
Iteration 5195, loss = 0.00486449
Iteration 5196, loss = 0.00486341
Iteration 5197, loss = 0.00486245
Iteration 5198, loss = 0.00486084
Iteration 5199, loss = 0.00486003
Iteration 5200, loss = 0.00485818
Iteration 5201, loss = 0.00485689
Iteration 5202, loss = 0.00485635
Iteration 5203, loss = 0.00485462
Iteration 5204, loss = 0.00485405
Iteration 5205, loss = 0.00485232
Iteration 5206, loss = 0.00485145
Iteration 5207, loss = 0.00484991
Iteration 5208, loss = 0.00484867
Iteration 5209, loss = 0.00484741
Iteration 5210, loss = 0.00484619
Iteration 5211, loss = 0.00484513
Iteration 5212, loss = 0.00484400
Iteration 5213, loss = 0.00484286
Iteration 5214, loss = 0.00484189
Iteration 5215, loss = 0.00484098
Iteration 5216, loss = 0.00484013
Iteration 5217, loss = 0.00483867
Iteration 5218, loss = 0.00483759
Iteration 5219, loss = 0.00483660
Iteration 5220, loss = 0.00483549
Iteration 5221, loss = 0.00483447
Iteration 5222, loss = 0.00483375
Iteration 5223, loss = 0.00483222
Iteration 5224, loss = 0.00483124
Iteration 5225, loss = 0.00482992
Iteration 5226, loss = 0.00482889
Iteration 5227, loss = 0.00482809
Iteration 5228, loss = 0.00482641
Iteration 5229, loss = 0.00482546
Iteration 5230, loss = 0.00482412
Iteration 5231, loss = 0.00482324
Iteration 5232, loss = 0.00482196
Iteration 5233, loss = 0.00482077
Iteration 5234, loss = 0.00481954
Iteration 5235, loss = 0.00481830
Iteration 5236, loss = 0.00481686
Iteration 5237, loss = 0.00481528
Iteration 5238, loss = 0.00481386
Iteration 5239, loss = 0.00481244
Iteration 5240, loss = 0.00481081
Iteration 5241, loss = 0.00481015
Iteration 5242, loss = 0.00480897
Iteration 5243, loss = 0.00480764
Iteration 5244, loss = 0.00480608
Iteration 5245, loss = 0.00480509
Iteration 5246, loss = 0.00480366
Iteration 5247, loss = 0.00480281
Iteration 5248, loss = 0.00480203
Iteration 5249, loss = 0.00480031
Iteration 5250, loss = 0.00479940
Iteration 5251, loss = 0.00479797
Iteration 5252, loss = 0.00479715
Iteration 5253, loss = 0.00479578
Iteration 5254, loss = 0.00479461
Iteration 5255, loss = 0.00479329
Iteration 5256, loss = 0.00479202
Iteration 5257, loss = 0.00479091
Iteration 5258, loss = 0.00478970
Iteration 5259, loss = 0.00478826
Iteration 5260, loss = 0.00478722
Iteration 5261, loss = 0.00478605
Iteration 5262, loss = 0.00478486
Iteration 5263, loss = 0.00478340
Iteration 5264, loss = 0.00478223
Iteration 5265, loss = 0.00478106
Iteration 5266, loss = 0.00477983
Iteration 5267, loss = 0.00477885
Iteration 5268, loss = 0.00477740
Iteration 5269, loss = 0.00477601
Iteration 5270, loss = 0.00477491
Iteration 5271, loss = 0.00477459
Iteration 5272, loss = 0.00477272
Iteration 5273, loss = 0.00477152
Iteration 5274, loss = 0.00477029
Iteration 5275, loss = 0.00476939
Iteration 5276, loss = 0.00476826
Iteration 5277, loss = 0.00476764
Iteration 5278, loss = 0.00476664
Iteration 5279, loss = 0.00476457
Iteration 5280, loss = 0.00476359
Iteration 5281, loss = 0.00476243
Iteration 5282, loss = 0.00476116
Iteration 5283, loss = 0.00475999
Iteration 5284, loss = 0.00475897
Iteration 5285, loss = 0.00475773
Iteration 5286, loss = 0.00475641
Iteration 5287, loss = 0.00475554
Iteration 5288, loss = 0.00475439
Iteration 5289, loss = 0.00475323
Iteration 5290, loss = 0.00475221
Iteration 5291, loss = 0.00475080
Iteration 5292, loss = 0.00474983
Iteration 5293, loss = 0.00474868
Iteration 5294, loss = 0.00474733
Iteration 5295, loss = 0.00474687
Iteration 5296, loss = 0.00474523
Iteration 5297, loss = 0.00474381
Iteration 5298, loss = 0.00474294
Iteration 5299, loss = 0.00474141
Iteration 5300, loss = 0.00474033
Iteration 5301, loss = 0.00473879
Iteration 5302, loss = 0.00473735
Iteration 5303, loss = 0.00473669
Iteration 5304, loss = 0.00473493
Iteration 5305, loss = 0.00473380
Iteration 5306, loss = 0.00473265
Iteration 5307, loss = 0.00473151
Iteration 5308, loss = 0.00473019
Iteration 5309, loss = 0.00472885
Iteration 5310, loss = 0.00472781
Iteration 5311, loss = 0.00472676
Iteration 5312, loss = 0.00472522
Iteration 5313, loss = 0.00472402
Iteration 5314, loss = 0.00472297
Iteration 5315, loss = 0.00472193
Iteration 5316, loss = 0.00472055
Iteration 5317, loss = 0.00471942
Iteration 5318, loss = 0.00471865
Iteration 5319, loss = 0.00471712
Iteration 5320, loss = 0.00471601
Iteration 5321, loss = 0.00471488
Iteration 5322, loss = 0.00471354
Iteration 5323, loss = 0.00471259
Iteration 5324, loss = 0.00471136
Iteration 5325, loss = 0.00471009
Iteration 5326, loss = 0.00470944
Iteration 5327, loss = 0.00470799
Iteration 5328, loss = 0.00470701
Iteration 5329, loss = 0.00470532
Iteration 5330, loss = 0.00470442
Iteration 5331, loss = 0.00470315
Iteration 5332, loss = 0.00470194
Iteration 5333, loss = 0.00470087
Iteration 5334, loss = 0.00469968
Iteration 5335, loss = 0.00469891
Iteration 5336, loss = 0.00469760
Iteration 5337, loss = 0.00469642
Iteration 5338, loss = 0.00469509
Iteration 5339, loss = 0.00469449
Iteration 5340, loss = 0.00469285
Iteration 5341, loss = 0.00469172
Iteration 5342, loss = 0.00469053
Iteration 5343, loss = 0.00468938
Iteration 5344, loss = 0.00468935
Iteration 5345, loss = 0.00468716
Iteration 5346, loss = 0.00468597
Iteration 5347, loss = 0.00468497
Iteration 5348, loss = 0.00468336
Iteration 5349, loss = 0.00468289
Iteration 5350, loss = 0.00468158
Iteration 5351, loss = 0.00468011
Iteration 5352, loss = 0.00467934
Iteration 5353, loss = 0.00467776
Iteration 5354, loss = 0.00467685
Iteration 5355, loss = 0.00467572
Iteration 5356, loss = 0.00467447
Iteration 5357, loss = 0.00467349
Iteration 5358, loss = 0.00467237
Iteration 5359, loss = 0.00467109
Iteration 5360, loss = 0.00466984
Iteration 5361, loss = 0.00466868
Iteration 5362, loss = 0.00466760
Iteration 5363, loss = 0.00466649
Iteration 5364, loss = 0.00466542
Iteration 5365, loss = 0.00466416
Iteration 5366, loss = 0.00466328
Iteration 5367, loss = 0.00466210
Iteration 5368, loss = 0.00466103
Iteration 5369, loss = 0.00466008
Iteration 5370, loss = 0.00465893
Iteration 5371, loss = 0.00465794
Iteration 5372, loss = 0.00465685
Iteration 5373, loss = 0.00465586
Iteration 5374, loss = 0.00465490
Iteration 5375, loss = 0.00465360
Iteration 5376, loss = 0.00465293
Iteration 5377, loss = 0.00465154
Iteration 5378, loss = 0.00465078
Iteration 5379, loss = 0.00464951
Iteration 5380, loss = 0.00464858
Iteration 5381, loss = 0.00464752
Iteration 5382, loss = 0.00464636
Iteration 5383, loss = 0.00464525
Iteration 5384, loss = 0.00464425
Iteration 5385, loss = 0.00464311
Iteration 5386, loss = 0.00464207
Iteration 5387, loss = 0.00464101
Iteration 5388, loss = 0.00464007
Iteration 5389, loss = 0.00463895
Iteration 5390, loss = 0.00463787
Iteration 5391, loss = 0.00463658
Iteration 5392, loss = 0.00463528
Iteration 5393, loss = 0.00463484
Iteration 5394, loss = 0.00463309
Iteration 5395, loss = 0.00463206
Iteration 5396, loss = 0.00463151
Iteration 5397, loss = 0.00463009
Iteration 5398, loss = 0.00462892
Iteration 5399, loss = 0.00462779
Iteration 5400, loss = 0.00462672
Iteration 5401, loss = 0.00462601
Iteration 5402, loss = 0.00462473
Iteration 5403, loss = 0.00462353
Iteration 5404, loss = 0.00462225
Iteration 5405, loss = 0.00462130
Iteration 5406, loss = 0.00461988
Iteration 5407, loss = 0.00461902
Iteration 5408, loss = 0.00461805
Iteration 5409, loss = 0.00461696
Iteration 5410, loss = 0.00461653
Iteration 5411, loss = 0.00461514
Iteration 5412, loss = 0.00461403
Iteration 5413, loss = 0.00461318
Iteration 5414, loss = 0.00461135
Iteration 5415, loss = 0.00461009
Iteration 5416, loss = 0.00460855
Iteration 5417, loss = 0.00460929
Iteration 5418, loss = 0.00460730
Iteration 5419, loss = 0.00460661
Iteration 5420, loss = 0.00460480
Iteration 5421, loss = 0.00460358
Iteration 5422, loss = 0.00460254
Iteration 5423, loss = 0.00460143
Iteration 5424, loss = 0.00460033
Iteration 5425, loss = 0.00459905
Iteration 5426, loss = 0.00459760
Iteration 5427, loss = 0.00459662
Iteration 5428, loss = 0.00459552
Iteration 5429, loss = 0.00459428
Iteration 5430, loss = 0.00459340
Iteration 5431, loss = 0.00459205
Iteration 5432, loss = 0.00459126
Iteration 5433, loss = 0.00458994
Iteration 5434, loss = 0.00458876
Iteration 5435, loss = 0.00458773
Iteration 5436, loss = 0.00458673
Iteration 5437, loss = 0.00458558
Iteration 5438, loss = 0.00458465
Iteration 5439, loss = 0.00458365
Iteration 5440, loss = 0.00458256
Iteration 5441, loss = 0.00458207
Iteration 5442, loss = 0.00458075
Iteration 5443, loss = 0.00457973
Iteration 5444, loss = 0.00457871
Iteration 5445, loss = 0.00457771
Iteration 5446, loss = 0.00457671
Iteration 5447, loss = 0.00457577
Iteration 5448, loss = 0.00457462
Iteration 5449, loss = 0.00457372
Iteration 5450, loss = 0.00457260
Iteration 5451, loss = 0.00457154
Iteration 5452, loss = 0.00457063
Iteration 5453, loss = 0.00456934
Iteration 5454, loss = 0.00457023
Iteration 5455, loss = 0.00456762
Iteration 5456, loss = 0.00456656
Iteration 5457, loss = 0.00456563
Iteration 5458, loss = 0.00456446
Iteration 5459, loss = 0.00456334
Iteration 5460, loss = 0.00456234
Iteration 5461, loss = 0.00456125
Iteration 5462, loss = 0.00456030
Iteration 5463, loss = 0.00455951
Iteration 5464, loss = 0.00455847
Iteration 5465, loss = 0.00455744
Iteration 5466, loss = 0.00455649
Iteration 5467, loss = 0.00455571
Iteration 5468, loss = 0.00455486
Iteration 5469, loss = 0.00455412
Iteration 5470, loss = 0.00455295
Iteration 5471, loss = 0.00455191
Iteration 5472, loss = 0.00455092
Iteration 5473, loss = 0.00454991
Iteration 5474, loss = 0.00454885
Iteration 5475, loss = 0.00454843
Iteration 5476, loss = 0.00454752
Iteration 5477, loss = 0.00454741
Iteration 5478, loss = 0.00454584
Iteration 5479, loss = 0.00454504
Iteration 5480, loss = 0.00454391
Iteration 5481, loss = 0.00454298
Iteration 5482, loss = 0.00454191
Iteration 5483, loss = 0.00454100
Iteration 5484, loss = 0.00454007
Iteration 5485, loss = 0.00453871
Iteration 5486, loss = 0.00453766
Iteration 5487, loss = 0.00453668
Iteration 5488, loss = 0.00453668
Iteration 5489, loss = 0.00453482
Iteration 5490, loss = 0.00453358
Iteration 5491, loss = 0.00453250
Iteration 5492, loss = 0.00453150
Iteration 5493, loss = 0.00453026
Iteration 5494, loss = 0.00452921
Iteration 5495, loss = 0.00452810
Iteration 5496, loss = 0.00452700
Iteration 5497, loss = 0.00452633
Iteration 5498, loss = 0.00452514
Iteration 5499, loss = 0.00452383
Iteration 5500, loss = 0.00452319
Iteration 5501, loss = 0.00452156
Iteration 5502, loss = 0.00452021
Iteration 5503, loss = 0.00451892
Iteration 5504, loss = 0.00451778
Iteration 5505, loss = 0.00451699
Iteration 5506, loss = 0.00451570
Iteration 5507, loss = 0.00451463
Iteration 5508, loss = 0.00451378
Iteration 5509, loss = 0.00451213
Iteration 5510, loss = 0.00451131
Iteration 5511, loss = 0.00451005
Iteration 5512, loss = 0.00450882
Iteration 5513, loss = 0.00450775
Iteration 5514, loss = 0.00450647
Iteration 5515, loss = 0.00450569
Iteration 5516, loss = 0.00450466
Iteration 5517, loss = 0.00450334
Iteration 5518, loss = 0.00450253
Iteration 5519, loss = 0.00450145
Iteration 5520, loss = 0.00450051
Iteration 5521, loss = 0.00449918
Iteration 5522, loss = 0.00449825
Iteration 5523, loss = 0.00449701
Iteration 5524, loss = 0.00449631
Iteration 5525, loss = 0.00449494
Iteration 5526, loss = 0.00449385
Iteration 5527, loss = 0.00449286
Iteration 5528, loss = 0.00449176
Iteration 5529, loss = 0.00449079
Iteration 5530, loss = 0.00448990
Iteration 5531, loss = 0.00448874
Iteration 5532, loss = 0.00448766
Iteration 5533, loss = 0.00448666
Iteration 5534, loss = 0.00448550
Iteration 5535, loss = 0.00448463
Iteration 5536, loss = 0.00448352
Iteration 5537, loss = 0.00448234
Iteration 5538, loss = 0.00448118
Iteration 5539, loss = 0.00448023
Iteration 5540, loss = 0.00447922
Iteration 5541, loss = 0.00447801
Iteration 5542, loss = 0.00447732
Iteration 5543, loss = 0.00447612
Iteration 5544, loss = 0.00447520
Iteration 5545, loss = 0.00447406
Iteration 5546, loss = 0.00447314
Iteration 5547, loss = 0.00447187
Iteration 5548, loss = 0.00447108
Iteration 5549, loss = 0.00447004
Iteration 5550, loss = 0.00446875
Iteration 5551, loss = 0.00446755
Iteration 5552, loss = 0.00446634
Iteration 5553, loss = 0.00446533
Iteration 5554, loss = 0.00446406
Iteration 5555, loss = 0.00446291
Iteration 5556, loss = 0.00446172
Iteration 5557, loss = 0.00446059
Iteration 5558, loss = 0.00445955
Iteration 5559, loss = 0.00445863
Iteration 5560, loss = 0.00445747
Iteration 5561, loss = 0.00445638
Iteration 5562, loss = 0.00445547
Iteration 5563, loss = 0.00445446
Iteration 5564, loss = 0.00445327
Iteration 5565, loss = 0.00445247
Iteration 5566, loss = 0.00445108
Iteration 5567, loss = 0.00445006
Iteration 5568, loss = 0.00444891
Iteration 5569, loss = 0.00444790
Iteration 5570, loss = 0.00444717
Iteration 5571, loss = 0.00444604
Iteration 5572, loss = 0.00444496
Iteration 5573, loss = 0.00444419
Iteration 5574, loss = 0.00444283
Iteration 5575, loss = 0.00444180
Iteration 5576, loss = 0.00444101
Iteration 5577, loss = 0.00443972
Iteration 5578, loss = 0.00443883
Iteration 5579, loss = 0.00443786
Iteration 5580, loss = 0.00443687
Iteration 5581, loss = 0.00443591
Iteration 5582, loss = 0.00443523
Iteration 5583, loss = 0.00443419
Iteration 5584, loss = 0.00443341
Iteration 5585, loss = 0.00443200
Iteration 5586, loss = 0.00443114
Iteration 5587, loss = 0.00443019
Iteration 5588, loss = 0.00442937
Iteration 5589, loss = 0.00442856
Iteration 5590, loss = 0.00442714
Iteration 5591, loss = 0.00442636
Iteration 5592, loss = 0.00442535
Iteration 5593, loss = 0.00442392
Iteration 5594, loss = 0.00442287
Iteration 5595, loss = 0.00442174
Iteration 5596, loss = 0.00442084
Iteration 5597, loss = 0.00441986
Iteration 5598, loss = 0.00441884
Iteration 5599, loss = 0.00441781
Iteration 5600, loss = 0.00441694
Iteration 5601, loss = 0.00441595
Iteration 5602, loss = 0.00441484
Iteration 5603, loss = 0.00441450
Iteration 5604, loss = 0.00441378
Iteration 5605, loss = 0.00441226
Iteration 5606, loss = 0.00441078
Iteration 5607, loss = 0.00440989
Iteration 5608, loss = 0.00440877
Iteration 5609, loss = 0.00440771
Iteration 5610, loss = 0.00440668
Iteration 5611, loss = 0.00440551
Iteration 5612, loss = 0.00440456
Iteration 5613, loss = 0.00440329
Iteration 5614, loss = 0.00440226
Iteration 5615, loss = 0.00440119
Iteration 5616, loss = 0.00440018
Iteration 5617, loss = 0.00440016
Iteration 5618, loss = 0.00439785
Iteration 5619, loss = 0.00439692
Iteration 5620, loss = 0.00439602
Iteration 5621, loss = 0.00439458
Iteration 5622, loss = 0.00439364
Iteration 5623, loss = 0.00439255
Iteration 5624, loss = 0.00439140
Iteration 5625, loss = 0.00438998
Iteration 5626, loss = 0.00438915
Iteration 5627, loss = 0.00438810
Iteration 5628, loss = 0.00438674
Iteration 5629, loss = 0.00438565
Iteration 5630, loss = 0.00438481
Iteration 5631, loss = 0.00438332
Iteration 5632, loss = 0.00438215
Iteration 5633, loss = 0.00438114
Iteration 5634, loss = 0.00438023
Iteration 5635, loss = 0.00437891
Iteration 5636, loss = 0.00437770
Iteration 5637, loss = 0.00437690
Iteration 5638, loss = 0.00437555
Iteration 5639, loss = 0.00437443
Iteration 5640, loss = 0.00437335
Iteration 5641, loss = 0.00437279
Iteration 5642, loss = 0.00437141
Iteration 5643, loss = 0.00437087
Iteration 5644, loss = 0.00436936
Iteration 5645, loss = 0.00436828
Iteration 5646, loss = 0.00436714
Iteration 5647, loss = 0.00436638
Iteration 5648, loss = 0.00436517
Iteration 5649, loss = 0.00436415
Iteration 5650, loss = 0.00436330
Iteration 5651, loss = 0.00436218
Iteration 5652, loss = 0.00436137
Iteration 5653, loss = 0.00436050
Iteration 5654, loss = 0.00435968
Iteration 5655, loss = 0.00435886
Iteration 5656, loss = 0.00435792
Iteration 5657, loss = 0.00435699
Iteration 5658, loss = 0.00435632
Iteration 5659, loss = 0.00435550
Iteration 5660, loss = 0.00435486
Iteration 5661, loss = 0.00435375
Iteration 5662, loss = 0.00435308
Iteration 5663, loss = 0.00435246
Iteration 5664, loss = 0.00435148
Iteration 5665, loss = 0.00435084
Iteration 5666, loss = 0.00435020
Iteration 5667, loss = 0.00434938
Iteration 5668, loss = 0.00434914
Iteration 5669, loss = 0.00434802
Iteration 5670, loss = 0.00434725
Iteration 5671, loss = 0.00434639
Iteration 5672, loss = 0.00434586
Iteration 5673, loss = 0.00434432
Iteration 5674, loss = 0.00434324
Iteration 5675, loss = 0.00434228
Iteration 5676, loss = 0.00434087
Iteration 5677, loss = 0.00433964
Iteration 5678, loss = 0.00433929
Iteration 5679, loss = 0.00433752
Iteration 5680, loss = 0.00433702
Iteration 5681, loss = 0.00433513
Iteration 5682, loss = 0.00433387
Iteration 5683, loss = 0.00433252
Iteration 5684, loss = 0.00433141
Iteration 5685, loss = 0.00433051
Iteration 5686, loss = 0.00432932
Iteration 5687, loss = 0.00432832
Iteration 5688, loss = 0.00432738
Iteration 5689, loss = 0.00432616
Iteration 5690, loss = 0.00432513
Iteration 5691, loss = 0.00432400
Iteration 5692, loss = 0.00432292
Iteration 5693, loss = 0.00432165
Iteration 5694, loss = 0.00432082
Iteration 5695, loss = 0.00431981
Iteration 5696, loss = 0.00431859
Iteration 5697, loss = 0.00431746
Iteration 5698, loss = 0.00431661
Iteration 5699, loss = 0.00431548
Iteration 5700, loss = 0.00431437
Iteration 5701, loss = 0.00431332
Iteration 5702, loss = 0.00431242
Iteration 5703, loss = 0.00431165
Iteration 5704, loss = 0.00430974
Iteration 5705, loss = 0.00430840
Iteration 5706, loss = 0.00430791
Iteration 5707, loss = 0.00430672
Iteration 5708, loss = 0.00430598
Iteration 5709, loss = 0.00430536
Iteration 5710, loss = 0.00430411
Iteration 5711, loss = 0.00430281
Iteration 5712, loss = 0.00430174
Iteration 5713, loss = 0.00430085
Iteration 5714, loss = 0.00430000
Iteration 5715, loss = 0.00429879
Iteration 5716, loss = 0.00429778
Iteration 5717, loss = 0.00429668
Iteration 5718, loss = 0.00429575
Iteration 5719, loss = 0.00429482
Iteration 5720, loss = 0.00429373
Iteration 5721, loss = 0.00429310
Iteration 5722, loss = 0.00429228
Iteration 5723, loss = 0.00429185
Iteration 5724, loss = 0.00429121
Iteration 5725, loss = 0.00428923
Iteration 5726, loss = 0.00428804
Iteration 5727, loss = 0.00428676
Iteration 5728, loss = 0.00428677
Iteration 5729, loss = 0.00428493
Iteration 5730, loss = 0.00428364
Iteration 5731, loss = 0.00428238
Iteration 5732, loss = 0.00428161
Iteration 5733, loss = 0.00428075
Iteration 5734, loss = 0.00427944
Iteration 5735, loss = 0.00427855
Iteration 5736, loss = 0.00427747
Iteration 5737, loss = 0.00427682
Iteration 5738, loss = 0.00427557
Iteration 5739, loss = 0.00427443
Iteration 5740, loss = 0.00427362
Iteration 5741, loss = 0.00427266
Iteration 5742, loss = 0.00427150
Iteration 5743, loss = 0.00427058
Iteration 5744, loss = 0.00427003
Iteration 5745, loss = 0.00426849
Iteration 5746, loss = 0.00426759
Iteration 5747, loss = 0.00426657
Iteration 5748, loss = 0.00426560
Iteration 5749, loss = 0.00426467
Iteration 5750, loss = 0.00426374
Iteration 5751, loss = 0.00426274
Iteration 5752, loss = 0.00426191
Iteration 5753, loss = 0.00426111
Iteration 5754, loss = 0.00425993
Iteration 5755, loss = 0.00425906
Iteration 5756, loss = 0.00425791
Iteration 5757, loss = 0.00425711
Iteration 5758, loss = 0.00425589
Iteration 5759, loss = 0.00425531
Iteration 5760, loss = 0.00425400
Iteration 5761, loss = 0.00425342
Iteration 5762, loss = 0.00425223
Iteration 5763, loss = 0.00425177
Iteration 5764, loss = 0.00425051
Iteration 5765, loss = 0.00424926
Iteration 5766, loss = 0.00424858
Iteration 5767, loss = 0.00424753
Iteration 5768, loss = 0.00424642
Iteration 5769, loss = 0.00424551
Iteration 5770, loss = 0.00424463
Iteration 5771, loss = 0.00424368
Iteration 5772, loss = 0.00424280
Iteration 5773, loss = 0.00424247
Iteration 5774, loss = 0.00424139
Iteration 5775, loss = 0.00424020
Iteration 5776, loss = 0.00423910
Iteration 5777, loss = 0.00423812
Iteration 5778, loss = 0.00423777
Iteration 5779, loss = 0.00423625
Iteration 5780, loss = 0.00423527
Iteration 5781, loss = 0.00423439
Iteration 5782, loss = 0.00423351
Iteration 5783, loss = 0.00423252
Iteration 5784, loss = 0.00423155
Iteration 5785, loss = 0.00423068
Iteration 5786, loss = 0.00422968
Iteration 5787, loss = 0.00422869
Iteration 5788, loss = 0.00422777
Iteration 5789, loss = 0.00422733
Iteration 5790, loss = 0.00422578
Iteration 5791, loss = 0.00422475
Iteration 5792, loss = 0.00422418
Iteration 5793, loss = 0.00422304
Iteration 5794, loss = 0.00422177
Iteration 5795, loss = 0.00422054
Iteration 5796, loss = 0.00421934
Iteration 5797, loss = 0.00421955
Iteration 5798, loss = 0.00421797
Iteration 5799, loss = 0.00421679
Iteration 5800, loss = 0.00421627
Iteration 5801, loss = 0.00421495
Iteration 5802, loss = 0.00421388
Iteration 5803, loss = 0.00421289
Iteration 5804, loss = 0.00421184
Iteration 5805, loss = 0.00421097
Iteration 5806, loss = 0.00420978
Iteration 5807, loss = 0.00420906
Iteration 5808, loss = 0.00420838
Iteration 5809, loss = 0.00420711
Iteration 5810, loss = 0.00420612
Iteration 5811, loss = 0.00420520
Iteration 5812, loss = 0.00420465
Iteration 5813, loss = 0.00420348
Iteration 5814, loss = 0.00420249
Iteration 5815, loss = 0.00420158
Iteration 5816, loss = 0.00420077
Iteration 5817, loss = 0.00419982
Iteration 5818, loss = 0.00419889
Iteration 5819, loss = 0.00419790
Iteration 5820, loss = 0.00419711
Iteration 5821, loss = 0.00419644
Iteration 5822, loss = 0.00419553
Iteration 5823, loss = 0.00419435
Iteration 5824, loss = 0.00419345
Iteration 5825, loss = 0.00419260
Iteration 5826, loss = 0.00419162
Iteration 5827, loss = 0.00419063
Iteration 5828, loss = 0.00418999
Iteration 5829, loss = 0.00418900
Iteration 5830, loss = 0.00418787
Iteration 5831, loss = 0.00418690
Iteration 5832, loss = 0.00418572
Iteration 5833, loss = 0.00418477
Iteration 5834, loss = 0.00418372
Iteration 5835, loss = 0.00418273
Iteration 5836, loss = 0.00418178
Iteration 5837, loss = 0.00418087
Iteration 5838, loss = 0.00417991
Iteration 5839, loss = 0.00417896
Iteration 5840, loss = 0.00417823
Iteration 5841, loss = 0.00417720
Iteration 5842, loss = 0.00417622
Iteration 5843, loss = 0.00417547
Iteration 5844, loss = 0.00417438
Iteration 5845, loss = 0.00417353
Iteration 5846, loss = 0.00417251
Iteration 5847, loss = 0.00417168
Iteration 5848, loss = 0.00417079
Iteration 5849, loss = 0.00416989
Iteration 5850, loss = 0.00416898
Iteration 5851, loss = 0.00416794
Iteration 5852, loss = 0.00416734
Iteration 5853, loss = 0.00416648
Iteration 5854, loss = 0.00416561
Iteration 5855, loss = 0.00416465
Iteration 5856, loss = 0.00416396
Iteration 5857, loss = 0.00416301
Iteration 5858, loss = 0.00416219
Iteration 5859, loss = 0.00416142
Iteration 5860, loss = 0.00416036
Iteration 5861, loss = 0.00415952
Iteration 5862, loss = 0.00415852
Iteration 5863, loss = 0.00415762
Iteration 5864, loss = 0.00415706
Iteration 5865, loss = 0.00415579
Iteration 5866, loss = 0.00415518
Iteration 5867, loss = 0.00415414
Iteration 5868, loss = 0.00415329
Iteration 5869, loss = 0.00415223
Iteration 5870, loss = 0.00415163
Iteration 5871, loss = 0.00415043
Iteration 5872, loss = 0.00414958
Iteration 5873, loss = 0.00414865
Iteration 5874, loss = 0.00414770
Iteration 5875, loss = 0.00414777
Iteration 5876, loss = 0.00414588
Iteration 5877, loss = 0.00414480
Iteration 5878, loss = 0.00414390
Iteration 5879, loss = 0.00414298
Iteration 5880, loss = 0.00414195
Iteration 5881, loss = 0.00414114
Iteration 5882, loss = 0.00414021
Iteration 5883, loss = 0.00414027
Iteration 5884, loss = 0.00413854
Iteration 5885, loss = 0.00413763
Iteration 5886, loss = 0.00413667
Iteration 5887, loss = 0.00413586
Iteration 5888, loss = 0.00413493
Iteration 5889, loss = 0.00413442
Iteration 5890, loss = 0.00413336
Iteration 5891, loss = 0.00413246
Iteration 5892, loss = 0.00413156
Iteration 5893, loss = 0.00413073
Iteration 5894, loss = 0.00412978
Iteration 5895, loss = 0.00412901
Iteration 5896, loss = 0.00412816
Iteration 5897, loss = 0.00412680
Iteration 5898, loss = 0.00412613
Iteration 5899, loss = 0.00412520
Iteration 5900, loss = 0.00412433
Iteration 5901, loss = 0.00412385
Iteration 5902, loss = 0.00412267
Iteration 5903, loss = 0.00412180
Iteration 5904, loss = 0.00412091
Iteration 5905, loss = 0.00411998
Iteration 5906, loss = 0.00411915
Iteration 5907, loss = 0.00411845
Iteration 5908, loss = 0.00411746
Iteration 5909, loss = 0.00411665
Iteration 5910, loss = 0.00411594
Iteration 5911, loss = 0.00411505
Iteration 5912, loss = 0.00411399
Iteration 5913, loss = 0.00411332
Iteration 5914, loss = 0.00411234
Iteration 5915, loss = 0.00411149
Iteration 5916, loss = 0.00411058
Iteration 5917, loss = 0.00410968
Iteration 5918, loss = 0.00410876
Iteration 5919, loss = 0.00410872
Iteration 5920, loss = 0.00410723
Iteration 5921, loss = 0.00410637
Iteration 5922, loss = 0.00410553
Iteration 5923, loss = 0.00410511
Iteration 5924, loss = 0.00410398
Iteration 5925, loss = 0.00410306
Iteration 5926, loss = 0.00410212
Iteration 5927, loss = 0.00410126
Iteration 5928, loss = 0.00410042
Iteration 5929, loss = 0.00409940
Iteration 5930, loss = 0.00409851
Iteration 5931, loss = 0.00409793
Iteration 5932, loss = 0.00409717
Iteration 5933, loss = 0.00409556
Iteration 5934, loss = 0.00409461
Iteration 5935, loss = 0.00409408
Iteration 5936, loss = 0.00409259
Iteration 5937, loss = 0.00409152
Iteration 5938, loss = 0.00409083
Iteration 5939, loss = 0.00408991
Iteration 5940, loss = 0.00408893
Iteration 5941, loss = 0.00408808
Iteration 5942, loss = 0.00408686
Iteration 5943, loss = 0.00408591
Iteration 5944, loss = 0.00408529
Iteration 5945, loss = 0.00408418
Iteration 5946, loss = 0.00408374
Iteration 5947, loss = 0.00408246
Iteration 5948, loss = 0.00408165
Iteration 5949, loss = 0.00408068
Iteration 5950, loss = 0.00407988
Iteration 5951, loss = 0.00407894
Iteration 5952, loss = 0.00407837
Iteration 5953, loss = 0.00407723
Iteration 5954, loss = 0.00407639
Iteration 5955, loss = 0.00407557
Iteration 5956, loss = 0.00407467
Iteration 5957, loss = 0.00407391
Iteration 5958, loss = 0.00407299
Iteration 5959, loss = 0.00407219
Iteration 5960, loss = 0.00407113
Iteration 5961, loss = 0.00407020
Iteration 5962, loss = 0.00406935
Iteration 5963, loss = 0.00406862
Iteration 5964, loss = 0.00406779
Iteration 5965, loss = 0.00406669
Iteration 5966, loss = 0.00406556
Iteration 5967, loss = 0.00406512
Iteration 5968, loss = 0.00406389
Iteration 5969, loss = 0.00406300
Iteration 5970, loss = 0.00406230
Iteration 5971, loss = 0.00406149
Iteration 5972, loss = 0.00406038
Iteration 5973, loss = 0.00405962
Iteration 5974, loss = 0.00405873
Iteration 5975, loss = 0.00405790
Iteration 5976, loss = 0.00405732
Iteration 5977, loss = 0.00405631
Iteration 5978, loss = 0.00405547
Iteration 5979, loss = 0.00405466
Iteration 5980, loss = 0.00405389
Iteration 5981, loss = 0.00405300
Iteration 5982, loss = 0.00405226
Iteration 5983, loss = 0.00405199
Iteration 5984, loss = 0.00405087
Iteration 5985, loss = 0.00405011
Iteration 5986, loss = 0.00404918
Iteration 5987, loss = 0.00404831
Iteration 5988, loss = 0.00404692
Iteration 5989, loss = 0.00404598
Iteration 5990, loss = 0.00404530
Iteration 5991, loss = 0.00404423
Iteration 5992, loss = 0.00404330
Iteration 5993, loss = 0.00404256
Iteration 5994, loss = 0.00404167
Iteration 5995, loss = 0.00404080
Iteration 5996, loss = 0.00404014
Iteration 5997, loss = 0.00403932
Iteration 5998, loss = 0.00403851
Iteration 5999, loss = 0.00403853
Iteration 6000, loss = 0.00403672
Iteration 6001, loss = 0.00403553
Iteration 6002, loss = 0.00403442
Iteration 6003, loss = 0.00403379
Iteration 6004, loss = 0.00403236
Iteration 6005, loss = 0.00403191
Iteration 6006, loss = 0.00403086
Iteration 6007, loss = 0.00403017
Iteration 6008, loss = 0.00402893
Iteration 6009, loss = 0.00402808
Iteration 6010, loss = 0.00402721
Iteration 6011, loss = 0.00402643
Iteration 6012, loss = 0.00402559
Iteration 6013, loss = 0.00402528
Iteration 6014, loss = 0.00402410
Iteration 6015, loss = 0.00402315
Iteration 6016, loss = 0.00402219
Iteration 6017, loss = 0.00402131
Iteration 6018, loss = 0.00402063
Iteration 6019, loss = 0.00401974
Iteration 6020, loss = 0.00401934
Iteration 6021, loss = 0.00401824
Iteration 6022, loss = 0.00401739
Iteration 6023, loss = 0.00401654
Iteration 6024, loss = 0.00401589
Iteration 6025, loss = 0.00401537
Iteration 6026, loss = 0.00401437
Iteration 6027, loss = 0.00401357
Iteration 6028, loss = 0.00401276
Iteration 6029, loss = 0.00401200
Iteration 6030, loss = 0.00401116
Iteration 6031, loss = 0.00401026
Iteration 6032, loss = 0.00400945
Iteration 6033, loss = 0.00400880
Iteration 6034, loss = 0.00400773
Iteration 6035, loss = 0.00400734
Iteration 6036, loss = 0.00400606
Iteration 6037, loss = 0.00400496
Iteration 6038, loss = 0.00400426
Iteration 6039, loss = 0.00400306
Iteration 6040, loss = 0.00400204
Iteration 6041, loss = 0.00400101
Iteration 6042, loss = 0.00400047
Iteration 6043, loss = 0.00399936
Iteration 6044, loss = 0.00399876
Iteration 6045, loss = 0.00399743
Iteration 6046, loss = 0.00399657
Iteration 6047, loss = 0.00399560
Iteration 6048, loss = 0.00399466
Iteration 6049, loss = 0.00399376
Iteration 6050, loss = 0.00399269
Iteration 6051, loss = 0.00399236
Iteration 6052, loss = 0.00399104
Iteration 6053, loss = 0.00399052
Iteration 6054, loss = 0.00398938
Iteration 6055, loss = 0.00398833
Iteration 6056, loss = 0.00398763
Iteration 6057, loss = 0.00398668
Iteration 6058, loss = 0.00398583
Iteration 6059, loss = 0.00398551
Iteration 6060, loss = 0.00398421
Iteration 6061, loss = 0.00398326
Iteration 6062, loss = 0.00398255
Iteration 6063, loss = 0.00398176
Iteration 6064, loss = 0.00398069
Iteration 6065, loss = 0.00397969
Iteration 6066, loss = 0.00397886
Iteration 6067, loss = 0.00397800
Iteration 6068, loss = 0.00397719
Iteration 6069, loss = 0.00397632
Iteration 6070, loss = 0.00397563
Iteration 6071, loss = 0.00397461
Iteration 6072, loss = 0.00397391
Iteration 6073, loss = 0.00397303
Iteration 6074, loss = 0.00397224
Iteration 6075, loss = 0.00397133
Iteration 6076, loss = 0.00397060
Iteration 6077, loss = 0.00396991
Iteration 6078, loss = 0.00396878
Iteration 6079, loss = 0.00396793
Iteration 6080, loss = 0.00396738
Iteration 6081, loss = 0.00396599
Iteration 6082, loss = 0.00396515
Iteration 6083, loss = 0.00396416
Iteration 6084, loss = 0.00396318
Iteration 6085, loss = 0.00396221
Iteration 6086, loss = 0.00396146
Iteration 6087, loss = 0.00396061
Iteration 6088, loss = 0.00395979
Iteration 6089, loss = 0.00395883
Iteration 6090, loss = 0.00395792
Iteration 6091, loss = 0.00395701
Iteration 6092, loss = 0.00395620
Iteration 6093, loss = 0.00395540
Iteration 6094, loss = 0.00395441
Iteration 6095, loss = 0.00395351
Iteration 6096, loss = 0.00395273
Iteration 6097, loss = 0.00395153
Iteration 6098, loss = 0.00395062
Iteration 6099, loss = 0.00394990
Iteration 6100, loss = 0.00394880
Iteration 6101, loss = 0.00394794
Iteration 6102, loss = 0.00394690
Iteration 6103, loss = 0.00394643
Iteration 6104, loss = 0.00394537
Iteration 6105, loss = 0.00394456
Iteration 6106, loss = 0.00394361
Iteration 6107, loss = 0.00394294
Iteration 6108, loss = 0.00394207
Iteration 6109, loss = 0.00394105
Iteration 6110, loss = 0.00394018
Iteration 6111, loss = 0.00393931
Iteration 6112, loss = 0.00393840
Iteration 6113, loss = 0.00393766
Iteration 6114, loss = 0.00393685
Iteration 6115, loss = 0.00393635
Iteration 6116, loss = 0.00393544
Iteration 6117, loss = 0.00393455
Iteration 6118, loss = 0.00393372
Iteration 6119, loss = 0.00393292
Iteration 6120, loss = 0.00393202
Iteration 6121, loss = 0.00393118
Iteration 6122, loss = 0.00393037
Iteration 6123, loss = 0.00392964
Iteration 6124, loss = 0.00392884
Iteration 6125, loss = 0.00392836
Iteration 6126, loss = 0.00392729
Iteration 6127, loss = 0.00392649
Iteration 6128, loss = 0.00392554
Iteration 6129, loss = 0.00392475
Iteration 6130, loss = 0.00392412
Iteration 6131, loss = 0.00392466
Iteration 6132, loss = 0.00392251
Iteration 6133, loss = 0.00392195
Iteration 6134, loss = 0.00392069
Iteration 6135, loss = 0.00391939
Iteration 6136, loss = 0.00391909
Iteration 6137, loss = 0.00391764
Iteration 6138, loss = 0.00391713
Iteration 6139, loss = 0.00391599
Iteration 6140, loss = 0.00391515
Iteration 6141, loss = 0.00391453
Iteration 6142, loss = 0.00391391
Iteration 6143, loss = 0.00391263
Iteration 6144, loss = 0.00391193
Iteration 6145, loss = 0.00391084
Iteration 6146, loss = 0.00391022
Iteration 6147, loss = 0.00390935
Iteration 6148, loss = 0.00390832
Iteration 6149, loss = 0.00390751
Iteration 6150, loss = 0.00390684
Iteration 6151, loss = 0.00390584
Iteration 6152, loss = 0.00390512
Iteration 6153, loss = 0.00390419
Iteration 6154, loss = 0.00390344
Iteration 6155, loss = 0.00390282
Iteration 6156, loss = 0.00390183
Iteration 6157, loss = 0.00390097
Iteration 6158, loss = 0.00389987
Iteration 6159, loss = 0.00389929
Iteration 6160, loss = 0.00389851
Iteration 6161, loss = 0.00389741
Iteration 6162, loss = 0.00389651
Iteration 6163, loss = 0.00389580
Iteration 6164, loss = 0.00389516
Iteration 6165, loss = 0.00389408
Iteration 6166, loss = 0.00389307
Iteration 6167, loss = 0.00389207
Iteration 6168, loss = 0.00389208
Iteration 6169, loss = 0.00389140
Iteration 6170, loss = 0.00388992
Iteration 6171, loss = 0.00388898
Iteration 6172, loss = 0.00388809
Iteration 6173, loss = 0.00388746
Iteration 6174, loss = 0.00388617
Iteration 6175, loss = 0.00388525
Iteration 6176, loss = 0.00388455
Iteration 6177, loss = 0.00388379
Iteration 6178, loss = 0.00388279
Iteration 6179, loss = 0.00388173
Iteration 6180, loss = 0.00388104
Iteration 6181, loss = 0.00387997
Iteration 6182, loss = 0.00387948
Iteration 6183, loss = 0.00387839
Iteration 6184, loss = 0.00387766
Iteration 6185, loss = 0.00387672
Iteration 6186, loss = 0.00387578
Iteration 6187, loss = 0.00387488
Iteration 6188, loss = 0.00387421
Iteration 6189, loss = 0.00387316
Iteration 6190, loss = 0.00387227
Iteration 6191, loss = 0.00387167
Iteration 6192, loss = 0.00387090
Iteration 6193, loss = 0.00387013
Iteration 6194, loss = 0.00386913
Iteration 6195, loss = 0.00386824
Iteration 6196, loss = 0.00386765
Iteration 6197, loss = 0.00386666
Iteration 6198, loss = 0.00386583
Iteration 6199, loss = 0.00386521
Iteration 6200, loss = 0.00386448
Iteration 6201, loss = 0.00386355
Iteration 6202, loss = 0.00386283
Iteration 6203, loss = 0.00386203
Iteration 6204, loss = 0.00386105
Iteration 6205, loss = 0.00386033
Iteration 6206, loss = 0.00385943
Iteration 6207, loss = 0.00385880
Iteration 6208, loss = 0.00385786
Iteration 6209, loss = 0.00385759
Iteration 6210, loss = 0.00385645
Iteration 6211, loss = 0.00385583
Iteration 6212, loss = 0.00385499
Iteration 6213, loss = 0.00385414
Iteration 6214, loss = 0.00385328
Iteration 6215, loss = 0.00385270
Iteration 6216, loss = 0.00385180
Iteration 6217, loss = 0.00385103
Iteration 6218, loss = 0.00385033
Iteration 6219, loss = 0.00384943
Iteration 6220, loss = 0.00384875
Iteration 6221, loss = 0.00384852
Iteration 6222, loss = 0.00384724
Iteration 6223, loss = 0.00384640
Iteration 6224, loss = 0.00384559
Iteration 6225, loss = 0.00384463
Iteration 6226, loss = 0.00384423
Iteration 6227, loss = 0.00384306
Iteration 6228, loss = 0.00384210
Iteration 6229, loss = 0.00384135
Iteration 6230, loss = 0.00384040
Iteration 6231, loss = 0.00383959
Iteration 6232, loss = 0.00383884
Iteration 6233, loss = 0.00383804
Iteration 6234, loss = 0.00383785
Iteration 6235, loss = 0.00383654
Iteration 6236, loss = 0.00383552
Iteration 6237, loss = 0.00383487
Iteration 6238, loss = 0.00383396
Iteration 6239, loss = 0.00383322
Iteration 6240, loss = 0.00383231
Iteration 6241, loss = 0.00383148
Iteration 6242, loss = 0.00383067
Iteration 6243, loss = 0.00382970
Iteration 6244, loss = 0.00382906
Iteration 6245, loss = 0.00382813
Iteration 6246, loss = 0.00382752
Iteration 6247, loss = 0.00382668
Iteration 6248, loss = 0.00382602
Iteration 6249, loss = 0.00382501
Iteration 6250, loss = 0.00382417
Iteration 6251, loss = 0.00382364
Iteration 6252, loss = 0.00382271
Iteration 6253, loss = 0.00382184
Iteration 6254, loss = 0.00382097
Iteration 6255, loss = 0.00382019
Iteration 6256, loss = 0.00381930
Iteration 6257, loss = 0.00381872
Iteration 6258, loss = 0.00381767
Iteration 6259, loss = 0.00381688
Iteration 6260, loss = 0.00381622
Iteration 6261, loss = 0.00381520
Iteration 6262, loss = 0.00381424
Iteration 6263, loss = 0.00381324
Iteration 6264, loss = 0.00381264
Iteration 6265, loss = 0.00381176
Iteration 6266, loss = 0.00381135
Iteration 6267, loss = 0.00381052
Iteration 6268, loss = 0.00380957
Iteration 6269, loss = 0.00380879
Iteration 6270, loss = 0.00380783
Iteration 6271, loss = 0.00380711
Iteration 6272, loss = 0.00380625
Iteration 6273, loss = 0.00380549
Iteration 6274, loss = 0.00380477
Iteration 6275, loss = 0.00380400
Iteration 6276, loss = 0.00380299
Iteration 6277, loss = 0.00380209
Iteration 6278, loss = 0.00380151
Iteration 6279, loss = 0.00380076
Iteration 6280, loss = 0.00380045
Iteration 6281, loss = 0.00379930
Iteration 6282, loss = 0.00379852
Iteration 6283, loss = 0.00379823
Iteration 6284, loss = 0.00379731
Iteration 6285, loss = 0.00379625
Iteration 6286, loss = 0.00379565
Iteration 6287, loss = 0.00379586
Iteration 6288, loss = 0.00379423
Iteration 6289, loss = 0.00379341
Iteration 6290, loss = 0.00379272
Iteration 6291, loss = 0.00379187
Iteration 6292, loss = 0.00379109
Iteration 6293, loss = 0.00379042
Iteration 6294, loss = 0.00378980
Iteration 6295, loss = 0.00378868
Iteration 6296, loss = 0.00378789
Iteration 6297, loss = 0.00378710
Iteration 6298, loss = 0.00378635
Iteration 6299, loss = 0.00378577
Iteration 6300, loss = 0.00378489
Iteration 6301, loss = 0.00378418
Iteration 6302, loss = 0.00378335
Iteration 6303, loss = 0.00378256
Iteration 6304, loss = 0.00378177
Iteration 6305, loss = 0.00378099
Iteration 6306, loss = 0.00378009
Iteration 6307, loss = 0.00377946
Iteration 6308, loss = 0.00377859
Iteration 6309, loss = 0.00377763
Iteration 6310, loss = 0.00377680
Iteration 6311, loss = 0.00377613
Iteration 6312, loss = 0.00377518
Iteration 6313, loss = 0.00377482
Iteration 6314, loss = 0.00377374
Iteration 6315, loss = 0.00377307
Iteration 6316, loss = 0.00377189
Iteration 6317, loss = 0.00377113
Iteration 6318, loss = 0.00377031
Iteration 6319, loss = 0.00376965
Iteration 6320, loss = 0.00376875
Iteration 6321, loss = 0.00376793
Iteration 6322, loss = 0.00376746
Iteration 6323, loss = 0.00376622
Iteration 6324, loss = 0.00376535
Iteration 6325, loss = 0.00376500
Iteration 6326, loss = 0.00376402
Iteration 6327, loss = 0.00376346
Iteration 6328, loss = 0.00376257
Iteration 6329, loss = 0.00376164
Iteration 6330, loss = 0.00376067
Iteration 6331, loss = 0.00375980
Iteration 6332, loss = 0.00375908
Iteration 6333, loss = 0.00375820
Iteration 6334, loss = 0.00375747
Iteration 6335, loss = 0.00375648
Iteration 6336, loss = 0.00375579
Iteration 6337, loss = 0.00375495
Iteration 6338, loss = 0.00375431
Iteration 6339, loss = 0.00375347
Iteration 6340, loss = 0.00375274
Iteration 6341, loss = 0.00375205
Iteration 6342, loss = 0.00375139
Iteration 6343, loss = 0.00375069
Iteration 6344, loss = 0.00375003
Iteration 6345, loss = 0.00374934
Iteration 6346, loss = 0.00374921
Iteration 6347, loss = 0.00374813
Iteration 6348, loss = 0.00374750
Iteration 6349, loss = 0.00374665
Iteration 6350, loss = 0.00374640
Iteration 6351, loss = 0.00374534
Iteration 6352, loss = 0.00374466
Iteration 6353, loss = 0.00374391
Iteration 6354, loss = 0.00374329
Iteration 6355, loss = 0.00374239
Iteration 6356, loss = 0.00374181
Iteration 6357, loss = 0.00374093
Iteration 6358, loss = 0.00374015
Iteration 6359, loss = 0.00373940
Iteration 6360, loss = 0.00373866
Iteration 6361, loss = 0.00373797
Iteration 6362, loss = 0.00373737
Iteration 6363, loss = 0.00373666
Iteration 6364, loss = 0.00373599
Iteration 6365, loss = 0.00373528
Iteration 6366, loss = 0.00373509
Iteration 6367, loss = 0.00373408
Iteration 6368, loss = 0.00373350
Iteration 6369, loss = 0.00373276
Iteration 6370, loss = 0.00373211
Iteration 6371, loss = 0.00373144
Iteration 6372, loss = 0.00373084
Iteration 6373, loss = 0.00373013
Iteration 6374, loss = 0.00372950
Iteration 6375, loss = 0.00372904
Iteration 6376, loss = 0.00372837
Iteration 6377, loss = 0.00372812
Iteration 6378, loss = 0.00372727
Iteration 6379, loss = 0.00372646
Iteration 6380, loss = 0.00372581
Iteration 6381, loss = 0.00372521
Iteration 6382, loss = 0.00372514
Iteration 6383, loss = 0.00372398
Iteration 6384, loss = 0.00372328
Iteration 6385, loss = 0.00372256
Iteration 6386, loss = 0.00372218
Iteration 6387, loss = 0.00372143
Iteration 6388, loss = 0.00372048
Iteration 6389, loss = 0.00371975
Iteration 6390, loss = 0.00371927
Iteration 6391, loss = 0.00371903
Iteration 6392, loss = 0.00371841
Iteration 6393, loss = 0.00371674
Iteration 6394, loss = 0.00371563
Iteration 6395, loss = 0.00371499
Iteration 6396, loss = 0.00371405
Iteration 6397, loss = 0.00371283
Iteration 6398, loss = 0.00371251
Iteration 6399, loss = 0.00371144
Iteration 6400, loss = 0.00371075
Iteration 6401, loss = 0.00370989
Iteration 6402, loss = 0.00370930
Iteration 6403, loss = 0.00370854
Iteration 6404, loss = 0.00370806
Iteration 6405, loss = 0.00370729
Iteration 6406, loss = 0.00370667
Iteration 6407, loss = 0.00370593
Iteration 6408, loss = 0.00370559
Iteration 6409, loss = 0.00370468
Iteration 6410, loss = 0.00370403
Iteration 6411, loss = 0.00370331
Iteration 6412, loss = 0.00370270
Iteration 6413, loss = 0.00370219
Iteration 6414, loss = 0.00370168
Iteration 6415, loss = 0.00370099
Iteration 6416, loss = 0.00370026
Iteration 6417, loss = 0.00369951
Iteration 6418, loss = 0.00369877
Iteration 6419, loss = 0.00369811
Iteration 6420, loss = 0.00369724
Iteration 6421, loss = 0.00369629
Iteration 6422, loss = 0.00369569
Iteration 6423, loss = 0.00369486
Iteration 6424, loss = 0.00369389
Iteration 6425, loss = 0.00369316
Iteration 6426, loss = 0.00369222
Iteration 6427, loss = 0.00369150
Iteration 6428, loss = 0.00369065
Iteration 6429, loss = 0.00369006
Iteration 6430, loss = 0.00368929
Iteration 6431, loss = 0.00368869
Iteration 6432, loss = 0.00368775
Iteration 6433, loss = 0.00368674
Iteration 6434, loss = 0.00368581
Iteration 6435, loss = 0.00368465
Iteration 6436, loss = 0.00368344
Iteration 6437, loss = 0.00368249
Iteration 6438, loss = 0.00368226
Iteration 6439, loss = 0.00368040
Iteration 6440, loss = 0.00368013
Iteration 6441, loss = 0.00367887
Iteration 6442, loss = 0.00367808
Iteration 6443, loss = 0.00367715
Iteration 6444, loss = 0.00367675
Iteration 6445, loss = 0.00367550
Iteration 6446, loss = 0.00367469
Iteration 6447, loss = 0.00367390
Iteration 6448, loss = 0.00367299
Iteration 6449, loss = 0.00367243
Iteration 6450, loss = 0.00367156
Iteration 6451, loss = 0.00367072
Iteration 6452, loss = 0.00367005
Iteration 6453, loss = 0.00366927
Iteration 6454, loss = 0.00366880
Iteration 6455, loss = 0.00366783
Iteration 6456, loss = 0.00366717
Iteration 6457, loss = 0.00366632
Iteration 6458, loss = 0.00366575
Iteration 6459, loss = 0.00366500
Iteration 6460, loss = 0.00366418
Iteration 6461, loss = 0.00366360
Iteration 6462, loss = 0.00366280
Iteration 6463, loss = 0.00366216
Iteration 6464, loss = 0.00366143
Iteration 6465, loss = 0.00366073
Iteration 6466, loss = 0.00366054
Iteration 6467, loss = 0.00365941
Iteration 6468, loss = 0.00365871
Iteration 6469, loss = 0.00365828
Iteration 6470, loss = 0.00365727
Iteration 6471, loss = 0.00365657
Iteration 6472, loss = 0.00365587
Iteration 6473, loss = 0.00365520
Iteration 6474, loss = 0.00365456
Iteration 6475, loss = 0.00365368
Iteration 6476, loss = 0.00365306
Iteration 6477, loss = 0.00365238
Iteration 6478, loss = 0.00365211
Iteration 6479, loss = 0.00365120
Iteration 6480, loss = 0.00365034
Iteration 6481, loss = 0.00364978
Iteration 6482, loss = 0.00364914
Iteration 6483, loss = 0.00364887
Iteration 6484, loss = 0.00364798
Iteration 6485, loss = 0.00364731
Iteration 6486, loss = 0.00364645
Iteration 6487, loss = 0.00364573
Iteration 6488, loss = 0.00364504
Iteration 6489, loss = 0.00364465
Iteration 6490, loss = 0.00364407
Iteration 6491, loss = 0.00364281
Iteration 6492, loss = 0.00364190
Iteration 6493, loss = 0.00364127
Iteration 6494, loss = 0.00364045
Iteration 6495, loss = 0.00363964
Iteration 6496, loss = 0.00363879
Iteration 6497, loss = 0.00363805
Iteration 6498, loss = 0.00363759
Iteration 6499, loss = 0.00363634
Iteration 6500, loss = 0.00363527
Iteration 6501, loss = 0.00363535
Iteration 6502, loss = 0.00363408
Iteration 6503, loss = 0.00363341
Iteration 6504, loss = 0.00363242
Iteration 6505, loss = 0.00363168
Iteration 6506, loss = 0.00363101
Iteration 6507, loss = 0.00363025
Iteration 6508, loss = 0.00362940
Iteration 6509, loss = 0.00362886
Iteration 6510, loss = 0.00362793
Iteration 6511, loss = 0.00362732
Iteration 6512, loss = 0.00362693
Iteration 6513, loss = 0.00362604
Iteration 6514, loss = 0.00362527
Iteration 6515, loss = 0.00362453
Iteration 6516, loss = 0.00362393
Iteration 6517, loss = 0.00362317
Iteration 6518, loss = 0.00362254
Iteration 6519, loss = 0.00362180
Iteration 6520, loss = 0.00362115
Iteration 6521, loss = 0.00362072
Iteration 6522, loss = 0.00361990
Iteration 6523, loss = 0.00361952
Iteration 6524, loss = 0.00361823
Iteration 6525, loss = 0.00361745
Iteration 6526, loss = 0.00361678
Iteration 6527, loss = 0.00361626
Iteration 6528, loss = 0.00361526
Iteration 6529, loss = 0.00361478
Iteration 6530, loss = 0.00361385
Iteration 6531, loss = 0.00361312
Iteration 6532, loss = 0.00361228
Iteration 6533, loss = 0.00361156
Iteration 6534, loss = 0.00361092
Iteration 6535, loss = 0.00361025
Iteration 6536, loss = 0.00360960
Iteration 6537, loss = 0.00360890
Iteration 6538, loss = 0.00360825
Iteration 6539, loss = 0.00360759
Iteration 6540, loss = 0.00360705
Iteration 6541, loss = 0.00360647
Iteration 6542, loss = 0.00360622
Iteration 6543, loss = 0.00360530
Iteration 6544, loss = 0.00360463
Iteration 6545, loss = 0.00360394
Iteration 6546, loss = 0.00360339
Iteration 6547, loss = 0.00360247
Iteration 6548, loss = 0.00360180
Iteration 6549, loss = 0.00360107
Iteration 6550, loss = 0.00360042
Iteration 6551, loss = 0.00359968
Iteration 6552, loss = 0.00359894
Iteration 6553, loss = 0.00359844
Iteration 6554, loss = 0.00359761
Iteration 6555, loss = 0.00359688
Iteration 6556, loss = 0.00359616
Iteration 6557, loss = 0.00359585
Iteration 6558, loss = 0.00359492
Iteration 6559, loss = 0.00359402
Iteration 6560, loss = 0.00359325
Iteration 6561, loss = 0.00359239
Iteration 6562, loss = 0.00359196
Iteration 6563, loss = 0.00359101
Iteration 6564, loss = 0.00359035
Iteration 6565, loss = 0.00358941
Iteration 6566, loss = 0.00358839
Iteration 6567, loss = 0.00358827
Iteration 6568, loss = 0.00358709
Iteration 6569, loss = 0.00358621
Iteration 6570, loss = 0.00358556
Iteration 6571, loss = 0.00358492
Iteration 6572, loss = 0.00358414
Iteration 6573, loss = 0.00358346
Iteration 6574, loss = 0.00358257
Iteration 6575, loss = 0.00358185
Iteration 6576, loss = 0.00358113
Iteration 6577, loss = 0.00358054
Iteration 6578, loss = 0.00357962
Iteration 6579, loss = 0.00357891
Iteration 6580, loss = 0.00357825
Iteration 6581, loss = 0.00357756
Iteration 6582, loss = 0.00357686
Iteration 6583, loss = 0.00357639
Iteration 6584, loss = 0.00357551
Iteration 6585, loss = 0.00357478
Iteration 6586, loss = 0.00357401
Iteration 6587, loss = 0.00357371
Iteration 6588, loss = 0.00357285
Iteration 6589, loss = 0.00357207
Iteration 6590, loss = 0.00357142
Iteration 6591, loss = 0.00357075
Iteration 6592, loss = 0.00356999
Iteration 6593, loss = 0.00356941
Iteration 6594, loss = 0.00356867
Iteration 6595, loss = 0.00356835
Iteration 6596, loss = 0.00356768
Iteration 6597, loss = 0.00356726
Iteration 6598, loss = 0.00356695
Iteration 6599, loss = 0.00356596
Iteration 6600, loss = 0.00356521
Iteration 6601, loss = 0.00356453
Iteration 6602, loss = 0.00356375
Iteration 6603, loss = 0.00356319
Iteration 6604, loss = 0.00356236
Iteration 6605, loss = 0.00356172
Iteration 6606, loss = 0.00356109
Iteration 6607, loss = 0.00356032
Iteration 6608, loss = 0.00355969
Iteration 6609, loss = 0.00355902
Iteration 6610, loss = 0.00355841
Iteration 6611, loss = 0.00355812
Iteration 6612, loss = 0.00355739
Iteration 6613, loss = 0.00355662
Iteration 6614, loss = 0.00355582
Iteration 6615, loss = 0.00355521
Iteration 6616, loss = 0.00355434
Iteration 6617, loss = 0.00355376
Iteration 6618, loss = 0.00355301
Iteration 6619, loss = 0.00355235
Iteration 6620, loss = 0.00355147
Iteration 6621, loss = 0.00355065
Iteration 6622, loss = 0.00355003
Iteration 6623, loss = 0.00354926
Iteration 6624, loss = 0.00354861
Iteration 6625, loss = 0.00354783
Iteration 6626, loss = 0.00354704
Iteration 6627, loss = 0.00354632
Iteration 6628, loss = 0.00354564
Iteration 6629, loss = 0.00354499
Iteration 6630, loss = 0.00354437
Iteration 6631, loss = 0.00354371
Iteration 6632, loss = 0.00354359
Iteration 6633, loss = 0.00354274
Iteration 6634, loss = 0.00354185
Iteration 6635, loss = 0.00354113
Iteration 6636, loss = 0.00354047
Iteration 6637, loss = 0.00354001
Iteration 6638, loss = 0.00353933
Iteration 6639, loss = 0.00353877
Iteration 6640, loss = 0.00353784
Iteration 6641, loss = 0.00353712
Iteration 6642, loss = 0.00353643
Iteration 6643, loss = 0.00353574
Iteration 6644, loss = 0.00353525
Iteration 6645, loss = 0.00353429
Iteration 6646, loss = 0.00353363
Iteration 6647, loss = 0.00353303
Iteration 6648, loss = 0.00353239
Iteration 6649, loss = 0.00353157
Iteration 6650, loss = 0.00353094
Iteration 6651, loss = 0.00353027
Iteration 6652, loss = 0.00352945
Iteration 6653, loss = 0.00352894
Iteration 6654, loss = 0.00352822
Iteration 6655, loss = 0.00352742
Iteration 6656, loss = 0.00352678
Iteration 6657, loss = 0.00352611
Iteration 6658, loss = 0.00352557
Iteration 6659, loss = 0.00352485
Iteration 6660, loss = 0.00352421
Iteration 6661, loss = 0.00352374
Iteration 6662, loss = 0.00352299
Iteration 6663, loss = 0.00352222
Iteration 6664, loss = 0.00352152
Iteration 6665, loss = 0.00352091
Iteration 6666, loss = 0.00352024
Iteration 6667, loss = 0.00351943
Iteration 6668, loss = 0.00351886
Iteration 6669, loss = 0.00351832
Iteration 6670, loss = 0.00351727
Iteration 6671, loss = 0.00351668
Iteration 6672, loss = 0.00351589
Iteration 6673, loss = 0.00351518
Iteration 6674, loss = 0.00351455
Iteration 6675, loss = 0.00351380
Iteration 6676, loss = 0.00351309
Iteration 6677, loss = 0.00351238
Iteration 6678, loss = 0.00351173
Iteration 6679, loss = 0.00351114
Iteration 6680, loss = 0.00351049
Iteration 6681, loss = 0.00350980
Iteration 6682, loss = 0.00350923
Iteration 6683, loss = 0.00350850
Iteration 6684, loss = 0.00350781
Iteration 6685, loss = 0.00350720
Iteration 6686, loss = 0.00350659
Iteration 6687, loss = 0.00350617
Iteration 6688, loss = 0.00350539
Iteration 6689, loss = 0.00350468
Iteration 6690, loss = 0.00350407
Iteration 6691, loss = 0.00350344
Iteration 6692, loss = 0.00350289
Iteration 6693, loss = 0.00350228
Iteration 6694, loss = 0.00350190
Iteration 6695, loss = 0.00350109
Iteration 6696, loss = 0.00350054
Iteration 6697, loss = 0.00349987
Iteration 6698, loss = 0.00349966
Iteration 6699, loss = 0.00349870
Iteration 6700, loss = 0.00349773
Iteration 6701, loss = 0.00349702
Iteration 6702, loss = 0.00349638
Iteration 6703, loss = 0.00349568
Iteration 6704, loss = 0.00349499
Iteration 6705, loss = 0.00349463
Iteration 6706, loss = 0.00349376
Iteration 6707, loss = 0.00349292
Iteration 6708, loss = 0.00349240
Iteration 6709, loss = 0.00349156
Iteration 6710, loss = 0.00349088
Iteration 6711, loss = 0.00349022
Iteration 6712, loss = 0.00348956
Iteration 6713, loss = 0.00348902
Iteration 6714, loss = 0.00348859
Iteration 6715, loss = 0.00348792
Iteration 6716, loss = 0.00348743
Iteration 6717, loss = 0.00348705
Iteration 6718, loss = 0.00348625
Iteration 6719, loss = 0.00348562
Iteration 6720, loss = 0.00348524
Iteration 6721, loss = 0.00348453
Iteration 6722, loss = 0.00348374
Iteration 6723, loss = 0.00348308
Iteration 6724, loss = 0.00348248
Iteration 6725, loss = 0.00348202
Iteration 6726, loss = 0.00348107
Iteration 6727, loss = 0.00348043
Iteration 6728, loss = 0.00347968
Iteration 6729, loss = 0.00347896
Iteration 6730, loss = 0.00347830
Iteration 6731, loss = 0.00347772
Iteration 6732, loss = 0.00347690
Iteration 6733, loss = 0.00347625
Iteration 6734, loss = 0.00347553
Iteration 6735, loss = 0.00347486
Iteration 6736, loss = 0.00347422
Iteration 6737, loss = 0.00347371
Iteration 6738, loss = 0.00347338
Iteration 6739, loss = 0.00347243
Iteration 6740, loss = 0.00347195
Iteration 6741, loss = 0.00347114
Iteration 6742, loss = 0.00347057
Iteration 6743, loss = 0.00346988
Iteration 6744, loss = 0.00346924
Iteration 6745, loss = 0.00346869
Iteration 6746, loss = 0.00346829
Iteration 6747, loss = 0.00346770
Iteration 6748, loss = 0.00346684
Iteration 6749, loss = 0.00346592
Iteration 6750, loss = 0.00346522
Iteration 6751, loss = 0.00346453
Iteration 6752, loss = 0.00346377
Iteration 6753, loss = 0.00346321
Iteration 6754, loss = 0.00346228
Iteration 6755, loss = 0.00346165
Iteration 6756, loss = 0.00346092
Iteration 6757, loss = 0.00346029
Iteration 6758, loss = 0.00345978
Iteration 6759, loss = 0.00345917
Iteration 6760, loss = 0.00345871
Iteration 6761, loss = 0.00345824
Iteration 6762, loss = 0.00345761
Iteration 6763, loss = 0.00345699
Iteration 6764, loss = 0.00345646
Iteration 6765, loss = 0.00345583
Iteration 6766, loss = 0.00345520
Iteration 6767, loss = 0.00345459
Iteration 6768, loss = 0.00345412
Iteration 6769, loss = 0.00345363
Iteration 6770, loss = 0.00345270
Iteration 6771, loss = 0.00345181
Iteration 6772, loss = 0.00345131
Iteration 6773, loss = 0.00345055
Iteration 6774, loss = 0.00344993
Iteration 6775, loss = 0.00344914
Iteration 6776, loss = 0.00344841
Iteration 6777, loss = 0.00344779
Iteration 6778, loss = 0.00344717
Iteration 6779, loss = 0.00344673
Iteration 6780, loss = 0.00344612
Iteration 6781, loss = 0.00344526
Iteration 6782, loss = 0.00344454
Iteration 6783, loss = 0.00344392
Iteration 6784, loss = 0.00344327
Iteration 6785, loss = 0.00344270
Iteration 6786, loss = 0.00344222
Iteration 6787, loss = 0.00344152
Iteration 6788, loss = 0.00344093
Iteration 6789, loss = 0.00344035
Iteration 6790, loss = 0.00343952
Iteration 6791, loss = 0.00343892
Iteration 6792, loss = 0.00343823
Iteration 6793, loss = 0.00343759
Iteration 6794, loss = 0.00343685
Iteration 6795, loss = 0.00343624
Iteration 6796, loss = 0.00343569
Iteration 6797, loss = 0.00343513
Iteration 6798, loss = 0.00343472
Iteration 6799, loss = 0.00343397
Iteration 6800, loss = 0.00343329
Iteration 6801, loss = 0.00343267
Iteration 6802, loss = 0.00343214
Iteration 6803, loss = 0.00343150
Iteration 6804, loss = 0.00343099
Iteration 6805, loss = 0.00343070
Iteration 6806, loss = 0.00342995
Iteration 6807, loss = 0.00342922
Iteration 6808, loss = 0.00342913
Iteration 6809, loss = 0.00342811
Iteration 6810, loss = 0.00342718
Iteration 6811, loss = 0.00342663
Iteration 6812, loss = 0.00342582
Iteration 6813, loss = 0.00342517
Iteration 6814, loss = 0.00342454
Iteration 6815, loss = 0.00342397
Iteration 6816, loss = 0.00342371
Iteration 6817, loss = 0.00342280
Iteration 6818, loss = 0.00342210
Iteration 6819, loss = 0.00342119
Iteration 6820, loss = 0.00342082
Iteration 6821, loss = 0.00341994
Iteration 6822, loss = 0.00341928
Iteration 6823, loss = 0.00341858
Iteration 6824, loss = 0.00341785
Iteration 6825, loss = 0.00341719
Iteration 6826, loss = 0.00341651
Iteration 6827, loss = 0.00341592
Iteration 6828, loss = 0.00341515
Iteration 6829, loss = 0.00341464
Iteration 6830, loss = 0.00341326
Iteration 6831, loss = 0.00341283
Iteration 6832, loss = 0.00341166
Iteration 6833, loss = 0.00341078
Iteration 6834, loss = 0.00341029
Iteration 6835, loss = 0.00340915
Iteration 6836, loss = 0.00340839
Iteration 6837, loss = 0.00340769
Iteration 6838, loss = 0.00340724
Iteration 6839, loss = 0.00340627
Iteration 6840, loss = 0.00340556
Iteration 6841, loss = 0.00340507
Iteration 6842, loss = 0.00340445
Iteration 6843, loss = 0.00340371
Iteration 6844, loss = 0.00340305
Iteration 6845, loss = 0.00340254
Iteration 6846, loss = 0.00340191
Iteration 6847, loss = 0.00340125
Iteration 6848, loss = 0.00340058
Iteration 6849, loss = 0.00340023
Iteration 6850, loss = 0.00339959
Iteration 6851, loss = 0.00339900
Iteration 6852, loss = 0.00339849
Iteration 6853, loss = 0.00339783
Iteration 6854, loss = 0.00339792
Iteration 6855, loss = 0.00339679
Iteration 6856, loss = 0.00339619
Iteration 6857, loss = 0.00339547
Iteration 6858, loss = 0.00339494
Iteration 6859, loss = 0.00339414
Iteration 6860, loss = 0.00339341
Iteration 6861, loss = 0.00339250
Iteration 6862, loss = 0.00339209
Iteration 6863, loss = 0.00339125
Iteration 6864, loss = 0.00339044
Iteration 6865, loss = 0.00338985
Iteration 6866, loss = 0.00338924
Iteration 6867, loss = 0.00338859
Iteration 6868, loss = 0.00338799
Iteration 6869, loss = 0.00338727
Iteration 6870, loss = 0.00338675
Iteration 6871, loss = 0.00338617
Iteration 6872, loss = 0.00338559
Iteration 6873, loss = 0.00338478
Iteration 6874, loss = 0.00338412
Iteration 6875, loss = 0.00338347
Iteration 6876, loss = 0.00338287
Iteration 6877, loss = 0.00338233
Iteration 6878, loss = 0.00338182
Iteration 6879, loss = 0.00338128
Iteration 6880, loss = 0.00338077
Iteration 6881, loss = 0.00338033
Iteration 6882, loss = 0.00337971
Iteration 6883, loss = 0.00337918
Iteration 6884, loss = 0.00337854
Iteration 6885, loss = 0.00337814
Iteration 6886, loss = 0.00337756
Iteration 6887, loss = 0.00337715
Iteration 6888, loss = 0.00337661
Iteration 6889, loss = 0.00337621
Iteration 6890, loss = 0.00337595
Iteration 6891, loss = 0.00337514
Iteration 6892, loss = 0.00337458
Iteration 6893, loss = 0.00337388
Iteration 6894, loss = 0.00337331
Iteration 6895, loss = 0.00337233
Iteration 6896, loss = 0.00337182
Iteration 6897, loss = 0.00337117
Iteration 6898, loss = 0.00337044
Iteration 6899, loss = 0.00336901
Iteration 6900, loss = 0.00336770
Iteration 6901, loss = 0.00336668
Iteration 6902, loss = 0.00336657
Iteration 6903, loss = 0.00336574
Iteration 6904, loss = 0.00336490
Iteration 6905, loss = 0.00336409
Iteration 6906, loss = 0.00336315
Iteration 6907, loss = 0.00336256
Iteration 6908, loss = 0.00336191
Iteration 6909, loss = 0.00336127
Iteration 6910, loss = 0.00336076
Iteration 6911, loss = 0.00335995
Iteration 6912, loss = 0.00335909
Iteration 6913, loss = 0.00335839
Iteration 6914, loss = 0.00335758
Iteration 6915, loss = 0.00335706
Iteration 6916, loss = 0.00335632
Iteration 6917, loss = 0.00335570
Iteration 6918, loss = 0.00335510
Iteration 6919, loss = 0.00335471
Iteration 6920, loss = 0.00335401
Iteration 6921, loss = 0.00335340
Iteration 6922, loss = 0.00335282
Iteration 6923, loss = 0.00335220
Iteration 6924, loss = 0.00335172
Iteration 6925, loss = 0.00335101
Iteration 6926, loss = 0.00335044
Iteration 6927, loss = 0.00334988
Iteration 6928, loss = 0.00334995
Iteration 6929, loss = 0.00334884
Iteration 6930, loss = 0.00334824
Iteration 6931, loss = 0.00334767
Iteration 6932, loss = 0.00334698
Iteration 6933, loss = 0.00334633
Iteration 6934, loss = 0.00334570
Iteration 6935, loss = 0.00334501
Iteration 6936, loss = 0.00334453
Iteration 6937, loss = 0.00334394
Iteration 6938, loss = 0.00334311
Iteration 6939, loss = 0.00334256
Iteration 6940, loss = 0.00334191
Iteration 6941, loss = 0.00334134
Iteration 6942, loss = 0.00334078
Iteration 6943, loss = 0.00334027
Iteration 6944, loss = 0.00333993
Iteration 6945, loss = 0.00333909
Iteration 6946, loss = 0.00333880
Iteration 6947, loss = 0.00333795
Iteration 6948, loss = 0.00333710
Iteration 6949, loss = 0.00333632
Iteration 6950, loss = 0.00333556
Iteration 6951, loss = 0.00333494
Iteration 6952, loss = 0.00333442
Iteration 6953, loss = 0.00333378
Iteration 6954, loss = 0.00333311
Iteration 6955, loss = 0.00333257
Iteration 6956, loss = 0.00333187
Iteration 6957, loss = 0.00333124
Iteration 6958, loss = 0.00333076
Iteration 6959, loss = 0.00333016
Iteration 6960, loss = 0.00332937
Iteration 6961, loss = 0.00332859
Iteration 6962, loss = 0.00332788
Iteration 6963, loss = 0.00332713
Iteration 6964, loss = 0.00332658
Iteration 6965, loss = 0.00332603
Iteration 6966, loss = 0.00332526
Iteration 6967, loss = 0.00332467
Iteration 6968, loss = 0.00332405
Iteration 6969, loss = 0.00332353
Iteration 6970, loss = 0.00332305
Iteration 6971, loss = 0.00332254
Iteration 6972, loss = 0.00332202
Iteration 6973, loss = 0.00332154
Iteration 6974, loss = 0.00332108
Iteration 6975, loss = 0.00332081
Iteration 6976, loss = 0.00332002
Iteration 6977, loss = 0.00331931
Iteration 6978, loss = 0.00331854
Iteration 6979, loss = 0.00331771
Iteration 6980, loss = 0.00331735
Iteration 6981, loss = 0.00331644
Iteration 6982, loss = 0.00331546
Iteration 6983, loss = 0.00331465
Iteration 6984, loss = 0.00331419
Iteration 6985, loss = 0.00331336
Iteration 6986, loss = 0.00331256
Iteration 6987, loss = 0.00331208
Iteration 6988, loss = 0.00331106
Iteration 6989, loss = 0.00331034
Iteration 6990, loss = 0.00330983
Iteration 6991, loss = 0.00330906
Iteration 6992, loss = 0.00330838
Iteration 6993, loss = 0.00330771
Iteration 6994, loss = 0.00330728
Iteration 6995, loss = 0.00330654
Iteration 6996, loss = 0.00330598
Iteration 6997, loss = 0.00330528
Iteration 6998, loss = 0.00330459
Iteration 6999, loss = 0.00330416
Iteration 7000, loss = 0.00330332
Iteration 7001, loss = 0.00330272
Iteration 7002, loss = 0.00330205
Iteration 7003, loss = 0.00330171
Iteration 7004, loss = 0.00330115
Iteration 7005, loss = 0.00330076
Iteration 7006, loss = 0.00329975
Iteration 7007, loss = 0.00329915
Iteration 7008, loss = 0.00329840
Iteration 7009, loss = 0.00329793
Iteration 7010, loss = 0.00329722
Iteration 7011, loss = 0.00329656
Iteration 7012, loss = 0.00329597
Iteration 7013, loss = 0.00329535
Iteration 7014, loss = 0.00329468
Iteration 7015, loss = 0.00329405
Iteration 7016, loss = 0.00329360
Iteration 7017, loss = 0.00329303
Iteration 7018, loss = 0.00329241
Iteration 7019, loss = 0.00329195
Iteration 7020, loss = 0.00329121
Iteration 7021, loss = 0.00329063
Iteration 7022, loss = 0.00329004
Iteration 7023, loss = 0.00328950
Iteration 7024, loss = 0.00328902
Iteration 7025, loss = 0.00328833
Iteration 7026, loss = 0.00328777
Iteration 7027, loss = 0.00328715
Iteration 7028, loss = 0.00328683
Iteration 7029, loss = 0.00328612
Iteration 7030, loss = 0.00328558
Iteration 7031, loss = 0.00328446
Iteration 7032, loss = 0.00328396
Iteration 7033, loss = 0.00328350
Iteration 7034, loss = 0.00328261
Iteration 7035, loss = 0.00328196
Iteration 7036, loss = 0.00328139
Iteration 7037, loss = 0.00328076
Iteration 7038, loss = 0.00328025
Iteration 7039, loss = 0.00327967
Iteration 7040, loss = 0.00327902
Iteration 7041, loss = 0.00327828
Iteration 7042, loss = 0.00327784
Iteration 7043, loss = 0.00327721
Iteration 7044, loss = 0.00327661
Iteration 7045, loss = 0.00327594
Iteration 7046, loss = 0.00327535
Iteration 7047, loss = 0.00327485
Iteration 7048, loss = 0.00327425
Iteration 7049, loss = 0.00327426
Iteration 7050, loss = 0.00327318
Iteration 7051, loss = 0.00327269
Iteration 7052, loss = 0.00327163
Iteration 7053, loss = 0.00327093
Iteration 7054, loss = 0.00327029
Iteration 7055, loss = 0.00326996
Iteration 7056, loss = 0.00326893
Iteration 7057, loss = 0.00326812
Iteration 7058, loss = 0.00326783
Iteration 7059, loss = 0.00326680
Iteration 7060, loss = 0.00326605
Iteration 7061, loss = 0.00326571
Iteration 7062, loss = 0.00326500
Iteration 7063, loss = 0.00326419
Iteration 7064, loss = 0.00326334
Iteration 7065, loss = 0.00326254
Iteration 7066, loss = 0.00326204
Iteration 7067, loss = 0.00326156
Iteration 7068, loss = 0.00326078
Iteration 7069, loss = 0.00326015
Iteration 7070, loss = 0.00325945
Iteration 7071, loss = 0.00325874
Iteration 7072, loss = 0.00325828
Iteration 7073, loss = 0.00325765
Iteration 7074, loss = 0.00325687
Iteration 7075, loss = 0.00325613
Iteration 7076, loss = 0.00325572
Iteration 7077, loss = 0.00325504
Iteration 7078, loss = 0.00325439
Iteration 7079, loss = 0.00325376
Iteration 7080, loss = 0.00325311
Iteration 7081, loss = 0.00325246
Iteration 7082, loss = 0.00325178
Iteration 7083, loss = 0.00325123
Iteration 7084, loss = 0.00325080
Iteration 7085, loss = 0.00325032
Iteration 7086, loss = 0.00324924
Iteration 7087, loss = 0.00324863
Iteration 7088, loss = 0.00324782
Iteration 7089, loss = 0.00324702
Iteration 7090, loss = 0.00324680
Iteration 7091, loss = 0.00324599
Iteration 7092, loss = 0.00324562
Iteration 7093, loss = 0.00324464
Iteration 7094, loss = 0.00324389
Iteration 7095, loss = 0.00324322
Iteration 7096, loss = 0.00324259
Iteration 7097, loss = 0.00324183
Iteration 7098, loss = 0.00324164
Iteration 7099, loss = 0.00324085
Iteration 7100, loss = 0.00324009
Iteration 7101, loss = 0.00323960
Iteration 7102, loss = 0.00323885
Iteration 7103, loss = 0.00323818
Iteration 7104, loss = 0.00323779
Iteration 7105, loss = 0.00323738
Iteration 7106, loss = 0.00323663
Iteration 7107, loss = 0.00323617
Iteration 7108, loss = 0.00323541
Iteration 7109, loss = 0.00323501
Iteration 7110, loss = 0.00323431
Iteration 7111, loss = 0.00323377
Iteration 7112, loss = 0.00323306
Iteration 7113, loss = 0.00323249
Iteration 7114, loss = 0.00323180
Iteration 7115, loss = 0.00323109
Iteration 7116, loss = 0.00323084
Iteration 7117, loss = 0.00322989
Iteration 7118, loss = 0.00322971
Iteration 7119, loss = 0.00322894
Iteration 7120, loss = 0.00322794
Iteration 7121, loss = 0.00322736
Iteration 7122, loss = 0.00322663
Iteration 7123, loss = 0.00322603
Iteration 7124, loss = 0.00322565
Iteration 7125, loss = 0.00322470
Iteration 7126, loss = 0.00322408
Iteration 7127, loss = 0.00322350
Iteration 7128, loss = 0.00322270
Iteration 7129, loss = 0.00322202
Iteration 7130, loss = 0.00322137
Iteration 7131, loss = 0.00322078
Iteration 7132, loss = 0.00322020
Iteration 7133, loss = 0.00321959
Iteration 7134, loss = 0.00321903
Iteration 7135, loss = 0.00321838
Iteration 7136, loss = 0.00321787
Iteration 7137, loss = 0.00321703
Iteration 7138, loss = 0.00321649
Iteration 7139, loss = 0.00321573
Iteration 7140, loss = 0.00321512
Iteration 7141, loss = 0.00321503
Iteration 7142, loss = 0.00321396
Iteration 7143, loss = 0.00321333
Iteration 7144, loss = 0.00321273
Iteration 7145, loss = 0.00321218
Iteration 7146, loss = 0.00321127
Iteration 7147, loss = 0.00321072
Iteration 7148, loss = 0.00321020
Iteration 7149, loss = 0.00320960
Iteration 7150, loss = 0.00320901
Iteration 7151, loss = 0.00320860
Iteration 7152, loss = 0.00320807
Iteration 7153, loss = 0.00320755
Iteration 7154, loss = 0.00320682
Iteration 7155, loss = 0.00320628
Iteration 7156, loss = 0.00320557
Iteration 7157, loss = 0.00320534
Iteration 7158, loss = 0.00320449
Iteration 7159, loss = 0.00320392
Iteration 7160, loss = 0.00320352
Iteration 7161, loss = 0.00320264
Iteration 7162, loss = 0.00320199
Iteration 7163, loss = 0.00320152
Iteration 7164, loss = 0.00320073
Iteration 7165, loss = 0.00320004
Iteration 7166, loss = 0.00319934
Iteration 7167, loss = 0.00319906
Iteration 7168, loss = 0.00319828
Iteration 7169, loss = 0.00319749
Iteration 7170, loss = 0.00319693
Iteration 7171, loss = 0.00319621
Iteration 7172, loss = 0.00319579
Iteration 7173, loss = 0.00319498
Iteration 7174, loss = 0.00319445
Iteration 7175, loss = 0.00319380
Iteration 7176, loss = 0.00319323
Iteration 7177, loss = 0.00319274
Iteration 7178, loss = 0.00319209
Iteration 7179, loss = 0.00319147
Iteration 7180, loss = 0.00319078
Iteration 7181, loss = 0.00319020
Iteration 7182, loss = 0.00318956
Iteration 7183, loss = 0.00318904
Iteration 7184, loss = 0.00318837
Iteration 7185, loss = 0.00318795
Iteration 7186, loss = 0.00318728
Iteration 7187, loss = 0.00318662
Iteration 7188, loss = 0.00318607
Iteration 7189, loss = 0.00318540
Iteration 7190, loss = 0.00318477
Iteration 7191, loss = 0.00318417
Iteration 7192, loss = 0.00318360
Iteration 7193, loss = 0.00318302
Iteration 7194, loss = 0.00318246
Iteration 7195, loss = 0.00318206
Iteration 7196, loss = 0.00318177
Iteration 7197, loss = 0.00318072
Iteration 7198, loss = 0.00318042
Iteration 7199, loss = 0.00317958
Iteration 7200, loss = 0.00317894
Iteration 7201, loss = 0.00317830
Iteration 7202, loss = 0.00317804
Iteration 7203, loss = 0.00317699
Iteration 7204, loss = 0.00317636
Iteration 7205, loss = 0.00317579
Iteration 7206, loss = 0.00317514
Iteration 7207, loss = 0.00317438
Iteration 7208, loss = 0.00317415
Iteration 7209, loss = 0.00317353
Iteration 7210, loss = 0.00317283
Iteration 7211, loss = 0.00317213
Iteration 7212, loss = 0.00317148
Iteration 7213, loss = 0.00317094
Iteration 7214, loss = 0.00317032
Iteration 7215, loss = 0.00316965
Iteration 7216, loss = 0.00316913
Iteration 7217, loss = 0.00316837
Iteration 7218, loss = 0.00316769
Iteration 7219, loss = 0.00316712
Iteration 7220, loss = 0.00316651
Iteration 7221, loss = 0.00316595
Iteration 7222, loss = 0.00316542
Iteration 7223, loss = 0.00316495
Iteration 7224, loss = 0.00316434
Iteration 7225, loss = 0.00316372
Iteration 7226, loss = 0.00316318
Iteration 7227, loss = 0.00316247
Iteration 7228, loss = 0.00316200
Iteration 7229, loss = 0.00316142
Iteration 7230, loss = 0.00316101
Iteration 7231, loss = 0.00316027
Iteration 7232, loss = 0.00315977
Iteration 7233, loss = 0.00315913
Iteration 7234, loss = 0.00315836
Iteration 7235, loss = 0.00315774
Iteration 7236, loss = 0.00315709
Iteration 7237, loss = 0.00315653
Iteration 7238, loss = 0.00315600
Iteration 7239, loss = 0.00315536
Iteration 7240, loss = 0.00315487
Iteration 7241, loss = 0.00315423
Iteration 7242, loss = 0.00315369
Iteration 7243, loss = 0.00315310
Iteration 7244, loss = 0.00315258
Iteration 7245, loss = 0.00315209
Iteration 7246, loss = 0.00315151
Iteration 7247, loss = 0.00315111
Iteration 7248, loss = 0.00315043
Iteration 7249, loss = 0.00314996
Iteration 7250, loss = 0.00314954
Iteration 7251, loss = 0.00314889
Iteration 7252, loss = 0.00314837
Iteration 7253, loss = 0.00314785
Iteration 7254, loss = 0.00314787
Iteration 7255, loss = 0.00314660
Iteration 7256, loss = 0.00314597
Iteration 7257, loss = 0.00314575
Iteration 7258, loss = 0.00314520
Iteration 7259, loss = 0.00314438
Iteration 7260, loss = 0.00314387
Iteration 7261, loss = 0.00314325
Iteration 7262, loss = 0.00314276
Iteration 7263, loss = 0.00314199
Iteration 7264, loss = 0.00314143
Iteration 7265, loss = 0.00314081
Iteration 7266, loss = 0.00314035
Iteration 7267, loss = 0.00313971
Iteration 7268, loss = 0.00313914
Iteration 7269, loss = 0.00313854
Iteration 7270, loss = 0.00313796
Iteration 7271, loss = 0.00313738
Iteration 7272, loss = 0.00313694
Iteration 7273, loss = 0.00313651
Iteration 7274, loss = 0.00313590
Iteration 7275, loss = 0.00313525
Iteration 7276, loss = 0.00313477
Iteration 7277, loss = 0.00313428
Iteration 7278, loss = 0.00313382
Iteration 7279, loss = 0.00313338
Iteration 7280, loss = 0.00313239
Iteration 7281, loss = 0.00313211
Iteration 7282, loss = 0.00313115
Iteration 7283, loss = 0.00313095
Iteration 7284, loss = 0.00313004
Iteration 7285, loss = 0.00312920
Iteration 7286, loss = 0.00312857
Iteration 7287, loss = 0.00312767
Iteration 7288, loss = 0.00312677
Iteration 7289, loss = 0.00312675
Iteration 7290, loss = 0.00312688
Iteration 7291, loss = 0.00312596
Iteration 7292, loss = 0.00312596
Iteration 7293, loss = 0.00312491
Iteration 7294, loss = 0.00312430
Iteration 7295, loss = 0.00312387
Iteration 7296, loss = 0.00312321
Iteration 7297, loss = 0.00312315
Iteration 7298, loss = 0.00312222
Iteration 7299, loss = 0.00312168
Iteration 7300, loss = 0.00312103
Iteration 7301, loss = 0.00312072
Iteration 7302, loss = 0.00312005
Iteration 7303, loss = 0.00311962
Iteration 7304, loss = 0.00311915
Iteration 7305, loss = 0.00311832
Iteration 7306, loss = 0.00311765
Iteration 7307, loss = 0.00311700
Iteration 7308, loss = 0.00311629
Iteration 7309, loss = 0.00311612
Iteration 7310, loss = 0.00311510
Iteration 7311, loss = 0.00311473
Iteration 7312, loss = 0.00311397
Iteration 7313, loss = 0.00311334
Iteration 7314, loss = 0.00311288
Iteration 7315, loss = 0.00311226
Iteration 7316, loss = 0.00311158
Iteration 7317, loss = 0.00311119
Iteration 7318, loss = 0.00311046
Iteration 7319, loss = 0.00310983
Iteration 7320, loss = 0.00310939
Iteration 7321, loss = 0.00310869
Iteration 7322, loss = 0.00310857
Iteration 7323, loss = 0.00310768
Iteration 7324, loss = 0.00310713
Iteration 7325, loss = 0.00310667
Iteration 7326, loss = 0.00310649
Iteration 7327, loss = 0.00310569
Iteration 7328, loss = 0.00310486
Iteration 7329, loss = 0.00310467
Iteration 7330, loss = 0.00310354
Iteration 7331, loss = 0.00310318
Iteration 7332, loss = 0.00310247
Iteration 7333, loss = 0.00310240
Iteration 7334, loss = 0.00310144
Iteration 7335, loss = 0.00310078
Iteration 7336, loss = 0.00310037
Iteration 7337, loss = 0.00309956
Iteration 7338, loss = 0.00309893
Iteration 7339, loss = 0.00309849
Iteration 7340, loss = 0.00309816
Iteration 7341, loss = 0.00309731
Iteration 7342, loss = 0.00309668
Iteration 7343, loss = 0.00309612
Iteration 7344, loss = 0.00309601
Iteration 7345, loss = 0.00309537
Iteration 7346, loss = 0.00309459
Iteration 7347, loss = 0.00309406
Iteration 7348, loss = 0.00309353
Iteration 7349, loss = 0.00309298
Iteration 7350, loss = 0.00309255
Iteration 7351, loss = 0.00309187
Iteration 7352, loss = 0.00309142
Iteration 7353, loss = 0.00309073
Iteration 7354, loss = 0.00309015
Iteration 7355, loss = 0.00308948
Iteration 7356, loss = 0.00308907
Iteration 7357, loss = 0.00308836
Iteration 7358, loss = 0.00308779
Iteration 7359, loss = 0.00308714
Iteration 7360, loss = 0.00308658
Iteration 7361, loss = 0.00308600
Iteration 7362, loss = 0.00308534
Iteration 7363, loss = 0.00308481
Iteration 7364, loss = 0.00308405
Iteration 7365, loss = 0.00308383
Iteration 7366, loss = 0.00308294
Iteration 7367, loss = 0.00308232
Iteration 7368, loss = 0.00308179
Iteration 7369, loss = 0.00308119
Iteration 7370, loss = 0.00308081
Iteration 7371, loss = 0.00308013
Iteration 7372, loss = 0.00307962
Iteration 7373, loss = 0.00307904
Iteration 7374, loss = 0.00307849
Iteration 7375, loss = 0.00307806
Iteration 7376, loss = 0.00307737
Iteration 7377, loss = 0.00307684
Iteration 7378, loss = 0.00307633
Iteration 7379, loss = 0.00307565
Iteration 7380, loss = 0.00307509
Iteration 7381, loss = 0.00307443
Iteration 7382, loss = 0.00307400
Iteration 7383, loss = 0.00307328
Iteration 7384, loss = 0.00307282
Iteration 7385, loss = 0.00307220
Iteration 7386, loss = 0.00307167
Iteration 7387, loss = 0.00307107
Iteration 7388, loss = 0.00307050
Iteration 7389, loss = 0.00307005
Iteration 7390, loss = 0.00306935
Iteration 7391, loss = 0.00306876
Iteration 7392, loss = 0.00306825
Iteration 7393, loss = 0.00306753
Iteration 7394, loss = 0.00306724
Iteration 7395, loss = 0.00306637
Iteration 7396, loss = 0.00306581
Iteration 7397, loss = 0.00306526
Iteration 7398, loss = 0.00306455
Iteration 7399, loss = 0.00306398
Iteration 7400, loss = 0.00306348
Iteration 7401, loss = 0.00306294
Iteration 7402, loss = 0.00306248
Iteration 7403, loss = 0.00306180
Iteration 7404, loss = 0.00306118
Iteration 7405, loss = 0.00306058
Iteration 7406, loss = 0.00305989
Iteration 7407, loss = 0.00305976
Iteration 7408, loss = 0.00305876
Iteration 7409, loss = 0.00305815
Iteration 7410, loss = 0.00305752
Iteration 7411, loss = 0.00305730
Iteration 7412, loss = 0.00305642
Iteration 7413, loss = 0.00305586
Iteration 7414, loss = 0.00305550
Iteration 7415, loss = 0.00305468
Iteration 7416, loss = 0.00305413
Iteration 7417, loss = 0.00305347
Iteration 7418, loss = 0.00305295
Iteration 7419, loss = 0.00305217
Iteration 7420, loss = 0.00305150
Iteration 7421, loss = 0.00305105
Iteration 7422, loss = 0.00305054
Iteration 7423, loss = 0.00304976
Iteration 7424, loss = 0.00304928
Iteration 7425, loss = 0.00304869
Iteration 7426, loss = 0.00304816
Iteration 7427, loss = 0.00304756
Iteration 7428, loss = 0.00304704
Iteration 7429, loss = 0.00304656
Iteration 7430, loss = 0.00304605
Iteration 7431, loss = 0.00304539
Iteration 7432, loss = 0.00304481
Iteration 7433, loss = 0.00304453
Iteration 7434, loss = 0.00304388
Iteration 7435, loss = 0.00304358
Iteration 7436, loss = 0.00304304
Iteration 7437, loss = 0.00304254
Iteration 7438, loss = 0.00304197
Iteration 7439, loss = 0.00304175
Iteration 7440, loss = 0.00304121
Iteration 7441, loss = 0.00304050
Iteration 7442, loss = 0.00304002
Iteration 7443, loss = 0.00303943
Iteration 7444, loss = 0.00303894
Iteration 7445, loss = 0.00303828
Iteration 7446, loss = 0.00303754
Iteration 7447, loss = 0.00303696
Iteration 7448, loss = 0.00303656
Iteration 7449, loss = 0.00303586
Iteration 7450, loss = 0.00303539
Iteration 7451, loss = 0.00303489
Iteration 7452, loss = 0.00303448
Iteration 7453, loss = 0.00303387
Iteration 7454, loss = 0.00303336
Iteration 7455, loss = 0.00303332
Iteration 7456, loss = 0.00303239
Iteration 7457, loss = 0.00303200
Iteration 7458, loss = 0.00303131
Iteration 7459, loss = 0.00303069
Iteration 7460, loss = 0.00303017
Iteration 7461, loss = 0.00303025
Iteration 7462, loss = 0.00302922
Iteration 7463, loss = 0.00302880
Iteration 7464, loss = 0.00302810
Iteration 7465, loss = 0.00302763
Iteration 7466, loss = 0.00302690
Iteration 7467, loss = 0.00302645
Iteration 7468, loss = 0.00302591
Iteration 7469, loss = 0.00302558
Iteration 7470, loss = 0.00302485
Iteration 7471, loss = 0.00302429
Iteration 7472, loss = 0.00302377
Iteration 7473, loss = 0.00302333
Iteration 7474, loss = 0.00302269
Iteration 7475, loss = 0.00302226
Iteration 7476, loss = 0.00302164
Iteration 7477, loss = 0.00302123
Iteration 7478, loss = 0.00302065
Iteration 7479, loss = 0.00302017
Iteration 7480, loss = 0.00301953
Iteration 7481, loss = 0.00301891
Iteration 7482, loss = 0.00301837
Iteration 7483, loss = 0.00301782
Iteration 7484, loss = 0.00301715
Iteration 7485, loss = 0.00301660
Iteration 7486, loss = 0.00301602
Iteration 7487, loss = 0.00301519
Iteration 7488, loss = 0.00301473
Iteration 7489, loss = 0.00301397
Iteration 7490, loss = 0.00301346
Iteration 7491, loss = 0.00301291
Iteration 7492, loss = 0.00301242
Iteration 7493, loss = 0.00301177
Iteration 7494, loss = 0.00301124
Iteration 7495, loss = 0.00301075
Iteration 7496, loss = 0.00301024
Iteration 7497, loss = 0.00300974
Iteration 7498, loss = 0.00300969
Iteration 7499, loss = 0.00300872
Iteration 7500, loss = 0.00300829
Iteration 7501, loss = 0.00300784
Iteration 7502, loss = 0.00300739
Iteration 7503, loss = 0.00300689
Iteration 7504, loss = 0.00300627
Iteration 7505, loss = 0.00300583
Iteration 7506, loss = 0.00300523
Iteration 7507, loss = 0.00300461
Iteration 7508, loss = 0.00300403
Iteration 7509, loss = 0.00300365
Iteration 7510, loss = 0.00300316
Iteration 7511, loss = 0.00300246
Iteration 7512, loss = 0.00300180
Iteration 7513, loss = 0.00300126
Iteration 7514, loss = 0.00300074
Iteration 7515, loss = 0.00300037
Iteration 7516, loss = 0.00299972
Iteration 7517, loss = 0.00299922
Iteration 7518, loss = 0.00299869
Iteration 7519, loss = 0.00299806
Iteration 7520, loss = 0.00299753
Iteration 7521, loss = 0.00299706
Iteration 7522, loss = 0.00299665
Iteration 7523, loss = 0.00299601
Iteration 7524, loss = 0.00299545
Iteration 7525, loss = 0.00299488
Iteration 7526, loss = 0.00299446
Iteration 7527, loss = 0.00299383
Iteration 7528, loss = 0.00299327
Iteration 7529, loss = 0.00299281
Iteration 7530, loss = 0.00299231
Iteration 7531, loss = 0.00299192
Iteration 7532, loss = 0.00299131
Iteration 7533, loss = 0.00299082
Iteration 7534, loss = 0.00299030
Iteration 7535, loss = 0.00298990
Iteration 7536, loss = 0.00298944
Iteration 7537, loss = 0.00298867
Iteration 7538, loss = 0.00298818
Iteration 7539, loss = 0.00298769
Iteration 7540, loss = 0.00298710
Iteration 7541, loss = 0.00298635
Iteration 7542, loss = 0.00298591
Iteration 7543, loss = 0.00298532
Iteration 7544, loss = 0.00298479
Iteration 7545, loss = 0.00298419
Iteration 7546, loss = 0.00298391
Iteration 7547, loss = 0.00298344
Iteration 7548, loss = 0.00298276
Iteration 7549, loss = 0.00298227
Iteration 7550, loss = 0.00298164
Iteration 7551, loss = 0.00298105
Iteration 7552, loss = 0.00298056
Iteration 7553, loss = 0.00298001
Iteration 7554, loss = 0.00297939
Iteration 7555, loss = 0.00297880
Iteration 7556, loss = 0.00297833
Iteration 7557, loss = 0.00297787
Iteration 7558, loss = 0.00297715
Iteration 7559, loss = 0.00297650
Iteration 7560, loss = 0.00297611
Iteration 7561, loss = 0.00297545
Iteration 7562, loss = 0.00297520
Iteration 7563, loss = 0.00297437
Iteration 7564, loss = 0.00297389
Iteration 7565, loss = 0.00297349
Iteration 7566, loss = 0.00297290
Iteration 7567, loss = 0.00297257
Iteration 7568, loss = 0.00297214
Iteration 7569, loss = 0.00297146
Iteration 7570, loss = 0.00297093
Iteration 7571, loss = 0.00297042
Iteration 7572, loss = 0.00296998
Iteration 7573, loss = 0.00296948
Iteration 7574, loss = 0.00296899
Iteration 7575, loss = 0.00296849
Iteration 7576, loss = 0.00296781
Iteration 7577, loss = 0.00296722
Iteration 7578, loss = 0.00296664
Iteration 7579, loss = 0.00296609
Iteration 7580, loss = 0.00296566
Iteration 7581, loss = 0.00296500
Iteration 7582, loss = 0.00296452
Iteration 7583, loss = 0.00296392
Iteration 7584, loss = 0.00296346
Iteration 7585, loss = 0.00296281
Iteration 7586, loss = 0.00296250
Iteration 7587, loss = 0.00296176
Iteration 7588, loss = 0.00296163
Iteration 7589, loss = 0.00296072
Iteration 7590, loss = 0.00296042
Iteration 7591, loss = 0.00295994
Iteration 7592, loss = 0.00295918
Iteration 7593, loss = 0.00295866
Iteration 7594, loss = 0.00295810
Iteration 7595, loss = 0.00295768
Iteration 7596, loss = 0.00295710
Iteration 7597, loss = 0.00295659
Iteration 7598, loss = 0.00295594
Iteration 7599, loss = 0.00295552
Iteration 7600, loss = 0.00295483
Iteration 7601, loss = 0.00295440
Iteration 7602, loss = 0.00295389
Iteration 7603, loss = 0.00295352
Iteration 7604, loss = 0.00295287
Iteration 7605, loss = 0.00295245
Iteration 7606, loss = 0.00295186
Iteration 7607, loss = 0.00295138
Iteration 7608, loss = 0.00295088
Iteration 7609, loss = 0.00295038
Iteration 7610, loss = 0.00295000
Iteration 7611, loss = 0.00294939
Iteration 7612, loss = 0.00294874
Iteration 7613, loss = 0.00294850
Iteration 7614, loss = 0.00294778
Iteration 7615, loss = 0.00294732
Iteration 7616, loss = 0.00294663
Iteration 7617, loss = 0.00294596
Iteration 7618, loss = 0.00294581
Iteration 7619, loss = 0.00294507
Iteration 7620, loss = 0.00294447
Iteration 7621, loss = 0.00294445
Iteration 7622, loss = 0.00294354
Iteration 7623, loss = 0.00294298
Iteration 7624, loss = 0.00294245
Iteration 7625, loss = 0.00294212
Iteration 7626, loss = 0.00294141
Iteration 7627, loss = 0.00294089
Iteration 7628, loss = 0.00294034
Iteration 7629, loss = 0.00293984
Iteration 7630, loss = 0.00293941
Iteration 7631, loss = 0.00293921
Iteration 7632, loss = 0.00293813
Iteration 7633, loss = 0.00293750
Iteration 7634, loss = 0.00293710
Iteration 7635, loss = 0.00293648
Iteration 7636, loss = 0.00293593
Iteration 7637, loss = 0.00293534
Iteration 7638, loss = 0.00293481
Iteration 7639, loss = 0.00293447
Iteration 7640, loss = 0.00293384
Iteration 7641, loss = 0.00293347
Iteration 7642, loss = 0.00293289
Iteration 7643, loss = 0.00293231
Iteration 7644, loss = 0.00293205
Iteration 7645, loss = 0.00293132
Iteration 7646, loss = 0.00293087
Iteration 7647, loss = 0.00293027
Iteration 7648, loss = 0.00292980
Iteration 7649, loss = 0.00292932
Iteration 7650, loss = 0.00292871
Iteration 7651, loss = 0.00292832
Iteration 7652, loss = 0.00292774
Iteration 7653, loss = 0.00292716
Iteration 7654, loss = 0.00292658
Iteration 7655, loss = 0.00292605
Iteration 7656, loss = 0.00292583
Iteration 7657, loss = 0.00292504
Iteration 7658, loss = 0.00292442
Iteration 7659, loss = 0.00292387
Iteration 7660, loss = 0.00292332
Iteration 7661, loss = 0.00292301
Iteration 7662, loss = 0.00292232
Iteration 7663, loss = 0.00292175
Iteration 7664, loss = 0.00292137
Iteration 7665, loss = 0.00292119
Iteration 7666, loss = 0.00292032
Iteration 7667, loss = 0.00291974
Iteration 7668, loss = 0.00291904
Iteration 7669, loss = 0.00291869
Iteration 7670, loss = 0.00291799
Iteration 7671, loss = 0.00291758
Iteration 7672, loss = 0.00291719
Iteration 7673, loss = 0.00291639
Iteration 7674, loss = 0.00291600
Iteration 7675, loss = 0.00291542
Iteration 7676, loss = 0.00291489
Iteration 7677, loss = 0.00291447
Iteration 7678, loss = 0.00291377
Iteration 7679, loss = 0.00291334
Iteration 7680, loss = 0.00291272
Iteration 7681, loss = 0.00291220
Iteration 7682, loss = 0.00291176
Iteration 7683, loss = 0.00291116
Iteration 7684, loss = 0.00291072
Iteration 7685, loss = 0.00291020
Iteration 7686, loss = 0.00290966
Iteration 7687, loss = 0.00290937
Iteration 7688, loss = 0.00290879
Iteration 7689, loss = 0.00290822
Iteration 7690, loss = 0.00290777
Iteration 7691, loss = 0.00290726
Iteration 7692, loss = 0.00290680
Iteration 7693, loss = 0.00290626
Iteration 7694, loss = 0.00290587
Iteration 7695, loss = 0.00290542
Iteration 7696, loss = 0.00290495
Iteration 7697, loss = 0.00290446
Iteration 7698, loss = 0.00290401
Iteration 7699, loss = 0.00290375
Iteration 7700, loss = 0.00290318
Iteration 7701, loss = 0.00290268
Iteration 7702, loss = 0.00290214
Iteration 7703, loss = 0.00290165
Iteration 7704, loss = 0.00290113
Iteration 7705, loss = 0.00290063
Iteration 7706, loss = 0.00290012
Iteration 7707, loss = 0.00289967
Iteration 7708, loss = 0.00289983
Iteration 7709, loss = 0.00289865
Iteration 7710, loss = 0.00289839
Iteration 7711, loss = 0.00289769
Iteration 7712, loss = 0.00289716
Iteration 7713, loss = 0.00289660
Iteration 7714, loss = 0.00289602
Iteration 7715, loss = 0.00289548
Iteration 7716, loss = 0.00289503
Iteration 7717, loss = 0.00289450
Iteration 7718, loss = 0.00289402
Iteration 7719, loss = 0.00289350
Iteration 7720, loss = 0.00289310
Iteration 7721, loss = 0.00289291
Iteration 7722, loss = 0.00289216
Iteration 7723, loss = 0.00289167
Iteration 7724, loss = 0.00289116
Iteration 7725, loss = 0.00289065
Iteration 7726, loss = 0.00289007
Iteration 7727, loss = 0.00288958
Iteration 7728, loss = 0.00288916
Iteration 7729, loss = 0.00288870
Iteration 7730, loss = 0.00288799
Iteration 7731, loss = 0.00288745
Iteration 7732, loss = 0.00288695
Iteration 7733, loss = 0.00288650
Iteration 7734, loss = 0.00288597
Iteration 7735, loss = 0.00288556
Iteration 7736, loss = 0.00288505
Iteration 7737, loss = 0.00288468
Iteration 7738, loss = 0.00288424
Iteration 7739, loss = 0.00288375
Iteration 7740, loss = 0.00288331
Iteration 7741, loss = 0.00288282
Iteration 7742, loss = 0.00288320
Iteration 7743, loss = 0.00288202
Iteration 7744, loss = 0.00288150
Iteration 7745, loss = 0.00288095
Iteration 7746, loss = 0.00288061
Iteration 7747, loss = 0.00288001
Iteration 7748, loss = 0.00287955
Iteration 7749, loss = 0.00287893
Iteration 7750, loss = 0.00287838
Iteration 7751, loss = 0.00287783
Iteration 7752, loss = 0.00287745
Iteration 7753, loss = 0.00287681
Iteration 7754, loss = 0.00287634
Iteration 7755, loss = 0.00287594
Iteration 7756, loss = 0.00287557
Iteration 7757, loss = 0.00287487
Iteration 7758, loss = 0.00287433
Iteration 7759, loss = 0.00287398
Iteration 7760, loss = 0.00287336
Iteration 7761, loss = 0.00287287
Iteration 7762, loss = 0.00287221
Iteration 7763, loss = 0.00287156
Iteration 7764, loss = 0.00287127
Iteration 7765, loss = 0.00287050
Iteration 7766, loss = 0.00286987
Iteration 7767, loss = 0.00286958
Iteration 7768, loss = 0.00286907
Iteration 7769, loss = 0.00286854
Iteration 7770, loss = 0.00286788
Iteration 7771, loss = 0.00286727
Iteration 7772, loss = 0.00286690
Iteration 7773, loss = 0.00286620
Iteration 7774, loss = 0.00286561
Iteration 7775, loss = 0.00286513
Iteration 7776, loss = 0.00286458
Iteration 7777, loss = 0.00286437
Iteration 7778, loss = 0.00286371
Iteration 7779, loss = 0.00286314
Iteration 7780, loss = 0.00286272
Iteration 7781, loss = 0.00286232
Iteration 7782, loss = 0.00286178
Iteration 7783, loss = 0.00286120
Iteration 7784, loss = 0.00286086
Iteration 7785, loss = 0.00286034
Iteration 7786, loss = 0.00285974
Iteration 7787, loss = 0.00285918
Iteration 7788, loss = 0.00285870
Iteration 7789, loss = 0.00285833
Iteration 7790, loss = 0.00285754
Iteration 7791, loss = 0.00285686
Iteration 7792, loss = 0.00285667
Iteration 7793, loss = 0.00285588
Iteration 7794, loss = 0.00285552
Iteration 7795, loss = 0.00285494
Iteration 7796, loss = 0.00285482
Iteration 7797, loss = 0.00285405
Iteration 7798, loss = 0.00285352
Iteration 7799, loss = 0.00285310
Iteration 7800, loss = 0.00285261
Iteration 7801, loss = 0.00285211
Iteration 7802, loss = 0.00285162
Iteration 7803, loss = 0.00285119
Iteration 7804, loss = 0.00285080
Iteration 7805, loss = 0.00285018
Iteration 7806, loss = 0.00284960
Iteration 7807, loss = 0.00284928
Iteration 7808, loss = 0.00284866
Iteration 7809, loss = 0.00284822
Iteration 7810, loss = 0.00284771
Iteration 7811, loss = 0.00284719
Iteration 7812, loss = 0.00284667
Iteration 7813, loss = 0.00284658
Iteration 7814, loss = 0.00284597
Iteration 7815, loss = 0.00284538
Iteration 7816, loss = 0.00284486
Iteration 7817, loss = 0.00284450
Iteration 7818, loss = 0.00284397
Iteration 7819, loss = 0.00284330
Iteration 7820, loss = 0.00284280
Iteration 7821, loss = 0.00284223
Iteration 7822, loss = 0.00284192
Iteration 7823, loss = 0.00284119
Iteration 7824, loss = 0.00284062
Iteration 7825, loss = 0.00284018
Iteration 7826, loss = 0.00283981
Iteration 7827, loss = 0.00283911
Iteration 7828, loss = 0.00283856
Iteration 7829, loss = 0.00283811
Iteration 7830, loss = 0.00283760
Iteration 7831, loss = 0.00283715
Iteration 7832, loss = 0.00283665
Iteration 7833, loss = 0.00283640
Iteration 7834, loss = 0.00283572
Iteration 7835, loss = 0.00283542
Iteration 7836, loss = 0.00283478
Iteration 7837, loss = 0.00283425
Iteration 7838, loss = 0.00283382
Iteration 7839, loss = 0.00283406
Iteration 7840, loss = 0.00283281
Iteration 7841, loss = 0.00283244
Iteration 7842, loss = 0.00283175
Iteration 7843, loss = 0.00283127
Iteration 7844, loss = 0.00283091
Iteration 7845, loss = 0.00283025
Iteration 7846, loss = 0.00282972
Iteration 7847, loss = 0.00282935
Iteration 7848, loss = 0.00282897
Iteration 7849, loss = 0.00282860
Iteration 7850, loss = 0.00282789
Iteration 7851, loss = 0.00282746
Iteration 7852, loss = 0.00282668
Iteration 7853, loss = 0.00282609
Iteration 7854, loss = 0.00282572
Iteration 7855, loss = 0.00282525
Iteration 7856, loss = 0.00282468
Iteration 7857, loss = 0.00282438
Iteration 7858, loss = 0.00282381
Iteration 7859, loss = 0.00282346
Iteration 7860, loss = 0.00282288
Iteration 7861, loss = 0.00282237
Iteration 7862, loss = 0.00282192
Iteration 7863, loss = 0.00282144
Iteration 7864, loss = 0.00282101
Iteration 7865, loss = 0.00282062
Iteration 7866, loss = 0.00282007
Iteration 7867, loss = 0.00281961
Iteration 7868, loss = 0.00281934
Iteration 7869, loss = 0.00281858
Iteration 7870, loss = 0.00281815
Iteration 7871, loss = 0.00281769
Iteration 7872, loss = 0.00281743
Iteration 7873, loss = 0.00281678
Iteration 7874, loss = 0.00281635
Iteration 7875, loss = 0.00281590
Iteration 7876, loss = 0.00281541
Iteration 7877, loss = 0.00281510
Iteration 7878, loss = 0.00281449
Iteration 7879, loss = 0.00281408
Iteration 7880, loss = 0.00281352
Iteration 7881, loss = 0.00281305
Iteration 7882, loss = 0.00281283
Iteration 7883, loss = 0.00281206
Iteration 7884, loss = 0.00281155
Iteration 7885, loss = 0.00281101
Iteration 7886, loss = 0.00281050
Iteration 7887, loss = 0.00281029
Iteration 7888, loss = 0.00280983
Iteration 7889, loss = 0.00280928
Iteration 7890, loss = 0.00280883
Iteration 7891, loss = 0.00280814
Iteration 7892, loss = 0.00280791
Iteration 7893, loss = 0.00280716
Iteration 7894, loss = 0.00280657
Iteration 7895, loss = 0.00280606
Iteration 7896, loss = 0.00280549
Iteration 7897, loss = 0.00280494
Iteration 7898, loss = 0.00280447
Iteration 7899, loss = 0.00280392
Iteration 7900, loss = 0.00280333
Iteration 7901, loss = 0.00280276
Iteration 7902, loss = 0.00280241
Iteration 7903, loss = 0.00280224
Iteration 7904, loss = 0.00280159
Iteration 7905, loss = 0.00280101
Iteration 7906, loss = 0.00280053
Iteration 7907, loss = 0.00280029
Iteration 7908, loss = 0.00279965
Iteration 7909, loss = 0.00279922
Iteration 7910, loss = 0.00279907
Iteration 7911, loss = 0.00279838
Iteration 7912, loss = 0.00279797
Iteration 7913, loss = 0.00279747
Iteration 7914, loss = 0.00279748
Iteration 7915, loss = 0.00279675
Iteration 7916, loss = 0.00279610
Iteration 7917, loss = 0.00279570
Iteration 7918, loss = 0.00279516
Iteration 7919, loss = 0.00279464
Iteration 7920, loss = 0.00279419
Iteration 7921, loss = 0.00279374
Iteration 7922, loss = 0.00279316
Iteration 7923, loss = 0.00279289
Iteration 7924, loss = 0.00279224
Iteration 7925, loss = 0.00279182
Iteration 7926, loss = 0.00279150
Iteration 7927, loss = 0.00279092
Iteration 7928, loss = 0.00279090
Iteration 7929, loss = 0.00278982
Iteration 7930, loss = 0.00278928
Iteration 7931, loss = 0.00278883
Iteration 7932, loss = 0.00278859
Iteration 7933, loss = 0.00278778
Iteration 7934, loss = 0.00278729
Iteration 7935, loss = 0.00278685
Iteration 7936, loss = 0.00278654
Iteration 7937, loss = 0.00278597
Iteration 7938, loss = 0.00278567
Iteration 7939, loss = 0.00278511
Iteration 7940, loss = 0.00278470
Iteration 7941, loss = 0.00278420
Iteration 7942, loss = 0.00278374
Iteration 7943, loss = 0.00278323
Iteration 7944, loss = 0.00278290
Iteration 7945, loss = 0.00278237
Iteration 7946, loss = 0.00278179
Iteration 7947, loss = 0.00278167
Iteration 7948, loss = 0.00278100
Iteration 7949, loss = 0.00278055
Iteration 7950, loss = 0.00278011
Iteration 7951, loss = 0.00277972
Iteration 7952, loss = 0.00277945
Iteration 7953, loss = 0.00277873
Iteration 7954, loss = 0.00277842
Iteration 7955, loss = 0.00277781
Iteration 7956, loss = 0.00277733
Iteration 7957, loss = 0.00277693
Iteration 7958, loss = 0.00277655
Iteration 7959, loss = 0.00277584
Iteration 7960, loss = 0.00277536
Iteration 7961, loss = 0.00277499
Iteration 7962, loss = 0.00277451
Iteration 7963, loss = 0.00277434
Iteration 7964, loss = 0.00277364
Iteration 7965, loss = 0.00277324
Iteration 7966, loss = 0.00277277
Iteration 7967, loss = 0.00277228
Iteration 7968, loss = 0.00277203
Iteration 7969, loss = 0.00277144
Iteration 7970, loss = 0.00277098
Iteration 7971, loss = 0.00277054
Iteration 7972, loss = 0.00277003
Iteration 7973, loss = 0.00276981
Iteration 7974, loss = 0.00276911
Iteration 7975, loss = 0.00276875
Iteration 7976, loss = 0.00276826
Iteration 7977, loss = 0.00276778
Iteration 7978, loss = 0.00276757
Iteration 7979, loss = 0.00276692
Iteration 7980, loss = 0.00276628
Iteration 7981, loss = 0.00276565
Iteration 7982, loss = 0.00276502
Iteration 7983, loss = 0.00276452
Iteration 7984, loss = 0.00276447
Iteration 7985, loss = 0.00276412
Iteration 7986, loss = 0.00276337
Iteration 7987, loss = 0.00276305
Iteration 7988, loss = 0.00276256
Iteration 7989, loss = 0.00276217
Iteration 7990, loss = 0.00276163
Iteration 7991, loss = 0.00276122
Iteration 7992, loss = 0.00276074
Iteration 7993, loss = 0.00276029
Iteration 7994, loss = 0.00275980
Iteration 7995, loss = 0.00275937
Iteration 7996, loss = 0.00275880
Iteration 7997, loss = 0.00275830
Iteration 7998, loss = 0.00275782
Iteration 7999, loss = 0.00275735
Iteration 8000, loss = 0.00275696
Iteration 1, loss = 1.04047078
Iteration 2, loss = 1.03728679
Iteration 3, loss = 1.03232620
Iteration 4, loss = 1.02600245
Iteration 5, loss = 1.01852447
Iteration 6, loss = 1.01055779
Iteration 7, loss = 1.00180529
Iteration 8, loss = 0.99283551
Iteration 9, loss = 0.98354265
Iteration 10, loss = 0.97395813
Iteration 11, loss = 0.96441745
Iteration 12, loss = 0.95476744
Iteration 13, loss = 0.94523850
Iteration 14, loss = 0.93563654
Iteration 15, loss = 0.92629477
Iteration 16, loss = 0.91708907
Iteration 17, loss = 0.90807142
Iteration 18, loss = 0.89938067
Iteration 19, loss = 0.89071319
Iteration 20, loss = 0.88247554
Iteration 21, loss = 0.87432911
Iteration 22, loss = 0.86669951
Iteration 23, loss = 0.85903522
Iteration 24, loss = 0.85142297
Iteration 25, loss = 0.84429749
Iteration 26, loss = 0.83702206
Iteration 27, loss = 0.83023044
Iteration 28, loss = 0.82325169
Iteration 29, loss = 0.81691741
Iteration 30, loss = 0.81053906
Iteration 31, loss = 0.80420770
Iteration 32, loss = 0.79839282
Iteration 33, loss = 0.79269307
Iteration 34, loss = 0.78684468
Iteration 35, loss = 0.78136108
Iteration 36, loss = 0.77621296
Iteration 37, loss = 0.77099333
Iteration 38, loss = 0.76614871
Iteration 39, loss = 0.76120391
Iteration 40, loss = 0.75662803
Iteration 41, loss = 0.75199027
Iteration 42, loss = 0.74771561
Iteration 43, loss = 0.74327914
Iteration 44, loss = 0.73901285
Iteration 45, loss = 0.73499651
Iteration 46, loss = 0.73079863
Iteration 47, loss = 0.72692105
Iteration 48, loss = 0.72307757
Iteration 49, loss = 0.71931259
Iteration 50, loss = 0.71563567
Iteration 51, loss = 0.71209157
Iteration 52, loss = 0.70858732
Iteration 53, loss = 0.70521430
Iteration 54, loss = 0.70191045
Iteration 55, loss = 0.69848397
Iteration 56, loss = 0.69522855
Iteration 57, loss = 0.69213439
Iteration 58, loss = 0.68878665
Iteration 59, loss = 0.68586031
Iteration 60, loss = 0.68277973
Iteration 61, loss = 0.67978986
Iteration 62, loss = 0.67697395
Iteration 63, loss = 0.67407915
Iteration 64, loss = 0.67124574
Iteration 65, loss = 0.66851478
Iteration 66, loss = 0.66571767
Iteration 67, loss = 0.66297573
Iteration 68, loss = 0.66025816
Iteration 69, loss = 0.65749350
Iteration 70, loss = 0.65486893
Iteration 71, loss = 0.65213716
Iteration 72, loss = 0.64949697
Iteration 73, loss = 0.64684973
Iteration 74, loss = 0.64421298
Iteration 75, loss = 0.64156328
Iteration 76, loss = 0.63891467
Iteration 77, loss = 0.63633225
Iteration 78, loss = 0.63366020
Iteration 79, loss = 0.63107581
Iteration 80, loss = 0.62853235
Iteration 81, loss = 0.62596497
Iteration 82, loss = 0.62346354
Iteration 83, loss = 0.62098278
Iteration 84, loss = 0.61849254
Iteration 85, loss = 0.61599476
Iteration 86, loss = 0.61363970
Iteration 87, loss = 0.61112196
Iteration 88, loss = 0.60872845
Iteration 89, loss = 0.60629416
Iteration 90, loss = 0.60383212
Iteration 91, loss = 0.60144344
Iteration 92, loss = 0.59899017
Iteration 93, loss = 0.59655208
Iteration 94, loss = 0.59413258
Iteration 95, loss = 0.59171696
Iteration 96, loss = 0.58931448
Iteration 97, loss = 0.58689823
Iteration 98, loss = 0.58448296
Iteration 99, loss = 0.58210344
Iteration 100, loss = 0.57974260
Iteration 101, loss = 0.57730699
Iteration 102, loss = 0.57489534
Iteration 103, loss = 0.57250855
Iteration 104, loss = 0.57015141
Iteration 105, loss = 0.56776630
Iteration 106, loss = 0.56547566
Iteration 107, loss = 0.56308866
Iteration 108, loss = 0.56085612
Iteration 109, loss = 0.55851534
Iteration 110, loss = 0.55623138
Iteration 111, loss = 0.55396119
Iteration 112, loss = 0.55168108
Iteration 113, loss = 0.54946329
Iteration 114, loss = 0.54718359
Iteration 115, loss = 0.54496325
Iteration 116, loss = 0.54274821
Iteration 117, loss = 0.54048916
Iteration 118, loss = 0.53826792
Iteration 119, loss = 0.53600840
Iteration 120, loss = 0.53375838
Iteration 121, loss = 0.53151527
Iteration 122, loss = 0.52932004
Iteration 123, loss = 0.52704579
Iteration 124, loss = 0.52484474
Iteration 125, loss = 0.52267358
Iteration 126, loss = 0.52045959
Iteration 127, loss = 0.51827652
Iteration 128, loss = 0.51611510
Iteration 129, loss = 0.51395300
Iteration 130, loss = 0.51179785
Iteration 131, loss = 0.50965132
Iteration 132, loss = 0.50750956
Iteration 133, loss = 0.50535463
Iteration 134, loss = 0.50324379
Iteration 135, loss = 0.50113486
Iteration 136, loss = 0.49903122
Iteration 137, loss = 0.49695368
Iteration 138, loss = 0.49486252
Iteration 139, loss = 0.49277835
Iteration 140, loss = 0.49068983
Iteration 141, loss = 0.48860566
Iteration 142, loss = 0.48651100
Iteration 143, loss = 0.48441876
Iteration 144, loss = 0.48235289
Iteration 145, loss = 0.48021539
Iteration 146, loss = 0.47817860
Iteration 147, loss = 0.47605488
Iteration 148, loss = 0.47402321
Iteration 149, loss = 0.47189941
Iteration 150, loss = 0.46983344
Iteration 151, loss = 0.46778601
Iteration 152, loss = 0.46568009
Iteration 153, loss = 0.46361674
Iteration 154, loss = 0.46153431
Iteration 155, loss = 0.45945926
Iteration 156, loss = 0.45743207
Iteration 157, loss = 0.45532515
Iteration 158, loss = 0.45329985
Iteration 159, loss = 0.45124096
Iteration 160, loss = 0.44918448
Iteration 161, loss = 0.44713918
Iteration 162, loss = 0.44507175
Iteration 163, loss = 0.44298979
Iteration 164, loss = 0.44092001
Iteration 165, loss = 0.43880839
Iteration 166, loss = 0.43671538
Iteration 167, loss = 0.43460778
Iteration 168, loss = 0.43249250
Iteration 169, loss = 0.43035851
Iteration 170, loss = 0.42825063
Iteration 171, loss = 0.42614216
Iteration 172, loss = 0.42402058
Iteration 173, loss = 0.42189786
Iteration 174, loss = 0.41982690
Iteration 175, loss = 0.41771754
Iteration 176, loss = 0.41561446
Iteration 177, loss = 0.41354226
Iteration 178, loss = 0.41143982
Iteration 179, loss = 0.40936271
Iteration 180, loss = 0.40729456
Iteration 181, loss = 0.40522817
Iteration 182, loss = 0.40315051
Iteration 183, loss = 0.40109434
Iteration 184, loss = 0.39901023
Iteration 185, loss = 0.39697874
Iteration 186, loss = 0.39491095
Iteration 187, loss = 0.39283506
Iteration 188, loss = 0.39079829
Iteration 189, loss = 0.38877131
Iteration 190, loss = 0.38671759
Iteration 191, loss = 0.38469055
Iteration 192, loss = 0.38267855
Iteration 193, loss = 0.38065367
Iteration 194, loss = 0.37861333
Iteration 195, loss = 0.37659299
Iteration 196, loss = 0.37456959
Iteration 197, loss = 0.37255045
Iteration 198, loss = 0.37052610
Iteration 199, loss = 0.36850250
Iteration 200, loss = 0.36647680
Iteration 201, loss = 0.36446842
Iteration 202, loss = 0.36244191
Iteration 203, loss = 0.36043072
Iteration 204, loss = 0.35840751
Iteration 205, loss = 0.35638140
Iteration 206, loss = 0.35439315
Iteration 207, loss = 0.35238034
Iteration 208, loss = 0.35037678
Iteration 209, loss = 0.34838758
Iteration 210, loss = 0.34640822
Iteration 211, loss = 0.34439811
Iteration 212, loss = 0.34243211
Iteration 213, loss = 0.34048581
Iteration 214, loss = 0.33850290
Iteration 215, loss = 0.33656277
Iteration 216, loss = 0.33461165
Iteration 217, loss = 0.33267792
Iteration 218, loss = 0.33075185
Iteration 219, loss = 0.32883780
Iteration 220, loss = 0.32692374
Iteration 221, loss = 0.32502615
Iteration 222, loss = 0.32314090
Iteration 223, loss = 0.32125812
Iteration 224, loss = 0.31937931
Iteration 225, loss = 0.31751600
Iteration 226, loss = 0.31567733
Iteration 227, loss = 0.31380043
Iteration 228, loss = 0.31195669
Iteration 229, loss = 0.31010245
Iteration 230, loss = 0.30826069
Iteration 231, loss = 0.30640053
Iteration 232, loss = 0.30456679
Iteration 233, loss = 0.30272001
Iteration 234, loss = 0.30092032
Iteration 235, loss = 0.29908987
Iteration 236, loss = 0.29729893
Iteration 237, loss = 0.29550734
Iteration 238, loss = 0.29373140
Iteration 239, loss = 0.29196239
Iteration 240, loss = 0.29019730
Iteration 241, loss = 0.28845264
Iteration 242, loss = 0.28671942
Iteration 243, loss = 0.28499888
Iteration 244, loss = 0.28328015
Iteration 245, loss = 0.28159623
Iteration 246, loss = 0.27989048
Iteration 247, loss = 0.27820027
Iteration 248, loss = 0.27652149
Iteration 249, loss = 0.27482980
Iteration 250, loss = 0.27317487
Iteration 251, loss = 0.27149154
Iteration 252, loss = 0.26984836
Iteration 253, loss = 0.26820613
Iteration 254, loss = 0.26656939
Iteration 255, loss = 0.26494947
Iteration 256, loss = 0.26332809
Iteration 257, loss = 0.26175267
Iteration 258, loss = 0.26013678
Iteration 259, loss = 0.25853765
Iteration 260, loss = 0.25694233
Iteration 261, loss = 0.25536951
Iteration 262, loss = 0.25379966
Iteration 263, loss = 0.25222916
Iteration 264, loss = 0.25068750
Iteration 265, loss = 0.24915793
Iteration 266, loss = 0.24763531
Iteration 267, loss = 0.24613576
Iteration 268, loss = 0.24463044
Iteration 269, loss = 0.24315279
Iteration 270, loss = 0.24166057
Iteration 271, loss = 0.24021789
Iteration 272, loss = 0.23876936
Iteration 273, loss = 0.23732145
Iteration 274, loss = 0.23591290
Iteration 275, loss = 0.23448690
Iteration 276, loss = 0.23309077
Iteration 277, loss = 0.23170056
Iteration 278, loss = 0.23035326
Iteration 279, loss = 0.22896564
Iteration 280, loss = 0.22762484
Iteration 281, loss = 0.22629283
Iteration 282, loss = 0.22497046
Iteration 283, loss = 0.22365468
Iteration 284, loss = 0.22234104
Iteration 285, loss = 0.22103414
Iteration 286, loss = 0.21974504
Iteration 287, loss = 0.21845091
Iteration 288, loss = 0.21716536
Iteration 289, loss = 0.21589799
Iteration 290, loss = 0.21463560
Iteration 291, loss = 0.21337998
Iteration 292, loss = 0.21214724
Iteration 293, loss = 0.21090330
Iteration 294, loss = 0.20967270
Iteration 295, loss = 0.20845711
Iteration 296, loss = 0.20724438
Iteration 297, loss = 0.20603996
Iteration 298, loss = 0.20484006
Iteration 299, loss = 0.20367093
Iteration 300, loss = 0.20251097
Iteration 301, loss = 0.20134877
Iteration 302, loss = 0.20020769
Iteration 303, loss = 0.19908116
Iteration 304, loss = 0.19796229
Iteration 305, loss = 0.19684966
Iteration 306, loss = 0.19573728
Iteration 307, loss = 0.19463835
Iteration 308, loss = 0.19353817
Iteration 309, loss = 0.19244521
Iteration 310, loss = 0.19137525
Iteration 311, loss = 0.19030371
Iteration 312, loss = 0.18923271
Iteration 313, loss = 0.18818257
Iteration 314, loss = 0.18713884
Iteration 315, loss = 0.18609631
Iteration 316, loss = 0.18506709
Iteration 317, loss = 0.18403826
Iteration 318, loss = 0.18302144
Iteration 319, loss = 0.18201249
Iteration 320, loss = 0.18100338
Iteration 321, loss = 0.18000407
Iteration 322, loss = 0.17901295
Iteration 323, loss = 0.17803174
Iteration 324, loss = 0.17705985
Iteration 325, loss = 0.17608755
Iteration 326, loss = 0.17513747
Iteration 327, loss = 0.17419102
Iteration 328, loss = 0.17324546
Iteration 329, loss = 0.17231854
Iteration 330, loss = 0.17140080
Iteration 331, loss = 0.17047156
Iteration 332, loss = 0.16957249
Iteration 333, loss = 0.16867498
Iteration 334, loss = 0.16778750
Iteration 335, loss = 0.16689990
Iteration 336, loss = 0.16602551
Iteration 337, loss = 0.16516911
Iteration 338, loss = 0.16430775
Iteration 339, loss = 0.16346830
Iteration 340, loss = 0.16262156
Iteration 341, loss = 0.16178981
Iteration 342, loss = 0.16095609
Iteration 343, loss = 0.16014105
Iteration 344, loss = 0.15931715
Iteration 345, loss = 0.15850309
Iteration 346, loss = 0.15769867
Iteration 347, loss = 0.15690908
Iteration 348, loss = 0.15611471
Iteration 349, loss = 0.15533161
Iteration 350, loss = 0.15455900
Iteration 351, loss = 0.15378497
Iteration 352, loss = 0.15301098
Iteration 353, loss = 0.15224702
Iteration 354, loss = 0.15148529
Iteration 355, loss = 0.15072640
Iteration 356, loss = 0.14997647
Iteration 357, loss = 0.14922817
Iteration 358, loss = 0.14848769
Iteration 359, loss = 0.14776109
Iteration 360, loss = 0.14703953
Iteration 361, loss = 0.14632733
Iteration 362, loss = 0.14562194
Iteration 363, loss = 0.14491888
Iteration 364, loss = 0.14423177
Iteration 365, loss = 0.14355117
Iteration 366, loss = 0.14285441
Iteration 367, loss = 0.14218231
Iteration 368, loss = 0.14150872
Iteration 369, loss = 0.14084231
Iteration 370, loss = 0.14018309
Iteration 371, loss = 0.13953165
Iteration 372, loss = 0.13888779
Iteration 373, loss = 0.13825186
Iteration 374, loss = 0.13761752
Iteration 375, loss = 0.13698617
Iteration 376, loss = 0.13636375
Iteration 377, loss = 0.13574579
Iteration 378, loss = 0.13513033
Iteration 379, loss = 0.13451292
Iteration 380, loss = 0.13390581
Iteration 381, loss = 0.13329299
Iteration 382, loss = 0.13268266
Iteration 383, loss = 0.13208550
Iteration 384, loss = 0.13149393
Iteration 385, loss = 0.13091662
Iteration 386, loss = 0.13033601
Iteration 387, loss = 0.12977040
Iteration 388, loss = 0.12919444
Iteration 389, loss = 0.12863764
Iteration 390, loss = 0.12808420
Iteration 391, loss = 0.12753660
Iteration 392, loss = 0.12700370
Iteration 393, loss = 0.12646918
Iteration 394, loss = 0.12594144
Iteration 395, loss = 0.12542178
Iteration 396, loss = 0.12490238
Iteration 397, loss = 0.12438556
Iteration 398, loss = 0.12386957
Iteration 399, loss = 0.12335622
Iteration 400, loss = 0.12284898
Iteration 401, loss = 0.12235337
Iteration 402, loss = 0.12184255
Iteration 403, loss = 0.12135631
Iteration 404, loss = 0.12086307
Iteration 405, loss = 0.12037231
Iteration 406, loss = 0.11988661
Iteration 407, loss = 0.11941035
Iteration 408, loss = 0.11893587
Iteration 409, loss = 0.11846535
Iteration 410, loss = 0.11799875
Iteration 411, loss = 0.11754067
Iteration 412, loss = 0.11707962
Iteration 413, loss = 0.11662573
Iteration 414, loss = 0.11616897
Iteration 415, loss = 0.11571935
Iteration 416, loss = 0.11527275
Iteration 417, loss = 0.11483238
Iteration 418, loss = 0.11439229
Iteration 419, loss = 0.11395630
Iteration 420, loss = 0.11352346
Iteration 421, loss = 0.11309197
Iteration 422, loss = 0.11266594
Iteration 423, loss = 0.11223117
Iteration 424, loss = 0.11180995
Iteration 425, loss = 0.11138616
Iteration 426, loss = 0.11096969
Iteration 427, loss = 0.11055313
Iteration 428, loss = 0.11013529
Iteration 429, loss = 0.10972713
Iteration 430, loss = 0.10931216
Iteration 431, loss = 0.10890752
Iteration 432, loss = 0.10850264
Iteration 433, loss = 0.10810473
Iteration 434, loss = 0.10770620
Iteration 435, loss = 0.10731223
Iteration 436, loss = 0.10692591
Iteration 437, loss = 0.10654625
Iteration 438, loss = 0.10615835
Iteration 439, loss = 0.10578255
Iteration 440, loss = 0.10540831
Iteration 441, loss = 0.10503759
Iteration 442, loss = 0.10467266
Iteration 443, loss = 0.10430991
Iteration 444, loss = 0.10393916
Iteration 445, loss = 0.10358116
Iteration 446, loss = 0.10321759
Iteration 447, loss = 0.10286191
Iteration 448, loss = 0.10250694
Iteration 449, loss = 0.10215659
Iteration 450, loss = 0.10180872
Iteration 451, loss = 0.10146209
Iteration 452, loss = 0.10111584
Iteration 453, loss = 0.10077502
Iteration 454, loss = 0.10043185
Iteration 455, loss = 0.10009765
Iteration 456, loss = 0.09975808
Iteration 457, loss = 0.09942137
Iteration 458, loss = 0.09908950
Iteration 459, loss = 0.09875924
Iteration 460, loss = 0.09842725
Iteration 461, loss = 0.09810395
Iteration 462, loss = 0.09777910
Iteration 463, loss = 0.09745118
Iteration 464, loss = 0.09711959
Iteration 465, loss = 0.09679769
Iteration 466, loss = 0.09648415
Iteration 467, loss = 0.09616104
Iteration 468, loss = 0.09584531
Iteration 469, loss = 0.09553469
Iteration 470, loss = 0.09522311
Iteration 471, loss = 0.09492336
Iteration 472, loss = 0.09462148
Iteration 473, loss = 0.09432520
Iteration 474, loss = 0.09402968
Iteration 475, loss = 0.09373980
Iteration 476, loss = 0.09344701
Iteration 477, loss = 0.09315684
Iteration 478, loss = 0.09287961
Iteration 479, loss = 0.09260432
Iteration 480, loss = 0.09232081
Iteration 481, loss = 0.09203037
Iteration 482, loss = 0.09174810
Iteration 483, loss = 0.09146164
Iteration 484, loss = 0.09117675
Iteration 485, loss = 0.09089443
Iteration 486, loss = 0.09061669
Iteration 487, loss = 0.09034252
Iteration 488, loss = 0.09007102
Iteration 489, loss = 0.08979852
Iteration 490, loss = 0.08952706
Iteration 491, loss = 0.08925091
Iteration 492, loss = 0.08898623
Iteration 493, loss = 0.08871727
Iteration 494, loss = 0.08844864
Iteration 495, loss = 0.08818963
Iteration 496, loss = 0.08792860
Iteration 497, loss = 0.08767616
Iteration 498, loss = 0.08742022
Iteration 499, loss = 0.08717098
Iteration 500, loss = 0.08692124
Iteration 501, loss = 0.08667582
Iteration 502, loss = 0.08642444
Iteration 503, loss = 0.08619000
Iteration 504, loss = 0.08594463
Iteration 505, loss = 0.08570814
Iteration 506, loss = 0.08547175
Iteration 507, loss = 0.08523636
Iteration 508, loss = 0.08500361
Iteration 509, loss = 0.08477222
Iteration 510, loss = 0.08454210
Iteration 511, loss = 0.08431323
Iteration 512, loss = 0.08408920
Iteration 513, loss = 0.08386192
Iteration 514, loss = 0.08363495
Iteration 515, loss = 0.08340527
Iteration 516, loss = 0.08318077
Iteration 517, loss = 0.08294973
Iteration 518, loss = 0.08273039
Iteration 519, loss = 0.08249777
Iteration 520, loss = 0.08227531
Iteration 521, loss = 0.08206091
Iteration 522, loss = 0.08183642
Iteration 523, loss = 0.08161954
Iteration 524, loss = 0.08140209
Iteration 525, loss = 0.08119694
Iteration 526, loss = 0.08097604
Iteration 527, loss = 0.08076667
Iteration 528, loss = 0.08056154
Iteration 529, loss = 0.08034386
Iteration 530, loss = 0.08014194
Iteration 531, loss = 0.07993298
Iteration 532, loss = 0.07972684
Iteration 533, loss = 0.07952639
Iteration 534, loss = 0.07932567
Iteration 535, loss = 0.07912283
Iteration 536, loss = 0.07892202
Iteration 537, loss = 0.07872008
Iteration 538, loss = 0.07852462
Iteration 539, loss = 0.07831826
Iteration 540, loss = 0.07811803
Iteration 541, loss = 0.07791968
Iteration 542, loss = 0.07772688
Iteration 543, loss = 0.07752878
Iteration 544, loss = 0.07733300
Iteration 545, loss = 0.07714929
Iteration 546, loss = 0.07695321
Iteration 547, loss = 0.07676809
Iteration 548, loss = 0.07657722
Iteration 549, loss = 0.07639439
Iteration 550, loss = 0.07621043
Iteration 551, loss = 0.07602705
Iteration 552, loss = 0.07584498
Iteration 553, loss = 0.07566058
Iteration 554, loss = 0.07548710
Iteration 555, loss = 0.07530485
Iteration 556, loss = 0.07512435
Iteration 557, loss = 0.07494174
Iteration 558, loss = 0.07476870
Iteration 559, loss = 0.07459379
Iteration 560, loss = 0.07441850
Iteration 561, loss = 0.07424550
Iteration 562, loss = 0.07407053
Iteration 563, loss = 0.07390726
Iteration 564, loss = 0.07373051
Iteration 565, loss = 0.07356397
Iteration 566, loss = 0.07339662
Iteration 567, loss = 0.07323136
Iteration 568, loss = 0.07306921
Iteration 569, loss = 0.07290609
Iteration 570, loss = 0.07274624
Iteration 571, loss = 0.07259040
Iteration 572, loss = 0.07242301
Iteration 573, loss = 0.07226928
Iteration 574, loss = 0.07210197
Iteration 575, loss = 0.07193173
Iteration 576, loss = 0.07177451
Iteration 577, loss = 0.07161285
Iteration 578, loss = 0.07145244
Iteration 579, loss = 0.07129105
Iteration 580, loss = 0.07113299
Iteration 581, loss = 0.07097505
Iteration 582, loss = 0.07081402
Iteration 583, loss = 0.07065547
Iteration 584, loss = 0.07049955
Iteration 585, loss = 0.07034196
Iteration 586, loss = 0.07019135
Iteration 587, loss = 0.07003937
Iteration 588, loss = 0.06987947
Iteration 589, loss = 0.06972423
Iteration 590, loss = 0.06957172
Iteration 591, loss = 0.06941555
Iteration 592, loss = 0.06925884
Iteration 593, loss = 0.06910409
Iteration 594, loss = 0.06895979
Iteration 595, loss = 0.06880352
Iteration 596, loss = 0.06865050
Iteration 597, loss = 0.06850327
Iteration 598, loss = 0.06835579
Iteration 599, loss = 0.06821479
Iteration 600, loss = 0.06806616
Iteration 601, loss = 0.06792055
Iteration 602, loss = 0.06778269
Iteration 603, loss = 0.06763795
Iteration 604, loss = 0.06749705
Iteration 605, loss = 0.06735806
Iteration 606, loss = 0.06722393
Iteration 607, loss = 0.06708978
Iteration 608, loss = 0.06695387
Iteration 609, loss = 0.06682015
Iteration 610, loss = 0.06668601
Iteration 611, loss = 0.06655570
Iteration 612, loss = 0.06642118
Iteration 613, loss = 0.06628992
Iteration 614, loss = 0.06615833
Iteration 615, loss = 0.06602236
Iteration 616, loss = 0.06589394
Iteration 617, loss = 0.06576243
Iteration 618, loss = 0.06563890
Iteration 619, loss = 0.06550823
Iteration 620, loss = 0.06538122
Iteration 621, loss = 0.06525175
Iteration 622, loss = 0.06512646
Iteration 623, loss = 0.06500130
Iteration 624, loss = 0.06487458
Iteration 625, loss = 0.06474835
Iteration 626, loss = 0.06462567
Iteration 627, loss = 0.06449952
Iteration 628, loss = 0.06437302
Iteration 629, loss = 0.06424973
Iteration 630, loss = 0.06412145
Iteration 631, loss = 0.06399593
Iteration 632, loss = 0.06388030
Iteration 633, loss = 0.06374917
Iteration 634, loss = 0.06363118
Iteration 635, loss = 0.06351822
Iteration 636, loss = 0.06339658
Iteration 637, loss = 0.06327800
Iteration 638, loss = 0.06316553
Iteration 639, loss = 0.06304142
Iteration 640, loss = 0.06292220
Iteration 641, loss = 0.06280202
Iteration 642, loss = 0.06268611
Iteration 643, loss = 0.06257263
Iteration 644, loss = 0.06245595
Iteration 645, loss = 0.06234017
Iteration 646, loss = 0.06222545
Iteration 647, loss = 0.06210922
Iteration 648, loss = 0.06199379
Iteration 649, loss = 0.06188321
Iteration 650, loss = 0.06176834
Iteration 651, loss = 0.06165824
Iteration 652, loss = 0.06154978
Iteration 653, loss = 0.06143518
Iteration 654, loss = 0.06132448
Iteration 655, loss = 0.06121626
Iteration 656, loss = 0.06110147
Iteration 657, loss = 0.06099317
Iteration 658, loss = 0.06088135
Iteration 659, loss = 0.06077321
Iteration 660, loss = 0.06066502
Iteration 661, loss = 0.06056286
Iteration 662, loss = 0.06044903
Iteration 663, loss = 0.06034094
Iteration 664, loss = 0.06023193
Iteration 665, loss = 0.06012331
Iteration 666, loss = 0.06001618
Iteration 667, loss = 0.05990648
Iteration 668, loss = 0.05980059
Iteration 669, loss = 0.05969685
Iteration 670, loss = 0.05958911
Iteration 671, loss = 0.05948952
Iteration 672, loss = 0.05938110
Iteration 673, loss = 0.05927653
Iteration 674, loss = 0.05917364
Iteration 675, loss = 0.05906852
Iteration 676, loss = 0.05896767
Iteration 677, loss = 0.05886654
Iteration 678, loss = 0.05876329
Iteration 679, loss = 0.05866260
Iteration 680, loss = 0.05856347
Iteration 681, loss = 0.05846073
Iteration 682, loss = 0.05836131
Iteration 683, loss = 0.05825956
Iteration 684, loss = 0.05815949
Iteration 685, loss = 0.05805988
Iteration 686, loss = 0.05797013
Iteration 687, loss = 0.05786794
Iteration 688, loss = 0.05777403
Iteration 689, loss = 0.05767612
Iteration 690, loss = 0.05757365
Iteration 691, loss = 0.05747643
Iteration 692, loss = 0.05737799
Iteration 693, loss = 0.05728250
Iteration 694, loss = 0.05719295
Iteration 695, loss = 0.05709207
Iteration 696, loss = 0.05699649
Iteration 697, loss = 0.05690517
Iteration 698, loss = 0.05680563
Iteration 699, loss = 0.05670912
Iteration 700, loss = 0.05660855
Iteration 701, loss = 0.05651916
Iteration 702, loss = 0.05641624
Iteration 703, loss = 0.05631677
Iteration 704, loss = 0.05621764
Iteration 705, loss = 0.05612607
Iteration 706, loss = 0.05602286
Iteration 707, loss = 0.05592983
Iteration 708, loss = 0.05583013
Iteration 709, loss = 0.05574009
Iteration 710, loss = 0.05564733
Iteration 711, loss = 0.05554916
Iteration 712, loss = 0.05545607
Iteration 713, loss = 0.05536266
Iteration 714, loss = 0.05527121
Iteration 715, loss = 0.05517961
Iteration 716, loss = 0.05509171
Iteration 717, loss = 0.05499614
Iteration 718, loss = 0.05490912
Iteration 719, loss = 0.05481961
Iteration 720, loss = 0.05473296
Iteration 721, loss = 0.05464482
Iteration 722, loss = 0.05456173
Iteration 723, loss = 0.05447218
Iteration 724, loss = 0.05438368
Iteration 725, loss = 0.05429993
Iteration 726, loss = 0.05421111
Iteration 727, loss = 0.05412683
Iteration 728, loss = 0.05404192
Iteration 729, loss = 0.05395757
Iteration 730, loss = 0.05387610
Iteration 731, loss = 0.05379081
Iteration 732, loss = 0.05370715
Iteration 733, loss = 0.05362314
Iteration 734, loss = 0.05353890
Iteration 735, loss = 0.05345505
Iteration 736, loss = 0.05337354
Iteration 737, loss = 0.05328874
Iteration 738, loss = 0.05320853
Iteration 739, loss = 0.05312302
Iteration 740, loss = 0.05304237
Iteration 741, loss = 0.05295937
Iteration 742, loss = 0.05287937
Iteration 743, loss = 0.05279628
Iteration 744, loss = 0.05271431
Iteration 745, loss = 0.05263532
Iteration 746, loss = 0.05255323
Iteration 747, loss = 0.05246829
Iteration 748, loss = 0.05238115
Iteration 749, loss = 0.05229657
Iteration 750, loss = 0.05221657
Iteration 751, loss = 0.05212925
Iteration 752, loss = 0.05204717
Iteration 753, loss = 0.05197030
Iteration 754, loss = 0.05188666
Iteration 755, loss = 0.05180612
Iteration 756, loss = 0.05173939
Iteration 757, loss = 0.05165065
Iteration 758, loss = 0.05158067
Iteration 759, loss = 0.05150069
Iteration 760, loss = 0.05142083
Iteration 761, loss = 0.05134846
Iteration 762, loss = 0.05126734
Iteration 763, loss = 0.05119274
Iteration 764, loss = 0.05111545
Iteration 765, loss = 0.05103561
Iteration 766, loss = 0.05096280
Iteration 767, loss = 0.05088992
Iteration 768, loss = 0.05081028
Iteration 769, loss = 0.05073660
Iteration 770, loss = 0.05066221
Iteration 771, loss = 0.05058587
Iteration 772, loss = 0.05051659
Iteration 773, loss = 0.05043958
Iteration 774, loss = 0.05036635
Iteration 775, loss = 0.05029313
Iteration 776, loss = 0.05022199
Iteration 777, loss = 0.05014762
Iteration 778, loss = 0.05007681
Iteration 779, loss = 0.05000489
Iteration 780, loss = 0.04993755
Iteration 781, loss = 0.04985948
Iteration 782, loss = 0.04979060
Iteration 783, loss = 0.04971768
Iteration 784, loss = 0.04963723
Iteration 785, loss = 0.04956616
Iteration 786, loss = 0.04949819
Iteration 787, loss = 0.04942083
Iteration 788, loss = 0.04934459
Iteration 789, loss = 0.04927405
Iteration 790, loss = 0.04919770
Iteration 791, loss = 0.04912851
Iteration 792, loss = 0.04905448
Iteration 793, loss = 0.04898563
Iteration 794, loss = 0.04891032
Iteration 795, loss = 0.04884160
Iteration 796, loss = 0.04877006
Iteration 797, loss = 0.04870585
Iteration 798, loss = 0.04863273
Iteration 799, loss = 0.04856761
Iteration 800, loss = 0.04849883
Iteration 801, loss = 0.04843257
Iteration 802, loss = 0.04836641
Iteration 803, loss = 0.04830080
Iteration 804, loss = 0.04823792
Iteration 805, loss = 0.04817367
Iteration 806, loss = 0.04810894
Iteration 807, loss = 0.04804246
Iteration 808, loss = 0.04797835
Iteration 809, loss = 0.04791086
Iteration 810, loss = 0.04784631
Iteration 811, loss = 0.04778140
Iteration 812, loss = 0.04771926
Iteration 813, loss = 0.04765474
Iteration 814, loss = 0.04759098
Iteration 815, loss = 0.04752841
Iteration 816, loss = 0.04746524
Iteration 817, loss = 0.04740273
Iteration 818, loss = 0.04734085
Iteration 819, loss = 0.04727947
Iteration 820, loss = 0.04721702
Iteration 821, loss = 0.04715444
Iteration 822, loss = 0.04709148
Iteration 823, loss = 0.04702355
Iteration 824, loss = 0.04695888
Iteration 825, loss = 0.04689519
Iteration 826, loss = 0.04682902
Iteration 827, loss = 0.04676927
Iteration 828, loss = 0.04670540
Iteration 829, loss = 0.04664445
Iteration 830, loss = 0.04658199
Iteration 831, loss = 0.04652284
Iteration 832, loss = 0.04646089
Iteration 833, loss = 0.04640426
Iteration 834, loss = 0.04634178
Iteration 835, loss = 0.04627920
Iteration 836, loss = 0.04621948
Iteration 837, loss = 0.04615365
Iteration 838, loss = 0.04609469
Iteration 839, loss = 0.04603363
Iteration 840, loss = 0.04597340
Iteration 841, loss = 0.04591566
Iteration 842, loss = 0.04585746
Iteration 843, loss = 0.04579948
Iteration 844, loss = 0.04574224
Iteration 845, loss = 0.04568713
Iteration 846, loss = 0.04563014
Iteration 847, loss = 0.04556689
Iteration 848, loss = 0.04550637
Iteration 849, loss = 0.04544804
Iteration 850, loss = 0.04538954
Iteration 851, loss = 0.04533098
Iteration 852, loss = 0.04527164
Iteration 853, loss = 0.04521536
Iteration 854, loss = 0.04515468
Iteration 855, loss = 0.04509294
Iteration 856, loss = 0.04503725
Iteration 857, loss = 0.04497692
Iteration 858, loss = 0.04491736
Iteration 859, loss = 0.04485794
Iteration 860, loss = 0.04480375
Iteration 861, loss = 0.04474814
Iteration 862, loss = 0.04468714
Iteration 863, loss = 0.04463098
Iteration 864, loss = 0.04457239
Iteration 865, loss = 0.04451964
Iteration 866, loss = 0.04446435
Iteration 867, loss = 0.04440565
Iteration 868, loss = 0.04435418
Iteration 869, loss = 0.04429265
Iteration 870, loss = 0.04424211
Iteration 871, loss = 0.04418309
Iteration 872, loss = 0.04412619
Iteration 873, loss = 0.04407351
Iteration 874, loss = 0.04401424
Iteration 875, loss = 0.04396210
Iteration 876, loss = 0.04390785
Iteration 877, loss = 0.04385082
Iteration 878, loss = 0.04379925
Iteration 879, loss = 0.04374308
Iteration 880, loss = 0.04369062
Iteration 881, loss = 0.04364041
Iteration 882, loss = 0.04358882
Iteration 883, loss = 0.04353911
Iteration 884, loss = 0.04348627
Iteration 885, loss = 0.04343930
Iteration 886, loss = 0.04338646
Iteration 887, loss = 0.04333167
Iteration 888, loss = 0.04328078
Iteration 889, loss = 0.04322562
Iteration 890, loss = 0.04317501
Iteration 891, loss = 0.04312584
Iteration 892, loss = 0.04307579
Iteration 893, loss = 0.04302973
Iteration 894, loss = 0.04297489
Iteration 895, loss = 0.04292355
Iteration 896, loss = 0.04287616
Iteration 897, loss = 0.04282655
Iteration 898, loss = 0.04277292
Iteration 899, loss = 0.04272134
Iteration 900, loss = 0.04267170
Iteration 901, loss = 0.04262094
Iteration 902, loss = 0.04257178
Iteration 903, loss = 0.04252127
Iteration 904, loss = 0.04247176
Iteration 905, loss = 0.04241948
Iteration 906, loss = 0.04236770
Iteration 907, loss = 0.04231926
Iteration 908, loss = 0.04227138
Iteration 909, loss = 0.04221985
Iteration 910, loss = 0.04217212
Iteration 911, loss = 0.04212073
Iteration 912, loss = 0.04207035
Iteration 913, loss = 0.04202494
Iteration 914, loss = 0.04197292
Iteration 915, loss = 0.04192212
Iteration 916, loss = 0.04187636
Iteration 917, loss = 0.04182765
Iteration 918, loss = 0.04177927
Iteration 919, loss = 0.04173264
Iteration 920, loss = 0.04168246
Iteration 921, loss = 0.04163709
Iteration 922, loss = 0.04158738
Iteration 923, loss = 0.04154083
Iteration 924, loss = 0.04149410
Iteration 925, loss = 0.04144806
Iteration 926, loss = 0.04140526
Iteration 927, loss = 0.04135579
Iteration 928, loss = 0.04130785
Iteration 929, loss = 0.04126264
Iteration 930, loss = 0.04121720
Iteration 931, loss = 0.04116922
Iteration 932, loss = 0.04112009
Iteration 933, loss = 0.04107277
Iteration 934, loss = 0.04102841
Iteration 935, loss = 0.04098161
Iteration 936, loss = 0.04093485
Iteration 937, loss = 0.04089006
Iteration 938, loss = 0.04084760
Iteration 939, loss = 0.04079740
Iteration 940, loss = 0.04075004
Iteration 941, loss = 0.04070472
Iteration 942, loss = 0.04065674
Iteration 943, loss = 0.04061040
Iteration 944, loss = 0.04056072
Iteration 945, loss = 0.04051361
Iteration 946, loss = 0.04046706
Iteration 947, loss = 0.04041824
Iteration 948, loss = 0.04037220
Iteration 949, loss = 0.04032702
Iteration 950, loss = 0.04027806
Iteration 951, loss = 0.04023025
Iteration 952, loss = 0.04018230
Iteration 953, loss = 0.04014512
Iteration 954, loss = 0.04009397
Iteration 955, loss = 0.04004977
Iteration 956, loss = 0.04000305
Iteration 957, loss = 0.03995746
Iteration 958, loss = 0.03991365
Iteration 959, loss = 0.03986882
Iteration 960, loss = 0.03982486
Iteration 961, loss = 0.03978179
Iteration 962, loss = 0.03973665
Iteration 963, loss = 0.03969414
Iteration 964, loss = 0.03965124
Iteration 965, loss = 0.03960809
Iteration 966, loss = 0.03956309
Iteration 967, loss = 0.03951956
Iteration 968, loss = 0.03947557
Iteration 969, loss = 0.03943451
Iteration 970, loss = 0.03938981
Iteration 971, loss = 0.03934567
Iteration 972, loss = 0.03930349
Iteration 973, loss = 0.03925978
Iteration 974, loss = 0.03921793
Iteration 975, loss = 0.03917591
Iteration 976, loss = 0.03913403
Iteration 977, loss = 0.03909392
Iteration 978, loss = 0.03905307
Iteration 979, loss = 0.03901261
Iteration 980, loss = 0.03897168
Iteration 981, loss = 0.03893119
Iteration 982, loss = 0.03889353
Iteration 983, loss = 0.03885221
Iteration 984, loss = 0.03881167
Iteration 985, loss = 0.03877650
Iteration 986, loss = 0.03873366
Iteration 987, loss = 0.03869250
Iteration 988, loss = 0.03865247
Iteration 989, loss = 0.03861417
Iteration 990, loss = 0.03857249
Iteration 991, loss = 0.03853346
Iteration 992, loss = 0.03849548
Iteration 993, loss = 0.03845429
Iteration 994, loss = 0.03841193
Iteration 995, loss = 0.03837181
Iteration 996, loss = 0.03833265
Iteration 997, loss = 0.03828982
Iteration 998, loss = 0.03824844
Iteration 999, loss = 0.03821421
Iteration 1000, loss = 0.03817205
Iteration 1001, loss = 0.03813578
Iteration 1002, loss = 0.03809508
Iteration 1003, loss = 0.03805454
Iteration 1004, loss = 0.03801896
Iteration 1005, loss = 0.03797577
Iteration 1006, loss = 0.03793954
Iteration 1007, loss = 0.03789742
Iteration 1008, loss = 0.03785616
Iteration 1009, loss = 0.03781569
Iteration 1010, loss = 0.03777636
Iteration 1011, loss = 0.03773481
Iteration 1012, loss = 0.03769365
Iteration 1013, loss = 0.03765436
Iteration 1014, loss = 0.03761412
Iteration 1015, loss = 0.03757445
Iteration 1016, loss = 0.03753453
Iteration 1017, loss = 0.03749692
Iteration 1018, loss = 0.03745899
Iteration 1019, loss = 0.03742050
Iteration 1020, loss = 0.03738204
Iteration 1021, loss = 0.03734153
Iteration 1022, loss = 0.03729938
Iteration 1023, loss = 0.03725936
Iteration 1024, loss = 0.03721884
Iteration 1025, loss = 0.03717502
Iteration 1026, loss = 0.03713715
Iteration 1027, loss = 0.03709800
Iteration 1028, loss = 0.03706227
Iteration 1029, loss = 0.03702630
Iteration 1030, loss = 0.03697896
Iteration 1031, loss = 0.03694074
Iteration 1032, loss = 0.03690239
Iteration 1033, loss = 0.03686115
Iteration 1034, loss = 0.03682191
Iteration 1035, loss = 0.03678800
Iteration 1036, loss = 0.03674693
Iteration 1037, loss = 0.03671012
Iteration 1038, loss = 0.03667156
Iteration 1039, loss = 0.03663813
Iteration 1040, loss = 0.03659879
Iteration 1041, loss = 0.03656200
Iteration 1042, loss = 0.03652671
Iteration 1043, loss = 0.03648726
Iteration 1044, loss = 0.03644949
Iteration 1045, loss = 0.03641331
Iteration 1046, loss = 0.03637536
Iteration 1047, loss = 0.03634078
Iteration 1048, loss = 0.03630155
Iteration 1049, loss = 0.03626757
Iteration 1050, loss = 0.03622986
Iteration 1051, loss = 0.03619330
Iteration 1052, loss = 0.03615777
Iteration 1053, loss = 0.03611572
Iteration 1054, loss = 0.03608359
Iteration 1055, loss = 0.03604470
Iteration 1056, loss = 0.03600784
Iteration 1057, loss = 0.03597088
Iteration 1058, loss = 0.03593234
Iteration 1059, loss = 0.03589621
Iteration 1060, loss = 0.03585998
Iteration 1061, loss = 0.03582012
Iteration 1062, loss = 0.03578185
Iteration 1063, loss = 0.03574761
Iteration 1064, loss = 0.03570748
Iteration 1065, loss = 0.03567049
Iteration 1066, loss = 0.03563079
Iteration 1067, loss = 0.03559721
Iteration 1068, loss = 0.03555966
Iteration 1069, loss = 0.03552176
Iteration 1070, loss = 0.03548404
Iteration 1071, loss = 0.03544437
Iteration 1072, loss = 0.03540753
Iteration 1073, loss = 0.03537152
Iteration 1074, loss = 0.03533677
Iteration 1075, loss = 0.03530025
Iteration 1076, loss = 0.03527316
Iteration 1077, loss = 0.03523429
Iteration 1078, loss = 0.03520232
Iteration 1079, loss = 0.03516796
Iteration 1080, loss = 0.03513084
Iteration 1081, loss = 0.03509653
Iteration 1082, loss = 0.03506121
Iteration 1083, loss = 0.03502414
Iteration 1084, loss = 0.03498834
Iteration 1085, loss = 0.03495156
Iteration 1086, loss = 0.03491473
Iteration 1087, loss = 0.03487718
Iteration 1088, loss = 0.03484696
Iteration 1089, loss = 0.03480657
Iteration 1090, loss = 0.03476915
Iteration 1091, loss = 0.03473450
Iteration 1092, loss = 0.03470021
Iteration 1093, loss = 0.03466448
Iteration 1094, loss = 0.03462600
Iteration 1095, loss = 0.03459700
Iteration 1096, loss = 0.03455441
Iteration 1097, loss = 0.03451694
Iteration 1098, loss = 0.03448565
Iteration 1099, loss = 0.03444716
Iteration 1100, loss = 0.03441221
Iteration 1101, loss = 0.03437702
Iteration 1102, loss = 0.03434161
Iteration 1103, loss = 0.03431124
Iteration 1104, loss = 0.03427705
Iteration 1105, loss = 0.03424301
Iteration 1106, loss = 0.03420699
Iteration 1107, loss = 0.03417177
Iteration 1108, loss = 0.03413899
Iteration 1109, loss = 0.03410518
Iteration 1110, loss = 0.03407213
Iteration 1111, loss = 0.03404213
Iteration 1112, loss = 0.03400795
Iteration 1113, loss = 0.03397420
Iteration 1114, loss = 0.03393831
Iteration 1115, loss = 0.03390579
Iteration 1116, loss = 0.03387414
Iteration 1117, loss = 0.03383990
Iteration 1118, loss = 0.03380839
Iteration 1119, loss = 0.03377680
Iteration 1120, loss = 0.03374441
Iteration 1121, loss = 0.03371141
Iteration 1122, loss = 0.03367838
Iteration 1123, loss = 0.03364551
Iteration 1124, loss = 0.03361433
Iteration 1125, loss = 0.03358593
Iteration 1126, loss = 0.03354925
Iteration 1127, loss = 0.03351883
Iteration 1128, loss = 0.03348643
Iteration 1129, loss = 0.03345660
Iteration 1130, loss = 0.03342177
Iteration 1131, loss = 0.03338983
Iteration 1132, loss = 0.03335449
Iteration 1133, loss = 0.03331982
Iteration 1134, loss = 0.03329304
Iteration 1135, loss = 0.03325961
Iteration 1136, loss = 0.03322542
Iteration 1137, loss = 0.03319328
Iteration 1138, loss = 0.03315911
Iteration 1139, loss = 0.03312574
Iteration 1140, loss = 0.03309664
Iteration 1141, loss = 0.03306003
Iteration 1142, loss = 0.03302750
Iteration 1143, loss = 0.03299581
Iteration 1144, loss = 0.03296769
Iteration 1145, loss = 0.03293134
Iteration 1146, loss = 0.03289999
Iteration 1147, loss = 0.03286602
Iteration 1148, loss = 0.03283348
Iteration 1149, loss = 0.03280133
Iteration 1150, loss = 0.03276914
Iteration 1151, loss = 0.03273524
Iteration 1152, loss = 0.03270940
Iteration 1153, loss = 0.03267874
Iteration 1154, loss = 0.03264638
Iteration 1155, loss = 0.03261677
Iteration 1156, loss = 0.03258567
Iteration 1157, loss = 0.03255875
Iteration 1158, loss = 0.03252626
Iteration 1159, loss = 0.03249822
Iteration 1160, loss = 0.03246896
Iteration 1161, loss = 0.03243766
Iteration 1162, loss = 0.03240746
Iteration 1163, loss = 0.03237749
Iteration 1164, loss = 0.03234905
Iteration 1165, loss = 0.03232007
Iteration 1166, loss = 0.03229370
Iteration 1167, loss = 0.03226331
Iteration 1168, loss = 0.03223299
Iteration 1169, loss = 0.03220854
Iteration 1170, loss = 0.03217276
Iteration 1171, loss = 0.03214377
Iteration 1172, loss = 0.03211414
Iteration 1173, loss = 0.03208082
Iteration 1174, loss = 0.03205217
Iteration 1175, loss = 0.03202067
Iteration 1176, loss = 0.03199141
Iteration 1177, loss = 0.03196328
Iteration 1178, loss = 0.03193491
Iteration 1179, loss = 0.03190851
Iteration 1180, loss = 0.03188023
Iteration 1181, loss = 0.03184880
Iteration 1182, loss = 0.03182175
Iteration 1183, loss = 0.03178988
Iteration 1184, loss = 0.03176018
Iteration 1185, loss = 0.03173138
Iteration 1186, loss = 0.03169941
Iteration 1187, loss = 0.03167335
Iteration 1188, loss = 0.03164141
Iteration 1189, loss = 0.03161263
Iteration 1190, loss = 0.03158429
Iteration 1191, loss = 0.03155701
Iteration 1192, loss = 0.03152773
Iteration 1193, loss = 0.03149973
Iteration 1194, loss = 0.03147283
Iteration 1195, loss = 0.03144619
Iteration 1196, loss = 0.03141712
Iteration 1197, loss = 0.03138867
Iteration 1198, loss = 0.03135878
Iteration 1199, loss = 0.03133434
Iteration 1200, loss = 0.03130397
Iteration 1201, loss = 0.03127589
Iteration 1202, loss = 0.03125210
Iteration 1203, loss = 0.03122066
Iteration 1204, loss = 0.03119119
Iteration 1205, loss = 0.03116473
Iteration 1206, loss = 0.03113794
Iteration 1207, loss = 0.03110770
Iteration 1208, loss = 0.03108369
Iteration 1209, loss = 0.03105430
Iteration 1210, loss = 0.03102875
Iteration 1211, loss = 0.03100301
Iteration 1212, loss = 0.03097658
Iteration 1213, loss = 0.03094883
Iteration 1214, loss = 0.03092205
Iteration 1215, loss = 0.03089509
Iteration 1216, loss = 0.03086928
Iteration 1217, loss = 0.03084224
Iteration 1218, loss = 0.03081625
Iteration 1219, loss = 0.03078929
Iteration 1220, loss = 0.03076415
Iteration 1221, loss = 0.03073886
Iteration 1222, loss = 0.03071292
Iteration 1223, loss = 0.03068908
Iteration 1224, loss = 0.03065648
Iteration 1225, loss = 0.03063685
Iteration 1226, loss = 0.03060852
Iteration 1227, loss = 0.03058110
Iteration 1228, loss = 0.03054903
Iteration 1229, loss = 0.03052271
Iteration 1230, loss = 0.03049562
Iteration 1231, loss = 0.03046819
Iteration 1232, loss = 0.03043956
Iteration 1233, loss = 0.03041571
Iteration 1234, loss = 0.03038614
Iteration 1235, loss = 0.03035772
Iteration 1236, loss = 0.03033207
Iteration 1237, loss = 0.03030703
Iteration 1238, loss = 0.03028004
Iteration 1239, loss = 0.03025239
Iteration 1240, loss = 0.03022749
Iteration 1241, loss = 0.03020061
Iteration 1242, loss = 0.03017508
Iteration 1243, loss = 0.03015229
Iteration 1244, loss = 0.03012581
Iteration 1245, loss = 0.03009711
Iteration 1246, loss = 0.03006893
Iteration 1247, loss = 0.03004178
Iteration 1248, loss = 0.03001497
Iteration 1249, loss = 0.02998627
Iteration 1250, loss = 0.02995851
Iteration 1251, loss = 0.02992921
Iteration 1252, loss = 0.02990433
Iteration 1253, loss = 0.02987641
Iteration 1254, loss = 0.02984775
Iteration 1255, loss = 0.02982064
Iteration 1256, loss = 0.02979388
Iteration 1257, loss = 0.02977197
Iteration 1258, loss = 0.02974099
Iteration 1259, loss = 0.02971453
Iteration 1260, loss = 0.02968816
Iteration 1261, loss = 0.02966120
Iteration 1262, loss = 0.02963490
Iteration 1263, loss = 0.02961061
Iteration 1264, loss = 0.02958368
Iteration 1265, loss = 0.02955843
Iteration 1266, loss = 0.02953217
Iteration 1267, loss = 0.02950840
Iteration 1268, loss = 0.02948206
Iteration 1269, loss = 0.02945738
Iteration 1270, loss = 0.02943088
Iteration 1271, loss = 0.02940728
Iteration 1272, loss = 0.02937900
Iteration 1273, loss = 0.02935557
Iteration 1274, loss = 0.02932886
Iteration 1275, loss = 0.02930117
Iteration 1276, loss = 0.02927991
Iteration 1277, loss = 0.02925045
Iteration 1278, loss = 0.02922366
Iteration 1279, loss = 0.02920025
Iteration 1280, loss = 0.02917146
Iteration 1281, loss = 0.02914631
Iteration 1282, loss = 0.02912145
Iteration 1283, loss = 0.02910366
Iteration 1284, loss = 0.02907536
Iteration 1285, loss = 0.02905072
Iteration 1286, loss = 0.02902713
Iteration 1287, loss = 0.02900321
Iteration 1288, loss = 0.02897806
Iteration 1289, loss = 0.02895178
Iteration 1290, loss = 0.02892852
Iteration 1291, loss = 0.02890254
Iteration 1292, loss = 0.02887698
Iteration 1293, loss = 0.02885413
Iteration 1294, loss = 0.02882843
Iteration 1295, loss = 0.02880326
Iteration 1296, loss = 0.02878001
Iteration 1297, loss = 0.02875627
Iteration 1298, loss = 0.02873249
Iteration 1299, loss = 0.02870647
Iteration 1300, loss = 0.02868179
Iteration 1301, loss = 0.02865733
Iteration 1302, loss = 0.02863375
Iteration 1303, loss = 0.02860712
Iteration 1304, loss = 0.02858310
Iteration 1305, loss = 0.02855878
Iteration 1306, loss = 0.02853301
Iteration 1307, loss = 0.02851068
Iteration 1308, loss = 0.02848501
Iteration 1309, loss = 0.02845850
Iteration 1310, loss = 0.02843630
Iteration 1311, loss = 0.02841178
Iteration 1312, loss = 0.02838509
Iteration 1313, loss = 0.02836090
Iteration 1314, loss = 0.02833725
Iteration 1315, loss = 0.02831450
Iteration 1316, loss = 0.02828954
Iteration 1317, loss = 0.02826512
Iteration 1318, loss = 0.02824084
Iteration 1319, loss = 0.02821760
Iteration 1320, loss = 0.02819426
Iteration 1321, loss = 0.02817040
Iteration 1322, loss = 0.02814662
Iteration 1323, loss = 0.02812523
Iteration 1324, loss = 0.02810219
Iteration 1325, loss = 0.02807617
Iteration 1326, loss = 0.02805365
Iteration 1327, loss = 0.02803033
Iteration 1328, loss = 0.02800893
Iteration 1329, loss = 0.02798691
Iteration 1330, loss = 0.02796357
Iteration 1331, loss = 0.02794127
Iteration 1332, loss = 0.02791739
Iteration 1333, loss = 0.02789335
Iteration 1334, loss = 0.02787403
Iteration 1335, loss = 0.02784892
Iteration 1336, loss = 0.02782712
Iteration 1337, loss = 0.02780419
Iteration 1338, loss = 0.02778185
Iteration 1339, loss = 0.02776453
Iteration 1340, loss = 0.02773991
Iteration 1341, loss = 0.02772262
Iteration 1342, loss = 0.02769701
Iteration 1343, loss = 0.02767496
Iteration 1344, loss = 0.02765511
Iteration 1345, loss = 0.02763314
Iteration 1346, loss = 0.02761114
Iteration 1347, loss = 0.02759119
Iteration 1348, loss = 0.02756845
Iteration 1349, loss = 0.02754573
Iteration 1350, loss = 0.02752314
Iteration 1351, loss = 0.02750043
Iteration 1352, loss = 0.02747685
Iteration 1353, loss = 0.02745486
Iteration 1354, loss = 0.02743168
Iteration 1355, loss = 0.02740986
Iteration 1356, loss = 0.02738587
Iteration 1357, loss = 0.02736557
Iteration 1358, loss = 0.02734167
Iteration 1359, loss = 0.02731956
Iteration 1360, loss = 0.02729636
Iteration 1361, loss = 0.02727564
Iteration 1362, loss = 0.02725259
Iteration 1363, loss = 0.02723138
Iteration 1364, loss = 0.02720950
Iteration 1365, loss = 0.02718631
Iteration 1366, loss = 0.02716448
Iteration 1367, loss = 0.02714215
Iteration 1368, loss = 0.02712172
Iteration 1369, loss = 0.02709871
Iteration 1370, loss = 0.02707417
Iteration 1371, loss = 0.02705809
Iteration 1372, loss = 0.02703373
Iteration 1373, loss = 0.02701142
Iteration 1374, loss = 0.02699078
Iteration 1375, loss = 0.02696941
Iteration 1376, loss = 0.02694681
Iteration 1377, loss = 0.02692504
Iteration 1378, loss = 0.02690297
Iteration 1379, loss = 0.02687896
Iteration 1380, loss = 0.02685482
Iteration 1381, loss = 0.02683535
Iteration 1382, loss = 0.02680962
Iteration 1383, loss = 0.02678736
Iteration 1384, loss = 0.02676711
Iteration 1385, loss = 0.02674139
Iteration 1386, loss = 0.02672094
Iteration 1387, loss = 0.02669906
Iteration 1388, loss = 0.02667903
Iteration 1389, loss = 0.02665636
Iteration 1390, loss = 0.02663611
Iteration 1391, loss = 0.02661257
Iteration 1392, loss = 0.02659227
Iteration 1393, loss = 0.02657159
Iteration 1394, loss = 0.02654944
Iteration 1395, loss = 0.02652964
Iteration 1396, loss = 0.02650748
Iteration 1397, loss = 0.02648494
Iteration 1398, loss = 0.02646558
Iteration 1399, loss = 0.02644287
Iteration 1400, loss = 0.02642433
Iteration 1401, loss = 0.02640238
Iteration 1402, loss = 0.02638473
Iteration 1403, loss = 0.02636083
Iteration 1404, loss = 0.02633925
Iteration 1405, loss = 0.02631905
Iteration 1406, loss = 0.02629807
Iteration 1407, loss = 0.02628031
Iteration 1408, loss = 0.02626104
Iteration 1409, loss = 0.02624180
Iteration 1410, loss = 0.02621875
Iteration 1411, loss = 0.02620160
Iteration 1412, loss = 0.02618023
Iteration 1413, loss = 0.02616200
Iteration 1414, loss = 0.02614020
Iteration 1415, loss = 0.02612061
Iteration 1416, loss = 0.02610184
Iteration 1417, loss = 0.02608040
Iteration 1418, loss = 0.02606190
Iteration 1419, loss = 0.02604467
Iteration 1420, loss = 0.02602243
Iteration 1421, loss = 0.02600307
Iteration 1422, loss = 0.02598178
Iteration 1423, loss = 0.02596053
Iteration 1424, loss = 0.02593890
Iteration 1425, loss = 0.02591966
Iteration 1426, loss = 0.02589883
Iteration 1427, loss = 0.02587963
Iteration 1428, loss = 0.02585884
Iteration 1429, loss = 0.02583884
Iteration 1430, loss = 0.02581705
Iteration 1431, loss = 0.02579567
Iteration 1432, loss = 0.02577776
Iteration 1433, loss = 0.02575513
Iteration 1434, loss = 0.02573549
Iteration 1435, loss = 0.02571571
Iteration 1436, loss = 0.02569256
Iteration 1437, loss = 0.02567360
Iteration 1438, loss = 0.02565049
Iteration 1439, loss = 0.02562833
Iteration 1440, loss = 0.02561176
Iteration 1441, loss = 0.02558769
Iteration 1442, loss = 0.02556962
Iteration 1443, loss = 0.02554800
Iteration 1444, loss = 0.02552663
Iteration 1445, loss = 0.02551022
Iteration 1446, loss = 0.02548528
Iteration 1447, loss = 0.02546385
Iteration 1448, loss = 0.02544570
Iteration 1449, loss = 0.02542967
Iteration 1450, loss = 0.02540672
Iteration 1451, loss = 0.02538886
Iteration 1452, loss = 0.02536834
Iteration 1453, loss = 0.02535225
Iteration 1454, loss = 0.02533167
Iteration 1455, loss = 0.02531083
Iteration 1456, loss = 0.02529283
Iteration 1457, loss = 0.02527235
Iteration 1458, loss = 0.02525264
Iteration 1459, loss = 0.02523384
Iteration 1460, loss = 0.02521281
Iteration 1461, loss = 0.02519214
Iteration 1462, loss = 0.02517349
Iteration 1463, loss = 0.02515267
Iteration 1464, loss = 0.02513260
Iteration 1465, loss = 0.02511236
Iteration 1466, loss = 0.02509095
Iteration 1467, loss = 0.02507773
Iteration 1468, loss = 0.02505316
Iteration 1469, loss = 0.02503391
Iteration 1470, loss = 0.02501391
Iteration 1471, loss = 0.02499565
Iteration 1472, loss = 0.02497842
Iteration 1473, loss = 0.02495804
Iteration 1474, loss = 0.02493945
Iteration 1475, loss = 0.02492289
Iteration 1476, loss = 0.02490469
Iteration 1477, loss = 0.02488566
Iteration 1478, loss = 0.02486392
Iteration 1479, loss = 0.02484593
Iteration 1480, loss = 0.02482430
Iteration 1481, loss = 0.02480648
Iteration 1482, loss = 0.02478535
Iteration 1483, loss = 0.02476582
Iteration 1484, loss = 0.02474669
Iteration 1485, loss = 0.02472762
Iteration 1486, loss = 0.02471020
Iteration 1487, loss = 0.02469006
Iteration 1488, loss = 0.02467375
Iteration 1489, loss = 0.02465364
Iteration 1490, loss = 0.02463439
Iteration 1491, loss = 0.02461634
Iteration 1492, loss = 0.02459860
Iteration 1493, loss = 0.02457790
Iteration 1494, loss = 0.02455779
Iteration 1495, loss = 0.02453891
Iteration 1496, loss = 0.02452002
Iteration 1497, loss = 0.02449938
Iteration 1498, loss = 0.02447995
Iteration 1499, loss = 0.02446110
Iteration 1500, loss = 0.02444332
Iteration 1501, loss = 0.02442301
Iteration 1502, loss = 0.02440421
Iteration 1503, loss = 0.02438623
Iteration 1504, loss = 0.02436820
Iteration 1505, loss = 0.02434948
Iteration 1506, loss = 0.02433120
Iteration 1507, loss = 0.02431363
Iteration 1508, loss = 0.02429840
Iteration 1509, loss = 0.02427876
Iteration 1510, loss = 0.02426373
Iteration 1511, loss = 0.02424642
Iteration 1512, loss = 0.02423027
Iteration 1513, loss = 0.02421047
Iteration 1514, loss = 0.02419245
Iteration 1515, loss = 0.02417381
Iteration 1516, loss = 0.02415380
Iteration 1517, loss = 0.02413554
Iteration 1518, loss = 0.02411716
Iteration 1519, loss = 0.02409556
Iteration 1520, loss = 0.02407788
Iteration 1521, loss = 0.02405793
Iteration 1522, loss = 0.02403934
Iteration 1523, loss = 0.02402061
Iteration 1524, loss = 0.02400083
Iteration 1525, loss = 0.02398413
Iteration 1526, loss = 0.02396734
Iteration 1527, loss = 0.02394626
Iteration 1528, loss = 0.02392683
Iteration 1529, loss = 0.02390914
Iteration 1530, loss = 0.02389133
Iteration 1531, loss = 0.02387362
Iteration 1532, loss = 0.02385398
Iteration 1533, loss = 0.02383455
Iteration 1534, loss = 0.02381728
Iteration 1535, loss = 0.02379906
Iteration 1536, loss = 0.02378217
Iteration 1537, loss = 0.02376497
Iteration 1538, loss = 0.02374737
Iteration 1539, loss = 0.02373079
Iteration 1540, loss = 0.02371232
Iteration 1541, loss = 0.02369635
Iteration 1542, loss = 0.02367919
Iteration 1543, loss = 0.02366190
Iteration 1544, loss = 0.02364499
Iteration 1545, loss = 0.02362765
Iteration 1546, loss = 0.02361143
Iteration 1547, loss = 0.02359301
Iteration 1548, loss = 0.02357902
Iteration 1549, loss = 0.02355636
Iteration 1550, loss = 0.02353979
Iteration 1551, loss = 0.02351989
Iteration 1552, loss = 0.02350362
Iteration 1553, loss = 0.02348630
Iteration 1554, loss = 0.02346925
Iteration 1555, loss = 0.02345129
Iteration 1556, loss = 0.02343508
Iteration 1557, loss = 0.02341707
Iteration 1558, loss = 0.02339955
Iteration 1559, loss = 0.02338265
Iteration 1560, loss = 0.02336507
Iteration 1561, loss = 0.02334824
Iteration 1562, loss = 0.02333016
Iteration 1563, loss = 0.02331417
Iteration 1564, loss = 0.02329616
Iteration 1565, loss = 0.02328034
Iteration 1566, loss = 0.02326141
Iteration 1567, loss = 0.02324497
Iteration 1568, loss = 0.02322760
Iteration 1569, loss = 0.02321114
Iteration 1570, loss = 0.02319366
Iteration 1571, loss = 0.02317624
Iteration 1572, loss = 0.02316170
Iteration 1573, loss = 0.02314174
Iteration 1574, loss = 0.02312685
Iteration 1575, loss = 0.02310660
Iteration 1576, loss = 0.02309084
Iteration 1577, loss = 0.02307466
Iteration 1578, loss = 0.02305561
Iteration 1579, loss = 0.02303802
Iteration 1580, loss = 0.02302178
Iteration 1581, loss = 0.02300412
Iteration 1582, loss = 0.02298739
Iteration 1583, loss = 0.02297507
Iteration 1584, loss = 0.02296305
Iteration 1585, loss = 0.02294418
Iteration 1586, loss = 0.02292719
Iteration 1587, loss = 0.02291015
Iteration 1588, loss = 0.02289312
Iteration 1589, loss = 0.02287646
Iteration 1590, loss = 0.02286002
Iteration 1591, loss = 0.02284281
Iteration 1592, loss = 0.02282705
Iteration 1593, loss = 0.02281350
Iteration 1594, loss = 0.02279314
Iteration 1595, loss = 0.02277755
Iteration 1596, loss = 0.02276071
Iteration 1597, loss = 0.02274399
Iteration 1598, loss = 0.02272722
Iteration 1599, loss = 0.02271092
Iteration 1600, loss = 0.02269434
Iteration 1601, loss = 0.02267734
Iteration 1602, loss = 0.02266429
Iteration 1603, loss = 0.02264516
Iteration 1604, loss = 0.02262873
Iteration 1605, loss = 0.02261263
Iteration 1606, loss = 0.02259912
Iteration 1607, loss = 0.02258208
Iteration 1608, loss = 0.02256463
Iteration 1609, loss = 0.02254954
Iteration 1610, loss = 0.02253239
Iteration 1611, loss = 0.02251750
Iteration 1612, loss = 0.02250338
Iteration 1613, loss = 0.02248610
Iteration 1614, loss = 0.02247065
Iteration 1615, loss = 0.02245448
Iteration 1616, loss = 0.02243790
Iteration 1617, loss = 0.02242223
Iteration 1618, loss = 0.02240666
Iteration 1619, loss = 0.02239108
Iteration 1620, loss = 0.02237568
Iteration 1621, loss = 0.02236124
Iteration 1622, loss = 0.02234667
Iteration 1623, loss = 0.02233089
Iteration 1624, loss = 0.02231979
Iteration 1625, loss = 0.02230115
Iteration 1626, loss = 0.02228591
Iteration 1627, loss = 0.02227023
Iteration 1628, loss = 0.02225705
Iteration 1629, loss = 0.02223900
Iteration 1630, loss = 0.02222739
Iteration 1631, loss = 0.02220595
Iteration 1632, loss = 0.02219084
Iteration 1633, loss = 0.02218019
Iteration 1634, loss = 0.02215832
Iteration 1635, loss = 0.02214340
Iteration 1636, loss = 0.02212667
Iteration 1637, loss = 0.02211080
Iteration 1638, loss = 0.02209381
Iteration 1639, loss = 0.02207716
Iteration 1640, loss = 0.02206389
Iteration 1641, loss = 0.02204508
Iteration 1642, loss = 0.02203347
Iteration 1643, loss = 0.02202016
Iteration 1644, loss = 0.02200065
Iteration 1645, loss = 0.02198629
Iteration 1646, loss = 0.02197063
Iteration 1647, loss = 0.02195488
Iteration 1648, loss = 0.02194052
Iteration 1649, loss = 0.02192537
Iteration 1650, loss = 0.02191080
Iteration 1651, loss = 0.02189497
Iteration 1652, loss = 0.02188070
Iteration 1653, loss = 0.02186599
Iteration 1654, loss = 0.02185019
Iteration 1655, loss = 0.02183657
Iteration 1656, loss = 0.02182354
Iteration 1657, loss = 0.02180893
Iteration 1658, loss = 0.02179335
Iteration 1659, loss = 0.02177796
Iteration 1660, loss = 0.02176164
Iteration 1661, loss = 0.02174688
Iteration 1662, loss = 0.02173334
Iteration 1663, loss = 0.02171641
Iteration 1664, loss = 0.02170085
Iteration 1665, loss = 0.02168492
Iteration 1666, loss = 0.02166928
Iteration 1667, loss = 0.02165595
Iteration 1668, loss = 0.02164096
Iteration 1669, loss = 0.02162453
Iteration 1670, loss = 0.02160936
Iteration 1671, loss = 0.02159473
Iteration 1672, loss = 0.02157869
Iteration 1673, loss = 0.02156320
Iteration 1674, loss = 0.02154758
Iteration 1675, loss = 0.02153383
Iteration 1676, loss = 0.02151910
Iteration 1677, loss = 0.02150137
Iteration 1678, loss = 0.02148626
Iteration 1679, loss = 0.02147621
Iteration 1680, loss = 0.02145994
Iteration 1681, loss = 0.02144601
Iteration 1682, loss = 0.02143324
Iteration 1683, loss = 0.02141846
Iteration 1684, loss = 0.02140338
Iteration 1685, loss = 0.02138994
Iteration 1686, loss = 0.02137467
Iteration 1687, loss = 0.02136026
Iteration 1688, loss = 0.02134483
Iteration 1689, loss = 0.02132950
Iteration 1690, loss = 0.02131425
Iteration 1691, loss = 0.02129919
Iteration 1692, loss = 0.02128456
Iteration 1693, loss = 0.02126928
Iteration 1694, loss = 0.02125460
Iteration 1695, loss = 0.02124013
Iteration 1696, loss = 0.02122474
Iteration 1697, loss = 0.02120989
Iteration 1698, loss = 0.02119632
Iteration 1699, loss = 0.02118382
Iteration 1700, loss = 0.02116702
Iteration 1701, loss = 0.02115320
Iteration 1702, loss = 0.02113855
Iteration 1703, loss = 0.02112431
Iteration 1704, loss = 0.02111379
Iteration 1705, loss = 0.02109575
Iteration 1706, loss = 0.02108168
Iteration 1707, loss = 0.02106642
Iteration 1708, loss = 0.02105196
Iteration 1709, loss = 0.02103802
Iteration 1710, loss = 0.02102271
Iteration 1711, loss = 0.02100913
Iteration 1712, loss = 0.02099243
Iteration 1713, loss = 0.02097712
Iteration 1714, loss = 0.02096338
Iteration 1715, loss = 0.02095255
Iteration 1716, loss = 0.02093793
Iteration 1717, loss = 0.02092916
Iteration 1718, loss = 0.02091151
Iteration 1719, loss = 0.02089739
Iteration 1720, loss = 0.02088191
Iteration 1721, loss = 0.02086732
Iteration 1722, loss = 0.02085492
Iteration 1723, loss = 0.02084044
Iteration 1724, loss = 0.02082588
Iteration 1725, loss = 0.02081209
Iteration 1726, loss = 0.02079747
Iteration 1727, loss = 0.02078522
Iteration 1728, loss = 0.02076925
Iteration 1729, loss = 0.02075528
Iteration 1730, loss = 0.02074107
Iteration 1731, loss = 0.02072513
Iteration 1732, loss = 0.02071967
Iteration 1733, loss = 0.02069793
Iteration 1734, loss = 0.02068355
Iteration 1735, loss = 0.02066998
Iteration 1736, loss = 0.02065816
Iteration 1737, loss = 0.02064483
Iteration 1738, loss = 0.02063011
Iteration 1739, loss = 0.02061660
Iteration 1740, loss = 0.02060281
Iteration 1741, loss = 0.02058898
Iteration 1742, loss = 0.02057583
Iteration 1743, loss = 0.02056250
Iteration 1744, loss = 0.02054850
Iteration 1745, loss = 0.02053518
Iteration 1746, loss = 0.02052150
Iteration 1747, loss = 0.02050954
Iteration 1748, loss = 0.02049472
Iteration 1749, loss = 0.02048196
Iteration 1750, loss = 0.02046892
Iteration 1751, loss = 0.02045467
Iteration 1752, loss = 0.02044102
Iteration 1753, loss = 0.02043039
Iteration 1754, loss = 0.02041509
Iteration 1755, loss = 0.02040139
Iteration 1756, loss = 0.02038722
Iteration 1757, loss = 0.02037745
Iteration 1758, loss = 0.02036123
Iteration 1759, loss = 0.02034777
Iteration 1760, loss = 0.02033471
Iteration 1761, loss = 0.02032053
Iteration 1762, loss = 0.02030672
Iteration 1763, loss = 0.02029665
Iteration 1764, loss = 0.02028182
Iteration 1765, loss = 0.02026735
Iteration 1766, loss = 0.02025508
Iteration 1767, loss = 0.02024174
Iteration 1768, loss = 0.02023028
Iteration 1769, loss = 0.02021840
Iteration 1770, loss = 0.02020789
Iteration 1771, loss = 0.02019308
Iteration 1772, loss = 0.02017953
Iteration 1773, loss = 0.02016638
Iteration 1774, loss = 0.02015330
Iteration 1775, loss = 0.02013927
Iteration 1776, loss = 0.02012623
Iteration 1777, loss = 0.02011249
Iteration 1778, loss = 0.02009949
Iteration 1779, loss = 0.02008590
Iteration 1780, loss = 0.02007254
Iteration 1781, loss = 0.02005989
Iteration 1782, loss = 0.02005351
Iteration 1783, loss = 0.02003402
Iteration 1784, loss = 0.02002159
Iteration 1785, loss = 0.02000665
Iteration 1786, loss = 0.01999335
Iteration 1787, loss = 0.01998065
Iteration 1788, loss = 0.01996706
Iteration 1789, loss = 0.01995300
Iteration 1790, loss = 0.01993956
Iteration 1791, loss = 0.01992496
Iteration 1792, loss = 0.01991070
Iteration 1793, loss = 0.01989769
Iteration 1794, loss = 0.01988241
Iteration 1795, loss = 0.01986958
Iteration 1796, loss = 0.01985775
Iteration 1797, loss = 0.01984454
Iteration 1798, loss = 0.01983186
Iteration 1799, loss = 0.01982344
Iteration 1800, loss = 0.01980600
Iteration 1801, loss = 0.01979190
Iteration 1802, loss = 0.01977872
Iteration 1803, loss = 0.01976565
Iteration 1804, loss = 0.01975365
Iteration 1805, loss = 0.01973912
Iteration 1806, loss = 0.01972612
Iteration 1807, loss = 0.01971749
Iteration 1808, loss = 0.01969949
Iteration 1809, loss = 0.01968639
Iteration 1810, loss = 0.01967312
Iteration 1811, loss = 0.01965926
Iteration 1812, loss = 0.01964422
Iteration 1813, loss = 0.01963478
Iteration 1814, loss = 0.01961900
Iteration 1815, loss = 0.01960499
Iteration 1816, loss = 0.01959122
Iteration 1817, loss = 0.01957662
Iteration 1818, loss = 0.01956551
Iteration 1819, loss = 0.01955531
Iteration 1820, loss = 0.01953838
Iteration 1821, loss = 0.01952612
Iteration 1822, loss = 0.01951448
Iteration 1823, loss = 0.01950018
Iteration 1824, loss = 0.01948841
Iteration 1825, loss = 0.01947528
Iteration 1826, loss = 0.01946259
Iteration 1827, loss = 0.01944952
Iteration 1828, loss = 0.01943652
Iteration 1829, loss = 0.01942457
Iteration 1830, loss = 0.01941257
Iteration 1831, loss = 0.01939936
Iteration 1832, loss = 0.01938698
Iteration 1833, loss = 0.01937506
Iteration 1834, loss = 0.01936279
Iteration 1835, loss = 0.01935111
Iteration 1836, loss = 0.01933742
Iteration 1837, loss = 0.01932561
Iteration 1838, loss = 0.01931625
Iteration 1839, loss = 0.01930071
Iteration 1840, loss = 0.01928976
Iteration 1841, loss = 0.01927954
Iteration 1842, loss = 0.01926540
Iteration 1843, loss = 0.01925251
Iteration 1844, loss = 0.01924388
Iteration 1845, loss = 0.01922977
Iteration 1846, loss = 0.01921882
Iteration 1847, loss = 0.01920816
Iteration 1848, loss = 0.01919646
Iteration 1849, loss = 0.01918676
Iteration 1850, loss = 0.01917488
Iteration 1851, loss = 0.01916232
Iteration 1852, loss = 0.01915047
Iteration 1853, loss = 0.01913844
Iteration 1854, loss = 0.01912708
Iteration 1855, loss = 0.01911689
Iteration 1856, loss = 0.01910721
Iteration 1857, loss = 0.01909680
Iteration 1858, loss = 0.01908496
Iteration 1859, loss = 0.01907383
Iteration 1860, loss = 0.01906207
Iteration 1861, loss = 0.01905061
Iteration 1862, loss = 0.01903866
Iteration 1863, loss = 0.01902663
Iteration 1864, loss = 0.01901462
Iteration 1865, loss = 0.01900183
Iteration 1866, loss = 0.01899065
Iteration 1867, loss = 0.01897790
Iteration 1868, loss = 0.01896520
Iteration 1869, loss = 0.01895519
Iteration 1870, loss = 0.01894303
Iteration 1871, loss = 0.01893064
Iteration 1872, loss = 0.01891887
Iteration 1873, loss = 0.01890548
Iteration 1874, loss = 0.01889415
Iteration 1875, loss = 0.01888201
Iteration 1876, loss = 0.01886877
Iteration 1877, loss = 0.01885592
Iteration 1878, loss = 0.01884355
Iteration 1879, loss = 0.01883357
Iteration 1880, loss = 0.01882350
Iteration 1881, loss = 0.01880905
Iteration 1882, loss = 0.01879606
Iteration 1883, loss = 0.01878471
Iteration 1884, loss = 0.01877028
Iteration 1885, loss = 0.01875697
Iteration 1886, loss = 0.01874592
Iteration 1887, loss = 0.01873202
Iteration 1888, loss = 0.01871910
Iteration 1889, loss = 0.01870602
Iteration 1890, loss = 0.01869374
Iteration 1891, loss = 0.01867972
Iteration 1892, loss = 0.01866832
Iteration 1893, loss = 0.01865708
Iteration 1894, loss = 0.01864560
Iteration 1895, loss = 0.01863086
Iteration 1896, loss = 0.01861830
Iteration 1897, loss = 0.01860693
Iteration 1898, loss = 0.01859431
Iteration 1899, loss = 0.01858249
Iteration 1900, loss = 0.01856903
Iteration 1901, loss = 0.01855559
Iteration 1902, loss = 0.01854414
Iteration 1903, loss = 0.01853040
Iteration 1904, loss = 0.01851944
Iteration 1905, loss = 0.01850801
Iteration 1906, loss = 0.01849761
Iteration 1907, loss = 0.01848480
Iteration 1908, loss = 0.01847430
Iteration 1909, loss = 0.01846062
Iteration 1910, loss = 0.01845008
Iteration 1911, loss = 0.01843760
Iteration 1912, loss = 0.01842801
Iteration 1913, loss = 0.01841529
Iteration 1914, loss = 0.01840548
Iteration 1915, loss = 0.01839237
Iteration 1916, loss = 0.01838047
Iteration 1917, loss = 0.01837045
Iteration 1918, loss = 0.01835841
Iteration 1919, loss = 0.01834562
Iteration 1920, loss = 0.01833534
Iteration 1921, loss = 0.01832368
Iteration 1922, loss = 0.01831227
Iteration 1923, loss = 0.01830171
Iteration 1924, loss = 0.01829117
Iteration 1925, loss = 0.01828237
Iteration 1926, loss = 0.01826857
Iteration 1927, loss = 0.01825686
Iteration 1928, loss = 0.01824570
Iteration 1929, loss = 0.01823315
Iteration 1930, loss = 0.01822497
Iteration 1931, loss = 0.01821200
Iteration 1932, loss = 0.01820342
Iteration 1933, loss = 0.01819169
Iteration 1934, loss = 0.01818167
Iteration 1935, loss = 0.01817333
Iteration 1936, loss = 0.01816326
Iteration 1937, loss = 0.01815124
Iteration 1938, loss = 0.01813939
Iteration 1939, loss = 0.01812984
Iteration 1940, loss = 0.01811846
Iteration 1941, loss = 0.01810745
Iteration 1942, loss = 0.01809594
Iteration 1943, loss = 0.01808665
Iteration 1944, loss = 0.01807406
Iteration 1945, loss = 0.01806251
Iteration 1946, loss = 0.01805030
Iteration 1947, loss = 0.01803924
Iteration 1948, loss = 0.01802685
Iteration 1949, loss = 0.01801509
Iteration 1950, loss = 0.01800350
Iteration 1951, loss = 0.01799308
Iteration 1952, loss = 0.01798196
Iteration 1953, loss = 0.01797117
Iteration 1954, loss = 0.01796164
Iteration 1955, loss = 0.01794973
Iteration 1956, loss = 0.01793890
Iteration 1957, loss = 0.01792897
Iteration 1958, loss = 0.01791891
Iteration 1959, loss = 0.01790706
Iteration 1960, loss = 0.01789693
Iteration 1961, loss = 0.01788812
Iteration 1962, loss = 0.01787813
Iteration 1963, loss = 0.01786819
Iteration 1964, loss = 0.01785864
Iteration 1965, loss = 0.01784740
Iteration 1966, loss = 0.01783698
Iteration 1967, loss = 0.01782860
Iteration 1968, loss = 0.01781547
Iteration 1969, loss = 0.01780467
Iteration 1970, loss = 0.01779318
Iteration 1971, loss = 0.01778324
Iteration 1972, loss = 0.01777311
Iteration 1973, loss = 0.01776611
Iteration 1974, loss = 0.01775148
Iteration 1975, loss = 0.01773994
Iteration 1976, loss = 0.01772888
Iteration 1977, loss = 0.01771750
Iteration 1978, loss = 0.01770669
Iteration 1979, loss = 0.01769492
Iteration 1980, loss = 0.01768280
Iteration 1981, loss = 0.01767231
Iteration 1982, loss = 0.01765958
Iteration 1983, loss = 0.01764815
Iteration 1984, loss = 0.01763705
Iteration 1985, loss = 0.01762583
Iteration 1986, loss = 0.01761446
Iteration 1987, loss = 0.01760421
Iteration 1988, loss = 0.01759481
Iteration 1989, loss = 0.01758336
Iteration 1990, loss = 0.01757327
Iteration 1991, loss = 0.01756282
Iteration 1992, loss = 0.01755436
Iteration 1993, loss = 0.01754272
Iteration 1994, loss = 0.01753339
Iteration 1995, loss = 0.01752305
Iteration 1996, loss = 0.01751270
Iteration 1997, loss = 0.01750314
Iteration 1998, loss = 0.01749296
Iteration 1999, loss = 0.01748235
Iteration 2000, loss = 0.01747488
Iteration 2001, loss = 0.01746278
Iteration 2002, loss = 0.01745200
Iteration 2003, loss = 0.01744308
Iteration 2004, loss = 0.01743123
Iteration 2005, loss = 0.01742264
Iteration 2006, loss = 0.01741090
Iteration 2007, loss = 0.01740121
Iteration 2008, loss = 0.01739060
Iteration 2009, loss = 0.01738048
Iteration 2010, loss = 0.01737014
Iteration 2011, loss = 0.01735982
Iteration 2012, loss = 0.01734969
Iteration 2013, loss = 0.01733954
Iteration 2014, loss = 0.01732977
Iteration 2015, loss = 0.01732112
Iteration 2016, loss = 0.01730901
Iteration 2017, loss = 0.01729766
Iteration 2018, loss = 0.01728426
Iteration 2019, loss = 0.01727412
Iteration 2020, loss = 0.01726258
Iteration 2021, loss = 0.01725000
Iteration 2022, loss = 0.01723880
Iteration 2023, loss = 0.01722838
Iteration 2024, loss = 0.01721774
Iteration 2025, loss = 0.01720598
Iteration 2026, loss = 0.01719592
Iteration 2027, loss = 0.01718604
Iteration 2028, loss = 0.01717452
Iteration 2029, loss = 0.01716574
Iteration 2030, loss = 0.01715409
Iteration 2031, loss = 0.01714275
Iteration 2032, loss = 0.01713322
Iteration 2033, loss = 0.01712215
Iteration 2034, loss = 0.01711229
Iteration 2035, loss = 0.01710047
Iteration 2036, loss = 0.01709078
Iteration 2037, loss = 0.01708244
Iteration 2038, loss = 0.01707000
Iteration 2039, loss = 0.01705897
Iteration 2040, loss = 0.01704760
Iteration 2041, loss = 0.01703875
Iteration 2042, loss = 0.01702735
Iteration 2043, loss = 0.01701682
Iteration 2044, loss = 0.01700429
Iteration 2045, loss = 0.01699470
Iteration 2046, loss = 0.01698364
Iteration 2047, loss = 0.01697258
Iteration 2048, loss = 0.01696366
Iteration 2049, loss = 0.01695170
Iteration 2050, loss = 0.01694005
Iteration 2051, loss = 0.01693077
Iteration 2052, loss = 0.01692174
Iteration 2053, loss = 0.01691042
Iteration 2054, loss = 0.01690144
Iteration 2055, loss = 0.01688886
Iteration 2056, loss = 0.01687930
Iteration 2057, loss = 0.01687178
Iteration 2058, loss = 0.01685873
Iteration 2059, loss = 0.01685005
Iteration 2060, loss = 0.01683931
Iteration 2061, loss = 0.01682856
Iteration 2062, loss = 0.01681921
Iteration 2063, loss = 0.01680817
Iteration 2064, loss = 0.01679863
Iteration 2065, loss = 0.01678809
Iteration 2066, loss = 0.01677844
Iteration 2067, loss = 0.01676825
Iteration 2068, loss = 0.01675883
Iteration 2069, loss = 0.01674890
Iteration 2070, loss = 0.01673966
Iteration 2071, loss = 0.01673092
Iteration 2072, loss = 0.01672104
Iteration 2073, loss = 0.01671478
Iteration 2074, loss = 0.01670183
Iteration 2075, loss = 0.01669121
Iteration 2076, loss = 0.01668133
Iteration 2077, loss = 0.01667166
Iteration 2078, loss = 0.01666014
Iteration 2079, loss = 0.01665184
Iteration 2080, loss = 0.01664017
Iteration 2081, loss = 0.01662981
Iteration 2082, loss = 0.01661927
Iteration 2083, loss = 0.01661019
Iteration 2084, loss = 0.01659948
Iteration 2085, loss = 0.01659115
Iteration 2086, loss = 0.01658026
Iteration 2087, loss = 0.01657178
Iteration 2088, loss = 0.01656227
Iteration 2089, loss = 0.01655515
Iteration 2090, loss = 0.01654554
Iteration 2091, loss = 0.01653809
Iteration 2092, loss = 0.01652777
Iteration 2093, loss = 0.01651920
Iteration 2094, loss = 0.01651063
Iteration 2095, loss = 0.01650144
Iteration 2096, loss = 0.01649186
Iteration 2097, loss = 0.01648155
Iteration 2098, loss = 0.01647307
Iteration 2099, loss = 0.01646305
Iteration 2100, loss = 0.01645189
Iteration 2101, loss = 0.01644224
Iteration 2102, loss = 0.01643257
Iteration 2103, loss = 0.01642212
Iteration 2104, loss = 0.01641374
Iteration 2105, loss = 0.01640307
Iteration 2106, loss = 0.01639320
Iteration 2107, loss = 0.01638173
Iteration 2108, loss = 0.01637223
Iteration 2109, loss = 0.01636237
Iteration 2110, loss = 0.01635436
Iteration 2111, loss = 0.01634279
Iteration 2112, loss = 0.01633415
Iteration 2113, loss = 0.01632390
Iteration 2114, loss = 0.01631544
Iteration 2115, loss = 0.01630573
Iteration 2116, loss = 0.01629673
Iteration 2117, loss = 0.01628720
Iteration 2118, loss = 0.01627688
Iteration 2119, loss = 0.01626782
Iteration 2120, loss = 0.01625682
Iteration 2121, loss = 0.01624764
Iteration 2122, loss = 0.01623715
Iteration 2123, loss = 0.01622773
Iteration 2124, loss = 0.01621850
Iteration 2125, loss = 0.01620840
Iteration 2126, loss = 0.01619949
Iteration 2127, loss = 0.01618962
Iteration 2128, loss = 0.01617935
Iteration 2129, loss = 0.01616921
Iteration 2130, loss = 0.01616092
Iteration 2131, loss = 0.01615171
Iteration 2132, loss = 0.01614276
Iteration 2133, loss = 0.01613394
Iteration 2134, loss = 0.01612219
Iteration 2135, loss = 0.01611386
Iteration 2136, loss = 0.01610536
Iteration 2137, loss = 0.01609484
Iteration 2138, loss = 0.01608459
Iteration 2139, loss = 0.01607449
Iteration 2140, loss = 0.01606633
Iteration 2141, loss = 0.01605693
Iteration 2142, loss = 0.01604679
Iteration 2143, loss = 0.01603808
Iteration 2144, loss = 0.01602747
Iteration 2145, loss = 0.01601846
Iteration 2146, loss = 0.01601025
Iteration 2147, loss = 0.01599981
Iteration 2148, loss = 0.01599119
Iteration 2149, loss = 0.01598188
Iteration 2150, loss = 0.01597387
Iteration 2151, loss = 0.01596432
Iteration 2152, loss = 0.01595514
Iteration 2153, loss = 0.01594700
Iteration 2154, loss = 0.01593683
Iteration 2155, loss = 0.01592744
Iteration 2156, loss = 0.01591880
Iteration 2157, loss = 0.01590889
Iteration 2158, loss = 0.01589860
Iteration 2159, loss = 0.01588995
Iteration 2160, loss = 0.01587984
Iteration 2161, loss = 0.01587243
Iteration 2162, loss = 0.01586545
Iteration 2163, loss = 0.01585294
Iteration 2164, loss = 0.01584310
Iteration 2165, loss = 0.01583446
Iteration 2166, loss = 0.01582309
Iteration 2167, loss = 0.01581437
Iteration 2168, loss = 0.01580420
Iteration 2169, loss = 0.01579325
Iteration 2170, loss = 0.01578690
Iteration 2171, loss = 0.01577802
Iteration 2172, loss = 0.01576748
Iteration 2173, loss = 0.01576018
Iteration 2174, loss = 0.01575152
Iteration 2175, loss = 0.01574421
Iteration 2176, loss = 0.01573412
Iteration 2177, loss = 0.01572465
Iteration 2178, loss = 0.01571487
Iteration 2179, loss = 0.01570665
Iteration 2180, loss = 0.01569774
Iteration 2181, loss = 0.01568883
Iteration 2182, loss = 0.01567857
Iteration 2183, loss = 0.01566855
Iteration 2184, loss = 0.01566062
Iteration 2185, loss = 0.01565062
Iteration 2186, loss = 0.01564268
Iteration 2187, loss = 0.01563290
Iteration 2188, loss = 0.01562536
Iteration 2189, loss = 0.01561579
Iteration 2190, loss = 0.01560715
Iteration 2191, loss = 0.01559804
Iteration 2192, loss = 0.01559027
Iteration 2193, loss = 0.01557989
Iteration 2194, loss = 0.01557205
Iteration 2195, loss = 0.01556141
Iteration 2196, loss = 0.01555269
Iteration 2197, loss = 0.01554411
Iteration 2198, loss = 0.01553483
Iteration 2199, loss = 0.01552589
Iteration 2200, loss = 0.01551791
Iteration 2201, loss = 0.01550922
Iteration 2202, loss = 0.01550100
Iteration 2203, loss = 0.01549375
Iteration 2204, loss = 0.01548472
Iteration 2205, loss = 0.01547611
Iteration 2206, loss = 0.01546798
Iteration 2207, loss = 0.01546157
Iteration 2208, loss = 0.01545301
Iteration 2209, loss = 0.01544408
Iteration 2210, loss = 0.01543628
Iteration 2211, loss = 0.01542765
Iteration 2212, loss = 0.01541824
Iteration 2213, loss = 0.01541038
Iteration 2214, loss = 0.01540247
Iteration 2215, loss = 0.01539520
Iteration 2216, loss = 0.01538808
Iteration 2217, loss = 0.01537696
Iteration 2218, loss = 0.01536896
Iteration 2219, loss = 0.01536020
Iteration 2220, loss = 0.01535078
Iteration 2221, loss = 0.01534134
Iteration 2222, loss = 0.01533254
Iteration 2223, loss = 0.01532297
Iteration 2224, loss = 0.01531515
Iteration 2225, loss = 0.01530573
Iteration 2226, loss = 0.01529687
Iteration 2227, loss = 0.01528882
Iteration 2228, loss = 0.01528048
Iteration 2229, loss = 0.01527396
Iteration 2230, loss = 0.01526482
Iteration 2231, loss = 0.01525628
Iteration 2232, loss = 0.01524801
Iteration 2233, loss = 0.01523968
Iteration 2234, loss = 0.01523188
Iteration 2235, loss = 0.01522369
Iteration 2236, loss = 0.01521640
Iteration 2237, loss = 0.01520817
Iteration 2238, loss = 0.01519998
Iteration 2239, loss = 0.01519154
Iteration 2240, loss = 0.01518148
Iteration 2241, loss = 0.01517385
Iteration 2242, loss = 0.01516395
Iteration 2243, loss = 0.01515403
Iteration 2244, loss = 0.01514641
Iteration 2245, loss = 0.01513871
Iteration 2246, loss = 0.01512784
Iteration 2247, loss = 0.01512026
Iteration 2248, loss = 0.01511256
Iteration 2249, loss = 0.01510354
Iteration 2250, loss = 0.01509496
Iteration 2251, loss = 0.01508966
Iteration 2252, loss = 0.01508166
Iteration 2253, loss = 0.01507298
Iteration 2254, loss = 0.01506366
Iteration 2255, loss = 0.01505672
Iteration 2256, loss = 0.01504748
Iteration 2257, loss = 0.01503971
Iteration 2258, loss = 0.01503218
Iteration 2259, loss = 0.01502349
Iteration 2260, loss = 0.01501460
Iteration 2261, loss = 0.01500957
Iteration 2262, loss = 0.01499750
Iteration 2263, loss = 0.01498907
Iteration 2264, loss = 0.01497995
Iteration 2265, loss = 0.01497095
Iteration 2266, loss = 0.01496355
Iteration 2267, loss = 0.01495652
Iteration 2268, loss = 0.01494763
Iteration 2269, loss = 0.01493985
Iteration 2270, loss = 0.01493170
Iteration 2271, loss = 0.01492393
Iteration 2272, loss = 0.01491649
Iteration 2273, loss = 0.01490933
Iteration 2274, loss = 0.01489980
Iteration 2275, loss = 0.01489380
Iteration 2276, loss = 0.01488311
Iteration 2277, loss = 0.01487390
Iteration 2278, loss = 0.01486433
Iteration 2279, loss = 0.01485656
Iteration 2280, loss = 0.01484852
Iteration 2281, loss = 0.01484072
Iteration 2282, loss = 0.01483146
Iteration 2283, loss = 0.01482409
Iteration 2284, loss = 0.01481453
Iteration 2285, loss = 0.01480657
Iteration 2286, loss = 0.01479809
Iteration 2287, loss = 0.01478976
Iteration 2288, loss = 0.01478090
Iteration 2289, loss = 0.01477422
Iteration 2290, loss = 0.01476606
Iteration 2291, loss = 0.01475761
Iteration 2292, loss = 0.01474907
Iteration 2293, loss = 0.01474034
Iteration 2294, loss = 0.01473292
Iteration 2295, loss = 0.01472441
Iteration 2296, loss = 0.01471697
Iteration 2297, loss = 0.01470811
Iteration 2298, loss = 0.01470055
Iteration 2299, loss = 0.01469249
Iteration 2300, loss = 0.01468604
Iteration 2301, loss = 0.01467629
Iteration 2302, loss = 0.01466832
Iteration 2303, loss = 0.01465943
Iteration 2304, loss = 0.01465064
Iteration 2305, loss = 0.01464209
Iteration 2306, loss = 0.01463412
Iteration 2307, loss = 0.01462770
Iteration 2308, loss = 0.01461933
Iteration 2309, loss = 0.01460982
Iteration 2310, loss = 0.01460144
Iteration 2311, loss = 0.01459583
Iteration 2312, loss = 0.01458569
Iteration 2313, loss = 0.01457719
Iteration 2314, loss = 0.01457006
Iteration 2315, loss = 0.01456221
Iteration 2316, loss = 0.01455406
Iteration 2317, loss = 0.01454554
Iteration 2318, loss = 0.01453810
Iteration 2319, loss = 0.01453000
Iteration 2320, loss = 0.01452303
Iteration 2321, loss = 0.01451549
Iteration 2322, loss = 0.01450686
Iteration 2323, loss = 0.01449837
Iteration 2324, loss = 0.01449023
Iteration 2325, loss = 0.01448354
Iteration 2326, loss = 0.01447510
Iteration 2327, loss = 0.01446695
Iteration 2328, loss = 0.01445877
Iteration 2329, loss = 0.01444979
Iteration 2330, loss = 0.01444402
Iteration 2331, loss = 0.01443447
Iteration 2332, loss = 0.01442727
Iteration 2333, loss = 0.01441963
Iteration 2334, loss = 0.01441043
Iteration 2335, loss = 0.01440335
Iteration 2336, loss = 0.01439517
Iteration 2337, loss = 0.01438679
Iteration 2338, loss = 0.01438050
Iteration 2339, loss = 0.01437174
Iteration 2340, loss = 0.01436522
Iteration 2341, loss = 0.01435662
Iteration 2342, loss = 0.01434893
Iteration 2343, loss = 0.01434167
Iteration 2344, loss = 0.01433359
Iteration 2345, loss = 0.01432617
Iteration 2346, loss = 0.01432041
Iteration 2347, loss = 0.01431091
Iteration 2348, loss = 0.01430155
Iteration 2349, loss = 0.01429377
Iteration 2350, loss = 0.01428623
Iteration 2351, loss = 0.01427836
Iteration 2352, loss = 0.01426984
Iteration 2353, loss = 0.01426332
Iteration 2354, loss = 0.01425551
Iteration 2355, loss = 0.01424607
Iteration 2356, loss = 0.01424111
Iteration 2357, loss = 0.01422915
Iteration 2358, loss = 0.01422099
Iteration 2359, loss = 0.01421375
Iteration 2360, loss = 0.01420516
Iteration 2361, loss = 0.01419710
Iteration 2362, loss = 0.01418921
Iteration 2363, loss = 0.01418143
Iteration 2364, loss = 0.01417241
Iteration 2365, loss = 0.01416364
Iteration 2366, loss = 0.01415667
Iteration 2367, loss = 0.01414756
Iteration 2368, loss = 0.01414151
Iteration 2369, loss = 0.01413198
Iteration 2370, loss = 0.01412437
Iteration 2371, loss = 0.01411748
Iteration 2372, loss = 0.01411095
Iteration 2373, loss = 0.01410180
Iteration 2374, loss = 0.01409418
Iteration 2375, loss = 0.01408651
Iteration 2376, loss = 0.01407807
Iteration 2377, loss = 0.01407033
Iteration 2378, loss = 0.01406268
Iteration 2379, loss = 0.01405588
Iteration 2380, loss = 0.01404756
Iteration 2381, loss = 0.01403980
Iteration 2382, loss = 0.01403269
Iteration 2383, loss = 0.01402686
Iteration 2384, loss = 0.01401892
Iteration 2385, loss = 0.01401178
Iteration 2386, loss = 0.01400443
Iteration 2387, loss = 0.01399757
Iteration 2388, loss = 0.01399049
Iteration 2389, loss = 0.01398239
Iteration 2390, loss = 0.01397511
Iteration 2391, loss = 0.01396717
Iteration 2392, loss = 0.01395961
Iteration 2393, loss = 0.01395238
Iteration 2394, loss = 0.01394496
Iteration 2395, loss = 0.01393922
Iteration 2396, loss = 0.01392958
Iteration 2397, loss = 0.01392217
Iteration 2398, loss = 0.01391529
Iteration 2399, loss = 0.01390610
Iteration 2400, loss = 0.01389994
Iteration 2401, loss = 0.01389242
Iteration 2402, loss = 0.01388332
Iteration 2403, loss = 0.01387547
Iteration 2404, loss = 0.01386853
Iteration 2405, loss = 0.01386188
Iteration 2406, loss = 0.01385333
Iteration 2407, loss = 0.01384573
Iteration 2408, loss = 0.01383876
Iteration 2409, loss = 0.01383153
Iteration 2410, loss = 0.01382463
Iteration 2411, loss = 0.01381674
Iteration 2412, loss = 0.01381006
Iteration 2413, loss = 0.01380271
Iteration 2414, loss = 0.01379637
Iteration 2415, loss = 0.01378632
Iteration 2416, loss = 0.01377813
Iteration 2417, loss = 0.01377017
Iteration 2418, loss = 0.01376524
Iteration 2419, loss = 0.01375533
Iteration 2420, loss = 0.01374836
Iteration 2421, loss = 0.01374121
Iteration 2422, loss = 0.01373368
Iteration 2423, loss = 0.01372657
Iteration 2424, loss = 0.01371907
Iteration 2425, loss = 0.01371139
Iteration 2426, loss = 0.01370499
Iteration 2427, loss = 0.01369756
Iteration 2428, loss = 0.01369138
Iteration 2429, loss = 0.01368395
Iteration 2430, loss = 0.01367697
Iteration 2431, loss = 0.01367014
Iteration 2432, loss = 0.01366288
Iteration 2433, loss = 0.01365674
Iteration 2434, loss = 0.01364923
Iteration 2435, loss = 0.01364334
Iteration 2436, loss = 0.01363627
Iteration 2437, loss = 0.01362907
Iteration 2438, loss = 0.01362222
Iteration 2439, loss = 0.01361611
Iteration 2440, loss = 0.01360978
Iteration 2441, loss = 0.01360319
Iteration 2442, loss = 0.01359686
Iteration 2443, loss = 0.01359000
Iteration 2444, loss = 0.01358576
Iteration 2445, loss = 0.01357995
Iteration 2446, loss = 0.01357207
Iteration 2447, loss = 0.01356655
Iteration 2448, loss = 0.01355752
Iteration 2449, loss = 0.01355091
Iteration 2450, loss = 0.01354339
Iteration 2451, loss = 0.01353684
Iteration 2452, loss = 0.01352996
Iteration 2453, loss = 0.01352380
Iteration 2454, loss = 0.01351773
Iteration 2455, loss = 0.01351118
Iteration 2456, loss = 0.01350542
Iteration 2457, loss = 0.01349811
Iteration 2458, loss = 0.01349092
Iteration 2459, loss = 0.01348487
Iteration 2460, loss = 0.01347830
Iteration 2461, loss = 0.01346960
Iteration 2462, loss = 0.01346276
Iteration 2463, loss = 0.01345571
Iteration 2464, loss = 0.01344733
Iteration 2465, loss = 0.01343972
Iteration 2466, loss = 0.01343371
Iteration 2467, loss = 0.01342460
Iteration 2468, loss = 0.01341847
Iteration 2469, loss = 0.01341016
Iteration 2470, loss = 0.01340249
Iteration 2471, loss = 0.01339547
Iteration 2472, loss = 0.01338758
Iteration 2473, loss = 0.01338186
Iteration 2474, loss = 0.01337401
Iteration 2475, loss = 0.01336627
Iteration 2476, loss = 0.01335968
Iteration 2477, loss = 0.01335175
Iteration 2478, loss = 0.01334520
Iteration 2479, loss = 0.01333872
Iteration 2480, loss = 0.01333134
Iteration 2481, loss = 0.01332529
Iteration 2482, loss = 0.01331874
Iteration 2483, loss = 0.01331279
Iteration 2484, loss = 0.01330682
Iteration 2485, loss = 0.01330096
Iteration 2486, loss = 0.01329534
Iteration 2487, loss = 0.01329109
Iteration 2488, loss = 0.01328397
Iteration 2489, loss = 0.01327818
Iteration 2490, loss = 0.01327269
Iteration 2491, loss = 0.01326567
Iteration 2492, loss = 0.01325964
Iteration 2493, loss = 0.01325406
Iteration 2494, loss = 0.01324789
Iteration 2495, loss = 0.01324090
Iteration 2496, loss = 0.01323450
Iteration 2497, loss = 0.01322778
Iteration 2498, loss = 0.01322268
Iteration 2499, loss = 0.01321594
Iteration 2500, loss = 0.01321041
Iteration 2501, loss = 0.01320275
Iteration 2502, loss = 0.01319681
Iteration 2503, loss = 0.01319006
Iteration 2504, loss = 0.01318353
Iteration 2505, loss = 0.01317712
Iteration 2506, loss = 0.01317145
Iteration 2507, loss = 0.01316462
Iteration 2508, loss = 0.01315823
Iteration 2509, loss = 0.01315168
Iteration 2510, loss = 0.01314590
Iteration 2511, loss = 0.01313944
Iteration 2512, loss = 0.01313339
Iteration 2513, loss = 0.01312741
Iteration 2514, loss = 0.01312138
Iteration 2515, loss = 0.01311528
Iteration 2516, loss = 0.01310970
Iteration 2517, loss = 0.01310429
Iteration 2518, loss = 0.01310104
Iteration 2519, loss = 0.01309404
Iteration 2520, loss = 0.01308856
Iteration 2521, loss = 0.01308357
Iteration 2522, loss = 0.01307664
Iteration 2523, loss = 0.01306975
Iteration 2524, loss = 0.01306300
Iteration 2525, loss = 0.01305692
Iteration 2526, loss = 0.01305008
Iteration 2527, loss = 0.01304383
Iteration 2528, loss = 0.01303766
Iteration 2529, loss = 0.01303221
Iteration 2530, loss = 0.01302755
Iteration 2531, loss = 0.01302157
Iteration 2532, loss = 0.01301401
Iteration 2533, loss = 0.01300748
Iteration 2534, loss = 0.01300054
Iteration 2535, loss = 0.01299395
Iteration 2536, loss = 0.01298542
Iteration 2537, loss = 0.01298103
Iteration 2538, loss = 0.01297424
Iteration 2539, loss = 0.01296472
Iteration 2540, loss = 0.01295845
Iteration 2541, loss = 0.01295008
Iteration 2542, loss = 0.01294414
Iteration 2543, loss = 0.01293625
Iteration 2544, loss = 0.01293030
Iteration 2545, loss = 0.01292322
Iteration 2546, loss = 0.01291593
Iteration 2547, loss = 0.01290730
Iteration 2548, loss = 0.01290169
Iteration 2549, loss = 0.01289208
Iteration 2550, loss = 0.01288492
Iteration 2551, loss = 0.01287872
Iteration 2552, loss = 0.01287056
Iteration 2553, loss = 0.01286437
Iteration 2554, loss = 0.01285679
Iteration 2555, loss = 0.01285102
Iteration 2556, loss = 0.01284409
Iteration 2557, loss = 0.01283765
Iteration 2558, loss = 0.01283250
Iteration 2559, loss = 0.01282466
Iteration 2560, loss = 0.01281764
Iteration 2561, loss = 0.01281145
Iteration 2562, loss = 0.01280495
Iteration 2563, loss = 0.01279761
Iteration 2564, loss = 0.01279186
Iteration 2565, loss = 0.01278423
Iteration 2566, loss = 0.01277700
Iteration 2567, loss = 0.01277072
Iteration 2568, loss = 0.01276275
Iteration 2569, loss = 0.01275547
Iteration 2570, loss = 0.01274883
Iteration 2571, loss = 0.01274282
Iteration 2572, loss = 0.01273530
Iteration 2573, loss = 0.01273046
Iteration 2574, loss = 0.01272374
Iteration 2575, loss = 0.01271686
Iteration 2576, loss = 0.01271069
Iteration 2577, loss = 0.01270467
Iteration 2578, loss = 0.01269722
Iteration 2579, loss = 0.01269124
Iteration 2580, loss = 0.01268534
Iteration 2581, loss = 0.01267921
Iteration 2582, loss = 0.01267352
Iteration 2583, loss = 0.01266792
Iteration 2584, loss = 0.01266104
Iteration 2585, loss = 0.01265494
Iteration 2586, loss = 0.01264922
Iteration 2587, loss = 0.01264340
Iteration 2588, loss = 0.01263758
Iteration 2589, loss = 0.01263418
Iteration 2590, loss = 0.01262765
Iteration 2591, loss = 0.01262152
Iteration 2592, loss = 0.01261535
Iteration 2593, loss = 0.01260947
Iteration 2594, loss = 0.01260321
Iteration 2595, loss = 0.01259787
Iteration 2596, loss = 0.01259333
Iteration 2597, loss = 0.01258437
Iteration 2598, loss = 0.01257877
Iteration 2599, loss = 0.01257155
Iteration 2600, loss = 0.01256753
Iteration 2601, loss = 0.01255898
Iteration 2602, loss = 0.01255257
Iteration 2603, loss = 0.01254664
Iteration 2604, loss = 0.01254022
Iteration 2605, loss = 0.01253439
Iteration 2606, loss = 0.01252836
Iteration 2607, loss = 0.01252276
Iteration 2608, loss = 0.01251715
Iteration 2609, loss = 0.01251093
Iteration 2610, loss = 0.01250442
Iteration 2611, loss = 0.01249795
Iteration 2612, loss = 0.01249158
Iteration 2613, loss = 0.01248609
Iteration 2614, loss = 0.01247805
Iteration 2615, loss = 0.01247209
Iteration 2616, loss = 0.01246494
Iteration 2617, loss = 0.01245883
Iteration 2618, loss = 0.01245346
Iteration 2619, loss = 0.01244736
Iteration 2620, loss = 0.01244154
Iteration 2621, loss = 0.01243649
Iteration 2622, loss = 0.01243050
Iteration 2623, loss = 0.01242681
Iteration 2624, loss = 0.01241952
Iteration 2625, loss = 0.01241358
Iteration 2626, loss = 0.01240795
Iteration 2627, loss = 0.01240239
Iteration 2628, loss = 0.01239707
Iteration 2629, loss = 0.01239287
Iteration 2630, loss = 0.01238732
Iteration 2631, loss = 0.01238458
Iteration 2632, loss = 0.01237782
Iteration 2633, loss = 0.01237230
Iteration 2634, loss = 0.01236663
Iteration 2635, loss = 0.01236130
Iteration 2636, loss = 0.01235440
Iteration 2637, loss = 0.01234817
Iteration 2638, loss = 0.01234259
Iteration 2639, loss = 0.01233563
Iteration 2640, loss = 0.01232990
Iteration 2641, loss = 0.01232437
Iteration 2642, loss = 0.01231873
Iteration 2643, loss = 0.01231328
Iteration 2644, loss = 0.01230812
Iteration 2645, loss = 0.01230288
Iteration 2646, loss = 0.01229714
Iteration 2647, loss = 0.01229167
Iteration 2648, loss = 0.01228660
Iteration 2649, loss = 0.01228238
Iteration 2650, loss = 0.01227633
Iteration 2651, loss = 0.01227061
Iteration 2652, loss = 0.01226531
Iteration 2653, loss = 0.01225958
Iteration 2654, loss = 0.01225514
Iteration 2655, loss = 0.01225121
Iteration 2656, loss = 0.01224515
Iteration 2657, loss = 0.01223989
Iteration 2658, loss = 0.01223403
Iteration 2659, loss = 0.01222843
Iteration 2660, loss = 0.01222171
Iteration 2661, loss = 0.01221533
Iteration 2662, loss = 0.01220898
Iteration 2663, loss = 0.01220239
Iteration 2664, loss = 0.01219645
Iteration 2665, loss = 0.01218990
Iteration 2666, loss = 0.01218313
Iteration 2667, loss = 0.01217723
Iteration 2668, loss = 0.01217012
Iteration 2669, loss = 0.01216471
Iteration 2670, loss = 0.01215879
Iteration 2671, loss = 0.01215314
Iteration 2672, loss = 0.01214650
Iteration 2673, loss = 0.01213976
Iteration 2674, loss = 0.01213460
Iteration 2675, loss = 0.01212754
Iteration 2676, loss = 0.01212180
Iteration 2677, loss = 0.01211551
Iteration 2678, loss = 0.01210952
Iteration 2679, loss = 0.01210338
Iteration 2680, loss = 0.01209745
Iteration 2681, loss = 0.01209248
Iteration 2682, loss = 0.01208478
Iteration 2683, loss = 0.01207763
Iteration 2684, loss = 0.01207035
Iteration 2685, loss = 0.01206241
Iteration 2686, loss = 0.01205515
Iteration 2687, loss = 0.01204891
Iteration 2688, loss = 0.01204235
Iteration 2689, loss = 0.01203532
Iteration 2690, loss = 0.01202975
Iteration 2691, loss = 0.01202243
Iteration 2692, loss = 0.01201620
Iteration 2693, loss = 0.01200976
Iteration 2694, loss = 0.01200554
Iteration 2695, loss = 0.01199796
Iteration 2696, loss = 0.01199095
Iteration 2697, loss = 0.01198550
Iteration 2698, loss = 0.01197781
Iteration 2699, loss = 0.01197110
Iteration 2700, loss = 0.01196628
Iteration 2701, loss = 0.01196375
Iteration 2702, loss = 0.01195370
Iteration 2703, loss = 0.01194828
Iteration 2704, loss = 0.01194325
Iteration 2705, loss = 0.01193605
Iteration 2706, loss = 0.01193034
Iteration 2707, loss = 0.01192459
Iteration 2708, loss = 0.01191967
Iteration 2709, loss = 0.01191409
Iteration 2710, loss = 0.01190714
Iteration 2711, loss = 0.01190147
Iteration 2712, loss = 0.01189544
Iteration 2713, loss = 0.01188964
Iteration 2714, loss = 0.01188414
Iteration 2715, loss = 0.01187915
Iteration 2716, loss = 0.01187277
Iteration 2717, loss = 0.01186664
Iteration 2718, loss = 0.01186196
Iteration 2719, loss = 0.01185547
Iteration 2720, loss = 0.01185001
Iteration 2721, loss = 0.01184468
Iteration 2722, loss = 0.01184026
Iteration 2723, loss = 0.01183366
Iteration 2724, loss = 0.01182784
Iteration 2725, loss = 0.01182239
Iteration 2726, loss = 0.01181714
Iteration 2727, loss = 0.01181189
Iteration 2728, loss = 0.01180650
Iteration 2729, loss = 0.01180045
Iteration 2730, loss = 0.01179500
Iteration 2731, loss = 0.01178954
Iteration 2732, loss = 0.01178409
Iteration 2733, loss = 0.01177985
Iteration 2734, loss = 0.01177248
Iteration 2735, loss = 0.01176678
Iteration 2736, loss = 0.01176085
Iteration 2737, loss = 0.01175511
Iteration 2738, loss = 0.01174941
Iteration 2739, loss = 0.01174411
Iteration 2740, loss = 0.01173881
Iteration 2741, loss = 0.01173237
Iteration 2742, loss = 0.01172702
Iteration 2743, loss = 0.01172278
Iteration 2744, loss = 0.01171600
Iteration 2745, loss = 0.01170972
Iteration 2746, loss = 0.01170428
Iteration 2747, loss = 0.01169829
Iteration 2748, loss = 0.01169253
Iteration 2749, loss = 0.01168713
Iteration 2750, loss = 0.01168087
Iteration 2751, loss = 0.01167465
Iteration 2752, loss = 0.01166879
Iteration 2753, loss = 0.01166220
Iteration 2754, loss = 0.01165761
Iteration 2755, loss = 0.01165032
Iteration 2756, loss = 0.01164483
Iteration 2757, loss = 0.01163892
Iteration 2758, loss = 0.01163269
Iteration 2759, loss = 0.01162746
Iteration 2760, loss = 0.01162184
Iteration 2761, loss = 0.01161570
Iteration 2762, loss = 0.01161007
Iteration 2763, loss = 0.01160532
Iteration 2764, loss = 0.01159934
Iteration 2765, loss = 0.01159316
Iteration 2766, loss = 0.01158662
Iteration 2767, loss = 0.01158228
Iteration 2768, loss = 0.01157567
Iteration 2769, loss = 0.01157008
Iteration 2770, loss = 0.01156472
Iteration 2771, loss = 0.01155935
Iteration 2772, loss = 0.01155389
Iteration 2773, loss = 0.01154851
Iteration 2774, loss = 0.01154281
Iteration 2775, loss = 0.01153838
Iteration 2776, loss = 0.01153264
Iteration 2777, loss = 0.01152721
Iteration 2778, loss = 0.01152133
Iteration 2779, loss = 0.01151750
Iteration 2780, loss = 0.01151214
Iteration 2781, loss = 0.01150682
Iteration 2782, loss = 0.01149946
Iteration 2783, loss = 0.01149389
Iteration 2784, loss = 0.01148841
Iteration 2785, loss = 0.01148289
Iteration 2786, loss = 0.01147778
Iteration 2787, loss = 0.01147271
Iteration 2788, loss = 0.01146649
Iteration 2789, loss = 0.01146053
Iteration 2790, loss = 0.01145487
Iteration 2791, loss = 0.01145001
Iteration 2792, loss = 0.01144459
Iteration 2793, loss = 0.01143907
Iteration 2794, loss = 0.01143367
Iteration 2795, loss = 0.01142841
Iteration 2796, loss = 0.01142345
Iteration 2797, loss = 0.01141753
Iteration 2798, loss = 0.01141221
Iteration 2799, loss = 0.01140693
Iteration 2800, loss = 0.01140162
Iteration 2801, loss = 0.01139583
Iteration 2802, loss = 0.01139031
Iteration 2803, loss = 0.01138514
Iteration 2804, loss = 0.01138077
Iteration 2805, loss = 0.01137553
Iteration 2806, loss = 0.01136940
Iteration 2807, loss = 0.01136411
Iteration 2808, loss = 0.01135857
Iteration 2809, loss = 0.01135322
Iteration 2810, loss = 0.01134920
Iteration 2811, loss = 0.01134350
Iteration 2812, loss = 0.01133931
Iteration 2813, loss = 0.01133377
Iteration 2814, loss = 0.01132859
Iteration 2815, loss = 0.01132331
Iteration 2816, loss = 0.01131908
Iteration 2817, loss = 0.01131192
Iteration 2818, loss = 0.01130665
Iteration 2819, loss = 0.01130175
Iteration 2820, loss = 0.01129678
Iteration 2821, loss = 0.01129143
Iteration 2822, loss = 0.01128697
Iteration 2823, loss = 0.01128051
Iteration 2824, loss = 0.01127425
Iteration 2825, loss = 0.01126999
Iteration 2826, loss = 0.01126306
Iteration 2827, loss = 0.01125911
Iteration 2828, loss = 0.01125276
Iteration 2829, loss = 0.01124744
Iteration 2830, loss = 0.01124240
Iteration 2831, loss = 0.01123724
Iteration 2832, loss = 0.01123161
Iteration 2833, loss = 0.01122617
Iteration 2834, loss = 0.01122098
Iteration 2835, loss = 0.01121558
Iteration 2836, loss = 0.01121085
Iteration 2837, loss = 0.01120478
Iteration 2838, loss = 0.01120026
Iteration 2839, loss = 0.01119431
Iteration 2840, loss = 0.01118916
Iteration 2841, loss = 0.01118358
Iteration 2842, loss = 0.01117809
Iteration 2843, loss = 0.01117380
Iteration 2844, loss = 0.01116729
Iteration 2845, loss = 0.01116114
Iteration 2846, loss = 0.01115595
Iteration 2847, loss = 0.01114918
Iteration 2848, loss = 0.01114414
Iteration 2849, loss = 0.01113813
Iteration 2850, loss = 0.01113319
Iteration 2851, loss = 0.01112680
Iteration 2852, loss = 0.01112137
Iteration 2853, loss = 0.01111591
Iteration 2854, loss = 0.01111048
Iteration 2855, loss = 0.01110634
Iteration 2856, loss = 0.01110050
Iteration 2857, loss = 0.01109510
Iteration 2858, loss = 0.01109034
Iteration 2859, loss = 0.01108453
Iteration 2860, loss = 0.01107990
Iteration 2861, loss = 0.01107384
Iteration 2862, loss = 0.01106875
Iteration 2863, loss = 0.01106310
Iteration 2864, loss = 0.01105722
Iteration 2865, loss = 0.01105201
Iteration 2866, loss = 0.01104629
Iteration 2867, loss = 0.01104034
Iteration 2868, loss = 0.01103476
Iteration 2869, loss = 0.01103005
Iteration 2870, loss = 0.01102364
Iteration 2871, loss = 0.01101844
Iteration 2872, loss = 0.01101258
Iteration 2873, loss = 0.01100825
Iteration 2874, loss = 0.01100238
Iteration 2875, loss = 0.01099709
Iteration 2876, loss = 0.01099209
Iteration 2877, loss = 0.01098740
Iteration 2878, loss = 0.01098165
Iteration 2879, loss = 0.01097674
Iteration 2880, loss = 0.01097465
Iteration 2881, loss = 0.01096680
Iteration 2882, loss = 0.01096150
Iteration 2883, loss = 0.01095640
Iteration 2884, loss = 0.01095076
Iteration 2885, loss = 0.01094725
Iteration 2886, loss = 0.01094088
Iteration 2887, loss = 0.01093546
Iteration 2888, loss = 0.01093124
Iteration 2889, loss = 0.01092572
Iteration 2890, loss = 0.01092035
Iteration 2891, loss = 0.01091473
Iteration 2892, loss = 0.01091150
Iteration 2893, loss = 0.01090464
Iteration 2894, loss = 0.01089915
Iteration 2895, loss = 0.01089397
Iteration 2896, loss = 0.01088890
Iteration 2897, loss = 0.01088363
Iteration 2898, loss = 0.01087800
Iteration 2899, loss = 0.01087418
Iteration 2900, loss = 0.01086824
Iteration 2901, loss = 0.01086277
Iteration 2902, loss = 0.01085727
Iteration 2903, loss = 0.01085219
Iteration 2904, loss = 0.01084711
Iteration 2905, loss = 0.01084170
Iteration 2906, loss = 0.01083703
Iteration 2907, loss = 0.01083313
Iteration 2908, loss = 0.01082684
Iteration 2909, loss = 0.01082175
Iteration 2910, loss = 0.01081742
Iteration 2911, loss = 0.01081196
Iteration 2912, loss = 0.01080755
Iteration 2913, loss = 0.01080185
Iteration 2914, loss = 0.01079622
Iteration 2915, loss = 0.01079093
Iteration 2916, loss = 0.01078648
Iteration 2917, loss = 0.01078241
Iteration 2918, loss = 0.01077715
Iteration 2919, loss = 0.01077172
Iteration 2920, loss = 0.01076661
Iteration 2921, loss = 0.01076290
Iteration 2922, loss = 0.01075645
Iteration 2923, loss = 0.01075138
Iteration 2924, loss = 0.01074662
Iteration 2925, loss = 0.01074097
Iteration 2926, loss = 0.01073623
Iteration 2927, loss = 0.01073083
Iteration 2928, loss = 0.01072551
Iteration 2929, loss = 0.01072085
Iteration 2930, loss = 0.01071632
Iteration 2931, loss = 0.01071144
Iteration 2932, loss = 0.01070678
Iteration 2933, loss = 0.01070139
Iteration 2934, loss = 0.01069816
Iteration 2935, loss = 0.01069170
Iteration 2936, loss = 0.01068720
Iteration 2937, loss = 0.01068204
Iteration 2938, loss = 0.01067838
Iteration 2939, loss = 0.01067236
Iteration 2940, loss = 0.01066876
Iteration 2941, loss = 0.01066256
Iteration 2942, loss = 0.01065853
Iteration 2943, loss = 0.01065296
Iteration 2944, loss = 0.01064852
Iteration 2945, loss = 0.01064239
Iteration 2946, loss = 0.01063682
Iteration 2947, loss = 0.01063233
Iteration 2948, loss = 0.01062834
Iteration 2949, loss = 0.01062089
Iteration 2950, loss = 0.01061536
Iteration 2951, loss = 0.01061008
Iteration 2952, loss = 0.01060573
Iteration 2953, loss = 0.01060003
Iteration 2954, loss = 0.01059575
Iteration 2955, loss = 0.01059054
Iteration 2956, loss = 0.01058628
Iteration 2957, loss = 0.01058090
Iteration 2958, loss = 0.01057642
Iteration 2959, loss = 0.01057134
Iteration 2960, loss = 0.01056626
Iteration 2961, loss = 0.01056120
Iteration 2962, loss = 0.01055667
Iteration 2963, loss = 0.01055181
Iteration 2964, loss = 0.01054738
Iteration 2965, loss = 0.01054341
Iteration 2966, loss = 0.01053737
Iteration 2967, loss = 0.01053230
Iteration 2968, loss = 0.01052643
Iteration 2969, loss = 0.01052313
Iteration 2970, loss = 0.01051686
Iteration 2971, loss = 0.01051257
Iteration 2972, loss = 0.01050641
Iteration 2973, loss = 0.01050300
Iteration 2974, loss = 0.01049645
Iteration 2975, loss = 0.01049158
Iteration 2976, loss = 0.01048650
Iteration 2977, loss = 0.01048154
Iteration 2978, loss = 0.01047720
Iteration 2979, loss = 0.01047254
Iteration 2980, loss = 0.01046807
Iteration 2981, loss = 0.01046302
Iteration 2982, loss = 0.01045834
Iteration 2983, loss = 0.01045352
Iteration 2984, loss = 0.01044996
Iteration 2985, loss = 0.01044518
Iteration 2986, loss = 0.01044252
Iteration 2987, loss = 0.01043675
Iteration 2988, loss = 0.01043330
Iteration 2989, loss = 0.01042924
Iteration 2990, loss = 0.01042473
Iteration 2991, loss = 0.01042106
Iteration 2992, loss = 0.01041678
Iteration 2993, loss = 0.01041352
Iteration 2994, loss = 0.01040829
Iteration 2995, loss = 0.01040438
Iteration 2996, loss = 0.01040004
Iteration 2997, loss = 0.01039538
Iteration 2998, loss = 0.01039140
Iteration 2999, loss = 0.01038716
Iteration 3000, loss = 0.01038282
Iteration 3001, loss = 0.01037814
Iteration 3002, loss = 0.01037366
Iteration 3003, loss = 0.01036890
Iteration 3004, loss = 0.01036414
Iteration 3005, loss = 0.01036052
Iteration 3006, loss = 0.01035507
Iteration 3007, loss = 0.01035138
Iteration 3008, loss = 0.01034629
Iteration 3009, loss = 0.01034167
Iteration 3010, loss = 0.01033764
Iteration 3011, loss = 0.01033251
Iteration 3012, loss = 0.01032806
Iteration 3013, loss = 0.01032330
Iteration 3014, loss = 0.01031795
Iteration 3015, loss = 0.01031371
Iteration 3016, loss = 0.01030922
Iteration 3017, loss = 0.01030374
Iteration 3018, loss = 0.01029866
Iteration 3019, loss = 0.01029310
Iteration 3020, loss = 0.01028817
Iteration 3021, loss = 0.01028511
Iteration 3022, loss = 0.01027862
Iteration 3023, loss = 0.01027350
Iteration 3024, loss = 0.01026860
Iteration 3025, loss = 0.01026398
Iteration 3026, loss = 0.01026025
Iteration 3027, loss = 0.01025593
Iteration 3028, loss = 0.01025181
Iteration 3029, loss = 0.01024738
Iteration 3030, loss = 0.01024239
Iteration 3031, loss = 0.01023799
Iteration 3032, loss = 0.01023319
Iteration 3033, loss = 0.01022839
Iteration 3034, loss = 0.01022429
Iteration 3035, loss = 0.01021957
Iteration 3036, loss = 0.01021495
Iteration 3037, loss = 0.01021076
Iteration 3038, loss = 0.01020597
Iteration 3039, loss = 0.01020096
Iteration 3040, loss = 0.01019734
Iteration 3041, loss = 0.01019265
Iteration 3042, loss = 0.01018809
Iteration 3043, loss = 0.01018366
Iteration 3044, loss = 0.01017986
Iteration 3045, loss = 0.01017589
Iteration 3046, loss = 0.01017154
Iteration 3047, loss = 0.01016593
Iteration 3048, loss = 0.01016135
Iteration 3049, loss = 0.01015733
Iteration 3050, loss = 0.01015358
Iteration 3051, loss = 0.01014730
Iteration 3052, loss = 0.01014239
Iteration 3053, loss = 0.01013716
Iteration 3054, loss = 0.01013438
Iteration 3055, loss = 0.01012909
Iteration 3056, loss = 0.01012370
Iteration 3057, loss = 0.01012017
Iteration 3058, loss = 0.01011491
Iteration 3059, loss = 0.01011071
Iteration 3060, loss = 0.01010656
Iteration 3061, loss = 0.01010276
Iteration 3062, loss = 0.01009740
Iteration 3063, loss = 0.01009326
Iteration 3064, loss = 0.01008914
Iteration 3065, loss = 0.01008582
Iteration 3066, loss = 0.01008028
Iteration 3067, loss = 0.01007529
Iteration 3068, loss = 0.01007037
Iteration 3069, loss = 0.01006790
Iteration 3070, loss = 0.01006314
Iteration 3071, loss = 0.01005750
Iteration 3072, loss = 0.01005318
Iteration 3073, loss = 0.01004847
Iteration 3074, loss = 0.01004434
Iteration 3075, loss = 0.01003994
Iteration 3076, loss = 0.01003529
Iteration 3077, loss = 0.01003041
Iteration 3078, loss = 0.01002605
Iteration 3079, loss = 0.01002182
Iteration 3080, loss = 0.01001739
Iteration 3081, loss = 0.01001299
Iteration 3082, loss = 0.01000896
Iteration 3083, loss = 0.01000469
Iteration 3084, loss = 0.01000060
Iteration 3085, loss = 0.00999664
Iteration 3086, loss = 0.00999211
Iteration 3087, loss = 0.00998813
Iteration 3088, loss = 0.00998427
Iteration 3089, loss = 0.00998045
Iteration 3090, loss = 0.00997627
Iteration 3091, loss = 0.00997337
Iteration 3092, loss = 0.00996859
Iteration 3093, loss = 0.00996478
Iteration 3094, loss = 0.00996072
Iteration 3095, loss = 0.00995850
Iteration 3096, loss = 0.00995395
Iteration 3097, loss = 0.00994861
Iteration 3098, loss = 0.00994430
Iteration 3099, loss = 0.00993949
Iteration 3100, loss = 0.00993549
Iteration 3101, loss = 0.00993170
Iteration 3102, loss = 0.00992809
Iteration 3103, loss = 0.00992408
Iteration 3104, loss = 0.00992005
Iteration 3105, loss = 0.00991547
Iteration 3106, loss = 0.00991166
Iteration 3107, loss = 0.00990724
Iteration 3108, loss = 0.00990346
Iteration 3109, loss = 0.00989900
Iteration 3110, loss = 0.00989463
Iteration 3111, loss = 0.00989076
Iteration 3112, loss = 0.00988646
Iteration 3113, loss = 0.00988224
Iteration 3114, loss = 0.00987831
Iteration 3115, loss = 0.00987440
Iteration 3116, loss = 0.00987060
Iteration 3117, loss = 0.00986659
Iteration 3118, loss = 0.00986232
Iteration 3119, loss = 0.00985815
Iteration 3120, loss = 0.00985388
Iteration 3121, loss = 0.00985039
Iteration 3122, loss = 0.00984597
Iteration 3123, loss = 0.00984181
Iteration 3124, loss = 0.00983831
Iteration 3125, loss = 0.00983319
Iteration 3126, loss = 0.00982864
Iteration 3127, loss = 0.00982428
Iteration 3128, loss = 0.00982129
Iteration 3129, loss = 0.00981587
Iteration 3130, loss = 0.00981147
Iteration 3131, loss = 0.00980687
Iteration 3132, loss = 0.00980194
Iteration 3133, loss = 0.00979914
Iteration 3134, loss = 0.00979353
Iteration 3135, loss = 0.00978994
Iteration 3136, loss = 0.00978501
Iteration 3137, loss = 0.00978094
Iteration 3138, loss = 0.00977704
Iteration 3139, loss = 0.00977285
Iteration 3140, loss = 0.00976848
Iteration 3141, loss = 0.00976594
Iteration 3142, loss = 0.00976127
Iteration 3143, loss = 0.00975651
Iteration 3144, loss = 0.00975285
Iteration 3145, loss = 0.00974893
Iteration 3146, loss = 0.00974635
Iteration 3147, loss = 0.00974356
Iteration 3148, loss = 0.00973839
Iteration 3149, loss = 0.00973383
Iteration 3150, loss = 0.00973051
Iteration 3151, loss = 0.00972607
Iteration 3152, loss = 0.00972220
Iteration 3153, loss = 0.00971845
Iteration 3154, loss = 0.00971492
Iteration 3155, loss = 0.00971080
Iteration 3156, loss = 0.00970780
Iteration 3157, loss = 0.00970317
Iteration 3158, loss = 0.00969796
Iteration 3159, loss = 0.00969406
Iteration 3160, loss = 0.00968944
Iteration 3161, loss = 0.00968513
Iteration 3162, loss = 0.00968075
Iteration 3163, loss = 0.00967701
Iteration 3164, loss = 0.00967276
Iteration 3165, loss = 0.00966957
Iteration 3166, loss = 0.00966517
Iteration 3167, loss = 0.00966179
Iteration 3168, loss = 0.00965763
Iteration 3169, loss = 0.00965132
Iteration 3170, loss = 0.00964755
Iteration 3171, loss = 0.00964335
Iteration 3172, loss = 0.00963907
Iteration 3173, loss = 0.00963477
Iteration 3174, loss = 0.00963065
Iteration 3175, loss = 0.00962666
Iteration 3176, loss = 0.00962297
Iteration 3177, loss = 0.00961904
Iteration 3178, loss = 0.00961563
Iteration 3179, loss = 0.00961238
Iteration 3180, loss = 0.00960839
Iteration 3181, loss = 0.00960473
Iteration 3182, loss = 0.00960090
Iteration 3183, loss = 0.00959709
Iteration 3184, loss = 0.00959380
Iteration 3185, loss = 0.00958953
Iteration 3186, loss = 0.00958550
Iteration 3187, loss = 0.00958168
Iteration 3188, loss = 0.00957794
Iteration 3189, loss = 0.00957538
Iteration 3190, loss = 0.00957062
Iteration 3191, loss = 0.00956654
Iteration 3192, loss = 0.00956211
Iteration 3193, loss = 0.00955842
Iteration 3194, loss = 0.00955434
Iteration 3195, loss = 0.00955071
Iteration 3196, loss = 0.00954622
Iteration 3197, loss = 0.00954222
Iteration 3198, loss = 0.00953792
Iteration 3199, loss = 0.00953416
Iteration 3200, loss = 0.00952962
Iteration 3201, loss = 0.00952594
Iteration 3202, loss = 0.00952177
Iteration 3203, loss = 0.00951854
Iteration 3204, loss = 0.00951528
Iteration 3205, loss = 0.00950981
Iteration 3206, loss = 0.00950521
Iteration 3207, loss = 0.00950178
Iteration 3208, loss = 0.00949730
Iteration 3209, loss = 0.00949313
Iteration 3210, loss = 0.00948949
Iteration 3211, loss = 0.00948552
Iteration 3212, loss = 0.00948133
Iteration 3213, loss = 0.00947804
Iteration 3214, loss = 0.00947342
Iteration 3215, loss = 0.00946990
Iteration 3216, loss = 0.00946642
Iteration 3217, loss = 0.00946134
Iteration 3218, loss = 0.00945746
Iteration 3219, loss = 0.00945363
Iteration 3220, loss = 0.00944893
Iteration 3221, loss = 0.00944543
Iteration 3222, loss = 0.00944168
Iteration 3223, loss = 0.00943752
Iteration 3224, loss = 0.00943406
Iteration 3225, loss = 0.00943005
Iteration 3226, loss = 0.00942652
Iteration 3227, loss = 0.00942289
Iteration 3228, loss = 0.00941914
Iteration 3229, loss = 0.00941634
Iteration 3230, loss = 0.00941223
Iteration 3231, loss = 0.00940877
Iteration 3232, loss = 0.00940462
Iteration 3233, loss = 0.00940090
Iteration 3234, loss = 0.00939656
Iteration 3235, loss = 0.00939319
Iteration 3236, loss = 0.00938885
Iteration 3237, loss = 0.00938562
Iteration 3238, loss = 0.00938169
Iteration 3239, loss = 0.00937787
Iteration 3240, loss = 0.00937470
Iteration 3241, loss = 0.00937110
Iteration 3242, loss = 0.00936755
Iteration 3243, loss = 0.00936509
Iteration 3244, loss = 0.00936031
Iteration 3245, loss = 0.00935632
Iteration 3246, loss = 0.00935159
Iteration 3247, loss = 0.00934723
Iteration 3248, loss = 0.00934348
Iteration 3249, loss = 0.00934023
Iteration 3250, loss = 0.00933481
Iteration 3251, loss = 0.00933162
Iteration 3252, loss = 0.00932611
Iteration 3253, loss = 0.00932169
Iteration 3254, loss = 0.00931738
Iteration 3255, loss = 0.00931551
Iteration 3256, loss = 0.00930983
Iteration 3257, loss = 0.00930558
Iteration 3258, loss = 0.00930129
Iteration 3259, loss = 0.00929787
Iteration 3260, loss = 0.00929432
Iteration 3261, loss = 0.00929043
Iteration 3262, loss = 0.00928636
Iteration 3263, loss = 0.00928229
Iteration 3264, loss = 0.00927845
Iteration 3265, loss = 0.00927465
Iteration 3266, loss = 0.00927054
Iteration 3267, loss = 0.00926668
Iteration 3268, loss = 0.00926278
Iteration 3269, loss = 0.00925878
Iteration 3270, loss = 0.00925552
Iteration 3271, loss = 0.00925211
Iteration 3272, loss = 0.00924861
Iteration 3273, loss = 0.00924463
Iteration 3274, loss = 0.00924009
Iteration 3275, loss = 0.00923607
Iteration 3276, loss = 0.00923235
Iteration 3277, loss = 0.00922851
Iteration 3278, loss = 0.00922544
Iteration 3279, loss = 0.00922132
Iteration 3280, loss = 0.00921762
Iteration 3281, loss = 0.00921396
Iteration 3282, loss = 0.00920955
Iteration 3283, loss = 0.00920560
Iteration 3284, loss = 0.00920200
Iteration 3285, loss = 0.00919770
Iteration 3286, loss = 0.00919388
Iteration 3287, loss = 0.00919028
Iteration 3288, loss = 0.00918613
Iteration 3289, loss = 0.00918238
Iteration 3290, loss = 0.00917869
Iteration 3291, loss = 0.00917554
Iteration 3292, loss = 0.00917284
Iteration 3293, loss = 0.00916837
Iteration 3294, loss = 0.00916489
Iteration 3295, loss = 0.00916188
Iteration 3296, loss = 0.00915760
Iteration 3297, loss = 0.00915401
Iteration 3298, loss = 0.00915074
Iteration 3299, loss = 0.00914734
Iteration 3300, loss = 0.00914254
Iteration 3301, loss = 0.00913886
Iteration 3302, loss = 0.00913546
Iteration 3303, loss = 0.00913085
Iteration 3304, loss = 0.00912746
Iteration 3305, loss = 0.00912554
Iteration 3306, loss = 0.00911952
Iteration 3307, loss = 0.00911545
Iteration 3308, loss = 0.00911143
Iteration 3309, loss = 0.00910837
Iteration 3310, loss = 0.00910364
Iteration 3311, loss = 0.00910018
Iteration 3312, loss = 0.00909711
Iteration 3313, loss = 0.00909281
Iteration 3314, loss = 0.00908880
Iteration 3315, loss = 0.00908502
Iteration 3316, loss = 0.00908134
Iteration 3317, loss = 0.00907740
Iteration 3318, loss = 0.00907351
Iteration 3319, loss = 0.00906987
Iteration 3320, loss = 0.00906575
Iteration 3321, loss = 0.00906239
Iteration 3322, loss = 0.00905961
Iteration 3323, loss = 0.00905535
Iteration 3324, loss = 0.00905117
Iteration 3325, loss = 0.00904764
Iteration 3326, loss = 0.00904432
Iteration 3327, loss = 0.00903991
Iteration 3328, loss = 0.00903644
Iteration 3329, loss = 0.00903233
Iteration 3330, loss = 0.00902792
Iteration 3331, loss = 0.00902480
Iteration 3332, loss = 0.00902037
Iteration 3333, loss = 0.00901650
Iteration 3334, loss = 0.00901232
Iteration 3335, loss = 0.00900890
Iteration 3336, loss = 0.00900452
Iteration 3337, loss = 0.00900139
Iteration 3338, loss = 0.00899658
Iteration 3339, loss = 0.00899340
Iteration 3340, loss = 0.00898866
Iteration 3341, loss = 0.00898447
Iteration 3342, loss = 0.00898199
Iteration 3343, loss = 0.00897720
Iteration 3344, loss = 0.00897336
Iteration 3345, loss = 0.00896936
Iteration 3346, loss = 0.00896558
Iteration 3347, loss = 0.00896164
Iteration 3348, loss = 0.00895807
Iteration 3349, loss = 0.00895395
Iteration 3350, loss = 0.00895106
Iteration 3351, loss = 0.00894689
Iteration 3352, loss = 0.00894288
Iteration 3353, loss = 0.00893947
Iteration 3354, loss = 0.00893612
Iteration 3355, loss = 0.00893185
Iteration 3356, loss = 0.00892738
Iteration 3357, loss = 0.00892476
Iteration 3358, loss = 0.00892051
Iteration 3359, loss = 0.00891653
Iteration 3360, loss = 0.00891354
Iteration 3361, loss = 0.00890962
Iteration 3362, loss = 0.00890663
Iteration 3363, loss = 0.00890197
Iteration 3364, loss = 0.00889840
Iteration 3365, loss = 0.00889405
Iteration 3366, loss = 0.00889243
Iteration 3367, loss = 0.00888898
Iteration 3368, loss = 0.00888435
Iteration 3369, loss = 0.00888139
Iteration 3370, loss = 0.00887703
Iteration 3371, loss = 0.00887351
Iteration 3372, loss = 0.00887001
Iteration 3373, loss = 0.00886623
Iteration 3374, loss = 0.00886256
Iteration 3375, loss = 0.00885900
Iteration 3376, loss = 0.00885517
Iteration 3377, loss = 0.00885057
Iteration 3378, loss = 0.00884754
Iteration 3379, loss = 0.00884330
Iteration 3380, loss = 0.00883927
Iteration 3381, loss = 0.00883565
Iteration 3382, loss = 0.00883355
Iteration 3383, loss = 0.00882840
Iteration 3384, loss = 0.00882438
Iteration 3385, loss = 0.00882002
Iteration 3386, loss = 0.00881671
Iteration 3387, loss = 0.00881293
Iteration 3388, loss = 0.00880904
Iteration 3389, loss = 0.00880532
Iteration 3390, loss = 0.00880069
Iteration 3391, loss = 0.00879694
Iteration 3392, loss = 0.00879337
Iteration 3393, loss = 0.00878985
Iteration 3394, loss = 0.00878554
Iteration 3395, loss = 0.00878354
Iteration 3396, loss = 0.00878020
Iteration 3397, loss = 0.00877636
Iteration 3398, loss = 0.00877297
Iteration 3399, loss = 0.00877024
Iteration 3400, loss = 0.00876659
Iteration 3401, loss = 0.00876302
Iteration 3402, loss = 0.00875918
Iteration 3403, loss = 0.00875580
Iteration 3404, loss = 0.00875317
Iteration 3405, loss = 0.00874900
Iteration 3406, loss = 0.00874506
Iteration 3407, loss = 0.00874148
Iteration 3408, loss = 0.00873784
Iteration 3409, loss = 0.00873374
Iteration 3410, loss = 0.00873032
Iteration 3411, loss = 0.00872647
Iteration 3412, loss = 0.00872272
Iteration 3413, loss = 0.00871917
Iteration 3414, loss = 0.00871658
Iteration 3415, loss = 0.00871272
Iteration 3416, loss = 0.00870953
Iteration 3417, loss = 0.00870635
Iteration 3418, loss = 0.00870251
Iteration 3419, loss = 0.00869900
Iteration 3420, loss = 0.00869548
Iteration 3421, loss = 0.00869249
Iteration 3422, loss = 0.00868892
Iteration 3423, loss = 0.00868533
Iteration 3424, loss = 0.00868201
Iteration 3425, loss = 0.00867859
Iteration 3426, loss = 0.00867556
Iteration 3427, loss = 0.00867213
Iteration 3428, loss = 0.00866805
Iteration 3429, loss = 0.00866611
Iteration 3430, loss = 0.00866097
Iteration 3431, loss = 0.00865696
Iteration 3432, loss = 0.00865351
Iteration 3433, loss = 0.00865007
Iteration 3434, loss = 0.00864652
Iteration 3435, loss = 0.00864283
Iteration 3436, loss = 0.00863935
Iteration 3437, loss = 0.00863608
Iteration 3438, loss = 0.00863223
Iteration 3439, loss = 0.00862872
Iteration 3440, loss = 0.00862525
Iteration 3441, loss = 0.00862207
Iteration 3442, loss = 0.00861865
Iteration 3443, loss = 0.00861537
Iteration 3444, loss = 0.00861228
Iteration 3445, loss = 0.00860907
Iteration 3446, loss = 0.00860561
Iteration 3447, loss = 0.00860225
Iteration 3448, loss = 0.00859928
Iteration 3449, loss = 0.00859596
Iteration 3450, loss = 0.00859260
Iteration 3451, loss = 0.00859059
Iteration 3452, loss = 0.00858637
Iteration 3453, loss = 0.00858273
Iteration 3454, loss = 0.00858000
Iteration 3455, loss = 0.00857634
Iteration 3456, loss = 0.00857459
Iteration 3457, loss = 0.00857014
Iteration 3458, loss = 0.00856715
Iteration 3459, loss = 0.00856349
Iteration 3460, loss = 0.00856033
Iteration 3461, loss = 0.00855713
Iteration 3462, loss = 0.00855418
Iteration 3463, loss = 0.00855059
Iteration 3464, loss = 0.00854753
Iteration 3465, loss = 0.00854424
Iteration 3466, loss = 0.00854044
Iteration 3467, loss = 0.00853674
Iteration 3468, loss = 0.00853336
Iteration 3469, loss = 0.00853011
Iteration 3470, loss = 0.00852646
Iteration 3471, loss = 0.00852329
Iteration 3472, loss = 0.00851945
Iteration 3473, loss = 0.00851646
Iteration 3474, loss = 0.00851258
Iteration 3475, loss = 0.00850930
Iteration 3476, loss = 0.00850527
Iteration 3477, loss = 0.00850185
Iteration 3478, loss = 0.00849877
Iteration 3479, loss = 0.00849484
Iteration 3480, loss = 0.00849200
Iteration 3481, loss = 0.00848800
Iteration 3482, loss = 0.00848594
Iteration 3483, loss = 0.00848180
Iteration 3484, loss = 0.00847992
Iteration 3485, loss = 0.00847659
Iteration 3486, loss = 0.00847321
Iteration 3487, loss = 0.00846965
Iteration 3488, loss = 0.00846603
Iteration 3489, loss = 0.00846347
Iteration 3490, loss = 0.00845929
Iteration 3491, loss = 0.00845572
Iteration 3492, loss = 0.00845288
Iteration 3493, loss = 0.00844926
Iteration 3494, loss = 0.00844587
Iteration 3495, loss = 0.00844290
Iteration 3496, loss = 0.00843965
Iteration 3497, loss = 0.00843615
Iteration 3498, loss = 0.00843290
Iteration 3499, loss = 0.00842946
Iteration 3500, loss = 0.00842617
Iteration 3501, loss = 0.00842264
Iteration 3502, loss = 0.00841961
Iteration 3503, loss = 0.00841580
Iteration 3504, loss = 0.00841244
Iteration 3505, loss = 0.00840888
Iteration 3506, loss = 0.00840534
Iteration 3507, loss = 0.00840387
Iteration 3508, loss = 0.00839932
Iteration 3509, loss = 0.00839617
Iteration 3510, loss = 0.00839232
Iteration 3511, loss = 0.00838889
Iteration 3512, loss = 0.00838622
Iteration 3513, loss = 0.00838218
Iteration 3514, loss = 0.00837978
Iteration 3515, loss = 0.00837577
Iteration 3516, loss = 0.00837241
Iteration 3517, loss = 0.00837007
Iteration 3518, loss = 0.00836611
Iteration 3519, loss = 0.00836281
Iteration 3520, loss = 0.00835909
Iteration 3521, loss = 0.00835569
Iteration 3522, loss = 0.00835302
Iteration 3523, loss = 0.00834899
Iteration 3524, loss = 0.00834577
Iteration 3525, loss = 0.00834224
Iteration 3526, loss = 0.00834026
Iteration 3527, loss = 0.00833538
Iteration 3528, loss = 0.00833186
Iteration 3529, loss = 0.00832836
Iteration 3530, loss = 0.00832468
Iteration 3531, loss = 0.00832155
Iteration 3532, loss = 0.00831762
Iteration 3533, loss = 0.00831426
Iteration 3534, loss = 0.00831063
Iteration 3535, loss = 0.00830718
Iteration 3536, loss = 0.00830390
Iteration 3537, loss = 0.00830079
Iteration 3538, loss = 0.00829736
Iteration 3539, loss = 0.00829427
Iteration 3540, loss = 0.00829142
Iteration 3541, loss = 0.00828815
Iteration 3542, loss = 0.00828488
Iteration 3543, loss = 0.00828182
Iteration 3544, loss = 0.00827858
Iteration 3545, loss = 0.00827603
Iteration 3546, loss = 0.00827272
Iteration 3547, loss = 0.00826989
Iteration 3548, loss = 0.00826718
Iteration 3549, loss = 0.00826291
Iteration 3550, loss = 0.00826007
Iteration 3551, loss = 0.00825633
Iteration 3552, loss = 0.00825461
Iteration 3553, loss = 0.00825028
Iteration 3554, loss = 0.00824713
Iteration 3555, loss = 0.00824399
Iteration 3556, loss = 0.00824025
Iteration 3557, loss = 0.00823680
Iteration 3558, loss = 0.00823366
Iteration 3559, loss = 0.00823029
Iteration 3560, loss = 0.00822740
Iteration 3561, loss = 0.00822472
Iteration 3562, loss = 0.00822120
Iteration 3563, loss = 0.00821834
Iteration 3564, loss = 0.00821545
Iteration 3565, loss = 0.00821254
Iteration 3566, loss = 0.00821043
Iteration 3567, loss = 0.00820747
Iteration 3568, loss = 0.00820431
Iteration 3569, loss = 0.00820087
Iteration 3570, loss = 0.00819770
Iteration 3571, loss = 0.00819492
Iteration 3572, loss = 0.00819153
Iteration 3573, loss = 0.00818972
Iteration 3574, loss = 0.00818466
Iteration 3575, loss = 0.00818177
Iteration 3576, loss = 0.00817925
Iteration 3577, loss = 0.00817411
Iteration 3578, loss = 0.00817097
Iteration 3579, loss = 0.00816744
Iteration 3580, loss = 0.00816510
Iteration 3581, loss = 0.00816183
Iteration 3582, loss = 0.00815834
Iteration 3583, loss = 0.00815595
Iteration 3584, loss = 0.00815222
Iteration 3585, loss = 0.00814913
Iteration 3586, loss = 0.00814578
Iteration 3587, loss = 0.00814279
Iteration 3588, loss = 0.00813995
Iteration 3589, loss = 0.00813672
Iteration 3590, loss = 0.00813353
Iteration 3591, loss = 0.00813043
Iteration 3592, loss = 0.00812754
Iteration 3593, loss = 0.00812496
Iteration 3594, loss = 0.00812221
Iteration 3595, loss = 0.00811926
Iteration 3596, loss = 0.00811539
Iteration 3597, loss = 0.00811194
Iteration 3598, loss = 0.00810830
Iteration 3599, loss = 0.00810528
Iteration 3600, loss = 0.00810141
Iteration 3601, loss = 0.00809823
Iteration 3602, loss = 0.00809543
Iteration 3603, loss = 0.00809167
Iteration 3604, loss = 0.00808969
Iteration 3605, loss = 0.00808592
Iteration 3606, loss = 0.00808239
Iteration 3607, loss = 0.00808043
Iteration 3608, loss = 0.00807684
Iteration 3609, loss = 0.00807358
Iteration 3610, loss = 0.00807057
Iteration 3611, loss = 0.00806746
Iteration 3612, loss = 0.00806492
Iteration 3613, loss = 0.00806190
Iteration 3614, loss = 0.00805922
Iteration 3615, loss = 0.00805656
Iteration 3616, loss = 0.00805385
Iteration 3617, loss = 0.00805088
Iteration 3618, loss = 0.00804870
Iteration 3619, loss = 0.00804496
Iteration 3620, loss = 0.00804191
Iteration 3621, loss = 0.00803858
Iteration 3622, loss = 0.00803651
Iteration 3623, loss = 0.00803270
Iteration 3624, loss = 0.00802985
Iteration 3625, loss = 0.00802645
Iteration 3626, loss = 0.00802375
Iteration 3627, loss = 0.00802117
Iteration 3628, loss = 0.00801795
Iteration 3629, loss = 0.00801492
Iteration 3630, loss = 0.00801190
Iteration 3631, loss = 0.00800939
Iteration 3632, loss = 0.00800638
Iteration 3633, loss = 0.00800387
Iteration 3634, loss = 0.00800091
Iteration 3635, loss = 0.00799847
Iteration 3636, loss = 0.00799600
Iteration 3637, loss = 0.00799337
Iteration 3638, loss = 0.00799050
Iteration 3639, loss = 0.00798796
Iteration 3640, loss = 0.00798522
Iteration 3641, loss = 0.00798245
Iteration 3642, loss = 0.00798000
Iteration 3643, loss = 0.00797742
Iteration 3644, loss = 0.00797364
Iteration 3645, loss = 0.00797082
Iteration 3646, loss = 0.00796763
Iteration 3647, loss = 0.00796460
Iteration 3648, loss = 0.00796184
Iteration 3649, loss = 0.00795888
Iteration 3650, loss = 0.00795585
Iteration 3651, loss = 0.00795336
Iteration 3652, loss = 0.00795007
Iteration 3653, loss = 0.00794672
Iteration 3654, loss = 0.00794400
Iteration 3655, loss = 0.00794074
Iteration 3656, loss = 0.00793791
Iteration 3657, loss = 0.00793499
Iteration 3658, loss = 0.00793185
Iteration 3659, loss = 0.00792945
Iteration 3660, loss = 0.00792579
Iteration 3661, loss = 0.00792291
Iteration 3662, loss = 0.00791943
Iteration 3663, loss = 0.00791684
Iteration 3664, loss = 0.00791339
Iteration 3665, loss = 0.00791053
Iteration 3666, loss = 0.00790810
Iteration 3667, loss = 0.00790469
Iteration 3668, loss = 0.00790329
Iteration 3669, loss = 0.00789959
Iteration 3670, loss = 0.00789688
Iteration 3671, loss = 0.00789402
Iteration 3672, loss = 0.00789107
Iteration 3673, loss = 0.00788851
Iteration 3674, loss = 0.00788568
Iteration 3675, loss = 0.00788301
Iteration 3676, loss = 0.00787987
Iteration 3677, loss = 0.00787696
Iteration 3678, loss = 0.00787416
Iteration 3679, loss = 0.00787164
Iteration 3680, loss = 0.00786949
Iteration 3681, loss = 0.00786618
Iteration 3682, loss = 0.00786364
Iteration 3683, loss = 0.00786059
Iteration 3684, loss = 0.00785761
Iteration 3685, loss = 0.00785475
Iteration 3686, loss = 0.00785135
Iteration 3687, loss = 0.00784861
Iteration 3688, loss = 0.00784535
Iteration 3689, loss = 0.00784286
Iteration 3690, loss = 0.00783969
Iteration 3691, loss = 0.00783674
Iteration 3692, loss = 0.00783402
Iteration 3693, loss = 0.00783175
Iteration 3694, loss = 0.00782893
Iteration 3695, loss = 0.00782704
Iteration 3696, loss = 0.00782339
Iteration 3697, loss = 0.00782050
Iteration 3698, loss = 0.00781786
Iteration 3699, loss = 0.00781477
Iteration 3700, loss = 0.00781194
Iteration 3701, loss = 0.00780891
Iteration 3702, loss = 0.00780645
Iteration 3703, loss = 0.00780329
Iteration 3704, loss = 0.00780045
Iteration 3705, loss = 0.00779673
Iteration 3706, loss = 0.00779392
Iteration 3707, loss = 0.00779051
Iteration 3708, loss = 0.00778817
Iteration 3709, loss = 0.00778465
Iteration 3710, loss = 0.00778174
Iteration 3711, loss = 0.00777887
Iteration 3712, loss = 0.00777583
Iteration 3713, loss = 0.00777302
Iteration 3714, loss = 0.00777047
Iteration 3715, loss = 0.00776760
Iteration 3716, loss = 0.00776472
Iteration 3717, loss = 0.00776216
Iteration 3718, loss = 0.00775897
Iteration 3719, loss = 0.00775639
Iteration 3720, loss = 0.00775333
Iteration 3721, loss = 0.00775060
Iteration 3722, loss = 0.00774753
Iteration 3723, loss = 0.00774493
Iteration 3724, loss = 0.00774130
Iteration 3725, loss = 0.00773846
Iteration 3726, loss = 0.00773524
Iteration 3727, loss = 0.00773261
Iteration 3728, loss = 0.00772995
Iteration 3729, loss = 0.00772708
Iteration 3730, loss = 0.00772422
Iteration 3731, loss = 0.00772092
Iteration 3732, loss = 0.00771823
Iteration 3733, loss = 0.00771488
Iteration 3734, loss = 0.00771213
Iteration 3735, loss = 0.00770930
Iteration 3736, loss = 0.00770571
Iteration 3737, loss = 0.00770264
Iteration 3738, loss = 0.00769923
Iteration 3739, loss = 0.00769588
Iteration 3740, loss = 0.00769251
Iteration 3741, loss = 0.00769008
Iteration 3742, loss = 0.00768647
Iteration 3743, loss = 0.00768391
Iteration 3744, loss = 0.00768096
Iteration 3745, loss = 0.00767743
Iteration 3746, loss = 0.00767522
Iteration 3747, loss = 0.00767186
Iteration 3748, loss = 0.00766923
Iteration 3749, loss = 0.00766669
Iteration 3750, loss = 0.00766395
Iteration 3751, loss = 0.00766124
Iteration 3752, loss = 0.00765867
Iteration 3753, loss = 0.00765737
Iteration 3754, loss = 0.00765345
Iteration 3755, loss = 0.00765020
Iteration 3756, loss = 0.00764752
Iteration 3757, loss = 0.00764432
Iteration 3758, loss = 0.00764165
Iteration 3759, loss = 0.00763877
Iteration 3760, loss = 0.00763581
Iteration 3761, loss = 0.00763271
Iteration 3762, loss = 0.00763048
Iteration 3763, loss = 0.00762718
Iteration 3764, loss = 0.00762418
Iteration 3765, loss = 0.00762166
Iteration 3766, loss = 0.00761910
Iteration 3767, loss = 0.00761629
Iteration 3768, loss = 0.00761365
Iteration 3769, loss = 0.00761121
Iteration 3770, loss = 0.00760872
Iteration 3771, loss = 0.00760612
Iteration 3772, loss = 0.00760334
Iteration 3773, loss = 0.00760098
Iteration 3774, loss = 0.00759780
Iteration 3775, loss = 0.00759522
Iteration 3776, loss = 0.00759283
Iteration 3777, loss = 0.00759027
Iteration 3778, loss = 0.00758725
Iteration 3779, loss = 0.00758444
Iteration 3780, loss = 0.00758201
Iteration 3781, loss = 0.00757909
Iteration 3782, loss = 0.00757664
Iteration 3783, loss = 0.00757403
Iteration 3784, loss = 0.00757135
Iteration 3785, loss = 0.00756914
Iteration 3786, loss = 0.00756589
Iteration 3787, loss = 0.00756343
Iteration 3788, loss = 0.00756083
Iteration 3789, loss = 0.00755791
Iteration 3790, loss = 0.00755532
Iteration 3791, loss = 0.00755263
Iteration 3792, loss = 0.00755002
Iteration 3793, loss = 0.00754752
Iteration 3794, loss = 0.00754528
Iteration 3795, loss = 0.00754247
Iteration 3796, loss = 0.00754005
Iteration 3797, loss = 0.00753756
Iteration 3798, loss = 0.00753527
Iteration 3799, loss = 0.00753285
Iteration 3800, loss = 0.00753042
Iteration 3801, loss = 0.00752773
Iteration 3802, loss = 0.00752519
Iteration 3803, loss = 0.00752261
Iteration 3804, loss = 0.00752048
Iteration 3805, loss = 0.00751747
Iteration 3806, loss = 0.00751457
Iteration 3807, loss = 0.00751258
Iteration 3808, loss = 0.00751044
Iteration 3809, loss = 0.00750697
Iteration 3810, loss = 0.00750493
Iteration 3811, loss = 0.00750164
Iteration 3812, loss = 0.00749896
Iteration 3813, loss = 0.00749745
Iteration 3814, loss = 0.00749401
Iteration 3815, loss = 0.00749141
Iteration 3816, loss = 0.00748864
Iteration 3817, loss = 0.00748621
Iteration 3818, loss = 0.00748372
Iteration 3819, loss = 0.00748104
Iteration 3820, loss = 0.00747829
Iteration 3821, loss = 0.00747559
Iteration 3822, loss = 0.00747267
Iteration 3823, loss = 0.00747037
Iteration 3824, loss = 0.00746773
Iteration 3825, loss = 0.00746504
Iteration 3826, loss = 0.00746206
Iteration 3827, loss = 0.00745979
Iteration 3828, loss = 0.00745689
Iteration 3829, loss = 0.00745413
Iteration 3830, loss = 0.00745161
Iteration 3831, loss = 0.00744920
Iteration 3832, loss = 0.00744684
Iteration 3833, loss = 0.00744403
Iteration 3834, loss = 0.00744156
Iteration 3835, loss = 0.00743881
Iteration 3836, loss = 0.00743624
Iteration 3837, loss = 0.00743366
Iteration 3838, loss = 0.00743122
Iteration 3839, loss = 0.00742836
Iteration 3840, loss = 0.00742570
Iteration 3841, loss = 0.00742318
Iteration 3842, loss = 0.00742053
Iteration 3843, loss = 0.00741766
Iteration 3844, loss = 0.00741545
Iteration 3845, loss = 0.00741215
Iteration 3846, loss = 0.00740924
Iteration 3847, loss = 0.00740662
Iteration 3848, loss = 0.00740423
Iteration 3849, loss = 0.00740113
Iteration 3850, loss = 0.00739862
Iteration 3851, loss = 0.00739619
Iteration 3852, loss = 0.00739378
Iteration 3853, loss = 0.00739162
Iteration 3854, loss = 0.00738909
Iteration 3855, loss = 0.00738655
Iteration 3856, loss = 0.00738343
Iteration 3857, loss = 0.00738131
Iteration 3858, loss = 0.00737960
Iteration 3859, loss = 0.00737577
Iteration 3860, loss = 0.00737321
Iteration 3861, loss = 0.00737078
Iteration 3862, loss = 0.00736816
Iteration 3863, loss = 0.00736529
Iteration 3864, loss = 0.00736235
Iteration 3865, loss = 0.00736132
Iteration 3866, loss = 0.00735750
Iteration 3867, loss = 0.00735466
Iteration 3868, loss = 0.00735213
Iteration 3869, loss = 0.00735020
Iteration 3870, loss = 0.00734817
Iteration 3871, loss = 0.00734529
Iteration 3872, loss = 0.00734295
Iteration 3873, loss = 0.00734029
Iteration 3874, loss = 0.00733789
Iteration 3875, loss = 0.00733537
Iteration 3876, loss = 0.00733290
Iteration 3877, loss = 0.00733051
Iteration 3878, loss = 0.00732814
Iteration 3879, loss = 0.00732636
Iteration 3880, loss = 0.00732381
Iteration 3881, loss = 0.00732110
Iteration 3882, loss = 0.00731895
Iteration 3883, loss = 0.00731618
Iteration 3884, loss = 0.00731364
Iteration 3885, loss = 0.00731127
Iteration 3886, loss = 0.00730851
Iteration 3887, loss = 0.00730602
Iteration 3888, loss = 0.00730373
Iteration 3889, loss = 0.00730142
Iteration 3890, loss = 0.00729901
Iteration 3891, loss = 0.00729637
Iteration 3892, loss = 0.00729437
Iteration 3893, loss = 0.00729189
Iteration 3894, loss = 0.00728995
Iteration 3895, loss = 0.00728763
Iteration 3896, loss = 0.00728572
Iteration 3897, loss = 0.00728269
Iteration 3898, loss = 0.00728031
Iteration 3899, loss = 0.00727781
Iteration 3900, loss = 0.00727571
Iteration 3901, loss = 0.00727301
Iteration 3902, loss = 0.00727063
Iteration 3903, loss = 0.00726880
Iteration 3904, loss = 0.00726593
Iteration 3905, loss = 0.00726395
Iteration 3906, loss = 0.00726122
Iteration 3907, loss = 0.00725899
Iteration 3908, loss = 0.00725687
Iteration 3909, loss = 0.00725422
Iteration 3910, loss = 0.00725192
Iteration 3911, loss = 0.00724944
Iteration 3912, loss = 0.00724776
Iteration 3913, loss = 0.00724414
Iteration 3914, loss = 0.00724177
Iteration 3915, loss = 0.00723835
Iteration 3916, loss = 0.00723518
Iteration 3917, loss = 0.00723227
Iteration 3918, loss = 0.00722983
Iteration 3919, loss = 0.00722665
Iteration 3920, loss = 0.00722392
Iteration 3921, loss = 0.00722197
Iteration 3922, loss = 0.00721959
Iteration 3923, loss = 0.00721639
Iteration 3924, loss = 0.00721458
Iteration 3925, loss = 0.00721143
Iteration 3926, loss = 0.00720882
Iteration 3927, loss = 0.00720596
Iteration 3928, loss = 0.00720296
Iteration 3929, loss = 0.00719984
Iteration 3930, loss = 0.00719760
Iteration 3931, loss = 0.00719412
Iteration 3932, loss = 0.00719153
Iteration 3933, loss = 0.00718955
Iteration 3934, loss = 0.00718634
Iteration 3935, loss = 0.00718413
Iteration 3936, loss = 0.00718109
Iteration 3937, loss = 0.00717872
Iteration 3938, loss = 0.00717616
Iteration 3939, loss = 0.00717351
Iteration 3940, loss = 0.00717092
Iteration 3941, loss = 0.00716810
Iteration 3942, loss = 0.00716536
Iteration 3943, loss = 0.00716247
Iteration 3944, loss = 0.00715992
Iteration 3945, loss = 0.00715755
Iteration 3946, loss = 0.00715485
Iteration 3947, loss = 0.00715239
Iteration 3948, loss = 0.00715007
Iteration 3949, loss = 0.00714778
Iteration 3950, loss = 0.00714516
Iteration 3951, loss = 0.00714301
Iteration 3952, loss = 0.00714076
Iteration 3953, loss = 0.00713952
Iteration 3954, loss = 0.00713623
Iteration 3955, loss = 0.00713371
Iteration 3956, loss = 0.00713134
Iteration 3957, loss = 0.00712915
Iteration 3958, loss = 0.00712680
Iteration 3959, loss = 0.00712493
Iteration 3960, loss = 0.00712251
Iteration 3961, loss = 0.00711958
Iteration 3962, loss = 0.00711694
Iteration 3963, loss = 0.00711489
Iteration 3964, loss = 0.00711130
Iteration 3965, loss = 0.00710825
Iteration 3966, loss = 0.00710731
Iteration 3967, loss = 0.00710446
Iteration 3968, loss = 0.00710085
Iteration 3969, loss = 0.00709846
Iteration 3970, loss = 0.00709575
Iteration 3971, loss = 0.00709336
Iteration 3972, loss = 0.00709099
Iteration 3973, loss = 0.00708789
Iteration 3974, loss = 0.00708480
Iteration 3975, loss = 0.00708268
Iteration 3976, loss = 0.00708072
Iteration 3977, loss = 0.00707727
Iteration 3978, loss = 0.00707507
Iteration 3979, loss = 0.00707263
Iteration 3980, loss = 0.00706951
Iteration 3981, loss = 0.00706723
Iteration 3982, loss = 0.00706504
Iteration 3983, loss = 0.00706352
Iteration 3984, loss = 0.00706025
Iteration 3985, loss = 0.00705812
Iteration 3986, loss = 0.00705540
Iteration 3987, loss = 0.00705306
Iteration 3988, loss = 0.00705054
Iteration 3989, loss = 0.00704798
Iteration 3990, loss = 0.00704590
Iteration 3991, loss = 0.00704290
Iteration 3992, loss = 0.00704066
Iteration 3993, loss = 0.00703852
Iteration 3994, loss = 0.00703532
Iteration 3995, loss = 0.00703286
Iteration 3996, loss = 0.00703064
Iteration 3997, loss = 0.00702806
Iteration 3998, loss = 0.00702520
Iteration 3999, loss = 0.00702314
Iteration 4000, loss = 0.00702022
Iteration 4001, loss = 0.00701786
Iteration 4002, loss = 0.00701517
Iteration 4003, loss = 0.00701266
Iteration 4004, loss = 0.00701039
Iteration 4005, loss = 0.00700765
Iteration 4006, loss = 0.00700504
Iteration 4007, loss = 0.00700297
Iteration 4008, loss = 0.00700001
Iteration 4009, loss = 0.00699726
Iteration 4010, loss = 0.00699477
Iteration 4011, loss = 0.00699221
Iteration 4012, loss = 0.00698954
Iteration 4013, loss = 0.00698708
Iteration 4014, loss = 0.00698420
Iteration 4015, loss = 0.00698200
Iteration 4016, loss = 0.00697903
Iteration 4017, loss = 0.00697664
Iteration 4018, loss = 0.00697415
Iteration 4019, loss = 0.00697190
Iteration 4020, loss = 0.00696911
Iteration 4021, loss = 0.00696683
Iteration 4022, loss = 0.00696431
Iteration 4023, loss = 0.00696243
Iteration 4024, loss = 0.00695951
Iteration 4025, loss = 0.00695726
Iteration 4026, loss = 0.00695509
Iteration 4027, loss = 0.00695254
Iteration 4028, loss = 0.00695022
Iteration 4029, loss = 0.00694808
Iteration 4030, loss = 0.00694610
Iteration 4031, loss = 0.00694354
Iteration 4032, loss = 0.00694058
Iteration 4033, loss = 0.00693834
Iteration 4034, loss = 0.00693613
Iteration 4035, loss = 0.00693356
Iteration 4036, loss = 0.00693103
Iteration 4037, loss = 0.00692873
Iteration 4038, loss = 0.00692607
Iteration 4039, loss = 0.00692354
Iteration 4040, loss = 0.00692108
Iteration 4041, loss = 0.00691820
Iteration 4042, loss = 0.00691673
Iteration 4043, loss = 0.00691342
Iteration 4044, loss = 0.00691126
Iteration 4045, loss = 0.00690822
Iteration 4046, loss = 0.00690649
Iteration 4047, loss = 0.00690344
Iteration 4048, loss = 0.00690162
Iteration 4049, loss = 0.00689897
Iteration 4050, loss = 0.00689654
Iteration 4051, loss = 0.00689395
Iteration 4052, loss = 0.00689147
Iteration 4053, loss = 0.00688905
Iteration 4054, loss = 0.00688668
Iteration 4055, loss = 0.00688516
Iteration 4056, loss = 0.00688179
Iteration 4057, loss = 0.00687928
Iteration 4058, loss = 0.00687705
Iteration 4059, loss = 0.00687399
Iteration 4060, loss = 0.00687124
Iteration 4061, loss = 0.00686859
Iteration 4062, loss = 0.00686648
Iteration 4063, loss = 0.00686394
Iteration 4064, loss = 0.00686127
Iteration 4065, loss = 0.00685876
Iteration 4066, loss = 0.00685619
Iteration 4067, loss = 0.00685525
Iteration 4068, loss = 0.00685165
Iteration 4069, loss = 0.00684935
Iteration 4070, loss = 0.00684704
Iteration 4071, loss = 0.00684452
Iteration 4072, loss = 0.00684234
Iteration 4073, loss = 0.00683999
Iteration 4074, loss = 0.00683817
Iteration 4075, loss = 0.00683492
Iteration 4076, loss = 0.00683327
Iteration 4077, loss = 0.00683177
Iteration 4078, loss = 0.00682841
Iteration 4079, loss = 0.00682659
Iteration 4080, loss = 0.00682371
Iteration 4081, loss = 0.00682152
Iteration 4082, loss = 0.00681925
Iteration 4083, loss = 0.00681697
Iteration 4084, loss = 0.00681486
Iteration 4085, loss = 0.00681265
Iteration 4086, loss = 0.00681027
Iteration 4087, loss = 0.00680801
Iteration 4088, loss = 0.00680679
Iteration 4089, loss = 0.00680347
Iteration 4090, loss = 0.00680098
Iteration 4091, loss = 0.00679896
Iteration 4092, loss = 0.00679646
Iteration 4093, loss = 0.00679427
Iteration 4094, loss = 0.00679235
Iteration 4095, loss = 0.00678994
Iteration 4096, loss = 0.00678789
Iteration 4097, loss = 0.00678632
Iteration 4098, loss = 0.00678403
Iteration 4099, loss = 0.00678170
Iteration 4100, loss = 0.00678005
Iteration 4101, loss = 0.00677792
Iteration 4102, loss = 0.00677564
Iteration 4103, loss = 0.00677350
Iteration 4104, loss = 0.00677155
Iteration 4105, loss = 0.00676924
Iteration 4106, loss = 0.00676726
Iteration 4107, loss = 0.00676571
Iteration 4108, loss = 0.00676336
Iteration 4109, loss = 0.00676102
Iteration 4110, loss = 0.00675904
Iteration 4111, loss = 0.00675678
Iteration 4112, loss = 0.00675472
Iteration 4113, loss = 0.00675262
Iteration 4114, loss = 0.00675054
Iteration 4115, loss = 0.00674915
Iteration 4116, loss = 0.00674746
Iteration 4117, loss = 0.00674481
Iteration 4118, loss = 0.00674237
Iteration 4119, loss = 0.00674006
Iteration 4120, loss = 0.00673799
Iteration 4121, loss = 0.00673586
Iteration 4122, loss = 0.00673409
Iteration 4123, loss = 0.00673190
Iteration 4124, loss = 0.00672961
Iteration 4125, loss = 0.00672780
Iteration 4126, loss = 0.00672550
Iteration 4127, loss = 0.00672332
Iteration 4128, loss = 0.00672179
Iteration 4129, loss = 0.00672075
Iteration 4130, loss = 0.00671858
Iteration 4131, loss = 0.00671668
Iteration 4132, loss = 0.00671447
Iteration 4133, loss = 0.00671387
Iteration 4134, loss = 0.00671078
Iteration 4135, loss = 0.00670862
Iteration 4136, loss = 0.00670666
Iteration 4137, loss = 0.00670427
Iteration 4138, loss = 0.00670191
Iteration 4139, loss = 0.00669964
Iteration 4140, loss = 0.00669776
Iteration 4141, loss = 0.00669630
Iteration 4142, loss = 0.00669342
Iteration 4143, loss = 0.00669193
Iteration 4144, loss = 0.00669047
Iteration 4145, loss = 0.00668869
Iteration 4146, loss = 0.00668567
Iteration 4147, loss = 0.00668395
Iteration 4148, loss = 0.00668076
Iteration 4149, loss = 0.00667807
Iteration 4150, loss = 0.00667541
Iteration 4151, loss = 0.00667250
Iteration 4152, loss = 0.00667079
Iteration 4153, loss = 0.00666723
Iteration 4154, loss = 0.00666497
Iteration 4155, loss = 0.00666258
Iteration 4156, loss = 0.00666023
Iteration 4157, loss = 0.00665798
Iteration 4158, loss = 0.00665579
Iteration 4159, loss = 0.00665334
Iteration 4160, loss = 0.00665036
Iteration 4161, loss = 0.00664819
Iteration 4162, loss = 0.00664501
Iteration 4163, loss = 0.00664245
Iteration 4164, loss = 0.00664108
Iteration 4165, loss = 0.00663778
Iteration 4166, loss = 0.00663530
Iteration 4167, loss = 0.00663322
Iteration 4168, loss = 0.00663114
Iteration 4169, loss = 0.00662847
Iteration 4170, loss = 0.00662620
Iteration 4171, loss = 0.00662386
Iteration 4172, loss = 0.00662156
Iteration 4173, loss = 0.00661913
Iteration 4174, loss = 0.00661638
Iteration 4175, loss = 0.00661361
Iteration 4176, loss = 0.00661139
Iteration 4177, loss = 0.00660889
Iteration 4178, loss = 0.00660617
Iteration 4179, loss = 0.00660376
Iteration 4180, loss = 0.00660100
Iteration 4181, loss = 0.00659889
Iteration 4182, loss = 0.00659593
Iteration 4183, loss = 0.00659393
Iteration 4184, loss = 0.00659156
Iteration 4185, loss = 0.00659029
Iteration 4186, loss = 0.00658683
Iteration 4187, loss = 0.00658507
Iteration 4188, loss = 0.00658217
Iteration 4189, loss = 0.00658003
Iteration 4190, loss = 0.00657797
Iteration 4191, loss = 0.00657585
Iteration 4192, loss = 0.00657374
Iteration 4193, loss = 0.00657147
Iteration 4194, loss = 0.00656943
Iteration 4195, loss = 0.00656704
Iteration 4196, loss = 0.00656451
Iteration 4197, loss = 0.00656226
Iteration 4198, loss = 0.00656043
Iteration 4199, loss = 0.00655792
Iteration 4200, loss = 0.00655557
Iteration 4201, loss = 0.00655360
Iteration 4202, loss = 0.00655164
Iteration 4203, loss = 0.00654961
Iteration 4204, loss = 0.00654721
Iteration 4205, loss = 0.00654501
Iteration 4206, loss = 0.00654258
Iteration 4207, loss = 0.00653996
Iteration 4208, loss = 0.00653779
Iteration 4209, loss = 0.00653573
Iteration 4210, loss = 0.00653321
Iteration 4211, loss = 0.00653127
Iteration 4212, loss = 0.00652877
Iteration 4213, loss = 0.00652711
Iteration 4214, loss = 0.00652500
Iteration 4215, loss = 0.00652317
Iteration 4216, loss = 0.00652081
Iteration 4217, loss = 0.00651864
Iteration 4218, loss = 0.00651635
Iteration 4219, loss = 0.00651463
Iteration 4220, loss = 0.00651217
Iteration 4221, loss = 0.00650993
Iteration 4222, loss = 0.00650770
Iteration 4223, loss = 0.00650637
Iteration 4224, loss = 0.00650403
Iteration 4225, loss = 0.00650164
Iteration 4226, loss = 0.00649944
Iteration 4227, loss = 0.00649777
Iteration 4228, loss = 0.00649545
Iteration 4229, loss = 0.00649300
Iteration 4230, loss = 0.00649093
Iteration 4231, loss = 0.00648860
Iteration 4232, loss = 0.00648657
Iteration 4233, loss = 0.00648429
Iteration 4234, loss = 0.00648205
Iteration 4235, loss = 0.00648017
Iteration 4236, loss = 0.00647760
Iteration 4237, loss = 0.00647524
Iteration 4238, loss = 0.00647373
Iteration 4239, loss = 0.00647155
Iteration 4240, loss = 0.00646897
Iteration 4241, loss = 0.00646664
Iteration 4242, loss = 0.00646435
Iteration 4243, loss = 0.00646250
Iteration 4244, loss = 0.00646058
Iteration 4245, loss = 0.00645854
Iteration 4246, loss = 0.00645637
Iteration 4247, loss = 0.00645456
Iteration 4248, loss = 0.00645239
Iteration 4249, loss = 0.00645049
Iteration 4250, loss = 0.00644886
Iteration 4251, loss = 0.00644670
Iteration 4252, loss = 0.00644478
Iteration 4253, loss = 0.00644290
Iteration 4254, loss = 0.00644101
Iteration 4255, loss = 0.00643922
Iteration 4256, loss = 0.00643773
Iteration 4257, loss = 0.00643554
Iteration 4258, loss = 0.00643320
Iteration 4259, loss = 0.00643143
Iteration 4260, loss = 0.00642920
Iteration 4261, loss = 0.00642727
Iteration 4262, loss = 0.00642545
Iteration 4263, loss = 0.00642354
Iteration 4264, loss = 0.00642135
Iteration 4265, loss = 0.00641962
Iteration 4266, loss = 0.00641730
Iteration 4267, loss = 0.00641544
Iteration 4268, loss = 0.00641347
Iteration 4269, loss = 0.00641125
Iteration 4270, loss = 0.00640902
Iteration 4271, loss = 0.00640691
Iteration 4272, loss = 0.00640487
Iteration 4273, loss = 0.00640279
Iteration 4274, loss = 0.00640083
Iteration 4275, loss = 0.00639883
Iteration 4276, loss = 0.00639652
Iteration 4277, loss = 0.00639414
Iteration 4278, loss = 0.00639204
Iteration 4279, loss = 0.00638970
Iteration 4280, loss = 0.00638730
Iteration 4281, loss = 0.00638538
Iteration 4282, loss = 0.00638271
Iteration 4283, loss = 0.00638094
Iteration 4284, loss = 0.00637821
Iteration 4285, loss = 0.00637603
Iteration 4286, loss = 0.00637343
Iteration 4287, loss = 0.00637178
Iteration 4288, loss = 0.00636938
Iteration 4289, loss = 0.00636694
Iteration 4290, loss = 0.00636446
Iteration 4291, loss = 0.00636383
Iteration 4292, loss = 0.00636042
Iteration 4293, loss = 0.00635883
Iteration 4294, loss = 0.00635622
Iteration 4295, loss = 0.00635409
Iteration 4296, loss = 0.00635173
Iteration 4297, loss = 0.00634952
Iteration 4298, loss = 0.00634789
Iteration 4299, loss = 0.00634622
Iteration 4300, loss = 0.00634373
Iteration 4301, loss = 0.00634152
Iteration 4302, loss = 0.00633931
Iteration 4303, loss = 0.00633739
Iteration 4304, loss = 0.00633475
Iteration 4305, loss = 0.00633263
Iteration 4306, loss = 0.00633108
Iteration 4307, loss = 0.00632822
Iteration 4308, loss = 0.00632603
Iteration 4309, loss = 0.00632423
Iteration 4310, loss = 0.00632217
Iteration 4311, loss = 0.00632025
Iteration 4312, loss = 0.00631816
Iteration 4313, loss = 0.00631591
Iteration 4314, loss = 0.00631379
Iteration 4315, loss = 0.00631157
Iteration 4316, loss = 0.00630959
Iteration 4317, loss = 0.00630740
Iteration 4318, loss = 0.00630527
Iteration 4319, loss = 0.00630285
Iteration 4320, loss = 0.00630113
Iteration 4321, loss = 0.00629880
Iteration 4322, loss = 0.00629665
Iteration 4323, loss = 0.00629482
Iteration 4324, loss = 0.00629249
Iteration 4325, loss = 0.00629078
Iteration 4326, loss = 0.00628849
Iteration 4327, loss = 0.00628581
Iteration 4328, loss = 0.00628383
Iteration 4329, loss = 0.00628191
Iteration 4330, loss = 0.00627917
Iteration 4331, loss = 0.00627742
Iteration 4332, loss = 0.00627485
Iteration 4333, loss = 0.00627273
Iteration 4334, loss = 0.00627084
Iteration 4335, loss = 0.00626854
Iteration 4336, loss = 0.00626669
Iteration 4337, loss = 0.00626401
Iteration 4338, loss = 0.00626218
Iteration 4339, loss = 0.00625948
Iteration 4340, loss = 0.00625747
Iteration 4341, loss = 0.00625500
Iteration 4342, loss = 0.00625393
Iteration 4343, loss = 0.00625087
Iteration 4344, loss = 0.00624877
Iteration 4345, loss = 0.00624651
Iteration 4346, loss = 0.00624444
Iteration 4347, loss = 0.00624276
Iteration 4348, loss = 0.00624025
Iteration 4349, loss = 0.00623831
Iteration 4350, loss = 0.00623626
Iteration 4351, loss = 0.00623398
Iteration 4352, loss = 0.00623198
Iteration 4353, loss = 0.00623029
Iteration 4354, loss = 0.00622815
Iteration 4355, loss = 0.00622629
Iteration 4356, loss = 0.00622481
Iteration 4357, loss = 0.00622236
Iteration 4358, loss = 0.00622068
Iteration 4359, loss = 0.00621852
Iteration 4360, loss = 0.00621632
Iteration 4361, loss = 0.00621452
Iteration 4362, loss = 0.00621237
Iteration 4363, loss = 0.00621070
Iteration 4364, loss = 0.00620858
Iteration 4365, loss = 0.00620668
Iteration 4366, loss = 0.00620452
Iteration 4367, loss = 0.00620287
Iteration 4368, loss = 0.00620092
Iteration 4369, loss = 0.00619888
Iteration 4370, loss = 0.00619711
Iteration 4371, loss = 0.00619555
Iteration 4372, loss = 0.00619344
Iteration 4373, loss = 0.00619154
Iteration 4374, loss = 0.00619035
Iteration 4375, loss = 0.00618800
Iteration 4376, loss = 0.00618597
Iteration 4377, loss = 0.00618433
Iteration 4378, loss = 0.00618268
Iteration 4379, loss = 0.00618071
Iteration 4380, loss = 0.00617846
Iteration 4381, loss = 0.00617659
Iteration 4382, loss = 0.00617427
Iteration 4383, loss = 0.00617239
Iteration 4384, loss = 0.00617089
Iteration 4385, loss = 0.00616827
Iteration 4386, loss = 0.00616661
Iteration 4387, loss = 0.00616445
Iteration 4388, loss = 0.00616283
Iteration 4389, loss = 0.00616086
Iteration 4390, loss = 0.00615987
Iteration 4391, loss = 0.00615694
Iteration 4392, loss = 0.00615501
Iteration 4393, loss = 0.00615305
Iteration 4394, loss = 0.00615121
Iteration 4395, loss = 0.00614973
Iteration 4396, loss = 0.00614701
Iteration 4397, loss = 0.00614531
Iteration 4398, loss = 0.00614322
Iteration 4399, loss = 0.00614084
Iteration 4400, loss = 0.00613870
Iteration 4401, loss = 0.00613727
Iteration 4402, loss = 0.00613531
Iteration 4403, loss = 0.00613302
Iteration 4404, loss = 0.00613135
Iteration 4405, loss = 0.00612955
Iteration 4406, loss = 0.00612712
Iteration 4407, loss = 0.00612522
Iteration 4408, loss = 0.00612315
Iteration 4409, loss = 0.00612147
Iteration 4410, loss = 0.00611943
Iteration 4411, loss = 0.00611748
Iteration 4412, loss = 0.00611554
Iteration 4413, loss = 0.00611350
Iteration 4414, loss = 0.00611168
Iteration 4415, loss = 0.00611010
Iteration 4416, loss = 0.00610795
Iteration 4417, loss = 0.00610659
Iteration 4418, loss = 0.00610405
Iteration 4419, loss = 0.00610226
Iteration 4420, loss = 0.00610018
Iteration 4421, loss = 0.00609830
Iteration 4422, loss = 0.00609639
Iteration 4423, loss = 0.00609461
Iteration 4424, loss = 0.00609265
Iteration 4425, loss = 0.00609061
Iteration 4426, loss = 0.00608877
Iteration 4427, loss = 0.00608676
Iteration 4428, loss = 0.00608503
Iteration 4429, loss = 0.00608331
Iteration 4430, loss = 0.00608129
Iteration 4431, loss = 0.00607969
Iteration 4432, loss = 0.00607786
Iteration 4433, loss = 0.00607616
Iteration 4434, loss = 0.00607430
Iteration 4435, loss = 0.00607253
Iteration 4436, loss = 0.00607083
Iteration 4437, loss = 0.00606873
Iteration 4438, loss = 0.00606708
Iteration 4439, loss = 0.00606496
Iteration 4440, loss = 0.00606334
Iteration 4441, loss = 0.00606243
Iteration 4442, loss = 0.00605942
Iteration 4443, loss = 0.00605758
Iteration 4444, loss = 0.00605565
Iteration 4445, loss = 0.00605477
Iteration 4446, loss = 0.00605221
Iteration 4447, loss = 0.00605024
Iteration 4448, loss = 0.00604801
Iteration 4449, loss = 0.00604598
Iteration 4450, loss = 0.00604402
Iteration 4451, loss = 0.00604224
Iteration 4452, loss = 0.00604011
Iteration 4453, loss = 0.00603804
Iteration 4454, loss = 0.00603617
Iteration 4455, loss = 0.00603447
Iteration 4456, loss = 0.00603234
Iteration 4457, loss = 0.00603052
Iteration 4458, loss = 0.00602877
Iteration 4459, loss = 0.00602717
Iteration 4460, loss = 0.00602490
Iteration 4461, loss = 0.00602317
Iteration 4462, loss = 0.00602104
Iteration 4463, loss = 0.00601914
Iteration 4464, loss = 0.00601741
Iteration 4465, loss = 0.00601565
Iteration 4466, loss = 0.00601434
Iteration 4467, loss = 0.00601225
Iteration 4468, loss = 0.00601062
Iteration 4469, loss = 0.00600896
Iteration 4470, loss = 0.00600704
Iteration 4471, loss = 0.00600534
Iteration 4472, loss = 0.00600344
Iteration 4473, loss = 0.00600151
Iteration 4474, loss = 0.00599979
Iteration 4475, loss = 0.00599764
Iteration 4476, loss = 0.00599560
Iteration 4477, loss = 0.00599405
Iteration 4478, loss = 0.00599169
Iteration 4479, loss = 0.00598988
Iteration 4480, loss = 0.00598849
Iteration 4481, loss = 0.00598600
Iteration 4482, loss = 0.00598408
Iteration 4483, loss = 0.00598211
Iteration 4484, loss = 0.00597978
Iteration 4485, loss = 0.00597774
Iteration 4486, loss = 0.00597677
Iteration 4487, loss = 0.00597422
Iteration 4488, loss = 0.00597235
Iteration 4489, loss = 0.00597032
Iteration 4490, loss = 0.00596871
Iteration 4491, loss = 0.00596657
Iteration 4492, loss = 0.00596459
Iteration 4493, loss = 0.00596259
Iteration 4494, loss = 0.00596077
Iteration 4495, loss = 0.00595867
Iteration 4496, loss = 0.00595683
Iteration 4497, loss = 0.00595478
Iteration 4498, loss = 0.00595293
Iteration 4499, loss = 0.00595102
Iteration 4500, loss = 0.00594950
Iteration 4501, loss = 0.00594740
Iteration 4502, loss = 0.00594572
Iteration 4503, loss = 0.00594392
Iteration 4504, loss = 0.00594233
Iteration 4505, loss = 0.00594034
Iteration 4506, loss = 0.00593848
Iteration 4507, loss = 0.00593673
Iteration 4508, loss = 0.00593547
Iteration 4509, loss = 0.00593330
Iteration 4510, loss = 0.00593181
Iteration 4511, loss = 0.00592976
Iteration 4512, loss = 0.00592813
Iteration 4513, loss = 0.00592590
Iteration 4514, loss = 0.00592401
Iteration 4515, loss = 0.00592221
Iteration 4516, loss = 0.00591963
Iteration 4517, loss = 0.00591740
Iteration 4518, loss = 0.00591554
Iteration 4519, loss = 0.00591339
Iteration 4520, loss = 0.00591254
Iteration 4521, loss = 0.00591026
Iteration 4522, loss = 0.00590787
Iteration 4523, loss = 0.00590590
Iteration 4524, loss = 0.00590412
Iteration 4525, loss = 0.00590216
Iteration 4526, loss = 0.00590031
Iteration 4527, loss = 0.00589872
Iteration 4528, loss = 0.00589658
Iteration 4529, loss = 0.00589500
Iteration 4530, loss = 0.00589314
Iteration 4531, loss = 0.00589100
Iteration 4532, loss = 0.00588927
Iteration 4533, loss = 0.00588746
Iteration 4534, loss = 0.00588635
Iteration 4535, loss = 0.00588425
Iteration 4536, loss = 0.00588304
Iteration 4537, loss = 0.00588045
Iteration 4538, loss = 0.00587863
Iteration 4539, loss = 0.00587655
Iteration 4540, loss = 0.00587484
Iteration 4541, loss = 0.00587379
Iteration 4542, loss = 0.00587138
Iteration 4543, loss = 0.00586981
Iteration 4544, loss = 0.00586774
Iteration 4545, loss = 0.00586596
Iteration 4546, loss = 0.00586429
Iteration 4547, loss = 0.00586255
Iteration 4548, loss = 0.00586063
Iteration 4549, loss = 0.00585887
Iteration 4550, loss = 0.00585695
Iteration 4551, loss = 0.00585496
Iteration 4552, loss = 0.00585322
Iteration 4553, loss = 0.00585142
Iteration 4554, loss = 0.00584937
Iteration 4555, loss = 0.00584740
Iteration 4556, loss = 0.00584587
Iteration 4557, loss = 0.00584366
Iteration 4558, loss = 0.00584210
Iteration 4559, loss = 0.00584043
Iteration 4560, loss = 0.00583823
Iteration 4561, loss = 0.00583625
Iteration 4562, loss = 0.00583413
Iteration 4563, loss = 0.00583237
Iteration 4564, loss = 0.00583024
Iteration 4565, loss = 0.00582836
Iteration 4566, loss = 0.00582689
Iteration 4567, loss = 0.00582474
Iteration 4568, loss = 0.00582260
Iteration 4569, loss = 0.00582128
Iteration 4570, loss = 0.00581882
Iteration 4571, loss = 0.00581730
Iteration 4572, loss = 0.00581509
Iteration 4573, loss = 0.00581320
Iteration 4574, loss = 0.00581130
Iteration 4575, loss = 0.00580931
Iteration 4576, loss = 0.00580793
Iteration 4577, loss = 0.00580557
Iteration 4578, loss = 0.00580410
Iteration 4579, loss = 0.00580222
Iteration 4580, loss = 0.00579982
Iteration 4581, loss = 0.00579831
Iteration 4582, loss = 0.00579597
Iteration 4583, loss = 0.00579486
Iteration 4584, loss = 0.00579258
Iteration 4585, loss = 0.00579070
Iteration 4586, loss = 0.00578939
Iteration 4587, loss = 0.00578696
Iteration 4588, loss = 0.00578543
Iteration 4589, loss = 0.00578334
Iteration 4590, loss = 0.00578172
Iteration 4591, loss = 0.00577974
Iteration 4592, loss = 0.00577797
Iteration 4593, loss = 0.00577630
Iteration 4594, loss = 0.00577435
Iteration 4595, loss = 0.00577284
Iteration 4596, loss = 0.00577127
Iteration 4597, loss = 0.00576902
Iteration 4598, loss = 0.00576724
Iteration 4599, loss = 0.00576566
Iteration 4600, loss = 0.00576335
Iteration 4601, loss = 0.00576162
Iteration 4602, loss = 0.00575981
Iteration 4603, loss = 0.00575800
Iteration 4604, loss = 0.00575651
Iteration 4605, loss = 0.00575503
Iteration 4606, loss = 0.00575334
Iteration 4607, loss = 0.00575157
Iteration 4608, loss = 0.00574986
Iteration 4609, loss = 0.00574845
Iteration 4610, loss = 0.00574665
Iteration 4611, loss = 0.00574479
Iteration 4612, loss = 0.00574331
Iteration 4613, loss = 0.00574140
Iteration 4614, loss = 0.00573942
Iteration 4615, loss = 0.00573799
Iteration 4616, loss = 0.00573578
Iteration 4617, loss = 0.00573421
Iteration 4618, loss = 0.00573251
Iteration 4619, loss = 0.00573037
Iteration 4620, loss = 0.00572886
Iteration 4621, loss = 0.00572690
Iteration 4622, loss = 0.00572510
Iteration 4623, loss = 0.00572321
Iteration 4624, loss = 0.00572156
Iteration 4625, loss = 0.00571958
Iteration 4626, loss = 0.00571811
Iteration 4627, loss = 0.00571631
Iteration 4628, loss = 0.00571453
Iteration 4629, loss = 0.00571292
Iteration 4630, loss = 0.00571139
Iteration 4631, loss = 0.00570937
Iteration 4632, loss = 0.00570796
Iteration 4633, loss = 0.00570591
Iteration 4634, loss = 0.00570455
Iteration 4635, loss = 0.00570227
Iteration 4636, loss = 0.00570022
Iteration 4637, loss = 0.00569850
Iteration 4638, loss = 0.00569643
Iteration 4639, loss = 0.00569496
Iteration 4640, loss = 0.00569344
Iteration 4641, loss = 0.00569162
Iteration 4642, loss = 0.00568958
Iteration 4643, loss = 0.00568770
Iteration 4644, loss = 0.00568609
Iteration 4645, loss = 0.00568433
Iteration 4646, loss = 0.00568241
Iteration 4647, loss = 0.00568102
Iteration 4648, loss = 0.00567924
Iteration 4649, loss = 0.00567757
Iteration 4650, loss = 0.00567575
Iteration 4651, loss = 0.00567411
Iteration 4652, loss = 0.00567197
Iteration 4653, loss = 0.00567101
Iteration 4654, loss = 0.00566953
Iteration 4655, loss = 0.00566717
Iteration 4656, loss = 0.00566533
Iteration 4657, loss = 0.00566358
Iteration 4658, loss = 0.00566157
Iteration 4659, loss = 0.00566006
Iteration 4660, loss = 0.00565802
Iteration 4661, loss = 0.00565636
Iteration 4662, loss = 0.00565481
Iteration 4663, loss = 0.00565278
Iteration 4664, loss = 0.00565101
Iteration 4665, loss = 0.00564935
Iteration 4666, loss = 0.00564755
Iteration 4667, loss = 0.00564583
Iteration 4668, loss = 0.00564427
Iteration 4669, loss = 0.00564266
Iteration 4670, loss = 0.00564084
Iteration 4671, loss = 0.00563896
Iteration 4672, loss = 0.00563847
Iteration 4673, loss = 0.00563555
Iteration 4674, loss = 0.00563383
Iteration 4675, loss = 0.00563190
Iteration 4676, loss = 0.00563011
Iteration 4677, loss = 0.00562851
Iteration 4678, loss = 0.00562676
Iteration 4679, loss = 0.00562499
Iteration 4680, loss = 0.00562354
Iteration 4681, loss = 0.00562163
Iteration 4682, loss = 0.00561992
Iteration 4683, loss = 0.00561834
Iteration 4684, loss = 0.00561681
Iteration 4685, loss = 0.00561495
Iteration 4686, loss = 0.00561327
Iteration 4687, loss = 0.00561147
Iteration 4688, loss = 0.00560981
Iteration 4689, loss = 0.00560840
Iteration 4690, loss = 0.00560696
Iteration 4691, loss = 0.00560506
Iteration 4692, loss = 0.00560333
Iteration 4693, loss = 0.00560175
Iteration 4694, loss = 0.00560004
Iteration 4695, loss = 0.00559834
Iteration 4696, loss = 0.00559713
Iteration 4697, loss = 0.00559522
Iteration 4698, loss = 0.00559368
Iteration 4699, loss = 0.00559243
Iteration 4700, loss = 0.00559029
Iteration 4701, loss = 0.00558881
Iteration 4702, loss = 0.00558699
Iteration 4703, loss = 0.00558533
Iteration 4704, loss = 0.00558365
Iteration 4705, loss = 0.00558179
Iteration 4706, loss = 0.00558069
Iteration 4707, loss = 0.00557866
Iteration 4708, loss = 0.00557785
Iteration 4709, loss = 0.00557569
Iteration 4710, loss = 0.00557415
Iteration 4711, loss = 0.00557281
Iteration 4712, loss = 0.00557117
Iteration 4713, loss = 0.00556968
Iteration 4714, loss = 0.00556825
Iteration 4715, loss = 0.00556684
Iteration 4716, loss = 0.00556521
Iteration 4717, loss = 0.00556366
Iteration 4718, loss = 0.00556274
Iteration 4719, loss = 0.00556038
Iteration 4720, loss = 0.00555884
Iteration 4721, loss = 0.00555727
Iteration 4722, loss = 0.00555545
Iteration 4723, loss = 0.00555389
Iteration 4724, loss = 0.00555183
Iteration 4725, loss = 0.00555015
Iteration 4726, loss = 0.00554848
Iteration 4727, loss = 0.00554700
Iteration 4728, loss = 0.00554540
Iteration 4729, loss = 0.00554361
Iteration 4730, loss = 0.00554190
Iteration 4731, loss = 0.00554069
Iteration 4732, loss = 0.00553897
Iteration 4733, loss = 0.00553740
Iteration 4734, loss = 0.00553609
Iteration 4735, loss = 0.00553489
Iteration 4736, loss = 0.00553336
Iteration 4737, loss = 0.00553181
Iteration 4738, loss = 0.00553033
Iteration 4739, loss = 0.00552884
Iteration 4740, loss = 0.00552786
Iteration 4741, loss = 0.00552612
Iteration 4742, loss = 0.00552451
Iteration 4743, loss = 0.00552318
Iteration 4744, loss = 0.00552180
Iteration 4745, loss = 0.00552049
Iteration 4746, loss = 0.00551892
Iteration 4747, loss = 0.00551746
Iteration 4748, loss = 0.00551617
Iteration 4749, loss = 0.00551467
Iteration 4750, loss = 0.00551329
Iteration 4751, loss = 0.00551093
Iteration 4752, loss = 0.00550954
Iteration 4753, loss = 0.00550723
Iteration 4754, loss = 0.00550592
Iteration 4755, loss = 0.00550398
Iteration 4756, loss = 0.00550230
Iteration 4757, loss = 0.00550050
Iteration 4758, loss = 0.00549922
Iteration 4759, loss = 0.00549717
Iteration 4760, loss = 0.00549558
Iteration 4761, loss = 0.00549408
Iteration 4762, loss = 0.00549252
Iteration 4763, loss = 0.00549085
Iteration 4764, loss = 0.00548911
Iteration 4765, loss = 0.00548760
Iteration 4766, loss = 0.00548583
Iteration 4767, loss = 0.00548390
Iteration 4768, loss = 0.00548205
Iteration 4769, loss = 0.00548014
Iteration 4770, loss = 0.00547891
Iteration 4771, loss = 0.00547668
Iteration 4772, loss = 0.00547536
Iteration 4773, loss = 0.00547349
Iteration 4774, loss = 0.00547200
Iteration 4775, loss = 0.00547023
Iteration 4776, loss = 0.00546870
Iteration 4777, loss = 0.00546691
Iteration 4778, loss = 0.00546508
Iteration 4779, loss = 0.00546340
Iteration 4780, loss = 0.00546215
Iteration 4781, loss = 0.00546043
Iteration 4782, loss = 0.00545903
Iteration 4783, loss = 0.00545708
Iteration 4784, loss = 0.00545600
Iteration 4785, loss = 0.00545407
Iteration 4786, loss = 0.00545229
Iteration 4787, loss = 0.00545081
Iteration 4788, loss = 0.00544896
Iteration 4789, loss = 0.00544740
Iteration 4790, loss = 0.00544581
Iteration 4791, loss = 0.00544374
Iteration 4792, loss = 0.00544182
Iteration 4793, loss = 0.00544024
Iteration 4794, loss = 0.00543853
Iteration 4795, loss = 0.00543662
Iteration 4796, loss = 0.00543535
Iteration 4797, loss = 0.00543347
Iteration 4798, loss = 0.00543169
Iteration 4799, loss = 0.00542993
Iteration 4800, loss = 0.00542821
Iteration 4801, loss = 0.00542677
Iteration 4802, loss = 0.00542518
Iteration 4803, loss = 0.00542349
Iteration 4804, loss = 0.00542182
Iteration 4805, loss = 0.00542032
Iteration 4806, loss = 0.00541849
Iteration 4807, loss = 0.00541707
Iteration 4808, loss = 0.00541545
Iteration 4809, loss = 0.00541379
Iteration 4810, loss = 0.00541215
Iteration 4811, loss = 0.00541066
Iteration 4812, loss = 0.00540891
Iteration 4813, loss = 0.00540742
Iteration 4814, loss = 0.00540721
Iteration 4815, loss = 0.00540438
Iteration 4816, loss = 0.00540263
Iteration 4817, loss = 0.00540080
Iteration 4818, loss = 0.00539903
Iteration 4819, loss = 0.00539715
Iteration 4820, loss = 0.00539632
Iteration 4821, loss = 0.00539419
Iteration 4822, loss = 0.00539256
Iteration 4823, loss = 0.00539070
Iteration 4824, loss = 0.00538900
Iteration 4825, loss = 0.00538759
Iteration 4826, loss = 0.00538593
Iteration 4827, loss = 0.00538448
Iteration 4828, loss = 0.00538250
Iteration 4829, loss = 0.00538101
Iteration 4830, loss = 0.00537940
Iteration 4831, loss = 0.00537767
Iteration 4832, loss = 0.00537579
Iteration 4833, loss = 0.00537419
Iteration 4834, loss = 0.00537265
Iteration 4835, loss = 0.00537088
Iteration 4836, loss = 0.00536970
Iteration 4837, loss = 0.00536786
Iteration 4838, loss = 0.00536602
Iteration 4839, loss = 0.00536430
Iteration 4840, loss = 0.00536312
Iteration 4841, loss = 0.00536129
Iteration 4842, loss = 0.00535987
Iteration 4843, loss = 0.00535825
Iteration 4844, loss = 0.00535695
Iteration 4845, loss = 0.00535545
Iteration 4846, loss = 0.00535391
Iteration 4847, loss = 0.00535210
Iteration 4848, loss = 0.00535057
Iteration 4849, loss = 0.00534897
Iteration 4850, loss = 0.00534730
Iteration 4851, loss = 0.00534573
Iteration 4852, loss = 0.00534440
Iteration 4853, loss = 0.00534277
Iteration 4854, loss = 0.00534104
Iteration 4855, loss = 0.00533970
Iteration 4856, loss = 0.00533793
Iteration 4857, loss = 0.00533673
Iteration 4858, loss = 0.00533457
Iteration 4859, loss = 0.00533273
Iteration 4860, loss = 0.00533116
Iteration 4861, loss = 0.00532967
Iteration 4862, loss = 0.00532796
Iteration 4863, loss = 0.00532646
Iteration 4864, loss = 0.00532483
Iteration 4865, loss = 0.00532329
Iteration 4866, loss = 0.00532176
Iteration 4867, loss = 0.00532034
Iteration 4868, loss = 0.00531850
Iteration 4869, loss = 0.00531748
Iteration 4870, loss = 0.00531580
Iteration 4871, loss = 0.00531493
Iteration 4872, loss = 0.00531360
Iteration 4873, loss = 0.00531259
Iteration 4874, loss = 0.00531135
Iteration 4875, loss = 0.00530961
Iteration 4876, loss = 0.00530821
Iteration 4877, loss = 0.00530652
Iteration 4878, loss = 0.00530521
Iteration 4879, loss = 0.00530358
Iteration 4880, loss = 0.00530201
Iteration 4881, loss = 0.00530126
Iteration 4882, loss = 0.00529936
Iteration 4883, loss = 0.00529813
Iteration 4884, loss = 0.00529675
Iteration 4885, loss = 0.00529535
Iteration 4886, loss = 0.00529408
Iteration 4887, loss = 0.00529248
Iteration 4888, loss = 0.00529136
Iteration 4889, loss = 0.00528953
Iteration 4890, loss = 0.00528807
Iteration 4891, loss = 0.00528638
Iteration 4892, loss = 0.00528461
Iteration 4893, loss = 0.00528264
Iteration 4894, loss = 0.00528123
Iteration 4895, loss = 0.00527941
Iteration 4896, loss = 0.00527800
Iteration 4897, loss = 0.00527637
Iteration 4898, loss = 0.00527482
Iteration 4899, loss = 0.00527330
Iteration 4900, loss = 0.00527184
Iteration 4901, loss = 0.00527014
Iteration 4902, loss = 0.00526893
Iteration 4903, loss = 0.00526725
Iteration 4904, loss = 0.00526568
Iteration 4905, loss = 0.00526427
Iteration 4906, loss = 0.00526295
Iteration 4907, loss = 0.00526102
Iteration 4908, loss = 0.00525924
Iteration 4909, loss = 0.00525761
Iteration 4910, loss = 0.00525602
Iteration 4911, loss = 0.00525437
Iteration 4912, loss = 0.00525324
Iteration 4913, loss = 0.00525135
Iteration 4914, loss = 0.00524988
Iteration 4915, loss = 0.00524856
Iteration 4916, loss = 0.00524707
Iteration 4917, loss = 0.00524497
Iteration 4918, loss = 0.00524355
Iteration 4919, loss = 0.00524215
Iteration 4920, loss = 0.00524073
Iteration 4921, loss = 0.00523992
Iteration 4922, loss = 0.00523800
Iteration 4923, loss = 0.00523626
Iteration 4924, loss = 0.00523482
Iteration 4925, loss = 0.00523390
Iteration 4926, loss = 0.00523215
Iteration 4927, loss = 0.00523056
Iteration 4928, loss = 0.00522917
Iteration 4929, loss = 0.00522768
Iteration 4930, loss = 0.00522625
Iteration 4931, loss = 0.00522476
Iteration 4932, loss = 0.00522319
Iteration 4933, loss = 0.00522190
Iteration 4934, loss = 0.00522049
Iteration 4935, loss = 0.00521894
Iteration 4936, loss = 0.00521724
Iteration 4937, loss = 0.00521699
Iteration 4938, loss = 0.00521447
Iteration 4939, loss = 0.00521295
Iteration 4940, loss = 0.00521116
Iteration 4941, loss = 0.00520946
Iteration 4942, loss = 0.00520811
Iteration 4943, loss = 0.00520627
Iteration 4944, loss = 0.00520535
Iteration 4945, loss = 0.00520318
Iteration 4946, loss = 0.00520184
Iteration 4947, loss = 0.00520056
Iteration 4948, loss = 0.00519902
Iteration 4949, loss = 0.00519797
Iteration 4950, loss = 0.00519636
Iteration 4951, loss = 0.00519487
Iteration 4952, loss = 0.00519331
Iteration 4953, loss = 0.00519168
Iteration 4954, loss = 0.00519010
Iteration 4955, loss = 0.00518875
Iteration 4956, loss = 0.00518742
Iteration 4957, loss = 0.00518552
Iteration 4958, loss = 0.00518401
Iteration 4959, loss = 0.00518232
Iteration 4960, loss = 0.00518090
Iteration 4961, loss = 0.00517929
Iteration 4962, loss = 0.00517775
Iteration 4963, loss = 0.00517617
Iteration 4964, loss = 0.00517468
Iteration 4965, loss = 0.00517334
Iteration 4966, loss = 0.00517166
Iteration 4967, loss = 0.00517003
Iteration 4968, loss = 0.00516827
Iteration 4969, loss = 0.00516673
Iteration 4970, loss = 0.00516481
Iteration 4971, loss = 0.00516403
Iteration 4972, loss = 0.00516178
Iteration 4973, loss = 0.00516080
Iteration 4974, loss = 0.00515876
Iteration 4975, loss = 0.00515717
Iteration 4976, loss = 0.00515565
Iteration 4977, loss = 0.00515440
Iteration 4978, loss = 0.00515266
Iteration 4979, loss = 0.00515122
Iteration 4980, loss = 0.00514980
Iteration 4981, loss = 0.00514836
Iteration 4982, loss = 0.00514736
Iteration 4983, loss = 0.00514586
Iteration 4984, loss = 0.00514419
Iteration 4985, loss = 0.00514258
Iteration 4986, loss = 0.00514109
Iteration 4987, loss = 0.00513972
Iteration 4988, loss = 0.00513799
Iteration 4989, loss = 0.00513655
Iteration 4990, loss = 0.00513489
Iteration 4991, loss = 0.00513360
Iteration 4992, loss = 0.00513182
Iteration 4993, loss = 0.00513037
Iteration 4994, loss = 0.00512896
Iteration 4995, loss = 0.00512714
Iteration 4996, loss = 0.00512571
Iteration 4997, loss = 0.00512425
Iteration 4998, loss = 0.00512276
Iteration 4999, loss = 0.00512148
Iteration 5000, loss = 0.00511985
Iteration 5001, loss = 0.00511829
Iteration 5002, loss = 0.00511688
Iteration 5003, loss = 0.00511558
Iteration 5004, loss = 0.00511422
Iteration 5005, loss = 0.00511277
Iteration 5006, loss = 0.00511207
Iteration 5007, loss = 0.00511010
Iteration 5008, loss = 0.00510864
Iteration 5009, loss = 0.00510720
Iteration 5010, loss = 0.00510595
Iteration 5011, loss = 0.00510446
Iteration 5012, loss = 0.00510319
Iteration 5013, loss = 0.00510179
Iteration 5014, loss = 0.00510075
Iteration 5015, loss = 0.00509879
Iteration 5016, loss = 0.00509754
Iteration 5017, loss = 0.00509603
Iteration 5018, loss = 0.00509461
Iteration 5019, loss = 0.00509324
Iteration 5020, loss = 0.00509189
Iteration 5021, loss = 0.00509073
Iteration 5022, loss = 0.00508927
Iteration 5023, loss = 0.00508801
Iteration 5024, loss = 0.00508670
Iteration 5025, loss = 0.00508545
Iteration 5026, loss = 0.00508416
Iteration 5027, loss = 0.00508282
Iteration 5028, loss = 0.00508185
Iteration 5029, loss = 0.00508049
Iteration 5030, loss = 0.00507886
Iteration 5031, loss = 0.00507772
Iteration 5032, loss = 0.00507642
Iteration 5033, loss = 0.00507493
Iteration 5034, loss = 0.00507367
Iteration 5035, loss = 0.00507240
Iteration 5036, loss = 0.00507104
Iteration 5037, loss = 0.00506982
Iteration 5038, loss = 0.00506839
Iteration 5039, loss = 0.00506723
Iteration 5040, loss = 0.00506573
Iteration 5041, loss = 0.00506449
Iteration 5042, loss = 0.00506302
Iteration 5043, loss = 0.00506187
Iteration 5044, loss = 0.00506051
Iteration 5045, loss = 0.00505913
Iteration 5046, loss = 0.00505778
Iteration 5047, loss = 0.00505652
Iteration 5048, loss = 0.00505538
Iteration 5049, loss = 0.00505364
Iteration 5050, loss = 0.00505222
Iteration 5051, loss = 0.00505116
Iteration 5052, loss = 0.00504979
Iteration 5053, loss = 0.00504822
Iteration 5054, loss = 0.00504688
Iteration 5055, loss = 0.00504571
Iteration 5056, loss = 0.00504436
Iteration 5057, loss = 0.00504300
Iteration 5058, loss = 0.00504169
Iteration 5059, loss = 0.00504056
Iteration 5060, loss = 0.00503885
Iteration 5061, loss = 0.00503754
Iteration 5062, loss = 0.00503612
Iteration 5063, loss = 0.00503467
Iteration 5064, loss = 0.00503335
Iteration 5065, loss = 0.00503191
Iteration 5066, loss = 0.00503041
Iteration 5067, loss = 0.00502932
Iteration 5068, loss = 0.00502780
Iteration 5069, loss = 0.00502616
Iteration 5070, loss = 0.00502548
Iteration 5071, loss = 0.00502353
Iteration 5072, loss = 0.00502216
Iteration 5073, loss = 0.00502092
Iteration 5074, loss = 0.00501954
Iteration 5075, loss = 0.00501842
Iteration 5076, loss = 0.00501714
Iteration 5077, loss = 0.00501564
Iteration 5078, loss = 0.00501443
Iteration 5079, loss = 0.00501277
Iteration 5080, loss = 0.00501117
Iteration 5081, loss = 0.00500955
Iteration 5082, loss = 0.00500851
Iteration 5083, loss = 0.00500685
Iteration 5084, loss = 0.00500535
Iteration 5085, loss = 0.00500414
Iteration 5086, loss = 0.00500247
Iteration 5087, loss = 0.00500107
Iteration 5088, loss = 0.00499937
Iteration 5089, loss = 0.00499793
Iteration 5090, loss = 0.00499680
Iteration 5091, loss = 0.00499542
Iteration 5092, loss = 0.00499374
Iteration 5093, loss = 0.00499218
Iteration 5094, loss = 0.00499117
Iteration 5095, loss = 0.00498953
Iteration 5096, loss = 0.00498809
Iteration 5097, loss = 0.00498679
Iteration 5098, loss = 0.00498528
Iteration 5099, loss = 0.00498389
Iteration 5100, loss = 0.00498278
Iteration 5101, loss = 0.00498144
Iteration 5102, loss = 0.00498026
Iteration 5103, loss = 0.00497901
Iteration 5104, loss = 0.00497820
Iteration 5105, loss = 0.00497640
Iteration 5106, loss = 0.00497502
Iteration 5107, loss = 0.00497374
Iteration 5108, loss = 0.00497237
Iteration 5109, loss = 0.00497104
Iteration 5110, loss = 0.00496964
Iteration 5111, loss = 0.00496844
Iteration 5112, loss = 0.00496695
Iteration 5113, loss = 0.00496559
Iteration 5114, loss = 0.00496385
Iteration 5115, loss = 0.00496251
Iteration 5116, loss = 0.00496086
Iteration 5117, loss = 0.00496003
Iteration 5118, loss = 0.00495813
Iteration 5119, loss = 0.00495714
Iteration 5120, loss = 0.00495551
Iteration 5121, loss = 0.00495433
Iteration 5122, loss = 0.00495273
Iteration 5123, loss = 0.00495227
Iteration 5124, loss = 0.00495041
Iteration 5125, loss = 0.00494890
Iteration 5126, loss = 0.00494790
Iteration 5127, loss = 0.00494617
Iteration 5128, loss = 0.00494457
Iteration 5129, loss = 0.00494360
Iteration 5130, loss = 0.00494169
Iteration 5131, loss = 0.00494062
Iteration 5132, loss = 0.00493896
Iteration 5133, loss = 0.00493729
Iteration 5134, loss = 0.00493607
Iteration 5135, loss = 0.00493443
Iteration 5136, loss = 0.00493283
Iteration 5137, loss = 0.00493123
Iteration 5138, loss = 0.00492994
Iteration 5139, loss = 0.00492841
Iteration 5140, loss = 0.00492743
Iteration 5141, loss = 0.00492568
Iteration 5142, loss = 0.00492461
Iteration 5143, loss = 0.00492305
Iteration 5144, loss = 0.00492172
Iteration 5145, loss = 0.00492047
Iteration 5146, loss = 0.00491889
Iteration 5147, loss = 0.00491747
Iteration 5148, loss = 0.00491594
Iteration 5149, loss = 0.00491466
Iteration 5150, loss = 0.00491316
Iteration 5151, loss = 0.00491216
Iteration 5152, loss = 0.00491069
Iteration 5153, loss = 0.00490906
Iteration 5154, loss = 0.00490828
Iteration 5155, loss = 0.00490633
Iteration 5156, loss = 0.00490510
Iteration 5157, loss = 0.00490367
Iteration 5158, loss = 0.00490238
Iteration 5159, loss = 0.00490157
Iteration 5160, loss = 0.00489986
Iteration 5161, loss = 0.00489841
Iteration 5162, loss = 0.00489713
Iteration 5163, loss = 0.00489602
Iteration 5164, loss = 0.00489457
Iteration 5165, loss = 0.00489325
Iteration 5166, loss = 0.00489198
Iteration 5167, loss = 0.00489067
Iteration 5168, loss = 0.00488944
Iteration 5169, loss = 0.00488826
Iteration 5170, loss = 0.00488703
Iteration 5171, loss = 0.00488587
Iteration 5172, loss = 0.00488457
Iteration 5173, loss = 0.00488335
Iteration 5174, loss = 0.00488193
Iteration 5175, loss = 0.00488003
Iteration 5176, loss = 0.00487900
Iteration 5177, loss = 0.00487779
Iteration 5178, loss = 0.00487641
Iteration 5179, loss = 0.00487587
Iteration 5180, loss = 0.00487389
Iteration 5181, loss = 0.00487281
Iteration 5182, loss = 0.00487105
Iteration 5183, loss = 0.00486994
Iteration 5184, loss = 0.00486837
Iteration 5185, loss = 0.00486682
Iteration 5186, loss = 0.00486537
Iteration 5187, loss = 0.00486420
Iteration 5188, loss = 0.00486246
Iteration 5189, loss = 0.00486153
Iteration 5190, loss = 0.00485974
Iteration 5191, loss = 0.00485845
Iteration 5192, loss = 0.00485705
Iteration 5193, loss = 0.00485576
Iteration 5194, loss = 0.00485457
Iteration 5195, loss = 0.00485344
Iteration 5196, loss = 0.00485180
Iteration 5197, loss = 0.00485056
Iteration 5198, loss = 0.00484935
Iteration 5199, loss = 0.00484809
Iteration 5200, loss = 0.00484682
Iteration 5201, loss = 0.00484571
Iteration 5202, loss = 0.00484418
Iteration 5203, loss = 0.00484296
Iteration 5204, loss = 0.00484136
Iteration 5205, loss = 0.00484020
Iteration 5206, loss = 0.00483881
Iteration 5207, loss = 0.00483757
Iteration 5208, loss = 0.00483625
Iteration 5209, loss = 0.00483532
Iteration 5210, loss = 0.00483388
Iteration 5211, loss = 0.00483255
Iteration 5212, loss = 0.00483118
Iteration 5213, loss = 0.00482990
Iteration 5214, loss = 0.00482911
Iteration 5215, loss = 0.00482748
Iteration 5216, loss = 0.00482640
Iteration 5217, loss = 0.00482505
Iteration 5218, loss = 0.00482377
Iteration 5219, loss = 0.00482277
Iteration 5220, loss = 0.00482106
Iteration 5221, loss = 0.00481990
Iteration 5222, loss = 0.00481857
Iteration 5223, loss = 0.00481722
Iteration 5224, loss = 0.00481619
Iteration 5225, loss = 0.00481465
Iteration 5226, loss = 0.00481395
Iteration 5227, loss = 0.00481226
Iteration 5228, loss = 0.00481098
Iteration 5229, loss = 0.00480973
Iteration 5230, loss = 0.00480845
Iteration 5231, loss = 0.00480711
Iteration 5232, loss = 0.00480599
Iteration 5233, loss = 0.00480474
Iteration 5234, loss = 0.00480359
Iteration 5235, loss = 0.00480223
Iteration 5236, loss = 0.00480113
Iteration 5237, loss = 0.00480000
Iteration 5238, loss = 0.00479853
Iteration 5239, loss = 0.00479726
Iteration 5240, loss = 0.00479604
Iteration 5241, loss = 0.00479458
Iteration 5242, loss = 0.00479340
Iteration 5243, loss = 0.00479197
Iteration 5244, loss = 0.00479106
Iteration 5245, loss = 0.00478943
Iteration 5246, loss = 0.00478839
Iteration 5247, loss = 0.00478713
Iteration 5248, loss = 0.00478581
Iteration 5249, loss = 0.00478490
Iteration 5250, loss = 0.00478343
Iteration 5251, loss = 0.00478201
Iteration 5252, loss = 0.00478058
Iteration 5253, loss = 0.00477932
Iteration 5254, loss = 0.00477817
Iteration 5255, loss = 0.00477655
Iteration 5256, loss = 0.00477526
Iteration 5257, loss = 0.00477398
Iteration 5258, loss = 0.00477250
Iteration 5259, loss = 0.00477135
Iteration 5260, loss = 0.00476969
Iteration 5261, loss = 0.00476822
Iteration 5262, loss = 0.00476726
Iteration 5263, loss = 0.00476553
Iteration 5264, loss = 0.00476428
Iteration 5265, loss = 0.00476305
Iteration 5266, loss = 0.00476157
Iteration 5267, loss = 0.00476015
Iteration 5268, loss = 0.00475867
Iteration 5269, loss = 0.00475790
Iteration 5270, loss = 0.00475625
Iteration 5271, loss = 0.00475473
Iteration 5272, loss = 0.00475335
Iteration 5273, loss = 0.00475257
Iteration 5274, loss = 0.00475086
Iteration 5275, loss = 0.00474978
Iteration 5276, loss = 0.00474841
Iteration 5277, loss = 0.00474716
Iteration 5278, loss = 0.00474580
Iteration 5279, loss = 0.00474456
Iteration 5280, loss = 0.00474340
Iteration 5281, loss = 0.00474223
Iteration 5282, loss = 0.00474104
Iteration 5283, loss = 0.00473992
Iteration 5284, loss = 0.00473878
Iteration 5285, loss = 0.00473748
Iteration 5286, loss = 0.00473628
Iteration 5287, loss = 0.00473499
Iteration 5288, loss = 0.00473374
Iteration 5289, loss = 0.00473239
Iteration 5290, loss = 0.00473102
Iteration 5291, loss = 0.00473003
Iteration 5292, loss = 0.00472863
Iteration 5293, loss = 0.00472744
Iteration 5294, loss = 0.00472629
Iteration 5295, loss = 0.00472502
Iteration 5296, loss = 0.00472399
Iteration 5297, loss = 0.00472243
Iteration 5298, loss = 0.00472160
Iteration 5299, loss = 0.00472014
Iteration 5300, loss = 0.00471870
Iteration 5301, loss = 0.00471742
Iteration 5302, loss = 0.00471633
Iteration 5303, loss = 0.00471477
Iteration 5304, loss = 0.00471426
Iteration 5305, loss = 0.00471212
Iteration 5306, loss = 0.00471061
Iteration 5307, loss = 0.00470944
Iteration 5308, loss = 0.00470811
Iteration 5309, loss = 0.00470687
Iteration 5310, loss = 0.00470560
Iteration 5311, loss = 0.00470399
Iteration 5312, loss = 0.00470280
Iteration 5313, loss = 0.00470141
Iteration 5314, loss = 0.00470035
Iteration 5315, loss = 0.00469908
Iteration 5316, loss = 0.00469774
Iteration 5317, loss = 0.00469680
Iteration 5318, loss = 0.00469516
Iteration 5319, loss = 0.00469376
Iteration 5320, loss = 0.00469262
Iteration 5321, loss = 0.00469114
Iteration 5322, loss = 0.00468984
Iteration 5323, loss = 0.00468862
Iteration 5324, loss = 0.00468731
Iteration 5325, loss = 0.00468603
Iteration 5326, loss = 0.00468484
Iteration 5327, loss = 0.00468355
Iteration 5328, loss = 0.00468212
Iteration 5329, loss = 0.00468093
Iteration 5330, loss = 0.00467951
Iteration 5331, loss = 0.00467847
Iteration 5332, loss = 0.00467697
Iteration 5333, loss = 0.00467590
Iteration 5334, loss = 0.00467435
Iteration 5335, loss = 0.00467298
Iteration 5336, loss = 0.00467175
Iteration 5337, loss = 0.00467053
Iteration 5338, loss = 0.00466916
Iteration 5339, loss = 0.00466793
Iteration 5340, loss = 0.00466669
Iteration 5341, loss = 0.00466544
Iteration 5342, loss = 0.00466428
Iteration 5343, loss = 0.00466293
Iteration 5344, loss = 0.00466194
Iteration 5345, loss = 0.00466098
Iteration 5346, loss = 0.00465950
Iteration 5347, loss = 0.00465843
Iteration 5348, loss = 0.00465720
Iteration 5349, loss = 0.00465607
Iteration 5350, loss = 0.00465475
Iteration 5351, loss = 0.00465399
Iteration 5352, loss = 0.00465250
Iteration 5353, loss = 0.00465132
Iteration 5354, loss = 0.00465046
Iteration 5355, loss = 0.00464928
Iteration 5356, loss = 0.00464769
Iteration 5357, loss = 0.00464637
Iteration 5358, loss = 0.00464495
Iteration 5359, loss = 0.00464371
Iteration 5360, loss = 0.00464242
Iteration 5361, loss = 0.00464110
Iteration 5362, loss = 0.00463995
Iteration 5363, loss = 0.00463860
Iteration 5364, loss = 0.00463745
Iteration 5365, loss = 0.00463618
Iteration 5366, loss = 0.00463503
Iteration 5367, loss = 0.00463388
Iteration 5368, loss = 0.00463259
Iteration 5369, loss = 0.00463117
Iteration 5370, loss = 0.00463016
Iteration 5371, loss = 0.00462888
Iteration 5372, loss = 0.00462800
Iteration 5373, loss = 0.00462643
Iteration 5374, loss = 0.00462532
Iteration 5375, loss = 0.00462407
Iteration 5376, loss = 0.00462272
Iteration 5377, loss = 0.00462163
Iteration 5378, loss = 0.00462015
Iteration 5379, loss = 0.00461900
Iteration 5380, loss = 0.00461756
Iteration 5381, loss = 0.00461639
Iteration 5382, loss = 0.00461503
Iteration 5383, loss = 0.00461361
Iteration 5384, loss = 0.00461288
Iteration 5385, loss = 0.00461214
Iteration 5386, loss = 0.00461037
Iteration 5387, loss = 0.00460917
Iteration 5388, loss = 0.00460809
Iteration 5389, loss = 0.00460720
Iteration 5390, loss = 0.00460545
Iteration 5391, loss = 0.00460418
Iteration 5392, loss = 0.00460302
Iteration 5393, loss = 0.00460175
Iteration 5394, loss = 0.00460055
Iteration 5395, loss = 0.00459936
Iteration 5396, loss = 0.00459832
Iteration 5397, loss = 0.00459703
Iteration 5398, loss = 0.00459593
Iteration 5399, loss = 0.00459477
Iteration 5400, loss = 0.00459343
Iteration 5401, loss = 0.00459216
Iteration 5402, loss = 0.00459096
Iteration 5403, loss = 0.00458964
Iteration 5404, loss = 0.00458818
Iteration 5405, loss = 0.00458754
Iteration 5406, loss = 0.00458658
Iteration 5407, loss = 0.00458466
Iteration 5408, loss = 0.00458332
Iteration 5409, loss = 0.00458208
Iteration 5410, loss = 0.00458058
Iteration 5411, loss = 0.00457954
Iteration 5412, loss = 0.00457863
Iteration 5413, loss = 0.00457823
Iteration 5414, loss = 0.00457683
Iteration 5415, loss = 0.00457509
Iteration 5416, loss = 0.00457361
Iteration 5417, loss = 0.00457254
Iteration 5418, loss = 0.00457160
Iteration 5419, loss = 0.00457042
Iteration 5420, loss = 0.00456892
Iteration 5421, loss = 0.00456768
Iteration 5422, loss = 0.00456648
Iteration 5423, loss = 0.00456514
Iteration 5424, loss = 0.00456425
Iteration 5425, loss = 0.00456276
Iteration 5426, loss = 0.00456181
Iteration 5427, loss = 0.00456065
Iteration 5428, loss = 0.00455897
Iteration 5429, loss = 0.00455785
Iteration 5430, loss = 0.00455640
Iteration 5431, loss = 0.00455569
Iteration 5432, loss = 0.00455420
Iteration 5433, loss = 0.00455326
Iteration 5434, loss = 0.00455174
Iteration 5435, loss = 0.00455057
Iteration 5436, loss = 0.00454927
Iteration 5437, loss = 0.00454834
Iteration 5438, loss = 0.00454689
Iteration 5439, loss = 0.00454577
Iteration 5440, loss = 0.00454444
Iteration 5441, loss = 0.00454324
Iteration 5442, loss = 0.00454193
Iteration 5443, loss = 0.00454064
Iteration 5444, loss = 0.00453938
Iteration 5445, loss = 0.00453802
Iteration 5446, loss = 0.00453665
Iteration 5447, loss = 0.00453546
Iteration 5448, loss = 0.00453386
Iteration 5449, loss = 0.00453280
Iteration 5450, loss = 0.00453170
Iteration 5451, loss = 0.00453027
Iteration 5452, loss = 0.00452922
Iteration 5453, loss = 0.00452798
Iteration 5454, loss = 0.00452765
Iteration 5455, loss = 0.00452567
Iteration 5456, loss = 0.00452467
Iteration 5457, loss = 0.00452337
Iteration 5458, loss = 0.00452216
Iteration 5459, loss = 0.00452107
Iteration 5460, loss = 0.00452004
Iteration 5461, loss = 0.00451900
Iteration 5462, loss = 0.00451801
Iteration 5463, loss = 0.00451682
Iteration 5464, loss = 0.00451551
Iteration 5465, loss = 0.00451462
Iteration 5466, loss = 0.00451337
Iteration 5467, loss = 0.00451214
Iteration 5468, loss = 0.00451102
Iteration 5469, loss = 0.00451023
Iteration 5470, loss = 0.00450885
Iteration 5471, loss = 0.00450759
Iteration 5472, loss = 0.00450657
Iteration 5473, loss = 0.00450610
Iteration 5474, loss = 0.00450430
Iteration 5475, loss = 0.00450347
Iteration 5476, loss = 0.00450228
Iteration 5477, loss = 0.00450105
Iteration 5478, loss = 0.00449994
Iteration 5479, loss = 0.00449903
Iteration 5480, loss = 0.00449777
Iteration 5481, loss = 0.00449667
Iteration 5482, loss = 0.00449574
Iteration 5483, loss = 0.00449489
Iteration 5484, loss = 0.00449365
Iteration 5485, loss = 0.00449264
Iteration 5486, loss = 0.00449154
Iteration 5487, loss = 0.00449048
Iteration 5488, loss = 0.00448937
Iteration 5489, loss = 0.00448825
Iteration 5490, loss = 0.00448713
Iteration 5491, loss = 0.00448623
Iteration 5492, loss = 0.00448537
Iteration 5493, loss = 0.00448418
Iteration 5494, loss = 0.00448327
Iteration 5495, loss = 0.00448198
Iteration 5496, loss = 0.00448086
Iteration 5497, loss = 0.00447981
Iteration 5498, loss = 0.00447879
Iteration 5499, loss = 0.00447756
Iteration 5500, loss = 0.00447635
Iteration 5501, loss = 0.00447518
Iteration 5502, loss = 0.00447403
Iteration 5503, loss = 0.00447295
Iteration 5504, loss = 0.00447161
Iteration 5505, loss = 0.00447049
Iteration 5506, loss = 0.00446960
Iteration 5507, loss = 0.00446822
Iteration 5508, loss = 0.00446715
Iteration 5509, loss = 0.00446630
Iteration 5510, loss = 0.00446490
Iteration 5511, loss = 0.00446395
Iteration 5512, loss = 0.00446314
Iteration 5513, loss = 0.00446162
Iteration 5514, loss = 0.00446061
Iteration 5515, loss = 0.00445946
Iteration 5516, loss = 0.00445857
Iteration 5517, loss = 0.00445743
Iteration 5518, loss = 0.00445637
Iteration 5519, loss = 0.00445523
Iteration 5520, loss = 0.00445415
Iteration 5521, loss = 0.00445309
Iteration 5522, loss = 0.00445225
Iteration 5523, loss = 0.00445109
Iteration 5524, loss = 0.00445004
Iteration 5525, loss = 0.00444904
Iteration 5526, loss = 0.00444791
Iteration 5527, loss = 0.00444674
Iteration 5528, loss = 0.00444541
Iteration 5529, loss = 0.00444446
Iteration 5530, loss = 0.00444352
Iteration 5531, loss = 0.00444202
Iteration 5532, loss = 0.00444120
Iteration 5533, loss = 0.00443965
Iteration 5534, loss = 0.00443858
Iteration 5535, loss = 0.00443731
Iteration 5536, loss = 0.00443646
Iteration 5537, loss = 0.00443510
Iteration 5538, loss = 0.00443371
Iteration 5539, loss = 0.00443313
Iteration 5540, loss = 0.00443153
Iteration 5541, loss = 0.00442995
Iteration 5542, loss = 0.00442929
Iteration 5543, loss = 0.00442803
Iteration 5544, loss = 0.00442625
Iteration 5545, loss = 0.00442515
Iteration 5546, loss = 0.00442400
Iteration 5547, loss = 0.00442263
Iteration 5548, loss = 0.00442143
Iteration 5549, loss = 0.00442000
Iteration 5550, loss = 0.00441946
Iteration 5551, loss = 0.00441774
Iteration 5552, loss = 0.00441685
Iteration 5553, loss = 0.00441526
Iteration 5554, loss = 0.00441397
Iteration 5555, loss = 0.00441282
Iteration 5556, loss = 0.00441195
Iteration 5557, loss = 0.00441052
Iteration 5558, loss = 0.00440950
Iteration 5559, loss = 0.00440829
Iteration 5560, loss = 0.00440715
Iteration 5561, loss = 0.00440616
Iteration 5562, loss = 0.00440515
Iteration 5563, loss = 0.00440377
Iteration 5564, loss = 0.00440252
Iteration 5565, loss = 0.00440162
Iteration 5566, loss = 0.00440020
Iteration 5567, loss = 0.00439917
Iteration 5568, loss = 0.00439787
Iteration 5569, loss = 0.00439675
Iteration 5570, loss = 0.00439556
Iteration 5571, loss = 0.00439464
Iteration 5572, loss = 0.00439341
Iteration 5573, loss = 0.00439256
Iteration 5574, loss = 0.00439133
Iteration 5575, loss = 0.00439013
Iteration 5576, loss = 0.00438905
Iteration 5577, loss = 0.00438759
Iteration 5578, loss = 0.00438794
Iteration 5579, loss = 0.00438548
Iteration 5580, loss = 0.00438438
Iteration 5581, loss = 0.00438307
Iteration 5582, loss = 0.00438195
Iteration 5583, loss = 0.00438076
Iteration 5584, loss = 0.00437960
Iteration 5585, loss = 0.00437861
Iteration 5586, loss = 0.00437760
Iteration 5587, loss = 0.00437660
Iteration 5588, loss = 0.00437544
Iteration 5589, loss = 0.00437453
Iteration 5590, loss = 0.00437338
Iteration 5591, loss = 0.00437237
Iteration 5592, loss = 0.00437118
Iteration 5593, loss = 0.00437029
Iteration 5594, loss = 0.00436942
Iteration 5595, loss = 0.00436812
Iteration 5596, loss = 0.00436707
Iteration 5597, loss = 0.00436610
Iteration 5598, loss = 0.00436528
Iteration 5599, loss = 0.00436373
Iteration 5600, loss = 0.00436255
Iteration 5601, loss = 0.00436133
Iteration 5602, loss = 0.00436093
Iteration 5603, loss = 0.00435942
Iteration 5604, loss = 0.00435828
Iteration 5605, loss = 0.00435720
Iteration 5606, loss = 0.00435613
Iteration 5607, loss = 0.00435512
Iteration 5608, loss = 0.00435414
Iteration 5609, loss = 0.00435297
Iteration 5610, loss = 0.00435172
Iteration 5611, loss = 0.00435046
Iteration 5612, loss = 0.00434944
Iteration 5613, loss = 0.00434811
Iteration 5614, loss = 0.00434690
Iteration 5615, loss = 0.00434594
Iteration 5616, loss = 0.00434471
Iteration 5617, loss = 0.00434337
Iteration 5618, loss = 0.00434198
Iteration 5619, loss = 0.00434090
Iteration 5620, loss = 0.00433959
Iteration 5621, loss = 0.00433845
Iteration 5622, loss = 0.00433765
Iteration 5623, loss = 0.00433639
Iteration 5624, loss = 0.00433517
Iteration 5625, loss = 0.00433381
Iteration 5626, loss = 0.00433273
Iteration 5627, loss = 0.00433152
Iteration 5628, loss = 0.00433047
Iteration 5629, loss = 0.00432948
Iteration 5630, loss = 0.00432857
Iteration 5631, loss = 0.00432752
Iteration 5632, loss = 0.00432624
Iteration 5633, loss = 0.00432510
Iteration 5634, loss = 0.00432408
Iteration 5635, loss = 0.00432301
Iteration 5636, loss = 0.00432169
Iteration 5637, loss = 0.00432060
Iteration 5638, loss = 0.00431941
Iteration 5639, loss = 0.00431822
Iteration 5640, loss = 0.00431711
Iteration 5641, loss = 0.00431614
Iteration 5642, loss = 0.00431496
Iteration 5643, loss = 0.00431407
Iteration 5644, loss = 0.00431272
Iteration 5645, loss = 0.00431151
Iteration 5646, loss = 0.00431032
Iteration 5647, loss = 0.00430923
Iteration 5648, loss = 0.00430830
Iteration 5649, loss = 0.00430688
Iteration 5650, loss = 0.00430592
Iteration 5651, loss = 0.00430476
Iteration 5652, loss = 0.00430405
Iteration 5653, loss = 0.00430277
Iteration 5654, loss = 0.00430169
Iteration 5655, loss = 0.00430067
Iteration 5656, loss = 0.00429966
Iteration 5657, loss = 0.00429853
Iteration 5658, loss = 0.00429772
Iteration 5659, loss = 0.00429651
Iteration 5660, loss = 0.00429552
Iteration 5661, loss = 0.00429445
Iteration 5662, loss = 0.00429351
Iteration 5663, loss = 0.00429250
Iteration 5664, loss = 0.00429167
Iteration 5665, loss = 0.00429073
Iteration 5666, loss = 0.00428976
Iteration 5667, loss = 0.00428872
Iteration 5668, loss = 0.00428765
Iteration 5669, loss = 0.00428678
Iteration 5670, loss = 0.00428586
Iteration 5671, loss = 0.00428511
Iteration 5672, loss = 0.00428409
Iteration 5673, loss = 0.00428313
Iteration 5674, loss = 0.00428202
Iteration 5675, loss = 0.00428110
Iteration 5676, loss = 0.00428004
Iteration 5677, loss = 0.00427891
Iteration 5678, loss = 0.00427807
Iteration 5679, loss = 0.00427678
Iteration 5680, loss = 0.00427567
Iteration 5681, loss = 0.00427458
Iteration 5682, loss = 0.00427367
Iteration 5683, loss = 0.00427258
Iteration 5684, loss = 0.00427159
Iteration 5685, loss = 0.00427040
Iteration 5686, loss = 0.00426924
Iteration 5687, loss = 0.00426821
Iteration 5688, loss = 0.00426712
Iteration 5689, loss = 0.00426606
Iteration 5690, loss = 0.00426511
Iteration 5691, loss = 0.00426409
Iteration 5692, loss = 0.00426317
Iteration 5693, loss = 0.00426222
Iteration 5694, loss = 0.00426099
Iteration 5695, loss = 0.00425994
Iteration 5696, loss = 0.00425871
Iteration 5697, loss = 0.00425747
Iteration 5698, loss = 0.00425630
Iteration 5699, loss = 0.00425570
Iteration 5700, loss = 0.00425467
Iteration 5701, loss = 0.00425342
Iteration 5702, loss = 0.00425226
Iteration 5703, loss = 0.00425119
Iteration 5704, loss = 0.00425011
Iteration 5705, loss = 0.00424929
Iteration 5706, loss = 0.00424810
Iteration 5707, loss = 0.00424708
Iteration 5708, loss = 0.00424605
Iteration 5709, loss = 0.00424497
Iteration 5710, loss = 0.00424415
Iteration 5711, loss = 0.00424293
Iteration 5712, loss = 0.00424215
Iteration 5713, loss = 0.00424103
Iteration 5714, loss = 0.00423986
Iteration 5715, loss = 0.00423863
Iteration 5716, loss = 0.00423820
Iteration 5717, loss = 0.00423661
Iteration 5718, loss = 0.00423559
Iteration 5719, loss = 0.00423472
Iteration 5720, loss = 0.00423354
Iteration 5721, loss = 0.00423240
Iteration 5722, loss = 0.00423139
Iteration 5723, loss = 0.00423037
Iteration 5724, loss = 0.00422926
Iteration 5725, loss = 0.00422810
Iteration 5726, loss = 0.00422709
Iteration 5727, loss = 0.00422625
Iteration 5728, loss = 0.00422533
Iteration 5729, loss = 0.00422402
Iteration 5730, loss = 0.00422309
Iteration 5731, loss = 0.00422211
Iteration 5732, loss = 0.00422230
Iteration 5733, loss = 0.00422054
Iteration 5734, loss = 0.00421944
Iteration 5735, loss = 0.00421834
Iteration 5736, loss = 0.00421724
Iteration 5737, loss = 0.00421630
Iteration 5738, loss = 0.00421528
Iteration 5739, loss = 0.00421429
Iteration 5740, loss = 0.00421319
Iteration 5741, loss = 0.00421237
Iteration 5742, loss = 0.00421125
Iteration 5743, loss = 0.00421020
Iteration 5744, loss = 0.00420945
Iteration 5745, loss = 0.00420829
Iteration 5746, loss = 0.00420722
Iteration 5747, loss = 0.00420632
Iteration 5748, loss = 0.00420489
Iteration 5749, loss = 0.00420374
Iteration 5750, loss = 0.00420290
Iteration 5751, loss = 0.00420218
Iteration 5752, loss = 0.00420095
Iteration 5753, loss = 0.00420007
Iteration 5754, loss = 0.00419919
Iteration 5755, loss = 0.00419834
Iteration 5756, loss = 0.00419724
Iteration 5757, loss = 0.00419628
Iteration 5758, loss = 0.00419517
Iteration 5759, loss = 0.00419426
Iteration 5760, loss = 0.00419323
Iteration 5761, loss = 0.00419188
Iteration 5762, loss = 0.00419084
Iteration 5763, loss = 0.00418958
Iteration 5764, loss = 0.00418844
Iteration 5765, loss = 0.00418753
Iteration 5766, loss = 0.00418637
Iteration 5767, loss = 0.00418524
Iteration 5768, loss = 0.00418432
Iteration 5769, loss = 0.00418309
Iteration 5770, loss = 0.00418210
Iteration 5771, loss = 0.00418113
Iteration 5772, loss = 0.00418010
Iteration 5773, loss = 0.00417899
Iteration 5774, loss = 0.00417792
Iteration 5775, loss = 0.00417709
Iteration 5776, loss = 0.00417619
Iteration 5777, loss = 0.00417482
Iteration 5778, loss = 0.00417372
Iteration 5779, loss = 0.00417256
Iteration 5780, loss = 0.00417156
Iteration 5781, loss = 0.00417044
Iteration 5782, loss = 0.00416957
Iteration 5783, loss = 0.00416899
Iteration 5784, loss = 0.00416778
Iteration 5785, loss = 0.00416665
Iteration 5786, loss = 0.00416560
Iteration 5787, loss = 0.00416487
Iteration 5788, loss = 0.00416376
Iteration 5789, loss = 0.00416296
Iteration 5790, loss = 0.00416167
Iteration 5791, loss = 0.00416057
Iteration 5792, loss = 0.00415951
Iteration 5793, loss = 0.00415861
Iteration 5794, loss = 0.00415785
Iteration 5795, loss = 0.00415649
Iteration 5796, loss = 0.00415553
Iteration 5797, loss = 0.00415443
Iteration 5798, loss = 0.00415345
Iteration 5799, loss = 0.00415259
Iteration 5800, loss = 0.00415143
Iteration 5801, loss = 0.00415020
Iteration 5802, loss = 0.00414918
Iteration 5803, loss = 0.00414807
Iteration 5804, loss = 0.00414700
Iteration 5805, loss = 0.00414597
Iteration 5806, loss = 0.00414496
Iteration 5807, loss = 0.00414386
Iteration 5808, loss = 0.00414281
Iteration 5809, loss = 0.00414176
Iteration 5810, loss = 0.00414074
Iteration 5811, loss = 0.00413985
Iteration 5812, loss = 0.00413885
Iteration 5813, loss = 0.00413780
Iteration 5814, loss = 0.00413678
Iteration 5815, loss = 0.00413600
Iteration 5816, loss = 0.00413471
Iteration 5817, loss = 0.00413396
Iteration 5818, loss = 0.00413294
Iteration 5819, loss = 0.00413188
Iteration 5820, loss = 0.00413094
Iteration 5821, loss = 0.00413001
Iteration 5822, loss = 0.00412905
Iteration 5823, loss = 0.00412813
Iteration 5824, loss = 0.00412738
Iteration 5825, loss = 0.00412614
Iteration 5826, loss = 0.00412524
Iteration 5827, loss = 0.00412418
Iteration 5828, loss = 0.00412315
Iteration 5829, loss = 0.00412208
Iteration 5830, loss = 0.00412130
Iteration 5831, loss = 0.00412021
Iteration 5832, loss = 0.00411922
Iteration 5833, loss = 0.00411824
Iteration 5834, loss = 0.00411731
Iteration 5835, loss = 0.00411629
Iteration 5836, loss = 0.00411575
Iteration 5837, loss = 0.00411433
Iteration 5838, loss = 0.00411359
Iteration 5839, loss = 0.00411222
Iteration 5840, loss = 0.00411117
Iteration 5841, loss = 0.00411021
Iteration 5842, loss = 0.00410906
Iteration 5843, loss = 0.00410806
Iteration 5844, loss = 0.00410714
Iteration 5845, loss = 0.00410595
Iteration 5846, loss = 0.00410498
Iteration 5847, loss = 0.00410412
Iteration 5848, loss = 0.00410302
Iteration 5849, loss = 0.00410221
Iteration 5850, loss = 0.00410115
Iteration 5851, loss = 0.00410039
Iteration 5852, loss = 0.00409915
Iteration 5853, loss = 0.00409807
Iteration 5854, loss = 0.00409765
Iteration 5855, loss = 0.00409589
Iteration 5856, loss = 0.00409484
Iteration 5857, loss = 0.00409349
Iteration 5858, loss = 0.00409299
Iteration 5859, loss = 0.00409124
Iteration 5860, loss = 0.00409014
Iteration 5861, loss = 0.00408889
Iteration 5862, loss = 0.00408773
Iteration 5863, loss = 0.00408692
Iteration 5864, loss = 0.00408569
Iteration 5865, loss = 0.00408463
Iteration 5866, loss = 0.00408337
Iteration 5867, loss = 0.00408249
Iteration 5868, loss = 0.00408154
Iteration 5869, loss = 0.00408046
Iteration 5870, loss = 0.00407955
Iteration 5871, loss = 0.00407847
Iteration 5872, loss = 0.00407756
Iteration 5873, loss = 0.00407651
Iteration 5874, loss = 0.00407563
Iteration 5875, loss = 0.00407462
Iteration 5876, loss = 0.00407348
Iteration 5877, loss = 0.00407263
Iteration 5878, loss = 0.00407155
Iteration 5879, loss = 0.00407047
Iteration 5880, loss = 0.00406946
Iteration 5881, loss = 0.00406844
Iteration 5882, loss = 0.00406754
Iteration 5883, loss = 0.00406662
Iteration 5884, loss = 0.00406553
Iteration 5885, loss = 0.00406453
Iteration 5886, loss = 0.00406370
Iteration 5887, loss = 0.00406278
Iteration 5888, loss = 0.00406176
Iteration 5889, loss = 0.00406084
Iteration 5890, loss = 0.00406013
Iteration 5891, loss = 0.00405876
Iteration 5892, loss = 0.00405767
Iteration 5893, loss = 0.00405669
Iteration 5894, loss = 0.00405600
Iteration 5895, loss = 0.00405482
Iteration 5896, loss = 0.00405460
Iteration 5897, loss = 0.00405303
Iteration 5898, loss = 0.00405213
Iteration 5899, loss = 0.00405108
Iteration 5900, loss = 0.00404988
Iteration 5901, loss = 0.00404949
Iteration 5902, loss = 0.00404797
Iteration 5903, loss = 0.00404692
Iteration 5904, loss = 0.00404597
Iteration 5905, loss = 0.00404493
Iteration 5906, loss = 0.00404391
Iteration 5907, loss = 0.00404297
Iteration 5908, loss = 0.00404206
Iteration 5909, loss = 0.00404088
Iteration 5910, loss = 0.00404001
Iteration 5911, loss = 0.00403930
Iteration 5912, loss = 0.00403825
Iteration 5913, loss = 0.00403722
Iteration 5914, loss = 0.00403624
Iteration 5915, loss = 0.00403514
Iteration 5916, loss = 0.00403405
Iteration 5917, loss = 0.00403287
Iteration 5918, loss = 0.00403169
Iteration 5919, loss = 0.00403055
Iteration 5920, loss = 0.00402970
Iteration 5921, loss = 0.00402925
Iteration 5922, loss = 0.00402776
Iteration 5923, loss = 0.00402689
Iteration 5924, loss = 0.00402576
Iteration 5925, loss = 0.00402465
Iteration 5926, loss = 0.00402377
Iteration 5927, loss = 0.00402259
Iteration 5928, loss = 0.00402192
Iteration 5929, loss = 0.00402073
Iteration 5930, loss = 0.00401986
Iteration 5931, loss = 0.00401893
Iteration 5932, loss = 0.00401793
Iteration 5933, loss = 0.00401709
Iteration 5934, loss = 0.00401605
Iteration 5935, loss = 0.00401525
Iteration 5936, loss = 0.00401424
Iteration 5937, loss = 0.00401378
Iteration 5938, loss = 0.00401245
Iteration 5939, loss = 0.00401164
Iteration 5940, loss = 0.00401036
Iteration 5941, loss = 0.00400937
Iteration 5942, loss = 0.00400840
Iteration 5943, loss = 0.00400740
Iteration 5944, loss = 0.00400642
Iteration 5945, loss = 0.00400547
Iteration 5946, loss = 0.00400447
Iteration 5947, loss = 0.00400359
Iteration 5948, loss = 0.00400254
Iteration 5949, loss = 0.00400157
Iteration 5950, loss = 0.00400067
Iteration 5951, loss = 0.00399958
Iteration 5952, loss = 0.00399867
Iteration 5953, loss = 0.00399757
Iteration 5954, loss = 0.00399661
Iteration 5955, loss = 0.00399546
Iteration 5956, loss = 0.00399450
Iteration 5957, loss = 0.00399377
Iteration 5958, loss = 0.00399278
Iteration 5959, loss = 0.00399151
Iteration 5960, loss = 0.00399039
Iteration 5961, loss = 0.00398990
Iteration 5962, loss = 0.00398839
Iteration 5963, loss = 0.00398774
Iteration 5964, loss = 0.00398626
Iteration 5965, loss = 0.00398521
Iteration 5966, loss = 0.00398434
Iteration 5967, loss = 0.00398324
Iteration 5968, loss = 0.00398238
Iteration 5969, loss = 0.00398138
Iteration 5970, loss = 0.00398057
Iteration 5971, loss = 0.00397969
Iteration 5972, loss = 0.00397879
Iteration 5973, loss = 0.00397785
Iteration 5974, loss = 0.00397685
Iteration 5975, loss = 0.00397614
Iteration 5976, loss = 0.00397515
Iteration 5977, loss = 0.00397451
Iteration 5978, loss = 0.00397315
Iteration 5979, loss = 0.00397225
Iteration 5980, loss = 0.00397125
Iteration 5981, loss = 0.00397044
Iteration 5982, loss = 0.00396937
Iteration 5983, loss = 0.00396852
Iteration 5984, loss = 0.00396744
Iteration 5985, loss = 0.00396660
Iteration 5986, loss = 0.00396566
Iteration 5987, loss = 0.00396465
Iteration 5988, loss = 0.00396417
Iteration 5989, loss = 0.00396300
Iteration 5990, loss = 0.00396189
Iteration 5991, loss = 0.00396124
Iteration 5992, loss = 0.00396002
Iteration 5993, loss = 0.00395894
Iteration 5994, loss = 0.00395807
Iteration 5995, loss = 0.00395744
Iteration 5996, loss = 0.00395616
Iteration 5997, loss = 0.00395551
Iteration 5998, loss = 0.00395437
Iteration 5999, loss = 0.00395342
Iteration 6000, loss = 0.00395269
Iteration 6001, loss = 0.00395162
Iteration 6002, loss = 0.00395067
Iteration 6003, loss = 0.00394967
Iteration 6004, loss = 0.00394878
Iteration 6005, loss = 0.00394804
Iteration 6006, loss = 0.00394690
Iteration 6007, loss = 0.00394594
Iteration 6008, loss = 0.00394497
Iteration 6009, loss = 0.00394399
Iteration 6010, loss = 0.00394306
Iteration 6011, loss = 0.00394230
Iteration 6012, loss = 0.00394138
Iteration 6013, loss = 0.00394030
Iteration 6014, loss = 0.00393956
Iteration 6015, loss = 0.00393848
Iteration 6016, loss = 0.00393752
Iteration 6017, loss = 0.00393661
Iteration 6018, loss = 0.00393562
Iteration 6019, loss = 0.00393476
Iteration 6020, loss = 0.00393374
Iteration 6021, loss = 0.00393273
Iteration 6022, loss = 0.00393176
Iteration 6023, loss = 0.00393167
Iteration 6024, loss = 0.00393041
Iteration 6025, loss = 0.00392932
Iteration 6026, loss = 0.00392865
Iteration 6027, loss = 0.00392773
Iteration 6028, loss = 0.00392697
Iteration 6029, loss = 0.00392598
Iteration 6030, loss = 0.00392502
Iteration 6031, loss = 0.00392433
Iteration 6032, loss = 0.00392350
Iteration 6033, loss = 0.00392251
Iteration 6034, loss = 0.00392172
Iteration 6035, loss = 0.00392088
Iteration 6036, loss = 0.00392007
Iteration 6037, loss = 0.00391908
Iteration 6038, loss = 0.00391818
Iteration 6039, loss = 0.00391738
Iteration 6040, loss = 0.00391651
Iteration 6041, loss = 0.00391566
Iteration 6042, loss = 0.00391473
Iteration 6043, loss = 0.00391374
Iteration 6044, loss = 0.00391330
Iteration 6045, loss = 0.00391205
Iteration 6046, loss = 0.00391118
Iteration 6047, loss = 0.00391016
Iteration 6048, loss = 0.00390915
Iteration 6049, loss = 0.00390840
Iteration 6050, loss = 0.00390736
Iteration 6051, loss = 0.00390640
Iteration 6052, loss = 0.00390572
Iteration 6053, loss = 0.00390478
Iteration 6054, loss = 0.00390395
Iteration 6055, loss = 0.00390358
Iteration 6056, loss = 0.00390248
Iteration 6057, loss = 0.00390137
Iteration 6058, loss = 0.00390054
Iteration 6059, loss = 0.00389961
Iteration 6060, loss = 0.00389878
Iteration 6061, loss = 0.00389799
Iteration 6062, loss = 0.00389706
Iteration 6063, loss = 0.00389641
Iteration 6064, loss = 0.00389539
Iteration 6065, loss = 0.00389454
Iteration 6066, loss = 0.00389389
Iteration 6067, loss = 0.00389292
Iteration 6068, loss = 0.00389196
Iteration 6069, loss = 0.00389110
Iteration 6070, loss = 0.00389029
Iteration 6071, loss = 0.00388941
Iteration 6072, loss = 0.00388848
Iteration 6073, loss = 0.00388843
Iteration 6074, loss = 0.00388692
Iteration 6075, loss = 0.00388619
Iteration 6076, loss = 0.00388540
Iteration 6077, loss = 0.00388436
Iteration 6078, loss = 0.00388369
Iteration 6079, loss = 0.00388277
Iteration 6080, loss = 0.00388189
Iteration 6081, loss = 0.00388096
Iteration 6082, loss = 0.00388000
Iteration 6083, loss = 0.00387922
Iteration 6084, loss = 0.00387845
Iteration 6085, loss = 0.00387766
Iteration 6086, loss = 0.00387660
Iteration 6087, loss = 0.00387656
Iteration 6088, loss = 0.00387522
Iteration 6089, loss = 0.00387431
Iteration 6090, loss = 0.00387353
Iteration 6091, loss = 0.00387288
Iteration 6092, loss = 0.00387235
Iteration 6093, loss = 0.00387115
Iteration 6094, loss = 0.00387026
Iteration 6095, loss = 0.00386937
Iteration 6096, loss = 0.00386842
Iteration 6097, loss = 0.00386782
Iteration 6098, loss = 0.00386668
Iteration 6099, loss = 0.00386576
Iteration 6100, loss = 0.00386495
Iteration 6101, loss = 0.00386393
Iteration 6102, loss = 0.00386316
Iteration 6103, loss = 0.00386228
Iteration 6104, loss = 0.00386149
Iteration 6105, loss = 0.00386076
Iteration 6106, loss = 0.00386011
Iteration 6107, loss = 0.00385917
Iteration 6108, loss = 0.00385896
Iteration 6109, loss = 0.00385755
Iteration 6110, loss = 0.00385638
Iteration 6111, loss = 0.00385538
Iteration 6112, loss = 0.00385447
Iteration 6113, loss = 0.00385356
Iteration 6114, loss = 0.00385248
Iteration 6115, loss = 0.00385165
Iteration 6116, loss = 0.00385073
Iteration 6117, loss = 0.00384968
Iteration 6118, loss = 0.00384878
Iteration 6119, loss = 0.00384785
Iteration 6120, loss = 0.00384705
Iteration 6121, loss = 0.00384618
Iteration 6122, loss = 0.00384526
Iteration 6123, loss = 0.00384425
Iteration 6124, loss = 0.00384341
Iteration 6125, loss = 0.00384255
Iteration 6126, loss = 0.00384168
Iteration 6127, loss = 0.00384059
Iteration 6128, loss = 0.00383946
Iteration 6129, loss = 0.00383917
Iteration 6130, loss = 0.00383770
Iteration 6131, loss = 0.00383668
Iteration 6132, loss = 0.00383576
Iteration 6133, loss = 0.00383474
Iteration 6134, loss = 0.00383398
Iteration 6135, loss = 0.00383284
Iteration 6136, loss = 0.00383194
Iteration 6137, loss = 0.00383125
Iteration 6138, loss = 0.00383025
Iteration 6139, loss = 0.00382968
Iteration 6140, loss = 0.00382858
Iteration 6141, loss = 0.00382780
Iteration 6142, loss = 0.00382694
Iteration 6143, loss = 0.00382615
Iteration 6144, loss = 0.00382526
Iteration 6145, loss = 0.00382446
Iteration 6146, loss = 0.00382329
Iteration 6147, loss = 0.00382266
Iteration 6148, loss = 0.00382185
Iteration 6149, loss = 0.00382056
Iteration 6150, loss = 0.00381960
Iteration 6151, loss = 0.00381873
Iteration 6152, loss = 0.00381794
Iteration 6153, loss = 0.00381694
Iteration 6154, loss = 0.00381688
Iteration 6155, loss = 0.00381513
Iteration 6156, loss = 0.00381412
Iteration 6157, loss = 0.00381326
Iteration 6158, loss = 0.00381237
Iteration 6159, loss = 0.00381142
Iteration 6160, loss = 0.00381069
Iteration 6161, loss = 0.00380980
Iteration 6162, loss = 0.00380861
Iteration 6163, loss = 0.00380810
Iteration 6164, loss = 0.00380692
Iteration 6165, loss = 0.00380579
Iteration 6166, loss = 0.00380491
Iteration 6167, loss = 0.00380399
Iteration 6168, loss = 0.00380305
Iteration 6169, loss = 0.00380214
Iteration 6170, loss = 0.00380138
Iteration 6171, loss = 0.00380036
Iteration 6172, loss = 0.00379940
Iteration 6173, loss = 0.00379843
Iteration 6174, loss = 0.00379756
Iteration 6175, loss = 0.00379668
Iteration 6176, loss = 0.00379568
Iteration 6177, loss = 0.00379505
Iteration 6178, loss = 0.00379379
Iteration 6179, loss = 0.00379301
Iteration 6180, loss = 0.00379208
Iteration 6181, loss = 0.00379123
Iteration 6182, loss = 0.00379030
Iteration 6183, loss = 0.00378936
Iteration 6184, loss = 0.00378857
Iteration 6185, loss = 0.00378773
Iteration 6186, loss = 0.00378694
Iteration 6187, loss = 0.00378600
Iteration 6188, loss = 0.00378511
Iteration 6189, loss = 0.00378424
Iteration 6190, loss = 0.00378343
Iteration 6191, loss = 0.00378278
Iteration 6192, loss = 0.00378170
Iteration 6193, loss = 0.00378085
Iteration 6194, loss = 0.00377989
Iteration 6195, loss = 0.00377898
Iteration 6196, loss = 0.00377802
Iteration 6197, loss = 0.00377716
Iteration 6198, loss = 0.00377615
Iteration 6199, loss = 0.00377528
Iteration 6200, loss = 0.00377438
Iteration 6201, loss = 0.00377343
Iteration 6202, loss = 0.00377258
Iteration 6203, loss = 0.00377177
Iteration 6204, loss = 0.00377064
Iteration 6205, loss = 0.00376965
Iteration 6206, loss = 0.00376926
Iteration 6207, loss = 0.00376788
Iteration 6208, loss = 0.00376701
Iteration 6209, loss = 0.00376660
Iteration 6210, loss = 0.00376532
Iteration 6211, loss = 0.00376441
Iteration 6212, loss = 0.00376347
Iteration 6213, loss = 0.00376255
Iteration 6214, loss = 0.00376162
Iteration 6215, loss = 0.00376085
Iteration 6216, loss = 0.00375984
Iteration 6217, loss = 0.00375897
Iteration 6218, loss = 0.00375824
Iteration 6219, loss = 0.00375733
Iteration 6220, loss = 0.00375638
Iteration 6221, loss = 0.00375568
Iteration 6222, loss = 0.00375483
Iteration 6223, loss = 0.00375440
Iteration 6224, loss = 0.00375285
Iteration 6225, loss = 0.00375192
Iteration 6226, loss = 0.00375116
Iteration 6227, loss = 0.00374996
Iteration 6228, loss = 0.00374915
Iteration 6229, loss = 0.00374834
Iteration 6230, loss = 0.00374773
Iteration 6231, loss = 0.00374676
Iteration 6232, loss = 0.00374564
Iteration 6233, loss = 0.00374499
Iteration 6234, loss = 0.00374401
Iteration 6235, loss = 0.00374291
Iteration 6236, loss = 0.00374205
Iteration 6237, loss = 0.00374110
Iteration 6238, loss = 0.00374028
Iteration 6239, loss = 0.00373959
Iteration 6240, loss = 0.00373847
Iteration 6241, loss = 0.00373762
Iteration 6242, loss = 0.00373676
Iteration 6243, loss = 0.00373593
Iteration 6244, loss = 0.00373509
Iteration 6245, loss = 0.00373425
Iteration 6246, loss = 0.00373350
Iteration 6247, loss = 0.00373252
Iteration 6248, loss = 0.00373169
Iteration 6249, loss = 0.00373094
Iteration 6250, loss = 0.00373008
Iteration 6251, loss = 0.00372939
Iteration 6252, loss = 0.00372857
Iteration 6253, loss = 0.00372778
Iteration 6254, loss = 0.00372694
Iteration 6255, loss = 0.00372637
Iteration 6256, loss = 0.00372546
Iteration 6257, loss = 0.00372486
Iteration 6258, loss = 0.00372404
Iteration 6259, loss = 0.00372308
Iteration 6260, loss = 0.00372231
Iteration 6261, loss = 0.00372162
Iteration 6262, loss = 0.00372082
Iteration 6263, loss = 0.00372017
Iteration 6264, loss = 0.00371941
Iteration 6265, loss = 0.00371935
Iteration 6266, loss = 0.00371812
Iteration 6267, loss = 0.00371737
Iteration 6268, loss = 0.00371672
Iteration 6269, loss = 0.00371591
Iteration 6270, loss = 0.00371515
Iteration 6271, loss = 0.00371439
Iteration 6272, loss = 0.00371369
Iteration 6273, loss = 0.00371341
Iteration 6274, loss = 0.00371222
Iteration 6275, loss = 0.00371127
Iteration 6276, loss = 0.00371053
Iteration 6277, loss = 0.00370950
Iteration 6278, loss = 0.00370903
Iteration 6279, loss = 0.00370778
Iteration 6280, loss = 0.00370712
Iteration 6281, loss = 0.00370599
Iteration 6282, loss = 0.00370500
Iteration 6283, loss = 0.00370430
Iteration 6284, loss = 0.00370381
Iteration 6285, loss = 0.00370265
Iteration 6286, loss = 0.00370177
Iteration 6287, loss = 0.00370101
Iteration 6288, loss = 0.00370023
Iteration 6289, loss = 0.00369943
Iteration 6290, loss = 0.00369864
Iteration 6291, loss = 0.00369788
Iteration 6292, loss = 0.00369713
Iteration 6293, loss = 0.00369637
Iteration 6294, loss = 0.00369549
Iteration 6295, loss = 0.00369464
Iteration 6296, loss = 0.00369381
Iteration 6297, loss = 0.00369305
Iteration 6298, loss = 0.00369223
Iteration 6299, loss = 0.00369156
Iteration 6300, loss = 0.00369067
Iteration 6301, loss = 0.00368986
Iteration 6302, loss = 0.00368949
Iteration 6303, loss = 0.00368851
Iteration 6304, loss = 0.00368775
Iteration 6305, loss = 0.00368699
Iteration 6306, loss = 0.00368613
Iteration 6307, loss = 0.00368544
Iteration 6308, loss = 0.00368466
Iteration 6309, loss = 0.00368395
Iteration 6310, loss = 0.00368317
Iteration 6311, loss = 0.00368250
Iteration 6312, loss = 0.00368157
Iteration 6313, loss = 0.00368085
Iteration 6314, loss = 0.00368015
Iteration 6315, loss = 0.00367941
Iteration 6316, loss = 0.00367860
Iteration 6317, loss = 0.00367772
Iteration 6318, loss = 0.00367690
Iteration 6319, loss = 0.00367616
Iteration 6320, loss = 0.00367530
Iteration 6321, loss = 0.00367442
Iteration 6322, loss = 0.00367368
Iteration 6323, loss = 0.00367292
Iteration 6324, loss = 0.00367211
Iteration 6325, loss = 0.00367120
Iteration 6326, loss = 0.00367055
Iteration 6327, loss = 0.00366978
Iteration 6328, loss = 0.00366920
Iteration 6329, loss = 0.00366834
Iteration 6330, loss = 0.00366745
Iteration 6331, loss = 0.00366747
Iteration 6332, loss = 0.00366627
Iteration 6333, loss = 0.00366543
Iteration 6334, loss = 0.00366448
Iteration 6335, loss = 0.00366438
Iteration 6336, loss = 0.00366330
Iteration 6337, loss = 0.00366283
Iteration 6338, loss = 0.00366202
Iteration 6339, loss = 0.00366101
Iteration 6340, loss = 0.00366028
Iteration 6341, loss = 0.00365939
Iteration 6342, loss = 0.00365877
Iteration 6343, loss = 0.00365790
Iteration 6344, loss = 0.00365721
Iteration 6345, loss = 0.00365632
Iteration 6346, loss = 0.00365549
Iteration 6347, loss = 0.00365469
Iteration 6348, loss = 0.00365391
Iteration 6349, loss = 0.00365294
Iteration 6350, loss = 0.00365201
Iteration 6351, loss = 0.00365103
Iteration 6352, loss = 0.00364993
Iteration 6353, loss = 0.00364893
Iteration 6354, loss = 0.00364777
Iteration 6355, loss = 0.00364694
Iteration 6356, loss = 0.00364675
Iteration 6357, loss = 0.00364506
Iteration 6358, loss = 0.00364417
Iteration 6359, loss = 0.00364326
Iteration 6360, loss = 0.00364252
Iteration 6361, loss = 0.00364159
Iteration 6362, loss = 0.00364065
Iteration 6363, loss = 0.00363976
Iteration 6364, loss = 0.00363864
Iteration 6365, loss = 0.00363767
Iteration 6366, loss = 0.00363692
Iteration 6367, loss = 0.00363582
Iteration 6368, loss = 0.00363495
Iteration 6369, loss = 0.00363398
Iteration 6370, loss = 0.00363296
Iteration 6371, loss = 0.00363210
Iteration 6372, loss = 0.00363130
Iteration 6373, loss = 0.00363050
Iteration 6374, loss = 0.00362962
Iteration 6375, loss = 0.00362887
Iteration 6376, loss = 0.00362818
Iteration 6377, loss = 0.00362724
Iteration 6378, loss = 0.00362667
Iteration 6379, loss = 0.00362566
Iteration 6380, loss = 0.00362478
Iteration 6381, loss = 0.00362389
Iteration 6382, loss = 0.00362304
Iteration 6383, loss = 0.00362215
Iteration 6384, loss = 0.00362150
Iteration 6385, loss = 0.00362038
Iteration 6386, loss = 0.00361943
Iteration 6387, loss = 0.00361868
Iteration 6388, loss = 0.00361776
Iteration 6389, loss = 0.00361767
Iteration 6390, loss = 0.00361617
Iteration 6391, loss = 0.00361539
Iteration 6392, loss = 0.00361458
Iteration 6393, loss = 0.00361369
Iteration 6394, loss = 0.00361319
Iteration 6395, loss = 0.00361222
Iteration 6396, loss = 0.00361135
Iteration 6397, loss = 0.00361038
Iteration 6398, loss = 0.00360956
Iteration 6399, loss = 0.00360886
Iteration 6400, loss = 0.00360784
Iteration 6401, loss = 0.00360701
Iteration 6402, loss = 0.00360672
Iteration 6403, loss = 0.00360525
Iteration 6404, loss = 0.00360442
Iteration 6405, loss = 0.00360351
Iteration 6406, loss = 0.00360266
Iteration 6407, loss = 0.00360182
Iteration 6408, loss = 0.00360100
Iteration 6409, loss = 0.00360017
Iteration 6410, loss = 0.00359940
Iteration 6411, loss = 0.00359893
Iteration 6412, loss = 0.00359791
Iteration 6413, loss = 0.00359717
Iteration 6414, loss = 0.00359638
Iteration 6415, loss = 0.00359552
Iteration 6416, loss = 0.00359504
Iteration 6417, loss = 0.00359419
Iteration 6418, loss = 0.00359306
Iteration 6419, loss = 0.00359224
Iteration 6420, loss = 0.00359136
Iteration 6421, loss = 0.00359071
Iteration 6422, loss = 0.00358978
Iteration 6423, loss = 0.00358882
Iteration 6424, loss = 0.00358800
Iteration 6425, loss = 0.00358729
Iteration 6426, loss = 0.00358665
Iteration 6427, loss = 0.00358573
Iteration 6428, loss = 0.00358488
Iteration 6429, loss = 0.00358407
Iteration 6430, loss = 0.00358325
Iteration 6431, loss = 0.00358277
Iteration 6432, loss = 0.00358178
Iteration 6433, loss = 0.00358108
Iteration 6434, loss = 0.00358018
Iteration 6435, loss = 0.00357926
Iteration 6436, loss = 0.00357867
Iteration 6437, loss = 0.00357764
Iteration 6438, loss = 0.00357680
Iteration 6439, loss = 0.00357599
Iteration 6440, loss = 0.00357518
Iteration 6441, loss = 0.00357442
Iteration 6442, loss = 0.00357367
Iteration 6443, loss = 0.00357295
Iteration 6444, loss = 0.00357242
Iteration 6445, loss = 0.00357159
Iteration 6446, loss = 0.00357094
Iteration 6447, loss = 0.00357019
Iteration 6448, loss = 0.00356957
Iteration 6449, loss = 0.00356874
Iteration 6450, loss = 0.00356796
Iteration 6451, loss = 0.00356707
Iteration 6452, loss = 0.00356651
Iteration 6453, loss = 0.00356555
Iteration 6454, loss = 0.00356473
Iteration 6455, loss = 0.00356380
Iteration 6456, loss = 0.00356304
Iteration 6457, loss = 0.00356215
Iteration 6458, loss = 0.00356149
Iteration 6459, loss = 0.00356066
Iteration 6460, loss = 0.00355986
Iteration 6461, loss = 0.00355933
Iteration 6462, loss = 0.00355838
Iteration 6463, loss = 0.00355764
Iteration 6464, loss = 0.00355692
Iteration 6465, loss = 0.00355626
Iteration 6466, loss = 0.00355536
Iteration 6467, loss = 0.00355457
Iteration 6468, loss = 0.00355387
Iteration 6469, loss = 0.00355310
Iteration 6470, loss = 0.00355229
Iteration 6471, loss = 0.00355159
Iteration 6472, loss = 0.00355067
Iteration 6473, loss = 0.00354982
Iteration 6474, loss = 0.00354908
Iteration 6475, loss = 0.00354825
Iteration 6476, loss = 0.00354742
Iteration 6477, loss = 0.00354656
Iteration 6478, loss = 0.00354578
Iteration 6479, loss = 0.00354504
Iteration 6480, loss = 0.00354423
Iteration 6481, loss = 0.00354325
Iteration 6482, loss = 0.00354267
Iteration 6483, loss = 0.00354169
Iteration 6484, loss = 0.00354097
Iteration 6485, loss = 0.00354015
Iteration 6486, loss = 0.00353944
Iteration 6487, loss = 0.00353869
Iteration 6488, loss = 0.00353798
Iteration 6489, loss = 0.00353729
Iteration 6490, loss = 0.00353653
Iteration 6491, loss = 0.00353568
Iteration 6492, loss = 0.00353487
Iteration 6493, loss = 0.00353410
Iteration 6494, loss = 0.00353321
Iteration 6495, loss = 0.00353234
Iteration 6496, loss = 0.00353161
Iteration 6497, loss = 0.00353091
Iteration 6498, loss = 0.00353004
Iteration 6499, loss = 0.00352930
Iteration 6500, loss = 0.00352849
Iteration 6501, loss = 0.00352773
Iteration 6502, loss = 0.00352701
Iteration 6503, loss = 0.00352693
Iteration 6504, loss = 0.00352582
Iteration 6505, loss = 0.00352493
Iteration 6506, loss = 0.00352428
Iteration 6507, loss = 0.00352332
Iteration 6508, loss = 0.00352269
Iteration 6509, loss = 0.00352192
Iteration 6510, loss = 0.00352105
Iteration 6511, loss = 0.00352034
Iteration 6512, loss = 0.00351967
Iteration 6513, loss = 0.00351886
Iteration 6514, loss = 0.00351829
Iteration 6515, loss = 0.00351781
Iteration 6516, loss = 0.00351667
Iteration 6517, loss = 0.00351595
Iteration 6518, loss = 0.00351512
Iteration 6519, loss = 0.00351428
Iteration 6520, loss = 0.00351344
Iteration 6521, loss = 0.00351249
Iteration 6522, loss = 0.00351196
Iteration 6523, loss = 0.00351119
Iteration 6524, loss = 0.00351042
Iteration 6525, loss = 0.00350953
Iteration 6526, loss = 0.00350855
Iteration 6527, loss = 0.00350793
Iteration 6528, loss = 0.00350687
Iteration 6529, loss = 0.00350623
Iteration 6530, loss = 0.00350533
Iteration 6531, loss = 0.00350446
Iteration 6532, loss = 0.00350365
Iteration 6533, loss = 0.00350306
Iteration 6534, loss = 0.00350223
Iteration 6535, loss = 0.00350140
Iteration 6536, loss = 0.00350065
Iteration 6537, loss = 0.00349982
Iteration 6538, loss = 0.00349920
Iteration 6539, loss = 0.00349836
Iteration 6540, loss = 0.00349790
Iteration 6541, loss = 0.00349702
Iteration 6542, loss = 0.00349647
Iteration 6543, loss = 0.00349562
Iteration 6544, loss = 0.00349492
Iteration 6545, loss = 0.00349414
Iteration 6546, loss = 0.00349348
Iteration 6547, loss = 0.00349286
Iteration 6548, loss = 0.00349269
Iteration 6549, loss = 0.00349139
Iteration 6550, loss = 0.00349071
Iteration 6551, loss = 0.00348995
Iteration 6552, loss = 0.00348918
Iteration 6553, loss = 0.00348824
Iteration 6554, loss = 0.00348761
Iteration 6555, loss = 0.00348693
Iteration 6556, loss = 0.00348603
Iteration 6557, loss = 0.00348518
Iteration 6558, loss = 0.00348442
Iteration 6559, loss = 0.00348384
Iteration 6560, loss = 0.00348308
Iteration 6561, loss = 0.00348216
Iteration 6562, loss = 0.00348131
Iteration 6563, loss = 0.00348058
Iteration 6564, loss = 0.00347973
Iteration 6565, loss = 0.00347895
Iteration 6566, loss = 0.00347808
Iteration 6567, loss = 0.00347741
Iteration 6568, loss = 0.00347665
Iteration 6569, loss = 0.00347574
Iteration 6570, loss = 0.00347527
Iteration 6571, loss = 0.00347441
Iteration 6572, loss = 0.00347369
Iteration 6573, loss = 0.00347285
Iteration 6574, loss = 0.00347215
Iteration 6575, loss = 0.00347149
Iteration 6576, loss = 0.00347071
Iteration 6577, loss = 0.00347005
Iteration 6578, loss = 0.00346923
Iteration 6579, loss = 0.00346852
Iteration 6580, loss = 0.00346771
Iteration 6581, loss = 0.00346704
Iteration 6582, loss = 0.00346630
Iteration 6583, loss = 0.00346548
Iteration 6584, loss = 0.00346464
Iteration 6585, loss = 0.00346386
Iteration 6586, loss = 0.00346309
Iteration 6587, loss = 0.00346238
Iteration 6588, loss = 0.00346151
Iteration 6589, loss = 0.00346078
Iteration 6590, loss = 0.00346006
Iteration 6591, loss = 0.00345912
Iteration 6592, loss = 0.00345867
Iteration 6593, loss = 0.00345762
Iteration 6594, loss = 0.00345693
Iteration 6595, loss = 0.00345611
Iteration 6596, loss = 0.00345562
Iteration 6597, loss = 0.00345477
Iteration 6598, loss = 0.00345378
Iteration 6599, loss = 0.00345297
Iteration 6600, loss = 0.00345217
Iteration 6601, loss = 0.00345137
Iteration 6602, loss = 0.00345078
Iteration 6603, loss = 0.00344997
Iteration 6604, loss = 0.00344954
Iteration 6605, loss = 0.00344849
Iteration 6606, loss = 0.00344805
Iteration 6607, loss = 0.00344700
Iteration 6608, loss = 0.00344624
Iteration 6609, loss = 0.00344549
Iteration 6610, loss = 0.00344483
Iteration 6611, loss = 0.00344418
Iteration 6612, loss = 0.00344366
Iteration 6613, loss = 0.00344288
Iteration 6614, loss = 0.00344227
Iteration 6615, loss = 0.00344154
Iteration 6616, loss = 0.00344088
Iteration 6617, loss = 0.00344022
Iteration 6618, loss = 0.00343955
Iteration 6619, loss = 0.00343889
Iteration 6620, loss = 0.00343846
Iteration 6621, loss = 0.00343755
Iteration 6622, loss = 0.00343682
Iteration 6623, loss = 0.00343615
Iteration 6624, loss = 0.00343574
Iteration 6625, loss = 0.00343485
Iteration 6626, loss = 0.00343404
Iteration 6627, loss = 0.00343327
Iteration 6628, loss = 0.00343250
Iteration 6629, loss = 0.00343218
Iteration 6630, loss = 0.00343127
Iteration 6631, loss = 0.00343069
Iteration 6632, loss = 0.00342976
Iteration 6633, loss = 0.00342885
Iteration 6634, loss = 0.00342823
Iteration 6635, loss = 0.00342756
Iteration 6636, loss = 0.00342664
Iteration 6637, loss = 0.00342604
Iteration 6638, loss = 0.00342548
Iteration 6639, loss = 0.00342457
Iteration 6640, loss = 0.00342382
Iteration 6641, loss = 0.00342329
Iteration 6642, loss = 0.00342235
Iteration 6643, loss = 0.00342166
Iteration 6644, loss = 0.00342094
Iteration 6645, loss = 0.00342028
Iteration 6646, loss = 0.00341946
Iteration 6647, loss = 0.00341855
Iteration 6648, loss = 0.00341812
Iteration 6649, loss = 0.00341704
Iteration 6650, loss = 0.00341629
Iteration 6651, loss = 0.00341555
Iteration 6652, loss = 0.00341491
Iteration 6653, loss = 0.00341402
Iteration 6654, loss = 0.00341319
Iteration 6655, loss = 0.00341237
Iteration 6656, loss = 0.00341182
Iteration 6657, loss = 0.00341099
Iteration 6658, loss = 0.00341031
Iteration 6659, loss = 0.00340994
Iteration 6660, loss = 0.00340897
Iteration 6661, loss = 0.00340824
Iteration 6662, loss = 0.00340752
Iteration 6663, loss = 0.00340682
Iteration 6664, loss = 0.00340609
Iteration 6665, loss = 0.00340535
Iteration 6666, loss = 0.00340506
Iteration 6667, loss = 0.00340403
Iteration 6668, loss = 0.00340340
Iteration 6669, loss = 0.00340265
Iteration 6670, loss = 0.00340200
Iteration 6671, loss = 0.00340138
Iteration 6672, loss = 0.00340073
Iteration 6673, loss = 0.00340007
Iteration 6674, loss = 0.00339958
Iteration 6675, loss = 0.00339861
Iteration 6676, loss = 0.00339783
Iteration 6677, loss = 0.00339702
Iteration 6678, loss = 0.00339642
Iteration 6679, loss = 0.00339555
Iteration 6680, loss = 0.00339477
Iteration 6681, loss = 0.00339433
Iteration 6682, loss = 0.00339337
Iteration 6683, loss = 0.00339296
Iteration 6684, loss = 0.00339202
Iteration 6685, loss = 0.00339138
Iteration 6686, loss = 0.00339071
Iteration 6687, loss = 0.00338995
Iteration 6688, loss = 0.00338932
Iteration 6689, loss = 0.00338872
Iteration 6690, loss = 0.00338800
Iteration 6691, loss = 0.00338727
Iteration 6692, loss = 0.00338652
Iteration 6693, loss = 0.00338589
Iteration 6694, loss = 0.00338525
Iteration 6695, loss = 0.00338455
Iteration 6696, loss = 0.00338388
Iteration 6697, loss = 0.00338339
Iteration 6698, loss = 0.00338253
Iteration 6699, loss = 0.00338186
Iteration 6700, loss = 0.00338109
Iteration 6701, loss = 0.00338087
Iteration 6702, loss = 0.00337952
Iteration 6703, loss = 0.00337897
Iteration 6704, loss = 0.00337815
Iteration 6705, loss = 0.00337747
Iteration 6706, loss = 0.00337660
Iteration 6707, loss = 0.00337580
Iteration 6708, loss = 0.00337512
Iteration 6709, loss = 0.00337425
Iteration 6710, loss = 0.00337350
Iteration 6711, loss = 0.00337281
Iteration 6712, loss = 0.00337200
Iteration 6713, loss = 0.00337137
Iteration 6714, loss = 0.00337071
Iteration 6715, loss = 0.00336983
Iteration 6716, loss = 0.00336967
Iteration 6717, loss = 0.00336840
Iteration 6718, loss = 0.00336775
Iteration 6719, loss = 0.00336707
Iteration 6720, loss = 0.00336621
Iteration 6721, loss = 0.00336546
Iteration 6722, loss = 0.00336483
Iteration 6723, loss = 0.00336402
Iteration 6724, loss = 0.00336324
Iteration 6725, loss = 0.00336254
Iteration 6726, loss = 0.00336183
Iteration 6727, loss = 0.00336108
Iteration 6728, loss = 0.00336028
Iteration 6729, loss = 0.00335956
Iteration 6730, loss = 0.00335883
Iteration 6731, loss = 0.00335805
Iteration 6732, loss = 0.00335739
Iteration 6733, loss = 0.00335656
Iteration 6734, loss = 0.00335570
Iteration 6735, loss = 0.00335494
Iteration 6736, loss = 0.00335430
Iteration 6737, loss = 0.00335354
Iteration 6738, loss = 0.00335280
Iteration 6739, loss = 0.00335212
Iteration 6740, loss = 0.00335154
Iteration 6741, loss = 0.00335093
Iteration 6742, loss = 0.00335026
Iteration 6743, loss = 0.00334963
Iteration 6744, loss = 0.00334905
Iteration 6745, loss = 0.00334842
Iteration 6746, loss = 0.00334779
Iteration 6747, loss = 0.00334722
Iteration 6748, loss = 0.00334662
Iteration 6749, loss = 0.00334595
Iteration 6750, loss = 0.00334533
Iteration 6751, loss = 0.00334470
Iteration 6752, loss = 0.00334400
Iteration 6753, loss = 0.00334323
Iteration 6754, loss = 0.00334256
Iteration 6755, loss = 0.00334179
Iteration 6756, loss = 0.00334124
Iteration 6757, loss = 0.00334048
Iteration 6758, loss = 0.00334000
Iteration 6759, loss = 0.00333920
Iteration 6760, loss = 0.00333843
Iteration 6761, loss = 0.00333794
Iteration 6762, loss = 0.00333703
Iteration 6763, loss = 0.00333635
Iteration 6764, loss = 0.00333561
Iteration 6765, loss = 0.00333485
Iteration 6766, loss = 0.00333422
Iteration 6767, loss = 0.00333372
Iteration 6768, loss = 0.00333290
Iteration 6769, loss = 0.00333220
Iteration 6770, loss = 0.00333154
Iteration 6771, loss = 0.00333086
Iteration 6772, loss = 0.00333013
Iteration 6773, loss = 0.00332964
Iteration 6774, loss = 0.00332880
Iteration 6775, loss = 0.00332798
Iteration 6776, loss = 0.00332739
Iteration 6777, loss = 0.00332656
Iteration 6778, loss = 0.00332583
Iteration 6779, loss = 0.00332500
Iteration 6780, loss = 0.00332424
Iteration 6781, loss = 0.00332351
Iteration 6782, loss = 0.00332298
Iteration 6783, loss = 0.00332202
Iteration 6784, loss = 0.00332134
Iteration 6785, loss = 0.00332068
Iteration 6786, loss = 0.00331988
Iteration 6787, loss = 0.00331916
Iteration 6788, loss = 0.00331847
Iteration 6789, loss = 0.00331781
Iteration 6790, loss = 0.00331694
Iteration 6791, loss = 0.00331633
Iteration 6792, loss = 0.00331561
Iteration 6793, loss = 0.00331508
Iteration 6794, loss = 0.00331420
Iteration 6795, loss = 0.00331364
Iteration 6796, loss = 0.00331293
Iteration 6797, loss = 0.00331209
Iteration 6798, loss = 0.00331142
Iteration 6799, loss = 0.00331075
Iteration 6800, loss = 0.00331012
Iteration 6801, loss = 0.00330958
Iteration 6802, loss = 0.00330888
Iteration 6803, loss = 0.00330825
Iteration 6804, loss = 0.00330756
Iteration 6805, loss = 0.00330702
Iteration 6806, loss = 0.00330640
Iteration 6807, loss = 0.00330599
Iteration 6808, loss = 0.00330522
Iteration 6809, loss = 0.00330450
Iteration 6810, loss = 0.00330382
Iteration 6811, loss = 0.00330338
Iteration 6812, loss = 0.00330282
Iteration 6813, loss = 0.00330216
Iteration 6814, loss = 0.00330152
Iteration 6815, loss = 0.00330091
Iteration 6816, loss = 0.00330057
Iteration 6817, loss = 0.00329965
Iteration 6818, loss = 0.00329902
Iteration 6819, loss = 0.00329841
Iteration 6820, loss = 0.00329769
Iteration 6821, loss = 0.00329709
Iteration 6822, loss = 0.00329646
Iteration 6823, loss = 0.00329579
Iteration 6824, loss = 0.00329507
Iteration 6825, loss = 0.00329436
Iteration 6826, loss = 0.00329356
Iteration 6827, loss = 0.00329298
Iteration 6828, loss = 0.00329220
Iteration 6829, loss = 0.00329149
Iteration 6830, loss = 0.00329071
Iteration 6831, loss = 0.00329012
Iteration 6832, loss = 0.00328941
Iteration 6833, loss = 0.00328887
Iteration 6834, loss = 0.00328795
Iteration 6835, loss = 0.00328723
Iteration 6836, loss = 0.00328652
Iteration 6837, loss = 0.00328579
Iteration 6838, loss = 0.00328511
Iteration 6839, loss = 0.00328418
Iteration 6840, loss = 0.00328392
Iteration 6841, loss = 0.00328340
Iteration 6842, loss = 0.00328228
Iteration 6843, loss = 0.00328150
Iteration 6844, loss = 0.00328073
Iteration 6845, loss = 0.00328015
Iteration 6846, loss = 0.00327947
Iteration 6847, loss = 0.00327863
Iteration 6848, loss = 0.00327790
Iteration 6849, loss = 0.00327716
Iteration 6850, loss = 0.00327655
Iteration 6851, loss = 0.00327580
Iteration 6852, loss = 0.00327511
Iteration 6853, loss = 0.00327447
Iteration 6854, loss = 0.00327383
Iteration 6855, loss = 0.00327311
Iteration 6856, loss = 0.00327256
Iteration 6857, loss = 0.00327201
Iteration 6858, loss = 0.00327111
Iteration 6859, loss = 0.00327061
Iteration 6860, loss = 0.00326975
Iteration 6861, loss = 0.00326937
Iteration 6862, loss = 0.00326840
Iteration 6863, loss = 0.00326770
Iteration 6864, loss = 0.00326701
Iteration 6865, loss = 0.00326646
Iteration 6866, loss = 0.00326571
Iteration 6867, loss = 0.00326492
Iteration 6868, loss = 0.00326451
Iteration 6869, loss = 0.00326372
Iteration 6870, loss = 0.00326315
Iteration 6871, loss = 0.00326249
Iteration 6872, loss = 0.00326229
Iteration 6873, loss = 0.00326122
Iteration 6874, loss = 0.00326055
Iteration 6875, loss = 0.00325995
Iteration 6876, loss = 0.00325920
Iteration 6877, loss = 0.00325860
Iteration 6878, loss = 0.00325833
Iteration 6879, loss = 0.00325731
Iteration 6880, loss = 0.00325658
Iteration 6881, loss = 0.00325595
Iteration 6882, loss = 0.00325536
Iteration 6883, loss = 0.00325459
Iteration 6884, loss = 0.00325402
Iteration 6885, loss = 0.00325335
Iteration 6886, loss = 0.00325274
Iteration 6887, loss = 0.00325199
Iteration 6888, loss = 0.00325137
Iteration 6889, loss = 0.00325074
Iteration 6890, loss = 0.00325004
Iteration 6891, loss = 0.00324950
Iteration 6892, loss = 0.00324899
Iteration 6893, loss = 0.00324826
Iteration 6894, loss = 0.00324762
Iteration 6895, loss = 0.00324697
Iteration 6896, loss = 0.00324648
Iteration 6897, loss = 0.00324592
Iteration 6898, loss = 0.00324512
Iteration 6899, loss = 0.00324457
Iteration 6900, loss = 0.00324379
Iteration 6901, loss = 0.00324318
Iteration 6902, loss = 0.00324269
Iteration 6903, loss = 0.00324187
Iteration 6904, loss = 0.00324110
Iteration 6905, loss = 0.00324081
Iteration 6906, loss = 0.00323999
Iteration 6907, loss = 0.00323982
Iteration 6908, loss = 0.00323868
Iteration 6909, loss = 0.00323799
Iteration 6910, loss = 0.00323723
Iteration 6911, loss = 0.00323654
Iteration 6912, loss = 0.00323573
Iteration 6913, loss = 0.00323515
Iteration 6914, loss = 0.00323443
Iteration 6915, loss = 0.00323358
Iteration 6916, loss = 0.00323297
Iteration 6917, loss = 0.00323222
Iteration 6918, loss = 0.00323172
Iteration 6919, loss = 0.00323122
Iteration 6920, loss = 0.00323042
Iteration 6921, loss = 0.00322981
Iteration 6922, loss = 0.00322932
Iteration 6923, loss = 0.00322876
Iteration 6924, loss = 0.00322808
Iteration 6925, loss = 0.00322733
Iteration 6926, loss = 0.00322667
Iteration 6927, loss = 0.00322594
Iteration 6928, loss = 0.00322536
Iteration 6929, loss = 0.00322463
Iteration 6930, loss = 0.00322407
Iteration 6931, loss = 0.00322332
Iteration 6932, loss = 0.00322286
Iteration 6933, loss = 0.00322204
Iteration 6934, loss = 0.00322143
Iteration 6935, loss = 0.00322070
Iteration 6936, loss = 0.00321994
Iteration 6937, loss = 0.00321928
Iteration 6938, loss = 0.00321868
Iteration 6939, loss = 0.00321791
Iteration 6940, loss = 0.00321734
Iteration 6941, loss = 0.00321655
Iteration 6942, loss = 0.00321586
Iteration 6943, loss = 0.00321519
Iteration 6944, loss = 0.00321465
Iteration 6945, loss = 0.00321398
Iteration 6946, loss = 0.00321316
Iteration 6947, loss = 0.00321239
Iteration 6948, loss = 0.00321161
Iteration 6949, loss = 0.00321082
Iteration 6950, loss = 0.00321004
Iteration 6951, loss = 0.00320941
Iteration 6952, loss = 0.00320874
Iteration 6953, loss = 0.00320832
Iteration 6954, loss = 0.00320728
Iteration 6955, loss = 0.00320662
Iteration 6956, loss = 0.00320584
Iteration 6957, loss = 0.00320515
Iteration 6958, loss = 0.00320449
Iteration 6959, loss = 0.00320376
Iteration 6960, loss = 0.00320309
Iteration 6961, loss = 0.00320240
Iteration 6962, loss = 0.00320174
Iteration 6963, loss = 0.00320103
Iteration 6964, loss = 0.00320033
Iteration 6965, loss = 0.00319965
Iteration 6966, loss = 0.00319906
Iteration 6967, loss = 0.00319842
Iteration 6968, loss = 0.00319782
Iteration 6969, loss = 0.00319720
Iteration 6970, loss = 0.00319656
Iteration 6971, loss = 0.00319610
Iteration 6972, loss = 0.00319540
Iteration 6973, loss = 0.00319456
Iteration 6974, loss = 0.00319395
Iteration 6975, loss = 0.00319319
Iteration 6976, loss = 0.00319258
Iteration 6977, loss = 0.00319200
Iteration 6978, loss = 0.00319137
Iteration 6979, loss = 0.00319042
Iteration 6980, loss = 0.00318974
Iteration 6981, loss = 0.00318894
Iteration 6982, loss = 0.00318857
Iteration 6983, loss = 0.00318760
Iteration 6984, loss = 0.00318690
Iteration 6985, loss = 0.00318628
Iteration 6986, loss = 0.00318570
Iteration 6987, loss = 0.00318492
Iteration 6988, loss = 0.00318424
Iteration 6989, loss = 0.00318361
Iteration 6990, loss = 0.00318307
Iteration 6991, loss = 0.00318239
Iteration 6992, loss = 0.00318178
Iteration 6993, loss = 0.00318122
Iteration 6994, loss = 0.00318075
Iteration 6995, loss = 0.00318007
Iteration 6996, loss = 0.00317954
Iteration 6997, loss = 0.00317919
Iteration 6998, loss = 0.00317820
Iteration 6999, loss = 0.00317771
Iteration 7000, loss = 0.00317713
Iteration 7001, loss = 0.00317648
Iteration 7002, loss = 0.00317609
Iteration 7003, loss = 0.00317536
Iteration 7004, loss = 0.00317479
Iteration 7005, loss = 0.00317417
Iteration 7006, loss = 0.00317359
Iteration 7007, loss = 0.00317300
Iteration 7008, loss = 0.00317264
Iteration 7009, loss = 0.00317171
Iteration 7010, loss = 0.00317118
Iteration 7011, loss = 0.00317046
Iteration 7012, loss = 0.00316972
Iteration 7013, loss = 0.00316896
Iteration 7014, loss = 0.00316865
Iteration 7015, loss = 0.00316736
Iteration 7016, loss = 0.00316680
Iteration 7017, loss = 0.00316637
Iteration 7018, loss = 0.00316518
Iteration 7019, loss = 0.00316476
Iteration 7020, loss = 0.00316378
Iteration 7021, loss = 0.00316322
Iteration 7022, loss = 0.00316253
Iteration 7023, loss = 0.00316182
Iteration 7024, loss = 0.00316120
Iteration 7025, loss = 0.00316055
Iteration 7026, loss = 0.00316001
Iteration 7027, loss = 0.00315951
Iteration 7028, loss = 0.00315884
Iteration 7029, loss = 0.00315816
Iteration 7030, loss = 0.00315764
Iteration 7031, loss = 0.00315695
Iteration 7032, loss = 0.00315602
Iteration 7033, loss = 0.00315558
Iteration 7034, loss = 0.00315500
Iteration 7035, loss = 0.00315448
Iteration 7036, loss = 0.00315384
Iteration 7037, loss = 0.00315349
Iteration 7038, loss = 0.00315302
Iteration 7039, loss = 0.00315239
Iteration 7040, loss = 0.00315172
Iteration 7041, loss = 0.00315127
Iteration 7042, loss = 0.00315056
Iteration 7043, loss = 0.00314991
Iteration 7044, loss = 0.00314926
Iteration 7045, loss = 0.00314870
Iteration 7046, loss = 0.00314810
Iteration 7047, loss = 0.00314742
Iteration 7048, loss = 0.00314667
Iteration 7049, loss = 0.00314621
Iteration 7050, loss = 0.00314549
Iteration 7051, loss = 0.00314484
Iteration 7052, loss = 0.00314421
Iteration 7053, loss = 0.00314379
Iteration 7054, loss = 0.00314304
Iteration 7055, loss = 0.00314237
Iteration 7056, loss = 0.00314171
Iteration 7057, loss = 0.00314114
Iteration 7058, loss = 0.00314057
Iteration 7059, loss = 0.00314000
Iteration 7060, loss = 0.00313955
Iteration 7061, loss = 0.00313928
Iteration 7062, loss = 0.00313837
Iteration 7063, loss = 0.00313777
Iteration 7064, loss = 0.00313714
Iteration 7065, loss = 0.00313644
Iteration 7066, loss = 0.00313574
Iteration 7067, loss = 0.00313529
Iteration 7068, loss = 0.00313447
Iteration 7069, loss = 0.00313380
Iteration 7070, loss = 0.00313315
Iteration 7071, loss = 0.00313251
Iteration 7072, loss = 0.00313179
Iteration 7073, loss = 0.00313108
Iteration 7074, loss = 0.00313065
Iteration 7075, loss = 0.00312995
Iteration 7076, loss = 0.00312921
Iteration 7077, loss = 0.00312851
Iteration 7078, loss = 0.00312790
Iteration 7079, loss = 0.00312723
Iteration 7080, loss = 0.00312656
Iteration 7081, loss = 0.00312603
Iteration 7082, loss = 0.00312535
Iteration 7083, loss = 0.00312459
Iteration 7084, loss = 0.00312419
Iteration 7085, loss = 0.00312332
Iteration 7086, loss = 0.00312267
Iteration 7087, loss = 0.00312233
Iteration 7088, loss = 0.00312144
Iteration 7089, loss = 0.00312087
Iteration 7090, loss = 0.00312020
Iteration 7091, loss = 0.00311970
Iteration 7092, loss = 0.00311902
Iteration 7093, loss = 0.00311840
Iteration 7094, loss = 0.00311774
Iteration 7095, loss = 0.00311723
Iteration 7096, loss = 0.00311655
Iteration 7097, loss = 0.00311602
Iteration 7098, loss = 0.00311539
Iteration 7099, loss = 0.00311481
Iteration 7100, loss = 0.00311403
Iteration 7101, loss = 0.00311328
Iteration 7102, loss = 0.00311266
Iteration 7103, loss = 0.00311194
Iteration 7104, loss = 0.00311160
Iteration 7105, loss = 0.00311082
Iteration 7106, loss = 0.00311031
Iteration 7107, loss = 0.00310963
Iteration 7108, loss = 0.00310906
Iteration 7109, loss = 0.00310857
Iteration 7110, loss = 0.00310790
Iteration 7111, loss = 0.00310730
Iteration 7112, loss = 0.00310677
Iteration 7113, loss = 0.00310618
Iteration 7114, loss = 0.00310564
Iteration 7115, loss = 0.00310532
Iteration 7116, loss = 0.00310446
Iteration 7117, loss = 0.00310383
Iteration 7118, loss = 0.00310326
Iteration 7119, loss = 0.00310263
Iteration 7120, loss = 0.00310192
Iteration 7121, loss = 0.00310133
Iteration 7122, loss = 0.00310062
Iteration 7123, loss = 0.00310017
Iteration 7124, loss = 0.00309953
Iteration 7125, loss = 0.00309892
Iteration 7126, loss = 0.00309830
Iteration 7127, loss = 0.00309771
Iteration 7128, loss = 0.00309728
Iteration 7129, loss = 0.00309661
Iteration 7130, loss = 0.00309614
Iteration 7131, loss = 0.00309551
Iteration 7132, loss = 0.00309503
Iteration 7133, loss = 0.00309432
Iteration 7134, loss = 0.00309366
Iteration 7135, loss = 0.00309311
Iteration 7136, loss = 0.00309239
Iteration 7137, loss = 0.00309181
Iteration 7138, loss = 0.00309123
Iteration 7139, loss = 0.00309064
Iteration 7140, loss = 0.00309008
Iteration 7141, loss = 0.00308952
Iteration 7142, loss = 0.00308888
Iteration 7143, loss = 0.00308831
Iteration 7144, loss = 0.00308788
Iteration 7145, loss = 0.00308728
Iteration 7146, loss = 0.00308662
Iteration 7147, loss = 0.00308618
Iteration 7148, loss = 0.00308551
Iteration 7149, loss = 0.00308501
Iteration 7150, loss = 0.00308438
Iteration 7151, loss = 0.00308369
Iteration 7152, loss = 0.00308314
Iteration 7153, loss = 0.00308252
Iteration 7154, loss = 0.00308194
Iteration 7155, loss = 0.00308134
Iteration 7156, loss = 0.00308077
Iteration 7157, loss = 0.00308022
Iteration 7158, loss = 0.00307969
Iteration 7159, loss = 0.00307931
Iteration 7160, loss = 0.00307872
Iteration 7161, loss = 0.00307805
Iteration 7162, loss = 0.00307742
Iteration 7163, loss = 0.00307686
Iteration 7164, loss = 0.00307623
Iteration 7165, loss = 0.00307527
Iteration 7166, loss = 0.00307461
Iteration 7167, loss = 0.00307406
Iteration 7168, loss = 0.00307347
Iteration 7169, loss = 0.00307266
Iteration 7170, loss = 0.00307206
Iteration 7171, loss = 0.00307143
Iteration 7172, loss = 0.00307081
Iteration 7173, loss = 0.00307028
Iteration 7174, loss = 0.00306961
Iteration 7175, loss = 0.00306912
Iteration 7176, loss = 0.00306856
Iteration 7177, loss = 0.00306802
Iteration 7178, loss = 0.00306744
Iteration 7179, loss = 0.00306688
Iteration 7180, loss = 0.00306630
Iteration 7181, loss = 0.00306571
Iteration 7182, loss = 0.00306498
Iteration 7183, loss = 0.00306436
Iteration 7184, loss = 0.00306382
Iteration 7185, loss = 0.00306319
Iteration 7186, loss = 0.00306261
Iteration 7187, loss = 0.00306190
Iteration 7188, loss = 0.00306134
Iteration 7189, loss = 0.00306079
Iteration 7190, loss = 0.00306020
Iteration 7191, loss = 0.00305949
Iteration 7192, loss = 0.00305892
Iteration 7193, loss = 0.00305824
Iteration 7194, loss = 0.00305772
Iteration 7195, loss = 0.00305711
Iteration 7196, loss = 0.00305667
Iteration 7197, loss = 0.00305611
Iteration 7198, loss = 0.00305574
Iteration 7199, loss = 0.00305481
Iteration 7200, loss = 0.00305431
Iteration 7201, loss = 0.00305367
Iteration 7202, loss = 0.00305305
Iteration 7203, loss = 0.00305252
Iteration 7204, loss = 0.00305185
Iteration 7205, loss = 0.00305132
Iteration 7206, loss = 0.00305078
Iteration 7207, loss = 0.00305026
Iteration 7208, loss = 0.00304968
Iteration 7209, loss = 0.00304916
Iteration 7210, loss = 0.00304861
Iteration 7211, loss = 0.00304811
Iteration 7212, loss = 0.00304747
Iteration 7213, loss = 0.00304683
Iteration 7214, loss = 0.00304623
Iteration 7215, loss = 0.00304566
Iteration 7216, loss = 0.00304500
Iteration 7217, loss = 0.00304425
Iteration 7218, loss = 0.00304365
Iteration 7219, loss = 0.00304312
Iteration 7220, loss = 0.00304263
Iteration 7221, loss = 0.00304186
Iteration 7222, loss = 0.00304140
Iteration 7223, loss = 0.00304070
Iteration 7224, loss = 0.00304004
Iteration 7225, loss = 0.00303959
Iteration 7226, loss = 0.00303899
Iteration 7227, loss = 0.00303854
Iteration 7228, loss = 0.00303798
Iteration 7229, loss = 0.00303725
Iteration 7230, loss = 0.00303659
Iteration 7231, loss = 0.00303603
Iteration 7232, loss = 0.00303562
Iteration 7233, loss = 0.00303492
Iteration 7234, loss = 0.00303425
Iteration 7235, loss = 0.00303373
Iteration 7236, loss = 0.00303308
Iteration 7237, loss = 0.00303247
Iteration 7238, loss = 0.00303194
Iteration 7239, loss = 0.00303141
Iteration 7240, loss = 0.00303083
Iteration 7241, loss = 0.00303006
Iteration 7242, loss = 0.00302950
Iteration 7243, loss = 0.00302888
Iteration 7244, loss = 0.00302823
Iteration 7245, loss = 0.00302753
Iteration 7246, loss = 0.00302693
Iteration 7247, loss = 0.00302629
Iteration 7248, loss = 0.00302546
Iteration 7249, loss = 0.00302485
Iteration 7250, loss = 0.00302414
Iteration 7251, loss = 0.00302370
Iteration 7252, loss = 0.00302295
Iteration 7253, loss = 0.00302239
Iteration 7254, loss = 0.00302192
Iteration 7255, loss = 0.00302124
Iteration 7256, loss = 0.00302118
Iteration 7257, loss = 0.00302019
Iteration 7258, loss = 0.00301959
Iteration 7259, loss = 0.00301907
Iteration 7260, loss = 0.00301851
Iteration 7261, loss = 0.00301807
Iteration 7262, loss = 0.00301733
Iteration 7263, loss = 0.00301715
Iteration 7264, loss = 0.00301622
Iteration 7265, loss = 0.00301564
Iteration 7266, loss = 0.00301509
Iteration 7267, loss = 0.00301455
Iteration 7268, loss = 0.00301391
Iteration 7269, loss = 0.00301338
Iteration 7270, loss = 0.00301301
Iteration 7271, loss = 0.00301229
Iteration 7272, loss = 0.00301180
Iteration 7273, loss = 0.00301125
Iteration 7274, loss = 0.00301069
Iteration 7275, loss = 0.00301010
Iteration 7276, loss = 0.00300951
Iteration 7277, loss = 0.00300893
Iteration 7278, loss = 0.00300840
Iteration 7279, loss = 0.00300783
Iteration 7280, loss = 0.00300726
Iteration 7281, loss = 0.00300664
Iteration 7282, loss = 0.00300597
Iteration 7283, loss = 0.00300536
Iteration 7284, loss = 0.00300484
Iteration 7285, loss = 0.00300422
Iteration 7286, loss = 0.00300357
Iteration 7287, loss = 0.00300304
Iteration 7288, loss = 0.00300235
Iteration 7289, loss = 0.00300177
Iteration 7290, loss = 0.00300129
Iteration 7291, loss = 0.00300068
Iteration 7292, loss = 0.00300005
Iteration 7293, loss = 0.00299944
Iteration 7294, loss = 0.00299881
Iteration 7295, loss = 0.00299833
Iteration 7296, loss = 0.00299787
Iteration 7297, loss = 0.00299714
Iteration 7298, loss = 0.00299654
Iteration 7299, loss = 0.00299597
Iteration 7300, loss = 0.00299549
Iteration 7301, loss = 0.00299486
Iteration 7302, loss = 0.00299439
Iteration 7303, loss = 0.00299383
Iteration 7304, loss = 0.00299332
Iteration 7305, loss = 0.00299272
Iteration 7306, loss = 0.00299217
Iteration 7307, loss = 0.00299152
Iteration 7308, loss = 0.00299106
Iteration 7309, loss = 0.00299033
Iteration 7310, loss = 0.00298965
Iteration 7311, loss = 0.00298898
Iteration 7312, loss = 0.00298869
Iteration 7313, loss = 0.00298847
Iteration 7314, loss = 0.00298740
Iteration 7315, loss = 0.00298668
Iteration 7316, loss = 0.00298603
Iteration 7317, loss = 0.00298579
Iteration 7318, loss = 0.00298493
Iteration 7319, loss = 0.00298433
Iteration 7320, loss = 0.00298371
Iteration 7321, loss = 0.00298319
Iteration 7322, loss = 0.00298252
Iteration 7323, loss = 0.00298186
Iteration 7324, loss = 0.00298133
Iteration 7325, loss = 0.00298083
Iteration 7326, loss = 0.00298019
Iteration 7327, loss = 0.00297952
Iteration 7328, loss = 0.00297913
Iteration 7329, loss = 0.00297856
Iteration 7330, loss = 0.00297804
Iteration 7331, loss = 0.00297754
Iteration 7332, loss = 0.00297651
Iteration 7333, loss = 0.00297568
Iteration 7334, loss = 0.00297557
Iteration 7335, loss = 0.00297473
Iteration 7336, loss = 0.00297480
Iteration 7337, loss = 0.00297370
Iteration 7338, loss = 0.00297307
Iteration 7339, loss = 0.00297244
Iteration 7340, loss = 0.00297185
Iteration 7341, loss = 0.00297134
Iteration 7342, loss = 0.00297077
Iteration 7343, loss = 0.00297032
Iteration 7344, loss = 0.00296975
Iteration 7345, loss = 0.00296920
Iteration 7346, loss = 0.00296865
Iteration 7347, loss = 0.00296808
Iteration 7348, loss = 0.00296765
Iteration 7349, loss = 0.00296708
Iteration 7350, loss = 0.00296627
Iteration 7351, loss = 0.00296585
Iteration 7352, loss = 0.00296521
Iteration 7353, loss = 0.00296461
Iteration 7354, loss = 0.00296411
Iteration 7355, loss = 0.00296361
Iteration 7356, loss = 0.00296311
Iteration 7357, loss = 0.00296243
Iteration 7358, loss = 0.00296191
Iteration 7359, loss = 0.00296130
Iteration 7360, loss = 0.00296116
Iteration 7361, loss = 0.00296039
Iteration 7362, loss = 0.00295970
Iteration 7363, loss = 0.00295904
Iteration 7364, loss = 0.00295862
Iteration 7365, loss = 0.00295787
Iteration 7366, loss = 0.00295726
Iteration 7367, loss = 0.00295651
Iteration 7368, loss = 0.00295598
Iteration 7369, loss = 0.00295551
Iteration 7370, loss = 0.00295477
Iteration 7371, loss = 0.00295419
Iteration 7372, loss = 0.00295358
Iteration 7373, loss = 0.00295307
Iteration 7374, loss = 0.00295242
Iteration 7375, loss = 0.00295183
Iteration 7376, loss = 0.00295127
Iteration 7377, loss = 0.00295065
Iteration 7378, loss = 0.00295005
Iteration 7379, loss = 0.00294937
Iteration 7380, loss = 0.00294885
Iteration 7381, loss = 0.00294859
Iteration 7382, loss = 0.00294767
Iteration 7383, loss = 0.00294720
Iteration 7384, loss = 0.00294650
Iteration 7385, loss = 0.00294585
Iteration 7386, loss = 0.00294534
Iteration 7387, loss = 0.00294479
Iteration 7388, loss = 0.00294412
Iteration 7389, loss = 0.00294355
Iteration 7390, loss = 0.00294298
Iteration 7391, loss = 0.00294242
Iteration 7392, loss = 0.00294186
Iteration 7393, loss = 0.00294120
Iteration 7394, loss = 0.00294070
Iteration 7395, loss = 0.00294003
Iteration 7396, loss = 0.00293965
Iteration 7397, loss = 0.00293901
Iteration 7398, loss = 0.00293861
Iteration 7399, loss = 0.00293783
Iteration 7400, loss = 0.00293725
Iteration 7401, loss = 0.00293646
Iteration 7402, loss = 0.00293615
Iteration 7403, loss = 0.00293567
Iteration 7404, loss = 0.00293490
Iteration 7405, loss = 0.00293464
Iteration 7406, loss = 0.00293388
Iteration 7407, loss = 0.00293336
Iteration 7408, loss = 0.00293285
Iteration 7409, loss = 0.00293232
Iteration 7410, loss = 0.00293176
Iteration 7411, loss = 0.00293120
Iteration 7412, loss = 0.00293067
Iteration 7413, loss = 0.00293009
Iteration 7414, loss = 0.00292963
Iteration 7415, loss = 0.00292921
Iteration 7416, loss = 0.00292855
Iteration 7417, loss = 0.00292809
Iteration 7418, loss = 0.00292754
Iteration 7419, loss = 0.00292707
Iteration 7420, loss = 0.00292654
Iteration 7421, loss = 0.00292604
Iteration 7422, loss = 0.00292556
Iteration 7423, loss = 0.00292512
Iteration 7424, loss = 0.00292441
Iteration 7425, loss = 0.00292413
Iteration 7426, loss = 0.00292336
Iteration 7427, loss = 0.00292283
Iteration 7428, loss = 0.00292230
Iteration 7429, loss = 0.00292176
Iteration 7430, loss = 0.00292119
Iteration 7431, loss = 0.00292076
Iteration 7432, loss = 0.00292023
Iteration 7433, loss = 0.00291950
Iteration 7434, loss = 0.00291897
Iteration 7435, loss = 0.00291834
Iteration 7436, loss = 0.00291773
Iteration 7437, loss = 0.00291715
Iteration 7438, loss = 0.00291683
Iteration 7439, loss = 0.00291605
Iteration 7440, loss = 0.00291544
Iteration 7441, loss = 0.00291492
Iteration 7442, loss = 0.00291442
Iteration 7443, loss = 0.00291372
Iteration 7444, loss = 0.00291319
Iteration 7445, loss = 0.00291261
Iteration 7446, loss = 0.00291203
Iteration 7447, loss = 0.00291150
Iteration 7448, loss = 0.00291126
Iteration 7449, loss = 0.00291056
Iteration 7450, loss = 0.00290992
Iteration 7451, loss = 0.00290943
Iteration 7452, loss = 0.00290894
Iteration 7453, loss = 0.00290885
Iteration 7454, loss = 0.00290796
Iteration 7455, loss = 0.00290744
Iteration 7456, loss = 0.00290689
Iteration 7457, loss = 0.00290634
Iteration 7458, loss = 0.00290583
Iteration 7459, loss = 0.00290523
Iteration 7460, loss = 0.00290461
Iteration 7461, loss = 0.00290407
Iteration 7462, loss = 0.00290367
Iteration 7463, loss = 0.00290306
Iteration 7464, loss = 0.00290237
Iteration 7465, loss = 0.00290191
Iteration 7466, loss = 0.00290127
Iteration 7467, loss = 0.00290079
Iteration 7468, loss = 0.00290027
Iteration 7469, loss = 0.00289969
Iteration 7470, loss = 0.00289933
Iteration 7471, loss = 0.00289871
Iteration 7472, loss = 0.00289801
Iteration 7473, loss = 0.00289761
Iteration 7474, loss = 0.00289689
Iteration 7475, loss = 0.00289628
Iteration 7476, loss = 0.00289570
Iteration 7477, loss = 0.00289528
Iteration 7478, loss = 0.00289457
Iteration 7479, loss = 0.00289405
Iteration 7480, loss = 0.00289355
Iteration 7481, loss = 0.00289314
Iteration 7482, loss = 0.00289245
Iteration 7483, loss = 0.00289179
Iteration 7484, loss = 0.00289123
Iteration 7485, loss = 0.00289069
Iteration 7486, loss = 0.00289013
Iteration 7487, loss = 0.00288958
Iteration 7488, loss = 0.00288895
Iteration 7489, loss = 0.00288865
Iteration 7490, loss = 0.00288813
Iteration 7491, loss = 0.00288743
Iteration 7492, loss = 0.00288686
Iteration 7493, loss = 0.00288633
Iteration 7494, loss = 0.00288582
Iteration 7495, loss = 0.00288529
Iteration 7496, loss = 0.00288472
Iteration 7497, loss = 0.00288428
Iteration 7498, loss = 0.00288388
Iteration 7499, loss = 0.00288302
Iteration 7500, loss = 0.00288252
Iteration 7501, loss = 0.00288192
Iteration 7502, loss = 0.00288141
Iteration 7503, loss = 0.00288083
Iteration 7504, loss = 0.00288035
Iteration 7505, loss = 0.00287974
Iteration 7506, loss = 0.00287924
Iteration 7507, loss = 0.00287875
Iteration 7508, loss = 0.00287819
Iteration 7509, loss = 0.00287790
Iteration 7510, loss = 0.00287716
Iteration 7511, loss = 0.00287666
Iteration 7512, loss = 0.00287610
Iteration 7513, loss = 0.00287567
Iteration 7514, loss = 0.00287509
Iteration 7515, loss = 0.00287453
Iteration 7516, loss = 0.00287395
Iteration 7517, loss = 0.00287347
Iteration 7518, loss = 0.00287290
Iteration 7519, loss = 0.00287235
Iteration 7520, loss = 0.00287216
Iteration 7521, loss = 0.00287150
Iteration 7522, loss = 0.00287086
Iteration 7523, loss = 0.00287045
Iteration 7524, loss = 0.00286985
Iteration 7525, loss = 0.00286942
Iteration 7526, loss = 0.00286879
Iteration 7527, loss = 0.00286827
Iteration 7528, loss = 0.00286776
Iteration 7529, loss = 0.00286724
Iteration 7530, loss = 0.00286672
Iteration 7531, loss = 0.00286617
Iteration 7532, loss = 0.00286568
Iteration 7533, loss = 0.00286538
Iteration 7534, loss = 0.00286471
Iteration 7535, loss = 0.00286427
Iteration 7536, loss = 0.00286379
Iteration 7537, loss = 0.00286321
Iteration 7538, loss = 0.00286290
Iteration 7539, loss = 0.00286210
Iteration 7540, loss = 0.00286165
Iteration 7541, loss = 0.00286116
Iteration 7542, loss = 0.00286056
Iteration 7543, loss = 0.00286010
Iteration 7544, loss = 0.00285972
Iteration 7545, loss = 0.00285898
Iteration 7546, loss = 0.00285846
Iteration 7547, loss = 0.00285805
Iteration 7548, loss = 0.00285747
Iteration 7549, loss = 0.00285697
Iteration 7550, loss = 0.00285643
Iteration 7551, loss = 0.00285596
Iteration 7552, loss = 0.00285550
Iteration 7553, loss = 0.00285514
Iteration 7554, loss = 0.00285456
Iteration 7555, loss = 0.00285426
Iteration 7556, loss = 0.00285363
Iteration 7557, loss = 0.00285338
Iteration 7558, loss = 0.00285255
Iteration 7559, loss = 0.00285205
Iteration 7560, loss = 0.00285160
Iteration 7561, loss = 0.00285098
Iteration 7562, loss = 0.00285046
Iteration 7563, loss = 0.00284991
Iteration 7564, loss = 0.00284940
Iteration 7565, loss = 0.00284889
Iteration 7566, loss = 0.00284844
Iteration 7567, loss = 0.00284791
Iteration 7568, loss = 0.00284735
Iteration 7569, loss = 0.00284684
Iteration 7570, loss = 0.00284632
Iteration 7571, loss = 0.00284589
Iteration 7572, loss = 0.00284542
Iteration 7573, loss = 0.00284492
Iteration 7574, loss = 0.00284439
Iteration 7575, loss = 0.00284387
Iteration 7576, loss = 0.00284353
Iteration 7577, loss = 0.00284313
Iteration 7578, loss = 0.00284254
Iteration 7579, loss = 0.00284202
Iteration 7580, loss = 0.00284153
Iteration 7581, loss = 0.00284100
Iteration 7582, loss = 0.00284048
Iteration 7583, loss = 0.00283990
Iteration 7584, loss = 0.00283933
Iteration 7585, loss = 0.00283895
Iteration 7586, loss = 0.00283829
Iteration 7587, loss = 0.00283774
Iteration 7588, loss = 0.00283726
Iteration 7589, loss = 0.00283670
Iteration 7590, loss = 0.00283612
Iteration 7591, loss = 0.00283556
Iteration 7592, loss = 0.00283512
Iteration 7593, loss = 0.00283455
Iteration 7594, loss = 0.00283417
Iteration 7595, loss = 0.00283348
Iteration 7596, loss = 0.00283293
Iteration 7597, loss = 0.00283237
Iteration 7598, loss = 0.00283199
Iteration 7599, loss = 0.00283131
Iteration 7600, loss = 0.00283073
Iteration 7601, loss = 0.00283018
Iteration 7602, loss = 0.00282977
Iteration 7603, loss = 0.00282931
Iteration 7604, loss = 0.00282886
Iteration 7605, loss = 0.00282812
Iteration 7606, loss = 0.00282759
Iteration 7607, loss = 0.00282697
Iteration 7608, loss = 0.00282661
Iteration 7609, loss = 0.00282596
Iteration 7610, loss = 0.00282547
Iteration 7611, loss = 0.00282527
Iteration 7612, loss = 0.00282451
Iteration 7613, loss = 0.00282398
Iteration 7614, loss = 0.00282343
Iteration 7615, loss = 0.00282293
Iteration 7616, loss = 0.00282250
Iteration 7617, loss = 0.00282187
Iteration 7618, loss = 0.00282130
Iteration 7619, loss = 0.00282082
Iteration 7620, loss = 0.00282050
Iteration 7621, loss = 0.00281995
Iteration 7622, loss = 0.00281934
Iteration 7623, loss = 0.00281878
Iteration 7624, loss = 0.00281820
Iteration 7625, loss = 0.00281777
Iteration 7626, loss = 0.00281739
Iteration 7627, loss = 0.00281674
Iteration 7628, loss = 0.00281618
Iteration 7629, loss = 0.00281565
Iteration 7630, loss = 0.00281519
Iteration 7631, loss = 0.00281472
Iteration 7632, loss = 0.00281415
Iteration 7633, loss = 0.00281360
Iteration 7634, loss = 0.00281301
Iteration 7635, loss = 0.00281279
Iteration 7636, loss = 0.00281204
Iteration 7637, loss = 0.00281148
Iteration 7638, loss = 0.00281098
Iteration 7639, loss = 0.00281052
Iteration 7640, loss = 0.00281031
Iteration 7641, loss = 0.00280954
Iteration 7642, loss = 0.00280904
Iteration 7643, loss = 0.00280855
Iteration 7644, loss = 0.00280807
Iteration 7645, loss = 0.00280761
Iteration 7646, loss = 0.00280713
Iteration 7647, loss = 0.00280689
Iteration 7648, loss = 0.00280615
Iteration 7649, loss = 0.00280575
Iteration 7650, loss = 0.00280502
Iteration 7651, loss = 0.00280455
Iteration 7652, loss = 0.00280393
Iteration 7653, loss = 0.00280354
Iteration 7654, loss = 0.00280309
Iteration 7655, loss = 0.00280244
Iteration 7656, loss = 0.00280195
Iteration 7657, loss = 0.00280147
Iteration 7658, loss = 0.00280093
Iteration 7659, loss = 0.00280043
Iteration 7660, loss = 0.00280001
Iteration 7661, loss = 0.00279948
Iteration 7662, loss = 0.00279901
Iteration 7663, loss = 0.00279849
Iteration 7664, loss = 0.00279809
Iteration 7665, loss = 0.00279756
Iteration 7666, loss = 0.00279710
Iteration 7667, loss = 0.00279662
Iteration 7668, loss = 0.00279619
Iteration 7669, loss = 0.00279575
Iteration 7670, loss = 0.00279538
Iteration 7671, loss = 0.00279488
Iteration 7672, loss = 0.00279434
Iteration 7673, loss = 0.00279387
Iteration 7674, loss = 0.00279334
Iteration 7675, loss = 0.00279283
Iteration 7676, loss = 0.00279240
Iteration 7677, loss = 0.00279176
Iteration 7678, loss = 0.00279124
Iteration 7679, loss = 0.00279074
Iteration 7680, loss = 0.00279022
Iteration 7681, loss = 0.00278970
Iteration 7682, loss = 0.00278928
Iteration 7683, loss = 0.00278872
Iteration 7684, loss = 0.00278831
Iteration 7685, loss = 0.00278772
Iteration 7686, loss = 0.00278726
Iteration 7687, loss = 0.00278663
Iteration 7688, loss = 0.00278616
Iteration 7689, loss = 0.00278549
Iteration 7690, loss = 0.00278501
Iteration 7691, loss = 0.00278445
Iteration 7692, loss = 0.00278396
Iteration 7693, loss = 0.00278342
Iteration 7694, loss = 0.00278292
Iteration 7695, loss = 0.00278254
Iteration 7696, loss = 0.00278201
Iteration 7697, loss = 0.00278139
Iteration 7698, loss = 0.00278124
Iteration 7699, loss = 0.00278063
Iteration 7700, loss = 0.00278010
Iteration 7701, loss = 0.00277953
Iteration 7702, loss = 0.00277907
Iteration 7703, loss = 0.00277858
Iteration 7704, loss = 0.00277805
Iteration 7705, loss = 0.00277760
Iteration 7706, loss = 0.00277717
Iteration 7707, loss = 0.00277696
Iteration 7708, loss = 0.00277620
Iteration 7709, loss = 0.00277576
Iteration 7710, loss = 0.00277523
Iteration 7711, loss = 0.00277483
Iteration 7712, loss = 0.00277432
Iteration 7713, loss = 0.00277369
Iteration 7714, loss = 0.00277302
Iteration 7715, loss = 0.00277269
Iteration 7716, loss = 0.00277220
Iteration 7717, loss = 0.00277151
Iteration 7718, loss = 0.00277091
Iteration 7719, loss = 0.00277048
Iteration 7720, loss = 0.00276973
Iteration 7721, loss = 0.00276924
Iteration 7722, loss = 0.00276893
Iteration 7723, loss = 0.00276820
Iteration 7724, loss = 0.00276801
Iteration 7725, loss = 0.00276722
Iteration 7726, loss = 0.00276668
Iteration 7727, loss = 0.00276608
Iteration 7728, loss = 0.00276559
Iteration 7729, loss = 0.00276500
Iteration 7730, loss = 0.00276442
Iteration 7731, loss = 0.00276386
Iteration 7732, loss = 0.00276328
Iteration 7733, loss = 0.00276272
Iteration 7734, loss = 0.00276227
Iteration 7735, loss = 0.00276174
Iteration 7736, loss = 0.00276114
Iteration 7737, loss = 0.00276068
Iteration 7738, loss = 0.00276007
Iteration 7739, loss = 0.00275955
Iteration 7740, loss = 0.00275935
Iteration 7741, loss = 0.00275846
Iteration 7742, loss = 0.00275795
Iteration 7743, loss = 0.00275748
Iteration 7744, loss = 0.00275691
Iteration 7745, loss = 0.00275660
Iteration 7746, loss = 0.00275587
Iteration 7747, loss = 0.00275554
Iteration 7748, loss = 0.00275490
Iteration 7749, loss = 0.00275429
Iteration 7750, loss = 0.00275377
Iteration 7751, loss = 0.00275331
Iteration 7752, loss = 0.00275269
Iteration 7753, loss = 0.00275213
Iteration 7754, loss = 0.00275177
Iteration 7755, loss = 0.00275120
Iteration 7756, loss = 0.00275078
Iteration 7757, loss = 0.00275033
Iteration 7758, loss = 0.00274972
Iteration 7759, loss = 0.00274938
Iteration 7760, loss = 0.00274879
Iteration 7761, loss = 0.00274818
Iteration 7762, loss = 0.00274772
Iteration 7763, loss = 0.00274710
Iteration 7764, loss = 0.00274669
Iteration 7765, loss = 0.00274602
Iteration 7766, loss = 0.00274558
Iteration 7767, loss = 0.00274499
Iteration 7768, loss = 0.00274450
Iteration 7769, loss = 0.00274396
Iteration 7770, loss = 0.00274339
Iteration 7771, loss = 0.00274291
Iteration 7772, loss = 0.00274245
Iteration 7773, loss = 0.00274188
Iteration 7774, loss = 0.00274134
Iteration 7775, loss = 0.00274089
Iteration 7776, loss = 0.00274051
Iteration 7777, loss = 0.00273990
Iteration 7778, loss = 0.00273945
Iteration 7779, loss = 0.00273885
Iteration 7780, loss = 0.00273831
Iteration 7781, loss = 0.00273788
Iteration 7782, loss = 0.00273725
Iteration 7783, loss = 0.00273670
Iteration 7784, loss = 0.00273608
Iteration 7785, loss = 0.00273617
Iteration 7786, loss = 0.00273523
Iteration 7787, loss = 0.00273486
Iteration 7788, loss = 0.00273441
Iteration 7789, loss = 0.00273418
Iteration 7790, loss = 0.00273347
Iteration 7791, loss = 0.00273296
Iteration 7792, loss = 0.00273262
Iteration 7793, loss = 0.00273210
Iteration 7794, loss = 0.00273182
Iteration 7795, loss = 0.00273118
Iteration 7796, loss = 0.00273070
Iteration 7797, loss = 0.00273023
Iteration 7798, loss = 0.00272980
Iteration 7799, loss = 0.00272921
Iteration 7800, loss = 0.00272882
Iteration 7801, loss = 0.00272828
Iteration 7802, loss = 0.00272787
Iteration 7803, loss = 0.00272732
Iteration 7804, loss = 0.00272684
Iteration 7805, loss = 0.00272645
Iteration 7806, loss = 0.00272595
Iteration 7807, loss = 0.00272544
Iteration 7808, loss = 0.00272503
Iteration 7809, loss = 0.00272448
Iteration 7810, loss = 0.00272400
Iteration 7811, loss = 0.00272355
Iteration 7812, loss = 0.00272331
Iteration 7813, loss = 0.00272256
Iteration 7814, loss = 0.00272210
Iteration 7815, loss = 0.00272157
Iteration 7816, loss = 0.00272106
Iteration 7817, loss = 0.00272069
Iteration 7818, loss = 0.00272008
Iteration 7819, loss = 0.00271960
Iteration 7820, loss = 0.00271915
Iteration 7821, loss = 0.00271869
Iteration 7822, loss = 0.00271811
Iteration 7823, loss = 0.00271761
Iteration 7824, loss = 0.00271735
Iteration 7825, loss = 0.00271671
Iteration 7826, loss = 0.00271621
Iteration 7827, loss = 0.00271569
Iteration 7828, loss = 0.00271522
Iteration 7829, loss = 0.00271473
Iteration 7830, loss = 0.00271467
Iteration 7831, loss = 0.00271391
Iteration 7832, loss = 0.00271338
Iteration 7833, loss = 0.00271290
Iteration 7834, loss = 0.00271242
Iteration 7835, loss = 0.00271195
Iteration 7836, loss = 0.00271156
Iteration 7837, loss = 0.00271107
Iteration 7838, loss = 0.00271063
Iteration 7839, loss = 0.00271030
Iteration 7840, loss = 0.00270964
Iteration 7841, loss = 0.00270903
Iteration 7842, loss = 0.00270848
Iteration 7843, loss = 0.00270793
Iteration 7844, loss = 0.00270774
Iteration 7845, loss = 0.00270703
Iteration 7846, loss = 0.00270653
Iteration 7847, loss = 0.00270600
Iteration 7848, loss = 0.00270556
Iteration 7849, loss = 0.00270516
Iteration 7850, loss = 0.00270470
Iteration 7851, loss = 0.00270419
Iteration 7852, loss = 0.00270367
Iteration 7853, loss = 0.00270314
Iteration 7854, loss = 0.00270264
Iteration 7855, loss = 0.00270219
Iteration 7856, loss = 0.00270172
Iteration 7857, loss = 0.00270127
Iteration 7858, loss = 0.00270078
Iteration 7859, loss = 0.00270031
Iteration 7860, loss = 0.00269982
Iteration 7861, loss = 0.00269947
Iteration 7862, loss = 0.00269896
Iteration 7863, loss = 0.00269852
Iteration 7864, loss = 0.00269818
Iteration 7865, loss = 0.00269757
Iteration 7866, loss = 0.00269718
Iteration 7867, loss = 0.00269677
Iteration 7868, loss = 0.00269629
Iteration 7869, loss = 0.00269587
Iteration 7870, loss = 0.00269539
Iteration 7871, loss = 0.00269499
Iteration 7872, loss = 0.00269446
Iteration 7873, loss = 0.00269405
Iteration 7874, loss = 0.00269351
Iteration 7875, loss = 0.00269301
Iteration 7876, loss = 0.00269263
Iteration 7877, loss = 0.00269208
Iteration 7878, loss = 0.00269175
Iteration 7879, loss = 0.00269121
Iteration 7880, loss = 0.00269068
Iteration 7881, loss = 0.00269041
Iteration 7882, loss = 0.00268989
Iteration 7883, loss = 0.00268933
Iteration 7884, loss = 0.00268888
Iteration 7885, loss = 0.00268831
Iteration 7886, loss = 0.00268779
Iteration 7887, loss = 0.00268733
Iteration 7888, loss = 0.00268710
Iteration 7889, loss = 0.00268663
Iteration 7890, loss = 0.00268594
Iteration 7891, loss = 0.00268551
Iteration 7892, loss = 0.00268499
Iteration 7893, loss = 0.00268459
Iteration 7894, loss = 0.00268404
Iteration 7895, loss = 0.00268361
Iteration 7896, loss = 0.00268325
Iteration 7897, loss = 0.00268274
Iteration 7898, loss = 0.00268231
Iteration 7899, loss = 0.00268185
Iteration 7900, loss = 0.00268139
Iteration 7901, loss = 0.00268085
Iteration 7902, loss = 0.00268048
Iteration 7903, loss = 0.00268002
Iteration 7904, loss = 0.00267952
Iteration 7905, loss = 0.00267900
Iteration 7906, loss = 0.00267852
Iteration 7907, loss = 0.00267795
Iteration 7908, loss = 0.00267749
Iteration 7909, loss = 0.00267693
Iteration 7910, loss = 0.00267663
Iteration 7911, loss = 0.00267606
Iteration 7912, loss = 0.00267552
Iteration 7913, loss = 0.00267499
Iteration 7914, loss = 0.00267478
Iteration 7915, loss = 0.00267407
Iteration 7916, loss = 0.00267362
Iteration 7917, loss = 0.00267308
Iteration 7918, loss = 0.00267254
Iteration 7919, loss = 0.00267207
Iteration 7920, loss = 0.00267157
Iteration 7921, loss = 0.00267128
Iteration 7922, loss = 0.00267071
Iteration 7923, loss = 0.00267024
Iteration 7924, loss = 0.00266979
Iteration 7925, loss = 0.00266932
Iteration 7926, loss = 0.00266885
Iteration 7927, loss = 0.00266839
Iteration 7928, loss = 0.00266795
Iteration 7929, loss = 0.00266744
Iteration 7930, loss = 0.00266699
Iteration 7931, loss = 0.00266652
Iteration 7932, loss = 0.00266615
Iteration 7933, loss = 0.00266562
Iteration 7934, loss = 0.00266521
Iteration 7935, loss = 0.00266479
Iteration 7936, loss = 0.00266431
Iteration 7937, loss = 0.00266390
Iteration 7938, loss = 0.00266350
Iteration 7939, loss = 0.00266311
Iteration 7940, loss = 0.00266274
Iteration 7941, loss = 0.00266214
Iteration 7942, loss = 0.00266165
Iteration 7943, loss = 0.00266113
Iteration 7944, loss = 0.00266055
Iteration 7945, loss = 0.00266000
Iteration 7946, loss = 0.00265969
Iteration 7947, loss = 0.00265916
Iteration 7948, loss = 0.00265863
Iteration 7949, loss = 0.00265805
Iteration 7950, loss = 0.00265800
Iteration 7951, loss = 0.00265723
Iteration 7952, loss = 0.00265677
Iteration 7953, loss = 0.00265638
Iteration 7954, loss = 0.00265594
Iteration 7955, loss = 0.00265543
Iteration 7956, loss = 0.00265514
Iteration 7957, loss = 0.00265452
Iteration 7958, loss = 0.00265430
Iteration 7959, loss = 0.00265369
Iteration 7960, loss = 0.00265324
Iteration 7961, loss = 0.00265308
Iteration 7962, loss = 0.00265247
Iteration 7963, loss = 0.00265191
Iteration 7964, loss = 0.00265139
Iteration 7965, loss = 0.00265106
Iteration 7966, loss = 0.00265041
Iteration 7967, loss = 0.00264999
Iteration 7968, loss = 0.00264949
Iteration 7969, loss = 0.00264903
Iteration 7970, loss = 0.00264856
Iteration 7971, loss = 0.00264800
Iteration 7972, loss = 0.00264755
Iteration 7973, loss = 0.00264724
Iteration 7974, loss = 0.00264660
Iteration 7975, loss = 0.00264618
Iteration 7976, loss = 0.00264563
Iteration 7977, loss = 0.00264500
Iteration 7978, loss = 0.00264454
Iteration 7979, loss = 0.00264399
Iteration 7980, loss = 0.00264350
Iteration 7981, loss = 0.00264303
Iteration 7982, loss = 0.00264258
Iteration 7983, loss = 0.00264206
Iteration 7984, loss = 0.00264167
Iteration 7985, loss = 0.00264117
Iteration 7986, loss = 0.00264070
Iteration 7987, loss = 0.00264029
Iteration 7988, loss = 0.00263984
Iteration 7989, loss = 0.00263933
Iteration 7990, loss = 0.00263894
Iteration 7991, loss = 0.00263838
Iteration 7992, loss = 0.00263795
Iteration 7993, loss = 0.00263750
Iteration 7994, loss = 0.00263698
Iteration 7995, loss = 0.00263655
Iteration 7996, loss = 0.00263605
Iteration 7997, loss = 0.00263565
Iteration 7998, loss = 0.00263517
Iteration 7999, loss = 0.00263471
Iteration 8000, loss = 0.00263424
Iteration 1, loss = 1.04347472
Iteration 2, loss = 1.04016060
Iteration 3, loss = 1.03499856
Iteration 4, loss = 1.02845023
Iteration 5, loss = 1.02078738
Iteration 6, loss = 1.01263375
Iteration 7, loss = 1.00370114
Iteration 8, loss = 0.99455040
Iteration 9, loss = 0.98507900
Iteration 10, loss = 0.97535638
Iteration 11, loss = 0.96553258
Iteration 12, loss = 0.95567027
Iteration 13, loss = 0.94590532
Iteration 14, loss = 0.93608087
Iteration 15, loss = 0.92649648
Iteration 16, loss = 0.91697405
Iteration 17, loss = 0.90776450
Iteration 18, loss = 0.89881684
Iteration 19, loss = 0.88997691
Iteration 20, loss = 0.88147843
Iteration 21, loss = 0.87308688
Iteration 22, loss = 0.86518574
Iteration 23, loss = 0.85729323
Iteration 24, loss = 0.84944322
Iteration 25, loss = 0.84204373
Iteration 26, loss = 0.83454918
Iteration 27, loss = 0.82752849
Iteration 28, loss = 0.82037277
Iteration 29, loss = 0.81390885
Iteration 30, loss = 0.80742935
Iteration 31, loss = 0.80092786
Iteration 32, loss = 0.79504138
Iteration 33, loss = 0.78917655
Iteration 34, loss = 0.78331039
Iteration 35, loss = 0.77778233
Iteration 36, loss = 0.77258953
Iteration 37, loss = 0.76737201
Iteration 38, loss = 0.76240031
Iteration 39, loss = 0.75751813
Iteration 40, loss = 0.75286658
Iteration 41, loss = 0.74815620
Iteration 42, loss = 0.74385279
Iteration 43, loss = 0.73936413
Iteration 44, loss = 0.73508889
Iteration 45, loss = 0.73099930
Iteration 46, loss = 0.72677159
Iteration 47, loss = 0.72285854
Iteration 48, loss = 0.71897500
Iteration 49, loss = 0.71521973
Iteration 50, loss = 0.71155063
Iteration 51, loss = 0.70795366
Iteration 52, loss = 0.70441910
Iteration 53, loss = 0.70096851
Iteration 54, loss = 0.69763813
Iteration 55, loss = 0.69417030
Iteration 56, loss = 0.69081627
Iteration 57, loss = 0.68768181
Iteration 58, loss = 0.68424318
Iteration 59, loss = 0.68120082
Iteration 60, loss = 0.67800159
Iteration 61, loss = 0.67494585
Iteration 62, loss = 0.67194843
Iteration 63, loss = 0.66894430
Iteration 64, loss = 0.66598969
Iteration 65, loss = 0.66312754
Iteration 66, loss = 0.66024547
Iteration 67, loss = 0.65739354
Iteration 68, loss = 0.65455036
Iteration 69, loss = 0.65173114
Iteration 70, loss = 0.64901483
Iteration 71, loss = 0.64618066
Iteration 72, loss = 0.64347139
Iteration 73, loss = 0.64073436
Iteration 74, loss = 0.63803303
Iteration 75, loss = 0.63528506
Iteration 76, loss = 0.63259664
Iteration 77, loss = 0.62996477
Iteration 78, loss = 0.62724224
Iteration 79, loss = 0.62460802
Iteration 80, loss = 0.62199962
Iteration 81, loss = 0.61940298
Iteration 82, loss = 0.61682238
Iteration 83, loss = 0.61426437
Iteration 84, loss = 0.61169487
Iteration 85, loss = 0.60909895
Iteration 86, loss = 0.60663559
Iteration 87, loss = 0.60400911
Iteration 88, loss = 0.60150310
Iteration 89, loss = 0.59896532
Iteration 90, loss = 0.59640800
Iteration 91, loss = 0.59393023
Iteration 92, loss = 0.59141436
Iteration 93, loss = 0.58888744
Iteration 94, loss = 0.58640989
Iteration 95, loss = 0.58394004
Iteration 96, loss = 0.58146791
Iteration 97, loss = 0.57901167
Iteration 98, loss = 0.57653509
Iteration 99, loss = 0.57414555
Iteration 100, loss = 0.57174918
Iteration 101, loss = 0.56928914
Iteration 102, loss = 0.56689807
Iteration 103, loss = 0.56448483
Iteration 104, loss = 0.56213688
Iteration 105, loss = 0.55972199
Iteration 106, loss = 0.55739935
Iteration 107, loss = 0.55497950
Iteration 108, loss = 0.55269718
Iteration 109, loss = 0.55033534
Iteration 110, loss = 0.54799795
Iteration 111, loss = 0.54567491
Iteration 112, loss = 0.54333616
Iteration 113, loss = 0.54106473
Iteration 114, loss = 0.53872565
Iteration 115, loss = 0.53642096
Iteration 116, loss = 0.53414952
Iteration 117, loss = 0.53183717
Iteration 118, loss = 0.52955000
Iteration 119, loss = 0.52723745
Iteration 120, loss = 0.52494310
Iteration 121, loss = 0.52264913
Iteration 122, loss = 0.52040102
Iteration 123, loss = 0.51807715
Iteration 124, loss = 0.51586153
Iteration 125, loss = 0.51367979
Iteration 126, loss = 0.51147418
Iteration 127, loss = 0.50928397
Iteration 128, loss = 0.50711793
Iteration 129, loss = 0.50494474
Iteration 130, loss = 0.50276866
Iteration 131, loss = 0.50061619
Iteration 132, loss = 0.49846113
Iteration 133, loss = 0.49632541
Iteration 134, loss = 0.49421802
Iteration 135, loss = 0.49209699
Iteration 136, loss = 0.48996418
Iteration 137, loss = 0.48787740
Iteration 138, loss = 0.48575340
Iteration 139, loss = 0.48363918
Iteration 140, loss = 0.48154034
Iteration 141, loss = 0.47941627
Iteration 142, loss = 0.47731046
Iteration 143, loss = 0.47519226
Iteration 144, loss = 0.47310300
Iteration 145, loss = 0.47095118
Iteration 146, loss = 0.46886160
Iteration 147, loss = 0.46672980
Iteration 148, loss = 0.46466104
Iteration 149, loss = 0.46250435
Iteration 150, loss = 0.46040565
Iteration 151, loss = 0.45831546
Iteration 152, loss = 0.45617053
Iteration 153, loss = 0.45405863
Iteration 154, loss = 0.45193867
Iteration 155, loss = 0.44981527
Iteration 156, loss = 0.44773926
Iteration 157, loss = 0.44559365
Iteration 158, loss = 0.44352523
Iteration 159, loss = 0.44142915
Iteration 160, loss = 0.43935821
Iteration 161, loss = 0.43727065
Iteration 162, loss = 0.43518676
Iteration 163, loss = 0.43307995
Iteration 164, loss = 0.43099589
Iteration 165, loss = 0.42886785
Iteration 166, loss = 0.42674981
Iteration 167, loss = 0.42462054
Iteration 168, loss = 0.42249378
Iteration 169, loss = 0.42034882
Iteration 170, loss = 0.41820396
Iteration 171, loss = 0.41608639
Iteration 172, loss = 0.41395200
Iteration 173, loss = 0.41180213
Iteration 174, loss = 0.40971870
Iteration 175, loss = 0.40759941
Iteration 176, loss = 0.40548491
Iteration 177, loss = 0.40340437
Iteration 178, loss = 0.40128372
Iteration 179, loss = 0.39920309
Iteration 180, loss = 0.39711057
Iteration 181, loss = 0.39505085
Iteration 182, loss = 0.39295047
Iteration 183, loss = 0.39088462
Iteration 184, loss = 0.38879515
Iteration 185, loss = 0.38676834
Iteration 186, loss = 0.38471432
Iteration 187, loss = 0.38263876
Iteration 188, loss = 0.38061044
Iteration 189, loss = 0.37858743
Iteration 190, loss = 0.37653975
Iteration 191, loss = 0.37450787
Iteration 192, loss = 0.37249621
Iteration 193, loss = 0.37046541
Iteration 194, loss = 0.36841806
Iteration 195, loss = 0.36640308
Iteration 196, loss = 0.36435019
Iteration 197, loss = 0.36233086
Iteration 198, loss = 0.36029481
Iteration 199, loss = 0.35826679
Iteration 200, loss = 0.35622811
Iteration 201, loss = 0.35422799
Iteration 202, loss = 0.35219126
Iteration 203, loss = 0.35016456
Iteration 204, loss = 0.34814838
Iteration 205, loss = 0.34612278
Iteration 206, loss = 0.34412585
Iteration 207, loss = 0.34212076
Iteration 208, loss = 0.34010801
Iteration 209, loss = 0.33811678
Iteration 210, loss = 0.33613378
Iteration 211, loss = 0.33413335
Iteration 212, loss = 0.33216612
Iteration 213, loss = 0.33022412
Iteration 214, loss = 0.32823897
Iteration 215, loss = 0.32630082
Iteration 216, loss = 0.32435095
Iteration 217, loss = 0.32241317
Iteration 218, loss = 0.32049133
Iteration 219, loss = 0.31857660
Iteration 220, loss = 0.31665587
Iteration 221, loss = 0.31476155
Iteration 222, loss = 0.31287491
Iteration 223, loss = 0.31099148
Iteration 224, loss = 0.30911401
Iteration 225, loss = 0.30724243
Iteration 226, loss = 0.30540329
Iteration 227, loss = 0.30352975
Iteration 228, loss = 0.30168912
Iteration 229, loss = 0.29983089
Iteration 230, loss = 0.29800351
Iteration 231, loss = 0.29614368
Iteration 232, loss = 0.29431638
Iteration 233, loss = 0.29248388
Iteration 234, loss = 0.29068163
Iteration 235, loss = 0.28885551
Iteration 236, loss = 0.28706800
Iteration 237, loss = 0.28528861
Iteration 238, loss = 0.28350128
Iteration 239, loss = 0.28173736
Iteration 240, loss = 0.27998382
Iteration 241, loss = 0.27823717
Iteration 242, loss = 0.27650643
Iteration 243, loss = 0.27479266
Iteration 244, loss = 0.27306894
Iteration 245, loss = 0.27138068
Iteration 246, loss = 0.26967535
Iteration 247, loss = 0.26798035
Iteration 248, loss = 0.26628775
Iteration 249, loss = 0.26460350
Iteration 250, loss = 0.26297071
Iteration 251, loss = 0.26128572
Iteration 252, loss = 0.25964989
Iteration 253, loss = 0.25802629
Iteration 254, loss = 0.25640288
Iteration 255, loss = 0.25479643
Iteration 256, loss = 0.25319567
Iteration 257, loss = 0.25163081
Iteration 1, loss = 1.04533777
Iteration 2, loss = 1.04197988
Iteration 3, loss = 1.03672599
Iteration 4, loss = 1.03014017
Iteration 5, loss = 1.02223377
Iteration 6, loss = 1.01389917
Iteration 7, loss = 1.00474357
Iteration 8, loss = 0.99526246
Iteration 9, loss = 0.98554390
Iteration 10, loss = 0.97556625
Iteration 11, loss = 0.96554581
Iteration 12, loss = 0.95541138
Iteration 13, loss = 0.94545463
Iteration 14, loss = 0.93537389
Iteration 15, loss = 0.92562783
Iteration 16, loss = 0.91595671
Iteration 17, loss = 0.90654725
Iteration 18, loss = 0.89760892
Iteration 19, loss = 0.88862650
Iteration 20, loss = 0.88020056
Iteration 21, loss = 0.87177416
Iteration 22, loss = 0.86383072
Iteration 23, loss = 0.85599932
Iteration 24, loss = 0.84808456
Iteration 25, loss = 0.84077675
Iteration 26, loss = 0.83327340
Iteration 27, loss = 0.82626859
Iteration 28, loss = 0.81908021
Iteration 29, loss = 0.81263345
Iteration 30, loss = 0.80627099
Iteration 31, loss = 0.79981006
Iteration 32, loss = 0.79407199
Iteration 33, loss = 0.78820908
Iteration 34, loss = 0.78250189
Iteration 35, loss = 0.77696534
Iteration 36, loss = 0.77174100
Iteration 37, loss = 0.76651579
Iteration 38, loss = 0.76158159
Iteration 39, loss = 0.75669047
Iteration 40, loss = 0.75200854
Iteration 41, loss = 0.74732348
Iteration 42, loss = 0.74298072
Iteration 43, loss = 0.73846953
Iteration 44, loss = 0.73412705
Iteration 45, loss = 0.72999926
Iteration 46, loss = 0.72580554
Iteration 47, loss = 0.72186305
Iteration 48, loss = 0.71797971
Iteration 49, loss = 0.71415697
Iteration 50, loss = 0.71047110
Iteration 51, loss = 0.70682267
Iteration 52, loss = 0.70329583
Iteration 53, loss = 0.69985456
Iteration 54, loss = 0.69648640
Iteration 55, loss = 0.69304056
Iteration 56, loss = 0.68974461
Iteration 57, loss = 0.68666158
Iteration 58, loss = 0.68329602
Iteration 59, loss = 0.68030677
Iteration 60, loss = 0.67723692
Iteration 61, loss = 0.67430879
Iteration 62, loss = 0.67143142
Iteration 63, loss = 0.66857475
Iteration 64, loss = 0.66575753
Iteration 65, loss = 0.66309150
Iteration 66, loss = 0.66033774
Iteration 67, loss = 0.65764418
Iteration 68, loss = 0.65494135
Iteration 69, loss = 0.65228927
Iteration 70, loss = 0.64968823
Iteration 71, loss = 0.64697935
Iteration 72, loss = 0.64440231
Iteration 73, loss = 0.64180102
Iteration 74, loss = 0.63920993
Iteration 75, loss = 0.63659168
Iteration 76, loss = 0.63403229
Iteration 77, loss = 0.63149562
Iteration 78, loss = 0.62887533
Iteration 79, loss = 0.62631596
Iteration 80, loss = 0.62381059
Iteration 81, loss = 0.62126474
Iteration 82, loss = 0.61876245
Iteration 83, loss = 0.61628056
Iteration 84, loss = 0.61376837
Iteration 85, loss = 0.61124511
Iteration 86, loss = 0.60883975
Iteration 87, loss = 0.60625140
Iteration 88, loss = 0.60381184
Iteration 89, loss = 0.60133259
Iteration 90, loss = 0.59882031
Iteration 91, loss = 0.59640363
Iteration 92, loss = 0.59393214
Iteration 93, loss = 0.59146374
Iteration 94, loss = 0.58903075
Iteration 95, loss = 0.58660935
Iteration 96, loss = 0.58419309
Iteration 97, loss = 0.58178278
Iteration 98, loss = 0.57934034
Iteration 99, loss = 0.57698279
Iteration 100, loss = 0.57460073
Iteration 101, loss = 0.57213735
Iteration 102, loss = 0.56976020
Iteration 103, loss = 0.56733488
Iteration 104, loss = 0.56496831
Iteration 105, loss = 0.56256520
Iteration 106, loss = 0.56022535
Iteration 107, loss = 0.55780774
Iteration 108, loss = 0.55551813
Iteration 109, loss = 0.55316246
Iteration 110, loss = 0.55082834
Iteration 111, loss = 0.54851314
Iteration 112, loss = 0.54618706
Iteration 113, loss = 0.54390374
Iteration 114, loss = 0.54157557
Iteration 115, loss = 0.53926576
Iteration 116, loss = 0.53698791
Iteration 117, loss = 0.53469017
Iteration 118, loss = 0.53239473
Iteration 119, loss = 0.53006936
Iteration 120, loss = 0.52778652
Iteration 121, loss = 0.52548268
Iteration 122, loss = 0.52320993
Iteration 123, loss = 0.52089119
Iteration 124, loss = 0.51862408
Iteration 125, loss = 0.51637146
Iteration 126, loss = 0.51410980
Iteration 127, loss = 0.51183987
Iteration 128, loss = 0.50961220
Iteration 129, loss = 0.50736292
Iteration 130, loss = 0.50511882
Iteration 131, loss = 0.50288535
Iteration 132, loss = 0.50064922
Iteration 133, loss = 0.49844581
Iteration 134, loss = 0.49628004
Iteration 135, loss = 0.49408994
Iteration 136, loss = 0.49190703
Iteration 137, loss = 0.48976161
Iteration 138, loss = 0.48759299
Iteration 139, loss = 0.48545464
Iteration 140, loss = 0.48335941
Iteration 141, loss = 0.48122433
Iteration 142, loss = 0.47912044
Iteration 143, loss = 0.47700825
Iteration 144, loss = 0.47491437
Iteration 145, loss = 0.47279813
Iteration 146, loss = 0.47071004
Iteration 147, loss = 0.46859083
Iteration 148, loss = 0.46654767
Iteration 149, loss = 0.46440276
Iteration 150, loss = 0.46232900
Iteration 151, loss = 0.46024468
Iteration 152, loss = 0.45812639
Iteration 153, loss = 0.45602343
Iteration 154, loss = 0.45392001
Iteration 155, loss = 0.45182505
Iteration 156, loss = 0.44976944
Iteration 157, loss = 0.44764982
Iteration 158, loss = 0.44559379
Iteration 159, loss = 0.44354011
Iteration 160, loss = 0.44148578
Iteration 161, loss = 0.43943547
Iteration 162, loss = 0.43737854
Iteration 163, loss = 0.43531309
Iteration 164, loss = 0.43325577
Iteration 165, loss = 0.43117178
Iteration 166, loss = 0.42908412
Iteration 167, loss = 0.42699960
Iteration 168, loss = 0.42491502
Iteration 169, loss = 0.42280711
Iteration 170, loss = 0.42070734
Iteration 171, loss = 0.41863541
Iteration 172, loss = 0.41654918
Iteration 173, loss = 0.41444923
Iteration 174, loss = 0.41239454
Iteration 175, loss = 0.41032507
Iteration 176, loss = 0.40823843
Iteration 177, loss = 0.40618314
Iteration 178, loss = 0.40409952
Iteration 179, loss = 0.40204726
Iteration 180, loss = 0.39997350
Iteration 181, loss = 0.39793861
Iteration 182, loss = 0.39586642
Iteration 183, loss = 0.39382274
Iteration 184, loss = 0.39176264
Iteration 185, loss = 0.38976212
Iteration 186, loss = 0.38769682
Iteration 187, loss = 0.38565259
Iteration 188, loss = 0.38362723
Iteration 189, loss = 0.38162080
Iteration 190, loss = 0.37958373
Iteration 191, loss = 0.37757050
Iteration 192, loss = 0.37556722
Iteration 193, loss = 0.37357762
Iteration 194, loss = 0.37154910
Iteration 195, loss = 0.36957282
Iteration 196, loss = 0.36754896
Iteration 197, loss = 0.36556621
Iteration 198, loss = 0.36356522
Iteration 199, loss = 0.36157158
Iteration 200, loss = 0.35957636
Iteration 201, loss = 0.35759488
Iteration 202, loss = 0.35561266
Iteration 203, loss = 0.35362860
Iteration 204, loss = 0.35166325
Iteration 205, loss = 0.34969779
Iteration 206, loss = 0.34775670
Iteration 207, loss = 0.34581535
Iteration 208, loss = 0.34385554
Iteration 209, loss = 0.34191510
Iteration 210, loss = 0.33998870
Iteration 211, loss = 0.33804088
Iteration 212, loss = 0.33611351
Iteration 213, loss = 0.33420178
Iteration 214, loss = 0.33225961
Iteration 215, loss = 0.33035739
Iteration 216, loss = 0.32842593
Iteration 217, loss = 0.32653036
Iteration 218, loss = 0.32460831
Iteration 219, loss = 0.32271409
Iteration 220, loss = 0.32081254
Iteration 221, loss = 0.31893015
Iteration 222, loss = 0.31705595
Iteration 223, loss = 0.31519335
Iteration 224, loss = 0.31332180
Iteration 225, loss = 0.31146929
Iteration 226, loss = 0.30963221
Iteration 227, loss = 0.30776918
Iteration 228, loss = 0.30592646
Iteration 229, loss = 0.30408044
Iteration 230, loss = 0.30225955
Iteration 231, loss = 0.30041997
Iteration 232, loss = 0.29860592
Iteration 233, loss = 0.29679088
Iteration 234, loss = 0.29501181
Iteration 235, loss = 0.29320777
Iteration 236, loss = 0.29144504
Iteration 237, loss = 0.28968817
Iteration 238, loss = 0.28792962
Iteration 239, loss = 0.28618437
Iteration 240, loss = 0.28445278
Iteration 241, loss = 0.28272931
Iteration 242, loss = 0.28101397
Iteration 243, loss = 0.27931649
Iteration 244, loss = 0.27762157
Iteration 245, loss = 0.27595261
Iteration 246, loss = 0.27428335
Iteration 247, loss = 0.27261746
Iteration 248, loss = 0.27095401
Iteration 249, loss = 0.26927899
Iteration 250, loss = 0.26765415
Iteration 251, loss = 0.26598009
Iteration 252, loss = 0.26435005
Iteration 253, loss = 0.26273116
Iteration 254, loss = 0.26111485
Iteration 255, loss = 0.25951445
Iteration 256, loss = 0.25792980
Iteration 257, loss = 0.25636912
Iteration 258, loss = 0.25481027
Iteration 259, loss = 0.25323283
Iteration 260, loss = 0.25167202
Iteration 261, loss = 0.25012734
Iteration 262, loss = 0.24859457
Iteration 263, loss = 0.24706072
Iteration 264, loss = 0.24553567
Iteration 265, loss = 0.24404446
Iteration 266, loss = 0.24253787
Iteration 267, loss = 0.24105158
Iteration 268, loss = 0.23958249
Iteration 269, loss = 0.23812869
Iteration 270, loss = 0.23666253
Iteration 271, loss = 0.23524018
Iteration 272, loss = 0.23382426
Iteration 273, loss = 0.23240184
Iteration 274, loss = 0.23101640
Iteration 275, loss = 0.22961616
Iteration 276, loss = 0.22823304
Iteration 277, loss = 0.22686304
Iteration 278, loss = 0.22552158
Iteration 279, loss = 0.22414145
Iteration 280, loss = 0.22281770
Iteration 281, loss = 0.22148900
Iteration 282, loss = 0.22017380
Iteration 283, loss = 0.21885517
Iteration 284, loss = 0.21754344
Iteration 285, loss = 0.21624562
Iteration 286, loss = 0.21496134
Iteration 287, loss = 0.21367501
Iteration 288, loss = 0.21239573
Iteration 289, loss = 0.21113941
Iteration 290, loss = 0.20989609
Iteration 291, loss = 0.20865125
Iteration 292, loss = 0.20742712
Iteration 293, loss = 0.20620823
Iteration 294, loss = 0.20499466
Iteration 295, loss = 0.20379707
Iteration 296, loss = 0.20260684
Iteration 297, loss = 0.20142977
Iteration 298, loss = 0.20025516
Iteration 299, loss = 0.19910010
Iteration 300, loss = 0.19796264
Iteration 301, loss = 0.19682623
Iteration 302, loss = 0.19569708
Iteration 303, loss = 0.19458779
Iteration 304, loss = 0.19348662
Iteration 305, loss = 0.19238416
Iteration 306, loss = 0.19129840
Iteration 307, loss = 0.19021060
Iteration 308, loss = 0.18913719
Iteration 309, loss = 0.18806666
Iteration 310, loss = 0.18701041
Iteration 311, loss = 0.18596451
Iteration 312, loss = 0.18491772
Iteration 313, loss = 0.18388903
Iteration 314, loss = 0.18286227
Iteration 315, loss = 0.18183945
Iteration 316, loss = 0.18083253
Iteration 317, loss = 0.17982006
Iteration 318, loss = 0.17883127
Iteration 319, loss = 0.17783667
Iteration 320, loss = 0.17685605
Iteration 321, loss = 0.17588318
Iteration 322, loss = 0.17491365
Iteration 323, loss = 0.17395510
Iteration 324, loss = 0.17300928
Iteration 325, loss = 0.17206300
Iteration 326, loss = 0.17113259
Iteration 327, loss = 0.17020037
Iteration 328, loss = 0.16927659
Iteration 329, loss = 0.16837125
Iteration 330, loss = 0.16747907
Iteration 331, loss = 0.16657932
Iteration 332, loss = 0.16569246
Iteration 333, loss = 0.16482690
Iteration 334, loss = 0.16396148
Iteration 335, loss = 0.16310518
Iteration 336, loss = 0.16225803
Iteration 337, loss = 0.16142842
Iteration 338, loss = 0.16058958
Iteration 339, loss = 0.15977236
Iteration 340, loss = 0.15894603
Iteration 341, loss = 0.15813079
Iteration 342, loss = 0.15731929
Iteration 343, loss = 0.15652295
Iteration 344, loss = 0.15572414
Iteration 345, loss = 0.15492624
Iteration 346, loss = 0.15414377
Iteration 347, loss = 0.15337022
Iteration 348, loss = 0.15259619
Iteration 349, loss = 0.15183804
Iteration 350, loss = 0.15108144
Iteration 351, loss = 0.15032614
Iteration 352, loss = 0.14957259
Iteration 353, loss = 0.14882663
Iteration 354, loss = 0.14807552
Iteration 355, loss = 0.14733115
Iteration 356, loss = 0.14659190
Iteration 357, loss = 0.14586302
Iteration 358, loss = 0.14513187
Iteration 359, loss = 0.14442373
Iteration 360, loss = 0.14370946
Iteration 361, loss = 0.14301413
Iteration 362, loss = 0.14231372
Iteration 363, loss = 0.14162814
Iteration 364, loss = 0.14094666
Iteration 365, loss = 0.14027383
Iteration 366, loss = 0.13959433
Iteration 367, loss = 0.13893328
Iteration 368, loss = 0.13827587
Iteration 369, loss = 0.13762308
Iteration 370, loss = 0.13697919
Iteration 371, loss = 0.13633794
Iteration 372, loss = 0.13570550
Iteration 373, loss = 0.13508274
Iteration 374, loss = 0.13446523
Iteration 375, loss = 0.13384739
Iteration 376, loss = 0.13324042
Iteration 377, loss = 0.13263895
Iteration 378, loss = 0.13204230
Iteration 379, loss = 0.13144661
Iteration 380, loss = 0.13085379
Iteration 381, loss = 0.13026754
Iteration 382, loss = 0.12968432
Iteration 383, loss = 0.12910510
Iteration 384, loss = 0.12853700
Iteration 385, loss = 0.12796742
Iteration 386, loss = 0.12740056
Iteration 387, loss = 0.12684513
Iteration 388, loss = 0.12628934
Iteration 389, loss = 0.12574029
Iteration 390, loss = 0.12519407
Iteration 391, loss = 0.12465122
Iteration 392, loss = 0.12412380
Iteration 393, loss = 0.12358843
Iteration 394, loss = 0.12306442
Iteration 395, loss = 0.12254439
Iteration 396, loss = 0.12202870
Iteration 397, loss = 0.12151795
Iteration 398, loss = 0.12100410
Iteration 399, loss = 0.12049970
Iteration 400, loss = 0.11999367
Iteration 401, loss = 0.11950040
Iteration 402, loss = 0.11899940
Iteration 403, loss = 0.11851434
Iteration 404, loss = 0.11802343
Iteration 405, loss = 0.11754761
Iteration 406, loss = 0.11705789
Iteration 407, loss = 0.11658494
Iteration 408, loss = 0.11611250
Iteration 409, loss = 0.11564486
Iteration 410, loss = 0.11517949
Iteration 411, loss = 0.11472133
Iteration 412, loss = 0.11426039
Iteration 413, loss = 0.11380778
Iteration 414, loss = 0.11335367
Iteration 415, loss = 0.11289857
Iteration 416, loss = 0.11245659
Iteration 417, loss = 0.11201453
Iteration 418, loss = 0.11157333
Iteration 419, loss = 0.11114249
Iteration 420, loss = 0.11071270
Iteration 421, loss = 0.11028485
Iteration 422, loss = 0.10986666
Iteration 423, loss = 0.10944007
Iteration 424, loss = 0.10901938
Iteration 425, loss = 0.10859805
Iteration 426, loss = 0.10818211
Iteration 427, loss = 0.10776363
Iteration 428, loss = 0.10734654
Iteration 429, loss = 0.10694218
Iteration 430, loss = 0.10653476
Iteration 431, loss = 0.10612633
Iteration 432, loss = 0.10572007
Iteration 433, loss = 0.10532726
Iteration 434, loss = 0.10492786
Iteration 435, loss = 0.10454083
Iteration 436, loss = 0.10415225
Iteration 437, loss = 0.10376818
Iteration 438, loss = 0.10338718
Iteration 439, loss = 0.10301015
Iteration 440, loss = 0.10263521
Iteration 441, loss = 0.10226249
Iteration 442, loss = 0.10189575
Iteration 443, loss = 0.10152805
Iteration 444, loss = 0.10116309
Iteration 445, loss = 0.10080226
Iteration 446, loss = 0.10044093
Iteration 447, loss = 0.10008361
Iteration 448, loss = 0.09972678
Iteration 449, loss = 0.09937582
Iteration 450, loss = 0.09902943
Iteration 451, loss = 0.09868318
Iteration 452, loss = 0.09833537
Iteration 453, loss = 0.09799713
Iteration 454, loss = 0.09765389
Iteration 455, loss = 0.09732262
Iteration 456, loss = 0.09698800
Iteration 457, loss = 0.09665764
Iteration 458, loss = 0.09633031
Iteration 459, loss = 0.09600210
Iteration 460, loss = 0.09567131
Iteration 461, loss = 0.09534738
Iteration 462, loss = 0.09502331
Iteration 463, loss = 0.09470269
Iteration 464, loss = 0.09437829
Iteration 465, loss = 0.09405193
Iteration 466, loss = 0.09373747
Iteration 467, loss = 0.09342042
Iteration 468, loss = 0.09311173
Iteration 469, loss = 0.09280333
Iteration 470, loss = 0.09249810
Iteration 471, loss = 0.09219906
Iteration 472, loss = 0.09189894
Iteration 473, loss = 0.09159673
Iteration 474, loss = 0.09130115
Iteration 475, loss = 0.09100631
Iteration 476, loss = 0.09071226
Iteration 477, loss = 0.09042628
Iteration 478, loss = 0.09014428
Iteration 479, loss = 0.08986051
Iteration 480, loss = 0.08957535
Iteration 481, loss = 0.08929835
Iteration 482, loss = 0.08900973
Iteration 483, loss = 0.08873065
Iteration 484, loss = 0.08844475
Iteration 485, loss = 0.08816849
Iteration 486, loss = 0.08789446
Iteration 487, loss = 0.08761105
Iteration 488, loss = 0.08734006
Iteration 489, loss = 0.08706511
Iteration 490, loss = 0.08679398
Iteration 491, loss = 0.08652231
Iteration 492, loss = 0.08626259
Iteration 493, loss = 0.08598762
Iteration 494, loss = 0.08572692
Iteration 495, loss = 0.08546910
Iteration 496, loss = 0.08520868
Iteration 497, loss = 0.08496106
Iteration 498, loss = 0.08470912
Iteration 499, loss = 0.08446150
Iteration 500, loss = 0.08422402
Iteration 501, loss = 0.08397640
Iteration 502, loss = 0.08373343
Iteration 503, loss = 0.08349572
Iteration 504, loss = 0.08325848
Iteration 505, loss = 0.08302296
Iteration 506, loss = 0.08279482
Iteration 507, loss = 0.08256179
Iteration 508, loss = 0.08233354
Iteration 509, loss = 0.08210381
Iteration 510, loss = 0.08187319
Iteration 511, loss = 0.08164799
Iteration 512, loss = 0.08142176
Iteration 513, loss = 0.08119523
Iteration 514, loss = 0.08097003
Iteration 515, loss = 0.08074062
Iteration 516, loss = 0.08051924
Iteration 517, loss = 0.08028897
Iteration 518, loss = 0.08007198
Iteration 519, loss = 0.07984225
Iteration 520, loss = 0.07962241
Iteration 521, loss = 0.07940730
Iteration 522, loss = 0.07918652
Iteration 523, loss = 0.07897256
Iteration 524, loss = 0.07875598
Iteration 525, loss = 0.07854922
Iteration 526, loss = 0.07833557
Iteration 527, loss = 0.07812898
Iteration 528, loss = 0.07792959
Iteration 529, loss = 0.07771652
Iteration 530, loss = 0.07751534
Iteration 531, loss = 0.07730965
Iteration 532, loss = 0.07710541
Iteration 533, loss = 0.07690724
Iteration 534, loss = 0.07670783
Iteration 535, loss = 0.07650950
Iteration 536, loss = 0.07630684
Iteration 537, loss = 0.07610342
Iteration 538, loss = 0.07590330
Iteration 539, loss = 0.07570219
Iteration 540, loss = 0.07550331
Iteration 541, loss = 0.07530755
Iteration 542, loss = 0.07511380
Iteration 543, loss = 0.07492079
Iteration 544, loss = 0.07472728
Iteration 545, loss = 0.07453532
Iteration 546, loss = 0.07434316
Iteration 547, loss = 0.07415460
Iteration 548, loss = 0.07396305
Iteration 549, loss = 0.07377968
Iteration 550, loss = 0.07359499
Iteration 551, loss = 0.07340814
Iteration 552, loss = 0.07322633
Iteration 553, loss = 0.07304038
Iteration 554, loss = 0.07286542
Iteration 555, loss = 0.07268836
Iteration 556, loss = 0.07251047
Iteration 557, loss = 0.07233082
Iteration 558, loss = 0.07216149
Iteration 559, loss = 0.07198878
Iteration 560, loss = 0.07181986
Iteration 561, loss = 0.07164989
Iteration 562, loss = 0.07148277
Iteration 563, loss = 0.07132253
Iteration 564, loss = 0.07115119
Iteration 565, loss = 0.07099495
Iteration 566, loss = 0.07082577
Iteration 567, loss = 0.07065594
Iteration 568, loss = 0.07048930
Iteration 569, loss = 0.07032889
Iteration 570, loss = 0.07015517
Iteration 571, loss = 0.06998881
Iteration 572, loss = 0.06981831
Iteration 573, loss = 0.06965539
Iteration 574, loss = 0.06949874
Iteration 575, loss = 0.06932614
Iteration 576, loss = 0.06916517
Iteration 577, loss = 0.06900978
Iteration 578, loss = 0.06884365
Iteration 579, loss = 0.06868382
Iteration 580, loss = 0.06852477
Iteration 581, loss = 0.06836534
Iteration 582, loss = 0.06820148
Iteration 583, loss = 0.06804436
Iteration 584, loss = 0.06788969
Iteration 585, loss = 0.06773587
Iteration 586, loss = 0.06758365
Iteration 587, loss = 0.06742998
Iteration 588, loss = 0.06727967
Iteration 589, loss = 0.06712651
Iteration 590, loss = 0.06697674
Iteration 591, loss = 0.06682846
Iteration 592, loss = 0.06667928
Iteration 593, loss = 0.06653155
Iteration 594, loss = 0.06638861
Iteration 595, loss = 0.06623606
Iteration 596, loss = 0.06608710
Iteration 597, loss = 0.06594231
Iteration 598, loss = 0.06579747
Iteration 599, loss = 0.06564353
Iteration 600, loss = 0.06550568
Iteration 601, loss = 0.06535411
Iteration 602, loss = 0.06521679
Iteration 603, loss = 0.06507443
Iteration 604, loss = 0.06493655
Iteration 605, loss = 0.06479410
Iteration 606, loss = 0.06465979
Iteration 607, loss = 0.06452119
Iteration 608, loss = 0.06438722
Iteration 609, loss = 0.06425832
Iteration 610, loss = 0.06412037
Iteration 611, loss = 0.06398543
Iteration 612, loss = 0.06385134
Iteration 613, loss = 0.06371979
Iteration 614, loss = 0.06358938
Iteration 615, loss = 0.06345295
Iteration 616, loss = 0.06332338
Iteration 617, loss = 0.06319684
Iteration 618, loss = 0.06306741
Iteration 619, loss = 0.06293793
Iteration 620, loss = 0.06281271
Iteration 621, loss = 0.06268701
Iteration 622, loss = 0.06256418
Iteration 623, loss = 0.06243821
Iteration 624, loss = 0.06231753
Iteration 625, loss = 0.06219316
Iteration 626, loss = 0.06207098
Iteration 627, loss = 0.06194755
Iteration 628, loss = 0.06182479
Iteration 629, loss = 0.06170527
Iteration 630, loss = 0.06157994
Iteration 631, loss = 0.06145433
Iteration 632, loss = 0.06133241
Iteration 633, loss = 0.06120610
Iteration 634, loss = 0.06108756
Iteration 635, loss = 0.06096140
Iteration 636, loss = 0.06084062
Iteration 637, loss = 0.06071685
Iteration 638, loss = 0.06060331
Iteration 639, loss = 0.06047942
Iteration 640, loss = 0.06035986
Iteration 641, loss = 0.06024275
Iteration 642, loss = 0.06012386
Iteration 643, loss = 0.06001410
Iteration 644, loss = 0.05989433
Iteration 645, loss = 0.05978512
Iteration 646, loss = 0.05967153
Iteration 647, loss = 0.05956143
Iteration 648, loss = 0.05944394
Iteration 649, loss = 0.05933336
Iteration 650, loss = 0.05922210
Iteration 651, loss = 0.05910978
Iteration 652, loss = 0.05899726
Iteration 653, loss = 0.05888741
Iteration 654, loss = 0.05877360
Iteration 655, loss = 0.05866752
Iteration 656, loss = 0.05855154
Iteration 657, loss = 0.05844185
Iteration 658, loss = 0.05833349
Iteration 659, loss = 0.05822432
Iteration 660, loss = 0.05811775
Iteration 661, loss = 0.05801070
Iteration 662, loss = 0.05789672
Iteration 663, loss = 0.05779107
Iteration 664, loss = 0.05767950
Iteration 665, loss = 0.05756821
Iteration 666, loss = 0.05746318
Iteration 667, loss = 0.05735057
Iteration 668, loss = 0.05724418
Iteration 669, loss = 0.05713765
Iteration 670, loss = 0.05702719
Iteration 671, loss = 0.05692282
Iteration 672, loss = 0.05681813
Iteration 673, loss = 0.05671207
Iteration 674, loss = 0.05661237
Iteration 675, loss = 0.05650981
Iteration 676, loss = 0.05640614
Iteration 677, loss = 0.05630521
Iteration 678, loss = 0.05620183
Iteration 679, loss = 0.05609885
Iteration 680, loss = 0.05600128
Iteration 681, loss = 0.05589744
Iteration 682, loss = 0.05580252
Iteration 683, loss = 0.05570199
Iteration 684, loss = 0.05559876
Iteration 685, loss = 0.05550261
Iteration 686, loss = 0.05540200
Iteration 687, loss = 0.05530464
Iteration 688, loss = 0.05520414
Iteration 689, loss = 0.05511052
Iteration 690, loss = 0.05500932
Iteration 691, loss = 0.05491512
Iteration 692, loss = 0.05481754
Iteration 693, loss = 0.05472106
Iteration 694, loss = 0.05462952
Iteration 695, loss = 0.05453065
Iteration 696, loss = 0.05443471
Iteration 697, loss = 0.05434028
Iteration 698, loss = 0.05424474
Iteration 699, loss = 0.05415304
Iteration 700, loss = 0.05405578
Iteration 701, loss = 0.05396533
Iteration 702, loss = 0.05387274
Iteration 703, loss = 0.05378212
Iteration 704, loss = 0.05369488
Iteration 705, loss = 0.05360017
Iteration 706, loss = 0.05350793
Iteration 707, loss = 0.05341418
Iteration 708, loss = 0.05331921
Iteration 709, loss = 0.05322794
Iteration 710, loss = 0.05313518
Iteration 711, loss = 0.05304275
Iteration 712, loss = 0.05295499
Iteration 713, loss = 0.05286485
Iteration 714, loss = 0.05277987
Iteration 715, loss = 0.05269112
Iteration 716, loss = 0.05260567
Iteration 717, loss = 0.05251850
Iteration 718, loss = 0.05243237
Iteration 719, loss = 0.05234610
Iteration 720, loss = 0.05226082
Iteration 721, loss = 0.05217501
Iteration 722, loss = 0.05209036
Iteration 723, loss = 0.05200341
Iteration 724, loss = 0.05191989
Iteration 725, loss = 0.05183439
Iteration 726, loss = 0.05174903
Iteration 727, loss = 0.05166540
Iteration 728, loss = 0.05158282
Iteration 729, loss = 0.05150101
Iteration 730, loss = 0.05141522
Iteration 731, loss = 0.05133061
Iteration 732, loss = 0.05124540
Iteration 733, loss = 0.05115663
Iteration 734, loss = 0.05106750
Iteration 735, loss = 0.05098216
Iteration 736, loss = 0.05089695
Iteration 737, loss = 0.05081214
Iteration 738, loss = 0.05073067
Iteration 739, loss = 0.05064846
Iteration 740, loss = 0.05056827
Iteration 741, loss = 0.05049048
Iteration 742, loss = 0.05041071
Iteration 743, loss = 0.05033041
Iteration 744, loss = 0.05025181
Iteration 745, loss = 0.05017217
Iteration 746, loss = 0.05009485
Iteration 747, loss = 0.05001382
Iteration 748, loss = 0.04993465
Iteration 749, loss = 0.04985630
Iteration 750, loss = 0.04977363
Iteration 751, loss = 0.04969398
Iteration 752, loss = 0.04961448
Iteration 753, loss = 0.04953772
Iteration 754, loss = 0.04945983
Iteration 755, loss = 0.04938453
Iteration 756, loss = 0.04930965
Iteration 757, loss = 0.04923060
Iteration 758, loss = 0.04915744
Iteration 759, loss = 0.04908124
Iteration 760, loss = 0.04900494
Iteration 761, loss = 0.04892868
Iteration 762, loss = 0.04885320
Iteration 763, loss = 0.04877892
Iteration 764, loss = 0.04869536
Iteration 765, loss = 0.04862085
Iteration 766, loss = 0.04854380
Iteration 767, loss = 0.04847207
Iteration 768, loss = 0.04839159
Iteration 769, loss = 0.04831905
Iteration 770, loss = 0.04824301
Iteration 771, loss = 0.04816784
Iteration 772, loss = 0.04809952
Iteration 773, loss = 0.04802115
Iteration 774, loss = 0.04794524
Iteration 775, loss = 0.04787263
Iteration 776, loss = 0.04779697
Iteration 777, loss = 0.04772369
Iteration 778, loss = 0.04765208
Iteration 779, loss = 0.04757668
Iteration 780, loss = 0.04750118
Iteration 781, loss = 0.04742676
Iteration 782, loss = 0.04735416
Iteration 783, loss = 0.04728017
Iteration 784, loss = 0.04720844
Iteration 785, loss = 0.04714216
Iteration 786, loss = 0.04707043
Iteration 787, loss = 0.04700081
Iteration 788, loss = 0.04692866
Iteration 789, loss = 0.04685892
Iteration 790, loss = 0.04678803
Iteration 791, loss = 0.04672037
Iteration 792, loss = 0.04664871
Iteration 793, loss = 0.04657929
Iteration 794, loss = 0.04650853
Iteration 795, loss = 0.04643680
Iteration 796, loss = 0.04636820
Iteration 797, loss = 0.04630349
Iteration 798, loss = 0.04622468
Iteration 799, loss = 0.04616112
Iteration 800, loss = 0.04608872
Iteration 801, loss = 0.04602025
Iteration 802, loss = 0.04595198
Iteration 803, loss = 0.04588702
Iteration 804, loss = 0.04581937
Iteration 805, loss = 0.04575326
Iteration 806, loss = 0.04568865
Iteration 807, loss = 0.04562073
Iteration 808, loss = 0.04555511
Iteration 809, loss = 0.04549217
Iteration 810, loss = 0.04542618
Iteration 811, loss = 0.04536390
Iteration 812, loss = 0.04530054
Iteration 813, loss = 0.04523884
Iteration 814, loss = 0.04517516
Iteration 815, loss = 0.04511446
Iteration 816, loss = 0.04504888
Iteration 817, loss = 0.04498628
Iteration 818, loss = 0.04492260
Iteration 819, loss = 0.04485592
Iteration 820, loss = 0.04479403
Iteration 821, loss = 0.04472718
Iteration 822, loss = 0.04466136
Iteration 823, loss = 0.04459248
Iteration 824, loss = 0.04452696
Iteration 825, loss = 0.04446304
Iteration 826, loss = 0.04439525
Iteration 827, loss = 0.04433268
Iteration 828, loss = 0.04426864
Iteration 829, loss = 0.04420568
Iteration 830, loss = 0.04414498
Iteration 831, loss = 0.04408188
Iteration 832, loss = 0.04401694
Iteration 833, loss = 0.04395158
Iteration 834, loss = 0.04389261
Iteration 835, loss = 0.04383098
Iteration 836, loss = 0.04376494
Iteration 837, loss = 0.04369961
Iteration 838, loss = 0.04363926
Iteration 839, loss = 0.04357596
Iteration 840, loss = 0.04351389
Iteration 841, loss = 0.04345417
Iteration 842, loss = 0.04339462
Iteration 843, loss = 0.04333565
Iteration 844, loss = 0.04327748
Iteration 845, loss = 0.04322262
Iteration 846, loss = 0.04316172
Iteration 847, loss = 0.04310306
Iteration 848, loss = 0.04304299
Iteration 849, loss = 0.04298563
Iteration 850, loss = 0.04292866
Iteration 851, loss = 0.04286863
Iteration 852, loss = 0.04280934
Iteration 853, loss = 0.04274663
Iteration 854, loss = 0.04268932
Iteration 855, loss = 0.04263122
Iteration 856, loss = 0.04257216
Iteration 857, loss = 0.04251540
Iteration 858, loss = 0.04245262
Iteration 859, loss = 0.04239112
Iteration 860, loss = 0.04233418
Iteration 861, loss = 0.04227436
Iteration 862, loss = 0.04221485
Iteration 863, loss = 0.04215415
Iteration 864, loss = 0.04209813
Iteration 865, loss = 0.04203728
Iteration 866, loss = 0.04198082
Iteration 867, loss = 0.04192330
Iteration 868, loss = 0.04187268
Iteration 869, loss = 0.04181197
Iteration 870, loss = 0.04175853
Iteration 871, loss = 0.04170873
Iteration 872, loss = 0.04164930
Iteration 873, loss = 0.04159612
Iteration 874, loss = 0.04154046
Iteration 875, loss = 0.04149062
Iteration 876, loss = 0.04143799
Iteration 877, loss = 0.04138545
Iteration 878, loss = 0.04133358
Iteration 879, loss = 0.04128489
Iteration 880, loss = 0.04122879
Iteration 881, loss = 0.04117694
Iteration 882, loss = 0.04112656
Iteration 883, loss = 0.04107683
Iteration 884, loss = 0.04102734
Iteration 885, loss = 0.04098136
Iteration 886, loss = 0.04092595
Iteration 887, loss = 0.04087629
Iteration 888, loss = 0.04082459
Iteration 889, loss = 0.04077413
Iteration 890, loss = 0.04072412
Iteration 891, loss = 0.04067415
Iteration 892, loss = 0.04062647
Iteration 893, loss = 0.04057417
Iteration 894, loss = 0.04052633
Iteration 895, loss = 0.04047359
Iteration 896, loss = 0.04042767
Iteration 897, loss = 0.04037535
Iteration 898, loss = 0.04032376
Iteration 899, loss = 0.04027330
Iteration 900, loss = 0.04022399
Iteration 901, loss = 0.04017330
Iteration 902, loss = 0.04012072
Iteration 903, loss = 0.04007152
Iteration 904, loss = 0.04002219
Iteration 905, loss = 0.03997149
Iteration 906, loss = 0.03991798
Iteration 907, loss = 0.03986814
Iteration 908, loss = 0.03981761
Iteration 909, loss = 0.03976701
Iteration 910, loss = 0.03971642
Iteration 911, loss = 0.03967212
Iteration 912, loss = 0.03962045
Iteration 913, loss = 0.03957855
Iteration 914, loss = 0.03952450
Iteration 915, loss = 0.03947931
Iteration 916, loss = 0.03943128
Iteration 917, loss = 0.03938701
Iteration 918, loss = 0.03933741
Iteration 919, loss = 0.03929145
Iteration 920, loss = 0.03924640
Iteration 921, loss = 0.03919833
Iteration 922, loss = 0.03915369
Iteration 923, loss = 0.03910741
Iteration 924, loss = 0.03906161
Iteration 925, loss = 0.03901625
Iteration 926, loss = 0.03897167
Iteration 927, loss = 0.03892587
Iteration 928, loss = 0.03887912
Iteration 929, loss = 0.03883713
Iteration 930, loss = 0.03878884
Iteration 931, loss = 0.03874559
Iteration 932, loss = 0.03869791
Iteration 933, loss = 0.03865071
Iteration 934, loss = 0.03860586
Iteration 935, loss = 0.03855992
Iteration 936, loss = 0.03851521
Iteration 937, loss = 0.03847224
Iteration 938, loss = 0.03842609
Iteration 939, loss = 0.03838221
Iteration 940, loss = 0.03833599
Iteration 941, loss = 0.03829109
Iteration 942, loss = 0.03824329
Iteration 943, loss = 0.03819707
Iteration 944, loss = 0.03815176
Iteration 945, loss = 0.03810258
Iteration 946, loss = 0.03806031
Iteration 947, loss = 0.03801219
Iteration 948, loss = 0.03796615
Iteration 949, loss = 0.03792335
Iteration 950, loss = 0.03787734
Iteration 951, loss = 0.03783437
Iteration 952, loss = 0.03778754
Iteration 953, loss = 0.03774914
Iteration 954, loss = 0.03770176
Iteration 955, loss = 0.03765760
Iteration 956, loss = 0.03761328
Iteration 957, loss = 0.03756835
Iteration 958, loss = 0.03752643
Iteration 959, loss = 0.03748305
Iteration 960, loss = 0.03744037
Iteration 961, loss = 0.03739651
Iteration 962, loss = 0.03735350
Iteration 963, loss = 0.03731084
Iteration 964, loss = 0.03726748
Iteration 965, loss = 0.03722534
Iteration 966, loss = 0.03718376
Iteration 967, loss = 0.03714142
Iteration 968, loss = 0.03710046
Iteration 969, loss = 0.03705935
Iteration 970, loss = 0.03701744
Iteration 971, loss = 0.03697742
Iteration 972, loss = 0.03693680
Iteration 973, loss = 0.03689478
Iteration 974, loss = 0.03685228
Iteration 975, loss = 0.03681022
Iteration 976, loss = 0.03676822
Iteration 977, loss = 0.03673024
Iteration 978, loss = 0.03668844
Iteration 979, loss = 0.03664789
Iteration 980, loss = 0.03660735
Iteration 981, loss = 0.03656660
Iteration 982, loss = 0.03652910
Iteration 983, loss = 0.03648985
Iteration 984, loss = 0.03645331
Iteration 985, loss = 0.03641413
Iteration 986, loss = 0.03637128
Iteration 987, loss = 0.03633114
Iteration 988, loss = 0.03629238
Iteration 989, loss = 0.03625751
Iteration 990, loss = 0.03621422
Iteration 991, loss = 0.03617368
Iteration 992, loss = 0.03613380
Iteration 993, loss = 0.03609200
Iteration 994, loss = 0.03605166
Iteration 995, loss = 0.03600932
Iteration 996, loss = 0.03597445
Iteration 997, loss = 0.03593641
Iteration 998, loss = 0.03589386
Iteration 999, loss = 0.03585511
Iteration 1000, loss = 0.03581637
Iteration 1001, loss = 0.03577891
Iteration 1002, loss = 0.03573984
Iteration 1003, loss = 0.03569844
Iteration 1004, loss = 0.03566116
Iteration 1005, loss = 0.03562404
Iteration 1006, loss = 0.03558469
Iteration 1007, loss = 0.03554267
Iteration 1008, loss = 0.03550676
Iteration 1009, loss = 0.03546312
Iteration 1010, loss = 0.03542471
Iteration 1011, loss = 0.03538313
Iteration 1012, loss = 0.03534403
Iteration 1013, loss = 0.03530634
Iteration 1014, loss = 0.03526459
Iteration 1015, loss = 0.03522665
Iteration 1016, loss = 0.03518903
Iteration 1017, loss = 0.03514881
Iteration 1018, loss = 0.03511054
Iteration 1019, loss = 0.03507011
Iteration 1020, loss = 0.03503000
Iteration 1021, loss = 0.03499208
Iteration 1022, loss = 0.03495166
Iteration 1023, loss = 0.03491044
Iteration 1024, loss = 0.03487553
Iteration 1025, loss = 0.03483218
Iteration 1026, loss = 0.03479372
Iteration 1027, loss = 0.03475343
Iteration 1028, loss = 0.03471986
Iteration 1029, loss = 0.03467883
Iteration 1030, loss = 0.03464063
Iteration 1031, loss = 0.03460448
Iteration 1032, loss = 0.03456787
Iteration 1033, loss = 0.03452952
Iteration 1034, loss = 0.03449463
Iteration 1035, loss = 0.03445854
Iteration 1036, loss = 0.03442069
Iteration 1037, loss = 0.03438694
Iteration 1038, loss = 0.03434826
Iteration 1039, loss = 0.03431215
Iteration 1040, loss = 0.03427444
Iteration 1041, loss = 0.03423792
Iteration 1042, loss = 0.03419976
Iteration 1043, loss = 0.03416561
Iteration 1044, loss = 0.03412767
Iteration 1045, loss = 0.03409217
Iteration 1046, loss = 0.03405723
Iteration 1047, loss = 0.03402104
Iteration 1048, loss = 0.03398706
Iteration 1049, loss = 0.03395030
Iteration 1050, loss = 0.03391517
Iteration 1051, loss = 0.03388039
Iteration 1052, loss = 0.03384560
Iteration 1053, loss = 0.03381292
Iteration 1054, loss = 0.03377597
Iteration 1055, loss = 0.03374147
Iteration 1056, loss = 0.03370950
Iteration 1057, loss = 0.03367190
Iteration 1058, loss = 0.03363633
Iteration 1059, loss = 0.03360191
Iteration 1060, loss = 0.03356871
Iteration 1061, loss = 0.03353268
Iteration 1062, loss = 0.03349645
Iteration 1063, loss = 0.03346311
Iteration 1064, loss = 0.03342654
Iteration 1065, loss = 0.03339272
Iteration 1066, loss = 0.03335762
Iteration 1067, loss = 0.03332396
Iteration 1068, loss = 0.03328942
Iteration 1069, loss = 0.03325581
Iteration 1070, loss = 0.03322030
Iteration 1071, loss = 0.03318680
Iteration 1072, loss = 0.03314509
Iteration 1073, loss = 0.03311082
Iteration 1074, loss = 0.03307476
Iteration 1075, loss = 0.03303934
Iteration 1076, loss = 0.03301102
Iteration 1077, loss = 0.03297443
Iteration 1078, loss = 0.03293918
Iteration 1079, loss = 0.03290735
Iteration 1080, loss = 0.03287100
Iteration 1081, loss = 0.03284092
Iteration 1082, loss = 0.03280613
Iteration 1083, loss = 0.03277114
Iteration 1084, loss = 0.03273799
Iteration 1085, loss = 0.03270422
Iteration 1086, loss = 0.03266881
Iteration 1087, loss = 0.03263464
Iteration 1088, loss = 0.03260370
Iteration 1089, loss = 0.03256912
Iteration 1090, loss = 0.03253539
Iteration 1091, loss = 0.03250160
Iteration 1092, loss = 0.03247024
Iteration 1093, loss = 0.03243490
Iteration 1094, loss = 0.03240467
Iteration 1095, loss = 0.03237146
Iteration 1096, loss = 0.03233852
Iteration 1097, loss = 0.03230416
Iteration 1098, loss = 0.03227203
Iteration 1099, loss = 0.03223915
Iteration 1100, loss = 0.03220609
Iteration 1101, loss = 0.03217030
Iteration 1102, loss = 0.03213555
Iteration 1103, loss = 0.03210247
Iteration 1104, loss = 0.03206907
Iteration 1105, loss = 0.03203704
Iteration 1106, loss = 0.03200255
Iteration 1107, loss = 0.03196930
Iteration 1108, loss = 0.03193786
Iteration 1109, loss = 0.03190490
Iteration 1110, loss = 0.03187502
Iteration 1111, loss = 0.03184161
Iteration 1112, loss = 0.03180814
Iteration 1113, loss = 0.03177702
Iteration 1114, loss = 0.03174549
Iteration 1115, loss = 0.03171293
Iteration 1116, loss = 0.03168216
Iteration 1117, loss = 0.03164984
Iteration 1118, loss = 0.03161880
Iteration 1119, loss = 0.03158875
Iteration 1120, loss = 0.03155757
Iteration 1121, loss = 0.03152579
Iteration 1122, loss = 0.03149480
Iteration 1123, loss = 0.03146265
Iteration 1124, loss = 0.03143166
Iteration 1125, loss = 0.03140054
Iteration 1126, loss = 0.03136948
Iteration 1127, loss = 0.03133795
Iteration 1128, loss = 0.03130714
Iteration 1129, loss = 0.03127949
Iteration 1130, loss = 0.03124543
Iteration 1131, loss = 0.03121460
Iteration 1132, loss = 0.03118127
Iteration 1133, loss = 0.03115019
Iteration 1134, loss = 0.03112809
Iteration 1135, loss = 0.03109239
Iteration 1136, loss = 0.03105885
Iteration 1137, loss = 0.03102968
Iteration 1138, loss = 0.03099763
Iteration 1139, loss = 0.03096577
Iteration 1140, loss = 0.03093504
Iteration 1141, loss = 0.03090517
Iteration 1142, loss = 0.03087463
Iteration 1143, loss = 0.03084389
Iteration 1144, loss = 0.03081502
Iteration 1145, loss = 0.03078414
Iteration 1146, loss = 0.03075613
Iteration 1147, loss = 0.03072549
Iteration 1148, loss = 0.03069450
Iteration 1149, loss = 0.03066502
Iteration 1150, loss = 0.03063435
Iteration 1151, loss = 0.03060435
Iteration 1152, loss = 0.03057807
Iteration 1153, loss = 0.03055029
Iteration 1154, loss = 0.03052133
Iteration 1155, loss = 0.03049266
Iteration 1156, loss = 0.03046158
Iteration 1157, loss = 0.03043511
Iteration 1158, loss = 0.03040530
Iteration 1159, loss = 0.03037587
Iteration 1160, loss = 0.03034684
Iteration 1161, loss = 0.03031664
Iteration 1162, loss = 0.03028776
Iteration 1163, loss = 0.03025874
Iteration 1164, loss = 0.03022945
Iteration 1165, loss = 0.03020420
Iteration 1166, loss = 0.03017645
Iteration 1167, loss = 0.03014907
Iteration 1168, loss = 0.03012204
Iteration 1169, loss = 0.03009564
Iteration 1170, loss = 0.03006499
Iteration 1171, loss = 0.03003942
Iteration 1172, loss = 0.03000869
Iteration 1173, loss = 0.02998064
Iteration 1174, loss = 0.02995573
Iteration 1175, loss = 0.02992871
Iteration 1176, loss = 0.02990186
Iteration 1177, loss = 0.02987628
Iteration 1178, loss = 0.02985383
Iteration 1179, loss = 0.02982644
Iteration 1180, loss = 0.02980080
Iteration 1181, loss = 0.02977241
Iteration 1182, loss = 0.02974522
Iteration 1183, loss = 0.02971529
Iteration 1184, loss = 0.02968777
Iteration 1185, loss = 0.02966103
Iteration 1186, loss = 0.02963278
Iteration 1187, loss = 0.02960588
Iteration 1188, loss = 0.02957890
Iteration 1189, loss = 0.02955349
Iteration 1190, loss = 0.02952683
Iteration 1191, loss = 0.02950112
Iteration 1192, loss = 0.02947425
Iteration 1193, loss = 0.02944726
Iteration 1194, loss = 0.02941869
Iteration 1195, loss = 0.02939345
Iteration 1196, loss = 0.02936490
Iteration 1197, loss = 0.02934072
Iteration 1198, loss = 0.02930968
Iteration 1199, loss = 0.02928439
Iteration 1200, loss = 0.02925661
Iteration 1201, loss = 0.02922981
Iteration 1202, loss = 0.02920321
Iteration 1203, loss = 0.02917773
Iteration 1204, loss = 0.02915026
Iteration 1205, loss = 0.02912482
Iteration 1206, loss = 0.02909974
Iteration 1207, loss = 0.02907418
Iteration 1208, loss = 0.02904967
Iteration 1209, loss = 0.02902379
Iteration 1210, loss = 0.02899947
Iteration 1211, loss = 0.02897606
Iteration 1212, loss = 0.02895183
Iteration 1213, loss = 0.02892580
Iteration 1214, loss = 0.02890211
Iteration 1215, loss = 0.02887739
Iteration 1216, loss = 0.02885324
Iteration 1217, loss = 0.02882747
Iteration 1218, loss = 0.02880265
Iteration 1219, loss = 0.02877582
Iteration 1220, loss = 0.02874826
Iteration 1221, loss = 0.02872580
Iteration 1222, loss = 0.02869674
Iteration 1223, loss = 0.02866961
Iteration 1224, loss = 0.02864320
Iteration 1225, loss = 0.02862280
Iteration 1226, loss = 0.02859547
Iteration 1227, loss = 0.02856723
Iteration 1228, loss = 0.02854119
Iteration 1229, loss = 0.02851482
Iteration 1230, loss = 0.02848944
Iteration 1231, loss = 0.02846223
Iteration 1232, loss = 0.02843398
Iteration 1233, loss = 0.02840860
Iteration 1234, loss = 0.02838599
Iteration 1235, loss = 0.02835748
Iteration 1236, loss = 0.02833277
Iteration 1237, loss = 0.02830799
Iteration 1238, loss = 0.02828074
Iteration 1239, loss = 0.02825380
Iteration 1240, loss = 0.02823175
Iteration 1241, loss = 0.02820370
Iteration 1242, loss = 0.02818028
Iteration 1243, loss = 0.02815689
Iteration 1244, loss = 0.02813106
Iteration 1245, loss = 0.02810644
Iteration 1246, loss = 0.02807913
Iteration 1247, loss = 0.02805473
Iteration 1248, loss = 0.02802949
Iteration 1249, loss = 0.02800625
Iteration 1250, loss = 0.02798173
Iteration 1251, loss = 0.02795580
Iteration 1252, loss = 0.02792862
Iteration 1253, loss = 0.02790383
Iteration 1254, loss = 0.02787908
Iteration 1255, loss = 0.02785119
Iteration 1256, loss = 0.02782620
Iteration 1257, loss = 0.02779815
Iteration 1258, loss = 0.02777399
Iteration 1259, loss = 0.02774749
Iteration 1260, loss = 0.02772209
Iteration 1261, loss = 0.02769691
Iteration 1262, loss = 0.02766962
Iteration 1263, loss = 0.02764502
Iteration 1264, loss = 0.02762067
Iteration 1265, loss = 0.02759512
Iteration 1266, loss = 0.02757057
Iteration 1267, loss = 0.02754591
Iteration 1268, loss = 0.02752283
Iteration 1269, loss = 0.02749933
Iteration 1270, loss = 0.02747309
Iteration 1271, loss = 0.02744960
Iteration 1272, loss = 0.02742554
Iteration 1273, loss = 0.02740002
Iteration 1274, loss = 0.02737641
Iteration 1275, loss = 0.02735060
Iteration 1276, loss = 0.02732833
Iteration 1277, loss = 0.02730187
Iteration 1278, loss = 0.02727772
Iteration 1279, loss = 0.02725273
Iteration 1280, loss = 0.02722692
Iteration 1281, loss = 0.02720472
Iteration 1282, loss = 0.02718232
Iteration 1283, loss = 0.02715715
Iteration 1284, loss = 0.02713470
Iteration 1285, loss = 0.02711176
Iteration 1286, loss = 0.02708871
Iteration 1287, loss = 0.02706698
Iteration 1288, loss = 0.02704460
Iteration 1289, loss = 0.02702031
Iteration 1290, loss = 0.02699851
Iteration 1291, loss = 0.02697474
Iteration 1292, loss = 0.02695084
Iteration 1293, loss = 0.02692811
Iteration 1294, loss = 0.02690545
Iteration 1295, loss = 0.02688078
Iteration 1296, loss = 0.02685854
Iteration 1297, loss = 0.02683676
Iteration 1298, loss = 0.02681237
Iteration 1299, loss = 0.02678923
Iteration 1300, loss = 0.02676489
Iteration 1301, loss = 0.02674212
Iteration 1302, loss = 0.02671959
Iteration 1303, loss = 0.02669716
Iteration 1304, loss = 0.02667275
Iteration 1305, loss = 0.02665252
Iteration 1306, loss = 0.02662727
Iteration 1307, loss = 0.02660386
Iteration 1308, loss = 0.02658101
Iteration 1309, loss = 0.02655772
Iteration 1310, loss = 0.02653374
Iteration 1311, loss = 0.02650689
Iteration 1312, loss = 0.02648295
Iteration 1313, loss = 0.02645892
Iteration 1314, loss = 0.02643634
Iteration 1315, loss = 0.02641365
Iteration 1316, loss = 0.02638870
Iteration 1317, loss = 0.02636590
Iteration 1318, loss = 0.02634475
Iteration 1319, loss = 0.02632050
Iteration 1320, loss = 0.02629720
Iteration 1321, loss = 0.02627497
Iteration 1322, loss = 0.02625518
Iteration 1323, loss = 0.02623172
Iteration 1324, loss = 0.02621057
Iteration 1325, loss = 0.02618803
Iteration 1326, loss = 0.02616623
Iteration 1327, loss = 0.02614510
Iteration 1328, loss = 0.02612332
Iteration 1329, loss = 0.02610191
Iteration 1330, loss = 0.02608362
Iteration 1331, loss = 0.02606004
Iteration 1332, loss = 0.02603730
Iteration 1333, loss = 0.02601410
Iteration 1334, loss = 0.02599658
Iteration 1335, loss = 0.02597265
Iteration 1336, loss = 0.02595322
Iteration 1337, loss = 0.02593092
Iteration 1338, loss = 0.02590924
Iteration 1339, loss = 0.02588958
Iteration 1340, loss = 0.02586683
Iteration 1341, loss = 0.02584548
Iteration 1342, loss = 0.02582379
Iteration 1343, loss = 0.02580243
Iteration 1344, loss = 0.02578152
Iteration 1345, loss = 0.02576277
Iteration 1346, loss = 0.02574037
Iteration 1347, loss = 0.02571939
Iteration 1348, loss = 0.02569860
Iteration 1349, loss = 0.02567878
Iteration 1350, loss = 0.02565848
Iteration 1351, loss = 0.02563640
Iteration 1352, loss = 0.02561531
Iteration 1353, loss = 0.02559441
Iteration 1354, loss = 0.02557196
Iteration 1355, loss = 0.02554856
Iteration 1356, loss = 0.02552647
Iteration 1357, loss = 0.02550811
Iteration 1358, loss = 0.02548344
Iteration 1359, loss = 0.02546248
Iteration 1360, loss = 0.02543997
Iteration 1361, loss = 0.02541968
Iteration 1362, loss = 0.02539886
Iteration 1363, loss = 0.02537797
Iteration 1364, loss = 0.02535706
Iteration 1365, loss = 0.02533707
Iteration 1366, loss = 0.02531722
Iteration 1367, loss = 0.02529764
Iteration 1368, loss = 0.02527798
Iteration 1369, loss = 0.02525977
Iteration 1370, loss = 0.02523981
Iteration 1371, loss = 0.02522121
Iteration 1372, loss = 0.02520150
Iteration 1373, loss = 0.02518305
Iteration 1374, loss = 0.02516423
Iteration 1375, loss = 0.02514484
Iteration 1376, loss = 0.02512636
Iteration 1377, loss = 0.02510823
Iteration 1378, loss = 0.02508607
Iteration 1379, loss = 0.02506567
Iteration 1380, loss = 0.02504688
Iteration 1381, loss = 0.02502718
Iteration 1382, loss = 0.02500746
Iteration 1383, loss = 0.02498746
Iteration 1384, loss = 0.02496853
Iteration 1385, loss = 0.02494765
Iteration 1386, loss = 0.02493001
Iteration 1387, loss = 0.02491106
Iteration 1388, loss = 0.02489278
Iteration 1389, loss = 0.02487036
Iteration 1390, loss = 0.02485031
Iteration 1391, loss = 0.02482993
Iteration 1392, loss = 0.02481013
Iteration 1393, loss = 0.02479201
Iteration 1394, loss = 0.02477029
Iteration 1395, loss = 0.02475256
Iteration 1396, loss = 0.02473131
Iteration 1397, loss = 0.02471059
Iteration 1398, loss = 0.02469321
Iteration 1399, loss = 0.02467084
Iteration 1400, loss = 0.02465409
Iteration 1401, loss = 0.02463253
Iteration 1402, loss = 0.02461348
Iteration 1403, loss = 0.02459381
Iteration 1404, loss = 0.02457486
Iteration 1405, loss = 0.02455580
Iteration 1406, loss = 0.02453635
Iteration 1407, loss = 0.02451746
Iteration 1408, loss = 0.02449634
Iteration 1409, loss = 0.02447662
Iteration 1410, loss = 0.02445320
Iteration 1411, loss = 0.02443592
Iteration 1412, loss = 0.02441286
Iteration 1413, loss = 0.02439571
Iteration 1414, loss = 0.02437484
Iteration 1415, loss = 0.02435512
Iteration 1416, loss = 0.02433647
Iteration 1417, loss = 0.02431760
Iteration 1418, loss = 0.02429939
Iteration 1419, loss = 0.02428044
Iteration 1420, loss = 0.02425865
Iteration 1421, loss = 0.02424074
Iteration 1422, loss = 0.02422030
Iteration 1423, loss = 0.02419971
Iteration 1424, loss = 0.02417931
Iteration 1425, loss = 0.02416132
Iteration 1426, loss = 0.02414339
Iteration 1427, loss = 0.02412299
Iteration 1428, loss = 0.02410466
Iteration 1429, loss = 0.02408593
Iteration 1430, loss = 0.02406639
Iteration 1431, loss = 0.02404871
Iteration 1432, loss = 0.02403059
Iteration 1433, loss = 0.02401187
Iteration 1434, loss = 0.02399435
Iteration 1435, loss = 0.02397419
Iteration 1436, loss = 0.02395498
Iteration 1437, loss = 0.02393684
Iteration 1438, loss = 0.02391693
Iteration 1439, loss = 0.02389997
Iteration 1440, loss = 0.02387923
Iteration 1441, loss = 0.02385860
Iteration 1442, loss = 0.02384085
Iteration 1443, loss = 0.02382236
Iteration 1444, loss = 0.02380365
Iteration 1445, loss = 0.02378620
Iteration 1446, loss = 0.02376712
Iteration 1447, loss = 0.02374739
Iteration 1448, loss = 0.02372893
Iteration 1449, loss = 0.02371162
Iteration 1450, loss = 0.02369265
Iteration 1451, loss = 0.02367565
Iteration 1452, loss = 0.02365811
Iteration 1453, loss = 0.02364023
Iteration 1454, loss = 0.02361993
Iteration 1455, loss = 0.02360171
Iteration 1456, loss = 0.02358410
Iteration 1457, loss = 0.02356563
Iteration 1458, loss = 0.02354613
Iteration 1459, loss = 0.02353142
Iteration 1460, loss = 0.02351090
Iteration 1461, loss = 0.02349160
Iteration 1462, loss = 0.02347272
Iteration 1463, loss = 0.02345509
Iteration 1464, loss = 0.02343725
Iteration 1465, loss = 0.02341824
Iteration 1466, loss = 0.02340070
Iteration 1467, loss = 0.02338495
Iteration 1468, loss = 0.02336672
Iteration 1469, loss = 0.02334950
Iteration 1470, loss = 0.02333116
Iteration 1471, loss = 0.02331358
Iteration 1472, loss = 0.02329677
Iteration 1473, loss = 0.02327866
Iteration 1474, loss = 0.02326150
Iteration 1475, loss = 0.02324388
Iteration 1476, loss = 0.02322655
Iteration 1477, loss = 0.02320768
Iteration 1478, loss = 0.02318825
Iteration 1479, loss = 0.02317005
Iteration 1480, loss = 0.02315324
Iteration 1481, loss = 0.02313367
Iteration 1482, loss = 0.02311741
Iteration 1483, loss = 0.02309850
Iteration 1484, loss = 0.02308298
Iteration 1485, loss = 0.02306530
Iteration 1486, loss = 0.02304785
Iteration 1487, loss = 0.02303186
Iteration 1488, loss = 0.02301454
Iteration 1489, loss = 0.02299707
Iteration 1490, loss = 0.02298159
Iteration 1491, loss = 0.02296239
Iteration 1492, loss = 0.02294438
Iteration 1493, loss = 0.02292558
Iteration 1494, loss = 0.02290581
Iteration 1495, loss = 0.02288821
Iteration 1496, loss = 0.02286921
Iteration 1497, loss = 0.02285031
Iteration 1498, loss = 0.02283137
Iteration 1499, loss = 0.02281464
Iteration 1500, loss = 0.02279558
Iteration 1501, loss = 0.02277883
Iteration 1502, loss = 0.02276121
Iteration 1503, loss = 0.02274465
Iteration 1504, loss = 0.02272804
Iteration 1505, loss = 0.02271109
Iteration 1506, loss = 0.02269518
Iteration 1507, loss = 0.02267770
Iteration 1508, loss = 0.02266149
Iteration 1509, loss = 0.02264505
Iteration 1510, loss = 0.02263040
Iteration 1511, loss = 0.02261245
Iteration 1512, loss = 0.02259561
Iteration 1513, loss = 0.02257851
Iteration 1514, loss = 0.02256194
Iteration 1515, loss = 0.02254612
Iteration 1516, loss = 0.02252840
Iteration 1517, loss = 0.02251053
Iteration 1518, loss = 0.02249388
Iteration 1519, loss = 0.02247660
Iteration 1520, loss = 0.02246033
Iteration 1521, loss = 0.02244611
Iteration 1522, loss = 0.02242990
Iteration 1523, loss = 0.02241629
Iteration 1524, loss = 0.02239815
Iteration 1525, loss = 0.02238219
Iteration 1526, loss = 0.02236717
Iteration 1527, loss = 0.02234897
Iteration 1528, loss = 0.02233357
Iteration 1529, loss = 0.02231547
Iteration 1530, loss = 0.02229898
Iteration 1531, loss = 0.02228146
Iteration 1532, loss = 0.02226485
Iteration 1533, loss = 0.02224838
Iteration 1534, loss = 0.02223221
Iteration 1535, loss = 0.02221441
Iteration 1536, loss = 0.02219713
Iteration 1537, loss = 0.02217989
Iteration 1538, loss = 0.02216466
Iteration 1539, loss = 0.02214658
Iteration 1540, loss = 0.02212888
Iteration 1541, loss = 0.02211165
Iteration 1542, loss = 0.02209483
Iteration 1543, loss = 0.02207716
Iteration 1544, loss = 0.02206408
Iteration 1545, loss = 0.02204571
Iteration 1546, loss = 0.02202780
Iteration 1547, loss = 0.02201088
Iteration 1548, loss = 0.02199572
Iteration 1549, loss = 0.02197570
Iteration 1550, loss = 0.02196150
Iteration 1551, loss = 0.02194374
Iteration 1552, loss = 0.02192678
Iteration 1553, loss = 0.02191012
Iteration 1554, loss = 0.02189279
Iteration 1555, loss = 0.02187939
Iteration 1556, loss = 0.02186112
Iteration 1557, loss = 0.02184367
Iteration 1558, loss = 0.02182793
Iteration 1559, loss = 0.02181250
Iteration 1560, loss = 0.02179620
Iteration 1561, loss = 0.02178119
Iteration 1562, loss = 0.02176453
Iteration 1563, loss = 0.02174846
Iteration 1564, loss = 0.02173221
Iteration 1565, loss = 0.02171500
Iteration 1566, loss = 0.02170053
Iteration 1567, loss = 0.02168292
Iteration 1568, loss = 0.02166648
Iteration 1569, loss = 0.02165179
Iteration 1570, loss = 0.02163361
Iteration 1571, loss = 0.02161766
Iteration 1572, loss = 0.02160073
Iteration 1573, loss = 0.02158539
Iteration 1574, loss = 0.02156850
Iteration 1575, loss = 0.02155244
Iteration 1576, loss = 0.02153570
Iteration 1577, loss = 0.02151885
Iteration 1578, loss = 0.02150279
Iteration 1579, loss = 0.02148623
Iteration 1580, loss = 0.02147011
Iteration 1581, loss = 0.02145493
Iteration 1582, loss = 0.02143956
Iteration 1583, loss = 0.02142635
Iteration 1584, loss = 0.02141184
Iteration 1585, loss = 0.02139709
Iteration 1586, loss = 0.02138048
Iteration 1587, loss = 0.02136417
Iteration 1588, loss = 0.02134921
Iteration 1589, loss = 0.02133319
Iteration 1590, loss = 0.02131810
Iteration 1591, loss = 0.02130116
Iteration 1592, loss = 0.02128658
Iteration 1593, loss = 0.02127294
Iteration 1594, loss = 0.02125609
Iteration 1595, loss = 0.02124020
Iteration 1596, loss = 0.02122345
Iteration 1597, loss = 0.02120877
Iteration 1598, loss = 0.02119248
Iteration 1599, loss = 0.02117689
Iteration 1600, loss = 0.02116107
Iteration 1601, loss = 0.02114517
Iteration 1602, loss = 0.02112990
Iteration 1603, loss = 0.02111476
Iteration 1604, loss = 0.02109889
Iteration 1605, loss = 0.02108360
Iteration 1606, loss = 0.02106816
Iteration 1607, loss = 0.02105233
Iteration 1608, loss = 0.02103675
Iteration 1609, loss = 0.02102277
Iteration 1610, loss = 0.02100781
Iteration 1611, loss = 0.02099085
Iteration 1612, loss = 0.02097839
Iteration 1613, loss = 0.02096046
Iteration 1614, loss = 0.02094580
Iteration 1615, loss = 0.02092944
Iteration 1616, loss = 0.02091387
Iteration 1617, loss = 0.02089889
Iteration 1618, loss = 0.02088374
Iteration 1619, loss = 0.02086807
Iteration 1620, loss = 0.02085441
Iteration 1621, loss = 0.02083634
Iteration 1622, loss = 0.02082148
Iteration 1623, loss = 0.02080569
Iteration 1624, loss = 0.02078972
Iteration 1625, loss = 0.02077437
Iteration 1626, loss = 0.02076042
Iteration 1627, loss = 0.02074493
Iteration 1628, loss = 0.02073067
Iteration 1629, loss = 0.02071536
Iteration 1630, loss = 0.02070085
Iteration 1631, loss = 0.02068591
Iteration 1632, loss = 0.02067236
Iteration 1633, loss = 0.02065961
Iteration 1634, loss = 0.02064243
Iteration 1635, loss = 0.02062678
Iteration 1636, loss = 0.02061227
Iteration 1637, loss = 0.02059694
Iteration 1638, loss = 0.02058084
Iteration 1639, loss = 0.02056567
Iteration 1640, loss = 0.02055513
Iteration 1641, loss = 0.02053646
Iteration 1642, loss = 0.02052522
Iteration 1643, loss = 0.02050936
Iteration 1644, loss = 0.02049409
Iteration 1645, loss = 0.02048105
Iteration 1646, loss = 0.02046527
Iteration 1647, loss = 0.02045041
Iteration 1648, loss = 0.02043664
Iteration 1649, loss = 0.02042095
Iteration 1650, loss = 0.02040780
Iteration 1651, loss = 0.02039350
Iteration 1652, loss = 0.02037930
Iteration 1653, loss = 0.02036596
Iteration 1654, loss = 0.02035126
Iteration 1655, loss = 0.02033759
Iteration 1656, loss = 0.02032665
Iteration 1657, loss = 0.02031084
Iteration 1658, loss = 0.02029764
Iteration 1659, loss = 0.02028354
Iteration 1660, loss = 0.02026727
Iteration 1661, loss = 0.02025327
Iteration 1662, loss = 0.02024004
Iteration 1663, loss = 0.02022458
Iteration 1664, loss = 0.02020914
Iteration 1665, loss = 0.02019516
Iteration 1666, loss = 0.02018043
Iteration 1667, loss = 0.02016559
Iteration 1668, loss = 0.02015152
Iteration 1669, loss = 0.02013767
Iteration 1670, loss = 0.02012330
Iteration 1671, loss = 0.02011139
Iteration 1672, loss = 0.02009475
Iteration 1673, loss = 0.02008132
Iteration 1674, loss = 0.02006735
Iteration 1675, loss = 0.02005437
Iteration 1676, loss = 0.02003874
Iteration 1677, loss = 0.02002427
Iteration 1678, loss = 0.02001100
Iteration 1679, loss = 0.01999745
Iteration 1680, loss = 0.01998751
Iteration 1681, loss = 0.01997213
Iteration 1682, loss = 0.01995834
Iteration 1683, loss = 0.01994503
Iteration 1684, loss = 0.01993095
Iteration 1685, loss = 0.01991954
Iteration 1686, loss = 0.01990488
Iteration 1687, loss = 0.01989091
Iteration 1688, loss = 0.01987763
Iteration 1689, loss = 0.01986396
Iteration 1690, loss = 0.01984979
Iteration 1691, loss = 0.01983729
Iteration 1692, loss = 0.01982406
Iteration 1693, loss = 0.01981013
Iteration 1694, loss = 0.01979598
Iteration 1695, loss = 0.01978463
Iteration 1696, loss = 0.01977008
Iteration 1697, loss = 0.01975810
Iteration 1698, loss = 0.01974339
Iteration 1699, loss = 0.01972914
Iteration 1700, loss = 0.01971532
Iteration 1701, loss = 0.01970189
Iteration 1702, loss = 0.01968778
Iteration 1703, loss = 0.01967451
Iteration 1704, loss = 0.01966252
Iteration 1705, loss = 0.01964749
Iteration 1706, loss = 0.01963558
Iteration 1707, loss = 0.01962070
Iteration 1708, loss = 0.01960787
Iteration 1709, loss = 0.01959341
Iteration 1710, loss = 0.01957949
Iteration 1711, loss = 0.01956607
Iteration 1712, loss = 0.01955417
Iteration 1713, loss = 0.01953896
Iteration 1714, loss = 0.01952497
Iteration 1715, loss = 0.01951086
Iteration 1716, loss = 0.01949744
Iteration 1717, loss = 0.01948791
Iteration 1718, loss = 0.01947136
Iteration 1719, loss = 0.01945633
Iteration 1720, loss = 0.01944266
Iteration 1721, loss = 0.01942911
Iteration 1722, loss = 0.01941555
Iteration 1723, loss = 0.01940278
Iteration 1724, loss = 0.01938840
Iteration 1725, loss = 0.01937567
Iteration 1726, loss = 0.01936257
Iteration 1727, loss = 0.01934993
Iteration 1728, loss = 0.01933594
Iteration 1729, loss = 0.01932291
Iteration 1730, loss = 0.01930969
Iteration 1731, loss = 0.01929733
Iteration 1732, loss = 0.01928512
Iteration 1733, loss = 0.01927142
Iteration 1734, loss = 0.01925830
Iteration 1735, loss = 0.01924416
Iteration 1736, loss = 0.01923335
Iteration 1737, loss = 0.01922052
Iteration 1738, loss = 0.01920867
Iteration 1739, loss = 0.01919450
Iteration 1740, loss = 0.01918177
Iteration 1741, loss = 0.01916970
Iteration 1742, loss = 0.01915521
Iteration 1743, loss = 0.01914271
Iteration 1744, loss = 0.01912974
Iteration 1745, loss = 0.01911937
Iteration 1746, loss = 0.01910609
Iteration 1747, loss = 0.01909270
Iteration 1748, loss = 0.01907916
Iteration 1749, loss = 0.01906668
Iteration 1750, loss = 0.01905398
Iteration 1751, loss = 0.01904021
Iteration 1752, loss = 0.01903137
Iteration 1753, loss = 0.01901592
Iteration 1754, loss = 0.01900341
Iteration 1755, loss = 0.01899120
Iteration 1756, loss = 0.01897829
Iteration 1757, loss = 0.01896597
Iteration 1758, loss = 0.01895201
Iteration 1759, loss = 0.01893932
Iteration 1760, loss = 0.01892612
Iteration 1761, loss = 0.01891311
Iteration 1762, loss = 0.01889979
Iteration 1763, loss = 0.01888780
Iteration 1764, loss = 0.01887496
Iteration 1765, loss = 0.01886189
Iteration 1766, loss = 0.01884943
Iteration 1767, loss = 0.01883596
Iteration 1768, loss = 0.01882311
Iteration 1769, loss = 0.01881262
Iteration 1770, loss = 0.01879800
Iteration 1771, loss = 0.01878612
Iteration 1772, loss = 0.01877327
Iteration 1773, loss = 0.01876071
Iteration 1774, loss = 0.01874773
Iteration 1775, loss = 0.01873736
Iteration 1776, loss = 0.01872632
Iteration 1777, loss = 0.01871033
Iteration 1778, loss = 0.01869768
Iteration 1779, loss = 0.01868409
Iteration 1780, loss = 0.01867000
Iteration 1781, loss = 0.01865714
Iteration 1782, loss = 0.01864532
Iteration 1783, loss = 0.01863108
Iteration 1784, loss = 0.01861820
Iteration 1785, loss = 0.01860558
Iteration 1786, loss = 0.01859229
Iteration 1787, loss = 0.01858005
Iteration 1788, loss = 0.01856647
Iteration 1789, loss = 0.01855509
Iteration 1790, loss = 0.01853934
Iteration 1791, loss = 0.01852589
Iteration 1792, loss = 0.01851225
Iteration 1793, loss = 0.01849870
Iteration 1794, loss = 0.01848544
Iteration 1795, loss = 0.01847258
Iteration 1796, loss = 0.01846001
Iteration 1797, loss = 0.01844711
Iteration 1798, loss = 0.01843454
Iteration 1799, loss = 0.01842245
Iteration 1800, loss = 0.01840932
Iteration 1801, loss = 0.01839909
Iteration 1802, loss = 0.01838416
Iteration 1803, loss = 0.01837189
Iteration 1804, loss = 0.01835940
Iteration 1805, loss = 0.01835060
Iteration 1806, loss = 0.01833500
Iteration 1807, loss = 0.01832397
Iteration 1808, loss = 0.01831018
Iteration 1809, loss = 0.01829855
Iteration 1810, loss = 0.01828589
Iteration 1811, loss = 0.01827274
Iteration 1812, loss = 0.01825981
Iteration 1813, loss = 0.01825119
Iteration 1814, loss = 0.01823751
Iteration 1815, loss = 0.01822527
Iteration 1816, loss = 0.01821301
Iteration 1817, loss = 0.01820222
Iteration 1818, loss = 0.01819260
Iteration 1819, loss = 0.01817834
Iteration 1820, loss = 0.01816636
Iteration 1821, loss = 0.01815425
Iteration 1822, loss = 0.01814256
Iteration 1823, loss = 0.01813007
Iteration 1824, loss = 0.01811744
Iteration 1825, loss = 0.01810550
Iteration 1826, loss = 0.01809578
Iteration 1827, loss = 0.01808161
Iteration 1828, loss = 0.01806994
Iteration 1829, loss = 0.01805791
Iteration 1830, loss = 0.01804703
Iteration 1831, loss = 0.01803487
Iteration 1832, loss = 0.01802375
Iteration 1833, loss = 0.01801209
Iteration 1834, loss = 0.01800035
Iteration 1835, loss = 0.01799001
Iteration 1836, loss = 0.01797798
Iteration 1837, loss = 0.01796540
Iteration 1838, loss = 0.01795398
Iteration 1839, loss = 0.01794214
Iteration 1840, loss = 0.01792939
Iteration 1841, loss = 0.01791868
Iteration 1842, loss = 0.01790605
Iteration 1843, loss = 0.01789335
Iteration 1844, loss = 0.01788202
Iteration 1845, loss = 0.01787141
Iteration 1846, loss = 0.01785969
Iteration 1847, loss = 0.01784799
Iteration 1848, loss = 0.01783550
Iteration 1849, loss = 0.01782458
Iteration 1850, loss = 0.01781331
Iteration 1851, loss = 0.01780238
Iteration 1852, loss = 0.01778974
Iteration 1853, loss = 0.01777772
Iteration 1854, loss = 0.01776579
Iteration 1855, loss = 0.01775691
Iteration 1856, loss = 0.01774375
Iteration 1857, loss = 0.01773153
Iteration 1858, loss = 0.01772049
Iteration 1859, loss = 0.01770788
Iteration 1860, loss = 0.01769555
Iteration 1861, loss = 0.01768518
Iteration 1862, loss = 0.01767269
Iteration 1863, loss = 0.01766115
Iteration 1864, loss = 0.01765086
Iteration 1865, loss = 0.01763903
Iteration 1866, loss = 0.01762788
Iteration 1867, loss = 0.01761622
Iteration 1868, loss = 0.01760616
Iteration 1869, loss = 0.01759497
Iteration 1870, loss = 0.01758387
Iteration 1871, loss = 0.01757322
Iteration 1872, loss = 0.01756214
Iteration 1873, loss = 0.01755105
Iteration 1874, loss = 0.01754027
Iteration 1875, loss = 0.01752964
Iteration 1876, loss = 0.01751844
Iteration 1877, loss = 0.01750654
Iteration 1878, loss = 0.01749534
Iteration 1879, loss = 0.01748503
Iteration 1880, loss = 0.01747618
Iteration 1881, loss = 0.01746366
Iteration 1882, loss = 0.01745185
Iteration 1883, loss = 0.01743853
Iteration 1884, loss = 0.01742880
Iteration 1885, loss = 0.01741458
Iteration 1886, loss = 0.01740371
Iteration 1887, loss = 0.01739179
Iteration 1888, loss = 0.01737968
Iteration 1889, loss = 0.01736850
Iteration 1890, loss = 0.01735852
Iteration 1891, loss = 0.01734684
Iteration 1892, loss = 0.01733411
Iteration 1893, loss = 0.01732399
Iteration 1894, loss = 0.01731362
Iteration 1895, loss = 0.01730197
Iteration 1896, loss = 0.01728970
Iteration 1897, loss = 0.01727944
Iteration 1898, loss = 0.01726779
Iteration 1899, loss = 0.01725842
Iteration 1900, loss = 0.01724498
Iteration 1901, loss = 0.01723356
Iteration 1902, loss = 0.01722273
Iteration 1903, loss = 0.01721006
Iteration 1904, loss = 0.01720039
Iteration 1905, loss = 0.01718821
Iteration 1906, loss = 0.01717781
Iteration 1907, loss = 0.01716619
Iteration 1908, loss = 0.01715472
Iteration 1909, loss = 0.01714478
Iteration 1910, loss = 0.01713342
Iteration 1911, loss = 0.01712345
Iteration 1912, loss = 0.01711139
Iteration 1913, loss = 0.01710108
Iteration 1914, loss = 0.01709031
Iteration 1915, loss = 0.01707984
Iteration 1916, loss = 0.01706880
Iteration 1917, loss = 0.01705876
Iteration 1918, loss = 0.01704745
Iteration 1919, loss = 0.01703718
Iteration 1920, loss = 0.01702728
Iteration 1921, loss = 0.01701654
Iteration 1922, loss = 0.01700641
Iteration 1923, loss = 0.01699655
Iteration 1924, loss = 0.01698607
Iteration 1925, loss = 0.01697658
Iteration 1926, loss = 0.01696571
Iteration 1927, loss = 0.01695475
Iteration 1928, loss = 0.01694443
Iteration 1929, loss = 0.01693404
Iteration 1930, loss = 0.01692385
Iteration 1931, loss = 0.01691445
Iteration 1932, loss = 0.01690559
Iteration 1933, loss = 0.01689576
Iteration 1934, loss = 0.01688610
Iteration 1935, loss = 0.01687688
Iteration 1936, loss = 0.01686709
Iteration 1937, loss = 0.01685625
Iteration 1938, loss = 0.01684588
Iteration 1939, loss = 0.01683528
Iteration 1940, loss = 0.01682531
Iteration 1941, loss = 0.01681261
Iteration 1942, loss = 0.01680132
Iteration 1943, loss = 0.01679417
Iteration 1944, loss = 0.01678103
Iteration 1945, loss = 0.01676992
Iteration 1946, loss = 0.01675778
Iteration 1947, loss = 0.01674710
Iteration 1948, loss = 0.01673708
Iteration 1949, loss = 0.01672490
Iteration 1950, loss = 0.01671415
Iteration 1951, loss = 0.01670391
Iteration 1952, loss = 0.01669328
Iteration 1953, loss = 0.01668353
Iteration 1954, loss = 0.01667325
Iteration 1955, loss = 0.01666333
Iteration 1956, loss = 0.01665369
Iteration 1957, loss = 0.01664374
Iteration 1958, loss = 0.01663356
Iteration 1959, loss = 0.01662417
Iteration 1960, loss = 0.01661520
Iteration 1961, loss = 0.01660589
Iteration 1962, loss = 0.01659598
Iteration 1963, loss = 0.01658737
Iteration 1964, loss = 0.01657872
Iteration 1965, loss = 0.01656773
Iteration 1966, loss = 0.01655830
Iteration 1967, loss = 0.01654906
Iteration 1968, loss = 0.01653824
Iteration 1969, loss = 0.01652864
Iteration 1970, loss = 0.01651777
Iteration 1971, loss = 0.01650722
Iteration 1972, loss = 0.01649758
Iteration 1973, loss = 0.01648978
Iteration 1974, loss = 0.01647827
Iteration 1975, loss = 0.01646811
Iteration 1976, loss = 0.01645967
Iteration 1977, loss = 0.01644978
Iteration 1978, loss = 0.01643949
Iteration 1979, loss = 0.01643072
Iteration 1980, loss = 0.01642109
Iteration 1981, loss = 0.01641037
Iteration 1982, loss = 0.01640095
Iteration 1983, loss = 0.01639040
Iteration 1984, loss = 0.01637932
Iteration 1985, loss = 0.01637033
Iteration 1986, loss = 0.01635922
Iteration 1987, loss = 0.01635002
Iteration 1988, loss = 0.01634036
Iteration 1989, loss = 0.01633404
Iteration 1990, loss = 0.01632104
Iteration 1991, loss = 0.01631113
Iteration 1992, loss = 0.01630168
Iteration 1993, loss = 0.01629153
Iteration 1994, loss = 0.01628283
Iteration 1995, loss = 0.01627214
Iteration 1996, loss = 0.01626209
Iteration 1997, loss = 0.01625318
Iteration 1998, loss = 0.01624357
Iteration 1999, loss = 0.01623331
Iteration 2000, loss = 0.01622349
Iteration 2001, loss = 0.01621553
Iteration 2002, loss = 0.01620530
Iteration 2003, loss = 0.01619544
Iteration 2004, loss = 0.01618572
Iteration 2005, loss = 0.01617610
Iteration 2006, loss = 0.01616696
Iteration 2007, loss = 0.01615736
Iteration 2008, loss = 0.01614734
Iteration 2009, loss = 0.01613800
Iteration 2010, loss = 0.01612873
Iteration 2011, loss = 0.01611944
Iteration 2012, loss = 0.01611005
Iteration 2013, loss = 0.01610161
Iteration 2014, loss = 0.01609271
Iteration 2015, loss = 0.01608421
Iteration 2016, loss = 0.01607576
Iteration 2017, loss = 0.01606437
Iteration 2018, loss = 0.01605419
Iteration 2019, loss = 0.01604406
Iteration 2020, loss = 0.01603398
Iteration 2021, loss = 0.01602275
Iteration 2022, loss = 0.01601392
Iteration 2023, loss = 0.01600519
Iteration 2024, loss = 0.01599599
Iteration 2025, loss = 0.01598536
Iteration 2026, loss = 0.01597631
Iteration 2027, loss = 0.01596758
Iteration 2028, loss = 0.01595887
Iteration 2029, loss = 0.01595029
Iteration 2030, loss = 0.01593965
Iteration 2031, loss = 0.01593267
Iteration 2032, loss = 0.01592188
Iteration 2033, loss = 0.01591227
Iteration 2034, loss = 0.01590347
Iteration 2035, loss = 0.01589402
Iteration 2036, loss = 0.01588531
Iteration 2037, loss = 0.01587603
Iteration 2038, loss = 0.01586741
Iteration 2039, loss = 0.01585958
Iteration 2040, loss = 0.01584959
Iteration 2041, loss = 0.01583974
Iteration 2042, loss = 0.01583065
Iteration 2043, loss = 0.01581951
Iteration 2044, loss = 0.01580898
Iteration 2045, loss = 0.01579957
Iteration 2046, loss = 0.01578808
Iteration 2047, loss = 0.01577951
Iteration 2048, loss = 0.01576833
Iteration 2049, loss = 0.01575886
Iteration 2050, loss = 0.01574802
Iteration 2051, loss = 0.01573757
Iteration 2052, loss = 0.01573096
Iteration 2053, loss = 0.01571936
Iteration 2054, loss = 0.01571114
Iteration 2055, loss = 0.01570055
Iteration 2056, loss = 0.01569224
Iteration 2057, loss = 0.01568215
Iteration 2058, loss = 0.01567302
Iteration 2059, loss = 0.01566369
Iteration 2060, loss = 0.01565459
Iteration 2061, loss = 0.01564522
Iteration 2062, loss = 0.01563619
Iteration 2063, loss = 0.01562666
Iteration 2064, loss = 0.01561699
Iteration 2065, loss = 0.01560784
Iteration 2066, loss = 0.01559759
Iteration 2067, loss = 0.01558826
Iteration 2068, loss = 0.01557860
Iteration 2069, loss = 0.01556911
Iteration 2070, loss = 0.01555995
Iteration 2071, loss = 0.01555097
Iteration 2072, loss = 0.01554229
Iteration 2073, loss = 0.01553446
Iteration 2074, loss = 0.01552281
Iteration 2075, loss = 0.01551372
Iteration 2076, loss = 0.01550298
Iteration 2077, loss = 0.01549362
Iteration 2078, loss = 0.01548358
Iteration 2079, loss = 0.01547407
Iteration 2080, loss = 0.01546405
Iteration 2081, loss = 0.01545422
Iteration 2082, loss = 0.01544521
Iteration 2083, loss = 0.01543545
Iteration 2084, loss = 0.01542594
Iteration 2085, loss = 0.01541589
Iteration 2086, loss = 0.01540693
Iteration 2087, loss = 0.01539829
Iteration 2088, loss = 0.01538870
Iteration 2089, loss = 0.01538193
Iteration 2090, loss = 0.01537079
Iteration 2091, loss = 0.01536307
Iteration 2092, loss = 0.01535350
Iteration 2093, loss = 0.01534489
Iteration 2094, loss = 0.01533600
Iteration 2095, loss = 0.01532762
Iteration 2096, loss = 0.01531921
Iteration 2097, loss = 0.01530988
Iteration 2098, loss = 0.01530192
Iteration 2099, loss = 0.01529177
Iteration 2100, loss = 0.01528345
Iteration 2101, loss = 0.01527415
Iteration 2102, loss = 0.01526471
Iteration 2103, loss = 0.01525614
Iteration 2104, loss = 0.01524779
Iteration 2105, loss = 0.01523963
Iteration 2106, loss = 0.01523047
Iteration 2107, loss = 0.01522132
Iteration 2108, loss = 0.01521338
Iteration 2109, loss = 0.01520457
Iteration 2110, loss = 0.01519545
Iteration 2111, loss = 0.01518740
Iteration 2112, loss = 0.01517818
Iteration 2113, loss = 0.01516981
Iteration 2114, loss = 0.01516162
Iteration 2115, loss = 0.01515393
Iteration 2116, loss = 0.01514760
Iteration 2117, loss = 0.01513752
Iteration 2118, loss = 0.01512855
Iteration 2119, loss = 0.01512041
Iteration 2120, loss = 0.01511142
Iteration 2121, loss = 0.01510276
Iteration 2122, loss = 0.01509389
Iteration 2123, loss = 0.01508468
Iteration 2124, loss = 0.01507813
Iteration 2125, loss = 0.01506936
Iteration 2126, loss = 0.01506251
Iteration 2127, loss = 0.01505017
Iteration 2128, loss = 0.01504029
Iteration 2129, loss = 0.01502968
Iteration 2130, loss = 0.01502216
Iteration 2131, loss = 0.01501248
Iteration 2132, loss = 0.01500388
Iteration 2133, loss = 0.01499517
Iteration 2134, loss = 0.01498425
Iteration 2135, loss = 0.01497786
Iteration 2136, loss = 0.01496797
Iteration 2137, loss = 0.01495871
Iteration 2138, loss = 0.01494977
Iteration 2139, loss = 0.01494163
Iteration 2140, loss = 0.01493239
Iteration 2141, loss = 0.01492493
Iteration 2142, loss = 0.01491397
Iteration 2143, loss = 0.01490655
Iteration 2144, loss = 0.01489595
Iteration 2145, loss = 0.01488812
Iteration 2146, loss = 0.01487846
Iteration 2147, loss = 0.01487020
Iteration 2148, loss = 0.01486158
Iteration 2149, loss = 0.01485290
Iteration 2150, loss = 0.01484431
Iteration 2151, loss = 0.01483647
Iteration 2152, loss = 0.01482824
Iteration 2153, loss = 0.01481937
Iteration 2154, loss = 0.01481123
Iteration 2155, loss = 0.01480202
Iteration 2156, loss = 0.01479298
Iteration 2157, loss = 0.01478372
Iteration 2158, loss = 0.01477450
Iteration 2159, loss = 0.01476645
Iteration 2160, loss = 0.01475755
Iteration 2161, loss = 0.01474757
Iteration 2162, loss = 0.01474116
Iteration 2163, loss = 0.01473092
Iteration 2164, loss = 0.01472265
Iteration 2165, loss = 0.01471265
Iteration 2166, loss = 0.01470412
Iteration 2167, loss = 0.01469552
Iteration 2168, loss = 0.01468740
Iteration 2169, loss = 0.01467848
Iteration 2170, loss = 0.01467010
Iteration 2171, loss = 0.01466239
Iteration 2172, loss = 0.01465435
Iteration 2173, loss = 0.01464584
Iteration 2174, loss = 0.01463722
Iteration 2175, loss = 0.01463045
Iteration 2176, loss = 0.01462003
Iteration 2177, loss = 0.01461196
Iteration 2178, loss = 0.01460265
Iteration 2179, loss = 0.01459475
Iteration 2180, loss = 0.01458663
Iteration 2181, loss = 0.01457794
Iteration 2182, loss = 0.01456915
Iteration 2183, loss = 0.01455990
Iteration 2184, loss = 0.01455198
Iteration 2185, loss = 0.01454322
Iteration 2186, loss = 0.01453524
Iteration 2187, loss = 0.01452738
Iteration 2188, loss = 0.01451838
Iteration 2189, loss = 0.01451045
Iteration 2190, loss = 0.01450233
Iteration 2191, loss = 0.01449433
Iteration 2192, loss = 0.01448680
Iteration 2193, loss = 0.01447758
Iteration 2194, loss = 0.01446942
Iteration 2195, loss = 0.01446056
Iteration 2196, loss = 0.01445259
Iteration 2197, loss = 0.01444334
Iteration 2198, loss = 0.01443435
Iteration 2199, loss = 0.01442546
Iteration 2200, loss = 0.01441785
Iteration 2201, loss = 0.01440993
Iteration 2202, loss = 0.01440292
Iteration 2203, loss = 0.01439479
Iteration 2204, loss = 0.01438764
Iteration 2205, loss = 0.01438044
Iteration 2206, loss = 0.01437337
Iteration 2207, loss = 0.01436699
Iteration 2208, loss = 0.01435905
Iteration 2209, loss = 0.01435149
Iteration 2210, loss = 0.01434316
Iteration 2211, loss = 0.01433579
Iteration 2212, loss = 0.01432925
Iteration 2213, loss = 0.01432014
Iteration 2214, loss = 0.01431235
Iteration 2215, loss = 0.01430350
Iteration 2216, loss = 0.01429524
Iteration 2217, loss = 0.01428718
Iteration 2218, loss = 0.01427967
Iteration 2219, loss = 0.01427189
Iteration 2220, loss = 0.01426286
Iteration 2221, loss = 0.01425672
Iteration 2222, loss = 0.01424645
Iteration 2223, loss = 0.01423892
Iteration 2224, loss = 0.01423103
Iteration 2225, loss = 0.01422177
Iteration 2226, loss = 0.01421374
Iteration 2227, loss = 0.01420643
Iteration 2228, loss = 0.01419864
Iteration 2229, loss = 0.01419066
Iteration 2230, loss = 0.01418293
Iteration 2231, loss = 0.01417553
Iteration 2232, loss = 0.01416782
Iteration 2233, loss = 0.01416005
Iteration 2234, loss = 0.01415367
Iteration 2235, loss = 0.01414591
Iteration 2236, loss = 0.01413895
Iteration 2237, loss = 0.01413240
Iteration 2238, loss = 0.01412459
Iteration 2239, loss = 0.01411577
Iteration 2240, loss = 0.01410749
Iteration 2241, loss = 0.01409975
Iteration 2242, loss = 0.01409020
Iteration 2243, loss = 0.01408064
Iteration 2244, loss = 0.01407344
Iteration 2245, loss = 0.01406615
Iteration 2246, loss = 0.01405687
Iteration 2247, loss = 0.01404809
Iteration 2248, loss = 0.01404120
Iteration 2249, loss = 0.01403324
Iteration 2250, loss = 0.01402453
Iteration 2251, loss = 0.01401931
Iteration 2252, loss = 0.01401095
Iteration 2253, loss = 0.01400351
Iteration 2254, loss = 0.01399430
Iteration 2255, loss = 0.01398696
Iteration 2256, loss = 0.01397859
Iteration 2257, loss = 0.01397138
Iteration 2258, loss = 0.01396312
Iteration 2259, loss = 0.01395520
Iteration 2260, loss = 0.01394761
Iteration 2261, loss = 0.01394017
Iteration 2262, loss = 0.01393250
Iteration 2263, loss = 0.01392346
Iteration 2264, loss = 0.01391600
Iteration 2265, loss = 0.01390753
Iteration 2266, loss = 0.01390023
Iteration 2267, loss = 0.01389261
Iteration 2268, loss = 0.01388593
Iteration 2269, loss = 0.01387880
Iteration 2270, loss = 0.01387112
Iteration 2271, loss = 0.01386406
Iteration 2272, loss = 0.01385667
Iteration 2273, loss = 0.01384987
Iteration 2274, loss = 0.01384166
Iteration 2275, loss = 0.01383341
Iteration 2276, loss = 0.01382637
Iteration 2277, loss = 0.01381845
Iteration 2278, loss = 0.01381026
Iteration 2279, loss = 0.01380161
Iteration 2280, loss = 0.01379307
Iteration 2281, loss = 0.01378719
Iteration 2282, loss = 0.01377864
Iteration 2283, loss = 0.01377100
Iteration 2284, loss = 0.01376285
Iteration 2285, loss = 0.01375482
Iteration 2286, loss = 0.01374786
Iteration 2287, loss = 0.01374004
Iteration 2288, loss = 0.01373179
Iteration 2289, loss = 0.01372483
Iteration 2290, loss = 0.01371697
Iteration 2291, loss = 0.01370839
Iteration 2292, loss = 0.01370092
Iteration 2293, loss = 0.01369325
Iteration 2294, loss = 0.01368566
Iteration 2295, loss = 0.01367841
Iteration 2296, loss = 0.01367159
Iteration 2297, loss = 0.01366432
Iteration 2298, loss = 0.01365889
Iteration 2299, loss = 0.01365095
Iteration 2300, loss = 0.01364428
Iteration 2301, loss = 0.01363742
Iteration 2302, loss = 0.01362967
Iteration 2303, loss = 0.01362121
Iteration 2304, loss = 0.01361265
Iteration 2305, loss = 0.01360570
Iteration 2306, loss = 0.01359670
Iteration 2307, loss = 0.01359144
Iteration 2308, loss = 0.01358284
Iteration 2309, loss = 0.01357431
Iteration 2310, loss = 0.01356690
Iteration 2311, loss = 0.01356025
Iteration 2312, loss = 0.01355317
Iteration 2313, loss = 0.01354512
Iteration 2314, loss = 0.01353808
Iteration 2315, loss = 0.01353052
Iteration 2316, loss = 0.01352397
Iteration 2317, loss = 0.01351649
Iteration 2318, loss = 0.01350973
Iteration 2319, loss = 0.01350295
Iteration 2320, loss = 0.01349759
Iteration 2321, loss = 0.01349032
Iteration 2322, loss = 0.01348270
Iteration 2323, loss = 0.01347558
Iteration 2324, loss = 0.01346881
Iteration 2325, loss = 0.01346100
Iteration 2326, loss = 0.01345425
Iteration 2327, loss = 0.01344635
Iteration 2328, loss = 0.01343804
Iteration 2329, loss = 0.01342903
Iteration 2330, loss = 0.01342218
Iteration 2331, loss = 0.01341405
Iteration 2332, loss = 0.01340481
Iteration 2333, loss = 0.01339699
Iteration 2334, loss = 0.01339068
Iteration 2335, loss = 0.01338149
Iteration 2336, loss = 0.01337539
Iteration 2337, loss = 0.01336607
Iteration 2338, loss = 0.01335862
Iteration 2339, loss = 0.01335128
Iteration 2340, loss = 0.01334331
Iteration 2341, loss = 0.01333595
Iteration 2342, loss = 0.01332792
Iteration 2343, loss = 0.01332105
Iteration 2344, loss = 0.01331316
Iteration 2345, loss = 0.01330539
Iteration 2346, loss = 0.01329829
Iteration 2347, loss = 0.01329176
Iteration 2348, loss = 0.01328215
Iteration 2349, loss = 0.01327543
Iteration 2350, loss = 0.01326790
Iteration 2351, loss = 0.01326113
Iteration 2352, loss = 0.01325326
Iteration 2353, loss = 0.01324664
Iteration 2354, loss = 0.01324026
Iteration 2355, loss = 0.01323206
Iteration 2356, loss = 0.01322700
Iteration 2357, loss = 0.01321772
Iteration 2358, loss = 0.01321038
Iteration 2359, loss = 0.01320398
Iteration 2360, loss = 0.01319572
Iteration 2361, loss = 0.01318945
Iteration 2362, loss = 0.01318116
Iteration 2363, loss = 0.01317403
Iteration 2364, loss = 0.01316673
Iteration 2365, loss = 0.01315916
Iteration 2366, loss = 0.01315192
Iteration 2367, loss = 0.01314506
Iteration 2368, loss = 0.01313719
Iteration 2369, loss = 0.01312901
Iteration 2370, loss = 0.01312281
Iteration 2371, loss = 0.01311556
Iteration 2372, loss = 0.01310978
Iteration 2373, loss = 0.01310053
Iteration 2374, loss = 0.01309339
Iteration 2375, loss = 0.01308629
Iteration 2376, loss = 0.01307947
Iteration 2377, loss = 0.01307126
Iteration 2378, loss = 0.01306480
Iteration 2379, loss = 0.01305741
Iteration 2380, loss = 0.01304981
Iteration 2381, loss = 0.01304231
Iteration 2382, loss = 0.01303569
Iteration 2383, loss = 0.01302956
Iteration 2384, loss = 0.01302213
Iteration 2385, loss = 0.01301641
Iteration 2386, loss = 0.01300876
Iteration 2387, loss = 0.01300336
Iteration 2388, loss = 0.01299629
Iteration 2389, loss = 0.01299113
Iteration 2390, loss = 0.01298197
Iteration 2391, loss = 0.01297484
Iteration 2392, loss = 0.01296774
Iteration 2393, loss = 0.01296036
Iteration 2394, loss = 0.01295388
Iteration 2395, loss = 0.01294678
Iteration 2396, loss = 0.01293902
Iteration 2397, loss = 0.01293207
Iteration 2398, loss = 0.01292547
Iteration 2399, loss = 0.01291750
Iteration 2400, loss = 0.01291103
Iteration 2401, loss = 0.01290449
Iteration 2402, loss = 0.01289627
Iteration 2403, loss = 0.01288966
Iteration 2404, loss = 0.01288195
Iteration 2405, loss = 0.01287690
Iteration 2406, loss = 0.01286844
Iteration 2407, loss = 0.01286142
Iteration 2408, loss = 0.01285461
Iteration 2409, loss = 0.01284792
Iteration 2410, loss = 0.01284077
Iteration 2411, loss = 0.01283384
Iteration 2412, loss = 0.01282759
Iteration 2413, loss = 0.01281960
Iteration 2414, loss = 0.01281246
Iteration 2415, loss = 0.01280450
Iteration 2416, loss = 0.01279811
Iteration 2417, loss = 0.01278992
Iteration 2418, loss = 0.01278409
Iteration 2419, loss = 0.01277639
Iteration 2420, loss = 0.01276945
Iteration 2421, loss = 0.01276289
Iteration 2422, loss = 0.01275633
Iteration 2423, loss = 0.01274904
Iteration 2424, loss = 0.01274286
Iteration 2425, loss = 0.01273604
Iteration 2426, loss = 0.01272899
Iteration 2427, loss = 0.01272272
Iteration 2428, loss = 0.01271628
Iteration 2429, loss = 0.01271011
Iteration 2430, loss = 0.01270376
Iteration 2431, loss = 0.01269698
Iteration 2432, loss = 0.01269079
Iteration 2433, loss = 0.01268616
Iteration 2434, loss = 0.01267881
Iteration 2435, loss = 0.01267271
Iteration 2436, loss = 0.01266758
Iteration 2437, loss = 0.01266107
Iteration 2438, loss = 0.01265535
Iteration 2439, loss = 0.01264888
Iteration 2440, loss = 0.01264154
Iteration 2441, loss = 0.01263567
Iteration 2442, loss = 0.01262846
Iteration 2443, loss = 0.01262147
Iteration 2444, loss = 0.01261487
Iteration 2445, loss = 0.01260750
Iteration 2446, loss = 0.01260069
Iteration 2447, loss = 0.01259405
Iteration 2448, loss = 0.01258638
Iteration 2449, loss = 0.01258024
Iteration 2450, loss = 0.01257266
Iteration 2451, loss = 0.01256704
Iteration 2452, loss = 0.01255958
Iteration 2453, loss = 0.01255363
Iteration 2454, loss = 0.01254737
Iteration 2455, loss = 0.01254138
Iteration 2456, loss = 0.01253501
Iteration 2457, loss = 0.01252863
Iteration 2458, loss = 0.01252232
Iteration 2459, loss = 0.01251673
Iteration 2460, loss = 0.01250950
Iteration 2461, loss = 0.01250302
Iteration 2462, loss = 0.01249648
Iteration 2463, loss = 0.01249038
Iteration 2464, loss = 0.01248360
Iteration 2465, loss = 0.01247547
Iteration 2466, loss = 0.01246992
Iteration 2467, loss = 0.01246160
Iteration 2468, loss = 0.01245569
Iteration 2469, loss = 0.01244876
Iteration 2470, loss = 0.01244193
Iteration 2471, loss = 0.01243579
Iteration 2472, loss = 0.01242847
Iteration 2473, loss = 0.01242288
Iteration 2474, loss = 0.01241583
Iteration 2475, loss = 0.01240926
Iteration 2476, loss = 0.01240270
Iteration 2477, loss = 0.01239627
Iteration 2478, loss = 0.01239007
Iteration 2479, loss = 0.01238361
Iteration 2480, loss = 0.01237709
Iteration 2481, loss = 0.01237118
Iteration 2482, loss = 0.01236498
Iteration 2483, loss = 0.01235908
Iteration 2484, loss = 0.01235329
Iteration 2485, loss = 0.01234752
Iteration 2486, loss = 0.01234167
Iteration 2487, loss = 0.01233626
Iteration 2488, loss = 0.01233042
Iteration 2489, loss = 0.01232463
Iteration 2490, loss = 0.01231946
Iteration 2491, loss = 0.01231425
Iteration 2492, loss = 0.01230848
Iteration 2493, loss = 0.01230386
Iteration 2494, loss = 0.01229774
Iteration 2495, loss = 0.01229205
Iteration 2496, loss = 0.01228597
Iteration 2497, loss = 0.01227975
Iteration 2498, loss = 0.01227533
Iteration 2499, loss = 0.01226931
Iteration 2500, loss = 0.01226444
Iteration 2501, loss = 0.01225806
Iteration 2502, loss = 0.01225193
Iteration 2503, loss = 0.01224565
Iteration 2504, loss = 0.01224045
Iteration 2505, loss = 0.01223333
Iteration 2506, loss = 0.01222712
Iteration 2507, loss = 0.01222078
Iteration 2508, loss = 0.01221374
Iteration 2509, loss = 0.01220722
Iteration 2510, loss = 0.01220089
Iteration 2511, loss = 0.01219466
Iteration 2512, loss = 0.01218858
Iteration 2513, loss = 0.01218288
Iteration 2514, loss = 0.01217710
Iteration 2515, loss = 0.01217159
Iteration 2516, loss = 0.01216597
Iteration 2517, loss = 0.01216047
Iteration 2518, loss = 0.01215631
Iteration 2519, loss = 0.01214913
Iteration 2520, loss = 0.01214357
Iteration 2521, loss = 0.01213705
Iteration 2522, loss = 0.01213109
Iteration 2523, loss = 0.01212542
Iteration 2524, loss = 0.01211937
Iteration 2525, loss = 0.01211303
Iteration 2526, loss = 0.01210655
Iteration 2527, loss = 0.01210004
Iteration 2528, loss = 0.01209442
Iteration 2529, loss = 0.01208808
Iteration 2530, loss = 0.01208391
Iteration 2531, loss = 0.01207643
Iteration 2532, loss = 0.01207023
Iteration 2533, loss = 0.01206463
Iteration 2534, loss = 0.01205884
Iteration 2535, loss = 0.01205248
Iteration 2536, loss = 0.01204699
Iteration 2537, loss = 0.01203967
Iteration 2538, loss = 0.01203496
Iteration 2539, loss = 0.01202715
Iteration 2540, loss = 0.01202104
Iteration 2541, loss = 0.01201373
Iteration 2542, loss = 0.01200892
Iteration 2543, loss = 0.01200122
Iteration 2544, loss = 0.01199517
Iteration 2545, loss = 0.01198945
Iteration 2546, loss = 0.01198251
Iteration 2547, loss = 0.01197519
Iteration 2548, loss = 0.01196873
Iteration 2549, loss = 0.01196110
Iteration 2550, loss = 0.01195451
Iteration 2551, loss = 0.01194769
Iteration 2552, loss = 0.01194042
Iteration 2553, loss = 0.01193434
Iteration 2554, loss = 0.01192774
Iteration 2555, loss = 0.01192154
Iteration 2556, loss = 0.01191501
Iteration 2557, loss = 0.01190890
Iteration 2558, loss = 0.01190409
Iteration 2559, loss = 0.01189690
Iteration 2560, loss = 0.01189178
Iteration 2561, loss = 0.01188635
Iteration 2562, loss = 0.01187964
Iteration 2563, loss = 0.01187322
Iteration 2564, loss = 0.01186683
Iteration 2565, loss = 0.01186012
Iteration 2566, loss = 0.01185426
Iteration 2567, loss = 0.01184725
Iteration 2568, loss = 0.01184089
Iteration 2569, loss = 0.01183387
Iteration 2570, loss = 0.01182760
Iteration 2571, loss = 0.01182230
Iteration 2572, loss = 0.01181470
Iteration 2573, loss = 0.01180890
Iteration 2574, loss = 0.01180305
Iteration 2575, loss = 0.01179642
Iteration 2576, loss = 0.01179151
Iteration 2577, loss = 0.01178418
Iteration 2578, loss = 0.01177845
Iteration 2579, loss = 0.01177091
Iteration 2580, loss = 0.01176577
Iteration 2581, loss = 0.01175914
Iteration 2582, loss = 0.01175236
Iteration 2583, loss = 0.01174701
Iteration 2584, loss = 0.01174073
Iteration 2585, loss = 0.01173401
Iteration 2586, loss = 0.01172773
Iteration 2587, loss = 0.01172266
Iteration 2588, loss = 0.01171586
Iteration 2589, loss = 0.01170987
Iteration 2590, loss = 0.01170401
Iteration 2591, loss = 0.01169820
Iteration 2592, loss = 0.01169229
Iteration 2593, loss = 0.01168754
Iteration 2594, loss = 0.01168158
Iteration 2595, loss = 0.01167623
Iteration 2596, loss = 0.01167222
Iteration 2597, loss = 0.01166570
Iteration 2598, loss = 0.01166050
Iteration 2599, loss = 0.01165498
Iteration 2600, loss = 0.01164982
Iteration 2601, loss = 0.01164388
Iteration 2602, loss = 0.01163851
Iteration 2603, loss = 0.01163137
Iteration 2604, loss = 0.01162620
Iteration 2605, loss = 0.01162061
Iteration 2606, loss = 0.01161446
Iteration 2607, loss = 0.01160944
Iteration 2608, loss = 0.01160430
Iteration 2609, loss = 0.01159802
Iteration 2610, loss = 0.01159154
Iteration 2611, loss = 0.01158608
Iteration 2612, loss = 0.01158072
Iteration 2613, loss = 0.01157501
Iteration 2614, loss = 0.01156888
Iteration 2615, loss = 0.01156278
Iteration 2616, loss = 0.01155812
Iteration 2617, loss = 0.01155248
Iteration 2618, loss = 0.01154744
Iteration 2619, loss = 0.01154170
Iteration 2620, loss = 0.01153637
Iteration 2621, loss = 0.01153191
Iteration 2622, loss = 0.01152682
Iteration 2623, loss = 0.01152281
Iteration 2624, loss = 0.01151860
Iteration 2625, loss = 0.01151369
Iteration 2626, loss = 0.01150893
Iteration 2627, loss = 0.01150460
Iteration 2628, loss = 0.01149942
Iteration 2629, loss = 0.01149484
Iteration 2630, loss = 0.01148893
Iteration 2631, loss = 0.01148378
Iteration 2632, loss = 0.01147795
Iteration 2633, loss = 0.01147267
Iteration 2634, loss = 0.01146714
Iteration 2635, loss = 0.01146162
Iteration 2636, loss = 0.01145613
Iteration 2637, loss = 0.01144943
Iteration 2638, loss = 0.01144440
Iteration 2639, loss = 0.01143691
Iteration 2640, loss = 0.01143153
Iteration 2641, loss = 0.01142641
Iteration 2642, loss = 0.01142003
Iteration 2643, loss = 0.01141422
Iteration 2644, loss = 0.01140878
Iteration 2645, loss = 0.01140276
Iteration 2646, loss = 0.01139922
Iteration 2647, loss = 0.01139297
Iteration 2648, loss = 0.01138682
Iteration 2649, loss = 0.01138184
Iteration 2650, loss = 0.01137682
Iteration 2651, loss = 0.01137213
Iteration 2652, loss = 0.01136612
Iteration 2653, loss = 0.01136129
Iteration 2654, loss = 0.01135586
Iteration 2655, loss = 0.01135090
Iteration 2656, loss = 0.01134551
Iteration 2657, loss = 0.01134048
Iteration 2658, loss = 0.01133548
Iteration 2659, loss = 0.01132936
Iteration 2660, loss = 0.01132321
Iteration 2661, loss = 0.01131755
Iteration 2662, loss = 0.01131193
Iteration 2663, loss = 0.01130638
Iteration 2664, loss = 0.01130077
Iteration 2665, loss = 0.01129587
Iteration 2666, loss = 0.01128993
Iteration 2667, loss = 0.01128442
Iteration 2668, loss = 0.01127985
Iteration 2669, loss = 0.01127405
Iteration 2670, loss = 0.01126859
Iteration 2671, loss = 0.01126387
Iteration 2672, loss = 0.01125655
Iteration 2673, loss = 0.01125005
Iteration 2674, loss = 0.01124395
Iteration 2675, loss = 0.01123749
Iteration 2676, loss = 0.01123317
Iteration 2677, loss = 0.01122535
Iteration 2678, loss = 0.01121998
Iteration 2679, loss = 0.01121411
Iteration 2680, loss = 0.01120775
Iteration 2681, loss = 0.01120347
Iteration 2682, loss = 0.01119579
Iteration 2683, loss = 0.01118980
Iteration 2684, loss = 0.01118427
Iteration 2685, loss = 0.01117759
Iteration 2686, loss = 0.01117184
Iteration 2687, loss = 0.01116510
Iteration 2688, loss = 0.01116204
Iteration 2689, loss = 0.01115455
Iteration 2690, loss = 0.01114959
Iteration 2691, loss = 0.01114337
Iteration 2692, loss = 0.01113782
Iteration 2693, loss = 0.01113192
Iteration 2694, loss = 0.01112734
Iteration 2695, loss = 0.01112151
Iteration 2696, loss = 0.01111522
Iteration 2697, loss = 0.01110943
Iteration 2698, loss = 0.01110304
Iteration 2699, loss = 0.01109698
Iteration 2700, loss = 0.01109038
Iteration 2701, loss = 0.01108743
Iteration 2702, loss = 0.01107925
Iteration 2703, loss = 0.01107624
Iteration 2704, loss = 0.01107128
Iteration 2705, loss = 0.01106483
Iteration 2706, loss = 0.01105953
Iteration 2707, loss = 0.01105409
Iteration 2708, loss = 0.01104876
Iteration 2709, loss = 0.01104325
Iteration 2710, loss = 0.01103775
Iteration 2711, loss = 0.01103206
Iteration 2712, loss = 0.01102762
Iteration 2713, loss = 0.01102200
Iteration 2714, loss = 0.01101632
Iteration 2715, loss = 0.01101052
Iteration 2716, loss = 0.01100602
Iteration 2717, loss = 0.01100005
Iteration 2718, loss = 0.01099479
Iteration 2719, loss = 0.01099016
Iteration 2720, loss = 0.01098430
Iteration 2721, loss = 0.01097904
Iteration 2722, loss = 0.01097382
Iteration 2723, loss = 0.01096895
Iteration 2724, loss = 0.01096286
Iteration 2725, loss = 0.01095757
Iteration 2726, loss = 0.01095216
Iteration 2727, loss = 0.01094682
Iteration 2728, loss = 0.01094162
Iteration 2729, loss = 0.01093583
Iteration 2730, loss = 0.01093012
Iteration 2731, loss = 0.01092483
Iteration 2732, loss = 0.01091990
Iteration 2733, loss = 0.01091443
Iteration 2734, loss = 0.01090830
Iteration 2735, loss = 0.01090270
Iteration 2736, loss = 0.01089845
Iteration 2737, loss = 0.01089250
Iteration 2738, loss = 0.01088652
Iteration 2739, loss = 0.01088099
Iteration 2740, loss = 0.01087642
Iteration 2741, loss = 0.01087051
Iteration 2742, loss = 0.01086547
Iteration 2743, loss = 0.01086231
Iteration 2744, loss = 0.01085547
Iteration 2745, loss = 0.01084992
Iteration 2746, loss = 0.01084595
Iteration 2747, loss = 0.01083901
Iteration 2748, loss = 0.01083257
Iteration 2749, loss = 0.01082679
Iteration 2750, loss = 0.01082193
Iteration 2751, loss = 0.01081595
Iteration 2752, loss = 0.01081013
Iteration 2753, loss = 0.01080490
Iteration 2754, loss = 0.01079954
Iteration 2755, loss = 0.01079453
Iteration 2756, loss = 0.01078831
Iteration 2757, loss = 0.01078355
Iteration 2758, loss = 0.01077744
Iteration 2759, loss = 0.01077195
Iteration 2760, loss = 0.01076664
Iteration 2761, loss = 0.01076146
Iteration 2762, loss = 0.01075551
Iteration 2763, loss = 0.01074994
Iteration 2764, loss = 0.01074497
Iteration 2765, loss = 0.01073927
Iteration 2766, loss = 0.01073399
Iteration 2767, loss = 0.01073025
Iteration 2768, loss = 0.01072381
Iteration 2769, loss = 0.01071894
Iteration 2770, loss = 0.01071464
Iteration 2771, loss = 0.01070909
Iteration 2772, loss = 0.01070477
Iteration 2773, loss = 0.01069864
Iteration 2774, loss = 0.01069396
Iteration 2775, loss = 0.01068885
Iteration 2776, loss = 0.01068352
Iteration 2777, loss = 0.01067896
Iteration 2778, loss = 0.01067363
Iteration 2779, loss = 0.01066828
Iteration 2780, loss = 0.01066296
Iteration 2781, loss = 0.01065992
Iteration 2782, loss = 0.01065342
Iteration 2783, loss = 0.01064663
Iteration 2784, loss = 0.01064223
Iteration 2785, loss = 0.01063691
Iteration 2786, loss = 0.01063199
Iteration 2787, loss = 0.01062605
Iteration 2788, loss = 0.01062074
Iteration 2789, loss = 0.01061529
Iteration 2790, loss = 0.01061188
Iteration 2791, loss = 0.01060550
Iteration 2792, loss = 0.01060050
Iteration 2793, loss = 0.01059576
Iteration 2794, loss = 0.01059044
Iteration 2795, loss = 0.01058579
Iteration 2796, loss = 0.01058073
Iteration 2797, loss = 0.01057558
Iteration 2798, loss = 0.01057032
Iteration 2799, loss = 0.01056588
Iteration 2800, loss = 0.01055981
Iteration 2801, loss = 0.01055500
Iteration 2802, loss = 0.01054966
Iteration 2803, loss = 0.01054429
Iteration 2804, loss = 0.01054014
Iteration 2805, loss = 0.01053499
Iteration 2806, loss = 0.01052939
Iteration 2807, loss = 0.01052428
Iteration 2808, loss = 0.01051924
Iteration 2809, loss = 0.01051422
Iteration 2810, loss = 0.01050956
Iteration 2811, loss = 0.01050461
Iteration 2812, loss = 0.01050020
Iteration 2813, loss = 0.01049535
Iteration 2814, loss = 0.01049102
Iteration 2815, loss = 0.01048559
Iteration 2816, loss = 0.01048077
Iteration 2817, loss = 0.01047487
Iteration 2818, loss = 0.01047024
Iteration 2819, loss = 0.01046478
Iteration 2820, loss = 0.01045934
Iteration 2821, loss = 0.01045477
Iteration 2822, loss = 0.01044935
Iteration 2823, loss = 0.01044426
Iteration 2824, loss = 0.01043888
Iteration 2825, loss = 0.01043478
Iteration 2826, loss = 0.01042865
Iteration 2827, loss = 0.01042458
Iteration 2828, loss = 0.01041894
Iteration 2829, loss = 0.01041461
Iteration 2830, loss = 0.01040941
Iteration 2831, loss = 0.01040513
Iteration 2832, loss = 0.01039923
Iteration 2833, loss = 0.01039430
Iteration 2834, loss = 0.01038928
Iteration 2835, loss = 0.01038438
Iteration 2836, loss = 0.01038057
Iteration 2837, loss = 0.01037456
Iteration 2838, loss = 0.01036990
Iteration 2839, loss = 0.01036488
Iteration 2840, loss = 0.01035965
Iteration 2841, loss = 0.01035455
Iteration 2842, loss = 0.01034944
Iteration 2843, loss = 0.01034407
Iteration 2844, loss = 0.01033784
Iteration 2845, loss = 0.01033291
Iteration 2846, loss = 0.01032712
Iteration 2847, loss = 0.01032172
Iteration 2848, loss = 0.01031570
Iteration 2849, loss = 0.01031142
Iteration 2850, loss = 0.01030676
Iteration 2851, loss = 0.01030053
Iteration 2852, loss = 0.01029527
Iteration 2853, loss = 0.01029030
Iteration 2854, loss = 0.01028548
Iteration 2855, loss = 0.01028144
Iteration 2856, loss = 0.01027507
Iteration 2857, loss = 0.01026972
Iteration 2858, loss = 0.01026552
Iteration 2859, loss = 0.01026005
Iteration 2860, loss = 0.01025462
Iteration 2861, loss = 0.01024934
Iteration 2862, loss = 0.01024415
Iteration 2863, loss = 0.01023922
Iteration 2864, loss = 0.01023395
Iteration 2865, loss = 0.01022867
Iteration 2866, loss = 0.01022320
Iteration 2867, loss = 0.01021834
Iteration 2868, loss = 0.01021339
Iteration 2869, loss = 0.01020772
Iteration 2870, loss = 0.01020252
Iteration 2871, loss = 0.01019768
Iteration 2872, loss = 0.01019239
Iteration 2873, loss = 0.01018845
Iteration 2874, loss = 0.01018275
Iteration 2875, loss = 0.01017806
Iteration 2876, loss = 0.01017352
Iteration 2877, loss = 0.01016947
Iteration 2878, loss = 0.01016415
Iteration 2879, loss = 0.01015966
Iteration 2880, loss = 0.01015598
Iteration 2881, loss = 0.01015003
Iteration 2882, loss = 0.01014528
Iteration 2883, loss = 0.01014074
Iteration 2884, loss = 0.01013591
Iteration 2885, loss = 0.01013096
Iteration 2886, loss = 0.01012644
Iteration 2887, loss = 0.01012135
Iteration 2888, loss = 0.01011689
Iteration 2889, loss = 0.01011192
Iteration 2890, loss = 0.01010748
Iteration 2891, loss = 0.01010250
Iteration 2892, loss = 0.01009871
Iteration 2893, loss = 0.01009268
Iteration 2894, loss = 0.01008755
Iteration 2895, loss = 0.01008297
Iteration 2896, loss = 0.01007751
Iteration 2897, loss = 0.01007285
Iteration 2898, loss = 0.01006762
Iteration 2899, loss = 0.01006301
Iteration 2900, loss = 0.01005756
Iteration 2901, loss = 0.01005262
Iteration 2902, loss = 0.01004756
Iteration 2903, loss = 0.01004253
Iteration 2904, loss = 0.01003958
Iteration 2905, loss = 0.01003363
Iteration 2906, loss = 0.01002841
Iteration 2907, loss = 0.01002360
Iteration 2908, loss = 0.01001921
Iteration 2909, loss = 0.01001425
Iteration 2910, loss = 0.01000939
Iteration 2911, loss = 0.01000494
Iteration 2912, loss = 0.01000015
Iteration 2913, loss = 0.00999477
Iteration 2914, loss = 0.00999014
Iteration 2915, loss = 0.00998539
Iteration 2916, loss = 0.00998064
Iteration 2917, loss = 0.00997638
Iteration 2918, loss = 0.00997117
Iteration 2919, loss = 0.00996640
Iteration 2920, loss = 0.00996183
Iteration 2921, loss = 0.00995686
Iteration 2922, loss = 0.00995221
Iteration 2923, loss = 0.00994720
Iteration 2924, loss = 0.00994338
Iteration 2925, loss = 0.00993833
Iteration 2926, loss = 0.00993390
Iteration 2927, loss = 0.00992947
Iteration 2928, loss = 0.00992455
Iteration 2929, loss = 0.00992001
Iteration 2930, loss = 0.00991590
Iteration 2931, loss = 0.00991139
Iteration 2932, loss = 0.00990683
Iteration 2933, loss = 0.00990288
Iteration 2934, loss = 0.00989848
Iteration 2935, loss = 0.00989311
Iteration 2936, loss = 0.00988966
Iteration 2937, loss = 0.00988506
Iteration 2938, loss = 0.00988117
Iteration 2939, loss = 0.00987598
Iteration 2940, loss = 0.00987267
Iteration 2941, loss = 0.00986677
Iteration 2942, loss = 0.00986269
Iteration 2943, loss = 0.00985759
Iteration 2944, loss = 0.00985299
Iteration 2945, loss = 0.00984785
Iteration 2946, loss = 0.00984284
Iteration 2947, loss = 0.00983854
Iteration 2948, loss = 0.00983333
Iteration 2949, loss = 0.00982831
Iteration 2950, loss = 0.00982347
Iteration 2951, loss = 0.00981858
Iteration 2952, loss = 0.00981477
Iteration 2953, loss = 0.00981011
Iteration 2954, loss = 0.00980548
Iteration 2955, loss = 0.00980079
Iteration 2956, loss = 0.00979631
Iteration 2957, loss = 0.00979273
Iteration 2958, loss = 0.00978775
Iteration 2959, loss = 0.00978341
Iteration 2960, loss = 0.00977906
Iteration 2961, loss = 0.00977469
Iteration 2962, loss = 0.00977085
Iteration 2963, loss = 0.00976638
Iteration 2964, loss = 0.00976218
Iteration 2965, loss = 0.00975768
Iteration 2966, loss = 0.00975326
Iteration 2967, loss = 0.00974866
Iteration 2968, loss = 0.00974400
Iteration 2969, loss = 0.00973963
Iteration 2970, loss = 0.00973470
Iteration 2971, loss = 0.00972959
Iteration 2972, loss = 0.00972516
Iteration 2973, loss = 0.00972031
Iteration 2974, loss = 0.00971569
Iteration 2975, loss = 0.00971104
Iteration 2976, loss = 0.00970695
Iteration 2977, loss = 0.00970187
Iteration 2978, loss = 0.00969759
Iteration 2979, loss = 0.00969346
Iteration 2980, loss = 0.00968900
Iteration 2981, loss = 0.00968449
Iteration 2982, loss = 0.00968002
Iteration 2983, loss = 0.00967546
Iteration 2984, loss = 0.00967100
Iteration 2985, loss = 0.00966642
Iteration 2986, loss = 0.00966206
Iteration 2987, loss = 0.00965865
Iteration 2988, loss = 0.00965401
Iteration 2989, loss = 0.00965042
Iteration 2990, loss = 0.00964653
Iteration 2991, loss = 0.00964199
Iteration 2992, loss = 0.00963845
Iteration 2993, loss = 0.00963424
Iteration 2994, loss = 0.00963013
Iteration 2995, loss = 0.00962612
Iteration 2996, loss = 0.00962304
Iteration 2997, loss = 0.00961861
Iteration 2998, loss = 0.00961540
Iteration 2999, loss = 0.00961011
Iteration 3000, loss = 0.00960626
Iteration 3001, loss = 0.00960226
Iteration 3002, loss = 0.00959821
Iteration 3003, loss = 0.00959353
Iteration 3004, loss = 0.00958925
Iteration 3005, loss = 0.00958525
Iteration 3006, loss = 0.00958061
Iteration 3007, loss = 0.00957799
Iteration 3008, loss = 0.00957310
Iteration 3009, loss = 0.00957015
Iteration 3010, loss = 0.00956649
Iteration 3011, loss = 0.00956162
Iteration 3012, loss = 0.00955753
Iteration 3013, loss = 0.00955317
Iteration 3014, loss = 0.00954963
Iteration 3015, loss = 0.00954539
Iteration 3016, loss = 0.00954112
Iteration 3017, loss = 0.00953678
Iteration 3018, loss = 0.00953218
Iteration 3019, loss = 0.00952705
Iteration 3020, loss = 0.00952264
Iteration 3021, loss = 0.00951926
Iteration 3022, loss = 0.00951314
Iteration 3023, loss = 0.00950883
Iteration 3024, loss = 0.00950447
Iteration 3025, loss = 0.00950006
Iteration 3026, loss = 0.00949596
Iteration 3027, loss = 0.00949243
Iteration 3028, loss = 0.00948879
Iteration 3029, loss = 0.00948402
Iteration 3030, loss = 0.00948008
Iteration 3031, loss = 0.00947601
Iteration 3032, loss = 0.00947219
Iteration 3033, loss = 0.00946803
Iteration 3034, loss = 0.00946395
Iteration 3035, loss = 0.00946005
Iteration 3036, loss = 0.00945668
Iteration 3037, loss = 0.00945189
Iteration 3038, loss = 0.00944876
Iteration 3039, loss = 0.00944376
Iteration 3040, loss = 0.00943996
Iteration 3041, loss = 0.00943590
Iteration 3042, loss = 0.00943222
Iteration 3043, loss = 0.00942816
Iteration 3044, loss = 0.00942435
Iteration 3045, loss = 0.00942059
Iteration 3046, loss = 0.00941625
Iteration 3047, loss = 0.00941318
Iteration 3048, loss = 0.00940853
Iteration 3049, loss = 0.00940491
Iteration 3050, loss = 0.00939968
Iteration 3051, loss = 0.00939478
Iteration 3052, loss = 0.00938988
Iteration 3053, loss = 0.00938436
Iteration 3054, loss = 0.00938000
Iteration 3055, loss = 0.00937670
Iteration 3056, loss = 0.00937094
Iteration 3057, loss = 0.00936819
Iteration 3058, loss = 0.00936233
Iteration 3059, loss = 0.00935762
Iteration 3060, loss = 0.00935429
Iteration 3061, loss = 0.00934950
Iteration 3062, loss = 0.00934565
Iteration 3063, loss = 0.00934136
Iteration 3064, loss = 0.00933744
Iteration 3065, loss = 0.00933346
Iteration 3066, loss = 0.00932952
Iteration 3067, loss = 0.00932495
Iteration 3068, loss = 0.00932066
Iteration 3069, loss = 0.00931722
Iteration 3070, loss = 0.00931247
Iteration 3071, loss = 0.00930870
Iteration 3072, loss = 0.00930437
Iteration 3073, loss = 0.00929944
Iteration 3074, loss = 0.00929497
Iteration 3075, loss = 0.00929048
Iteration 3076, loss = 0.00928653
Iteration 3077, loss = 0.00928201
Iteration 3078, loss = 0.00927779
Iteration 3079, loss = 0.00927419
Iteration 3080, loss = 0.00926971
Iteration 3081, loss = 0.00926593
Iteration 3082, loss = 0.00926204
Iteration 3083, loss = 0.00925793
Iteration 3084, loss = 0.00925414
Iteration 3085, loss = 0.00925098
Iteration 3086, loss = 0.00924616
Iteration 3087, loss = 0.00924238
Iteration 3088, loss = 0.00923933
Iteration 3089, loss = 0.00923531
Iteration 3090, loss = 0.00923157
Iteration 3091, loss = 0.00922785
Iteration 3092, loss = 0.00922401
Iteration 3093, loss = 0.00922078
Iteration 3094, loss = 0.00921701
Iteration 3095, loss = 0.00921348
Iteration 3096, loss = 0.00920961
Iteration 3097, loss = 0.00920536
Iteration 3098, loss = 0.00920124
Iteration 3099, loss = 0.00919700
Iteration 3100, loss = 0.00919269
Iteration 3101, loss = 0.00918903
Iteration 3102, loss = 0.00918540
Iteration 3103, loss = 0.00918152
Iteration 3104, loss = 0.00917780
Iteration 3105, loss = 0.00917366
Iteration 3106, loss = 0.00916953
Iteration 3107, loss = 0.00916569
Iteration 3108, loss = 0.00916190
Iteration 3109, loss = 0.00915780
Iteration 3110, loss = 0.00915445
Iteration 3111, loss = 0.00915037
Iteration 3112, loss = 0.00914614
Iteration 3113, loss = 0.00914244
Iteration 3114, loss = 0.00913994
Iteration 3115, loss = 0.00913496
Iteration 3116, loss = 0.00913136
Iteration 3117, loss = 0.00912710
Iteration 3118, loss = 0.00912293
Iteration 3119, loss = 0.00911926
Iteration 3120, loss = 0.00911556
Iteration 3121, loss = 0.00911187
Iteration 3122, loss = 0.00910801
Iteration 3123, loss = 0.00910437
Iteration 3124, loss = 0.00910100
Iteration 3125, loss = 0.00909656
Iteration 3126, loss = 0.00909293
Iteration 3127, loss = 0.00908905
Iteration 3128, loss = 0.00908546
Iteration 3129, loss = 0.00908146
Iteration 3130, loss = 0.00907768
Iteration 3131, loss = 0.00907412
Iteration 3132, loss = 0.00906968
Iteration 3133, loss = 0.00906621
Iteration 3134, loss = 0.00906149
Iteration 3135, loss = 0.00905798
Iteration 3136, loss = 0.00905358
Iteration 3137, loss = 0.00905033
Iteration 3138, loss = 0.00904635
Iteration 3139, loss = 0.00904259
Iteration 3140, loss = 0.00903909
Iteration 3141, loss = 0.00903590
Iteration 3142, loss = 0.00903227
Iteration 3143, loss = 0.00902910
Iteration 3144, loss = 0.00902610
Iteration 3145, loss = 0.00902234
Iteration 3146, loss = 0.00902004
Iteration 3147, loss = 0.00901557
Iteration 3148, loss = 0.00901167
Iteration 3149, loss = 0.00900771
Iteration 3150, loss = 0.00900447
Iteration 3151, loss = 0.00900048
Iteration 3152, loss = 0.00899701
Iteration 3153, loss = 0.00899358
Iteration 3154, loss = 0.00898985
Iteration 3155, loss = 0.00898633
Iteration 3156, loss = 0.00898260
Iteration 3157, loss = 0.00897841
Iteration 3158, loss = 0.00897353
Iteration 3159, loss = 0.00896996
Iteration 3160, loss = 0.00896516
Iteration 3161, loss = 0.00896104
Iteration 3162, loss = 0.00895682
Iteration 3163, loss = 0.00895269
Iteration 3164, loss = 0.00894878
Iteration 3165, loss = 0.00894494
Iteration 3166, loss = 0.00894085
Iteration 3167, loss = 0.00893715
Iteration 3168, loss = 0.00893207
Iteration 3169, loss = 0.00892789
Iteration 3170, loss = 0.00892375
Iteration 3171, loss = 0.00892000
Iteration 3172, loss = 0.00891578
Iteration 3173, loss = 0.00891200
Iteration 3174, loss = 0.00890828
Iteration 3175, loss = 0.00890428
Iteration 3176, loss = 0.00890075
Iteration 3177, loss = 0.00889692
Iteration 3178, loss = 0.00889368
Iteration 3179, loss = 0.00889021
Iteration 3180, loss = 0.00888689
Iteration 3181, loss = 0.00888299
Iteration 3182, loss = 0.00887966
Iteration 3183, loss = 0.00887529
Iteration 3184, loss = 0.00887297
Iteration 3185, loss = 0.00886786
Iteration 3186, loss = 0.00886418
Iteration 3187, loss = 0.00886021
Iteration 3188, loss = 0.00885659
Iteration 3189, loss = 0.00885297
Iteration 3190, loss = 0.00884920
Iteration 3191, loss = 0.00884547
Iteration 3192, loss = 0.00884183
Iteration 3193, loss = 0.00883739
Iteration 3194, loss = 0.00883355
Iteration 3195, loss = 0.00882994
Iteration 3196, loss = 0.00882587
Iteration 3197, loss = 0.00882239
Iteration 3198, loss = 0.00881860
Iteration 3199, loss = 0.00881503
Iteration 3200, loss = 0.00881153
Iteration 3201, loss = 0.00880769
Iteration 3202, loss = 0.00880388
Iteration 3203, loss = 0.00880054
Iteration 3204, loss = 0.00879803
Iteration 3205, loss = 0.00879364
Iteration 3206, loss = 0.00878958
Iteration 3207, loss = 0.00878593
Iteration 3208, loss = 0.00878175
Iteration 3209, loss = 0.00877765
Iteration 3210, loss = 0.00877377
Iteration 3211, loss = 0.00877008
Iteration 3212, loss = 0.00876572
Iteration 3213, loss = 0.00876272
Iteration 3214, loss = 0.00875791
Iteration 3215, loss = 0.00875439
Iteration 3216, loss = 0.00875041
Iteration 3217, loss = 0.00874682
Iteration 3218, loss = 0.00874275
Iteration 3219, loss = 0.00873855
Iteration 3220, loss = 0.00873480
Iteration 3221, loss = 0.00873170
Iteration 3222, loss = 0.00872790
Iteration 3223, loss = 0.00872478
Iteration 3224, loss = 0.00872162
Iteration 3225, loss = 0.00871830
Iteration 3226, loss = 0.00871471
Iteration 3227, loss = 0.00871149
Iteration 3228, loss = 0.00870789
Iteration 3229, loss = 0.00870502
Iteration 3230, loss = 0.00870191
Iteration 3231, loss = 0.00869836
Iteration 3232, loss = 0.00869468
Iteration 3233, loss = 0.00869239
Iteration 3234, loss = 0.00868786
Iteration 3235, loss = 0.00868472
Iteration 3236, loss = 0.00868083
Iteration 3237, loss = 0.00867727
Iteration 3238, loss = 0.00867415
Iteration 3239, loss = 0.00867072
Iteration 3240, loss = 0.00866767
Iteration 3241, loss = 0.00866465
Iteration 3242, loss = 0.00866195
Iteration 3243, loss = 0.00865899
Iteration 3244, loss = 0.00865570
Iteration 3245, loss = 0.00865168
Iteration 3246, loss = 0.00864799
Iteration 3247, loss = 0.00864390
Iteration 3248, loss = 0.00864095
Iteration 3249, loss = 0.00863696
Iteration 3250, loss = 0.00863281
Iteration 3251, loss = 0.00863007
Iteration 3252, loss = 0.00862512
Iteration 3253, loss = 0.00862045
Iteration 3254, loss = 0.00861702
Iteration 3255, loss = 0.00861221
Iteration 3256, loss = 0.00860852
Iteration 3257, loss = 0.00860503
Iteration 3258, loss = 0.00860056
Iteration 3259, loss = 0.00859718
Iteration 3260, loss = 0.00859342
Iteration 3261, loss = 0.00859002
Iteration 3262, loss = 0.00858621
Iteration 3263, loss = 0.00858266
Iteration 3264, loss = 0.00857913
Iteration 3265, loss = 0.00857546
Iteration 3266, loss = 0.00857218
Iteration 3267, loss = 0.00856899
Iteration 3268, loss = 0.00856545
Iteration 3269, loss = 0.00856190
Iteration 3270, loss = 0.00855845
Iteration 3271, loss = 0.00855568
Iteration 3272, loss = 0.00855200
Iteration 3273, loss = 0.00854882
Iteration 3274, loss = 0.00854538
Iteration 3275, loss = 0.00854242
Iteration 3276, loss = 0.00853880
Iteration 3277, loss = 0.00853565
Iteration 3278, loss = 0.00853231
Iteration 3279, loss = 0.00852885
Iteration 3280, loss = 0.00852532
Iteration 3281, loss = 0.00852196
Iteration 3282, loss = 0.00851844
Iteration 3283, loss = 0.00851476
Iteration 3284, loss = 0.00851160
Iteration 3285, loss = 0.00850751
Iteration 3286, loss = 0.00850466
Iteration 3287, loss = 0.00850031
Iteration 3288, loss = 0.00849675
Iteration 3289, loss = 0.00849321
Iteration 3290, loss = 0.00848982
Iteration 3291, loss = 0.00848633
Iteration 3292, loss = 0.00848303
Iteration 3293, loss = 0.00847903
Iteration 3294, loss = 0.00847583
Iteration 3295, loss = 0.00847171
Iteration 3296, loss = 0.00846819
Iteration 3297, loss = 0.00846443
Iteration 3298, loss = 0.00846063
Iteration 3299, loss = 0.00845776
Iteration 3300, loss = 0.00845378
Iteration 3301, loss = 0.00844899
Iteration 3302, loss = 0.00844538
Iteration 3303, loss = 0.00844115
Iteration 3304, loss = 0.00843780
Iteration 3305, loss = 0.00843391
Iteration 3306, loss = 0.00842981
Iteration 3307, loss = 0.00842645
Iteration 3308, loss = 0.00842213
Iteration 3309, loss = 0.00841867
Iteration 3310, loss = 0.00841477
Iteration 3311, loss = 0.00841129
Iteration 3312, loss = 0.00840802
Iteration 3313, loss = 0.00840427
Iteration 3314, loss = 0.00840075
Iteration 3315, loss = 0.00839715
Iteration 3316, loss = 0.00839361
Iteration 3317, loss = 0.00839001
Iteration 3318, loss = 0.00838637
Iteration 3319, loss = 0.00838312
Iteration 3320, loss = 0.00837959
Iteration 3321, loss = 0.00837712
Iteration 3322, loss = 0.00837567
Iteration 3323, loss = 0.00837086
Iteration 3324, loss = 0.00836751
Iteration 3325, loss = 0.00836431
Iteration 3326, loss = 0.00836102
Iteration 3327, loss = 0.00835776
Iteration 3328, loss = 0.00835457
Iteration 3329, loss = 0.00835120
Iteration 3330, loss = 0.00834725
Iteration 3331, loss = 0.00834407
Iteration 3332, loss = 0.00834065
Iteration 3333, loss = 0.00833722
Iteration 3334, loss = 0.00833411
Iteration 3335, loss = 0.00833012
Iteration 3336, loss = 0.00832662
Iteration 3337, loss = 0.00832301
Iteration 3338, loss = 0.00831906
Iteration 3339, loss = 0.00831587
Iteration 3340, loss = 0.00831193
Iteration 3341, loss = 0.00830853
Iteration 3342, loss = 0.00830560
Iteration 3343, loss = 0.00830214
Iteration 3344, loss = 0.00829913
Iteration 3345, loss = 0.00829576
Iteration 3346, loss = 0.00829226
Iteration 3347, loss = 0.00828874
Iteration 3348, loss = 0.00828511
Iteration 3349, loss = 0.00828185
Iteration 3350, loss = 0.00827890
Iteration 3351, loss = 0.00827557
Iteration 3352, loss = 0.00827187
Iteration 3353, loss = 0.00826869
Iteration 3354, loss = 0.00826551
Iteration 3355, loss = 0.00826163
Iteration 3356, loss = 0.00825803
Iteration 3357, loss = 0.00825469
Iteration 3358, loss = 0.00825108
Iteration 3359, loss = 0.00824776
Iteration 3360, loss = 0.00824475
Iteration 3361, loss = 0.00824125
Iteration 3362, loss = 0.00823889
Iteration 3363, loss = 0.00823383
Iteration 3364, loss = 0.00823015
Iteration 3365, loss = 0.00822611
Iteration 3366, loss = 0.00822318
Iteration 3367, loss = 0.00822071
Iteration 3368, loss = 0.00821556
Iteration 3369, loss = 0.00821205
Iteration 3370, loss = 0.00820889
Iteration 3371, loss = 0.00820530
Iteration 3372, loss = 0.00820178
Iteration 3373, loss = 0.00819886
Iteration 3374, loss = 0.00819566
Iteration 3375, loss = 0.00819180
Iteration 3376, loss = 0.00818798
Iteration 3377, loss = 0.00818410
Iteration 3378, loss = 0.00818081
Iteration 3379, loss = 0.00817773
Iteration 3380, loss = 0.00817283
Iteration 3381, loss = 0.00816976
Iteration 3382, loss = 0.00816631
Iteration 3383, loss = 0.00816233
Iteration 3384, loss = 0.00815801
Iteration 3385, loss = 0.00815529
Iteration 3386, loss = 0.00815157
Iteration 3387, loss = 0.00814725
Iteration 3388, loss = 0.00814400
Iteration 3389, loss = 0.00814022
Iteration 3390, loss = 0.00813685
Iteration 3391, loss = 0.00813332
Iteration 3392, loss = 0.00813046
Iteration 3393, loss = 0.00812691
Iteration 3394, loss = 0.00812290
Iteration 3395, loss = 0.00811944
Iteration 3396, loss = 0.00811635
Iteration 3397, loss = 0.00811286
Iteration 3398, loss = 0.00810962
Iteration 3399, loss = 0.00810610
Iteration 3400, loss = 0.00810349
Iteration 3401, loss = 0.00809951
Iteration 3402, loss = 0.00809699
Iteration 3403, loss = 0.00809268
Iteration 3404, loss = 0.00808929
Iteration 3405, loss = 0.00808653
Iteration 3406, loss = 0.00808291
Iteration 3407, loss = 0.00807939
Iteration 3408, loss = 0.00807620
Iteration 3409, loss = 0.00807279
Iteration 3410, loss = 0.00806992
Iteration 3411, loss = 0.00806632
Iteration 3412, loss = 0.00806307
Iteration 3413, loss = 0.00805996
Iteration 3414, loss = 0.00805724
Iteration 3415, loss = 0.00805400
Iteration 3416, loss = 0.00805091
Iteration 3417, loss = 0.00804763
Iteration 3418, loss = 0.00804433
Iteration 3419, loss = 0.00804113
Iteration 3420, loss = 0.00803780
Iteration 3421, loss = 0.00803492
Iteration 3422, loss = 0.00803183
Iteration 3423, loss = 0.00802871
Iteration 3424, loss = 0.00802550
Iteration 3425, loss = 0.00802267
Iteration 3426, loss = 0.00801921
Iteration 3427, loss = 0.00801644
Iteration 3428, loss = 0.00801232
Iteration 3429, loss = 0.00800932
Iteration 3430, loss = 0.00800555
Iteration 3431, loss = 0.00800219
Iteration 3432, loss = 0.00799930
Iteration 3433, loss = 0.00799606
Iteration 3434, loss = 0.00799239
Iteration 3435, loss = 0.00798937
Iteration 3436, loss = 0.00798631
Iteration 3437, loss = 0.00798375
Iteration 3438, loss = 0.00797983
Iteration 3439, loss = 0.00797662
Iteration 3440, loss = 0.00797364
Iteration 3441, loss = 0.00797068
Iteration 3442, loss = 0.00796768
Iteration 3443, loss = 0.00796470
Iteration 3444, loss = 0.00796187
Iteration 3445, loss = 0.00795876
Iteration 3446, loss = 0.00795560
Iteration 3447, loss = 0.00795261
Iteration 3448, loss = 0.00794941
Iteration 3449, loss = 0.00794648
Iteration 3450, loss = 0.00794349
Iteration 3451, loss = 0.00794184
Iteration 3452, loss = 0.00793724
Iteration 3453, loss = 0.00793330
Iteration 3454, loss = 0.00793128
Iteration 3455, loss = 0.00792747
Iteration 3456, loss = 0.00792459
Iteration 3457, loss = 0.00792093
Iteration 3458, loss = 0.00791787
Iteration 3459, loss = 0.00791463
Iteration 3460, loss = 0.00791152
Iteration 3461, loss = 0.00790855
Iteration 3462, loss = 0.00790586
Iteration 3463, loss = 0.00790274
Iteration 3464, loss = 0.00789955
Iteration 3465, loss = 0.00789705
Iteration 3466, loss = 0.00789345
Iteration 3467, loss = 0.00789061
Iteration 3468, loss = 0.00788774
Iteration 3469, loss = 0.00788510
Iteration 3470, loss = 0.00788315
Iteration 3471, loss = 0.00787951
Iteration 3472, loss = 0.00787605
Iteration 3473, loss = 0.00787287
Iteration 3474, loss = 0.00786924
Iteration 3475, loss = 0.00786590
Iteration 3476, loss = 0.00786216
Iteration 3477, loss = 0.00785952
Iteration 3478, loss = 0.00785625
Iteration 3479, loss = 0.00785234
Iteration 3480, loss = 0.00784935
Iteration 3481, loss = 0.00784594
Iteration 3482, loss = 0.00784343
Iteration 3483, loss = 0.00784001
Iteration 3484, loss = 0.00783722
Iteration 3485, loss = 0.00783415
Iteration 3486, loss = 0.00783111
Iteration 3487, loss = 0.00782843
Iteration 3488, loss = 0.00782490
Iteration 3489, loss = 0.00782264
Iteration 3490, loss = 0.00781882
Iteration 3491, loss = 0.00781570
Iteration 3492, loss = 0.00781305
Iteration 3493, loss = 0.00780932
Iteration 3494, loss = 0.00780629
Iteration 3495, loss = 0.00780352
Iteration 3496, loss = 0.00780004
Iteration 3497, loss = 0.00779704
Iteration 3498, loss = 0.00779436
Iteration 3499, loss = 0.00779108
Iteration 3500, loss = 0.00778816
Iteration 3501, loss = 0.00778474
Iteration 3502, loss = 0.00778175
Iteration 3503, loss = 0.00777858
Iteration 3504, loss = 0.00777577
Iteration 3505, loss = 0.00777260
Iteration 3506, loss = 0.00776942
Iteration 3507, loss = 0.00776763
Iteration 3508, loss = 0.00776370
Iteration 3509, loss = 0.00776064
Iteration 3510, loss = 0.00775773
Iteration 3511, loss = 0.00775407
Iteration 3512, loss = 0.00775143
Iteration 3513, loss = 0.00774813
Iteration 3514, loss = 0.00774558
Iteration 3515, loss = 0.00774221
Iteration 3516, loss = 0.00773906
Iteration 3517, loss = 0.00773600
Iteration 3518, loss = 0.00773268
Iteration 3519, loss = 0.00772953
Iteration 3520, loss = 0.00772653
Iteration 3521, loss = 0.00772318
Iteration 3522, loss = 0.00772042
Iteration 3523, loss = 0.00771704
Iteration 3524, loss = 0.00771356
Iteration 3525, loss = 0.00771030
Iteration 3526, loss = 0.00770824
Iteration 3527, loss = 0.00770458
Iteration 3528, loss = 0.00770117
Iteration 3529, loss = 0.00769771
Iteration 3530, loss = 0.00769445
Iteration 3531, loss = 0.00769161
Iteration 3532, loss = 0.00768732
Iteration 3533, loss = 0.00768461
Iteration 3534, loss = 0.00768063
Iteration 3535, loss = 0.00767748
Iteration 3536, loss = 0.00767387
Iteration 3537, loss = 0.00767060
Iteration 3538, loss = 0.00766739
Iteration 3539, loss = 0.00766538
Iteration 3540, loss = 0.00766135
Iteration 3541, loss = 0.00765858
Iteration 3542, loss = 0.00765548
Iteration 3543, loss = 0.00765290
Iteration 3544, loss = 0.00764972
Iteration 3545, loss = 0.00764669
Iteration 3546, loss = 0.00764405
Iteration 3547, loss = 0.00764105
Iteration 3548, loss = 0.00763808
Iteration 3549, loss = 0.00763499
Iteration 3550, loss = 0.00763213
Iteration 3551, loss = 0.00762887
Iteration 3552, loss = 0.00762597
Iteration 3553, loss = 0.00762286
Iteration 3554, loss = 0.00761995
Iteration 3555, loss = 0.00761671
Iteration 3556, loss = 0.00761435
Iteration 3557, loss = 0.00761073
Iteration 3558, loss = 0.00760744
Iteration 3559, loss = 0.00760480
Iteration 3560, loss = 0.00760164
Iteration 3561, loss = 0.00759886
Iteration 3562, loss = 0.00759549
Iteration 3563, loss = 0.00759263
Iteration 3564, loss = 0.00759023
Iteration 3565, loss = 0.00758717
Iteration 3566, loss = 0.00758423
Iteration 3567, loss = 0.00758165
Iteration 3568, loss = 0.00757861
Iteration 3569, loss = 0.00757668
Iteration 3570, loss = 0.00757221
Iteration 3571, loss = 0.00756976
Iteration 3572, loss = 0.00756576
Iteration 3573, loss = 0.00756261
Iteration 3574, loss = 0.00755985
Iteration 3575, loss = 0.00755631
Iteration 3576, loss = 0.00755275
Iteration 3577, loss = 0.00754935
Iteration 3578, loss = 0.00754643
Iteration 3579, loss = 0.00754320
Iteration 3580, loss = 0.00754041
Iteration 3581, loss = 0.00753722
Iteration 3582, loss = 0.00753439
Iteration 3583, loss = 0.00753148
Iteration 3584, loss = 0.00752834
Iteration 3585, loss = 0.00752537
Iteration 3586, loss = 0.00752242
Iteration 3587, loss = 0.00751950
Iteration 3588, loss = 0.00751690
Iteration 3589, loss = 0.00751397
Iteration 3590, loss = 0.00751075
Iteration 3591, loss = 0.00750822
Iteration 3592, loss = 0.00750515
Iteration 3593, loss = 0.00750233
Iteration 3594, loss = 0.00749934
Iteration 3595, loss = 0.00749621
Iteration 3596, loss = 0.00749309
Iteration 3597, loss = 0.00749083
Iteration 3598, loss = 0.00748738
Iteration 3599, loss = 0.00748478
Iteration 3600, loss = 0.00748163
Iteration 3601, loss = 0.00747883
Iteration 3602, loss = 0.00747606
Iteration 3603, loss = 0.00747281
Iteration 3604, loss = 0.00747088
Iteration 3605, loss = 0.00746776
Iteration 3606, loss = 0.00746476
Iteration 3607, loss = 0.00746216
Iteration 3608, loss = 0.00745912
Iteration 3609, loss = 0.00745603
Iteration 3610, loss = 0.00745329
Iteration 3611, loss = 0.00745087
Iteration 3612, loss = 0.00744857
Iteration 3613, loss = 0.00744581
Iteration 3614, loss = 0.00744328
Iteration 3615, loss = 0.00744096
Iteration 3616, loss = 0.00743853
Iteration 3617, loss = 0.00743609
Iteration 3618, loss = 0.00743404
Iteration 3619, loss = 0.00743112
Iteration 3620, loss = 0.00742856
Iteration 3621, loss = 0.00742624
Iteration 3622, loss = 0.00742352
Iteration 3623, loss = 0.00742101
Iteration 3624, loss = 0.00741786
Iteration 3625, loss = 0.00741556
Iteration 3626, loss = 0.00741206
Iteration 3627, loss = 0.00740989
Iteration 3628, loss = 0.00740696
Iteration 3629, loss = 0.00740440
Iteration 3630, loss = 0.00740145
Iteration 3631, loss = 0.00739865
Iteration 3632, loss = 0.00739599
Iteration 3633, loss = 0.00739336
Iteration 3634, loss = 0.00739063
Iteration 3635, loss = 0.00738826
Iteration 3636, loss = 0.00738658
Iteration 3637, loss = 0.00738335
Iteration 3638, loss = 0.00738058
Iteration 3639, loss = 0.00737853
Iteration 3640, loss = 0.00737500
Iteration 3641, loss = 0.00737175
Iteration 3642, loss = 0.00736853
Iteration 3643, loss = 0.00736546
Iteration 3644, loss = 0.00736234
Iteration 3645, loss = 0.00735913
Iteration 3646, loss = 0.00735652
Iteration 3647, loss = 0.00735323
Iteration 3648, loss = 0.00735053
Iteration 3649, loss = 0.00734791
Iteration 3650, loss = 0.00734483
Iteration 3651, loss = 0.00734236
Iteration 3652, loss = 0.00733892
Iteration 3653, loss = 0.00733585
Iteration 3654, loss = 0.00733303
Iteration 3655, loss = 0.00733009
Iteration 3656, loss = 0.00732736
Iteration 3657, loss = 0.00732491
Iteration 3658, loss = 0.00732175
Iteration 3659, loss = 0.00731892
Iteration 3660, loss = 0.00731635
Iteration 3661, loss = 0.00731325
Iteration 3662, loss = 0.00730946
Iteration 3663, loss = 0.00730713
Iteration 3664, loss = 0.00730377
Iteration 3665, loss = 0.00730094
Iteration 3666, loss = 0.00729812
Iteration 3667, loss = 0.00729511
Iteration 3668, loss = 0.00729233
Iteration 3669, loss = 0.00728961
Iteration 3670, loss = 0.00728723
Iteration 3671, loss = 0.00728435
Iteration 3672, loss = 0.00728172
Iteration 3673, loss = 0.00727950
Iteration 3674, loss = 0.00727668
Iteration 3675, loss = 0.00727416
Iteration 3676, loss = 0.00727132
Iteration 3677, loss = 0.00726863
Iteration 3678, loss = 0.00726598
Iteration 3679, loss = 0.00726365
Iteration 3680, loss = 0.00726127
Iteration 3681, loss = 0.00725859
Iteration 3682, loss = 0.00725640
Iteration 3683, loss = 0.00725515
Iteration 3684, loss = 0.00725148
Iteration 3685, loss = 0.00724864
Iteration 3686, loss = 0.00724580
Iteration 3687, loss = 0.00724313
Iteration 3688, loss = 0.00724042
Iteration 3689, loss = 0.00723793
Iteration 3690, loss = 0.00723538
Iteration 3691, loss = 0.00723281
Iteration 3692, loss = 0.00723018
Iteration 3693, loss = 0.00722815
Iteration 3694, loss = 0.00722580
Iteration 3695, loss = 0.00722363
Iteration 3696, loss = 0.00722124
Iteration 3697, loss = 0.00721876
Iteration 3698, loss = 0.00721694
Iteration 3699, loss = 0.00721379
Iteration 3700, loss = 0.00721100
Iteration 3701, loss = 0.00720861
Iteration 3702, loss = 0.00720538
Iteration 3703, loss = 0.00720235
Iteration 3704, loss = 0.00719965
Iteration 3705, loss = 0.00719647
Iteration 3706, loss = 0.00719371
Iteration 3707, loss = 0.00719074
Iteration 3708, loss = 0.00718829
Iteration 3709, loss = 0.00718548
Iteration 3710, loss = 0.00718315
Iteration 3711, loss = 0.00718051
Iteration 3712, loss = 0.00717766
Iteration 3713, loss = 0.00717562
Iteration 3714, loss = 0.00717286
Iteration 3715, loss = 0.00717057
Iteration 3716, loss = 0.00716819
Iteration 3717, loss = 0.00716625
Iteration 3718, loss = 0.00716373
Iteration 3719, loss = 0.00716096
Iteration 3720, loss = 0.00715800
Iteration 3721, loss = 0.00715504
Iteration 3722, loss = 0.00715299
Iteration 3723, loss = 0.00714983
Iteration 3724, loss = 0.00714706
Iteration 3725, loss = 0.00714458
Iteration 3726, loss = 0.00714183
Iteration 3727, loss = 0.00713940
Iteration 3728, loss = 0.00713684
Iteration 3729, loss = 0.00713510
Iteration 3730, loss = 0.00713166
Iteration 3731, loss = 0.00712828
Iteration 3732, loss = 0.00712545
Iteration 3733, loss = 0.00712244
Iteration 3734, loss = 0.00711993
Iteration 3735, loss = 0.00711658
Iteration 3736, loss = 0.00711404
Iteration 3737, loss = 0.00711057
Iteration 3738, loss = 0.00710774
Iteration 3739, loss = 0.00710418
Iteration 3740, loss = 0.00710109
Iteration 3741, loss = 0.00709863
Iteration 3742, loss = 0.00709508
Iteration 3743, loss = 0.00709259
Iteration 3744, loss = 0.00708993
Iteration 3745, loss = 0.00708660
Iteration 3746, loss = 0.00708440
Iteration 3747, loss = 0.00708152
Iteration 3748, loss = 0.00707889
Iteration 3749, loss = 0.00707686
Iteration 3750, loss = 0.00707417
Iteration 3751, loss = 0.00707219
Iteration 3752, loss = 0.00706977
Iteration 3753, loss = 0.00706833
Iteration 3754, loss = 0.00706489
Iteration 3755, loss = 0.00706206
Iteration 3756, loss = 0.00705957
Iteration 3757, loss = 0.00705649
Iteration 3758, loss = 0.00705442
Iteration 3759, loss = 0.00705142
Iteration 3760, loss = 0.00704814
Iteration 3761, loss = 0.00704520
Iteration 3762, loss = 0.00704199
Iteration 3763, loss = 0.00703947
Iteration 3764, loss = 0.00703625
Iteration 3765, loss = 0.00703336
Iteration 3766, loss = 0.00703071
Iteration 3767, loss = 0.00702791
Iteration 3768, loss = 0.00702526
Iteration 3769, loss = 0.00702257
Iteration 3770, loss = 0.00701990
Iteration 3771, loss = 0.00701749
Iteration 3772, loss = 0.00701495
Iteration 3773, loss = 0.00701244
Iteration 3774, loss = 0.00700949
Iteration 3775, loss = 0.00700693
Iteration 3776, loss = 0.00700477
Iteration 3777, loss = 0.00700225
Iteration 3778, loss = 0.00699907
Iteration 3779, loss = 0.00699660
Iteration 3780, loss = 0.00699421
Iteration 3781, loss = 0.00699139
Iteration 3782, loss = 0.00698905
Iteration 3783, loss = 0.00698642
Iteration 3784, loss = 0.00698397
Iteration 3785, loss = 0.00698156
Iteration 3786, loss = 0.00697861
Iteration 3787, loss = 0.00697643
Iteration 3788, loss = 0.00697471
Iteration 3789, loss = 0.00697281
Iteration 3790, loss = 0.00696952
Iteration 3791, loss = 0.00696709
Iteration 3792, loss = 0.00696455
Iteration 3793, loss = 0.00696224
Iteration 3794, loss = 0.00695984
Iteration 3795, loss = 0.00695769
Iteration 3796, loss = 0.00695553
Iteration 3797, loss = 0.00695329
Iteration 3798, loss = 0.00695112
Iteration 3799, loss = 0.00694888
Iteration 3800, loss = 0.00694636
Iteration 3801, loss = 0.00694362
Iteration 3802, loss = 0.00694139
Iteration 3803, loss = 0.00693872
Iteration 3804, loss = 0.00693635
Iteration 3805, loss = 0.00693359
Iteration 3806, loss = 0.00693071
Iteration 3807, loss = 0.00692841
Iteration 3808, loss = 0.00692657
Iteration 3809, loss = 0.00692329
Iteration 3810, loss = 0.00692111
Iteration 3811, loss = 0.00691834
Iteration 3812, loss = 0.00691614
Iteration 3813, loss = 0.00691343
Iteration 3814, loss = 0.00691078
Iteration 3815, loss = 0.00690823
Iteration 3816, loss = 0.00690589
Iteration 3817, loss = 0.00690385
Iteration 3818, loss = 0.00690109
Iteration 3819, loss = 0.00689878
Iteration 3820, loss = 0.00689637
Iteration 3821, loss = 0.00689413
Iteration 3822, loss = 0.00689185
Iteration 3823, loss = 0.00688979
Iteration 3824, loss = 0.00688713
Iteration 3825, loss = 0.00688514
Iteration 3826, loss = 0.00688310
Iteration 3827, loss = 0.00688103
Iteration 3828, loss = 0.00687881
Iteration 3829, loss = 0.00687680
Iteration 3830, loss = 0.00687548
Iteration 3831, loss = 0.00687346
Iteration 3832, loss = 0.00687166
Iteration 3833, loss = 0.00686906
Iteration 3834, loss = 0.00686707
Iteration 3835, loss = 0.00686450
Iteration 3836, loss = 0.00686154
Iteration 3837, loss = 0.00685865
Iteration 3838, loss = 0.00685567
Iteration 3839, loss = 0.00685383
Iteration 3840, loss = 0.00685017
Iteration 3841, loss = 0.00684770
Iteration 3842, loss = 0.00684528
Iteration 3843, loss = 0.00684243
Iteration 3844, loss = 0.00684027
Iteration 3845, loss = 0.00683756
Iteration 3846, loss = 0.00683480
Iteration 3847, loss = 0.00683236
Iteration 3848, loss = 0.00682951
Iteration 3849, loss = 0.00682721
Iteration 3850, loss = 0.00682453
Iteration 3851, loss = 0.00682253
Iteration 3852, loss = 0.00681991
Iteration 3853, loss = 0.00681739
Iteration 3854, loss = 0.00681511
Iteration 3855, loss = 0.00681251
Iteration 3856, loss = 0.00681059
Iteration 3857, loss = 0.00680805
Iteration 3858, loss = 0.00680507
Iteration 3859, loss = 0.00680312
Iteration 3860, loss = 0.00680037
Iteration 3861, loss = 0.00679795
Iteration 3862, loss = 0.00679598
Iteration 3863, loss = 0.00679356
Iteration 3864, loss = 0.00679119
Iteration 3865, loss = 0.00679004
Iteration 3866, loss = 0.00678663
Iteration 3867, loss = 0.00678402
Iteration 3868, loss = 0.00678177
Iteration 3869, loss = 0.00677912
Iteration 3870, loss = 0.00677694
Iteration 3871, loss = 0.00677499
Iteration 3872, loss = 0.00677307
Iteration 3873, loss = 0.00677044
Iteration 3874, loss = 0.00676810
Iteration 3875, loss = 0.00676571
Iteration 3876, loss = 0.00676339
Iteration 3877, loss = 0.00676074
Iteration 3878, loss = 0.00675878
Iteration 3879, loss = 0.00675614
Iteration 3880, loss = 0.00675389
Iteration 3881, loss = 0.00675123
Iteration 3882, loss = 0.00674902
Iteration 3883, loss = 0.00674636
Iteration 3884, loss = 0.00674376
Iteration 3885, loss = 0.00674104
Iteration 3886, loss = 0.00673868
Iteration 3887, loss = 0.00673593
Iteration 3888, loss = 0.00673381
Iteration 3889, loss = 0.00673131
Iteration 3890, loss = 0.00672934
Iteration 3891, loss = 0.00672687
Iteration 3892, loss = 0.00672458
Iteration 3893, loss = 0.00672243
Iteration 3894, loss = 0.00672001
Iteration 3895, loss = 0.00671774
Iteration 3896, loss = 0.00671563
Iteration 3897, loss = 0.00671293
Iteration 3898, loss = 0.00671014
Iteration 3899, loss = 0.00670753
Iteration 3900, loss = 0.00670548
Iteration 3901, loss = 0.00670264
Iteration 3902, loss = 0.00670032
Iteration 3903, loss = 0.00669864
Iteration 3904, loss = 0.00669606
Iteration 3905, loss = 0.00669382
Iteration 3906, loss = 0.00669144
Iteration 3907, loss = 0.00668942
Iteration 3908, loss = 0.00668732
Iteration 3909, loss = 0.00668523
Iteration 3910, loss = 0.00668293
Iteration 3911, loss = 0.00668051
Iteration 3912, loss = 0.00667875
Iteration 3913, loss = 0.00667588
Iteration 3914, loss = 0.00667337
Iteration 3915, loss = 0.00667065
Iteration 3916, loss = 0.00666837
Iteration 3917, loss = 0.00666454
Iteration 3918, loss = 0.00666215
Iteration 3919, loss = 0.00665914
Iteration 3920, loss = 0.00665629
Iteration 3921, loss = 0.00665360
Iteration 3922, loss = 0.00665249
Iteration 3923, loss = 0.00664897
Iteration 3924, loss = 0.00664646
Iteration 3925, loss = 0.00664345
Iteration 3926, loss = 0.00664047
Iteration 3927, loss = 0.00663725
Iteration 3928, loss = 0.00663476
Iteration 3929, loss = 0.00663180
Iteration 3930, loss = 0.00662853
Iteration 3931, loss = 0.00662523
Iteration 3932, loss = 0.00662282
Iteration 3933, loss = 0.00662202
Iteration 3934, loss = 0.00661881
Iteration 3935, loss = 0.00661560
Iteration 3936, loss = 0.00661300
Iteration 3937, loss = 0.00661045
Iteration 3938, loss = 0.00660754
Iteration 3939, loss = 0.00660487
Iteration 3940, loss = 0.00660303
Iteration 3941, loss = 0.00660003
Iteration 3942, loss = 0.00659756
Iteration 3943, loss = 0.00659453
Iteration 3944, loss = 0.00659236
Iteration 3945, loss = 0.00659012
Iteration 3946, loss = 0.00658742
Iteration 3947, loss = 0.00658511
Iteration 3948, loss = 0.00658277
Iteration 3949, loss = 0.00658039
Iteration 3950, loss = 0.00657850
Iteration 3951, loss = 0.00657578
Iteration 3952, loss = 0.00657359
Iteration 3953, loss = 0.00657120
Iteration 3954, loss = 0.00656899
Iteration 3955, loss = 0.00656660
Iteration 3956, loss = 0.00656444
Iteration 3957, loss = 0.00656232
Iteration 3958, loss = 0.00656003
Iteration 3959, loss = 0.00655768
Iteration 3960, loss = 0.00655591
Iteration 3961, loss = 0.00655352
Iteration 3962, loss = 0.00655128
Iteration 3963, loss = 0.00654894
Iteration 3964, loss = 0.00654633
Iteration 3965, loss = 0.00654416
Iteration 3966, loss = 0.00654231
Iteration 3967, loss = 0.00654018
Iteration 3968, loss = 0.00653724
Iteration 3969, loss = 0.00653499
Iteration 3970, loss = 0.00653245
Iteration 3971, loss = 0.00653004
Iteration 3972, loss = 0.00652776
Iteration 3973, loss = 0.00652509
Iteration 3974, loss = 0.00652261
Iteration 3975, loss = 0.00652047
Iteration 3976, loss = 0.00651880
Iteration 3977, loss = 0.00651559
Iteration 3978, loss = 0.00651306
Iteration 3979, loss = 0.00651125
Iteration 3980, loss = 0.00650855
Iteration 3981, loss = 0.00650651
Iteration 3982, loss = 0.00650418
Iteration 3983, loss = 0.00650238
Iteration 3984, loss = 0.00649970
Iteration 3985, loss = 0.00649727
Iteration 3986, loss = 0.00649501
Iteration 3987, loss = 0.00649253
Iteration 3988, loss = 0.00649014
Iteration 3989, loss = 0.00648781
Iteration 3990, loss = 0.00648545
Iteration 3991, loss = 0.00648285
Iteration 3992, loss = 0.00648072
Iteration 3993, loss = 0.00647800
Iteration 3994, loss = 0.00647537
Iteration 3995, loss = 0.00647392
Iteration 3996, loss = 0.00647093
Iteration 3997, loss = 0.00646865
Iteration 3998, loss = 0.00646615
Iteration 3999, loss = 0.00646393
Iteration 4000, loss = 0.00646251
Iteration 4001, loss = 0.00645935
Iteration 4002, loss = 0.00645754
Iteration 4003, loss = 0.00645493
Iteration 4004, loss = 0.00645258
Iteration 4005, loss = 0.00645024
Iteration 4006, loss = 0.00644792
Iteration 4007, loss = 0.00644545
Iteration 4008, loss = 0.00644331
Iteration 4009, loss = 0.00644039
Iteration 4010, loss = 0.00643801
Iteration 4011, loss = 0.00643548
Iteration 4012, loss = 0.00643294
Iteration 4013, loss = 0.00643053
Iteration 4014, loss = 0.00642788
Iteration 4015, loss = 0.00642561
Iteration 4016, loss = 0.00642313
Iteration 4017, loss = 0.00642070
Iteration 4018, loss = 0.00641846
Iteration 4019, loss = 0.00641611
Iteration 4020, loss = 0.00641377
Iteration 4021, loss = 0.00641160
Iteration 4022, loss = 0.00640921
Iteration 4023, loss = 0.00640763
Iteration 4024, loss = 0.00640506
Iteration 4025, loss = 0.00640294
Iteration 4026, loss = 0.00640132
Iteration 4027, loss = 0.00639884
Iteration 4028, loss = 0.00639660
Iteration 4029, loss = 0.00639438
Iteration 4030, loss = 0.00639225
Iteration 4031, loss = 0.00639011
Iteration 4032, loss = 0.00638802
Iteration 4033, loss = 0.00638618
Iteration 4034, loss = 0.00638405
Iteration 4035, loss = 0.00638175
Iteration 4036, loss = 0.00637927
Iteration 4037, loss = 0.00637676
Iteration 4038, loss = 0.00637449
Iteration 4039, loss = 0.00637216
Iteration 4040, loss = 0.00636972
Iteration 4041, loss = 0.00636737
Iteration 4042, loss = 0.00636563
Iteration 4043, loss = 0.00636317
Iteration 4044, loss = 0.00636079
Iteration 4045, loss = 0.00635828
Iteration 4046, loss = 0.00635640
Iteration 4047, loss = 0.00635428
Iteration 4048, loss = 0.00635228
Iteration 4049, loss = 0.00635011
Iteration 4050, loss = 0.00634765
Iteration 4051, loss = 0.00634553
Iteration 4052, loss = 0.00634325
Iteration 4053, loss = 0.00634106
Iteration 4054, loss = 0.00633898
Iteration 4055, loss = 0.00633687
Iteration 4056, loss = 0.00633458
Iteration 4057, loss = 0.00633254
Iteration 4058, loss = 0.00633026
Iteration 4059, loss = 0.00632841
Iteration 4060, loss = 0.00632586
Iteration 4061, loss = 0.00632374
Iteration 4062, loss = 0.00632194
Iteration 4063, loss = 0.00631952
Iteration 4064, loss = 0.00631705
Iteration 4065, loss = 0.00631446
Iteration 4066, loss = 0.00631191
Iteration 4067, loss = 0.00631050
Iteration 4068, loss = 0.00630737
Iteration 4069, loss = 0.00630527
Iteration 4070, loss = 0.00630329
Iteration 4071, loss = 0.00630110
Iteration 4072, loss = 0.00629891
Iteration 4073, loss = 0.00629658
Iteration 4074, loss = 0.00629454
Iteration 4075, loss = 0.00629214
Iteration 4076, loss = 0.00628988
Iteration 4077, loss = 0.00628788
Iteration 4078, loss = 0.00628520
Iteration 4079, loss = 0.00628316
Iteration 4080, loss = 0.00628094
Iteration 4081, loss = 0.00627866
Iteration 4082, loss = 0.00627655
Iteration 4083, loss = 0.00627464
Iteration 4084, loss = 0.00627253
Iteration 4085, loss = 0.00627033
Iteration 4086, loss = 0.00626850
Iteration 4087, loss = 0.00626613
Iteration 4088, loss = 0.00626360
Iteration 4089, loss = 0.00626156
Iteration 4090, loss = 0.00625933
Iteration 4091, loss = 0.00625720
Iteration 4092, loss = 0.00625491
Iteration 4093, loss = 0.00625280
Iteration 4094, loss = 0.00625093
Iteration 4095, loss = 0.00624874
Iteration 4096, loss = 0.00624713
Iteration 4097, loss = 0.00624582
Iteration 4098, loss = 0.00624324
Iteration 4099, loss = 0.00624124
Iteration 4100, loss = 0.00623983
Iteration 4101, loss = 0.00623751
Iteration 4102, loss = 0.00623551
Iteration 4103, loss = 0.00623343
Iteration 4104, loss = 0.00623157
Iteration 4105, loss = 0.00622980
Iteration 4106, loss = 0.00622782
Iteration 4107, loss = 0.00622608
Iteration 4108, loss = 0.00622415
Iteration 4109, loss = 0.00622222
Iteration 4110, loss = 0.00622041
Iteration 4111, loss = 0.00621858
Iteration 4112, loss = 0.00621667
Iteration 4113, loss = 0.00621455
Iteration 4114, loss = 0.00621277
Iteration 4115, loss = 0.00621119
Iteration 4116, loss = 0.00620864
Iteration 4117, loss = 0.00620651
Iteration 4118, loss = 0.00620438
Iteration 4119, loss = 0.00620220
Iteration 4120, loss = 0.00619995
Iteration 4121, loss = 0.00619787
Iteration 4122, loss = 0.00619580
Iteration 4123, loss = 0.00619359
Iteration 4124, loss = 0.00619139
Iteration 4125, loss = 0.00618951
Iteration 4126, loss = 0.00618720
Iteration 4127, loss = 0.00618518
Iteration 4128, loss = 0.00618319
Iteration 4129, loss = 0.00618132
Iteration 4130, loss = 0.00617918
Iteration 4131, loss = 0.00617716
Iteration 4132, loss = 0.00617530
Iteration 4133, loss = 0.00617346
Iteration 4134, loss = 0.00617141
Iteration 4135, loss = 0.00616921
Iteration 4136, loss = 0.00616717
Iteration 4137, loss = 0.00616516
Iteration 4138, loss = 0.00616307
Iteration 4139, loss = 0.00616143
Iteration 4140, loss = 0.00615935
Iteration 4141, loss = 0.00615784
Iteration 4142, loss = 0.00615544
Iteration 4143, loss = 0.00615401
Iteration 4144, loss = 0.00615256
Iteration 4145, loss = 0.00615029
Iteration 4146, loss = 0.00614794
Iteration 4147, loss = 0.00614546
Iteration 4148, loss = 0.00614325
Iteration 4149, loss = 0.00614114
Iteration 4150, loss = 0.00613755
Iteration 4151, loss = 0.00613509
Iteration 4152, loss = 0.00613222
Iteration 4153, loss = 0.00612899
Iteration 4154, loss = 0.00612716
Iteration 4155, loss = 0.00612393
Iteration 4156, loss = 0.00612181
Iteration 4157, loss = 0.00611942
Iteration 4158, loss = 0.00611662
Iteration 4159, loss = 0.00611428
Iteration 4160, loss = 0.00611161
Iteration 4161, loss = 0.00610978
Iteration 4162, loss = 0.00610665
Iteration 4163, loss = 0.00610411
Iteration 4164, loss = 0.00610207
Iteration 4165, loss = 0.00609968
Iteration 4166, loss = 0.00609733
Iteration 4167, loss = 0.00609538
Iteration 4168, loss = 0.00609307
Iteration 4169, loss = 0.00609050
Iteration 4170, loss = 0.00608798
Iteration 4171, loss = 0.00608636
Iteration 4172, loss = 0.00608362
Iteration 4173, loss = 0.00608182
Iteration 4174, loss = 0.00607932
Iteration 4175, loss = 0.00607709
Iteration 4176, loss = 0.00607492
Iteration 4177, loss = 0.00607266
Iteration 4178, loss = 0.00607061
Iteration 4179, loss = 0.00606826
Iteration 4180, loss = 0.00606652
Iteration 4181, loss = 0.00606406
Iteration 4182, loss = 0.00606185
Iteration 4183, loss = 0.00605958
Iteration 4184, loss = 0.00605757
Iteration 4185, loss = 0.00605604
Iteration 4186, loss = 0.00605337
Iteration 4187, loss = 0.00605098
Iteration 4188, loss = 0.00604932
Iteration 4189, loss = 0.00604729
Iteration 4190, loss = 0.00604515
Iteration 4191, loss = 0.00604324
Iteration 4192, loss = 0.00604126
Iteration 4193, loss = 0.00603921
Iteration 4194, loss = 0.00603692
Iteration 4195, loss = 0.00603504
Iteration 4196, loss = 0.00603288
Iteration 4197, loss = 0.00603061
Iteration 4198, loss = 0.00602887
Iteration 4199, loss = 0.00602649
Iteration 4200, loss = 0.00602401
Iteration 4201, loss = 0.00602229
Iteration 4202, loss = 0.00601987
Iteration 4203, loss = 0.00601798
Iteration 4204, loss = 0.00601585
Iteration 4205, loss = 0.00601370
Iteration 4206, loss = 0.00601171
Iteration 4207, loss = 0.00601000
Iteration 4208, loss = 0.00600749
Iteration 4209, loss = 0.00600539
Iteration 4210, loss = 0.00600319
Iteration 4211, loss = 0.00600125
Iteration 4212, loss = 0.00599906
Iteration 4213, loss = 0.00599717
Iteration 4214, loss = 0.00599498
Iteration 4215, loss = 0.00599325
Iteration 4216, loss = 0.00599105
Iteration 4217, loss = 0.00598894
Iteration 4218, loss = 0.00598717
Iteration 4219, loss = 0.00598538
Iteration 4220, loss = 0.00598300
Iteration 4221, loss = 0.00598092
Iteration 4222, loss = 0.00597889
Iteration 4223, loss = 0.00597753
Iteration 4224, loss = 0.00597523
Iteration 4225, loss = 0.00597312
Iteration 4226, loss = 0.00597111
Iteration 4227, loss = 0.00596912
Iteration 4228, loss = 0.00596712
Iteration 4229, loss = 0.00596517
Iteration 4230, loss = 0.00596315
Iteration 4231, loss = 0.00596099
Iteration 4232, loss = 0.00595897
Iteration 4233, loss = 0.00595742
Iteration 4234, loss = 0.00595469
Iteration 4235, loss = 0.00595294
Iteration 4236, loss = 0.00595078
Iteration 4237, loss = 0.00594848
Iteration 4238, loss = 0.00594647
Iteration 4239, loss = 0.00594446
Iteration 4240, loss = 0.00594222
Iteration 4241, loss = 0.00594024
Iteration 4242, loss = 0.00593817
Iteration 4243, loss = 0.00593600
Iteration 4244, loss = 0.00593410
Iteration 4245, loss = 0.00593211
Iteration 4246, loss = 0.00593012
Iteration 4247, loss = 0.00592809
Iteration 4248, loss = 0.00592618
Iteration 4249, loss = 0.00592448
Iteration 4250, loss = 0.00592262
Iteration 4251, loss = 0.00592068
Iteration 4252, loss = 0.00591887
Iteration 4253, loss = 0.00591705
Iteration 4254, loss = 0.00591515
Iteration 4255, loss = 0.00591430
Iteration 4256, loss = 0.00591149
Iteration 4257, loss = 0.00590967
Iteration 4258, loss = 0.00590769
Iteration 4259, loss = 0.00590567
Iteration 4260, loss = 0.00590351
Iteration 4261, loss = 0.00590152
Iteration 4262, loss = 0.00589979
Iteration 4263, loss = 0.00589778
Iteration 4264, loss = 0.00589578
Iteration 4265, loss = 0.00589384
Iteration 4266, loss = 0.00589173
Iteration 4267, loss = 0.00588997
Iteration 4268, loss = 0.00588871
Iteration 4269, loss = 0.00588614
Iteration 4270, loss = 0.00588408
Iteration 4271, loss = 0.00588219
Iteration 4272, loss = 0.00587999
Iteration 4273, loss = 0.00587822
Iteration 4274, loss = 0.00587630
Iteration 4275, loss = 0.00587382
Iteration 4276, loss = 0.00587219
Iteration 4277, loss = 0.00586986
Iteration 4278, loss = 0.00586750
Iteration 4279, loss = 0.00586500
Iteration 4280, loss = 0.00586316
Iteration 4281, loss = 0.00586099
Iteration 4282, loss = 0.00585909
Iteration 4283, loss = 0.00585672
Iteration 4284, loss = 0.00585449
Iteration 4285, loss = 0.00585243
Iteration 4286, loss = 0.00585059
Iteration 4287, loss = 0.00584880
Iteration 4288, loss = 0.00584651
Iteration 4289, loss = 0.00584477
Iteration 4290, loss = 0.00584294
Iteration 4291, loss = 0.00584091
Iteration 4292, loss = 0.00583914
Iteration 4293, loss = 0.00583751
Iteration 4294, loss = 0.00583515
Iteration 4295, loss = 0.00583346
Iteration 4296, loss = 0.00583118
Iteration 4297, loss = 0.00582957
Iteration 4298, loss = 0.00582762
Iteration 4299, loss = 0.00582554
Iteration 4300, loss = 0.00582353
Iteration 4301, loss = 0.00582168
Iteration 4302, loss = 0.00581946
Iteration 4303, loss = 0.00581753
Iteration 4304, loss = 0.00581562
Iteration 4305, loss = 0.00581368
Iteration 4306, loss = 0.00581166
Iteration 4307, loss = 0.00580990
Iteration 4308, loss = 0.00580768
Iteration 4309, loss = 0.00580591
Iteration 4310, loss = 0.00580398
Iteration 4311, loss = 0.00580226
Iteration 4312, loss = 0.00580028
Iteration 4313, loss = 0.00579808
Iteration 4314, loss = 0.00579632
Iteration 4315, loss = 0.00579441
Iteration 4316, loss = 0.00579253
Iteration 4317, loss = 0.00579071
Iteration 4318, loss = 0.00578844
Iteration 4319, loss = 0.00578650
Iteration 4320, loss = 0.00578448
Iteration 4321, loss = 0.00578287
Iteration 4322, loss = 0.00578067
Iteration 4323, loss = 0.00577903
Iteration 4324, loss = 0.00577673
Iteration 4325, loss = 0.00577462
Iteration 4326, loss = 0.00577246
Iteration 4327, loss = 0.00577010
Iteration 4328, loss = 0.00576818
Iteration 4329, loss = 0.00576588
Iteration 4330, loss = 0.00576370
Iteration 4331, loss = 0.00576245
Iteration 4332, loss = 0.00576002
Iteration 4333, loss = 0.00575775
Iteration 4334, loss = 0.00575586
Iteration 4335, loss = 0.00575395
Iteration 4336, loss = 0.00575314
Iteration 4337, loss = 0.00575046
Iteration 4338, loss = 0.00574846
Iteration 4339, loss = 0.00574584
Iteration 4340, loss = 0.00574351
Iteration 4341, loss = 0.00574146
Iteration 4342, loss = 0.00574064
Iteration 4343, loss = 0.00573760
Iteration 4344, loss = 0.00573572
Iteration 4345, loss = 0.00573396
Iteration 4346, loss = 0.00573219
Iteration 4347, loss = 0.00573030
Iteration 4348, loss = 0.00572830
Iteration 4349, loss = 0.00572638
Iteration 4350, loss = 0.00572442
Iteration 4351, loss = 0.00572271
Iteration 4352, loss = 0.00572147
Iteration 4353, loss = 0.00571937
Iteration 4354, loss = 0.00571740
Iteration 4355, loss = 0.00571548
Iteration 4356, loss = 0.00571409
Iteration 4357, loss = 0.00571244
Iteration 4358, loss = 0.00571060
Iteration 4359, loss = 0.00570908
Iteration 4360, loss = 0.00570684
Iteration 4361, loss = 0.00570518
Iteration 4362, loss = 0.00570336
Iteration 4363, loss = 0.00570139
Iteration 4364, loss = 0.00569929
Iteration 4365, loss = 0.00569743
Iteration 4366, loss = 0.00569539
Iteration 4367, loss = 0.00569357
Iteration 4368, loss = 0.00569162
Iteration 4369, loss = 0.00568981
Iteration 4370, loss = 0.00568774
Iteration 4371, loss = 0.00568599
Iteration 4372, loss = 0.00568443
Iteration 4373, loss = 0.00568224
Iteration 4374, loss = 0.00568033
Iteration 4375, loss = 0.00567851
Iteration 4376, loss = 0.00567678
Iteration 4377, loss = 0.00567517
Iteration 4378, loss = 0.00567308
Iteration 4379, loss = 0.00567177
Iteration 4380, loss = 0.00566941
Iteration 4381, loss = 0.00566759
Iteration 4382, loss = 0.00566567
Iteration 4383, loss = 0.00566388
Iteration 4384, loss = 0.00566203
Iteration 4385, loss = 0.00566012
Iteration 4386, loss = 0.00565845
Iteration 4387, loss = 0.00565635
Iteration 4388, loss = 0.00565469
Iteration 4389, loss = 0.00565273
Iteration 4390, loss = 0.00565097
Iteration 4391, loss = 0.00564904
Iteration 4392, loss = 0.00564722
Iteration 4393, loss = 0.00564535
Iteration 4394, loss = 0.00564346
Iteration 4395, loss = 0.00564248
Iteration 4396, loss = 0.00563971
Iteration 4397, loss = 0.00563791
Iteration 4398, loss = 0.00563605
Iteration 4399, loss = 0.00563400
Iteration 4400, loss = 0.00563216
Iteration 4401, loss = 0.00563040
Iteration 4402, loss = 0.00562903
Iteration 4403, loss = 0.00562696
Iteration 4404, loss = 0.00562522
Iteration 4405, loss = 0.00562321
Iteration 4406, loss = 0.00562129
Iteration 4407, loss = 0.00561929
Iteration 4408, loss = 0.00561753
Iteration 4409, loss = 0.00561560
Iteration 4410, loss = 0.00561414
Iteration 4411, loss = 0.00561211
Iteration 4412, loss = 0.00561038
Iteration 4413, loss = 0.00560876
Iteration 4414, loss = 0.00560699
Iteration 4415, loss = 0.00560547
Iteration 4416, loss = 0.00560355
Iteration 4417, loss = 0.00560190
Iteration 4418, loss = 0.00560012
Iteration 4419, loss = 0.00559828
Iteration 4420, loss = 0.00559667
Iteration 4421, loss = 0.00559467
Iteration 4422, loss = 0.00559266
Iteration 4423, loss = 0.00559130
Iteration 4424, loss = 0.00558938
Iteration 4425, loss = 0.00558758
Iteration 4426, loss = 0.00558588
Iteration 4427, loss = 0.00558416
Iteration 4428, loss = 0.00558252
Iteration 4429, loss = 0.00558085
Iteration 4430, loss = 0.00557948
Iteration 4431, loss = 0.00557783
Iteration 4432, loss = 0.00557620
Iteration 4433, loss = 0.00557467
Iteration 4434, loss = 0.00557335
Iteration 4435, loss = 0.00557118
Iteration 4436, loss = 0.00556950
Iteration 4437, loss = 0.00556821
Iteration 4438, loss = 0.00556640
Iteration 4439, loss = 0.00556467
Iteration 4440, loss = 0.00556306
Iteration 4441, loss = 0.00556135
Iteration 4442, loss = 0.00555923
Iteration 4443, loss = 0.00555806
Iteration 4444, loss = 0.00555583
Iteration 4445, loss = 0.00555386
Iteration 4446, loss = 0.00555205
Iteration 4447, loss = 0.00555048
Iteration 4448, loss = 0.00554843
Iteration 4449, loss = 0.00554667
Iteration 4450, loss = 0.00554480
Iteration 4451, loss = 0.00554289
Iteration 4452, loss = 0.00554092
Iteration 4453, loss = 0.00553909
Iteration 4454, loss = 0.00553741
Iteration 4455, loss = 0.00553566
Iteration 4456, loss = 0.00553376
Iteration 4457, loss = 0.00553245
Iteration 4458, loss = 0.00553033
Iteration 4459, loss = 0.00552912
Iteration 4460, loss = 0.00552697
Iteration 4461, loss = 0.00552512
Iteration 4462, loss = 0.00552347
Iteration 4463, loss = 0.00552160
Iteration 4464, loss = 0.00551986
Iteration 4465, loss = 0.00551829
Iteration 4466, loss = 0.00551644
Iteration 4467, loss = 0.00551487
Iteration 4468, loss = 0.00551317
Iteration 4469, loss = 0.00551187
Iteration 4470, loss = 0.00550986
Iteration 4471, loss = 0.00550853
Iteration 4472, loss = 0.00550666
Iteration 4473, loss = 0.00550469
Iteration 4474, loss = 0.00550326
Iteration 4475, loss = 0.00550125
Iteration 4476, loss = 0.00549934
Iteration 4477, loss = 0.00549756
Iteration 4478, loss = 0.00549561
Iteration 4479, loss = 0.00549449
Iteration 4480, loss = 0.00549236
Iteration 4481, loss = 0.00549085
Iteration 4482, loss = 0.00548892
Iteration 4483, loss = 0.00548737
Iteration 4484, loss = 0.00548566
Iteration 4485, loss = 0.00548402
Iteration 4486, loss = 0.00548215
Iteration 4487, loss = 0.00548055
Iteration 4488, loss = 0.00547883
Iteration 4489, loss = 0.00547717
Iteration 4490, loss = 0.00547542
Iteration 4491, loss = 0.00547388
Iteration 4492, loss = 0.00547154
Iteration 4493, loss = 0.00546974
Iteration 4494, loss = 0.00546795
Iteration 4495, loss = 0.00546607
Iteration 4496, loss = 0.00546431
Iteration 4497, loss = 0.00546214
Iteration 4498, loss = 0.00546037
Iteration 4499, loss = 0.00545843
Iteration 4500, loss = 0.00545730
Iteration 4501, loss = 0.00545502
Iteration 4502, loss = 0.00545325
Iteration 4503, loss = 0.00545150
Iteration 4504, loss = 0.00544996
Iteration 4505, loss = 0.00544814
Iteration 4506, loss = 0.00544679
Iteration 4507, loss = 0.00544464
Iteration 4508, loss = 0.00544286
Iteration 4509, loss = 0.00544130
Iteration 4510, loss = 0.00543930
Iteration 4511, loss = 0.00543744
Iteration 4512, loss = 0.00543592
Iteration 4513, loss = 0.00543405
Iteration 4514, loss = 0.00543232
Iteration 4515, loss = 0.00543027
Iteration 4516, loss = 0.00542830
Iteration 4517, loss = 0.00542691
Iteration 4518, loss = 0.00542495
Iteration 4519, loss = 0.00542296
Iteration 4520, loss = 0.00542260
Iteration 4521, loss = 0.00542021
Iteration 4522, loss = 0.00541812
Iteration 4523, loss = 0.00541627
Iteration 4524, loss = 0.00541445
Iteration 4525, loss = 0.00541263
Iteration 4526, loss = 0.00541113
Iteration 4527, loss = 0.00540923
Iteration 4528, loss = 0.00540746
Iteration 4529, loss = 0.00540584
Iteration 4530, loss = 0.00540385
Iteration 4531, loss = 0.00540210
Iteration 4532, loss = 0.00540033
Iteration 4533, loss = 0.00539859
Iteration 4534, loss = 0.00539699
Iteration 4535, loss = 0.00539568
Iteration 4536, loss = 0.00539365
Iteration 4537, loss = 0.00539159
Iteration 4538, loss = 0.00538996
Iteration 4539, loss = 0.00538832
Iteration 4540, loss = 0.00538663
Iteration 4541, loss = 0.00538480
Iteration 4542, loss = 0.00538327
Iteration 4543, loss = 0.00538203
Iteration 4544, loss = 0.00537977
Iteration 4545, loss = 0.00537814
Iteration 4546, loss = 0.00537639
Iteration 4547, loss = 0.00537492
Iteration 4548, loss = 0.00537293
Iteration 4549, loss = 0.00537145
Iteration 4550, loss = 0.00536938
Iteration 4551, loss = 0.00536777
Iteration 4552, loss = 0.00536586
Iteration 4553, loss = 0.00536401
Iteration 4554, loss = 0.00536208
Iteration 4555, loss = 0.00536044
Iteration 4556, loss = 0.00535859
Iteration 4557, loss = 0.00535683
Iteration 4558, loss = 0.00535484
Iteration 4559, loss = 0.00535445
Iteration 4560, loss = 0.00535178
Iteration 4561, loss = 0.00535001
Iteration 4562, loss = 0.00534834
Iteration 4563, loss = 0.00534667
Iteration 4564, loss = 0.00534465
Iteration 4565, loss = 0.00534289
Iteration 4566, loss = 0.00534143
Iteration 4567, loss = 0.00533987
Iteration 4568, loss = 0.00533776
Iteration 4569, loss = 0.00533622
Iteration 4570, loss = 0.00533413
Iteration 4571, loss = 0.00533261
Iteration 4572, loss = 0.00533053
Iteration 4573, loss = 0.00532898
Iteration 4574, loss = 0.00532687
Iteration 4575, loss = 0.00532513
Iteration 4576, loss = 0.00532341
Iteration 4577, loss = 0.00532204
Iteration 4578, loss = 0.00532030
Iteration 4579, loss = 0.00531902
Iteration 4580, loss = 0.00531635
Iteration 4581, loss = 0.00531540
Iteration 4582, loss = 0.00531305
Iteration 4583, loss = 0.00531139
Iteration 4584, loss = 0.00530947
Iteration 4585, loss = 0.00530791
Iteration 4586, loss = 0.00530608
Iteration 4587, loss = 0.00530457
Iteration 4588, loss = 0.00530280
Iteration 4589, loss = 0.00530131
Iteration 4590, loss = 0.00529931
Iteration 4591, loss = 0.00529757
Iteration 4592, loss = 0.00529579
Iteration 4593, loss = 0.00529432
Iteration 4594, loss = 0.00529243
Iteration 4595, loss = 0.00529103
Iteration 4596, loss = 0.00528911
Iteration 4597, loss = 0.00528720
Iteration 4598, loss = 0.00528513
Iteration 4599, loss = 0.00528344
Iteration 4600, loss = 0.00528140
Iteration 4601, loss = 0.00527989
Iteration 4602, loss = 0.00527794
Iteration 4603, loss = 0.00527617
Iteration 4604, loss = 0.00527447
Iteration 4605, loss = 0.00527283
Iteration 4606, loss = 0.00527087
Iteration 4607, loss = 0.00526926
Iteration 4608, loss = 0.00526801
Iteration 4609, loss = 0.00526597
Iteration 4610, loss = 0.00526427
Iteration 4611, loss = 0.00526269
Iteration 4612, loss = 0.00526066
Iteration 4613, loss = 0.00525956
Iteration 4614, loss = 0.00525795
Iteration 4615, loss = 0.00525598
Iteration 4616, loss = 0.00525420
Iteration 4617, loss = 0.00525267
Iteration 4618, loss = 0.00525079
Iteration 4619, loss = 0.00524897
Iteration 4620, loss = 0.00524725
Iteration 4621, loss = 0.00524572
Iteration 4622, loss = 0.00524398
Iteration 4623, loss = 0.00524227
Iteration 4624, loss = 0.00524062
Iteration 4625, loss = 0.00523899
Iteration 4626, loss = 0.00523741
Iteration 4627, loss = 0.00523579
Iteration 4628, loss = 0.00523433
Iteration 4629, loss = 0.00523279
Iteration 4630, loss = 0.00523142
Iteration 4631, loss = 0.00522926
Iteration 4632, loss = 0.00522778
Iteration 4633, loss = 0.00522590
Iteration 4634, loss = 0.00522434
Iteration 4635, loss = 0.00522277
Iteration 4636, loss = 0.00522089
Iteration 4637, loss = 0.00521954
Iteration 4638, loss = 0.00521777
Iteration 4639, loss = 0.00521629
Iteration 4640, loss = 0.00521464
Iteration 4641, loss = 0.00521321
Iteration 4642, loss = 0.00521138
Iteration 4643, loss = 0.00520971
Iteration 4644, loss = 0.00520809
Iteration 4645, loss = 0.00520688
Iteration 4646, loss = 0.00520476
Iteration 4647, loss = 0.00520270
Iteration 4648, loss = 0.00520098
Iteration 4649, loss = 0.00519919
Iteration 4650, loss = 0.00519763
Iteration 4651, loss = 0.00519579
Iteration 4652, loss = 0.00519415
Iteration 4653, loss = 0.00519232
Iteration 4654, loss = 0.00519064
Iteration 4655, loss = 0.00518889
Iteration 4656, loss = 0.00518723
Iteration 4657, loss = 0.00518547
Iteration 4658, loss = 0.00518389
Iteration 4659, loss = 0.00518211
Iteration 4660, loss = 0.00518044
Iteration 4661, loss = 0.00517882
Iteration 4662, loss = 0.00517749
Iteration 4663, loss = 0.00517555
Iteration 4664, loss = 0.00517418
Iteration 4665, loss = 0.00517244
Iteration 4666, loss = 0.00517081
Iteration 4667, loss = 0.00516926
Iteration 4668, loss = 0.00516773
Iteration 4669, loss = 0.00516623
Iteration 4670, loss = 0.00516461
Iteration 4671, loss = 0.00516320
Iteration 4672, loss = 0.00516155
Iteration 4673, loss = 0.00516018
Iteration 4674, loss = 0.00515825
Iteration 4675, loss = 0.00515663
Iteration 4676, loss = 0.00515504
Iteration 4677, loss = 0.00515362
Iteration 4678, loss = 0.00515203
Iteration 4679, loss = 0.00515035
Iteration 4680, loss = 0.00514866
Iteration 4681, loss = 0.00514697
Iteration 4682, loss = 0.00514547
Iteration 4683, loss = 0.00514404
Iteration 4684, loss = 0.00514246
Iteration 4685, loss = 0.00514090
Iteration 4686, loss = 0.00513926
Iteration 4687, loss = 0.00513766
Iteration 4688, loss = 0.00513609
Iteration 4689, loss = 0.00513468
Iteration 4690, loss = 0.00513304
Iteration 4691, loss = 0.00513143
Iteration 4692, loss = 0.00512990
Iteration 4693, loss = 0.00512853
Iteration 4694, loss = 0.00512678
Iteration 4695, loss = 0.00512526
Iteration 4696, loss = 0.00512386
Iteration 4697, loss = 0.00512236
Iteration 4698, loss = 0.00512086
Iteration 4699, loss = 0.00511974
Iteration 4700, loss = 0.00511771
Iteration 4701, loss = 0.00511599
Iteration 4702, loss = 0.00511441
Iteration 4703, loss = 0.00511311
Iteration 4704, loss = 0.00511111
Iteration 4705, loss = 0.00510955
Iteration 4706, loss = 0.00510807
Iteration 4707, loss = 0.00510666
Iteration 4708, loss = 0.00510506
Iteration 4709, loss = 0.00510336
Iteration 4710, loss = 0.00510181
Iteration 4711, loss = 0.00510036
Iteration 4712, loss = 0.00509889
Iteration 4713, loss = 0.00509739
Iteration 4714, loss = 0.00509616
Iteration 4715, loss = 0.00509465
Iteration 4716, loss = 0.00509319
Iteration 4717, loss = 0.00509223
Iteration 4718, loss = 0.00509053
Iteration 4719, loss = 0.00508873
Iteration 4720, loss = 0.00508731
Iteration 4721, loss = 0.00508576
Iteration 4722, loss = 0.00508406
Iteration 4723, loss = 0.00508278
Iteration 4724, loss = 0.00508090
Iteration 4725, loss = 0.00507931
Iteration 4726, loss = 0.00507765
Iteration 4727, loss = 0.00507615
Iteration 4728, loss = 0.00507496
Iteration 4729, loss = 0.00507324
Iteration 4730, loss = 0.00507184
Iteration 4731, loss = 0.00507062
Iteration 4732, loss = 0.00506917
Iteration 4733, loss = 0.00506772
Iteration 4734, loss = 0.00506638
Iteration 4735, loss = 0.00506505
Iteration 4736, loss = 0.00506371
Iteration 4737, loss = 0.00506228
Iteration 4738, loss = 0.00506070
Iteration 4739, loss = 0.00505994
Iteration 4740, loss = 0.00505807
Iteration 4741, loss = 0.00505666
Iteration 4742, loss = 0.00505503
Iteration 4743, loss = 0.00505361
Iteration 4744, loss = 0.00505218
Iteration 4745, loss = 0.00505074
Iteration 4746, loss = 0.00504934
Iteration 4747, loss = 0.00504803
Iteration 4748, loss = 0.00504672
Iteration 4749, loss = 0.00504553
Iteration 4750, loss = 0.00504386
Iteration 4751, loss = 0.00504248
Iteration 4752, loss = 0.00504094
Iteration 4753, loss = 0.00503898
Iteration 4754, loss = 0.00503765
Iteration 4755, loss = 0.00503577
Iteration 4756, loss = 0.00503401
Iteration 4757, loss = 0.00503246
Iteration 4758, loss = 0.00503152
Iteration 4759, loss = 0.00502951
Iteration 4760, loss = 0.00502816
Iteration 4761, loss = 0.00502693
Iteration 4762, loss = 0.00502512
Iteration 4763, loss = 0.00502359
Iteration 4764, loss = 0.00502215
Iteration 4765, loss = 0.00502043
Iteration 4766, loss = 0.00501875
Iteration 4767, loss = 0.00501731
Iteration 4768, loss = 0.00501565
Iteration 4769, loss = 0.00501413
Iteration 4770, loss = 0.00501257
Iteration 4771, loss = 0.00501105
Iteration 4772, loss = 0.00500943
Iteration 4773, loss = 0.00500790
Iteration 4774, loss = 0.00500643
Iteration 4775, loss = 0.00500484
Iteration 4776, loss = 0.00500371
Iteration 4777, loss = 0.00500200
Iteration 4778, loss = 0.00500043
Iteration 4779, loss = 0.00499937
Iteration 4780, loss = 0.00499776
Iteration 4781, loss = 0.00499617
Iteration 4782, loss = 0.00499466
Iteration 4783, loss = 0.00499335
Iteration 4784, loss = 0.00499201
Iteration 4785, loss = 0.00499018
Iteration 4786, loss = 0.00498916
Iteration 4787, loss = 0.00498748
Iteration 4788, loss = 0.00498552
Iteration 4789, loss = 0.00498400
Iteration 4790, loss = 0.00498247
Iteration 4791, loss = 0.00498073
Iteration 4792, loss = 0.00497910
Iteration 4793, loss = 0.00497759
Iteration 4794, loss = 0.00497596
Iteration 4795, loss = 0.00497441
Iteration 4796, loss = 0.00497303
Iteration 4797, loss = 0.00497134
Iteration 4798, loss = 0.00497022
Iteration 4799, loss = 0.00496848
Iteration 4800, loss = 0.00496697
Iteration 4801, loss = 0.00496556
Iteration 4802, loss = 0.00496414
Iteration 4803, loss = 0.00496353
Iteration 4804, loss = 0.00496129
Iteration 4805, loss = 0.00495988
Iteration 4806, loss = 0.00495864
Iteration 4807, loss = 0.00495672
Iteration 4808, loss = 0.00495534
Iteration 4809, loss = 0.00495397
Iteration 4810, loss = 0.00495226
Iteration 4811, loss = 0.00495074
Iteration 4812, loss = 0.00494914
Iteration 4813, loss = 0.00494769
Iteration 4814, loss = 0.00494643
Iteration 4815, loss = 0.00494493
Iteration 4816, loss = 0.00494319
Iteration 4817, loss = 0.00494154
Iteration 4818, loss = 0.00493994
Iteration 4819, loss = 0.00493815
Iteration 4820, loss = 0.00493712
Iteration 4821, loss = 0.00493525
Iteration 4822, loss = 0.00493355
Iteration 4823, loss = 0.00493204
Iteration 4824, loss = 0.00493058
Iteration 4825, loss = 0.00492925
Iteration 4826, loss = 0.00492792
Iteration 4827, loss = 0.00492620
Iteration 4828, loss = 0.00492461
Iteration 4829, loss = 0.00492278
Iteration 4830, loss = 0.00492104
Iteration 4831, loss = 0.00491993
Iteration 4832, loss = 0.00491813
Iteration 4833, loss = 0.00491623
Iteration 4834, loss = 0.00491565
Iteration 4835, loss = 0.00491324
Iteration 4836, loss = 0.00491271
Iteration 4837, loss = 0.00491021
Iteration 4838, loss = 0.00490867
Iteration 4839, loss = 0.00490722
Iteration 4840, loss = 0.00490604
Iteration 4841, loss = 0.00490421
Iteration 4842, loss = 0.00490314
Iteration 4843, loss = 0.00490141
Iteration 4844, loss = 0.00490007
Iteration 4845, loss = 0.00489857
Iteration 4846, loss = 0.00489726
Iteration 4847, loss = 0.00489542
Iteration 4848, loss = 0.00489392
Iteration 4849, loss = 0.00489252
Iteration 4850, loss = 0.00489126
Iteration 4851, loss = 0.00488996
Iteration 4852, loss = 0.00488828
Iteration 4853, loss = 0.00488682
Iteration 4854, loss = 0.00488578
Iteration 4855, loss = 0.00488401
Iteration 4856, loss = 0.00488258
Iteration 4857, loss = 0.00488090
Iteration 4858, loss = 0.00487958
Iteration 4859, loss = 0.00487781
Iteration 4860, loss = 0.00487649
Iteration 4861, loss = 0.00487498
Iteration 4862, loss = 0.00487350
Iteration 4863, loss = 0.00487213
Iteration 4864, loss = 0.00487056
Iteration 4865, loss = 0.00486913
Iteration 4866, loss = 0.00486762
Iteration 4867, loss = 0.00486607
Iteration 4868, loss = 0.00486469
Iteration 4869, loss = 0.00486352
Iteration 4870, loss = 0.00486271
Iteration 4871, loss = 0.00486094
Iteration 4872, loss = 0.00486030
Iteration 4873, loss = 0.00485853
Iteration 4874, loss = 0.00485703
Iteration 4875, loss = 0.00485572
Iteration 4876, loss = 0.00485454
Iteration 4877, loss = 0.00485275
Iteration 4878, loss = 0.00485116
Iteration 4879, loss = 0.00484963
Iteration 4880, loss = 0.00484860
Iteration 4881, loss = 0.00484690
Iteration 4882, loss = 0.00484553
Iteration 4883, loss = 0.00484385
Iteration 4884, loss = 0.00484236
Iteration 4885, loss = 0.00484086
Iteration 4886, loss = 0.00483947
Iteration 4887, loss = 0.00483764
Iteration 4888, loss = 0.00483601
Iteration 4889, loss = 0.00483486
Iteration 4890, loss = 0.00483292
Iteration 4891, loss = 0.00483146
Iteration 4892, loss = 0.00482977
Iteration 4893, loss = 0.00482838
Iteration 4894, loss = 0.00482689
Iteration 4895, loss = 0.00482553
Iteration 4896, loss = 0.00482376
Iteration 4897, loss = 0.00482267
Iteration 4898, loss = 0.00482084
Iteration 4899, loss = 0.00481955
Iteration 4900, loss = 0.00481816
Iteration 4901, loss = 0.00481656
Iteration 4902, loss = 0.00481510
Iteration 4903, loss = 0.00481374
Iteration 4904, loss = 0.00481222
Iteration 4905, loss = 0.00481088
Iteration 4906, loss = 0.00480956
Iteration 4907, loss = 0.00480795
Iteration 4908, loss = 0.00480654
Iteration 4909, loss = 0.00480515
Iteration 4910, loss = 0.00480351
Iteration 4911, loss = 0.00480217
Iteration 4912, loss = 0.00480039
Iteration 4913, loss = 0.00479901
Iteration 4914, loss = 0.00479798
Iteration 4915, loss = 0.00479634
Iteration 4916, loss = 0.00479449
Iteration 4917, loss = 0.00479303
Iteration 4918, loss = 0.00479172
Iteration 4919, loss = 0.00479040
Iteration 4920, loss = 0.00478848
Iteration 4921, loss = 0.00478701
Iteration 4922, loss = 0.00478538
Iteration 4923, loss = 0.00478391
Iteration 4924, loss = 0.00478250
Iteration 4925, loss = 0.00478106
Iteration 4926, loss = 0.00477974
Iteration 4927, loss = 0.00477823
Iteration 4928, loss = 0.00477680
Iteration 4929, loss = 0.00477533
Iteration 4930, loss = 0.00477420
Iteration 4931, loss = 0.00477254
Iteration 4932, loss = 0.00477116
Iteration 4933, loss = 0.00476979
Iteration 4934, loss = 0.00476826
Iteration 4935, loss = 0.00476697
Iteration 4936, loss = 0.00476545
Iteration 4937, loss = 0.00476415
Iteration 4938, loss = 0.00476266
Iteration 4939, loss = 0.00476113
Iteration 4940, loss = 0.00475941
Iteration 4941, loss = 0.00475795
Iteration 4942, loss = 0.00475695
Iteration 4943, loss = 0.00475539
Iteration 4944, loss = 0.00475375
Iteration 4945, loss = 0.00475224
Iteration 4946, loss = 0.00475111
Iteration 4947, loss = 0.00474930
Iteration 4948, loss = 0.00474791
Iteration 4949, loss = 0.00474645
Iteration 4950, loss = 0.00474513
Iteration 4951, loss = 0.00474370
Iteration 4952, loss = 0.00474237
Iteration 4953, loss = 0.00474109
Iteration 4954, loss = 0.00473983
Iteration 4955, loss = 0.00473827
Iteration 4956, loss = 0.00473695
Iteration 4957, loss = 0.00473546
Iteration 4958, loss = 0.00473430
Iteration 4959, loss = 0.00473315
Iteration 1, loss = 1.02924602
Iteration 2, loss = 1.02603546
Iteration 3, loss = 1.02105733
Iteration 4, loss = 1.01483506
Iteration 5, loss = 1.00742757
Iteration 6, loss = 0.99962128
Iteration 7, loss = 0.99108443
Iteration 8, loss = 0.98219828
Iteration 9, loss = 0.97309884
Iteration 10, loss = 0.96388227
Iteration 11, loss = 0.95452481
Iteration 12, loss = 0.94526268
Iteration 13, loss = 0.93599634
Iteration 14, loss = 0.92684828
Iteration 15, loss = 0.91785871
Iteration 16, loss = 0.90903557
Iteration 17, loss = 0.90042755
Iteration 18, loss = 0.89225408
Iteration 19, loss = 0.88395934
Iteration 20, loss = 0.87615366
Iteration 21, loss = 0.86838927
Iteration 22, loss = 0.86096845
Iteration 23, loss = 0.85377428
Iteration 24, loss = 0.84633931
Iteration 25, loss = 0.83952342
Iteration 26, loss = 0.83248898
Iteration 27, loss = 0.82602981
Iteration 28, loss = 0.81924763
Iteration 29, loss = 0.81315270
Iteration 30, loss = 0.80715108
Iteration 31, loss = 0.80106190
Iteration 32, loss = 0.79553018
Iteration 33, loss = 0.78995926
Iteration 34, loss = 0.78455907
Iteration 35, loss = 0.77934658
Iteration 36, loss = 0.77447143
Iteration 37, loss = 0.76944722
Iteration 38, loss = 0.76489379
Iteration 39, loss = 0.76018095
Iteration 40, loss = 0.75574900
Iteration 41, loss = 0.75131218
Iteration 42, loss = 0.74710791
Iteration 43, loss = 0.74280644
Iteration 44, loss = 0.73873723
Iteration 45, loss = 0.73475250
Iteration 46, loss = 0.73086877
Iteration 47, loss = 0.72698467
Iteration 48, loss = 0.72338309
Iteration 49, loss = 0.71966340
Iteration 50, loss = 0.71612645
Iteration 51, loss = 0.71266253
Iteration 52, loss = 0.70920878
Iteration 53, loss = 0.70595190
Iteration 54, loss = 0.70270387
Iteration 55, loss = 0.69943385
Iteration 56, loss = 0.69631865
Iteration 57, loss = 0.69331139
Iteration 58, loss = 0.69009054
Iteration 59, loss = 0.68719258
Iteration 60, loss = 0.68424958
Iteration 61, loss = 0.68138899
Iteration 62, loss = 0.67860111
Iteration 63, loss = 0.67578011
Iteration 64, loss = 0.67308598
Iteration 65, loss = 0.67045977
Iteration 66, loss = 0.66778765
Iteration 67, loss = 0.66512930
Iteration 68, loss = 0.66249015
Iteration 69, loss = 0.65988812
Iteration 70, loss = 0.65736972
Iteration 71, loss = 0.65469456
Iteration 72, loss = 0.65219536
Iteration 73, loss = 0.64960319
Iteration 74, loss = 0.64705161
Iteration 75, loss = 0.64440332
Iteration 76, loss = 0.64187148
Iteration 77, loss = 0.63928682
Iteration 78, loss = 0.63670427
Iteration 79, loss = 0.63410211
Iteration 80, loss = 0.63161845
Iteration 81, loss = 0.62906962
Iteration 82, loss = 0.62656255
Iteration 83, loss = 0.62407469
Iteration 84, loss = 0.62156008
Iteration 85, loss = 0.61908128
Iteration 86, loss = 0.61665382
Iteration 87, loss = 0.61411858
Iteration 88, loss = 0.61168684
Iteration 89, loss = 0.60921949
Iteration 90, loss = 0.60671258
Iteration 91, loss = 0.60431214
Iteration 92, loss = 0.60185581
Iteration 93, loss = 0.59940666
Iteration 94, loss = 0.59698626
Iteration 95, loss = 0.59458103
Iteration 96, loss = 0.59217660
Iteration 97, loss = 0.58977010
Iteration 98, loss = 0.58734829
Iteration 99, loss = 0.58500078
Iteration 100, loss = 0.58262236
Iteration 101, loss = 0.58017293
Iteration 102, loss = 0.57781746
Iteration 103, loss = 0.57542895
Iteration 104, loss = 0.57314227
Iteration 105, loss = 0.57076749
Iteration 106, loss = 0.56849826
Iteration 107, loss = 0.56615903
Iteration 108, loss = 0.56392450
Iteration 109, loss = 0.56164704
Iteration 110, loss = 0.55941008
Iteration 111, loss = 0.55719311
Iteration 112, loss = 0.55494160
Iteration 113, loss = 0.55276953
Iteration 114, loss = 0.55053829
Iteration 115, loss = 0.54833783
Iteration 116, loss = 0.54614691
Iteration 117, loss = 0.54395414
Iteration 118, loss = 0.54177558
Iteration 119, loss = 0.53954130
Iteration 120, loss = 0.53735566
Iteration 121, loss = 0.53515370
Iteration 122, loss = 0.53296517
Iteration 123, loss = 0.53072684
Iteration 124, loss = 0.52854243
Iteration 125, loss = 0.52635891
Iteration 126, loss = 0.52420246
Iteration 127, loss = 0.52204443
Iteration 128, loss = 0.51993817
Iteration 129, loss = 0.51780842
Iteration 130, loss = 0.51570171
Iteration 131, loss = 0.51360608
Iteration 132, loss = 0.51149977
Iteration 133, loss = 0.50941025
Iteration 134, loss = 0.50735225
Iteration 135, loss = 0.50534412
Iteration 136, loss = 0.50327052
Iteration 137, loss = 0.50128588
Iteration 138, loss = 0.49925054
Iteration 139, loss = 0.49720713
Iteration 140, loss = 0.49519920
Iteration 141, loss = 0.49316535
Iteration 142, loss = 0.49113195
Iteration 143, loss = 0.48908202
Iteration 144, loss = 0.48707068
Iteration 145, loss = 0.48502283
Iteration 146, loss = 0.48301353
Iteration 147, loss = 0.48096521
Iteration 148, loss = 0.47899061
Iteration 149, loss = 0.47692410
Iteration 150, loss = 0.47491734
Iteration 151, loss = 0.47289591
Iteration 152, loss = 0.47084326
Iteration 153, loss = 0.46881112
Iteration 154, loss = 0.46677407
Iteration 155, loss = 0.46474389
Iteration 156, loss = 0.46274724
Iteration 157, loss = 0.46070250
Iteration 158, loss = 0.45870887
Iteration 159, loss = 0.45672828
Iteration 160, loss = 0.45473843
Iteration 161, loss = 0.45277439
Iteration 162, loss = 0.45077487
Iteration 163, loss = 0.44878563
Iteration 164, loss = 0.44679976
Iteration 165, loss = 0.44478924
Iteration 166, loss = 0.44277280
Iteration 167, loss = 0.44075524
Iteration 168, loss = 0.43871821
Iteration 169, loss = 0.43667311
Iteration 170, loss = 0.43466095
Iteration 171, loss = 0.43264896
Iteration 172, loss = 0.43062170
Iteration 173, loss = 0.42861561
Iteration 174, loss = 0.42663590
Iteration 175, loss = 0.42465066
Iteration 176, loss = 0.42265289
Iteration 177, loss = 0.42066712
Iteration 178, loss = 0.41866203
Iteration 179, loss = 0.41667322
Iteration 180, loss = 0.41465665
Iteration 181, loss = 0.41270262
Iteration 182, loss = 0.41069065
Iteration 183, loss = 0.40869818
Iteration 184, loss = 0.40669532
Iteration 185, loss = 0.40471763
Iteration 186, loss = 0.40269160
Iteration 187, loss = 0.40068973
Iteration 188, loss = 0.39871020
Iteration 189, loss = 0.39671682
Iteration 190, loss = 0.39472239
Iteration 191, loss = 0.39274426
Iteration 192, loss = 0.39077957
Iteration 193, loss = 0.38882104
Iteration 194, loss = 0.38684197
Iteration 195, loss = 0.38489387
Iteration 196, loss = 0.38290493
Iteration 197, loss = 0.38096548
Iteration 198, loss = 0.37899056
Iteration 199, loss = 0.37703116
Iteration 200, loss = 0.37506953
Iteration 201, loss = 0.37313178
Iteration 202, loss = 0.37117795
Iteration 203, loss = 0.36922441
Iteration 204, loss = 0.36729257
Iteration 205, loss = 0.36534681
Iteration 206, loss = 0.36342134
Iteration 207, loss = 0.36149502
Iteration 208, loss = 0.35954903
Iteration 209, loss = 0.35760907
Iteration 210, loss = 0.35568083
Iteration 211, loss = 0.35373932
Iteration 212, loss = 0.35180325
Iteration 213, loss = 0.34988277
Iteration 214, loss = 0.34794520
Iteration 215, loss = 0.34604789
Iteration 216, loss = 0.34411153
Iteration 217, loss = 0.34222069
Iteration 218, loss = 0.34030006
Iteration 219, loss = 0.33841150
Iteration 220, loss = 0.33651514
Iteration 221, loss = 0.33462666
Iteration 222, loss = 0.33274681
Iteration 223, loss = 0.33088673
Iteration 224, loss = 0.32900635
Iteration 225, loss = 0.32715567
Iteration 226, loss = 0.32531085
Iteration 227, loss = 0.32344605
Iteration 228, loss = 0.32159611
Iteration 229, loss = 0.31973413
Iteration 230, loss = 0.31790861
Iteration 231, loss = 0.31603995
Iteration 232, loss = 0.31421882
Iteration 233, loss = 0.31237157
Iteration 234, loss = 0.31056578
Iteration 235, loss = 0.30873843
Iteration 236, loss = 0.30693946
Iteration 237, loss = 0.30516459
Iteration 238, loss = 0.30336425
Iteration 239, loss = 0.30158247
Iteration 240, loss = 0.29982116
Iteration 241, loss = 0.29804938
Iteration 242, loss = 0.29631688
Iteration 243, loss = 0.29456208
Iteration 244, loss = 0.29284208
Iteration 245, loss = 0.29113682
Iteration 246, loss = 0.28942884
Iteration 247, loss = 0.28774231
Iteration 248, loss = 0.28603346
Iteration 249, loss = 0.28432956
Iteration 250, loss = 0.28266819
Iteration 251, loss = 0.28096579
Iteration 252, loss = 0.27930589
Iteration 253, loss = 0.27765279
Iteration 254, loss = 0.27600775
Iteration 255, loss = 0.27437185
Iteration 256, loss = 0.27275860
Iteration 257, loss = 0.27115837
Iteration 258, loss = 0.26956320
Iteration 259, loss = 0.26795471
Iteration 260, loss = 0.26636446
Iteration 261, loss = 0.26478702
Iteration 262, loss = 0.26321724
Iteration 263, loss = 0.26164282
Iteration 264, loss = 0.26007192
Iteration 265, loss = 0.25852905
Iteration 266, loss = 0.25697096
Iteration 267, loss = 0.25541713
Iteration 268, loss = 0.25388783
Iteration 269, loss = 0.25237025
Iteration 270, loss = 0.25082961
Iteration 271, loss = 0.24933923
Iteration 272, loss = 0.24786124
Iteration 273, loss = 0.24637547
Iteration 274, loss = 0.24492379
Iteration 275, loss = 0.24345511
Iteration 276, loss = 0.24201145
Iteration 277, loss = 0.24057646
Iteration 278, loss = 0.23916280
Iteration 279, loss = 0.23772565
Iteration 280, loss = 0.23633787
Iteration 281, loss = 0.23495405
Iteration 282, loss = 0.23357922
Iteration 283, loss = 0.23220610
Iteration 284, loss = 0.23084772
Iteration 285, loss = 0.22950058
Iteration 286, loss = 0.22816489
Iteration 287, loss = 0.22682556
Iteration 288, loss = 0.22550811
Iteration 289, loss = 0.22418907
Iteration 290, loss = 0.22289384
Iteration 291, loss = 0.22159602
Iteration 292, loss = 0.22031019
Iteration 293, loss = 0.21904436
Iteration 294, loss = 0.21776983
Iteration 295, loss = 0.21651019
Iteration 296, loss = 0.21526756
Iteration 297, loss = 0.21402523
Iteration 298, loss = 0.21279084
Iteration 299, loss = 0.21156524
Iteration 300, loss = 0.21036874
Iteration 301, loss = 0.20916407
Iteration 302, loss = 0.20796614
Iteration 303, loss = 0.20679637
Iteration 304, loss = 0.20561984
Iteration 305, loss = 0.20445149
Iteration 306, loss = 0.20330330
Iteration 307, loss = 0.20215457
Iteration 308, loss = 0.20101614
Iteration 309, loss = 0.19988303
Iteration 310, loss = 0.19876384
Iteration 311, loss = 0.19765760
Iteration 312, loss = 0.19654948
Iteration 313, loss = 0.19545722
Iteration 314, loss = 0.19437479
Iteration 315, loss = 0.19328107
Iteration 316, loss = 0.19220726
Iteration 317, loss = 0.19112978
Iteration 318, loss = 0.19007224
Iteration 319, loss = 0.18901460
Iteration 320, loss = 0.18796264
Iteration 321, loss = 0.18692718
Iteration 322, loss = 0.18589328
Iteration 323, loss = 0.18486635
Iteration 324, loss = 0.18385734
Iteration 325, loss = 0.18285011
Iteration 326, loss = 0.18185724
Iteration 327, loss = 0.18086137
Iteration 328, loss = 0.17987375
Iteration 329, loss = 0.17890750
Iteration 330, loss = 0.17794440
Iteration 331, loss = 0.17697913
Iteration 332, loss = 0.17602643
Iteration 333, loss = 0.17509916
Iteration 334, loss = 0.17416546
Iteration 335, loss = 0.17324501
Iteration 336, loss = 0.17233478
Iteration 337, loss = 0.17143193
Iteration 338, loss = 0.17052948
Iteration 339, loss = 0.16963939
Iteration 340, loss = 0.16874972
Iteration 341, loss = 0.16787027
Iteration 342, loss = 0.16698927
Iteration 343, loss = 0.16612287
Iteration 344, loss = 0.16526084
Iteration 345, loss = 0.16439470
Iteration 346, loss = 0.16354445
Iteration 347, loss = 0.16270045
Iteration 348, loss = 0.16186072
Iteration 349, loss = 0.16102969
Iteration 350, loss = 0.16020778
Iteration 351, loss = 0.15938586
Iteration 352, loss = 0.15856686
Iteration 353, loss = 0.15775241
Iteration 354, loss = 0.15694320
Iteration 355, loss = 0.15613410
Iteration 356, loss = 0.15533129
Iteration 357, loss = 0.15453758
Iteration 358, loss = 0.15374954
Iteration 359, loss = 0.15296978
Iteration 360, loss = 0.15219740
Iteration 361, loss = 0.15143417
Iteration 362, loss = 0.15065915
Iteration 363, loss = 0.14990561
Iteration 364, loss = 0.14916137
Iteration 365, loss = 0.14842298
Iteration 366, loss = 0.14767302
Iteration 367, loss = 0.14694517
Iteration 368, loss = 0.14622487
Iteration 369, loss = 0.14550991
Iteration 370, loss = 0.14480204
Iteration 371, loss = 0.14410428
Iteration 372, loss = 0.14340990
Iteration 373, loss = 0.14272620
Iteration 374, loss = 0.14205129
Iteration 375, loss = 0.14137245
Iteration 376, loss = 0.14070591
Iteration 377, loss = 0.14004966
Iteration 378, loss = 0.13939514
Iteration 379, loss = 0.13874085
Iteration 380, loss = 0.13808974
Iteration 381, loss = 0.13744648
Iteration 382, loss = 0.13680282
Iteration 383, loss = 0.13616311
Iteration 384, loss = 0.13553743
Iteration 385, loss = 0.13490845
Iteration 386, loss = 0.13428355
Iteration 387, loss = 0.13367115
Iteration 388, loss = 0.13305746
Iteration 389, loss = 0.13245578
Iteration 390, loss = 0.13185517
Iteration 391, loss = 0.13125530
Iteration 392, loss = 0.13067401
Iteration 393, loss = 0.13008602
Iteration 394, loss = 0.12950769
Iteration 395, loss = 0.12893473
Iteration 396, loss = 0.12836706
Iteration 397, loss = 0.12780429
Iteration 398, loss = 0.12724223
Iteration 399, loss = 0.12668648
Iteration 400, loss = 0.12613283
Iteration 401, loss = 0.12559175
Iteration 402, loss = 0.12504451
Iteration 403, loss = 0.12451278
Iteration 404, loss = 0.12397731
Iteration 405, loss = 0.12345182
Iteration 406, loss = 0.12292284
Iteration 407, loss = 0.12240750
Iteration 408, loss = 0.12188772
Iteration 409, loss = 0.12137565
Iteration 410, loss = 0.12086586
Iteration 411, loss = 0.12036634
Iteration 412, loss = 0.11986602
Iteration 413, loss = 0.11936929
Iteration 414, loss = 0.11887600
Iteration 415, loss = 0.11837819
Iteration 416, loss = 0.11789344
Iteration 417, loss = 0.11741049
Iteration 418, loss = 0.11693493
Iteration 419, loss = 0.11646266
Iteration 420, loss = 0.11599939
Iteration 421, loss = 0.11553834
Iteration 422, loss = 0.11506985
Iteration 423, loss = 0.11460741
Iteration 424, loss = 0.11415603
Iteration 425, loss = 0.11367885
Iteration 426, loss = 0.11322584
Iteration 427, loss = 0.11277249
Iteration 428, loss = 0.11231074
Iteration 429, loss = 0.11187360
Iteration 430, loss = 0.11143025
Iteration 431, loss = 0.11098465
Iteration 432, loss = 0.11054912
Iteration 433, loss = 0.11011909
Iteration 434, loss = 0.10968908
Iteration 435, loss = 0.10926581
Iteration 436, loss = 0.10884739
Iteration 437, loss = 0.10843071
Iteration 438, loss = 0.10801787
Iteration 439, loss = 0.10760880
Iteration 440, loss = 0.10719954
Iteration 441, loss = 0.10679799
Iteration 442, loss = 0.10639834
Iteration 443, loss = 0.10599963
Iteration 444, loss = 0.10560472
Iteration 445, loss = 0.10520960
Iteration 446, loss = 0.10482045
Iteration 447, loss = 0.10443112
Iteration 448, loss = 0.10404754
Iteration 449, loss = 0.10366733
Iteration 450, loss = 0.10328783
Iteration 451, loss = 0.10290995
Iteration 452, loss = 0.10253512
Iteration 453, loss = 0.10216436
Iteration 454, loss = 0.10179646
Iteration 455, loss = 0.10143199
Iteration 456, loss = 0.10107005
Iteration 457, loss = 0.10071285
Iteration 458, loss = 0.10034938
Iteration 459, loss = 0.09999305
Iteration 460, loss = 0.09962636
Iteration 461, loss = 0.09926585
Iteration 462, loss = 0.09891871
Iteration 463, loss = 0.09856182
Iteration 464, loss = 0.09820512
Iteration 465, loss = 0.09785349
Iteration 466, loss = 0.09751065
Iteration 467, loss = 0.09716691
Iteration 468, loss = 0.09682545
Iteration 469, loss = 0.09649023
Iteration 470, loss = 0.09615861
Iteration 471, loss = 0.09582515
Iteration 472, loss = 0.09550044
Iteration 473, loss = 0.09517294
Iteration 474, loss = 0.09485392
Iteration 475, loss = 0.09452947
Iteration 476, loss = 0.09421402
Iteration 477, loss = 0.09390619
Iteration 478, loss = 0.09359449
Iteration 479, loss = 0.09328712
Iteration 480, loss = 0.09297668
Iteration 481, loss = 0.09267530
Iteration 482, loss = 0.09236265
Iteration 483, loss = 0.09205586
Iteration 484, loss = 0.09175222
Iteration 485, loss = 0.09144827
Iteration 486, loss = 0.09114477
Iteration 487, loss = 0.09083978
Iteration 488, loss = 0.09053944
Iteration 489, loss = 0.09023793
Iteration 490, loss = 0.08994338
Iteration 491, loss = 0.08964620
Iteration 492, loss = 0.08936313
Iteration 493, loss = 0.08906741
Iteration 494, loss = 0.08878510
Iteration 495, loss = 0.08850630
Iteration 496, loss = 0.08822437
Iteration 497, loss = 0.08795587
Iteration 498, loss = 0.08768108
Iteration 499, loss = 0.08741482
Iteration 500, loss = 0.08716119
Iteration 501, loss = 0.08689239
Iteration 502, loss = 0.08662142
Iteration 503, loss = 0.08636815
Iteration 504, loss = 0.08611049
Iteration 505, loss = 0.08584762
Iteration 506, loss = 0.08561218
Iteration 507, loss = 0.08535618
Iteration 508, loss = 0.08510540
Iteration 509, loss = 0.08486030
Iteration 510, loss = 0.08461278
Iteration 511, loss = 0.08436799
Iteration 512, loss = 0.08412304
Iteration 513, loss = 0.08387881
Iteration 514, loss = 0.08363910
Iteration 515, loss = 0.08339378
Iteration 516, loss = 0.08315094
Iteration 517, loss = 0.08290511
Iteration 518, loss = 0.08266700
Iteration 519, loss = 0.08242305
Iteration 520, loss = 0.08218888
Iteration 521, loss = 0.08195768
Iteration 522, loss = 0.08172155
Iteration 523, loss = 0.08149107
Iteration 524, loss = 0.08126441
Iteration 525, loss = 0.08104130
Iteration 526, loss = 0.08080876
Iteration 527, loss = 0.08058936
Iteration 528, loss = 0.08037517
Iteration 529, loss = 0.08014633
Iteration 530, loss = 0.07993836
Iteration 531, loss = 0.07971347
Iteration 532, loss = 0.07949816
Iteration 533, loss = 0.07928717
Iteration 534, loss = 0.07907283
Iteration 535, loss = 0.07886243
Iteration 536, loss = 0.07864520
Iteration 537, loss = 0.07843284
Iteration 538, loss = 0.07821795
Iteration 539, loss = 0.07800412
Iteration 540, loss = 0.07779708
Iteration 541, loss = 0.07758704
Iteration 542, loss = 0.07738282
Iteration 543, loss = 0.07717469
Iteration 544, loss = 0.07696939
Iteration 545, loss = 0.07676371
Iteration 546, loss = 0.07656096
Iteration 547, loss = 0.07636042
Iteration 548, loss = 0.07615771
Iteration 549, loss = 0.07596036
Iteration 550, loss = 0.07576394
Iteration 551, loss = 0.07556854
Iteration 552, loss = 0.07537215
Iteration 553, loss = 0.07517502
Iteration 554, loss = 0.07499105
Iteration 555, loss = 0.07479508
Iteration 556, loss = 0.07460744
Iteration 557, loss = 0.07441452
Iteration 558, loss = 0.07423459
Iteration 559, loss = 0.07404848
Iteration 560, loss = 0.07386734
Iteration 561, loss = 0.07368149
Iteration 562, loss = 0.07350129
Iteration 563, loss = 0.07332326
Iteration 564, loss = 0.07313996
Iteration 565, loss = 0.07296935
Iteration 566, loss = 0.07279086
Iteration 567, loss = 0.07260857
Iteration 568, loss = 0.07243141
Iteration 569, loss = 0.07227112
Iteration 570, loss = 0.07208277
Iteration 571, loss = 0.07190848
Iteration 572, loss = 0.07173252
Iteration 573, loss = 0.07156084
Iteration 574, loss = 0.07139391
Iteration 575, loss = 0.07121905
Iteration 576, loss = 0.07105055
Iteration 577, loss = 0.07088532
Iteration 578, loss = 0.07071459
Iteration 579, loss = 0.07055226
Iteration 580, loss = 0.07038387
Iteration 581, loss = 0.07022022
Iteration 582, loss = 0.07005267
Iteration 583, loss = 0.06988803
Iteration 584, loss = 0.06972443
Iteration 585, loss = 0.06956451
Iteration 586, loss = 0.06940674
Iteration 587, loss = 0.06924419
Iteration 588, loss = 0.06908534
Iteration 589, loss = 0.06892452
Iteration 590, loss = 0.06876700
Iteration 591, loss = 0.06860830
Iteration 592, loss = 0.06844953
Iteration 593, loss = 0.06829610
Iteration 594, loss = 0.06814847
Iteration 595, loss = 0.06798990
Iteration 596, loss = 0.06783271
Iteration 597, loss = 0.06768024
Iteration 598, loss = 0.06753050
Iteration 599, loss = 0.06736991
Iteration 600, loss = 0.06722613
Iteration 601, loss = 0.06707353
Iteration 602, loss = 0.06692413
Iteration 603, loss = 0.06677845
Iteration 604, loss = 0.06663053
Iteration 605, loss = 0.06648560
Iteration 606, loss = 0.06634145
Iteration 607, loss = 0.06619752
Iteration 608, loss = 0.06605378
Iteration 609, loss = 0.06592558
Iteration 610, loss = 0.06577653
Iteration 611, loss = 0.06563186
Iteration 612, loss = 0.06548936
Iteration 613, loss = 0.06535361
Iteration 614, loss = 0.06521711
Iteration 615, loss = 0.06507286
Iteration 616, loss = 0.06493267
Iteration 617, loss = 0.06480039
Iteration 618, loss = 0.06466100
Iteration 619, loss = 0.06452567
Iteration 620, loss = 0.06439223
Iteration 621, loss = 0.06426000
Iteration 622, loss = 0.06412891
Iteration 623, loss = 0.06399628
Iteration 624, loss = 0.06386812
Iteration 625, loss = 0.06373750
Iteration 626, loss = 0.06361231
Iteration 627, loss = 0.06347953
Iteration 628, loss = 0.06335200
Iteration 629, loss = 0.06322853
Iteration 630, loss = 0.06309671
Iteration 631, loss = 0.06296745
Iteration 632, loss = 0.06284237
Iteration 633, loss = 0.06271261
Iteration 634, loss = 0.06258647
Iteration 635, loss = 0.06245890
Iteration 636, loss = 0.06233403
Iteration 637, loss = 0.06220434
Iteration 638, loss = 0.06208600
Iteration 639, loss = 0.06195880
Iteration 640, loss = 0.06183607
Iteration 641, loss = 0.06171818
Iteration 642, loss = 0.06159348
Iteration 643, loss = 0.06147662
Iteration 644, loss = 0.06135710
Iteration 645, loss = 0.06124397
Iteration 646, loss = 0.06112670
Iteration 647, loss = 0.06101690
Iteration 648, loss = 0.06089500
Iteration 649, loss = 0.06078161
Iteration 650, loss = 0.06066889
Iteration 651, loss = 0.06055296
Iteration 652, loss = 0.06043700
Iteration 653, loss = 0.06032479
Iteration 654, loss = 0.06020896
Iteration 655, loss = 0.06009664
Iteration 656, loss = 0.05997910
Iteration 657, loss = 0.05986614
Iteration 658, loss = 0.05975506
Iteration 659, loss = 0.05964386
Iteration 660, loss = 0.05953129
Iteration 661, loss = 0.05942191
Iteration 662, loss = 0.05930717
Iteration 663, loss = 0.05919484
Iteration 664, loss = 0.05908159
Iteration 665, loss = 0.05896770
Iteration 666, loss = 0.05885520
Iteration 667, loss = 0.05874077
Iteration 668, loss = 0.05863242
Iteration 669, loss = 0.05852129
Iteration 670, loss = 0.05840746
Iteration 671, loss = 0.05830014
Iteration 672, loss = 0.05819092
Iteration 673, loss = 0.05808207
Iteration 674, loss = 0.05798067
Iteration 675, loss = 0.05787388
Iteration 676, loss = 0.05776801
Iteration 677, loss = 0.05766739
Iteration 678, loss = 0.05756398
Iteration 679, loss = 0.05745647
Iteration 680, loss = 0.05735641
Iteration 681, loss = 0.05725207
Iteration 682, loss = 0.05715339
Iteration 683, loss = 0.05705154
Iteration 684, loss = 0.05694924
Iteration 685, loss = 0.05685281
Iteration 686, loss = 0.05675084
Iteration 687, loss = 0.05665309
Iteration 688, loss = 0.05655040
Iteration 689, loss = 0.05645422
Iteration 690, loss = 0.05635339
Iteration 691, loss = 0.05625460
Iteration 692, loss = 0.05615499
Iteration 693, loss = 0.05606271
Iteration 694, loss = 0.05596275
Iteration 695, loss = 0.05586683
Iteration 696, loss = 0.05576808
Iteration 697, loss = 0.05567223
Iteration 698, loss = 0.05557482
Iteration 699, loss = 0.05548369
Iteration 700, loss = 0.05538549
Iteration 701, loss = 0.05529124
Iteration 702, loss = 0.05519952
Iteration 703, loss = 0.05510736
Iteration 704, loss = 0.05501877
Iteration 705, loss = 0.05492274
Iteration 706, loss = 0.05482892
Iteration 707, loss = 0.05473420
Iteration 708, loss = 0.05463974
Iteration 709, loss = 0.05454867
Iteration 710, loss = 0.05445525
Iteration 711, loss = 0.05436302
Iteration 712, loss = 0.05427532
Iteration 713, loss = 0.05418756
Iteration 714, loss = 0.05409771
Iteration 715, loss = 0.05400804
Iteration 716, loss = 0.05392127
Iteration 717, loss = 0.05383148
Iteration 718, loss = 0.05374549
Iteration 719, loss = 0.05365842
Iteration 720, loss = 0.05356962
Iteration 721, loss = 0.05348433
Iteration 722, loss = 0.05339757
Iteration 723, loss = 0.05330858
Iteration 724, loss = 0.05322014
Iteration 725, loss = 0.05313986
Iteration 726, loss = 0.05304796
Iteration 727, loss = 0.05295955
Iteration 728, loss = 0.05287667
Iteration 729, loss = 0.05278774
Iteration 730, loss = 0.05270118
Iteration 731, loss = 0.05261382
Iteration 732, loss = 0.05252400
Iteration 733, loss = 0.05243344
Iteration 734, loss = 0.05234567
Iteration 735, loss = 0.05226345
Iteration 736, loss = 0.05217433
Iteration 737, loss = 0.05209057
Iteration 738, loss = 0.05200723
Iteration 739, loss = 0.05192452
Iteration 740, loss = 0.05184335
Iteration 741, loss = 0.05176434
Iteration 742, loss = 0.05168304
Iteration 743, loss = 0.05160445
Iteration 744, loss = 0.05152620
Iteration 745, loss = 0.05144569
Iteration 746, loss = 0.05136753
Iteration 747, loss = 0.05128458
Iteration 748, loss = 0.05120284
Iteration 749, loss = 0.05112335
Iteration 750, loss = 0.05103931
Iteration 751, loss = 0.05095885
Iteration 752, loss = 0.05087830
Iteration 753, loss = 0.05080240
Iteration 754, loss = 0.05072325
Iteration 755, loss = 0.05064571
Iteration 756, loss = 0.05057005
Iteration 757, loss = 0.05049213
Iteration 758, loss = 0.05041739
Iteration 759, loss = 0.05034211
Iteration 760, loss = 0.05026734
Iteration 761, loss = 0.05018660
Iteration 762, loss = 0.05011261
Iteration 763, loss = 0.05003571
Iteration 764, loss = 0.04995260
Iteration 765, loss = 0.04987831
Iteration 766, loss = 0.04980198
Iteration 767, loss = 0.04972610
Iteration 768, loss = 0.04964891
Iteration 769, loss = 0.04957533
Iteration 770, loss = 0.04949756
Iteration 771, loss = 0.04942139
Iteration 772, loss = 0.04934926
Iteration 773, loss = 0.04927306
Iteration 774, loss = 0.04919810
Iteration 775, loss = 0.04912551
Iteration 776, loss = 0.04904971
Iteration 777, loss = 0.04897572
Iteration 778, loss = 0.04890452
Iteration 779, loss = 0.04882882
Iteration 780, loss = 0.04875412
Iteration 781, loss = 0.04867799
Iteration 782, loss = 0.04860629
Iteration 783, loss = 0.04853332
Iteration 784, loss = 0.04846616
Iteration 785, loss = 0.04839843
Iteration 786, loss = 0.04832511
Iteration 787, loss = 0.04825993
Iteration 788, loss = 0.04818777
Iteration 789, loss = 0.04811938
Iteration 790, loss = 0.04804953
Iteration 791, loss = 0.04797941
Iteration 792, loss = 0.04790999
Iteration 793, loss = 0.04783773
Iteration 794, loss = 0.04776787
Iteration 795, loss = 0.04769685
Iteration 796, loss = 0.04762687
Iteration 797, loss = 0.04756410
Iteration 798, loss = 0.04748818
Iteration 799, loss = 0.04742283
Iteration 800, loss = 0.04735869
Iteration 801, loss = 0.04728342
Iteration 802, loss = 0.04721783
Iteration 803, loss = 0.04715243
Iteration 804, loss = 0.04708528
Iteration 805, loss = 0.04701687
Iteration 806, loss = 0.04695269
Iteration 807, loss = 0.04688249
Iteration 808, loss = 0.04681983
Iteration 809, loss = 0.04675452
Iteration 810, loss = 0.04668958
Iteration 811, loss = 0.04662661
Iteration 812, loss = 0.04656461
Iteration 813, loss = 0.04650121
Iteration 814, loss = 0.04644186
Iteration 815, loss = 0.04638072
Iteration 816, loss = 0.04631566
Iteration 817, loss = 0.04625464
Iteration 818, loss = 0.04618827
Iteration 819, loss = 0.04612272
Iteration 820, loss = 0.04605914
Iteration 821, loss = 0.04599502
Iteration 822, loss = 0.04593329
Iteration 823, loss = 0.04586590
Iteration 824, loss = 0.04580368
Iteration 825, loss = 0.04574018
Iteration 826, loss = 0.04567418
Iteration 827, loss = 0.04561186
Iteration 828, loss = 0.04554743
Iteration 829, loss = 0.04548496
Iteration 830, loss = 0.04542746
Iteration 831, loss = 0.04536155
Iteration 832, loss = 0.04529899
Iteration 833, loss = 0.04523499
Iteration 834, loss = 0.04517920
Iteration 835, loss = 0.04511420
Iteration 836, loss = 0.04505395
Iteration 837, loss = 0.04498976
Iteration 838, loss = 0.04493045
Iteration 839, loss = 0.04486953
Iteration 840, loss = 0.04481056
Iteration 841, loss = 0.04475030
Iteration 842, loss = 0.04469234
Iteration 843, loss = 0.04463358
Iteration 844, loss = 0.04457611
Iteration 845, loss = 0.04451880
Iteration 846, loss = 0.04445938
Iteration 847, loss = 0.04440031
Iteration 848, loss = 0.04434181
Iteration 849, loss = 0.04428535
Iteration 850, loss = 0.04422264
Iteration 851, loss = 0.04416611
Iteration 852, loss = 0.04410632
Iteration 853, loss = 0.04404829
Iteration 854, loss = 0.04398986
Iteration 855, loss = 0.04393241
Iteration 856, loss = 0.04387556
Iteration 857, loss = 0.04382551
Iteration 858, loss = 0.04376233
Iteration 859, loss = 0.04370594
Iteration 860, loss = 0.04364760
Iteration 861, loss = 0.04359069
Iteration 862, loss = 0.04353124
Iteration 863, loss = 0.04347441
Iteration 864, loss = 0.04341771
Iteration 865, loss = 0.04335637
Iteration 866, loss = 0.04329986
Iteration 867, loss = 0.04324318
Iteration 868, loss = 0.04319225
Iteration 869, loss = 0.04312941
Iteration 870, loss = 0.04307438
Iteration 871, loss = 0.04301900
Iteration 872, loss = 0.04296009
Iteration 873, loss = 0.04290451
Iteration 874, loss = 0.04284878
Iteration 875, loss = 0.04279810
Iteration 876, loss = 0.04274306
Iteration 877, loss = 0.04268882
Iteration 878, loss = 0.04263607
Iteration 879, loss = 0.04258636
Iteration 880, loss = 0.04252733
Iteration 881, loss = 0.04247313
Iteration 882, loss = 0.04242214
Iteration 883, loss = 0.04237011
Iteration 884, loss = 0.04231843
Iteration 885, loss = 0.04227087
Iteration 886, loss = 0.04221438
Iteration 887, loss = 0.04216119
Iteration 888, loss = 0.04210905
Iteration 889, loss = 0.04205764
Iteration 890, loss = 0.04200593
Iteration 891, loss = 0.04195674
Iteration 892, loss = 0.04190790
Iteration 893, loss = 0.04185735
Iteration 894, loss = 0.04180803
Iteration 895, loss = 0.04175785
Iteration 896, loss = 0.04171181
Iteration 897, loss = 0.04165785
Iteration 898, loss = 0.04160705
Iteration 899, loss = 0.04155606
Iteration 900, loss = 0.04150755
Iteration 901, loss = 0.04145458
Iteration 902, loss = 0.04140595
Iteration 903, loss = 0.04135414
Iteration 904, loss = 0.04130497
Iteration 905, loss = 0.04125422
Iteration 906, loss = 0.04120176
Iteration 907, loss = 0.04115058
Iteration 908, loss = 0.04109797
Iteration 909, loss = 0.04104687
Iteration 910, loss = 0.04099605
Iteration 911, loss = 0.04094861
Iteration 912, loss = 0.04089675
Iteration 913, loss = 0.04085506
Iteration 914, loss = 0.04079744
Iteration 915, loss = 0.04075057
Iteration 916, loss = 0.04070133
Iteration 917, loss = 0.04065606
Iteration 918, loss = 0.04060660
Iteration 919, loss = 0.04055914
Iteration 920, loss = 0.04051153
Iteration 921, loss = 0.04046176
Iteration 922, loss = 0.04041559
Iteration 923, loss = 0.04036777
Iteration 924, loss = 0.04032013
Iteration 925, loss = 0.04027280
Iteration 926, loss = 0.04022764
Iteration 927, loss = 0.04018051
Iteration 928, loss = 0.04013271
Iteration 929, loss = 0.04008703
Iteration 930, loss = 0.04004011
Iteration 931, loss = 0.03999649
Iteration 932, loss = 0.03994693
Iteration 933, loss = 0.03989834
Iteration 934, loss = 0.03985124
Iteration 935, loss = 0.03980644
Iteration 936, loss = 0.03976190
Iteration 937, loss = 0.03971513
Iteration 938, loss = 0.03967067
Iteration 939, loss = 0.03962419
Iteration 940, loss = 0.03957764
Iteration 941, loss = 0.03953082
Iteration 942, loss = 0.03948236
Iteration 943, loss = 0.03943553
Iteration 944, loss = 0.03938847
Iteration 945, loss = 0.03933917
Iteration 946, loss = 0.03929532
Iteration 947, loss = 0.03924863
Iteration 948, loss = 0.03919895
Iteration 949, loss = 0.03915480
Iteration 950, loss = 0.03911051
Iteration 951, loss = 0.03906366
Iteration 952, loss = 0.03901587
Iteration 953, loss = 0.03897811
Iteration 954, loss = 0.03892769
Iteration 955, loss = 0.03888156
Iteration 956, loss = 0.03883693
Iteration 957, loss = 0.03879034
Iteration 958, loss = 0.03874687
Iteration 959, loss = 0.03870054
Iteration 960, loss = 0.03865688
Iteration 961, loss = 0.03861336
Iteration 962, loss = 0.03856629
Iteration 963, loss = 0.03852385
Iteration 964, loss = 0.03847801
Iteration 965, loss = 0.03843365
Iteration 966, loss = 0.03838869
Iteration 967, loss = 0.03834570
Iteration 968, loss = 0.03830146
Iteration 969, loss = 0.03825824
Iteration 970, loss = 0.03821542
Iteration 971, loss = 0.03817383
Iteration 972, loss = 0.03813358
Iteration 973, loss = 0.03808886
Iteration 974, loss = 0.03804624
Iteration 975, loss = 0.03800415
Iteration 976, loss = 0.03796002
Iteration 977, loss = 0.03792182
Iteration 978, loss = 0.03787908
Iteration 979, loss = 0.03783909
Iteration 980, loss = 0.03779855
Iteration 981, loss = 0.03775933
Iteration 982, loss = 0.03772073
Iteration 983, loss = 0.03768127
Iteration 984, loss = 0.03764364
Iteration 985, loss = 0.03760584
Iteration 986, loss = 0.03756108
Iteration 987, loss = 0.03751935
Iteration 988, loss = 0.03747802
Iteration 989, loss = 0.03744011
Iteration 990, loss = 0.03739749
Iteration 991, loss = 0.03735610
Iteration 992, loss = 0.03731470
Iteration 993, loss = 0.03727192
Iteration 994, loss = 0.03723293
Iteration 995, loss = 0.03718992
Iteration 996, loss = 0.03715011
Iteration 997, loss = 0.03711076
Iteration 998, loss = 0.03706686
Iteration 999, loss = 0.03702748
Iteration 1000, loss = 0.03698918
Iteration 1001, loss = 0.03694713
Iteration 1002, loss = 0.03690855
Iteration 1003, loss = 0.03686809
Iteration 1004, loss = 0.03682477
Iteration 1005, loss = 0.03678809
Iteration 1006, loss = 0.03674816
Iteration 1007, loss = 0.03670318
Iteration 1008, loss = 0.03666914
Iteration 1009, loss = 0.03662197
Iteration 1010, loss = 0.03658508
Iteration 1011, loss = 0.03654032
Iteration 1012, loss = 0.03650019
Iteration 1013, loss = 0.03646037
Iteration 1014, loss = 0.03641982
Iteration 1015, loss = 0.03638025
Iteration 1016, loss = 0.03634116
Iteration 1017, loss = 0.03630104
Iteration 1018, loss = 0.03626404
Iteration 1019, loss = 0.03622141
Iteration 1020, loss = 0.03618031
Iteration 1021, loss = 0.03614053
Iteration 1022, loss = 0.03610010
Iteration 1023, loss = 0.03605599
Iteration 1024, loss = 0.03601885
Iteration 1025, loss = 0.03597778
Iteration 1026, loss = 0.03593553
Iteration 1027, loss = 0.03589783
Iteration 1028, loss = 0.03585810
Iteration 1029, loss = 0.03581542
Iteration 1030, loss = 0.03577663
Iteration 1031, loss = 0.03573940
Iteration 1032, loss = 0.03570148
Iteration 1033, loss = 0.03566161
Iteration 1034, loss = 0.03562462
Iteration 1035, loss = 0.03558790
Iteration 1036, loss = 0.03555008
Iteration 1037, loss = 0.03551703
Iteration 1038, loss = 0.03547589
Iteration 1039, loss = 0.03543853
Iteration 1040, loss = 0.03539962
Iteration 1041, loss = 0.03536285
Iteration 1042, loss = 0.03532377
Iteration 1043, loss = 0.03528569
Iteration 1044, loss = 0.03524901
Iteration 1045, loss = 0.03521266
Iteration 1046, loss = 0.03517943
Iteration 1047, loss = 0.03514062
Iteration 1048, loss = 0.03510542
Iteration 1049, loss = 0.03506773
Iteration 1050, loss = 0.03503291
Iteration 1051, loss = 0.03499734
Iteration 1052, loss = 0.03495961
Iteration 1053, loss = 0.03492496
Iteration 1054, loss = 0.03488736
Iteration 1055, loss = 0.03485242
Iteration 1056, loss = 0.03481566
Iteration 1057, loss = 0.03478183
Iteration 1058, loss = 0.03474478
Iteration 1059, loss = 0.03471115
Iteration 1060, loss = 0.03467545
Iteration 1061, loss = 0.03464054
Iteration 1062, loss = 0.03460290
Iteration 1063, loss = 0.03457013
Iteration 1064, loss = 0.03453343
Iteration 1065, loss = 0.03449995
Iteration 1066, loss = 0.03446608
Iteration 1067, loss = 0.03443271
Iteration 1068, loss = 0.03440300
Iteration 1069, loss = 0.03436494
Iteration 1070, loss = 0.03432931
Iteration 1071, loss = 0.03429731
Iteration 1072, loss = 0.03425141
Iteration 1073, loss = 0.03421582
Iteration 1074, loss = 0.03417872
Iteration 1075, loss = 0.03413903
Iteration 1076, loss = 0.03410758
Iteration 1077, loss = 0.03406944
Iteration 1078, loss = 0.03403021
Iteration 1079, loss = 0.03399774
Iteration 1080, loss = 0.03395829
Iteration 1081, loss = 0.03392623
Iteration 1082, loss = 0.03388918
Iteration 1083, loss = 0.03385494
Iteration 1084, loss = 0.03381845
Iteration 1085, loss = 0.03378350
Iteration 1086, loss = 0.03374610
Iteration 1087, loss = 0.03371066
Iteration 1088, loss = 0.03367728
Iteration 1089, loss = 0.03364485
Iteration 1090, loss = 0.03360795
Iteration 1091, loss = 0.03357368
Iteration 1092, loss = 0.03354192
Iteration 1093, loss = 0.03350607
Iteration 1094, loss = 0.03347616
Iteration 1095, loss = 0.03344088
Iteration 1096, loss = 0.03340926
Iteration 1097, loss = 0.03337273
Iteration 1098, loss = 0.03333904
Iteration 1099, loss = 0.03330452
Iteration 1100, loss = 0.03327263
Iteration 1101, loss = 0.03323764
Iteration 1102, loss = 0.03320050
Iteration 1103, loss = 0.03316572
Iteration 1104, loss = 0.03313192
Iteration 1105, loss = 0.03309677
Iteration 1106, loss = 0.03306326
Iteration 1107, loss = 0.03302787
Iteration 1108, loss = 0.03299504
Iteration 1109, loss = 0.03296159
Iteration 1110, loss = 0.03293087
Iteration 1111, loss = 0.03289537
Iteration 1112, loss = 0.03286124
Iteration 1113, loss = 0.03282948
Iteration 1114, loss = 0.03279614
Iteration 1115, loss = 0.03276210
Iteration 1116, loss = 0.03272760
Iteration 1117, loss = 0.03269421
Iteration 1118, loss = 0.03266201
Iteration 1119, loss = 0.03262853
Iteration 1120, loss = 0.03259711
Iteration 1121, loss = 0.03256141
Iteration 1122, loss = 0.03253426
Iteration 1123, loss = 0.03250225
Iteration 1124, loss = 0.03246795
Iteration 1125, loss = 0.03243540
Iteration 1126, loss = 0.03240402
Iteration 1127, loss = 0.03237173
Iteration 1128, loss = 0.03234027
Iteration 1129, loss = 0.03231192
Iteration 1130, loss = 0.03227985
Iteration 1131, loss = 0.03224482
Iteration 1132, loss = 0.03220930
Iteration 1133, loss = 0.03217538
Iteration 1134, loss = 0.03214696
Iteration 1135, loss = 0.03211240
Iteration 1136, loss = 0.03207560
Iteration 1137, loss = 0.03204280
Iteration 1138, loss = 0.03200922
Iteration 1139, loss = 0.03197517
Iteration 1140, loss = 0.03194471
Iteration 1141, loss = 0.03191223
Iteration 1142, loss = 0.03187995
Iteration 1143, loss = 0.03185160
Iteration 1144, loss = 0.03181827
Iteration 1145, loss = 0.03178763
Iteration 1146, loss = 0.03175489
Iteration 1147, loss = 0.03172378
Iteration 1148, loss = 0.03169257
Iteration 1149, loss = 0.03166276
Iteration 1150, loss = 0.03163101
Iteration 1151, loss = 0.03160129
Iteration 1152, loss = 0.03157414
Iteration 1153, loss = 0.03154510
Iteration 1154, loss = 0.03151563
Iteration 1155, loss = 0.03148647
Iteration 1156, loss = 0.03145572
Iteration 1157, loss = 0.03142654
Iteration 1158, loss = 0.03139540
Iteration 1159, loss = 0.03136551
Iteration 1160, loss = 0.03133460
Iteration 1161, loss = 0.03130522
Iteration 1162, loss = 0.03127440
Iteration 1163, loss = 0.03124545
Iteration 1164, loss = 0.03121850
Iteration 1165, loss = 0.03119149
Iteration 1166, loss = 0.03116556
Iteration 1167, loss = 0.03113630
Iteration 1168, loss = 0.03110846
Iteration 1169, loss = 0.03107845
Iteration 1170, loss = 0.03104902
Iteration 1171, loss = 0.03102351
Iteration 1172, loss = 0.03099159
Iteration 1173, loss = 0.03096283
Iteration 1174, loss = 0.03093812
Iteration 1175, loss = 0.03090894
Iteration 1176, loss = 0.03088073
Iteration 1177, loss = 0.03085511
Iteration 1178, loss = 0.03083306
Iteration 1179, loss = 0.03080315
Iteration 1180, loss = 0.03077868
Iteration 1181, loss = 0.03074628
Iteration 1182, loss = 0.03071682
Iteration 1183, loss = 0.03068450
Iteration 1184, loss = 0.03065762
Iteration 1185, loss = 0.03062681
Iteration 1186, loss = 0.03059616
Iteration 1187, loss = 0.03056795
Iteration 1188, loss = 0.03053934
Iteration 1189, loss = 0.03051289
Iteration 1190, loss = 0.03048367
Iteration 1191, loss = 0.03045620
Iteration 1192, loss = 0.03042686
Iteration 1193, loss = 0.03039748
Iteration 1194, loss = 0.03036723
Iteration 1195, loss = 0.03034122
Iteration 1196, loss = 0.03030872
Iteration 1197, loss = 0.03028104
Iteration 1198, loss = 0.03024970
Iteration 1199, loss = 0.03022269
Iteration 1200, loss = 0.03019339
Iteration 1201, loss = 0.03016549
Iteration 1202, loss = 0.03013868
Iteration 1203, loss = 0.03011093
Iteration 1204, loss = 0.03008348
Iteration 1205, loss = 0.03005680
Iteration 1206, loss = 0.03003056
Iteration 1207, loss = 0.03000392
Iteration 1208, loss = 0.02997777
Iteration 1209, loss = 0.02995315
Iteration 1210, loss = 0.02992770
Iteration 1211, loss = 0.02990318
Iteration 1212, loss = 0.02987757
Iteration 1213, loss = 0.02985094
Iteration 1214, loss = 0.02982583
Iteration 1215, loss = 0.02980077
Iteration 1216, loss = 0.02977507
Iteration 1217, loss = 0.02974899
Iteration 1218, loss = 0.02972210
Iteration 1219, loss = 0.02969533
Iteration 1220, loss = 0.02966733
Iteration 1221, loss = 0.02964369
Iteration 1222, loss = 0.02961235
Iteration 1223, loss = 0.02958352
Iteration 1224, loss = 0.02955957
Iteration 1225, loss = 0.02953651
Iteration 1226, loss = 0.02950656
Iteration 1227, loss = 0.02947742
Iteration 1228, loss = 0.02945185
Iteration 1229, loss = 0.02942333
Iteration 1230, loss = 0.02939537
Iteration 1231, loss = 0.02936607
Iteration 1232, loss = 0.02933547
Iteration 1233, loss = 0.02930732
Iteration 1234, loss = 0.02928357
Iteration 1235, loss = 0.02925237
Iteration 1236, loss = 0.02922551
Iteration 1237, loss = 0.02919853
Iteration 1238, loss = 0.02917202
Iteration 1239, loss = 0.02914193
Iteration 1240, loss = 0.02911997
Iteration 1241, loss = 0.02908914
Iteration 1242, loss = 0.02906463
Iteration 1243, loss = 0.02903970
Iteration 1244, loss = 0.02901434
Iteration 1245, loss = 0.02898516
Iteration 1246, loss = 0.02895912
Iteration 1247, loss = 0.02893248
Iteration 1248, loss = 0.02890772
Iteration 1249, loss = 0.02888188
Iteration 1250, loss = 0.02885608
Iteration 1251, loss = 0.02882895
Iteration 1252, loss = 0.02880240
Iteration 1253, loss = 0.02877641
Iteration 1254, loss = 0.02875068
Iteration 1255, loss = 0.02872166
Iteration 1256, loss = 0.02869577
Iteration 1257, loss = 0.02866677
Iteration 1258, loss = 0.02864001
Iteration 1259, loss = 0.02861255
Iteration 1260, loss = 0.02858751
Iteration 1261, loss = 0.02856044
Iteration 1262, loss = 0.02853247
Iteration 1263, loss = 0.02850581
Iteration 1264, loss = 0.02848330
Iteration 1265, loss = 0.02845501
Iteration 1266, loss = 0.02842973
Iteration 1267, loss = 0.02840547
Iteration 1268, loss = 0.02838144
Iteration 1269, loss = 0.02835781
Iteration 1270, loss = 0.02832894
Iteration 1271, loss = 0.02830406
Iteration 1272, loss = 0.02827796
Iteration 1273, loss = 0.02825020
Iteration 1274, loss = 0.02822841
Iteration 1275, loss = 0.02819884
Iteration 1276, loss = 0.02817424
Iteration 1277, loss = 0.02814675
Iteration 1278, loss = 0.02812101
Iteration 1279, loss = 0.02809418
Iteration 1280, loss = 0.02806940
Iteration 1281, loss = 0.02804232
Iteration 1282, loss = 0.02801987
Iteration 1283, loss = 0.02799304
Iteration 1284, loss = 0.02796774
Iteration 1285, loss = 0.02794376
Iteration 1286, loss = 0.02792002
Iteration 1287, loss = 0.02789634
Iteration 1288, loss = 0.02787348
Iteration 1289, loss = 0.02784782
Iteration 1290, loss = 0.02782536
Iteration 1291, loss = 0.02780039
Iteration 1292, loss = 0.02777533
Iteration 1293, loss = 0.02775168
Iteration 1294, loss = 0.02772864
Iteration 1295, loss = 0.02770314
Iteration 1296, loss = 0.02767983
Iteration 1297, loss = 0.02765562
Iteration 1298, loss = 0.02763175
Iteration 1299, loss = 0.02760823
Iteration 1300, loss = 0.02758314
Iteration 1301, loss = 0.02756069
Iteration 1302, loss = 0.02753665
Iteration 1303, loss = 0.02751329
Iteration 1304, loss = 0.02748817
Iteration 1305, loss = 0.02746889
Iteration 1306, loss = 0.02744318
Iteration 1307, loss = 0.02742044
Iteration 1308, loss = 0.02739693
Iteration 1309, loss = 0.02737146
Iteration 1310, loss = 0.02734763
Iteration 1311, loss = 0.02731874
Iteration 1312, loss = 0.02729457
Iteration 1313, loss = 0.02726770
Iteration 1314, loss = 0.02724365
Iteration 1315, loss = 0.02722034
Iteration 1316, loss = 0.02719360
Iteration 1317, loss = 0.02716920
Iteration 1318, loss = 0.02714957
Iteration 1319, loss = 0.02712131
Iteration 1320, loss = 0.02709807
Iteration 1321, loss = 0.02707477
Iteration 1322, loss = 0.02705176
Iteration 1323, loss = 0.02702696
Iteration 1324, loss = 0.02700713
Iteration 1325, loss = 0.02698230
Iteration 1326, loss = 0.02695960
Iteration 1327, loss = 0.02693739
Iteration 1328, loss = 0.02691512
Iteration 1329, loss = 0.02689277
Iteration 1330, loss = 0.02687401
Iteration 1331, loss = 0.02684809
Iteration 1332, loss = 0.02682562
Iteration 1333, loss = 0.02680223
Iteration 1334, loss = 0.02678152
Iteration 1335, loss = 0.02675784
Iteration 1336, loss = 0.02673702
Iteration 1337, loss = 0.02671488
Iteration 1338, loss = 0.02669238
Iteration 1339, loss = 0.02667231
Iteration 1340, loss = 0.02664869
Iteration 1341, loss = 0.02662703
Iteration 1342, loss = 0.02660356
Iteration 1343, loss = 0.02658228
Iteration 1344, loss = 0.02655983
Iteration 1345, loss = 0.02653924
Iteration 1346, loss = 0.02651879
Iteration 1347, loss = 0.02649583
Iteration 1348, loss = 0.02647325
Iteration 1349, loss = 0.02645134
Iteration 1350, loss = 0.02642954
Iteration 1351, loss = 0.02640979
Iteration 1352, loss = 0.02638391
Iteration 1353, loss = 0.02635931
Iteration 1354, loss = 0.02633474
Iteration 1355, loss = 0.02631440
Iteration 1356, loss = 0.02629224
Iteration 1357, loss = 0.02627581
Iteration 1358, loss = 0.02625068
Iteration 1359, loss = 0.02622860
Iteration 1360, loss = 0.02620678
Iteration 1361, loss = 0.02618656
Iteration 1362, loss = 0.02616619
Iteration 1363, loss = 0.02614481
Iteration 1364, loss = 0.02612611
Iteration 1365, loss = 0.02610374
Iteration 1366, loss = 0.02608327
Iteration 1367, loss = 0.02606344
Iteration 1368, loss = 0.02604357
Iteration 1369, loss = 0.02602551
Iteration 1370, loss = 0.02600541
Iteration 1371, loss = 0.02598836
Iteration 1372, loss = 0.02596766
Iteration 1373, loss = 0.02594961
Iteration 1374, loss = 0.02593221
Iteration 1375, loss = 0.02591209
Iteration 1376, loss = 0.02589323
Iteration 1377, loss = 0.02587704
Iteration 1378, loss = 0.02585415
Iteration 1379, loss = 0.02583370
Iteration 1380, loss = 0.02581559
Iteration 1381, loss = 0.02579520
Iteration 1382, loss = 0.02577497
Iteration 1383, loss = 0.02575535
Iteration 1384, loss = 0.02573683
Iteration 1385, loss = 0.02571585
Iteration 1386, loss = 0.02569655
Iteration 1387, loss = 0.02567733
Iteration 1388, loss = 0.02565951
Iteration 1389, loss = 0.02563433
Iteration 1390, loss = 0.02561630
Iteration 1391, loss = 0.02559382
Iteration 1392, loss = 0.02557359
Iteration 1393, loss = 0.02555473
Iteration 1394, loss = 0.02553396
Iteration 1395, loss = 0.02551776
Iteration 1396, loss = 0.02549706
Iteration 1397, loss = 0.02547712
Iteration 1398, loss = 0.02545815
Iteration 1399, loss = 0.02543683
Iteration 1400, loss = 0.02541905
Iteration 1401, loss = 0.02539774
Iteration 1402, loss = 0.02537818
Iteration 1403, loss = 0.02535849
Iteration 1404, loss = 0.02533936
Iteration 1405, loss = 0.02532009
Iteration 1406, loss = 0.02530063
Iteration 1407, loss = 0.02528320
Iteration 1408, loss = 0.02525962
Iteration 1409, loss = 0.02524062
Iteration 1410, loss = 0.02521643
Iteration 1411, loss = 0.02519907
Iteration 1412, loss = 0.02517778
Iteration 1413, loss = 0.02515775
Iteration 1414, loss = 0.02513790
Iteration 1415, loss = 0.02511813
Iteration 1416, loss = 0.02509919
Iteration 1417, loss = 0.02508253
Iteration 1418, loss = 0.02506282
Iteration 1419, loss = 0.02504394
Iteration 1420, loss = 0.02502176
Iteration 1421, loss = 0.02500380
Iteration 1422, loss = 0.02498319
Iteration 1423, loss = 0.02496222
Iteration 1424, loss = 0.02494095
Iteration 1425, loss = 0.02492216
Iteration 1426, loss = 0.02490402
Iteration 1427, loss = 0.02488265
Iteration 1428, loss = 0.02486486
Iteration 1429, loss = 0.02484463
Iteration 1430, loss = 0.02482446
Iteration 1431, loss = 0.02480539
Iteration 1432, loss = 0.02478777
Iteration 1433, loss = 0.02476875
Iteration 1434, loss = 0.02474880
Iteration 1435, loss = 0.02472952
Iteration 1436, loss = 0.02471053
Iteration 1437, loss = 0.02469221
Iteration 1438, loss = 0.02467192
Iteration 1439, loss = 0.02465497
Iteration 1440, loss = 0.02463347
Iteration 1441, loss = 0.02461374
Iteration 1442, loss = 0.02459491
Iteration 1443, loss = 0.02457691
Iteration 1444, loss = 0.02455718
Iteration 1445, loss = 0.02453854
Iteration 1446, loss = 0.02452052
Iteration 1447, loss = 0.02450250
Iteration 1448, loss = 0.02448346
Iteration 1449, loss = 0.02446794
Iteration 1450, loss = 0.02444904
Iteration 1451, loss = 0.02443133
Iteration 1452, loss = 0.02441438
Iteration 1453, loss = 0.02439736
Iteration 1454, loss = 0.02437754
Iteration 1455, loss = 0.02435774
Iteration 1456, loss = 0.02434097
Iteration 1457, loss = 0.02432259
Iteration 1458, loss = 0.02430295
Iteration 1459, loss = 0.02429142
Iteration 1460, loss = 0.02426870
Iteration 1461, loss = 0.02424963
Iteration 1462, loss = 0.02423066
Iteration 1463, loss = 0.02421293
Iteration 1464, loss = 0.02419489
Iteration 1465, loss = 0.02417594
Iteration 1466, loss = 0.02415893
Iteration 1467, loss = 0.02414357
Iteration 1468, loss = 0.02412459
Iteration 1469, loss = 0.02410756
Iteration 1470, loss = 0.02408817
Iteration 1471, loss = 0.02407054
Iteration 1472, loss = 0.02405288
Iteration 1473, loss = 0.02403446
Iteration 1474, loss = 0.02401723
Iteration 1475, loss = 0.02399789
Iteration 1476, loss = 0.02398056
Iteration 1477, loss = 0.02396160
Iteration 1478, loss = 0.02394326
Iteration 1479, loss = 0.02392340
Iteration 1480, loss = 0.02390690
Iteration 1481, loss = 0.02388684
Iteration 1482, loss = 0.02387090
Iteration 1483, loss = 0.02385237
Iteration 1484, loss = 0.02383494
Iteration 1485, loss = 0.02381690
Iteration 1486, loss = 0.02379847
Iteration 1487, loss = 0.02378120
Iteration 1488, loss = 0.02376302
Iteration 1489, loss = 0.02374489
Iteration 1490, loss = 0.02372961
Iteration 1491, loss = 0.02370954
Iteration 1492, loss = 0.02369004
Iteration 1493, loss = 0.02367192
Iteration 1494, loss = 0.02365281
Iteration 1495, loss = 0.02363556
Iteration 1496, loss = 0.02361444
Iteration 1497, loss = 0.02359631
Iteration 1498, loss = 0.02357910
Iteration 1499, loss = 0.02356040
Iteration 1500, loss = 0.02354193
Iteration 1501, loss = 0.02352516
Iteration 1502, loss = 0.02350736
Iteration 1503, loss = 0.02349086
Iteration 1504, loss = 0.02347363
Iteration 1505, loss = 0.02345726
Iteration 1506, loss = 0.02344108
Iteration 1507, loss = 0.02342397
Iteration 1508, loss = 0.02340681
Iteration 1509, loss = 0.02339009
Iteration 1510, loss = 0.02337603
Iteration 1511, loss = 0.02335707
Iteration 1512, loss = 0.02334102
Iteration 1513, loss = 0.02332368
Iteration 1514, loss = 0.02330711
Iteration 1515, loss = 0.02329058
Iteration 1516, loss = 0.02327239
Iteration 1517, loss = 0.02325420
Iteration 1518, loss = 0.02323614
Iteration 1519, loss = 0.02321964
Iteration 1520, loss = 0.02320246
Iteration 1521, loss = 0.02318798
Iteration 1522, loss = 0.02317033
Iteration 1523, loss = 0.02315703
Iteration 1524, loss = 0.02313865
Iteration 1525, loss = 0.02312193
Iteration 1526, loss = 0.02310638
Iteration 1527, loss = 0.02308768
Iteration 1528, loss = 0.02307185
Iteration 1529, loss = 0.02305450
Iteration 1530, loss = 0.02303757
Iteration 1531, loss = 0.02301931
Iteration 1532, loss = 0.02300327
Iteration 1533, loss = 0.02298654
Iteration 1534, loss = 0.02296911
Iteration 1535, loss = 0.02295151
Iteration 1536, loss = 0.02293424
Iteration 1537, loss = 0.02291688
Iteration 1538, loss = 0.02290241
Iteration 1539, loss = 0.02288391
Iteration 1540, loss = 0.02286672
Iteration 1541, loss = 0.02284846
Iteration 1542, loss = 0.02283183
Iteration 1543, loss = 0.02281734
Iteration 1544, loss = 0.02280134
Iteration 1545, loss = 0.02278344
Iteration 1546, loss = 0.02276575
Iteration 1547, loss = 0.02274892
Iteration 1548, loss = 0.02273298
Iteration 1549, loss = 0.02271477
Iteration 1550, loss = 0.02269859
Iteration 1551, loss = 0.02268123
Iteration 1552, loss = 0.02266320
Iteration 1553, loss = 0.02264789
Iteration 1554, loss = 0.02262942
Iteration 1555, loss = 0.02261364
Iteration 1556, loss = 0.02259698
Iteration 1557, loss = 0.02257975
Iteration 1558, loss = 0.02256415
Iteration 1559, loss = 0.02254768
Iteration 1560, loss = 0.02253213
Iteration 1561, loss = 0.02251537
Iteration 1562, loss = 0.02249810
Iteration 1563, loss = 0.02248200
Iteration 1564, loss = 0.02246507
Iteration 1565, loss = 0.02244715
Iteration 1566, loss = 0.02243461
Iteration 1567, loss = 0.02241501
Iteration 1568, loss = 0.02239898
Iteration 1569, loss = 0.02238452
Iteration 1570, loss = 0.02236685
Iteration 1571, loss = 0.02235140
Iteration 1572, loss = 0.02233342
Iteration 1573, loss = 0.02231688
Iteration 1574, loss = 0.02229968
Iteration 1575, loss = 0.02228431
Iteration 1576, loss = 0.02226706
Iteration 1577, loss = 0.02224910
Iteration 1578, loss = 0.02223270
Iteration 1579, loss = 0.02221612
Iteration 1580, loss = 0.02219971
Iteration 1581, loss = 0.02218422
Iteration 1582, loss = 0.02216867
Iteration 1583, loss = 0.02215534
Iteration 1584, loss = 0.02213901
Iteration 1585, loss = 0.02212442
Iteration 1586, loss = 0.02210914
Iteration 1587, loss = 0.02208982
Iteration 1588, loss = 0.02207753
Iteration 1589, loss = 0.02205902
Iteration 1590, loss = 0.02204253
Iteration 1591, loss = 0.02202624
Iteration 1592, loss = 0.02201231
Iteration 1593, loss = 0.02199818
Iteration 1594, loss = 0.02198012
Iteration 1595, loss = 0.02196367
Iteration 1596, loss = 0.02194736
Iteration 1597, loss = 0.02193309
Iteration 1598, loss = 0.02191558
Iteration 1599, loss = 0.02189920
Iteration 1600, loss = 0.02188374
Iteration 1601, loss = 0.02186620
Iteration 1602, loss = 0.02185029
Iteration 1603, loss = 0.02183493
Iteration 1604, loss = 0.02181804
Iteration 1605, loss = 0.02180298
Iteration 1606, loss = 0.02178607
Iteration 1607, loss = 0.02177011
Iteration 1608, loss = 0.02175334
Iteration 1609, loss = 0.02174288
Iteration 1610, loss = 0.02172462
Iteration 1611, loss = 0.02170767
Iteration 1612, loss = 0.02169386
Iteration 1613, loss = 0.02167711
Iteration 1614, loss = 0.02166228
Iteration 1615, loss = 0.02164652
Iteration 1616, loss = 0.02163010
Iteration 1617, loss = 0.02161451
Iteration 1618, loss = 0.02159955
Iteration 1619, loss = 0.02158402
Iteration 1620, loss = 0.02156916
Iteration 1621, loss = 0.02155155
Iteration 1622, loss = 0.02153826
Iteration 1623, loss = 0.02152117
Iteration 1624, loss = 0.02150558
Iteration 1625, loss = 0.02148951
Iteration 1626, loss = 0.02147461
Iteration 1627, loss = 0.02145989
Iteration 1628, loss = 0.02144477
Iteration 1629, loss = 0.02143002
Iteration 1630, loss = 0.02141503
Iteration 1631, loss = 0.02139967
Iteration 1632, loss = 0.02138662
Iteration 1633, loss = 0.02137351
Iteration 1634, loss = 0.02135680
Iteration 1635, loss = 0.02134053
Iteration 1636, loss = 0.02132610
Iteration 1637, loss = 0.02131188
Iteration 1638, loss = 0.02129436
Iteration 1639, loss = 0.02127938
Iteration 1640, loss = 0.02126837
Iteration 1641, loss = 0.02125026
Iteration 1642, loss = 0.02123932
Iteration 1643, loss = 0.02122256
Iteration 1644, loss = 0.02120689
Iteration 1645, loss = 0.02119302
Iteration 1646, loss = 0.02117711
Iteration 1647, loss = 0.02116170
Iteration 1648, loss = 0.02114769
Iteration 1649, loss = 0.02113183
Iteration 1650, loss = 0.02111816
Iteration 1651, loss = 0.02110434
Iteration 1652, loss = 0.02108944
Iteration 1653, loss = 0.02107597
Iteration 1654, loss = 0.02106097
Iteration 1655, loss = 0.02104684
Iteration 1656, loss = 0.02103487
Iteration 1657, loss = 0.02101977
Iteration 1658, loss = 0.02100702
Iteration 1659, loss = 0.02099274
Iteration 1660, loss = 0.02097747
Iteration 1661, loss = 0.02096259
Iteration 1662, loss = 0.02094764
Iteration 1663, loss = 0.02093346
Iteration 1664, loss = 0.02091825
Iteration 1665, loss = 0.02090395
Iteration 1666, loss = 0.02089010
Iteration 1667, loss = 0.02087458
Iteration 1668, loss = 0.02086101
Iteration 1669, loss = 0.02084758
Iteration 1670, loss = 0.02083227
Iteration 1671, loss = 0.02081985
Iteration 1672, loss = 0.02080430
Iteration 1673, loss = 0.02079072
Iteration 1674, loss = 0.02077809
Iteration 1675, loss = 0.02076273
Iteration 1676, loss = 0.02074766
Iteration 1677, loss = 0.02073274
Iteration 1678, loss = 0.02071929
Iteration 1679, loss = 0.02070537
Iteration 1680, loss = 0.02069602
Iteration 1681, loss = 0.02067963
Iteration 1682, loss = 0.02066668
Iteration 1683, loss = 0.02065212
Iteration 1684, loss = 0.02063842
Iteration 1685, loss = 0.02062658
Iteration 1686, loss = 0.02061196
Iteration 1687, loss = 0.02059796
Iteration 1688, loss = 0.02058440
Iteration 1689, loss = 0.02057108
Iteration 1690, loss = 0.02055628
Iteration 1691, loss = 0.02054445
Iteration 1692, loss = 0.02053103
Iteration 1693, loss = 0.02051582
Iteration 1694, loss = 0.02050136
Iteration 1695, loss = 0.02048819
Iteration 1696, loss = 0.02047871
Iteration 1697, loss = 0.02046290
Iteration 1698, loss = 0.02044866
Iteration 1699, loss = 0.02043456
Iteration 1700, loss = 0.02041991
Iteration 1701, loss = 0.02040692
Iteration 1702, loss = 0.02039347
Iteration 1703, loss = 0.02038096
Iteration 1704, loss = 0.02036804
Iteration 1705, loss = 0.02035308
Iteration 1706, loss = 0.02034104
Iteration 1707, loss = 0.02032716
Iteration 1708, loss = 0.02031204
Iteration 1709, loss = 0.02029894
Iteration 1710, loss = 0.02028439
Iteration 1711, loss = 0.02027190
Iteration 1712, loss = 0.02025993
Iteration 1713, loss = 0.02024438
Iteration 1714, loss = 0.02023061
Iteration 1715, loss = 0.02021592
Iteration 1716, loss = 0.02020244
Iteration 1717, loss = 0.02019244
Iteration 1718, loss = 0.02017598
Iteration 1719, loss = 0.02016101
Iteration 1720, loss = 0.02014616
Iteration 1721, loss = 0.02013237
Iteration 1722, loss = 0.02011790
Iteration 1723, loss = 0.02010850
Iteration 1724, loss = 0.02009153
Iteration 1725, loss = 0.02007820
Iteration 1726, loss = 0.02006500
Iteration 1727, loss = 0.02005229
Iteration 1728, loss = 0.02003938
Iteration 1729, loss = 0.02002584
Iteration 1730, loss = 0.02001158
Iteration 1731, loss = 0.02000168
Iteration 1732, loss = 0.01998683
Iteration 1733, loss = 0.01997301
Iteration 1734, loss = 0.01995931
Iteration 1735, loss = 0.01994547
Iteration 1736, loss = 0.01993341
Iteration 1737, loss = 0.01991985
Iteration 1738, loss = 0.01990725
Iteration 1739, loss = 0.01989309
Iteration 1740, loss = 0.01987968
Iteration 1741, loss = 0.01986734
Iteration 1742, loss = 0.01985271
Iteration 1743, loss = 0.01983937
Iteration 1744, loss = 0.01982634
Iteration 1745, loss = 0.01981659
Iteration 1746, loss = 0.01980145
Iteration 1747, loss = 0.01978811
Iteration 1748, loss = 0.01977398
Iteration 1749, loss = 0.01976099
Iteration 1750, loss = 0.01974798
Iteration 1751, loss = 0.01973339
Iteration 1752, loss = 0.01972378
Iteration 1753, loss = 0.01970807
Iteration 1754, loss = 0.01969583
Iteration 1755, loss = 0.01968323
Iteration 1756, loss = 0.01967052
Iteration 1757, loss = 0.01965770
Iteration 1758, loss = 0.01964403
Iteration 1759, loss = 0.01963083
Iteration 1760, loss = 0.01961793
Iteration 1761, loss = 0.01960382
Iteration 1762, loss = 0.01959001
Iteration 1763, loss = 0.01957758
Iteration 1764, loss = 0.01956391
Iteration 1765, loss = 0.01955352
Iteration 1766, loss = 0.01954012
Iteration 1767, loss = 0.01952763
Iteration 1768, loss = 0.01951752
Iteration 1769, loss = 0.01950497
Iteration 1770, loss = 0.01949317
Iteration 1771, loss = 0.01948186
Iteration 1772, loss = 0.01946928
Iteration 1773, loss = 0.01945894
Iteration 1774, loss = 0.01944390
Iteration 1775, loss = 0.01943274
Iteration 1776, loss = 0.01942352
Iteration 1777, loss = 0.01940686
Iteration 1778, loss = 0.01939348
Iteration 1779, loss = 0.01938043
Iteration 1780, loss = 0.01936644
Iteration 1781, loss = 0.01935359
Iteration 1782, loss = 0.01934168
Iteration 1783, loss = 0.01932686
Iteration 1784, loss = 0.01931428
Iteration 1785, loss = 0.01930182
Iteration 1786, loss = 0.01928793
Iteration 1787, loss = 0.01927494
Iteration 1788, loss = 0.01926126
Iteration 1789, loss = 0.01924873
Iteration 1790, loss = 0.01923102
Iteration 1791, loss = 0.01921723
Iteration 1792, loss = 0.01920310
Iteration 1793, loss = 0.01918810
Iteration 1794, loss = 0.01917462
Iteration 1795, loss = 0.01916108
Iteration 1796, loss = 0.01914922
Iteration 1797, loss = 0.01913661
Iteration 1798, loss = 0.01912340
Iteration 1799, loss = 0.01911132
Iteration 1800, loss = 0.01909838
Iteration 1801, loss = 0.01908682
Iteration 1802, loss = 0.01907484
Iteration 1803, loss = 0.01906160
Iteration 1804, loss = 0.01904914
Iteration 1805, loss = 0.01904001
Iteration 1806, loss = 0.01902340
Iteration 1807, loss = 0.01901153
Iteration 1808, loss = 0.01899749
Iteration 1809, loss = 0.01898530
Iteration 1810, loss = 0.01897572
Iteration 1811, loss = 0.01895902
Iteration 1812, loss = 0.01894752
Iteration 1813, loss = 0.01893724
Iteration 1814, loss = 0.01892350
Iteration 1815, loss = 0.01891141
Iteration 1816, loss = 0.01889853
Iteration 1817, loss = 0.01888748
Iteration 1818, loss = 0.01887661
Iteration 1819, loss = 0.01886232
Iteration 1820, loss = 0.01884944
Iteration 1821, loss = 0.01883708
Iteration 1822, loss = 0.01882486
Iteration 1823, loss = 0.01881213
Iteration 1824, loss = 0.01879924
Iteration 1825, loss = 0.01878733
Iteration 1826, loss = 0.01877658
Iteration 1827, loss = 0.01876415
Iteration 1828, loss = 0.01875114
Iteration 1829, loss = 0.01874018
Iteration 1830, loss = 0.01872755
Iteration 1831, loss = 0.01871577
Iteration 1832, loss = 0.01870414
Iteration 1833, loss = 0.01869184
Iteration 1834, loss = 0.01867930
Iteration 1835, loss = 0.01866933
Iteration 1836, loss = 0.01865843
Iteration 1837, loss = 0.01864521
Iteration 1838, loss = 0.01863408
Iteration 1839, loss = 0.01862192
Iteration 1840, loss = 0.01860969
Iteration 1841, loss = 0.01859909
Iteration 1842, loss = 0.01858646
Iteration 1843, loss = 0.01857451
Iteration 1844, loss = 0.01856246
Iteration 1845, loss = 0.01855299
Iteration 1846, loss = 0.01854147
Iteration 1847, loss = 0.01852931
Iteration 1848, loss = 0.01851752
Iteration 1849, loss = 0.01850685
Iteration 1850, loss = 0.01849703
Iteration 1851, loss = 0.01848464
Iteration 1852, loss = 0.01847198
Iteration 1853, loss = 0.01845994
Iteration 1854, loss = 0.01844879
Iteration 1855, loss = 0.01844005
Iteration 1856, loss = 0.01842619
Iteration 1857, loss = 0.01841477
Iteration 1858, loss = 0.01840307
Iteration 1859, loss = 0.01839085
Iteration 1860, loss = 0.01837881
Iteration 1861, loss = 0.01836754
Iteration 1862, loss = 0.01835429
Iteration 1863, loss = 0.01834307
Iteration 1864, loss = 0.01833264
Iteration 1865, loss = 0.01831971
Iteration 1866, loss = 0.01830843
Iteration 1867, loss = 0.01829620
Iteration 1868, loss = 0.01828813
Iteration 1869, loss = 0.01827453
Iteration 1870, loss = 0.01826289
Iteration 1871, loss = 0.01825203
Iteration 1872, loss = 0.01824078
Iteration 1873, loss = 0.01822924
Iteration 1874, loss = 0.01821832
Iteration 1875, loss = 0.01820710
Iteration 1876, loss = 0.01819551
Iteration 1877, loss = 0.01818377
Iteration 1878, loss = 0.01817264
Iteration 1879, loss = 0.01816407
Iteration 1880, loss = 0.01815462
Iteration 1881, loss = 0.01814072
Iteration 1882, loss = 0.01812864
Iteration 1883, loss = 0.01811490
Iteration 1884, loss = 0.01810572
Iteration 1885, loss = 0.01809013
Iteration 1886, loss = 0.01807921
Iteration 1887, loss = 0.01806782
Iteration 1888, loss = 0.01805532
Iteration 1889, loss = 0.01804411
Iteration 1890, loss = 0.01803391
Iteration 1891, loss = 0.01802246
Iteration 1892, loss = 0.01800997
Iteration 1893, loss = 0.01799949
Iteration 1894, loss = 0.01798884
Iteration 1895, loss = 0.01797624
Iteration 1896, loss = 0.01796517
Iteration 1897, loss = 0.01795460
Iteration 1898, loss = 0.01794325
Iteration 1899, loss = 0.01793322
Iteration 1900, loss = 0.01791980
Iteration 1901, loss = 0.01790805
Iteration 1902, loss = 0.01789681
Iteration 1903, loss = 0.01788358
Iteration 1904, loss = 0.01787379
Iteration 1905, loss = 0.01786155
Iteration 1906, loss = 0.01784993
Iteration 1907, loss = 0.01783892
Iteration 1908, loss = 0.01782736
Iteration 1909, loss = 0.01781846
Iteration 1910, loss = 0.01780623
Iteration 1911, loss = 0.01779509
Iteration 1912, loss = 0.01778338
Iteration 1913, loss = 0.01777294
Iteration 1914, loss = 0.01776227
Iteration 1915, loss = 0.01775180
Iteration 1916, loss = 0.01774066
Iteration 1917, loss = 0.01773033
Iteration 1918, loss = 0.01771949
Iteration 1919, loss = 0.01770914
Iteration 1920, loss = 0.01769925
Iteration 1921, loss = 0.01768833
Iteration 1922, loss = 0.01767759
Iteration 1923, loss = 0.01766743
Iteration 1924, loss = 0.01765722
Iteration 1925, loss = 0.01764774
Iteration 1926, loss = 0.01763675
Iteration 1927, loss = 0.01762529
Iteration 1928, loss = 0.01761536
Iteration 1929, loss = 0.01760479
Iteration 1930, loss = 0.01759485
Iteration 1931, loss = 0.01758459
Iteration 1932, loss = 0.01757617
Iteration 1933, loss = 0.01756723
Iteration 1934, loss = 0.01755683
Iteration 1935, loss = 0.01754704
Iteration 1936, loss = 0.01753813
Iteration 1937, loss = 0.01752730
Iteration 1938, loss = 0.01751670
Iteration 1939, loss = 0.01750523
Iteration 1940, loss = 0.01749573
Iteration 1941, loss = 0.01748316
Iteration 1942, loss = 0.01747287
Iteration 1943, loss = 0.01746328
Iteration 1944, loss = 0.01745103
Iteration 1945, loss = 0.01743982
Iteration 1946, loss = 0.01742767
Iteration 1947, loss = 0.01741664
Iteration 1948, loss = 0.01740644
Iteration 1949, loss = 0.01739410
Iteration 1950, loss = 0.01738343
Iteration 1951, loss = 0.01737272
Iteration 1952, loss = 0.01736196
Iteration 1953, loss = 0.01735165
Iteration 1954, loss = 0.01734130
Iteration 1955, loss = 0.01733094
Iteration 1956, loss = 0.01732150
Iteration 1957, loss = 0.01731140
Iteration 1958, loss = 0.01730061
Iteration 1959, loss = 0.01729104
Iteration 1960, loss = 0.01728158
Iteration 1961, loss = 0.01727188
Iteration 1962, loss = 0.01726212
Iteration 1963, loss = 0.01725315
Iteration 1964, loss = 0.01724404
Iteration 1965, loss = 0.01723235
Iteration 1966, loss = 0.01722303
Iteration 1967, loss = 0.01721290
Iteration 1968, loss = 0.01720151
Iteration 1969, loss = 0.01719316
Iteration 1970, loss = 0.01718039
Iteration 1971, loss = 0.01716984
Iteration 1972, loss = 0.01716010
Iteration 1973, loss = 0.01715263
Iteration 1974, loss = 0.01714046
Iteration 1975, loss = 0.01712985
Iteration 1976, loss = 0.01712149
Iteration 1977, loss = 0.01711152
Iteration 1978, loss = 0.01710131
Iteration 1979, loss = 0.01709193
Iteration 1980, loss = 0.01708334
Iteration 1981, loss = 0.01707144
Iteration 1982, loss = 0.01706299
Iteration 1983, loss = 0.01705260
Iteration 1984, loss = 0.01704164
Iteration 1985, loss = 0.01703163
Iteration 1986, loss = 0.01702301
Iteration 1987, loss = 0.01701269
Iteration 1988, loss = 0.01700289
Iteration 1989, loss = 0.01699644
Iteration 1990, loss = 0.01698357
Iteration 1991, loss = 0.01697347
Iteration 1992, loss = 0.01696374
Iteration 1993, loss = 0.01695456
Iteration 1994, loss = 0.01694518
Iteration 1995, loss = 0.01693468
Iteration 1996, loss = 0.01692505
Iteration 1997, loss = 0.01691618
Iteration 1998, loss = 0.01690660
Iteration 1999, loss = 0.01689769
Iteration 2000, loss = 0.01688762
Iteration 2001, loss = 0.01687966
Iteration 2002, loss = 0.01687355
Iteration 2003, loss = 0.01686115
Iteration 2004, loss = 0.01685229
Iteration 2005, loss = 0.01684259
Iteration 2006, loss = 0.01683274
Iteration 2007, loss = 0.01682298
Iteration 2008, loss = 0.01681247
Iteration 2009, loss = 0.01680295
Iteration 2010, loss = 0.01679352
Iteration 2011, loss = 0.01678387
Iteration 2012, loss = 0.01677392
Iteration 2013, loss = 0.01676549
Iteration 2014, loss = 0.01675604
Iteration 2015, loss = 0.01674723
Iteration 2016, loss = 0.01673975
Iteration 2017, loss = 0.01672816
Iteration 2018, loss = 0.01671665
Iteration 2019, loss = 0.01670618
Iteration 2020, loss = 0.01669561
Iteration 2021, loss = 0.01668417
Iteration 2022, loss = 0.01667561
Iteration 2023, loss = 0.01666703
Iteration 2024, loss = 0.01665711
Iteration 2025, loss = 0.01664655
Iteration 2026, loss = 0.01663931
Iteration 2027, loss = 0.01663041
Iteration 2028, loss = 0.01662104
Iteration 2029, loss = 0.01661138
Iteration 2030, loss = 0.01660128
Iteration 2031, loss = 0.01659302
Iteration 2032, loss = 0.01658222
Iteration 2033, loss = 0.01657170
Iteration 2034, loss = 0.01656280
Iteration 2035, loss = 0.01655290
Iteration 2036, loss = 0.01654280
Iteration 2037, loss = 0.01653281
Iteration 2038, loss = 0.01652385
Iteration 2039, loss = 0.01651575
Iteration 2040, loss = 0.01650510
Iteration 2041, loss = 0.01649523
Iteration 2042, loss = 0.01648462
Iteration 2043, loss = 0.01647467
Iteration 2044, loss = 0.01646327
Iteration 2045, loss = 0.01645342
Iteration 2046, loss = 0.01644162
Iteration 2047, loss = 0.01643291
Iteration 2048, loss = 0.01642111
Iteration 2049, loss = 0.01641196
Iteration 2050, loss = 0.01640074
Iteration 2051, loss = 0.01638997
Iteration 2052, loss = 0.01638383
Iteration 2053, loss = 0.01637135
Iteration 2054, loss = 0.01636285
Iteration 2055, loss = 0.01635211
Iteration 2056, loss = 0.01634404
Iteration 2057, loss = 0.01633292
Iteration 2058, loss = 0.01632476
Iteration 2059, loss = 0.01631439
Iteration 2060, loss = 0.01630456
Iteration 2061, loss = 0.01629450
Iteration 2062, loss = 0.01628555
Iteration 2063, loss = 0.01627490
Iteration 2064, loss = 0.01626513
Iteration 2065, loss = 0.01625429
Iteration 2066, loss = 0.01624443
Iteration 2067, loss = 0.01623399
Iteration 2068, loss = 0.01622455
Iteration 2069, loss = 0.01621528
Iteration 2070, loss = 0.01620544
Iteration 2071, loss = 0.01619670
Iteration 2072, loss = 0.01618817
Iteration 2073, loss = 0.01618017
Iteration 2074, loss = 0.01616900
Iteration 2075, loss = 0.01616106
Iteration 2076, loss = 0.01614995
Iteration 2077, loss = 0.01614088
Iteration 2078, loss = 0.01613125
Iteration 2079, loss = 0.01612122
Iteration 2080, loss = 0.01611262
Iteration 2081, loss = 0.01610488
Iteration 2082, loss = 0.01609481
Iteration 2083, loss = 0.01608674
Iteration 2084, loss = 0.01607607
Iteration 2085, loss = 0.01606584
Iteration 2086, loss = 0.01605712
Iteration 2087, loss = 0.01604790
Iteration 2088, loss = 0.01603810
Iteration 2089, loss = 0.01603069
Iteration 2090, loss = 0.01601966
Iteration 2091, loss = 0.01601254
Iteration 2092, loss = 0.01600248
Iteration 2093, loss = 0.01599389
Iteration 2094, loss = 0.01598474
Iteration 2095, loss = 0.01597656
Iteration 2096, loss = 0.01596816
Iteration 2097, loss = 0.01595813
Iteration 2098, loss = 0.01594966
Iteration 2099, loss = 0.01593921
Iteration 2100, loss = 0.01593168
Iteration 2101, loss = 0.01592125
Iteration 2102, loss = 0.01591109
Iteration 2103, loss = 0.01590258
Iteration 2104, loss = 0.01589372
Iteration 2105, loss = 0.01588580
Iteration 2106, loss = 0.01587712
Iteration 2107, loss = 0.01586743
Iteration 2108, loss = 0.01585934
Iteration 2109, loss = 0.01585061
Iteration 2110, loss = 0.01584073
Iteration 2111, loss = 0.01583196
Iteration 2112, loss = 0.01582254
Iteration 2113, loss = 0.01581397
Iteration 2114, loss = 0.01580504
Iteration 2115, loss = 0.01579646
Iteration 2116, loss = 0.01579208
Iteration 2117, loss = 0.01578036
Iteration 2118, loss = 0.01577123
Iteration 2119, loss = 0.01576273
Iteration 2120, loss = 0.01575285
Iteration 2121, loss = 0.01574486
Iteration 2122, loss = 0.01573534
Iteration 2123, loss = 0.01572563
Iteration 2124, loss = 0.01571899
Iteration 2125, loss = 0.01570987
Iteration 2126, loss = 0.01570288
Iteration 2127, loss = 0.01568924
Iteration 2128, loss = 0.01567885
Iteration 2129, loss = 0.01566755
Iteration 2130, loss = 0.01566038
Iteration 2131, loss = 0.01564956
Iteration 2132, loss = 0.01564050
Iteration 2133, loss = 0.01563120
Iteration 2134, loss = 0.01562043
Iteration 2135, loss = 0.01561484
Iteration 2136, loss = 0.01560402
Iteration 2137, loss = 0.01559453
Iteration 2138, loss = 0.01558576
Iteration 2139, loss = 0.01557690
Iteration 2140, loss = 0.01556698
Iteration 2141, loss = 0.01555771
Iteration 2142, loss = 0.01554700
Iteration 2143, loss = 0.01553989
Iteration 2144, loss = 0.01552852
Iteration 2145, loss = 0.01552025
Iteration 2146, loss = 0.01551037
Iteration 2147, loss = 0.01550299
Iteration 2148, loss = 0.01549345
Iteration 2149, loss = 0.01548454
Iteration 2150, loss = 0.01547671
Iteration 2151, loss = 0.01546918
Iteration 2152, loss = 0.01546059
Iteration 2153, loss = 0.01545266
Iteration 2154, loss = 0.01544323
Iteration 2155, loss = 0.01543397
Iteration 2156, loss = 0.01542514
Iteration 2157, loss = 0.01541480
Iteration 2158, loss = 0.01540633
Iteration 2159, loss = 0.01539613
Iteration 2160, loss = 0.01538773
Iteration 2161, loss = 0.01537745
Iteration 2162, loss = 0.01537161
Iteration 2163, loss = 0.01536063
Iteration 2164, loss = 0.01535135
Iteration 2165, loss = 0.01534138
Iteration 2166, loss = 0.01533306
Iteration 2167, loss = 0.01532410
Iteration 2168, loss = 0.01531431
Iteration 2169, loss = 0.01530722
Iteration 2170, loss = 0.01529797
Iteration 2171, loss = 0.01529027
Iteration 2172, loss = 0.01528140
Iteration 2173, loss = 0.01527298
Iteration 2174, loss = 0.01526425
Iteration 2175, loss = 0.01525715
Iteration 2176, loss = 0.01524677
Iteration 2177, loss = 0.01523899
Iteration 2178, loss = 0.01522883
Iteration 2179, loss = 0.01522116
Iteration 2180, loss = 0.01521476
Iteration 2181, loss = 0.01520498
Iteration 2182, loss = 0.01519673
Iteration 2183, loss = 0.01518747
Iteration 2184, loss = 0.01517942
Iteration 2185, loss = 0.01517078
Iteration 2186, loss = 0.01516399
Iteration 2187, loss = 0.01515619
Iteration 2188, loss = 0.01514775
Iteration 2189, loss = 0.01513912
Iteration 2190, loss = 0.01513071
Iteration 2191, loss = 0.01512294
Iteration 2192, loss = 0.01511432
Iteration 2193, loss = 0.01510475
Iteration 2194, loss = 0.01509636
Iteration 2195, loss = 0.01508636
Iteration 2196, loss = 0.01507807
Iteration 2197, loss = 0.01507002
Iteration 2198, loss = 0.01506109
Iteration 2199, loss = 0.01505133
Iteration 2200, loss = 0.01504444
Iteration 2201, loss = 0.01503632
Iteration 2202, loss = 0.01502974
Iteration 2203, loss = 0.01502071
Iteration 2204, loss = 0.01501373
Iteration 2205, loss = 0.01500520
Iteration 2206, loss = 0.01499829
Iteration 2207, loss = 0.01499143
Iteration 2208, loss = 0.01498341
Iteration 2209, loss = 0.01497522
Iteration 2210, loss = 0.01496622
Iteration 2211, loss = 0.01495894
Iteration 2212, loss = 0.01495347
Iteration 2213, loss = 0.01494174
Iteration 2214, loss = 0.01493517
Iteration 2215, loss = 0.01492476
Iteration 2216, loss = 0.01491649
Iteration 2217, loss = 0.01490766
Iteration 2218, loss = 0.01490021
Iteration 2219, loss = 0.01489321
Iteration 2220, loss = 0.01488350
Iteration 2221, loss = 0.01487789
Iteration 2222, loss = 0.01486805
Iteration 2223, loss = 0.01486214
Iteration 2224, loss = 0.01485252
Iteration 2225, loss = 0.01484372
Iteration 2226, loss = 0.01483544
Iteration 2227, loss = 0.01482817
Iteration 2228, loss = 0.01482060
Iteration 2229, loss = 0.01481226
Iteration 2230, loss = 0.01480447
Iteration 2231, loss = 0.01479728
Iteration 2232, loss = 0.01478940
Iteration 2233, loss = 0.01478091
Iteration 2234, loss = 0.01477456
Iteration 2235, loss = 0.01476594
Iteration 2236, loss = 0.01475813
Iteration 2237, loss = 0.01475129
Iteration 2238, loss = 0.01474258
Iteration 2239, loss = 0.01473432
Iteration 2240, loss = 0.01472621
Iteration 2241, loss = 0.01471773
Iteration 2242, loss = 0.01470849
Iteration 2243, loss = 0.01469903
Iteration 2244, loss = 0.01469128
Iteration 2245, loss = 0.01468431
Iteration 2246, loss = 0.01467515
Iteration 2247, loss = 0.01466612
Iteration 2248, loss = 0.01465882
Iteration 2249, loss = 0.01465201
Iteration 2250, loss = 0.01464356
Iteration 2251, loss = 0.01463799
Iteration 2252, loss = 0.01462976
Iteration 2253, loss = 0.01462273
Iteration 2254, loss = 0.01461306
Iteration 2255, loss = 0.01460565
Iteration 2256, loss = 0.01459717
Iteration 2257, loss = 0.01458950
Iteration 2258, loss = 0.01458092
Iteration 2259, loss = 0.01457302
Iteration 2260, loss = 0.01456540
Iteration 2261, loss = 0.01455728
Iteration 2262, loss = 0.01454806
Iteration 2263, loss = 0.01454004
Iteration 2264, loss = 0.01453228
Iteration 2265, loss = 0.01452388
Iteration 2266, loss = 0.01451691
Iteration 2267, loss = 0.01450920
Iteration 2268, loss = 0.01450222
Iteration 2269, loss = 0.01449510
Iteration 2270, loss = 0.01448802
Iteration 2271, loss = 0.01448015
Iteration 2272, loss = 0.01447259
Iteration 2273, loss = 0.01446530
Iteration 2274, loss = 0.01445688
Iteration 2275, loss = 0.01444875
Iteration 2276, loss = 0.01444114
Iteration 2277, loss = 0.01443398
Iteration 2278, loss = 0.01442591
Iteration 2279, loss = 0.01441650
Iteration 2280, loss = 0.01440841
Iteration 2281, loss = 0.01440134
Iteration 2282, loss = 0.01439313
Iteration 2283, loss = 0.01438486
Iteration 2284, loss = 0.01437673
Iteration 2285, loss = 0.01436900
Iteration 2286, loss = 0.01436124
Iteration 2287, loss = 0.01435297
Iteration 2288, loss = 0.01434501
Iteration 2289, loss = 0.01433706
Iteration 2290, loss = 0.01432926
Iteration 2291, loss = 0.01432025
Iteration 2292, loss = 0.01431343
Iteration 2293, loss = 0.01430515
Iteration 2294, loss = 0.01429770
Iteration 2295, loss = 0.01429165
Iteration 2296, loss = 0.01428381
Iteration 2297, loss = 0.01427680
Iteration 2298, loss = 0.01427228
Iteration 2299, loss = 0.01426329
Iteration 2300, loss = 0.01425705
Iteration 2301, loss = 0.01425213
Iteration 2302, loss = 0.01424298
Iteration 2303, loss = 0.01423485
Iteration 2304, loss = 0.01422617
Iteration 2305, loss = 0.01421944
Iteration 2306, loss = 0.01421092
Iteration 2307, loss = 0.01420544
Iteration 2308, loss = 0.01419784
Iteration 2309, loss = 0.01418891
Iteration 2310, loss = 0.01418183
Iteration 2311, loss = 0.01417418
Iteration 2312, loss = 0.01416694
Iteration 2313, loss = 0.01415933
Iteration 2314, loss = 0.01415208
Iteration 2315, loss = 0.01414455
Iteration 2316, loss = 0.01413793
Iteration 2317, loss = 0.01413017
Iteration 2318, loss = 0.01412388
Iteration 2319, loss = 0.01411647
Iteration 2320, loss = 0.01411030
Iteration 2321, loss = 0.01410280
Iteration 2322, loss = 0.01409563
Iteration 2323, loss = 0.01408852
Iteration 2324, loss = 0.01408165
Iteration 2325, loss = 0.01407348
Iteration 2326, loss = 0.01406651
Iteration 2327, loss = 0.01405789
Iteration 2328, loss = 0.01404966
Iteration 2329, loss = 0.01404066
Iteration 2330, loss = 0.01403295
Iteration 2331, loss = 0.01402581
Iteration 2332, loss = 0.01401590
Iteration 2333, loss = 0.01400778
Iteration 2334, loss = 0.01400203
Iteration 2335, loss = 0.01399300
Iteration 2336, loss = 0.01398675
Iteration 2337, loss = 0.01397675
Iteration 2338, loss = 0.01396909
Iteration 2339, loss = 0.01396143
Iteration 2340, loss = 0.01395323
Iteration 2341, loss = 0.01394656
Iteration 2342, loss = 0.01393724
Iteration 2343, loss = 0.01393037
Iteration 2344, loss = 0.01392231
Iteration 2345, loss = 0.01391415
Iteration 2346, loss = 0.01390797
Iteration 2347, loss = 0.01390056
Iteration 2348, loss = 0.01389079
Iteration 2349, loss = 0.01388379
Iteration 2350, loss = 0.01387568
Iteration 2351, loss = 0.01386788
Iteration 2352, loss = 0.01385996
Iteration 2353, loss = 0.01385270
Iteration 2354, loss = 0.01384756
Iteration 2355, loss = 0.01383782
Iteration 2356, loss = 0.01383101
Iteration 2357, loss = 0.01382252
Iteration 2358, loss = 0.01381496
Iteration 2359, loss = 0.01380766
Iteration 2360, loss = 0.01379977
Iteration 2361, loss = 0.01379285
Iteration 2362, loss = 0.01378504
Iteration 2363, loss = 0.01377738
Iteration 2364, loss = 0.01377059
Iteration 2365, loss = 0.01376255
Iteration 2366, loss = 0.01375570
Iteration 2367, loss = 0.01374916
Iteration 2368, loss = 0.01374122
Iteration 2369, loss = 0.01373250
Iteration 2370, loss = 0.01372638
Iteration 2371, loss = 0.01371929
Iteration 2372, loss = 0.01371306
Iteration 2373, loss = 0.01370423
Iteration 2374, loss = 0.01369704
Iteration 2375, loss = 0.01369057
Iteration 2376, loss = 0.01368316
Iteration 2377, loss = 0.01367561
Iteration 2378, loss = 0.01366903
Iteration 2379, loss = 0.01366197
Iteration 2380, loss = 0.01365381
Iteration 2381, loss = 0.01364645
Iteration 2382, loss = 0.01364013
Iteration 2383, loss = 0.01363411
Iteration 2384, loss = 0.01362641
Iteration 2385, loss = 0.01362016
Iteration 2386, loss = 0.01361336
Iteration 2387, loss = 0.01360688
Iteration 2388, loss = 0.01359968
Iteration 2389, loss = 0.01359468
Iteration 2390, loss = 0.01358754
Iteration 2391, loss = 0.01357989
Iteration 2392, loss = 0.01357197
Iteration 2393, loss = 0.01356422
Iteration 2394, loss = 0.01355782
Iteration 2395, loss = 0.01354960
Iteration 2396, loss = 0.01354248
Iteration 2397, loss = 0.01353486
Iteration 2398, loss = 0.01352906
Iteration 2399, loss = 0.01352037
Iteration 2400, loss = 0.01351342
Iteration 2401, loss = 0.01350665
Iteration 2402, loss = 0.01349877
Iteration 2403, loss = 0.01349159
Iteration 2404, loss = 0.01348430
Iteration 2405, loss = 0.01347816
Iteration 2406, loss = 0.01347068
Iteration 2407, loss = 0.01346323
Iteration 2408, loss = 0.01345640
Iteration 2409, loss = 0.01345152
Iteration 2410, loss = 0.01344332
Iteration 2411, loss = 0.01343627
Iteration 2412, loss = 0.01343050
Iteration 2413, loss = 0.01342090
Iteration 2414, loss = 0.01341356
Iteration 2415, loss = 0.01340627
Iteration 2416, loss = 0.01339956
Iteration 2417, loss = 0.01339081
Iteration 2418, loss = 0.01338556
Iteration 2419, loss = 0.01337725
Iteration 2420, loss = 0.01336975
Iteration 2421, loss = 0.01336271
Iteration 2422, loss = 0.01335565
Iteration 2423, loss = 0.01334853
Iteration 2424, loss = 0.01334156
Iteration 2425, loss = 0.01333506
Iteration 2426, loss = 0.01332761
Iteration 2427, loss = 0.01332161
Iteration 2428, loss = 0.01331469
Iteration 2429, loss = 0.01330839
Iteration 2430, loss = 0.01330205
Iteration 2431, loss = 0.01329570
Iteration 2432, loss = 0.01328941
Iteration 2433, loss = 0.01328467
Iteration 2434, loss = 0.01327749
Iteration 2435, loss = 0.01327180
Iteration 2436, loss = 0.01326646
Iteration 2437, loss = 0.01325920
Iteration 2438, loss = 0.01325376
Iteration 2439, loss = 0.01324773
Iteration 2440, loss = 0.01323993
Iteration 2441, loss = 0.01323380
Iteration 2442, loss = 0.01322596
Iteration 2443, loss = 0.01321937
Iteration 2444, loss = 0.01321226
Iteration 2445, loss = 0.01320481
Iteration 2446, loss = 0.01319770
Iteration 2447, loss = 0.01319086
Iteration 2448, loss = 0.01318281
Iteration 2449, loss = 0.01317707
Iteration 2450, loss = 0.01316922
Iteration 2451, loss = 0.01316378
Iteration 2452, loss = 0.01315560
Iteration 2453, loss = 0.01314976
Iteration 2454, loss = 0.01314355
Iteration 2455, loss = 0.01313738
Iteration 2456, loss = 0.01313091
Iteration 2457, loss = 0.01312425
Iteration 2458, loss = 0.01311774
Iteration 2459, loss = 0.01311196
Iteration 2460, loss = 0.01310471
Iteration 2461, loss = 0.01309782
Iteration 2462, loss = 0.01309124
Iteration 2463, loss = 0.01308558
Iteration 2464, loss = 0.01307865
Iteration 2465, loss = 0.01306986
Iteration 2466, loss = 0.01306438
Iteration 2467, loss = 0.01305575
Iteration 2468, loss = 0.01304910
Iteration 2469, loss = 0.01304247
Iteration 2470, loss = 0.01303553
Iteration 2471, loss = 0.01302926
Iteration 2472, loss = 0.01302180
Iteration 2473, loss = 0.01301705
Iteration 2474, loss = 0.01300940
Iteration 2475, loss = 0.01300311
Iteration 2476, loss = 0.01299586
Iteration 2477, loss = 0.01299042
Iteration 2478, loss = 0.01298336
Iteration 2479, loss = 0.01297668
Iteration 2480, loss = 0.01297020
Iteration 2481, loss = 0.01296403
Iteration 2482, loss = 0.01295776
Iteration 2483, loss = 0.01295197
Iteration 2484, loss = 0.01294696
Iteration 2485, loss = 0.01294016
Iteration 2486, loss = 0.01293438
Iteration 2487, loss = 0.01292845
Iteration 2488, loss = 0.01292278
Iteration 2489, loss = 0.01291681
Iteration 2490, loss = 0.01291238
Iteration 2491, loss = 0.01290653
Iteration 2492, loss = 0.01290122
Iteration 2493, loss = 0.01289715
Iteration 2494, loss = 0.01289063
Iteration 2495, loss = 0.01288513
Iteration 2496, loss = 0.01287917
Iteration 2497, loss = 0.01287330
Iteration 2498, loss = 0.01286891
Iteration 2499, loss = 0.01286326
Iteration 2500, loss = 0.01285842
Iteration 2501, loss = 0.01285149
Iteration 2502, loss = 0.01284553
Iteration 2503, loss = 0.01283885
Iteration 2504, loss = 0.01283324
Iteration 2505, loss = 0.01282643
Iteration 2506, loss = 0.01282010
Iteration 2507, loss = 0.01281396
Iteration 2508, loss = 0.01280662
Iteration 2509, loss = 0.01279969
Iteration 2510, loss = 0.01279318
Iteration 2511, loss = 0.01278765
Iteration 2512, loss = 0.01278143
Iteration 2513, loss = 0.01277565
Iteration 2514, loss = 0.01276982
Iteration 2515, loss = 0.01276448
Iteration 2516, loss = 0.01275886
Iteration 2517, loss = 0.01275323
Iteration 2518, loss = 0.01274934
Iteration 2519, loss = 0.01274169
Iteration 2520, loss = 0.01273580
Iteration 2521, loss = 0.01272886
Iteration 2522, loss = 0.01272235
Iteration 2523, loss = 0.01271650
Iteration 2524, loss = 0.01270967
Iteration 2525, loss = 0.01270255
Iteration 2526, loss = 0.01269569
Iteration 2527, loss = 0.01268847
Iteration 2528, loss = 0.01268305
Iteration 2529, loss = 0.01267650
Iteration 2530, loss = 0.01267015
Iteration 2531, loss = 0.01266315
Iteration 2532, loss = 0.01265696
Iteration 2533, loss = 0.01265107
Iteration 2534, loss = 0.01264502
Iteration 2535, loss = 0.01263887
Iteration 2536, loss = 0.01263323
Iteration 2537, loss = 0.01262552
Iteration 2538, loss = 0.01262138
Iteration 2539, loss = 0.01261271
Iteration 2540, loss = 0.01260616
Iteration 2541, loss = 0.01259918
Iteration 2542, loss = 0.01259452
Iteration 2543, loss = 0.01258687
Iteration 2544, loss = 0.01258094
Iteration 2545, loss = 0.01257497
Iteration 2546, loss = 0.01256788
Iteration 2547, loss = 0.01256106
Iteration 2548, loss = 0.01255424
Iteration 2549, loss = 0.01254664
Iteration 2550, loss = 0.01253953
Iteration 2551, loss = 0.01253277
Iteration 2552, loss = 0.01252496
Iteration 2553, loss = 0.01251888
Iteration 2554, loss = 0.01251228
Iteration 2555, loss = 0.01250573
Iteration 2556, loss = 0.01249893
Iteration 2557, loss = 0.01249221
Iteration 2558, loss = 0.01248842
Iteration 2559, loss = 0.01248020
Iteration 2560, loss = 0.01247461
Iteration 2561, loss = 0.01247033
Iteration 2562, loss = 0.01246212
Iteration 2563, loss = 0.01245539
Iteration 2564, loss = 0.01244920
Iteration 2565, loss = 0.01244199
Iteration 2566, loss = 0.01243741
Iteration 2567, loss = 0.01242940
Iteration 2568, loss = 0.01242284
Iteration 2569, loss = 0.01241584
Iteration 2570, loss = 0.01240924
Iteration 2571, loss = 0.01240352
Iteration 2572, loss = 0.01239556
Iteration 2573, loss = 0.01238934
Iteration 2574, loss = 0.01238385
Iteration 2575, loss = 0.01237703
Iteration 2576, loss = 0.01237048
Iteration 2577, loss = 0.01236286
Iteration 2578, loss = 0.01235600
Iteration 2579, loss = 0.01234852
Iteration 2580, loss = 0.01234412
Iteration 2581, loss = 0.01233670
Iteration 2582, loss = 0.01232951
Iteration 2583, loss = 0.01232531
Iteration 2584, loss = 0.01231764
Iteration 2585, loss = 0.01231101
Iteration 2586, loss = 0.01230467
Iteration 2587, loss = 0.01229945
Iteration 2588, loss = 0.01229242
Iteration 2589, loss = 0.01228680
Iteration 2590, loss = 0.01228039
Iteration 2591, loss = 0.01227448
Iteration 2592, loss = 0.01226852
Iteration 2593, loss = 0.01226445
Iteration 2594, loss = 0.01225744
Iteration 2595, loss = 0.01225257
Iteration 2596, loss = 0.01224807
Iteration 2597, loss = 0.01224160
Iteration 2598, loss = 0.01223600
Iteration 2599, loss = 0.01223047
Iteration 2600, loss = 0.01222481
Iteration 2601, loss = 0.01221904
Iteration 2602, loss = 0.01221434
Iteration 2603, loss = 0.01220680
Iteration 2604, loss = 0.01220135
Iteration 2605, loss = 0.01219519
Iteration 2606, loss = 0.01218937
Iteration 2607, loss = 0.01218416
Iteration 2608, loss = 0.01217825
Iteration 2609, loss = 0.01217288
Iteration 2610, loss = 0.01216613
Iteration 2611, loss = 0.01216083
Iteration 2612, loss = 0.01215491
Iteration 2613, loss = 0.01214928
Iteration 2614, loss = 0.01214343
Iteration 2615, loss = 0.01213692
Iteration 2616, loss = 0.01213309
Iteration 2617, loss = 0.01212603
Iteration 2618, loss = 0.01212084
Iteration 2619, loss = 0.01211506
Iteration 2620, loss = 0.01210950
Iteration 2621, loss = 0.01210459
Iteration 2622, loss = 0.01209944
Iteration 2623, loss = 0.01209473
Iteration 2624, loss = 0.01209145
Iteration 2625, loss = 0.01208538
Iteration 2626, loss = 0.01208096
Iteration 2627, loss = 0.01207699
Iteration 2628, loss = 0.01207191
Iteration 2629, loss = 0.01206662
Iteration 2630, loss = 0.01206096
Iteration 2631, loss = 0.01205589
Iteration 2632, loss = 0.01205002
Iteration 2633, loss = 0.01204479
Iteration 2634, loss = 0.01203925
Iteration 2635, loss = 0.01203395
Iteration 2636, loss = 0.01202861
Iteration 2637, loss = 0.01202224
Iteration 2638, loss = 0.01201629
Iteration 2639, loss = 0.01200915
Iteration 2640, loss = 0.01200348
Iteration 2641, loss = 0.01199821
Iteration 2642, loss = 0.01199150
Iteration 2643, loss = 0.01198515
Iteration 2644, loss = 0.01198045
Iteration 2645, loss = 0.01197360
Iteration 2646, loss = 0.01197000
Iteration 2647, loss = 0.01196352
Iteration 2648, loss = 0.01195724
Iteration 2649, loss = 0.01195207
Iteration 2650, loss = 0.01194679
Iteration 2651, loss = 0.01194132
Iteration 2652, loss = 0.01193514
Iteration 2653, loss = 0.01193050
Iteration 2654, loss = 0.01192431
Iteration 2655, loss = 0.01191941
Iteration 2656, loss = 0.01191391
Iteration 2657, loss = 0.01190892
Iteration 2658, loss = 0.01190296
Iteration 2659, loss = 0.01189643
Iteration 2660, loss = 0.01189002
Iteration 2661, loss = 0.01188408
Iteration 2662, loss = 0.01187822
Iteration 2663, loss = 0.01187389
Iteration 2664, loss = 0.01186700
Iteration 2665, loss = 0.01186308
Iteration 2666, loss = 0.01185577
Iteration 2667, loss = 0.01185011
Iteration 2668, loss = 0.01184503
Iteration 2669, loss = 0.01183880
Iteration 2670, loss = 0.01183300
Iteration 2671, loss = 0.01182856
Iteration 2672, loss = 0.01182036
Iteration 2673, loss = 0.01181379
Iteration 2674, loss = 0.01180780
Iteration 2675, loss = 0.01180122
Iteration 2676, loss = 0.01179620
Iteration 2677, loss = 0.01178895
Iteration 2678, loss = 0.01178317
Iteration 2679, loss = 0.01177701
Iteration 2680, loss = 0.01177069
Iteration 2681, loss = 0.01176658
Iteration 2682, loss = 0.01175847
Iteration 2683, loss = 0.01175280
Iteration 2684, loss = 0.01174688
Iteration 2685, loss = 0.01174044
Iteration 2686, loss = 0.01173456
Iteration 2687, loss = 0.01172765
Iteration 2688, loss = 0.01172381
Iteration 2689, loss = 0.01171642
Iteration 2690, loss = 0.01171231
Iteration 2691, loss = 0.01170568
Iteration 2692, loss = 0.01169985
Iteration 2693, loss = 0.01169414
Iteration 2694, loss = 0.01168894
Iteration 2695, loss = 0.01168403
Iteration 2696, loss = 0.01167811
Iteration 2697, loss = 0.01167253
Iteration 2698, loss = 0.01166644
Iteration 2699, loss = 0.01166111
Iteration 2700, loss = 0.01165432
Iteration 2701, loss = 0.01165122
Iteration 2702, loss = 0.01164354
Iteration 2703, loss = 0.01164097
Iteration 2704, loss = 0.01163578
Iteration 2705, loss = 0.01163032
Iteration 2706, loss = 0.01162483
Iteration 2707, loss = 0.01161949
Iteration 2708, loss = 0.01161463
Iteration 2709, loss = 0.01160898
Iteration 2710, loss = 0.01160361
Iteration 2711, loss = 0.01159790
Iteration 2712, loss = 0.01159346
Iteration 2713, loss = 0.01158798
Iteration 2714, loss = 0.01158242
Iteration 2715, loss = 0.01157665
Iteration 2716, loss = 0.01157308
Iteration 2717, loss = 0.01156641
Iteration 2718, loss = 0.01156082
Iteration 2719, loss = 0.01155682
Iteration 2720, loss = 0.01155058
Iteration 2721, loss = 0.01154519
Iteration 2722, loss = 0.01153964
Iteration 2723, loss = 0.01153458
Iteration 2724, loss = 0.01152902
Iteration 2725, loss = 0.01152366
Iteration 2726, loss = 0.01151816
Iteration 2727, loss = 0.01151296
Iteration 2728, loss = 0.01150774
Iteration 2729, loss = 0.01150245
Iteration 2730, loss = 0.01149661
Iteration 2731, loss = 0.01149076
Iteration 2732, loss = 0.01148661
Iteration 2733, loss = 0.01148038
Iteration 2734, loss = 0.01147464
Iteration 2735, loss = 0.01146864
Iteration 2736, loss = 0.01146444
Iteration 2737, loss = 0.01145774
Iteration 2738, loss = 0.01145199
Iteration 2739, loss = 0.01144609
Iteration 2740, loss = 0.01144066
Iteration 2741, loss = 0.01143569
Iteration 2742, loss = 0.01143029
Iteration 2743, loss = 0.01142643
Iteration 2744, loss = 0.01141983
Iteration 2745, loss = 0.01141417
Iteration 2746, loss = 0.01141048
Iteration 2747, loss = 0.01140395
Iteration 2748, loss = 0.01139692
Iteration 2749, loss = 0.01139090
Iteration 2750, loss = 0.01138587
Iteration 2751, loss = 0.01138023
Iteration 2752, loss = 0.01137506
Iteration 2753, loss = 0.01136933
Iteration 2754, loss = 0.01136443
Iteration 2755, loss = 0.01135903
Iteration 2756, loss = 0.01135321
Iteration 2757, loss = 0.01134862
Iteration 2758, loss = 0.01134190
Iteration 2759, loss = 0.01133643
Iteration 2760, loss = 0.01133130
Iteration 2761, loss = 0.01132574
Iteration 2762, loss = 0.01131926
Iteration 2763, loss = 0.01131394
Iteration 2764, loss = 0.01130870
Iteration 2765, loss = 0.01130267
Iteration 2766, loss = 0.01129735
Iteration 2767, loss = 0.01129324
Iteration 2768, loss = 0.01128670
Iteration 2769, loss = 0.01128154
Iteration 2770, loss = 0.01127812
Iteration 2771, loss = 0.01127179
Iteration 2772, loss = 0.01126691
Iteration 2773, loss = 0.01126076
Iteration 2774, loss = 0.01125606
Iteration 2775, loss = 0.01125060
Iteration 2776, loss = 0.01124595
Iteration 2777, loss = 0.01124085
Iteration 2778, loss = 0.01123451
Iteration 2779, loss = 0.01122999
Iteration 2780, loss = 0.01122365
Iteration 2781, loss = 0.01122053
Iteration 2782, loss = 0.01121372
Iteration 2783, loss = 0.01120723
Iteration 2784, loss = 0.01120318
Iteration 2785, loss = 0.01119806
Iteration 2786, loss = 0.01119244
Iteration 2787, loss = 0.01118663
Iteration 2788, loss = 0.01118135
Iteration 2789, loss = 0.01117601
Iteration 2790, loss = 0.01117421
Iteration 2791, loss = 0.01116709
Iteration 2792, loss = 0.01116209
Iteration 2793, loss = 0.01115714
Iteration 2794, loss = 0.01115181
Iteration 2795, loss = 0.01114726
Iteration 2796, loss = 0.01114229
Iteration 2797, loss = 0.01113700
Iteration 2798, loss = 0.01113211
Iteration 2799, loss = 0.01112781
Iteration 2800, loss = 0.01112157
Iteration 2801, loss = 0.01111674
Iteration 2802, loss = 0.01111176
Iteration 2803, loss = 0.01110705
Iteration 2804, loss = 0.01110342
Iteration 2805, loss = 0.01109872
Iteration 2806, loss = 0.01109409
Iteration 2807, loss = 0.01108868
Iteration 2808, loss = 0.01108354
Iteration 2809, loss = 0.01107809
Iteration 2810, loss = 0.01107333
Iteration 2811, loss = 0.01106833
Iteration 2812, loss = 0.01106372
Iteration 2813, loss = 0.01105841
Iteration 2814, loss = 0.01105466
Iteration 2815, loss = 0.01104899
Iteration 2816, loss = 0.01104345
Iteration 2817, loss = 0.01103734
Iteration 2818, loss = 0.01103246
Iteration 2819, loss = 0.01102680
Iteration 2820, loss = 0.01102081
Iteration 2821, loss = 0.01101639
Iteration 2822, loss = 0.01101033
Iteration 2823, loss = 0.01100498
Iteration 2824, loss = 0.01099953
Iteration 2825, loss = 0.01099390
Iteration 2826, loss = 0.01098942
Iteration 2827, loss = 0.01098321
Iteration 2828, loss = 0.01097743
Iteration 2829, loss = 0.01097288
Iteration 2830, loss = 0.01096726
Iteration 2831, loss = 0.01096262
Iteration 2832, loss = 0.01095654
Iteration 2833, loss = 0.01095121
Iteration 2834, loss = 0.01094575
Iteration 2835, loss = 0.01094039
Iteration 2836, loss = 0.01093654
Iteration 2837, loss = 0.01093063
Iteration 2838, loss = 0.01092587
Iteration 2839, loss = 0.01092000
Iteration 2840, loss = 0.01091524
Iteration 2841, loss = 0.01090932
Iteration 2842, loss = 0.01090395
Iteration 2843, loss = 0.01089853
Iteration 2844, loss = 0.01089207
Iteration 2845, loss = 0.01088737
Iteration 2846, loss = 0.01088056
Iteration 2847, loss = 0.01087530
Iteration 2848, loss = 0.01086902
Iteration 2849, loss = 0.01086442
Iteration 2850, loss = 0.01086059
Iteration 2851, loss = 0.01085374
Iteration 2852, loss = 0.01084810
Iteration 2853, loss = 0.01084323
Iteration 2854, loss = 0.01083835
Iteration 2855, loss = 0.01083463
Iteration 2856, loss = 0.01082805
Iteration 2857, loss = 0.01082262
Iteration 2858, loss = 0.01081872
Iteration 2859, loss = 0.01081270
Iteration 2860, loss = 0.01080702
Iteration 2861, loss = 0.01080174
Iteration 2862, loss = 0.01079653
Iteration 2863, loss = 0.01079119
Iteration 2864, loss = 0.01078588
Iteration 2865, loss = 0.01078069
Iteration 2866, loss = 0.01077543
Iteration 2867, loss = 0.01077018
Iteration 2868, loss = 0.01076464
Iteration 2869, loss = 0.01075923
Iteration 2870, loss = 0.01075319
Iteration 2871, loss = 0.01074812
Iteration 2872, loss = 0.01074286
Iteration 2873, loss = 0.01073849
Iteration 2874, loss = 0.01073315
Iteration 2875, loss = 0.01072800
Iteration 2876, loss = 0.01072344
Iteration 2877, loss = 0.01071895
Iteration 2878, loss = 0.01071365
Iteration 2879, loss = 0.01070900
Iteration 2880, loss = 0.01070571
Iteration 2881, loss = 0.01069904
Iteration 2882, loss = 0.01069436
Iteration 2883, loss = 0.01068962
Iteration 2884, loss = 0.01068479
Iteration 2885, loss = 0.01067965
Iteration 2886, loss = 0.01067499
Iteration 2887, loss = 0.01067017
Iteration 2888, loss = 0.01066547
Iteration 2889, loss = 0.01066064
Iteration 2890, loss = 0.01065621
Iteration 2891, loss = 0.01065123
Iteration 2892, loss = 0.01064661
Iteration 2893, loss = 0.01064064
Iteration 2894, loss = 0.01063549
Iteration 2895, loss = 0.01063088
Iteration 2896, loss = 0.01062550
Iteration 2897, loss = 0.01062215
Iteration 2898, loss = 0.01061504
Iteration 2899, loss = 0.01060978
Iteration 2900, loss = 0.01060453
Iteration 2901, loss = 0.01059950
Iteration 2902, loss = 0.01059404
Iteration 2903, loss = 0.01058949
Iteration 2904, loss = 0.01058703
Iteration 2905, loss = 0.01058077
Iteration 2906, loss = 0.01057499
Iteration 2907, loss = 0.01057000
Iteration 2908, loss = 0.01056547
Iteration 2909, loss = 0.01056050
Iteration 2910, loss = 0.01055515
Iteration 2911, loss = 0.01055097
Iteration 2912, loss = 0.01054541
Iteration 2913, loss = 0.01054055
Iteration 2914, loss = 0.01053531
Iteration 2915, loss = 0.01053001
Iteration 2916, loss = 0.01052506
Iteration 2917, loss = 0.01052106
Iteration 2918, loss = 0.01051527
Iteration 2919, loss = 0.01051074
Iteration 2920, loss = 0.01050590
Iteration 2921, loss = 0.01050086
Iteration 2922, loss = 0.01049633
Iteration 2923, loss = 0.01049155
Iteration 2924, loss = 0.01048687
Iteration 2925, loss = 0.01048218
Iteration 2926, loss = 0.01047752
Iteration 2927, loss = 0.01047293
Iteration 2928, loss = 0.01046835
Iteration 2929, loss = 0.01046302
Iteration 2930, loss = 0.01045847
Iteration 2931, loss = 0.01045409
Iteration 2932, loss = 0.01044913
Iteration 2933, loss = 0.01044522
Iteration 2934, loss = 0.01044033
Iteration 2935, loss = 0.01043512
Iteration 2936, loss = 0.01043212
Iteration 2937, loss = 0.01042591
Iteration 2938, loss = 0.01042164
Iteration 2939, loss = 0.01041672
Iteration 2940, loss = 0.01041315
Iteration 2941, loss = 0.01040674
Iteration 2942, loss = 0.01040318
Iteration 2943, loss = 0.01039705
Iteration 2944, loss = 0.01039415
Iteration 2945, loss = 0.01038746
Iteration 2946, loss = 0.01038174
Iteration 2947, loss = 0.01037840
Iteration 2948, loss = 0.01037193
Iteration 2949, loss = 0.01036645
Iteration 2950, loss = 0.01036117
Iteration 2951, loss = 0.01035583
Iteration 2952, loss = 0.01035200
Iteration 2953, loss = 0.01034695
Iteration 2954, loss = 0.01034215
Iteration 2955, loss = 0.01033774
Iteration 2956, loss = 0.01033308
Iteration 2957, loss = 0.01032919
Iteration 2958, loss = 0.01032423
Iteration 2959, loss = 0.01032011
Iteration 2960, loss = 0.01031563
Iteration 2961, loss = 0.01031146
Iteration 2962, loss = 0.01030748
Iteration 2963, loss = 0.01030302
Iteration 2964, loss = 0.01029905
Iteration 2965, loss = 0.01029411
Iteration 2966, loss = 0.01028979
Iteration 2967, loss = 0.01028473
Iteration 2968, loss = 0.01028047
Iteration 2969, loss = 0.01027556
Iteration 2970, loss = 0.01027074
Iteration 2971, loss = 0.01026572
Iteration 2972, loss = 0.01026090
Iteration 2973, loss = 0.01025589
Iteration 2974, loss = 0.01025145
Iteration 2975, loss = 0.01024654
Iteration 2976, loss = 0.01024193
Iteration 2977, loss = 0.01023654
Iteration 2978, loss = 0.01023171
Iteration 2979, loss = 0.01022678
Iteration 2980, loss = 0.01022205
Iteration 2981, loss = 0.01021880
Iteration 2982, loss = 0.01021276
Iteration 2983, loss = 0.01020830
Iteration 2984, loss = 0.01020336
Iteration 2985, loss = 0.01019854
Iteration 2986, loss = 0.01019371
Iteration 2987, loss = 0.01019082
Iteration 2988, loss = 0.01018598
Iteration 2989, loss = 0.01018200
Iteration 2990, loss = 0.01017780
Iteration 2991, loss = 0.01017307
Iteration 2992, loss = 0.01016882
Iteration 2993, loss = 0.01016453
Iteration 2994, loss = 0.01015953
Iteration 2995, loss = 0.01015474
Iteration 2996, loss = 0.01015186
Iteration 2997, loss = 0.01014662
Iteration 2998, loss = 0.01014318
Iteration 2999, loss = 0.01013762
Iteration 3000, loss = 0.01013462
Iteration 3001, loss = 0.01013001
Iteration 3002, loss = 0.01012551
Iteration 3003, loss = 0.01012078
Iteration 3004, loss = 0.01011640
Iteration 3005, loss = 0.01011215
Iteration 3006, loss = 0.01010774
Iteration 3007, loss = 0.01010449
Iteration 3008, loss = 0.01009971
Iteration 3009, loss = 0.01009567
Iteration 3010, loss = 0.01009278
Iteration 3011, loss = 0.01008771
Iteration 3012, loss = 0.01008298
Iteration 3013, loss = 0.01007830
Iteration 3014, loss = 0.01007452
Iteration 3015, loss = 0.01007013
Iteration 3016, loss = 0.01006556
Iteration 3017, loss = 0.01006101
Iteration 3018, loss = 0.01005625
Iteration 3019, loss = 0.01005109
Iteration 3020, loss = 0.01004623
Iteration 3021, loss = 0.01004353
Iteration 3022, loss = 0.01003736
Iteration 3023, loss = 0.01003280
Iteration 3024, loss = 0.01002835
Iteration 3025, loss = 0.01002428
Iteration 3026, loss = 0.01002000
Iteration 3027, loss = 0.01001619
Iteration 3028, loss = 0.01001245
Iteration 3029, loss = 0.01000773
Iteration 3030, loss = 0.01000377
Iteration 3031, loss = 0.00999918
Iteration 3032, loss = 0.00999522
Iteration 3033, loss = 0.00999165
Iteration 3034, loss = 0.00998665
Iteration 3035, loss = 0.00998250
Iteration 3036, loss = 0.00997883
Iteration 3037, loss = 0.00997433
Iteration 3038, loss = 0.00997032
Iteration 3039, loss = 0.00996559
Iteration 3040, loss = 0.00996119
Iteration 3041, loss = 0.00995709
Iteration 3042, loss = 0.00995378
Iteration 3043, loss = 0.00994916
Iteration 3044, loss = 0.00994487
Iteration 3045, loss = 0.00994204
Iteration 3046, loss = 0.00993777
Iteration 3047, loss = 0.00993385
Iteration 3048, loss = 0.00992912
Iteration 3049, loss = 0.00992543
Iteration 3050, loss = 0.00991993
Iteration 3051, loss = 0.00991468
Iteration 3052, loss = 0.00990986
Iteration 3053, loss = 0.00990508
Iteration 3054, loss = 0.00989938
Iteration 3055, loss = 0.00989654
Iteration 3056, loss = 0.00989077
Iteration 3057, loss = 0.00988789
Iteration 3058, loss = 0.00988203
Iteration 3059, loss = 0.00987745
Iteration 3060, loss = 0.00987425
Iteration 3061, loss = 0.00986931
Iteration 3062, loss = 0.00986547
Iteration 3063, loss = 0.00986121
Iteration 3064, loss = 0.00985740
Iteration 3065, loss = 0.00985312
Iteration 3066, loss = 0.00984940
Iteration 3067, loss = 0.00984464
Iteration 3068, loss = 0.00984041
Iteration 3069, loss = 0.00983740
Iteration 3070, loss = 0.00983190
Iteration 3071, loss = 0.00982787
Iteration 3072, loss = 0.00982329
Iteration 3073, loss = 0.00981834
Iteration 3074, loss = 0.00981371
Iteration 3075, loss = 0.00980893
Iteration 3076, loss = 0.00980493
Iteration 3077, loss = 0.00980047
Iteration 3078, loss = 0.00979593
Iteration 3079, loss = 0.00979190
Iteration 3080, loss = 0.00978777
Iteration 3081, loss = 0.00978338
Iteration 3082, loss = 0.00977931
Iteration 3083, loss = 0.00977523
Iteration 3084, loss = 0.00977108
Iteration 3085, loss = 0.00976685
Iteration 3086, loss = 0.00976275
Iteration 3087, loss = 0.00975836
Iteration 3088, loss = 0.00975549
Iteration 3089, loss = 0.00975151
Iteration 3090, loss = 0.00974720
Iteration 3091, loss = 0.00974318
Iteration 3092, loss = 0.00973910
Iteration 3093, loss = 0.00973538
Iteration 3094, loss = 0.00973223
Iteration 3095, loss = 0.00972743
Iteration 3096, loss = 0.00972424
Iteration 3097, loss = 0.00971929
Iteration 3098, loss = 0.00971518
Iteration 3099, loss = 0.00971092
Iteration 3100, loss = 0.00970569
Iteration 3101, loss = 0.00970155
Iteration 3102, loss = 0.00969738
Iteration 3103, loss = 0.00969377
Iteration 3104, loss = 0.00968955
Iteration 3105, loss = 0.00968513
Iteration 3106, loss = 0.00968111
Iteration 3107, loss = 0.00967691
Iteration 3108, loss = 0.00967300
Iteration 3109, loss = 0.00966870
Iteration 3110, loss = 0.00966445
Iteration 3111, loss = 0.00966069
Iteration 3112, loss = 0.00965622
Iteration 3113, loss = 0.00965233
Iteration 3114, loss = 0.00964903
Iteration 3115, loss = 0.00964436
Iteration 3116, loss = 0.00964069
Iteration 3117, loss = 0.00963662
Iteration 3118, loss = 0.00963198
Iteration 3119, loss = 0.00962814
Iteration 3120, loss = 0.00962441
Iteration 3121, loss = 0.00962066
Iteration 3122, loss = 0.00961683
Iteration 3123, loss = 0.00961294
Iteration 3124, loss = 0.00960927
Iteration 3125, loss = 0.00960484
Iteration 3126, loss = 0.00960116
Iteration 3127, loss = 0.00959729
Iteration 3128, loss = 0.00959415
Iteration 3129, loss = 0.00959003
Iteration 3130, loss = 0.00958596
Iteration 3131, loss = 0.00958208
Iteration 3132, loss = 0.00957740
Iteration 3133, loss = 0.00957376
Iteration 3134, loss = 0.00956873
Iteration 3135, loss = 0.00956568
Iteration 3136, loss = 0.00956050
Iteration 3137, loss = 0.00955677
Iteration 3138, loss = 0.00955286
Iteration 3139, loss = 0.00954892
Iteration 3140, loss = 0.00954522
Iteration 3141, loss = 0.00954183
Iteration 3142, loss = 0.00953806
Iteration 3143, loss = 0.00953437
Iteration 3144, loss = 0.00953180
Iteration 3145, loss = 0.00952806
Iteration 3146, loss = 0.00952533
Iteration 3147, loss = 0.00952127
Iteration 3148, loss = 0.00951752
Iteration 3149, loss = 0.00951326
Iteration 3150, loss = 0.00950982
Iteration 3151, loss = 0.00950619
Iteration 3152, loss = 0.00950290
Iteration 3153, loss = 0.00949926
Iteration 3154, loss = 0.00949635
Iteration 3155, loss = 0.00949273
Iteration 3156, loss = 0.00948889
Iteration 3157, loss = 0.00948432
Iteration 3158, loss = 0.00947912
Iteration 3159, loss = 0.00947524
Iteration 3160, loss = 0.00947034
Iteration 3161, loss = 0.00946599
Iteration 3162, loss = 0.00946156
Iteration 3163, loss = 0.00945738
Iteration 3164, loss = 0.00945309
Iteration 3165, loss = 0.00944905
Iteration 3166, loss = 0.00944484
Iteration 3167, loss = 0.00944080
Iteration 3168, loss = 0.00943553
Iteration 3169, loss = 0.00943120
Iteration 3170, loss = 0.00942661
Iteration 3171, loss = 0.00942292
Iteration 3172, loss = 0.00941795
Iteration 3173, loss = 0.00941397
Iteration 3174, loss = 0.00941024
Iteration 3175, loss = 0.00940597
Iteration 3176, loss = 0.00940251
Iteration 3177, loss = 0.00939846
Iteration 3178, loss = 0.00939516
Iteration 3179, loss = 0.00939146
Iteration 3180, loss = 0.00938855
Iteration 3181, loss = 0.00938403
Iteration 3182, loss = 0.00938022
Iteration 3183, loss = 0.00937587
Iteration 3184, loss = 0.00937295
Iteration 3185, loss = 0.00936831
Iteration 3186, loss = 0.00936422
Iteration 3187, loss = 0.00935986
Iteration 3188, loss = 0.00935648
Iteration 3189, loss = 0.00935230
Iteration 3190, loss = 0.00934849
Iteration 3191, loss = 0.00934475
Iteration 3192, loss = 0.00934066
Iteration 3193, loss = 0.00933629
Iteration 3194, loss = 0.00933227
Iteration 3195, loss = 0.00932828
Iteration 3196, loss = 0.00932388
Iteration 3197, loss = 0.00932081
Iteration 3198, loss = 0.00931645
Iteration 3199, loss = 0.00931272
Iteration 3200, loss = 0.00930934
Iteration 3201, loss = 0.00930545
Iteration 3202, loss = 0.00930150
Iteration 3203, loss = 0.00929829
Iteration 3204, loss = 0.00929567
Iteration 3205, loss = 0.00929134
Iteration 3206, loss = 0.00928705
Iteration 3207, loss = 0.00928283
Iteration 3208, loss = 0.00927858
Iteration 3209, loss = 0.00927440
Iteration 3210, loss = 0.00926968
Iteration 3211, loss = 0.00926633
Iteration 3212, loss = 0.00926136
Iteration 3213, loss = 0.00925806
Iteration 3214, loss = 0.00925330
Iteration 3215, loss = 0.00924933
Iteration 3216, loss = 0.00924514
Iteration 3217, loss = 0.00924176
Iteration 3218, loss = 0.00923770
Iteration 3219, loss = 0.00923338
Iteration 3220, loss = 0.00922962
Iteration 3221, loss = 0.00922617
Iteration 3222, loss = 0.00922265
Iteration 3223, loss = 0.00921927
Iteration 3224, loss = 0.00921625
Iteration 3225, loss = 0.00921238
Iteration 3226, loss = 0.00920889
Iteration 3227, loss = 0.00920563
Iteration 3228, loss = 0.00920182
Iteration 3229, loss = 0.00919908
Iteration 3230, loss = 0.00919537
Iteration 3231, loss = 0.00919175
Iteration 3232, loss = 0.00918813
Iteration 3233, loss = 0.00918543
Iteration 3234, loss = 0.00918089
Iteration 3235, loss = 0.00917758
Iteration 3236, loss = 0.00917354
Iteration 3237, loss = 0.00916995
Iteration 3238, loss = 0.00916679
Iteration 3239, loss = 0.00916340
Iteration 3240, loss = 0.00916029
Iteration 3241, loss = 0.00915699
Iteration 3242, loss = 0.00915408
Iteration 3243, loss = 0.00915127
Iteration 3244, loss = 0.00914787
Iteration 3245, loss = 0.00914360
Iteration 3246, loss = 0.00913996
Iteration 3247, loss = 0.00913578
Iteration 3248, loss = 0.00913245
Iteration 3249, loss = 0.00912819
Iteration 3250, loss = 0.00912395
Iteration 3251, loss = 0.00912071
Iteration 3252, loss = 0.00911508
Iteration 3253, loss = 0.00911055
Iteration 3254, loss = 0.00910683
Iteration 3255, loss = 0.00910159
Iteration 3256, loss = 0.00909795
Iteration 3257, loss = 0.00909489
Iteration 3258, loss = 0.00908953
Iteration 3259, loss = 0.00908618
Iteration 3260, loss = 0.00908206
Iteration 3261, loss = 0.00907875
Iteration 3262, loss = 0.00907461
Iteration 3263, loss = 0.00907120
Iteration 3264, loss = 0.00906737
Iteration 3265, loss = 0.00906385
Iteration 3266, loss = 0.00906010
Iteration 3267, loss = 0.00905695
Iteration 3268, loss = 0.00905309
Iteration 3269, loss = 0.00904946
Iteration 3270, loss = 0.00904598
Iteration 3271, loss = 0.00904293
Iteration 3272, loss = 0.00903936
Iteration 3273, loss = 0.00903634
Iteration 3274, loss = 0.00903286
Iteration 3275, loss = 0.00902908
Iteration 3276, loss = 0.00902570
Iteration 3277, loss = 0.00902237
Iteration 3278, loss = 0.00901926
Iteration 3279, loss = 0.00901561
Iteration 3280, loss = 0.00901213
Iteration 3281, loss = 0.00900894
Iteration 3282, loss = 0.00900498
Iteration 3283, loss = 0.00900108
Iteration 3284, loss = 0.00899778
Iteration 3285, loss = 0.00899315
Iteration 3286, loss = 0.00899115
Iteration 3287, loss = 0.00898579
Iteration 3288, loss = 0.00898208
Iteration 3289, loss = 0.00897895
Iteration 3290, loss = 0.00897475
Iteration 3291, loss = 0.00897166
Iteration 3292, loss = 0.00896820
Iteration 3293, loss = 0.00896337
Iteration 3294, loss = 0.00896062
Iteration 3295, loss = 0.00895612
Iteration 3296, loss = 0.00895272
Iteration 3297, loss = 0.00894897
Iteration 3298, loss = 0.00894485
Iteration 3299, loss = 0.00894180
Iteration 3300, loss = 0.00893777
Iteration 3301, loss = 0.00893240
Iteration 3302, loss = 0.00892877
Iteration 3303, loss = 0.00892437
Iteration 3304, loss = 0.00892144
Iteration 3305, loss = 0.00891636
Iteration 3306, loss = 0.00891196
Iteration 3307, loss = 0.00890843
Iteration 3308, loss = 0.00890419
Iteration 3309, loss = 0.00890066
Iteration 3310, loss = 0.00889731
Iteration 3311, loss = 0.00889315
Iteration 3312, loss = 0.00888998
Iteration 3313, loss = 0.00888585
Iteration 3314, loss = 0.00888237
Iteration 3315, loss = 0.00887851
Iteration 3316, loss = 0.00887505
Iteration 3317, loss = 0.00887107
Iteration 3318, loss = 0.00886761
Iteration 3319, loss = 0.00886387
Iteration 3320, loss = 0.00886051
Iteration 3321, loss = 0.00885744
Iteration 3322, loss = 0.00885526
Iteration 3323, loss = 0.00885115
Iteration 3324, loss = 0.00884756
Iteration 3325, loss = 0.00884439
Iteration 3326, loss = 0.00884062
Iteration 3327, loss = 0.00883735
Iteration 3328, loss = 0.00883424
Iteration 3329, loss = 0.00883071
Iteration 3330, loss = 0.00882694
Iteration 3331, loss = 0.00882346
Iteration 3332, loss = 0.00881992
Iteration 3333, loss = 0.00881674
Iteration 3334, loss = 0.00881294
Iteration 3335, loss = 0.00880938
Iteration 3336, loss = 0.00880554
Iteration 3337, loss = 0.00880189
Iteration 3338, loss = 0.00879828
Iteration 3339, loss = 0.00879476
Iteration 3340, loss = 0.00879137
Iteration 3341, loss = 0.00878835
Iteration 3342, loss = 0.00878448
Iteration 3343, loss = 0.00878123
Iteration 3344, loss = 0.00877842
Iteration 3345, loss = 0.00877499
Iteration 3346, loss = 0.00877132
Iteration 3347, loss = 0.00876832
Iteration 3348, loss = 0.00876451
Iteration 3349, loss = 0.00876104
Iteration 3350, loss = 0.00875800
Iteration 3351, loss = 0.00875483
Iteration 3352, loss = 0.00875096
Iteration 3353, loss = 0.00874762
Iteration 3354, loss = 0.00874475
Iteration 3355, loss = 0.00874074
Iteration 3356, loss = 0.00873692
Iteration 3357, loss = 0.00873385
Iteration 3358, loss = 0.00872992
Iteration 3359, loss = 0.00872642
Iteration 3360, loss = 0.00872336
Iteration 3361, loss = 0.00871983
Iteration 3362, loss = 0.00871701
Iteration 3363, loss = 0.00871207
Iteration 3364, loss = 0.00870807
Iteration 3365, loss = 0.00870397
Iteration 3366, loss = 0.00870123
Iteration 3367, loss = 0.00869816
Iteration 3368, loss = 0.00869334
Iteration 3369, loss = 0.00868981
Iteration 3370, loss = 0.00868659
Iteration 3371, loss = 0.00868307
Iteration 3372, loss = 0.00867957
Iteration 3373, loss = 0.00867683
Iteration 3374, loss = 0.00867282
Iteration 3375, loss = 0.00866950
Iteration 3376, loss = 0.00866527
Iteration 3377, loss = 0.00866142
Iteration 3378, loss = 0.00865784
Iteration 3379, loss = 0.00865442
Iteration 3380, loss = 0.00864999
Iteration 3381, loss = 0.00864640
Iteration 3382, loss = 0.00864292
Iteration 3383, loss = 0.00863884
Iteration 3384, loss = 0.00863469
Iteration 3385, loss = 0.00863186
Iteration 3386, loss = 0.00862799
Iteration 3387, loss = 0.00862413
Iteration 3388, loss = 0.00862074
Iteration 3389, loss = 0.00861674
Iteration 3390, loss = 0.00861353
Iteration 3391, loss = 0.00860985
Iteration 3392, loss = 0.00860678
Iteration 3393, loss = 0.00860339
Iteration 3394, loss = 0.00859928
Iteration 3395, loss = 0.00859578
Iteration 3396, loss = 0.00859307
Iteration 3397, loss = 0.00858909
Iteration 3398, loss = 0.00858600
Iteration 3399, loss = 0.00858218
Iteration 3400, loss = 0.00857955
Iteration 3401, loss = 0.00857551
Iteration 3402, loss = 0.00857242
Iteration 3403, loss = 0.00856846
Iteration 3404, loss = 0.00856483
Iteration 3405, loss = 0.00856167
Iteration 3406, loss = 0.00855850
Iteration 3407, loss = 0.00855513
Iteration 3408, loss = 0.00855143
Iteration 3409, loss = 0.00854814
Iteration 3410, loss = 0.00854548
Iteration 3411, loss = 0.00854168
Iteration 3412, loss = 0.00853830
Iteration 3413, loss = 0.00853519
Iteration 3414, loss = 0.00853194
Iteration 3415, loss = 0.00852880
Iteration 3416, loss = 0.00852594
Iteration 3417, loss = 0.00852249
Iteration 3418, loss = 0.00851929
Iteration 3419, loss = 0.00851597
Iteration 3420, loss = 0.00851284
Iteration 3421, loss = 0.00850983
Iteration 3422, loss = 0.00850685
Iteration 3423, loss = 0.00850355
Iteration 3424, loss = 0.00850027
Iteration 3425, loss = 0.00849747
Iteration 3426, loss = 0.00849427
Iteration 3427, loss = 0.00849150
Iteration 3428, loss = 0.00848724
Iteration 3429, loss = 0.00848467
Iteration 3430, loss = 0.00848061
Iteration 3431, loss = 0.00847734
Iteration 3432, loss = 0.00847451
Iteration 3433, loss = 0.00847168
Iteration 3434, loss = 0.00846751
Iteration 3435, loss = 0.00846410
Iteration 3436, loss = 0.00846072
Iteration 3437, loss = 0.00845809
Iteration 3438, loss = 0.00845428
Iteration 3439, loss = 0.00845113
Iteration 3440, loss = 0.00844793
Iteration 3441, loss = 0.00844486
Iteration 3442, loss = 0.00844190
Iteration 3443, loss = 0.00843889
Iteration 3444, loss = 0.00843599
Iteration 3445, loss = 0.00843228
Iteration 3446, loss = 0.00842912
Iteration 3447, loss = 0.00842589
Iteration 3448, loss = 0.00842286
Iteration 3449, loss = 0.00841970
Iteration 3450, loss = 0.00841647
Iteration 3451, loss = 0.00841537
Iteration 3452, loss = 0.00841021
Iteration 3453, loss = 0.00840674
Iteration 3454, loss = 0.00840400
Iteration 3455, loss = 0.00840033
Iteration 3456, loss = 0.00839738
Iteration 3457, loss = 0.00839360
Iteration 3458, loss = 0.00839036
Iteration 3459, loss = 0.00838696
Iteration 3460, loss = 0.00838378
Iteration 3461, loss = 0.00838069
Iteration 3462, loss = 0.00837773
Iteration 3463, loss = 0.00837461
Iteration 3464, loss = 0.00837121
Iteration 3465, loss = 0.00836843
Iteration 3466, loss = 0.00836529
Iteration 3467, loss = 0.00836215
Iteration 3468, loss = 0.00835925
Iteration 3469, loss = 0.00835608
Iteration 3470, loss = 0.00835466
Iteration 3471, loss = 0.00835040
Iteration 3472, loss = 0.00834753
Iteration 3473, loss = 0.00834344
Iteration 3474, loss = 0.00833999
Iteration 3475, loss = 0.00833635
Iteration 3476, loss = 0.00833292
Iteration 3477, loss = 0.00832954
Iteration 3478, loss = 0.00832630
Iteration 3479, loss = 0.00832219
Iteration 3480, loss = 0.00831918
Iteration 3481, loss = 0.00831557
Iteration 3482, loss = 0.00831279
Iteration 3483, loss = 0.00830944
Iteration 3484, loss = 0.00830659
Iteration 3485, loss = 0.00830341
Iteration 3486, loss = 0.00830048
Iteration 3487, loss = 0.00829757
Iteration 3488, loss = 0.00829409
Iteration 3489, loss = 0.00829188
Iteration 3490, loss = 0.00828800
Iteration 3491, loss = 0.00828455
Iteration 3492, loss = 0.00828176
Iteration 3493, loss = 0.00827803
Iteration 3494, loss = 0.00827535
Iteration 3495, loss = 0.00827216
Iteration 3496, loss = 0.00826897
Iteration 3497, loss = 0.00826606
Iteration 3498, loss = 0.00826261
Iteration 3499, loss = 0.00826010
Iteration 3500, loss = 0.00825718
Iteration 3501, loss = 0.00825338
Iteration 3502, loss = 0.00825041
Iteration 3503, loss = 0.00824711
Iteration 3504, loss = 0.00824418
Iteration 3505, loss = 0.00824087
Iteration 3506, loss = 0.00823750
Iteration 3507, loss = 0.00823646
Iteration 3508, loss = 0.00823218
Iteration 3509, loss = 0.00822913
Iteration 3510, loss = 0.00822586
Iteration 3511, loss = 0.00822242
Iteration 3512, loss = 0.00822010
Iteration 3513, loss = 0.00821674
Iteration 3514, loss = 0.00821483
Iteration 3515, loss = 0.00821097
Iteration 3516, loss = 0.00820790
Iteration 3517, loss = 0.00820589
Iteration 3518, loss = 0.00820207
Iteration 3519, loss = 0.00819914
Iteration 3520, loss = 0.00819602
Iteration 3521, loss = 0.00819282
Iteration 3522, loss = 0.00818963
Iteration 3523, loss = 0.00818665
Iteration 3524, loss = 0.00818312
Iteration 3525, loss = 0.00818024
Iteration 3526, loss = 0.00817812
Iteration 3527, loss = 0.00817362
Iteration 3528, loss = 0.00817061
Iteration 3529, loss = 0.00816688
Iteration 3530, loss = 0.00816427
Iteration 3531, loss = 0.00816097
Iteration 3532, loss = 0.00815659
Iteration 3533, loss = 0.00815360
Iteration 3534, loss = 0.00814953
Iteration 3535, loss = 0.00814674
Iteration 3536, loss = 0.00814298
Iteration 3537, loss = 0.00813930
Iteration 3538, loss = 0.00813654
Iteration 3539, loss = 0.00813430
Iteration 3540, loss = 0.00813037
Iteration 3541, loss = 0.00812697
Iteration 3542, loss = 0.00812400
Iteration 3543, loss = 0.00812129
Iteration 3544, loss = 0.00811815
Iteration 3545, loss = 0.00811507
Iteration 3546, loss = 0.00811242
Iteration 3547, loss = 0.00810957
Iteration 3548, loss = 0.00810650
Iteration 3549, loss = 0.00810363
Iteration 3550, loss = 0.00810019
Iteration 3551, loss = 0.00809715
Iteration 3552, loss = 0.00809379
Iteration 3553, loss = 0.00809062
Iteration 3554, loss = 0.00808784
Iteration 3555, loss = 0.00808443
Iteration 3556, loss = 0.00808177
Iteration 3557, loss = 0.00807834
Iteration 3558, loss = 0.00807476
Iteration 3559, loss = 0.00807209
Iteration 3560, loss = 0.00806917
Iteration 3561, loss = 0.00806623
Iteration 3562, loss = 0.00806305
Iteration 3563, loss = 0.00805991
Iteration 3564, loss = 0.00805752
Iteration 3565, loss = 0.00805443
Iteration 3566, loss = 0.00805140
Iteration 3567, loss = 0.00804867
Iteration 3568, loss = 0.00804620
Iteration 3569, loss = 0.00804418
Iteration 3570, loss = 0.00803937
Iteration 3571, loss = 0.00803662
Iteration 3572, loss = 0.00803283
Iteration 3573, loss = 0.00802941
Iteration 3574, loss = 0.00802689
Iteration 3575, loss = 0.00802292
Iteration 3576, loss = 0.00801923
Iteration 3577, loss = 0.00801570
Iteration 3578, loss = 0.00801285
Iteration 3579, loss = 0.00800949
Iteration 3580, loss = 0.00800695
Iteration 3581, loss = 0.00800366
Iteration 3582, loss = 0.00800048
Iteration 3583, loss = 0.00799758
Iteration 3584, loss = 0.00799411
Iteration 3585, loss = 0.00799132
Iteration 3586, loss = 0.00798798
Iteration 3587, loss = 0.00798508
Iteration 3588, loss = 0.00798243
Iteration 3589, loss = 0.00797961
Iteration 3590, loss = 0.00797660
Iteration 3591, loss = 0.00797401
Iteration 3592, loss = 0.00797097
Iteration 3593, loss = 0.00796823
Iteration 3594, loss = 0.00796550
Iteration 3595, loss = 0.00796162
Iteration 3596, loss = 0.00795901
Iteration 3597, loss = 0.00795637
Iteration 3598, loss = 0.00795295
Iteration 3599, loss = 0.00794977
Iteration 3600, loss = 0.00794701
Iteration 3601, loss = 0.00794397
Iteration 3602, loss = 0.00794124
Iteration 3603, loss = 0.00793803
Iteration 3604, loss = 0.00793538
Iteration 3605, loss = 0.00793279
Iteration 3606, loss = 0.00792992
Iteration 3607, loss = 0.00792656
Iteration 3608, loss = 0.00792405
Iteration 3609, loss = 0.00792074
Iteration 3610, loss = 0.00791801
Iteration 3611, loss = 0.00791563
Iteration 3612, loss = 0.00791313
Iteration 3613, loss = 0.00791043
Iteration 3614, loss = 0.00790803
Iteration 3615, loss = 0.00790632
Iteration 3616, loss = 0.00790373
Iteration 3617, loss = 0.00790164
Iteration 3618, loss = 0.00789974
Iteration 3619, loss = 0.00789700
Iteration 3620, loss = 0.00789420
Iteration 3621, loss = 0.00789180
Iteration 3622, loss = 0.00788876
Iteration 3623, loss = 0.00788578
Iteration 3624, loss = 0.00788311
Iteration 3625, loss = 0.00788047
Iteration 3626, loss = 0.00787725
Iteration 3627, loss = 0.00787512
Iteration 3628, loss = 0.00787197
Iteration 3629, loss = 0.00786945
Iteration 3630, loss = 0.00786641
Iteration 3631, loss = 0.00786345
Iteration 3632, loss = 0.00786083
Iteration 3633, loss = 0.00785819
Iteration 3634, loss = 0.00785533
Iteration 3635, loss = 0.00785283
Iteration 3636, loss = 0.00785101
Iteration 3637, loss = 0.00784791
Iteration 3638, loss = 0.00784491
Iteration 3639, loss = 0.00784378
Iteration 3640, loss = 0.00783980
Iteration 3641, loss = 0.00783610
Iteration 3642, loss = 0.00783229
Iteration 3643, loss = 0.00782902
Iteration 3644, loss = 0.00782591
Iteration 3645, loss = 0.00782289
Iteration 3646, loss = 0.00782022
Iteration 3647, loss = 0.00781616
Iteration 3648, loss = 0.00781352
Iteration 3649, loss = 0.00781065
Iteration 3650, loss = 0.00780713
Iteration 3651, loss = 0.00780471
Iteration 3652, loss = 0.00780099
Iteration 3653, loss = 0.00779767
Iteration 3654, loss = 0.00779470
Iteration 3655, loss = 0.00779170
Iteration 3656, loss = 0.00778878
Iteration 3657, loss = 0.00778620
Iteration 3658, loss = 0.00778314
Iteration 3659, loss = 0.00778017
Iteration 3660, loss = 0.00777750
Iteration 3661, loss = 0.00777418
Iteration 3662, loss = 0.00777027
Iteration 3663, loss = 0.00776823
Iteration 3664, loss = 0.00776501
Iteration 3665, loss = 0.00776148
Iteration 3666, loss = 0.00775869
Iteration 3667, loss = 0.00775548
Iteration 3668, loss = 0.00775259
Iteration 3669, loss = 0.00774991
Iteration 3670, loss = 0.00774721
Iteration 3671, loss = 0.00774441
Iteration 3672, loss = 0.00774169
Iteration 3673, loss = 0.00773958
Iteration 3674, loss = 0.00773684
Iteration 3675, loss = 0.00773397
Iteration 3676, loss = 0.00773115
Iteration 3677, loss = 0.00772804
Iteration 3678, loss = 0.00772587
Iteration 3679, loss = 0.00772288
Iteration 3680, loss = 0.00772093
Iteration 3681, loss = 0.00771823
Iteration 3682, loss = 0.00771602
Iteration 3683, loss = 0.00771498
Iteration 3684, loss = 0.00771108
Iteration 3685, loss = 0.00770800
Iteration 3686, loss = 0.00770517
Iteration 3687, loss = 0.00770261
Iteration 3688, loss = 0.00769957
Iteration 3689, loss = 0.00769731
Iteration 3690, loss = 0.00769445
Iteration 3691, loss = 0.00769181
Iteration 3692, loss = 0.00768908
Iteration 3693, loss = 0.00768689
Iteration 3694, loss = 0.00768468
Iteration 3695, loss = 0.00768220
Iteration 3696, loss = 0.00767961
Iteration 3697, loss = 0.00767734
Iteration 3698, loss = 0.00767501
Iteration 3699, loss = 0.00767182
Iteration 3700, loss = 0.00766883
Iteration 3701, loss = 0.00766685
Iteration 3702, loss = 0.00766302
Iteration 3703, loss = 0.00766016
Iteration 3704, loss = 0.00765710
Iteration 3705, loss = 0.00765396
Iteration 3706, loss = 0.00765105
Iteration 3707, loss = 0.00764792
Iteration 3708, loss = 0.00764566
Iteration 3709, loss = 0.00764275
Iteration 3710, loss = 0.00764020
Iteration 3711, loss = 0.00763736
Iteration 3712, loss = 0.00763462
Iteration 3713, loss = 0.00763218
Iteration 3714, loss = 0.00763009
Iteration 3715, loss = 0.00762727
Iteration 3716, loss = 0.00762520
Iteration 3717, loss = 0.00762292
Iteration 3718, loss = 0.00762057
Iteration 3719, loss = 0.00761748
Iteration 3720, loss = 0.00761445
Iteration 3721, loss = 0.00761108
Iteration 3722, loss = 0.00760978
Iteration 3723, loss = 0.00760671
Iteration 3724, loss = 0.00760313
Iteration 3725, loss = 0.00760119
Iteration 3726, loss = 0.00759806
Iteration 3727, loss = 0.00759565
Iteration 3728, loss = 0.00759336
Iteration 3729, loss = 0.00759169
Iteration 3730, loss = 0.00758801
Iteration 3731, loss = 0.00758494
Iteration 3732, loss = 0.00758176
Iteration 3733, loss = 0.00757904
Iteration 3734, loss = 0.00757612
Iteration 3735, loss = 0.00757279
Iteration 3736, loss = 0.00757034
Iteration 3737, loss = 0.00756768
Iteration 3738, loss = 0.00756414
Iteration 3739, loss = 0.00756055
Iteration 3740, loss = 0.00755763
Iteration 3741, loss = 0.00755529
Iteration 3742, loss = 0.00755152
Iteration 3743, loss = 0.00754889
Iteration 3744, loss = 0.00754640
Iteration 3745, loss = 0.00754257
Iteration 3746, loss = 0.00754025
Iteration 3747, loss = 0.00753737
Iteration 3748, loss = 0.00753472
Iteration 3749, loss = 0.00753226
Iteration 3750, loss = 0.00752980
Iteration 3751, loss = 0.00752792
Iteration 3752, loss = 0.00752504
Iteration 3753, loss = 0.00752351
Iteration 3754, loss = 0.00752004
Iteration 3755, loss = 0.00751723
Iteration 3756, loss = 0.00751505
Iteration 3757, loss = 0.00751198
Iteration 3758, loss = 0.00750967
Iteration 3759, loss = 0.00750669
Iteration 3760, loss = 0.00750346
Iteration 3761, loss = 0.00750043
Iteration 3762, loss = 0.00749719
Iteration 3763, loss = 0.00749478
Iteration 3764, loss = 0.00749137
Iteration 3765, loss = 0.00748881
Iteration 3766, loss = 0.00748577
Iteration 3767, loss = 0.00748310
Iteration 3768, loss = 0.00748025
Iteration 3769, loss = 0.00747746
Iteration 3770, loss = 0.00747477
Iteration 3771, loss = 0.00747236
Iteration 3772, loss = 0.00747031
Iteration 3773, loss = 0.00746722
Iteration 3774, loss = 0.00746407
Iteration 3775, loss = 0.00746161
Iteration 3776, loss = 0.00745959
Iteration 3777, loss = 0.00745668
Iteration 3778, loss = 0.00745365
Iteration 3779, loss = 0.00745107
Iteration 3780, loss = 0.00744858
Iteration 3781, loss = 0.00744601
Iteration 3782, loss = 0.00744360
Iteration 3783, loss = 0.00744098
Iteration 3784, loss = 0.00743871
Iteration 3785, loss = 0.00743645
Iteration 3786, loss = 0.00743378
Iteration 3787, loss = 0.00743160
Iteration 3788, loss = 0.00742890
Iteration 3789, loss = 0.00742700
Iteration 3790, loss = 0.00742403
Iteration 3791, loss = 0.00742140
Iteration 3792, loss = 0.00741915
Iteration 3793, loss = 0.00741686
Iteration 3794, loss = 0.00741440
Iteration 3795, loss = 0.00741227
Iteration 3796, loss = 0.00741000
Iteration 3797, loss = 0.00740793
Iteration 3798, loss = 0.00740588
Iteration 3799, loss = 0.00740342
Iteration 3800, loss = 0.00740057
Iteration 3801, loss = 0.00739790
Iteration 3802, loss = 0.00739564
Iteration 3803, loss = 0.00739303
Iteration 3804, loss = 0.00739065
Iteration 3805, loss = 0.00738769
Iteration 3806, loss = 0.00738501
Iteration 3807, loss = 0.00738237
Iteration 3808, loss = 0.00738036
Iteration 3809, loss = 0.00737729
Iteration 3810, loss = 0.00737492
Iteration 3811, loss = 0.00737252
Iteration 3812, loss = 0.00737006
Iteration 3813, loss = 0.00736724
Iteration 3814, loss = 0.00736520
Iteration 3815, loss = 0.00736237
Iteration 3816, loss = 0.00735991
Iteration 3817, loss = 0.00735820
Iteration 3818, loss = 0.00735514
Iteration 3819, loss = 0.00735296
Iteration 3820, loss = 0.00735049
Iteration 3821, loss = 0.00734835
Iteration 3822, loss = 0.00734596
Iteration 3823, loss = 0.00734344
Iteration 3824, loss = 0.00734088
Iteration 3825, loss = 0.00733901
Iteration 3826, loss = 0.00733680
Iteration 3827, loss = 0.00733472
Iteration 3828, loss = 0.00733245
Iteration 3829, loss = 0.00733045
Iteration 3830, loss = 0.00732905
Iteration 3831, loss = 0.00732672
Iteration 3832, loss = 0.00732492
Iteration 3833, loss = 0.00732292
Iteration 3834, loss = 0.00732023
Iteration 3835, loss = 0.00731822
Iteration 3836, loss = 0.00731435
Iteration 3837, loss = 0.00731165
Iteration 3838, loss = 0.00730882
Iteration 3839, loss = 0.00730708
Iteration 3840, loss = 0.00730297
Iteration 3841, loss = 0.00730049
Iteration 3842, loss = 0.00729757
Iteration 3843, loss = 0.00729522
Iteration 3844, loss = 0.00729321
Iteration 3845, loss = 0.00729033
Iteration 3846, loss = 0.00728757
Iteration 3847, loss = 0.00728542
Iteration 3848, loss = 0.00728241
Iteration 3849, loss = 0.00727994
Iteration 3850, loss = 0.00727723
Iteration 3851, loss = 0.00727518
Iteration 3852, loss = 0.00727236
Iteration 3853, loss = 0.00726980
Iteration 3854, loss = 0.00726723
Iteration 3855, loss = 0.00726444
Iteration 3856, loss = 0.00726235
Iteration 3857, loss = 0.00726053
Iteration 3858, loss = 0.00725658
Iteration 3859, loss = 0.00725493
Iteration 3860, loss = 0.00725175
Iteration 3861, loss = 0.00724902
Iteration 3862, loss = 0.00724701
Iteration 3863, loss = 0.00724462
Iteration 3864, loss = 0.00724209
Iteration 3865, loss = 0.00724011
Iteration 3866, loss = 0.00723686
Iteration 3867, loss = 0.00723413
Iteration 3868, loss = 0.00723178
Iteration 3869, loss = 0.00722904
Iteration 3870, loss = 0.00722687
Iteration 3871, loss = 0.00722449
Iteration 3872, loss = 0.00722287
Iteration 3873, loss = 0.00722024
Iteration 3874, loss = 0.00721778
Iteration 3875, loss = 0.00721533
Iteration 3876, loss = 0.00721281
Iteration 3877, loss = 0.00721020
Iteration 3878, loss = 0.00720811
Iteration 3879, loss = 0.00720545
Iteration 3880, loss = 0.00720321
Iteration 3881, loss = 0.00720108
Iteration 3882, loss = 0.00719853
Iteration 3883, loss = 0.00719569
Iteration 3884, loss = 0.00719297
Iteration 3885, loss = 0.00719017
Iteration 3886, loss = 0.00718776
Iteration 3887, loss = 0.00718505
Iteration 3888, loss = 0.00718266
Iteration 3889, loss = 0.00718040
Iteration 3890, loss = 0.00717810
Iteration 3891, loss = 0.00717562
Iteration 3892, loss = 0.00717344
Iteration 3893, loss = 0.00717125
Iteration 3894, loss = 0.00716880
Iteration 3895, loss = 0.00716640
Iteration 3896, loss = 0.00716474
Iteration 3897, loss = 0.00716180
Iteration 3898, loss = 0.00715895
Iteration 3899, loss = 0.00715628
Iteration 3900, loss = 0.00715430
Iteration 3901, loss = 0.00715124
Iteration 3902, loss = 0.00714892
Iteration 3903, loss = 0.00714708
Iteration 3904, loss = 0.00714475
Iteration 3905, loss = 0.00714229
Iteration 3906, loss = 0.00714011
Iteration 3907, loss = 0.00713790
Iteration 3908, loss = 0.00713585
Iteration 3909, loss = 0.00713367
Iteration 3910, loss = 0.00713136
Iteration 3911, loss = 0.00712899
Iteration 3912, loss = 0.00712728
Iteration 3913, loss = 0.00712428
Iteration 3914, loss = 0.00712179
Iteration 3915, loss = 0.00711896
Iteration 3916, loss = 0.00711639
Iteration 3917, loss = 0.00711218
Iteration 3918, loss = 0.00711068
Iteration 3919, loss = 0.00710665
Iteration 3920, loss = 0.00710364
Iteration 3921, loss = 0.00710084
Iteration 3922, loss = 0.00709951
Iteration 3923, loss = 0.00709610
Iteration 3924, loss = 0.00709371
Iteration 3925, loss = 0.00709042
Iteration 3926, loss = 0.00708754
Iteration 3927, loss = 0.00708409
Iteration 3928, loss = 0.00708167
Iteration 3929, loss = 0.00707822
Iteration 3930, loss = 0.00707478
Iteration 3931, loss = 0.00707119
Iteration 3932, loss = 0.00706824
Iteration 3933, loss = 0.00706786
Iteration 3934, loss = 0.00706461
Iteration 3935, loss = 0.00706086
Iteration 3936, loss = 0.00705806
Iteration 3937, loss = 0.00705551
Iteration 3938, loss = 0.00705247
Iteration 3939, loss = 0.00704953
Iteration 3940, loss = 0.00704786
Iteration 3941, loss = 0.00704468
Iteration 3942, loss = 0.00704189
Iteration 3943, loss = 0.00703881
Iteration 3944, loss = 0.00703667
Iteration 3945, loss = 0.00703458
Iteration 3946, loss = 0.00703142
Iteration 3947, loss = 0.00702879
Iteration 3948, loss = 0.00702645
Iteration 3949, loss = 0.00702399
Iteration 3950, loss = 0.00702174
Iteration 3951, loss = 0.00701934
Iteration 3952, loss = 0.00701706
Iteration 3953, loss = 0.00701458
Iteration 3954, loss = 0.00701255
Iteration 3955, loss = 0.00701008
Iteration 3956, loss = 0.00700783
Iteration 3957, loss = 0.00700577
Iteration 3958, loss = 0.00700372
Iteration 3959, loss = 0.00700132
Iteration 3960, loss = 0.00699941
Iteration 3961, loss = 0.00699714
Iteration 3962, loss = 0.00699489
Iteration 3963, loss = 0.00699255
Iteration 3964, loss = 0.00698993
Iteration 3965, loss = 0.00698804
Iteration 3966, loss = 0.00698622
Iteration 3967, loss = 0.00698337
Iteration 3968, loss = 0.00698053
Iteration 3969, loss = 0.00697801
Iteration 3970, loss = 0.00697549
Iteration 3971, loss = 0.00697311
Iteration 3972, loss = 0.00697056
Iteration 3973, loss = 0.00696800
Iteration 3974, loss = 0.00696513
Iteration 3975, loss = 0.00696281
Iteration 3976, loss = 0.00696117
Iteration 3977, loss = 0.00695810
Iteration 3978, loss = 0.00695541
Iteration 3979, loss = 0.00695381
Iteration 3980, loss = 0.00695082
Iteration 3981, loss = 0.00694891
Iteration 3982, loss = 0.00694639
Iteration 3983, loss = 0.00694568
Iteration 3984, loss = 0.00694208
Iteration 3985, loss = 0.00693965
Iteration 3986, loss = 0.00693728
Iteration 3987, loss = 0.00693503
Iteration 3988, loss = 0.00693247
Iteration 3989, loss = 0.00693017
Iteration 3990, loss = 0.00692805
Iteration 3991, loss = 0.00692521
Iteration 3992, loss = 0.00692316
Iteration 3993, loss = 0.00692031
Iteration 3994, loss = 0.00691772
Iteration 3995, loss = 0.00691637
Iteration 3996, loss = 0.00691327
Iteration 3997, loss = 0.00691091
Iteration 3998, loss = 0.00690856
Iteration 3999, loss = 0.00690624
Iteration 4000, loss = 0.00690485
Iteration 4001, loss = 0.00690161
Iteration 4002, loss = 0.00689963
Iteration 4003, loss = 0.00689716
Iteration 4004, loss = 0.00689477
Iteration 4005, loss = 0.00689241
Iteration 4006, loss = 0.00688994
Iteration 4007, loss = 0.00688791
Iteration 4008, loss = 0.00688497
Iteration 4009, loss = 0.00688250
Iteration 4010, loss = 0.00688006
Iteration 4011, loss = 0.00687733
Iteration 4012, loss = 0.00687475
Iteration 4013, loss = 0.00687263
Iteration 4014, loss = 0.00686966
Iteration 4015, loss = 0.00686757
Iteration 4016, loss = 0.00686523
Iteration 4017, loss = 0.00686237
Iteration 4018, loss = 0.00686015
Iteration 4019, loss = 0.00685766
Iteration 4020, loss = 0.00685537
Iteration 4021, loss = 0.00685296
Iteration 4022, loss = 0.00685074
Iteration 4023, loss = 0.00684904
Iteration 4024, loss = 0.00684648
Iteration 4025, loss = 0.00684429
Iteration 4026, loss = 0.00684267
Iteration 4027, loss = 0.00684068
Iteration 4028, loss = 0.00683815
Iteration 4029, loss = 0.00683592
Iteration 4030, loss = 0.00683395
Iteration 4031, loss = 0.00683162
Iteration 4032, loss = 0.00682931
Iteration 4033, loss = 0.00682761
Iteration 4034, loss = 0.00682561
Iteration 4035, loss = 0.00682306
Iteration 4036, loss = 0.00682044
Iteration 4037, loss = 0.00681779
Iteration 4038, loss = 0.00681571
Iteration 4039, loss = 0.00681398
Iteration 4040, loss = 0.00681077
Iteration 4041, loss = 0.00680830
Iteration 4042, loss = 0.00680594
Iteration 4043, loss = 0.00680404
Iteration 4044, loss = 0.00680129
Iteration 4045, loss = 0.00679874
Iteration 4046, loss = 0.00679656
Iteration 4047, loss = 0.00679448
Iteration 4048, loss = 0.00679235
Iteration 4049, loss = 0.00678991
Iteration 4050, loss = 0.00678795
Iteration 4051, loss = 0.00678551
Iteration 4052, loss = 0.00678319
Iteration 4053, loss = 0.00678099
Iteration 4054, loss = 0.00677868
Iteration 4055, loss = 0.00677615
Iteration 4056, loss = 0.00677395
Iteration 4057, loss = 0.00677156
Iteration 4058, loss = 0.00676965
Iteration 4059, loss = 0.00676836
Iteration 4060, loss = 0.00676520
Iteration 4061, loss = 0.00676330
Iteration 4062, loss = 0.00676101
Iteration 4063, loss = 0.00675889
Iteration 4064, loss = 0.00675703
Iteration 4065, loss = 0.00675384
Iteration 4066, loss = 0.00675127
Iteration 4067, loss = 0.00675013
Iteration 4068, loss = 0.00674700
Iteration 4069, loss = 0.00674441
Iteration 4070, loss = 0.00674246
Iteration 4071, loss = 0.00674035
Iteration 4072, loss = 0.00673802
Iteration 4073, loss = 0.00673578
Iteration 4074, loss = 0.00673361
Iteration 4075, loss = 0.00673153
Iteration 4076, loss = 0.00672913
Iteration 4077, loss = 0.00672682
Iteration 4078, loss = 0.00672431
Iteration 4079, loss = 0.00672229
Iteration 4080, loss = 0.00671995
Iteration 4081, loss = 0.00671761
Iteration 4082, loss = 0.00671570
Iteration 4083, loss = 0.00671373
Iteration 4084, loss = 0.00671173
Iteration 4085, loss = 0.00670971
Iteration 4086, loss = 0.00670764
Iteration 4087, loss = 0.00670542
Iteration 4088, loss = 0.00670272
Iteration 4089, loss = 0.00670088
Iteration 4090, loss = 0.00669834
Iteration 4091, loss = 0.00669632
Iteration 4092, loss = 0.00669374
Iteration 4093, loss = 0.00669211
Iteration 4094, loss = 0.00669008
Iteration 4095, loss = 0.00668791
Iteration 4096, loss = 0.00668624
Iteration 4097, loss = 0.00668520
Iteration 4098, loss = 0.00668251
Iteration 4099, loss = 0.00668048
Iteration 4100, loss = 0.00667899
Iteration 4101, loss = 0.00667688
Iteration 4102, loss = 0.00667495
Iteration 4103, loss = 0.00667286
Iteration 4104, loss = 0.00667119
Iteration 4105, loss = 0.00666916
Iteration 4106, loss = 0.00666724
Iteration 4107, loss = 0.00666574
Iteration 4108, loss = 0.00666366
Iteration 4109, loss = 0.00666154
Iteration 4110, loss = 0.00665934
Iteration 4111, loss = 0.00665716
Iteration 4112, loss = 0.00665529
Iteration 4113, loss = 0.00665327
Iteration 4114, loss = 0.00665108
Iteration 4115, loss = 0.00664875
Iteration 4116, loss = 0.00664653
Iteration 4117, loss = 0.00664438
Iteration 4118, loss = 0.00664209
Iteration 4119, loss = 0.00663989
Iteration 4120, loss = 0.00663759
Iteration 4121, loss = 0.00663550
Iteration 4122, loss = 0.00663341
Iteration 4123, loss = 0.00663133
Iteration 4124, loss = 0.00662892
Iteration 4125, loss = 0.00662670
Iteration 4126, loss = 0.00662441
Iteration 4127, loss = 0.00662229
Iteration 4128, loss = 0.00662028
Iteration 4129, loss = 0.00661799
Iteration 4130, loss = 0.00661606
Iteration 4131, loss = 0.00661400
Iteration 4132, loss = 0.00661205
Iteration 4133, loss = 0.00661050
Iteration 4134, loss = 0.00660806
Iteration 4135, loss = 0.00660605
Iteration 4136, loss = 0.00660388
Iteration 4137, loss = 0.00660162
Iteration 4138, loss = 0.00659951
Iteration 4139, loss = 0.00659819
Iteration 4140, loss = 0.00659602
Iteration 4141, loss = 0.00659464
Iteration 4142, loss = 0.00659212
Iteration 4143, loss = 0.00659043
Iteration 4144, loss = 0.00658894
Iteration 4145, loss = 0.00658661
Iteration 4146, loss = 0.00658423
Iteration 4147, loss = 0.00658179
Iteration 4148, loss = 0.00657960
Iteration 4149, loss = 0.00657722
Iteration 4150, loss = 0.00657404
Iteration 4151, loss = 0.00657131
Iteration 4152, loss = 0.00656830
Iteration 4153, loss = 0.00656521
Iteration 4154, loss = 0.00656331
Iteration 4155, loss = 0.00655990
Iteration 4156, loss = 0.00655789
Iteration 4157, loss = 0.00655547
Iteration 4158, loss = 0.00655255
Iteration 4159, loss = 0.00654995
Iteration 4160, loss = 0.00654746
Iteration 4161, loss = 0.00654545
Iteration 4162, loss = 0.00654249
Iteration 4163, loss = 0.00654002
Iteration 4164, loss = 0.00653767
Iteration 4165, loss = 0.00653509
Iteration 4166, loss = 0.00653327
Iteration 4167, loss = 0.00653113
Iteration 4168, loss = 0.00652919
Iteration 4169, loss = 0.00652633
Iteration 4170, loss = 0.00652364
Iteration 4171, loss = 0.00652172
Iteration 4172, loss = 0.00651913
Iteration 4173, loss = 0.00651715
Iteration 4174, loss = 0.00651470
Iteration 4175, loss = 0.00651260
Iteration 4176, loss = 0.00651063
Iteration 4177, loss = 0.00650815
Iteration 4178, loss = 0.00650614
Iteration 4179, loss = 0.00650378
Iteration 4180, loss = 0.00650192
Iteration 4181, loss = 0.00649971
Iteration 4182, loss = 0.00649731
Iteration 4183, loss = 0.00649532
Iteration 4184, loss = 0.00649312
Iteration 4185, loss = 0.00649192
Iteration 4186, loss = 0.00648926
Iteration 4187, loss = 0.00648682
Iteration 4188, loss = 0.00648516
Iteration 4189, loss = 0.00648317
Iteration 4190, loss = 0.00648109
Iteration 4191, loss = 0.00647940
Iteration 4192, loss = 0.00647719
Iteration 4193, loss = 0.00647522
Iteration 4194, loss = 0.00647310
Iteration 4195, loss = 0.00647109
Iteration 4196, loss = 0.00646883
Iteration 4197, loss = 0.00646631
Iteration 4198, loss = 0.00646430
Iteration 4199, loss = 0.00646216
Iteration 4200, loss = 0.00645952
Iteration 4201, loss = 0.00645766
Iteration 4202, loss = 0.00645534
Iteration 4203, loss = 0.00645328
Iteration 4204, loss = 0.00645108
Iteration 4205, loss = 0.00644898
Iteration 4206, loss = 0.00644700
Iteration 4207, loss = 0.00644505
Iteration 4208, loss = 0.00644268
Iteration 4209, loss = 0.00644058
Iteration 4210, loss = 0.00643858
Iteration 4211, loss = 0.00643708
Iteration 4212, loss = 0.00643422
Iteration 4213, loss = 0.00643248
Iteration 4214, loss = 0.00643009
Iteration 4215, loss = 0.00642860
Iteration 4216, loss = 0.00642600
Iteration 4217, loss = 0.00642392
Iteration 4218, loss = 0.00642208
Iteration 4219, loss = 0.00642012
Iteration 4220, loss = 0.00641782
Iteration 4221, loss = 0.00641580
Iteration 4222, loss = 0.00641375
Iteration 4223, loss = 0.00641225
Iteration 4224, loss = 0.00640983
Iteration 4225, loss = 0.00640778
Iteration 4226, loss = 0.00640562
Iteration 4227, loss = 0.00640399
Iteration 4228, loss = 0.00640172
Iteration 4229, loss = 0.00639990
Iteration 4230, loss = 0.00639749
Iteration 4231, loss = 0.00639545
Iteration 4232, loss = 0.00639340
Iteration 4233, loss = 0.00639181
Iteration 4234, loss = 0.00638923
Iteration 4235, loss = 0.00638754
Iteration 4236, loss = 0.00638525
Iteration 4237, loss = 0.00638301
Iteration 4238, loss = 0.00638088
Iteration 4239, loss = 0.00637910
Iteration 4240, loss = 0.00637657
Iteration 4241, loss = 0.00637453
Iteration 4242, loss = 0.00637250
Iteration 4243, loss = 0.00637032
Iteration 4244, loss = 0.00636853
Iteration 4245, loss = 0.00636628
Iteration 4246, loss = 0.00636475
Iteration 4247, loss = 0.00636225
Iteration 4248, loss = 0.00636028
Iteration 4249, loss = 0.00635874
Iteration 4250, loss = 0.00635672
Iteration 4251, loss = 0.00635466
Iteration 4252, loss = 0.00635283
Iteration 4253, loss = 0.00635100
Iteration 4254, loss = 0.00634913
Iteration 4255, loss = 0.00634775
Iteration 4256, loss = 0.00634570
Iteration 4257, loss = 0.00634406
Iteration 4258, loss = 0.00634146
Iteration 4259, loss = 0.00633993
Iteration 4260, loss = 0.00633702
Iteration 4261, loss = 0.00633511
Iteration 4262, loss = 0.00633342
Iteration 4263, loss = 0.00633130
Iteration 4264, loss = 0.00632908
Iteration 4265, loss = 0.00632706
Iteration 4266, loss = 0.00632528
Iteration 4267, loss = 0.00632334
Iteration 4268, loss = 0.00632154
Iteration 4269, loss = 0.00631925
Iteration 4270, loss = 0.00631702
Iteration 4271, loss = 0.00631510
Iteration 4272, loss = 0.00631312
Iteration 4273, loss = 0.00631106
Iteration 4274, loss = 0.00630909
Iteration 4275, loss = 0.00630660
Iteration 4276, loss = 0.00630514
Iteration 4277, loss = 0.00630252
Iteration 4278, loss = 0.00629996
Iteration 4279, loss = 0.00629758
Iteration 4280, loss = 0.00629570
Iteration 4281, loss = 0.00629324
Iteration 4282, loss = 0.00629125
Iteration 4283, loss = 0.00628903
Iteration 4284, loss = 0.00628663
Iteration 4285, loss = 0.00628468
Iteration 4286, loss = 0.00628347
Iteration 4287, loss = 0.00628084
Iteration 4288, loss = 0.00627856
Iteration 4289, loss = 0.00627694
Iteration 4290, loss = 0.00627490
Iteration 4291, loss = 0.00627286
Iteration 4292, loss = 0.00627089
Iteration 4293, loss = 0.00626912
Iteration 4294, loss = 0.00626705
Iteration 4295, loss = 0.00626486
Iteration 4296, loss = 0.00626277
Iteration 4297, loss = 0.00626114
Iteration 4298, loss = 0.00625906
Iteration 4299, loss = 0.00625712
Iteration 4300, loss = 0.00625493
Iteration 4301, loss = 0.00625302
Iteration 4302, loss = 0.00625089
Iteration 4303, loss = 0.00624893
Iteration 4304, loss = 0.00624706
Iteration 4305, loss = 0.00624497
Iteration 4306, loss = 0.00624290
Iteration 4307, loss = 0.00624191
Iteration 4308, loss = 0.00623912
Iteration 4309, loss = 0.00623727
Iteration 4310, loss = 0.00623521
Iteration 4311, loss = 0.00623324
Iteration 4312, loss = 0.00623163
Iteration 4313, loss = 0.00622947
Iteration 4314, loss = 0.00622748
Iteration 4315, loss = 0.00622597
Iteration 4316, loss = 0.00622328
Iteration 4317, loss = 0.00622115
Iteration 4318, loss = 0.00621890
Iteration 4319, loss = 0.00621707
Iteration 4320, loss = 0.00621517
Iteration 4321, loss = 0.00621307
Iteration 4322, loss = 0.00621105
Iteration 4323, loss = 0.00620957
Iteration 4324, loss = 0.00620709
Iteration 4325, loss = 0.00620463
Iteration 4326, loss = 0.00620245
Iteration 4327, loss = 0.00619994
Iteration 4328, loss = 0.00619791
Iteration 4329, loss = 0.00619557
Iteration 4330, loss = 0.00619356
Iteration 4331, loss = 0.00619221
Iteration 4332, loss = 0.00618994
Iteration 4333, loss = 0.00618771
Iteration 4334, loss = 0.00618606
Iteration 4335, loss = 0.00618439
Iteration 4336, loss = 0.00618346
Iteration 4337, loss = 0.00618119
Iteration 4338, loss = 0.00617921
Iteration 4339, loss = 0.00617635
Iteration 4340, loss = 0.00617408
Iteration 4341, loss = 0.00617210
Iteration 4342, loss = 0.00617085
Iteration 4343, loss = 0.00616805
Iteration 4344, loss = 0.00616582
Iteration 4345, loss = 0.00616420
Iteration 4346, loss = 0.00616293
Iteration 4347, loss = 0.00616018
Iteration 4348, loss = 0.00615839
Iteration 4349, loss = 0.00615620
Iteration 4350, loss = 0.00615420
Iteration 4351, loss = 0.00615235
Iteration 4352, loss = 0.00615101
Iteration 4353, loss = 0.00614867
Iteration 4354, loss = 0.00614668
Iteration 4355, loss = 0.00614469
Iteration 4356, loss = 0.00614308
Iteration 4357, loss = 0.00614112
Iteration 4358, loss = 0.00613939
Iteration 4359, loss = 0.00613791
Iteration 4360, loss = 0.00613553
Iteration 4361, loss = 0.00613382
Iteration 4362, loss = 0.00613189
Iteration 4363, loss = 0.00613046
Iteration 4364, loss = 0.00612808
Iteration 4365, loss = 0.00612624
Iteration 4366, loss = 0.00612451
Iteration 4367, loss = 0.00612233
Iteration 4368, loss = 0.00612060
Iteration 4369, loss = 0.00611857
Iteration 4370, loss = 0.00611682
Iteration 4371, loss = 0.00611476
Iteration 4372, loss = 0.00611318
Iteration 4373, loss = 0.00611111
Iteration 4374, loss = 0.00610922
Iteration 4375, loss = 0.00610771
Iteration 4376, loss = 0.00610577
Iteration 4377, loss = 0.00610409
Iteration 4378, loss = 0.00610205
Iteration 4379, loss = 0.00610072
Iteration 4380, loss = 0.00609888
Iteration 4381, loss = 0.00609679
Iteration 4382, loss = 0.00609504
Iteration 4383, loss = 0.00609320
Iteration 4384, loss = 0.00609129
Iteration 4385, loss = 0.00608947
Iteration 4386, loss = 0.00608800
Iteration 4387, loss = 0.00608589
Iteration 4388, loss = 0.00608417
Iteration 4389, loss = 0.00608230
Iteration 4390, loss = 0.00608045
Iteration 4391, loss = 0.00607863
Iteration 4392, loss = 0.00607687
Iteration 4393, loss = 0.00607500
Iteration 4394, loss = 0.00607308
Iteration 4395, loss = 0.00607244
Iteration 4396, loss = 0.00606934
Iteration 4397, loss = 0.00606733
Iteration 4398, loss = 0.00606560
Iteration 4399, loss = 0.00606355
Iteration 4400, loss = 0.00606148
Iteration 4401, loss = 0.00605962
Iteration 4402, loss = 0.00605833
Iteration 4403, loss = 0.00605588
Iteration 4404, loss = 0.00605447
Iteration 4405, loss = 0.00605215
Iteration 4406, loss = 0.00605039
Iteration 4407, loss = 0.00604836
Iteration 4408, loss = 0.00604657
Iteration 4409, loss = 0.00604466
Iteration 4410, loss = 0.00604308
Iteration 4411, loss = 0.00604109
Iteration 4412, loss = 0.00603922
Iteration 4413, loss = 0.00603769
Iteration 4414, loss = 0.00603564
Iteration 4415, loss = 0.00603435
Iteration 4416, loss = 0.00603197
Iteration 4417, loss = 0.00603025
Iteration 4418, loss = 0.00602847
Iteration 4419, loss = 0.00602663
Iteration 4420, loss = 0.00602506
Iteration 4421, loss = 0.00602301
Iteration 4422, loss = 0.00602096
Iteration 4423, loss = 0.00601988
Iteration 4424, loss = 0.00601791
Iteration 4425, loss = 0.00601596
Iteration 4426, loss = 0.00601454
Iteration 4427, loss = 0.00601284
Iteration 4428, loss = 0.00601125
Iteration 4429, loss = 0.00600967
Iteration 4430, loss = 0.00600817
Iteration 4431, loss = 0.00600657
Iteration 4432, loss = 0.00600494
Iteration 4433, loss = 0.00600355
Iteration 4434, loss = 0.00600190
Iteration 4435, loss = 0.00599986
Iteration 4436, loss = 0.00599807
Iteration 4437, loss = 0.00599752
Iteration 4438, loss = 0.00599542
Iteration 4439, loss = 0.00599366
Iteration 4440, loss = 0.00599223
Iteration 4441, loss = 0.00599049
Iteration 4442, loss = 0.00598837
Iteration 4443, loss = 0.00598694
Iteration 4444, loss = 0.00598479
Iteration 4445, loss = 0.00598284
Iteration 4446, loss = 0.00598102
Iteration 4447, loss = 0.00597937
Iteration 4448, loss = 0.00597711
Iteration 4449, loss = 0.00597562
Iteration 4450, loss = 0.00597328
Iteration 4451, loss = 0.00597161
Iteration 4452, loss = 0.00596948
Iteration 4453, loss = 0.00596764
Iteration 4454, loss = 0.00596587
Iteration 4455, loss = 0.00596414
Iteration 4456, loss = 0.00596204
Iteration 4457, loss = 0.00596056
Iteration 4458, loss = 0.00595852
Iteration 4459, loss = 0.00595709
Iteration 4460, loss = 0.00595482
Iteration 4461, loss = 0.00595307
Iteration 4462, loss = 0.00595158
Iteration 4463, loss = 0.00594964
Iteration 4464, loss = 0.00594785
Iteration 4465, loss = 0.00594627
Iteration 4466, loss = 0.00594434
Iteration 4467, loss = 0.00594294
Iteration 4468, loss = 0.00594114
Iteration 4469, loss = 0.00593978
Iteration 4470, loss = 0.00593797
Iteration 4471, loss = 0.00593647
Iteration 4472, loss = 0.00593484
Iteration 4473, loss = 0.00593286
Iteration 4474, loss = 0.00593153
Iteration 4475, loss = 0.00592971
Iteration 4476, loss = 0.00592776
Iteration 4477, loss = 0.00592600
Iteration 4478, loss = 0.00592405
Iteration 4479, loss = 0.00592287
Iteration 4480, loss = 0.00592098
Iteration 4481, loss = 0.00591969
Iteration 4482, loss = 0.00591770
Iteration 4483, loss = 0.00591640
Iteration 4484, loss = 0.00591465
Iteration 4485, loss = 0.00591330
Iteration 4486, loss = 0.00591080
Iteration 4487, loss = 0.00590924
Iteration 4488, loss = 0.00590721
Iteration 4489, loss = 0.00590543
Iteration 4490, loss = 0.00590329
Iteration 4491, loss = 0.00590196
Iteration 4492, loss = 0.00589935
Iteration 4493, loss = 0.00589765
Iteration 4494, loss = 0.00589572
Iteration 4495, loss = 0.00589373
Iteration 4496, loss = 0.00589199
Iteration 4497, loss = 0.00588987
Iteration 4498, loss = 0.00588806
Iteration 4499, loss = 0.00588610
Iteration 4500, loss = 0.00588436
Iteration 4501, loss = 0.00588273
Iteration 4502, loss = 0.00588070
Iteration 4503, loss = 0.00587888
Iteration 4504, loss = 0.00587722
Iteration 4505, loss = 0.00587538
Iteration 4506, loss = 0.00587400
Iteration 4507, loss = 0.00587181
Iteration 4508, loss = 0.00587017
Iteration 4509, loss = 0.00586847
Iteration 4510, loss = 0.00586644
Iteration 4511, loss = 0.00586453
Iteration 4512, loss = 0.00586300
Iteration 4513, loss = 0.00586125
Iteration 4514, loss = 0.00586060
Iteration 4515, loss = 0.00585777
Iteration 4516, loss = 0.00585600
Iteration 4517, loss = 0.00585412
Iteration 4518, loss = 0.00585233
Iteration 4519, loss = 0.00585048
Iteration 4520, loss = 0.00584979
Iteration 4521, loss = 0.00584785
Iteration 4522, loss = 0.00584553
Iteration 4523, loss = 0.00584390
Iteration 4524, loss = 0.00584185
Iteration 4525, loss = 0.00583970
Iteration 4526, loss = 0.00583843
Iteration 4527, loss = 0.00583603
Iteration 4528, loss = 0.00583424
Iteration 4529, loss = 0.00583248
Iteration 4530, loss = 0.00583042
Iteration 4531, loss = 0.00582860
Iteration 4532, loss = 0.00582668
Iteration 4533, loss = 0.00582484
Iteration 4534, loss = 0.00582313
Iteration 4535, loss = 0.00582157
Iteration 4536, loss = 0.00581969
Iteration 4537, loss = 0.00581760
Iteration 4538, loss = 0.00581589
Iteration 4539, loss = 0.00581404
Iteration 4540, loss = 0.00581249
Iteration 4541, loss = 0.00581053
Iteration 4542, loss = 0.00580892
Iteration 4543, loss = 0.00580770
Iteration 4544, loss = 0.00580530
Iteration 4545, loss = 0.00580346
Iteration 4546, loss = 0.00580152
Iteration 4547, loss = 0.00580032
Iteration 4548, loss = 0.00579812
Iteration 4549, loss = 0.00579647
Iteration 4550, loss = 0.00579452
Iteration 4551, loss = 0.00579292
Iteration 4552, loss = 0.00579122
Iteration 4553, loss = 0.00578936
Iteration 4554, loss = 0.00578716
Iteration 4555, loss = 0.00578551
Iteration 4556, loss = 0.00578375
Iteration 4557, loss = 0.00578216
Iteration 4558, loss = 0.00578021
Iteration 4559, loss = 0.00578008
Iteration 4560, loss = 0.00577708
Iteration 4561, loss = 0.00577516
Iteration 4562, loss = 0.00577349
Iteration 4563, loss = 0.00577144
Iteration 4564, loss = 0.00576946
Iteration 4565, loss = 0.00576763
Iteration 4566, loss = 0.00576597
Iteration 4567, loss = 0.00576414
Iteration 4568, loss = 0.00576211
Iteration 4569, loss = 0.00576018
Iteration 4570, loss = 0.00575830
Iteration 4571, loss = 0.00575680
Iteration 4572, loss = 0.00575493
Iteration 4573, loss = 0.00575323
Iteration 4574, loss = 0.00575110
Iteration 4575, loss = 0.00574949
Iteration 4576, loss = 0.00574782
Iteration 4577, loss = 0.00574685
Iteration 4578, loss = 0.00574494
Iteration 4579, loss = 0.00574410
Iteration 4580, loss = 0.00574101
Iteration 4581, loss = 0.00574011
Iteration 4582, loss = 0.00573791
Iteration 4583, loss = 0.00573628
Iteration 4584, loss = 0.00573438
Iteration 4585, loss = 0.00573285
Iteration 4586, loss = 0.00573104
Iteration 4587, loss = 0.00572949
Iteration 4588, loss = 0.00572766
Iteration 4589, loss = 0.00572637
Iteration 4590, loss = 0.00572406
Iteration 4591, loss = 0.00572241
Iteration 4592, loss = 0.00572081
Iteration 4593, loss = 0.00571935
Iteration 4594, loss = 0.00571752
Iteration 4595, loss = 0.00571668
Iteration 4596, loss = 0.00571438
Iteration 4597, loss = 0.00571267
Iteration 4598, loss = 0.00571042
Iteration 4599, loss = 0.00570893
Iteration 4600, loss = 0.00570657
Iteration 4601, loss = 0.00570506
Iteration 4602, loss = 0.00570303
Iteration 4603, loss = 0.00570104
Iteration 4604, loss = 0.00569926
Iteration 4605, loss = 0.00569733
Iteration 4606, loss = 0.00569545
Iteration 4607, loss = 0.00569390
Iteration 4608, loss = 0.00569234
Iteration 4609, loss = 0.00569047
Iteration 4610, loss = 0.00568862
Iteration 4611, loss = 0.00568676
Iteration 4612, loss = 0.00568465
Iteration 4613, loss = 0.00568337
Iteration 4614, loss = 0.00568218
Iteration 4615, loss = 0.00567981
Iteration 4616, loss = 0.00567785
Iteration 4617, loss = 0.00567615
Iteration 4618, loss = 0.00567422
Iteration 4619, loss = 0.00567255
Iteration 4620, loss = 0.00567069
Iteration 4621, loss = 0.00566897
Iteration 4622, loss = 0.00566697
Iteration 4623, loss = 0.00566520
Iteration 4624, loss = 0.00566343
Iteration 4625, loss = 0.00566181
Iteration 4626, loss = 0.00566019
Iteration 4627, loss = 0.00565851
Iteration 4628, loss = 0.00565689
Iteration 4629, loss = 0.00565555
Iteration 4630, loss = 0.00565405
Iteration 4631, loss = 0.00565169
Iteration 4632, loss = 0.00565034
Iteration 4633, loss = 0.00564872
Iteration 4634, loss = 0.00564705
Iteration 4635, loss = 0.00564559
Iteration 4636, loss = 0.00564364
Iteration 4637, loss = 0.00564190
Iteration 4638, loss = 0.00564009
Iteration 4639, loss = 0.00563864
Iteration 4640, loss = 0.00563677
Iteration 4641, loss = 0.00563563
Iteration 4642, loss = 0.00563376
Iteration 4643, loss = 0.00563169
Iteration 4644, loss = 0.00563011
Iteration 4645, loss = 0.00562870
Iteration 4646, loss = 0.00562639
Iteration 4647, loss = 0.00562447
Iteration 4648, loss = 0.00562275
Iteration 4649, loss = 0.00562096
Iteration 4650, loss = 0.00561937
Iteration 4651, loss = 0.00561765
Iteration 4652, loss = 0.00561598
Iteration 4653, loss = 0.00561422
Iteration 4654, loss = 0.00561259
Iteration 4655, loss = 0.00561097
Iteration 4656, loss = 0.00560918
Iteration 4657, loss = 0.00560760
Iteration 4658, loss = 0.00560601
Iteration 4659, loss = 0.00560428
Iteration 4660, loss = 0.00560217
Iteration 4661, loss = 0.00560082
Iteration 4662, loss = 0.00559965
Iteration 4663, loss = 0.00559730
Iteration 4664, loss = 0.00559565
Iteration 4665, loss = 0.00559369
Iteration 4666, loss = 0.00559216
Iteration 4667, loss = 0.00559044
Iteration 4668, loss = 0.00558882
Iteration 4669, loss = 0.00558713
Iteration 4670, loss = 0.00558548
Iteration 4671, loss = 0.00558415
Iteration 4672, loss = 0.00558264
Iteration 4673, loss = 0.00558075
Iteration 4674, loss = 0.00557910
Iteration 4675, loss = 0.00557731
Iteration 4676, loss = 0.00557564
Iteration 4677, loss = 0.00557406
Iteration 4678, loss = 0.00557254
Iteration 4679, loss = 0.00557110
Iteration 4680, loss = 0.00556916
Iteration 4681, loss = 0.00556748
Iteration 4682, loss = 0.00556646
Iteration 4683, loss = 0.00556455
Iteration 4684, loss = 0.00556332
Iteration 4685, loss = 0.00556158
Iteration 4686, loss = 0.00556005
Iteration 4687, loss = 0.00555833
Iteration 4688, loss = 0.00555688
Iteration 4689, loss = 0.00555543
Iteration 4690, loss = 0.00555365
Iteration 4691, loss = 0.00555191
Iteration 4692, loss = 0.00555034
Iteration 4693, loss = 0.00554904
Iteration 4694, loss = 0.00554741
Iteration 4695, loss = 0.00554570
Iteration 4696, loss = 0.00554424
Iteration 4697, loss = 0.00554299
Iteration 4698, loss = 0.00554117
Iteration 4699, loss = 0.00554015
Iteration 4700, loss = 0.00553806
Iteration 4701, loss = 0.00553641
Iteration 4702, loss = 0.00553490
Iteration 4703, loss = 0.00553342
Iteration 4704, loss = 0.00553164
Iteration 4705, loss = 0.00553012
Iteration 4706, loss = 0.00552853
Iteration 4707, loss = 0.00552740
Iteration 4708, loss = 0.00552534
Iteration 4709, loss = 0.00552397
Iteration 4710, loss = 0.00552259
Iteration 4711, loss = 0.00552113
Iteration 4712, loss = 0.00551980
Iteration 4713, loss = 0.00551818
Iteration 4714, loss = 0.00551667
Iteration 4715, loss = 0.00551532
Iteration 4716, loss = 0.00551381
Iteration 4717, loss = 0.00551277
Iteration 4718, loss = 0.00551108
Iteration 4719, loss = 0.00550945
Iteration 4720, loss = 0.00550775
Iteration 4721, loss = 0.00550610
Iteration 4722, loss = 0.00550464
Iteration 4723, loss = 0.00550297
Iteration 4724, loss = 0.00550114
Iteration 4725, loss = 0.00549930
Iteration 4726, loss = 0.00549778
Iteration 4727, loss = 0.00549610
Iteration 4728, loss = 0.00549507
Iteration 4729, loss = 0.00549312
Iteration 4730, loss = 0.00549170
Iteration 4731, loss = 0.00549052
Iteration 4732, loss = 0.00548885
Iteration 4733, loss = 0.00548751
Iteration 4734, loss = 0.00548597
Iteration 4735, loss = 0.00548450
Iteration 4736, loss = 0.00548311
Iteration 4737, loss = 0.00548161
Iteration 4738, loss = 0.00548005
Iteration 4739, loss = 0.00547939
Iteration 4740, loss = 0.00547706
Iteration 4741, loss = 0.00547567
Iteration 4742, loss = 0.00547396
Iteration 4743, loss = 0.00547233
Iteration 4744, loss = 0.00547092
Iteration 4745, loss = 0.00546948
Iteration 4746, loss = 0.00546791
Iteration 4747, loss = 0.00546647
Iteration 4748, loss = 0.00546508
Iteration 4749, loss = 0.00546357
Iteration 4750, loss = 0.00546187
Iteration 4751, loss = 0.00546071
Iteration 4752, loss = 0.00545897
Iteration 4753, loss = 0.00545666
Iteration 4754, loss = 0.00545522
Iteration 4755, loss = 0.00545357
Iteration 4756, loss = 0.00545169
Iteration 4757, loss = 0.00545002
Iteration 4758, loss = 0.00544930
Iteration 4759, loss = 0.00544714
Iteration 4760, loss = 0.00544574
Iteration 4761, loss = 0.00544456
Iteration 4762, loss = 0.00544275
Iteration 4763, loss = 0.00544119
Iteration 4764, loss = 0.00543964
Iteration 4765, loss = 0.00543791
Iteration 4766, loss = 0.00543627
Iteration 4767, loss = 0.00543489
Iteration 4768, loss = 0.00543313
Iteration 4769, loss = 0.00543142
Iteration 4770, loss = 0.00542984
Iteration 4771, loss = 0.00542843
Iteration 4772, loss = 0.00542669
Iteration 4773, loss = 0.00542523
Iteration 4774, loss = 0.00542368
Iteration 4775, loss = 0.00542211
Iteration 4776, loss = 0.00542085
Iteration 4777, loss = 0.00541913
Iteration 4778, loss = 0.00541748
Iteration 4779, loss = 0.00541632
Iteration 4780, loss = 0.00541490
Iteration 4781, loss = 0.00541320
Iteration 4782, loss = 0.00541174
Iteration 4783, loss = 0.00541035
Iteration 4784, loss = 0.00540918
Iteration 4785, loss = 0.00540727
Iteration 4786, loss = 0.00540584
Iteration 4787, loss = 0.00540487
Iteration 4788, loss = 0.00540232
Iteration 4789, loss = 0.00540091
Iteration 4790, loss = 0.00539918
Iteration 4791, loss = 0.00539739
Iteration 4792, loss = 0.00539576
Iteration 4793, loss = 0.00539431
Iteration 4794, loss = 0.00539272
Iteration 4795, loss = 0.00539076
Iteration 4796, loss = 0.00538929
Iteration 4797, loss = 0.00538763
Iteration 4798, loss = 0.00538599
Iteration 4799, loss = 0.00538480
Iteration 4800, loss = 0.00538271
Iteration 4801, loss = 0.00538148
Iteration 4802, loss = 0.00537982
Iteration 4803, loss = 0.00537943
Iteration 4804, loss = 0.00537693
Iteration 4805, loss = 0.00537547
Iteration 4806, loss = 0.00537476
Iteration 4807, loss = 0.00537217
Iteration 4808, loss = 0.00537072
Iteration 4809, loss = 0.00536947
Iteration 4810, loss = 0.00536770
Iteration 4811, loss = 0.00536623
Iteration 4812, loss = 0.00536448
Iteration 4813, loss = 0.00536304
Iteration 4814, loss = 0.00536155
Iteration 4815, loss = 0.00536045
Iteration 4816, loss = 0.00535848
Iteration 4817, loss = 0.00535689
Iteration 4818, loss = 0.00535523
Iteration 4819, loss = 0.00535346
Iteration 4820, loss = 0.00535228
Iteration 4821, loss = 0.00535070
Iteration 4822, loss = 0.00534895
Iteration 4823, loss = 0.00534748
Iteration 4824, loss = 0.00534597
Iteration 4825, loss = 0.00534468
Iteration 4826, loss = 0.00534326
Iteration 4827, loss = 0.00534152
Iteration 4828, loss = 0.00534062
Iteration 4829, loss = 0.00533796
Iteration 4830, loss = 0.00533630
Iteration 4831, loss = 0.00533488
Iteration 4832, loss = 0.00533301
Iteration 4833, loss = 0.00533128
Iteration 4834, loss = 0.00533058
Iteration 4835, loss = 0.00532830
Iteration 4836, loss = 0.00532678
Iteration 4837, loss = 0.00532480
Iteration 4838, loss = 0.00532319
Iteration 4839, loss = 0.00532175
Iteration 4840, loss = 0.00532010
Iteration 4841, loss = 0.00531827
Iteration 4842, loss = 0.00531694
Iteration 4843, loss = 0.00531533
Iteration 4844, loss = 0.00531394
Iteration 4845, loss = 0.00531253
Iteration 4846, loss = 0.00531120
Iteration 4847, loss = 0.00530958
Iteration 4848, loss = 0.00530816
Iteration 4849, loss = 0.00530698
Iteration 4850, loss = 0.00530563
Iteration 4851, loss = 0.00530433
Iteration 4852, loss = 0.00530275
Iteration 4853, loss = 0.00530109
Iteration 4854, loss = 0.00530027
Iteration 4855, loss = 0.00529835
Iteration 4856, loss = 0.00529645
Iteration 4857, loss = 0.00529507
Iteration 4858, loss = 0.00529366
Iteration 4859, loss = 0.00529192
Iteration 4860, loss = 0.00529068
Iteration 4861, loss = 0.00528906
Iteration 4862, loss = 0.00528788
Iteration 4863, loss = 0.00528630
Iteration 4864, loss = 0.00528476
Iteration 4865, loss = 0.00528339
Iteration 4866, loss = 0.00528194
Iteration 4867, loss = 0.00528041
Iteration 4868, loss = 0.00527932
Iteration 4869, loss = 0.00527810
Iteration 4870, loss = 0.00527726
Iteration 4871, loss = 0.00527557
Iteration 4872, loss = 0.00527513
Iteration 4873, loss = 0.00527330
Iteration 4874, loss = 0.00527135
Iteration 4875, loss = 0.00527020
Iteration 4876, loss = 0.00526854
Iteration 4877, loss = 0.00526693
Iteration 4878, loss = 0.00526504
Iteration 4879, loss = 0.00526339
Iteration 4880, loss = 0.00526236
Iteration 4881, loss = 0.00526048
Iteration 4882, loss = 0.00525893
Iteration 4883, loss = 0.00525730
Iteration 4884, loss = 0.00525579
Iteration 4885, loss = 0.00525424
Iteration 4886, loss = 0.00525322
Iteration 4887, loss = 0.00525062
Iteration 4888, loss = 0.00524927
Iteration 4889, loss = 0.00524760
Iteration 4890, loss = 0.00524560
Iteration 4891, loss = 0.00524425
Iteration 4892, loss = 0.00524229
Iteration 4893, loss = 0.00524096
Iteration 4894, loss = 0.00523922
Iteration 4895, loss = 0.00523790
Iteration 4896, loss = 0.00523667
Iteration 4897, loss = 0.00523516
Iteration 4898, loss = 0.00523325
Iteration 4899, loss = 0.00523202
Iteration 4900, loss = 0.00523096
Iteration 4901, loss = 0.00522907
Iteration 4902, loss = 0.00522765
Iteration 4903, loss = 0.00522647
Iteration 4904, loss = 0.00522465
Iteration 4905, loss = 0.00522332
Iteration 4906, loss = 0.00522196
Iteration 4907, loss = 0.00522031
Iteration 4908, loss = 0.00521887
Iteration 4909, loss = 0.00521729
Iteration 4910, loss = 0.00521563
Iteration 4911, loss = 0.00521434
Iteration 4912, loss = 0.00521242
Iteration 4913, loss = 0.00521104
Iteration 4914, loss = 0.00521000
Iteration 4915, loss = 0.00520869
Iteration 4916, loss = 0.00520650
Iteration 4917, loss = 0.00520501
Iteration 4918, loss = 0.00520342
Iteration 4919, loss = 0.00520228
Iteration 4920, loss = 0.00520015
Iteration 4921, loss = 0.00519873
Iteration 4922, loss = 0.00519692
Iteration 4923, loss = 0.00519541
Iteration 4924, loss = 0.00519386
Iteration 4925, loss = 0.00519237
Iteration 4926, loss = 0.00519114
Iteration 4927, loss = 0.00518960
Iteration 4928, loss = 0.00518822
Iteration 4929, loss = 0.00518656
Iteration 4930, loss = 0.00518547
Iteration 4931, loss = 0.00518381
Iteration 4932, loss = 0.00518224
Iteration 4933, loss = 0.00518101
Iteration 4934, loss = 0.00517958
Iteration 4935, loss = 0.00517816
Iteration 4936, loss = 0.00517653
Iteration 4937, loss = 0.00517522
Iteration 4938, loss = 0.00517353
Iteration 4939, loss = 0.00517198
Iteration 4940, loss = 0.00517030
Iteration 4941, loss = 0.00516915
Iteration 4942, loss = 0.00516769
Iteration 4943, loss = 0.00516592
Iteration 4944, loss = 0.00516442
Iteration 4945, loss = 0.00516271
Iteration 4946, loss = 0.00516159
Iteration 4947, loss = 0.00515971
Iteration 4948, loss = 0.00515840
Iteration 4949, loss = 0.00515691
Iteration 4950, loss = 0.00515563
Iteration 4951, loss = 0.00515399
Iteration 4952, loss = 0.00515250
Iteration 4953, loss = 0.00515098
Iteration 4954, loss = 0.00514998
Iteration 4955, loss = 0.00514814
Iteration 4956, loss = 0.00514660
Iteration 4957, loss = 0.00514504
Iteration 4958, loss = 0.00514366
Iteration 4959, loss = 0.00514212
Iteration 4960, loss = 0.00514075
Iteration 4961, loss = 0.00513937
Iteration 4962, loss = 0.00513792
Iteration 4963, loss = 0.00513651
Iteration 4964, loss = 0.00513503
Iteration 4965, loss = 0.00513370
Iteration 4966, loss = 0.00513227
Iteration 4967, loss = 0.00513116
Iteration 4968, loss = 0.00512957
Iteration 4969, loss = 0.00512797
Iteration 4970, loss = 0.00512657
Iteration 4971, loss = 0.00512571
Iteration 4972, loss = 0.00512368
Iteration 4973, loss = 0.00512238
Iteration 4974, loss = 0.00512096
Iteration 4975, loss = 0.00511978
Iteration 4976, loss = 0.00511798
Iteration 4977, loss = 0.00511656
Iteration 4978, loss = 0.00511527
Iteration 4979, loss = 0.00511418
Iteration 4980, loss = 0.00511257
Iteration 4981, loss = 0.00511138
Iteration 4982, loss = 0.00511003
Iteration 4983, loss = 0.00510865
Iteration 4984, loss = 0.00510732
Iteration 4985, loss = 0.00510661
Iteration 4986, loss = 0.00510492
Iteration 4987, loss = 0.00510354
Iteration 4988, loss = 0.00510255
Iteration 4989, loss = 0.00510087
Iteration 4990, loss = 0.00509916
Iteration 4991, loss = 0.00509780
Iteration 4992, loss = 0.00509645
Iteration 4993, loss = 0.00509483
Iteration 4994, loss = 0.00509328
Iteration 4995, loss = 0.00509187
Iteration 4996, loss = 0.00509060
Iteration 4997, loss = 0.00508908
Iteration 4998, loss = 0.00508773
Iteration 4999, loss = 0.00508672
Iteration 5000, loss = 0.00508501
Iteration 5001, loss = 0.00508369
Iteration 5002, loss = 0.00508239
Iteration 5003, loss = 0.00508113
Iteration 5004, loss = 0.00508005
Iteration 5005, loss = 0.00507880
Iteration 5006, loss = 0.00507734
Iteration 5007, loss = 0.00507632
Iteration 5008, loss = 0.00507479
Iteration 5009, loss = 0.00507336
Iteration 5010, loss = 0.00507232
Iteration 5011, loss = 0.00507065
Iteration 5012, loss = 0.00506945
Iteration 5013, loss = 0.00506875
Iteration 5014, loss = 0.00506666
Iteration 5015, loss = 0.00506529
Iteration 5016, loss = 0.00506406
Iteration 5017, loss = 0.00506253
Iteration 5018, loss = 0.00506113
Iteration 5019, loss = 0.00505974
Iteration 5020, loss = 0.00505840
Iteration 5021, loss = 0.00505717
Iteration 5022, loss = 0.00505595
Iteration 5023, loss = 0.00505472
Iteration 5024, loss = 0.00505337
Iteration 5025, loss = 0.00505204
Iteration 5026, loss = 0.00505066
Iteration 5027, loss = 0.00504964
Iteration 5028, loss = 0.00504913
Iteration 5029, loss = 0.00504787
Iteration 5030, loss = 0.00504600
Iteration 5031, loss = 0.00504471
Iteration 5032, loss = 0.00504383
Iteration 5033, loss = 0.00504221
Iteration 5034, loss = 0.00504151
Iteration 5035, loss = 0.00503976
Iteration 5036, loss = 0.00503830
Iteration 5037, loss = 0.00503714
Iteration 5038, loss = 0.00503583
Iteration 5039, loss = 0.00503463
Iteration 5040, loss = 0.00503337
Iteration 5041, loss = 0.00503206
Iteration 5042, loss = 0.00503079
Iteration 5043, loss = 0.00502956
Iteration 5044, loss = 0.00502848
Iteration 5045, loss = 0.00502712
Iteration 5046, loss = 0.00502591
Iteration 5047, loss = 0.00502471
Iteration 5048, loss = 0.00502355
Iteration 5049, loss = 0.00502224
Iteration 5050, loss = 0.00502099
Iteration 5051, loss = 0.00502011
Iteration 5052, loss = 0.00501853
Iteration 5053, loss = 0.00501725
Iteration 5054, loss = 0.00501597
Iteration 5055, loss = 0.00501466
Iteration 5056, loss = 0.00501349
Iteration 5057, loss = 0.00501225
Iteration 5058, loss = 0.00501094
Iteration 5059, loss = 0.00500995
Iteration 5060, loss = 0.00500861
Iteration 5061, loss = 0.00500726
Iteration 5062, loss = 0.00500567
Iteration 5063, loss = 0.00500451
Iteration 5064, loss = 0.00500326
Iteration 5065, loss = 0.00500203
Iteration 5066, loss = 0.00500061
Iteration 5067, loss = 0.00499979
Iteration 5068, loss = 0.00499855
Iteration 5069, loss = 0.00499687
Iteration 5070, loss = 0.00499584
Iteration 5071, loss = 0.00499427
Iteration 5072, loss = 0.00499299
Iteration 5073, loss = 0.00499152
Iteration 5074, loss = 0.00499035
Iteration 5075, loss = 0.00498895
Iteration 5076, loss = 0.00498779
Iteration 5077, loss = 0.00498660
Iteration 5078, loss = 0.00498560
Iteration 5079, loss = 0.00498379
Iteration 5080, loss = 0.00498228
Iteration 5081, loss = 0.00498073
Iteration 5082, loss = 0.00497960
Iteration 5083, loss = 0.00497806
Iteration 5084, loss = 0.00497666
Iteration 5085, loss = 0.00497497
Iteration 5086, loss = 0.00497342
Iteration 5087, loss = 0.00497240
Iteration 5088, loss = 0.00497078
Iteration 5089, loss = 0.00496935
Iteration 5090, loss = 0.00496784
Iteration 5091, loss = 0.00496715
Iteration 5092, loss = 0.00496520
Iteration 5093, loss = 0.00496374
Iteration 5094, loss = 0.00496264
Iteration 5095, loss = 0.00496088
Iteration 5096, loss = 0.00496000
Iteration 5097, loss = 0.00495853
Iteration 5098, loss = 0.00495766
Iteration 5099, loss = 0.00495612
Iteration 5100, loss = 0.00495491
Iteration 5101, loss = 0.00495366
Iteration 5102, loss = 0.00495220
Iteration 5103, loss = 0.00495126
Iteration 5104, loss = 0.00494974
Iteration 5105, loss = 0.00494866
Iteration 5106, loss = 0.00494704
Iteration 5107, loss = 0.00494587
Iteration 5108, loss = 0.00494459
Iteration 5109, loss = 0.00494322
Iteration 5110, loss = 0.00494223
Iteration 5111, loss = 0.00494110
Iteration 5112, loss = 0.00493955
Iteration 5113, loss = 0.00493846
Iteration 5114, loss = 0.00493669
Iteration 5115, loss = 0.00493536
Iteration 5116, loss = 0.00493400
Iteration 5117, loss = 0.00493275
Iteration 5118, loss = 0.00493113
Iteration 5119, loss = 0.00492987
Iteration 5120, loss = 0.00492858
Iteration 5121, loss = 0.00492705
Iteration 5122, loss = 0.00492594
Iteration 5123, loss = 0.00492476
Iteration 5124, loss = 0.00492287
Iteration 5125, loss = 0.00492179
Iteration 5126, loss = 0.00492044
Iteration 5127, loss = 0.00491924
Iteration 5128, loss = 0.00491807
Iteration 5129, loss = 0.00491664
Iteration 5130, loss = 0.00491555
Iteration 5131, loss = 0.00491392
Iteration 5132, loss = 0.00491274
Iteration 5133, loss = 0.00491115
Iteration 5134, loss = 0.00490986
Iteration 5135, loss = 0.00490831
Iteration 5136, loss = 0.00490685
Iteration 5137, loss = 0.00490563
Iteration 5138, loss = 0.00490422
Iteration 5139, loss = 0.00490286
Iteration 5140, loss = 0.00490170
Iteration 5141, loss = 0.00490038
Iteration 5142, loss = 0.00489907
Iteration 5143, loss = 0.00489765
Iteration 5144, loss = 0.00489642
Iteration 5145, loss = 0.00489499
Iteration 5146, loss = 0.00489335
Iteration 5147, loss = 0.00489207
Iteration 5148, loss = 0.00489054
Iteration 5149, loss = 0.00488909
Iteration 5150, loss = 0.00488747
Iteration 5151, loss = 0.00488633
Iteration 5152, loss = 0.00488512
Iteration 5153, loss = 0.00488373
Iteration 5154, loss = 0.00488220
Iteration 5155, loss = 0.00488126
Iteration 5156, loss = 0.00487984
Iteration 5157, loss = 0.00487848
Iteration 5158, loss = 0.00487736
Iteration 5159, loss = 0.00487604
Iteration 5160, loss = 0.00487489
Iteration 5161, loss = 0.00487357
Iteration 5162, loss = 0.00487219
Iteration 5163, loss = 0.00487091
Iteration 5164, loss = 0.00486964
Iteration 5165, loss = 0.00486849
Iteration 5166, loss = 0.00486711
Iteration 5167, loss = 0.00486592
Iteration 5168, loss = 0.00486472
Iteration 5169, loss = 0.00486362
Iteration 5170, loss = 0.00486237
Iteration 5171, loss = 0.00486197
Iteration 5172, loss = 0.00485989
Iteration 5173, loss = 0.00485863
Iteration 5174, loss = 0.00485748
Iteration 5175, loss = 0.00485639
Iteration 5176, loss = 0.00485483
Iteration 5177, loss = 0.00485339
Iteration 5178, loss = 0.00485211
Iteration 5179, loss = 0.00485090
Iteration 5180, loss = 0.00484955
Iteration 5181, loss = 0.00484874
Iteration 5182, loss = 0.00484700
Iteration 5183, loss = 0.00484609
Iteration 5184, loss = 0.00484446
Iteration 5185, loss = 0.00484304
Iteration 5186, loss = 0.00484184
Iteration 5187, loss = 0.00484047
Iteration 5188, loss = 0.00483911
Iteration 5189, loss = 0.00483763
Iteration 5190, loss = 0.00483641
Iteration 5191, loss = 0.00483518
Iteration 5192, loss = 0.00483388
Iteration 5193, loss = 0.00483277
Iteration 5194, loss = 0.00483106
Iteration 5195, loss = 0.00482993
Iteration 5196, loss = 0.00482850
Iteration 5197, loss = 0.00482742
Iteration 5198, loss = 0.00482618
Iteration 5199, loss = 0.00482492
Iteration 5200, loss = 0.00482373
Iteration 5201, loss = 0.00482265
Iteration 5202, loss = 0.00482129
Iteration 5203, loss = 0.00482016
Iteration 5204, loss = 0.00481889
Iteration 5205, loss = 0.00481790
Iteration 5206, loss = 0.00481633
Iteration 5207, loss = 0.00481530
Iteration 5208, loss = 0.00481398
Iteration 5209, loss = 0.00481257
Iteration 5210, loss = 0.00481112
Iteration 5211, loss = 0.00480969
Iteration 5212, loss = 0.00480886
Iteration 5213, loss = 0.00480710
Iteration 5214, loss = 0.00480664
Iteration 5215, loss = 0.00480543
Iteration 5216, loss = 0.00480400
Iteration 5217, loss = 0.00480265
Iteration 5218, loss = 0.00480161
Iteration 5219, loss = 0.00480028
Iteration 5220, loss = 0.00479909
Iteration 5221, loss = 0.00479768
Iteration 5222, loss = 0.00479649
Iteration 5223, loss = 0.00479534
Iteration 5224, loss = 0.00479388
Iteration 5225, loss = 0.00479265
Iteration 5226, loss = 0.00479140
Iteration 5227, loss = 0.00479018
Iteration 5228, loss = 0.00478914
Iteration 5229, loss = 0.00478782
Iteration 5230, loss = 0.00478674
Iteration 5231, loss = 0.00478546
Iteration 5232, loss = 0.00478438
Iteration 5233, loss = 0.00478324
Iteration 5234, loss = 0.00478217
Iteration 5235, loss = 0.00478089
Iteration 5236, loss = 0.00477966
Iteration 5237, loss = 0.00477841
Iteration 5238, loss = 0.00477691
Iteration 5239, loss = 0.00477565
Iteration 5240, loss = 0.00477443
Iteration 5241, loss = 0.00477281
Iteration 5242, loss = 0.00477219
Iteration 5243, loss = 0.00477032
Iteration 5244, loss = 0.00476967
Iteration 5245, loss = 0.00476869
Iteration 5246, loss = 0.00476712
Iteration 5247, loss = 0.00476656
Iteration 5248, loss = 0.00476487
Iteration 5249, loss = 0.00476360
Iteration 5250, loss = 0.00476297
Iteration 5251, loss = 0.00476137
Iteration 5252, loss = 0.00476006
Iteration 5253, loss = 0.00475881
Iteration 5254, loss = 0.00475766
Iteration 5255, loss = 0.00475661
Iteration 5256, loss = 0.00475477
Iteration 5257, loss = 0.00475336
Iteration 5258, loss = 0.00475196
Iteration 5259, loss = 0.00475096
Iteration 5260, loss = 0.00474950
Iteration 5261, loss = 0.00474821
Iteration 5262, loss = 0.00474685
Iteration 5263, loss = 0.00474557
Iteration 5264, loss = 0.00474441
Iteration 5265, loss = 0.00474301
Iteration 5266, loss = 0.00474226
Iteration 5267, loss = 0.00474052
Iteration 5268, loss = 0.00473928
Iteration 5269, loss = 0.00473786
Iteration 5270, loss = 0.00473658
Iteration 5271, loss = 0.00473549
Iteration 5272, loss = 0.00473437
Iteration 5273, loss = 0.00473287
Iteration 5274, loss = 0.00473153
Iteration 5275, loss = 0.00473046
Iteration 5276, loss = 0.00472971
Iteration 5277, loss = 0.00472813
Iteration 5278, loss = 0.00472696
Iteration 5279, loss = 0.00472581
Iteration 5280, loss = 0.00472475
Iteration 5281, loss = 0.00472376
Iteration 5282, loss = 0.00472252
Iteration 5283, loss = 0.00472151
Iteration 5284, loss = 0.00472023
Iteration 5285, loss = 0.00471896
Iteration 5286, loss = 0.00471787
Iteration 5287, loss = 0.00471679
Iteration 5288, loss = 0.00471511
Iteration 5289, loss = 0.00471383
Iteration 5290, loss = 0.00471262
Iteration 5291, loss = 0.00471142
Iteration 5292, loss = 0.00471017
Iteration 5293, loss = 0.00470903
Iteration 5294, loss = 0.00470787
Iteration 5295, loss = 0.00470677
Iteration 5296, loss = 0.00470550
Iteration 5297, loss = 0.00470423
Iteration 5298, loss = 0.00470310
Iteration 5299, loss = 0.00470178
Iteration 5300, loss = 0.00470075
Iteration 5301, loss = 0.00469958
Iteration 5302, loss = 0.00469875
Iteration 5303, loss = 0.00469719
Iteration 5304, loss = 0.00469592
Iteration 5305, loss = 0.00469476
Iteration 5306, loss = 0.00469340
Iteration 5307, loss = 0.00469218
Iteration 5308, loss = 0.00469144
Iteration 5309, loss = 0.00468975
Iteration 5310, loss = 0.00468851
Iteration 5311, loss = 0.00468715
Iteration 5312, loss = 0.00468583
Iteration 5313, loss = 0.00468493
Iteration 5314, loss = 0.00468350
Iteration 5315, loss = 0.00468225
Iteration 5316, loss = 0.00468109
Iteration 5317, loss = 0.00468045
Iteration 5318, loss = 0.00467873
Iteration 5319, loss = 0.00467715
Iteration 5320, loss = 0.00467602
Iteration 5321, loss = 0.00467449
Iteration 5322, loss = 0.00467302
Iteration 5323, loss = 0.00467200
Iteration 5324, loss = 0.00467061
Iteration 5325, loss = 0.00466924
Iteration 5326, loss = 0.00466797
Iteration 5327, loss = 0.00466665
Iteration 5328, loss = 0.00466544
Iteration 5329, loss = 0.00466445
Iteration 5330, loss = 0.00466290
Iteration 5331, loss = 0.00466179
Iteration 5332, loss = 0.00466043
Iteration 5333, loss = 0.00465924
Iteration 5334, loss = 0.00465804
Iteration 5335, loss = 0.00465674
Iteration 5336, loss = 0.00465550
Iteration 5337, loss = 0.00465435
Iteration 5338, loss = 0.00465296
Iteration 5339, loss = 0.00465176
Iteration 5340, loss = 0.00465055
Iteration 5341, loss = 0.00464935
Iteration 5342, loss = 0.00464828
Iteration 5343, loss = 0.00464688
Iteration 5344, loss = 0.00464578
Iteration 5345, loss = 0.00464462
Iteration 5346, loss = 0.00464328
Iteration 5347, loss = 0.00464239
Iteration 5348, loss = 0.00464116
Iteration 5349, loss = 0.00463996
Iteration 5350, loss = 0.00463880
Iteration 5351, loss = 0.00463778
Iteration 5352, loss = 0.00463644
Iteration 5353, loss = 0.00463541
Iteration 5354, loss = 0.00463427
Iteration 5355, loss = 0.00463301
Iteration 5356, loss = 0.00463174
Iteration 5357, loss = 0.00463045
Iteration 5358, loss = 0.00462943
Iteration 5359, loss = 0.00462903
Iteration 5360, loss = 0.00462725
Iteration 5361, loss = 0.00462591
Iteration 5362, loss = 0.00462502
Iteration 5363, loss = 0.00462348
Iteration 5364, loss = 0.00462239
Iteration 5365, loss = 0.00462119
Iteration 5366, loss = 0.00462062
Iteration 5367, loss = 0.00461871
Iteration 5368, loss = 0.00461761
Iteration 5369, loss = 0.00461656
Iteration 5370, loss = 0.00461529
Iteration 5371, loss = 0.00461440
Iteration 5372, loss = 0.00461303
Iteration 5373, loss = 0.00461212
Iteration 5374, loss = 0.00461090
Iteration 5375, loss = 0.00461010
Iteration 5376, loss = 0.00460883
Iteration 5377, loss = 0.00460754
Iteration 5378, loss = 0.00460695
Iteration 5379, loss = 0.00460478
Iteration 5380, loss = 0.00460379
Iteration 5381, loss = 0.00460293
Iteration 5382, loss = 0.00460134
Iteration 5383, loss = 0.00460017
Iteration 5384, loss = 0.00459934
Iteration 5385, loss = 0.00459796
Iteration 5386, loss = 0.00459713
Iteration 5387, loss = 0.00459592
Iteration 5388, loss = 0.00459471
Iteration 5389, loss = 0.00459368
Iteration 5390, loss = 0.00459242
Iteration 5391, loss = 0.00459130
Iteration 5392, loss = 0.00459002
Iteration 5393, loss = 0.00458887
Iteration 5394, loss = 0.00458766
Iteration 5395, loss = 0.00458653
Iteration 5396, loss = 0.00458553
Iteration 5397, loss = 0.00458445
Iteration 5398, loss = 0.00458305
Iteration 5399, loss = 0.00458207
Iteration 5400, loss = 0.00458084
Iteration 5401, loss = 0.00457966
Iteration 5402, loss = 0.00457857
Iteration 5403, loss = 0.00457728
Iteration 5404, loss = 0.00457630
Iteration 5405, loss = 0.00457498
Iteration 5406, loss = 0.00457375
Iteration 5407, loss = 0.00457293
Iteration 5408, loss = 0.00457135
Iteration 5409, loss = 0.00457018
Iteration 5410, loss = 0.00456885
Iteration 5411, loss = 0.00456790
Iteration 5412, loss = 0.00456666
Iteration 5413, loss = 0.00456565
Iteration 5414, loss = 0.00456437
Iteration 5415, loss = 0.00456281
Iteration 5416, loss = 0.00456168
Iteration 5417, loss = 0.00456055
Iteration 5418, loss = 0.00455940
Iteration 5419, loss = 0.00455797
Iteration 5420, loss = 0.00455671
Iteration 5421, loss = 0.00455605
Iteration 5422, loss = 0.00455445
Iteration 5423, loss = 0.00455296
Iteration 5424, loss = 0.00455193
Iteration 5425, loss = 0.00455049
Iteration 5426, loss = 0.00454933
Iteration 5427, loss = 0.00454802
Iteration 5428, loss = 0.00454678
Iteration 5429, loss = 0.00454568
Iteration 5430, loss = 0.00454438
Iteration 5431, loss = 0.00454329
Iteration 5432, loss = 0.00454207
Iteration 5433, loss = 0.00454104
Iteration 5434, loss = 0.00453977
Iteration 5435, loss = 0.00453861
Iteration 5436, loss = 0.00453738
Iteration 5437, loss = 0.00453649
Iteration 5438, loss = 0.00453520
Iteration 5439, loss = 0.00453398
Iteration 5440, loss = 0.00453313
Iteration 5441, loss = 0.00453179
Iteration 5442, loss = 0.00453058
Iteration 5443, loss = 0.00452938
Iteration 5444, loss = 0.00452893
Iteration 5445, loss = 0.00452709
Iteration 5446, loss = 0.00452606
Iteration 5447, loss = 0.00452469
Iteration 5448, loss = 0.00452359
Iteration 5449, loss = 0.00452237
Iteration 5450, loss = 0.00452118
Iteration 5451, loss = 0.00451997
Iteration 5452, loss = 0.00451881
Iteration 5453, loss = 0.00451753
Iteration 5454, loss = 0.00451667
Iteration 5455, loss = 0.00451534
Iteration 5456, loss = 0.00451421
Iteration 5457, loss = 0.00451309
Iteration 5458, loss = 0.00451192
Iteration 5459, loss = 0.00451095
Iteration 5460, loss = 0.00451072
Iteration 5461, loss = 0.00450895
Iteration 5462, loss = 0.00450786
Iteration 5463, loss = 0.00450677
Iteration 5464, loss = 0.00450571
Iteration 5465, loss = 0.00450482
Iteration 5466, loss = 0.00450361
Iteration 5467, loss = 0.00450256
Iteration 5468, loss = 0.00450149
Iteration 5469, loss = 0.00450053
Iteration 5470, loss = 0.00449942
Iteration 5471, loss = 0.00449840
Iteration 5472, loss = 0.00449709
Iteration 5473, loss = 0.00449593
Iteration 5474, loss = 0.00449494
Iteration 5475, loss = 0.00449426
Iteration 5476, loss = 0.00449301
Iteration 5477, loss = 0.00449199
Iteration 5478, loss = 0.00449087
Iteration 5479, loss = 0.00448982
Iteration 5480, loss = 0.00448869
Iteration 5481, loss = 0.00448758
Iteration 5482, loss = 0.00448648
Iteration 5483, loss = 0.00448546
Iteration 5484, loss = 0.00448492
Iteration 5485, loss = 0.00448334
Iteration 5486, loss = 0.00448218
Iteration 5487, loss = 0.00448109
Iteration 5488, loss = 0.00448000
Iteration 5489, loss = 0.00447902
Iteration 5490, loss = 0.00447777
Iteration 5491, loss = 0.00447678
Iteration 5492, loss = 0.00447574
Iteration 5493, loss = 0.00447463
Iteration 5494, loss = 0.00447381
Iteration 5495, loss = 0.00447282
Iteration 5496, loss = 0.00447148
Iteration 5497, loss = 0.00447041
Iteration 5498, loss = 0.00446907
Iteration 5499, loss = 0.00446820
Iteration 5500, loss = 0.00446661
Iteration 5501, loss = 0.00446612
Iteration 5502, loss = 0.00446453
Iteration 5503, loss = 0.00446332
Iteration 5504, loss = 0.00446214
Iteration 5505, loss = 0.00446118
Iteration 5506, loss = 0.00446004
Iteration 5507, loss = 0.00445902
Iteration 5508, loss = 0.00445772
Iteration 5509, loss = 0.00445671
Iteration 5510, loss = 0.00445591
Iteration 5511, loss = 0.00445475
Iteration 5512, loss = 0.00445367
Iteration 5513, loss = 0.00445278
Iteration 5514, loss = 0.00445191
Iteration 5515, loss = 0.00445069
Iteration 5516, loss = 0.00444971
Iteration 5517, loss = 0.00444878
Iteration 5518, loss = 0.00444758
Iteration 5519, loss = 0.00444625
Iteration 5520, loss = 0.00444574
Iteration 5521, loss = 0.00444505
Iteration 5522, loss = 0.00444359
Iteration 5523, loss = 0.00444244
Iteration 5524, loss = 0.00444126
Iteration 5525, loss = 0.00444014
Iteration 5526, loss = 0.00443908
Iteration 5527, loss = 0.00443821
Iteration 5528, loss = 0.00443679
Iteration 5529, loss = 0.00443593
Iteration 5530, loss = 0.00443452
Iteration 5531, loss = 0.00443327
Iteration 5532, loss = 0.00443257
Iteration 5533, loss = 0.00443091
Iteration 5534, loss = 0.00442994
Iteration 5535, loss = 0.00442875
Iteration 5536, loss = 0.00442736
Iteration 5537, loss = 0.00442703
Iteration 5538, loss = 0.00442558
Iteration 5539, loss = 0.00442457
Iteration 5540, loss = 0.00442351
Iteration 5541, loss = 0.00442206
Iteration 5542, loss = 0.00442100
Iteration 5543, loss = 0.00441999
Iteration 5544, loss = 0.00441865
Iteration 5545, loss = 0.00441745
Iteration 5546, loss = 0.00441632
Iteration 5547, loss = 0.00441518
Iteration 5548, loss = 0.00441402
Iteration 5549, loss = 0.00441275
Iteration 5550, loss = 0.00441170
Iteration 5551, loss = 0.00441042
Iteration 5552, loss = 0.00440922
Iteration 5553, loss = 0.00440822
Iteration 5554, loss = 0.00440724
Iteration 5555, loss = 0.00440557
Iteration 5556, loss = 0.00440467
Iteration 5557, loss = 0.00440328
Iteration 5558, loss = 0.00440231
Iteration 5559, loss = 0.00440122
Iteration 5560, loss = 0.00440005
Iteration 5561, loss = 0.00439910
Iteration 5562, loss = 0.00439839
Iteration 5563, loss = 0.00439689
Iteration 5564, loss = 0.00439577
Iteration 5565, loss = 0.00439505
Iteration 5566, loss = 0.00439364
Iteration 5567, loss = 0.00439270
Iteration 5568, loss = 0.00439142
Iteration 5569, loss = 0.00439032
Iteration 5570, loss = 0.00438927
Iteration 5571, loss = 0.00438814
Iteration 5572, loss = 0.00438743
Iteration 5573, loss = 0.00438622
Iteration 5574, loss = 0.00438529
Iteration 5575, loss = 0.00438385
Iteration 5576, loss = 0.00438263
Iteration 5577, loss = 0.00438156
Iteration 5578, loss = 0.00438030
Iteration 5579, loss = 0.00437949
Iteration 5580, loss = 0.00437791
Iteration 5581, loss = 0.00437691
Iteration 5582, loss = 0.00437583
Iteration 5583, loss = 0.00437467
Iteration 5584, loss = 0.00437367
Iteration 5585, loss = 0.00437286
Iteration 5586, loss = 0.00437195
Iteration 5587, loss = 0.00437130
Iteration 5588, loss = 0.00437023
Iteration 5589, loss = 0.00436919
Iteration 5590, loss = 0.00436813
Iteration 5591, loss = 0.00436716
Iteration 5592, loss = 0.00436618
Iteration 5593, loss = 0.00436504
Iteration 5594, loss = 0.00436408
Iteration 5595, loss = 0.00436330
Iteration 5596, loss = 0.00436212
Iteration 5597, loss = 0.00436130
Iteration 5598, loss = 0.00436043
Iteration 5599, loss = 0.00435958
Iteration 5600, loss = 0.00435781
Iteration 5601, loss = 0.00435713
Iteration 5602, loss = 0.00435579
Iteration 5603, loss = 0.00435495
Iteration 5604, loss = 0.00435374
Iteration 5605, loss = 0.00435279
Iteration 5606, loss = 0.00435177
Iteration 5607, loss = 0.00435077
Iteration 5608, loss = 0.00434963
Iteration 5609, loss = 0.00434879
Iteration 5610, loss = 0.00434750
Iteration 5611, loss = 0.00434619
Iteration 5612, loss = 0.00434526
Iteration 5613, loss = 0.00434379
Iteration 5614, loss = 0.00434260
Iteration 5615, loss = 0.00434112
Iteration 5616, loss = 0.00434000
Iteration 5617, loss = 0.00433847
Iteration 5618, loss = 0.00433731
Iteration 5619, loss = 0.00433613
Iteration 5620, loss = 0.00433476
Iteration 5621, loss = 0.00433351
Iteration 5622, loss = 0.00433265
Iteration 5623, loss = 0.00433094
Iteration 5624, loss = 0.00433006
Iteration 5625, loss = 0.00432864
Iteration 5626, loss = 0.00432806
Iteration 5627, loss = 0.00432645
Iteration 5628, loss = 0.00432539
Iteration 5629, loss = 0.00432434
Iteration 5630, loss = 0.00432332
Iteration 5631, loss = 0.00432240
Iteration 5632, loss = 0.00432162
Iteration 5633, loss = 0.00432017
Iteration 5634, loss = 0.00431908
Iteration 5635, loss = 0.00431788
Iteration 5636, loss = 0.00431685
Iteration 5637, loss = 0.00431586
Iteration 5638, loss = 0.00431460
Iteration 5639, loss = 0.00431366
Iteration 5640, loss = 0.00431243
Iteration 5641, loss = 0.00431157
Iteration 5642, loss = 0.00431042
Iteration 5643, loss = 0.00430962
Iteration 5644, loss = 0.00430816
Iteration 5645, loss = 0.00430717
Iteration 5646, loss = 0.00430610
Iteration 5647, loss = 0.00430510
Iteration 5648, loss = 0.00430417
Iteration 5649, loss = 0.00430294
Iteration 5650, loss = 0.00430193
Iteration 5651, loss = 0.00430089
Iteration 5652, loss = 0.00429997
Iteration 5653, loss = 0.00429883
Iteration 5654, loss = 0.00429796
Iteration 5655, loss = 0.00429739
Iteration 5656, loss = 0.00429586
Iteration 5657, loss = 0.00429494
Iteration 5658, loss = 0.00429386
Iteration 5659, loss = 0.00429292
Iteration 5660, loss = 0.00429192
Iteration 5661, loss = 0.00429085
Iteration 5662, loss = 0.00429009
Iteration 5663, loss = 0.00428891
Iteration 5664, loss = 0.00428782
Iteration 5665, loss = 0.00428686
Iteration 5666, loss = 0.00428592
Iteration 5667, loss = 0.00428518
Iteration 5668, loss = 0.00428407
Iteration 5669, loss = 0.00428296
Iteration 5670, loss = 0.00428193
Iteration 5671, loss = 0.00428097
Iteration 5672, loss = 0.00427992
Iteration 5673, loss = 0.00427902
Iteration 5674, loss = 0.00427776
Iteration 5675, loss = 0.00427677
Iteration 5676, loss = 0.00427576
Iteration 5677, loss = 0.00427459
Iteration 5678, loss = 0.00427349
Iteration 5679, loss = 0.00427256
Iteration 5680, loss = 0.00427151
Iteration 5681, loss = 0.00427055
Iteration 5682, loss = 0.00426930
Iteration 5683, loss = 0.00426831
Iteration 5684, loss = 0.00426760
Iteration 5685, loss = 0.00426642
Iteration 5686, loss = 0.00426542
Iteration 5687, loss = 0.00426439
Iteration 5688, loss = 0.00426334
Iteration 5689, loss = 0.00426234
Iteration 5690, loss = 0.00426148
Iteration 5691, loss = 0.00426068
Iteration 5692, loss = 0.00425984
Iteration 5693, loss = 0.00425865
Iteration 5694, loss = 0.00425783
Iteration 5695, loss = 0.00425644
Iteration 5696, loss = 0.00425538
Iteration 5697, loss = 0.00425435
Iteration 5698, loss = 0.00425317
Iteration 5699, loss = 0.00425263
Iteration 5700, loss = 0.00425123
Iteration 5701, loss = 0.00425025
Iteration 5702, loss = 0.00424915
Iteration 5703, loss = 0.00424814
Iteration 5704, loss = 0.00424727
Iteration 5705, loss = 0.00424623
Iteration 5706, loss = 0.00424509
Iteration 5707, loss = 0.00424407
Iteration 5708, loss = 0.00424322
Iteration 5709, loss = 0.00424231
Iteration 5710, loss = 0.00424183
Iteration 5711, loss = 0.00424024
Iteration 5712, loss = 0.00423971
Iteration 5713, loss = 0.00423849
Iteration 5714, loss = 0.00423740
Iteration 5715, loss = 0.00423617
Iteration 5716, loss = 0.00423516
Iteration 5717, loss = 0.00423417
Iteration 5718, loss = 0.00423309
Iteration 5719, loss = 0.00423222
Iteration 5720, loss = 0.00423115
Iteration 5721, loss = 0.00423027
Iteration 5722, loss = 0.00422916
Iteration 5723, loss = 0.00422804
Iteration 5724, loss = 0.00422703
Iteration 5725, loss = 0.00422589
Iteration 5726, loss = 0.00422488
Iteration 5727, loss = 0.00422400
Iteration 5728, loss = 0.00422308
Iteration 5729, loss = 0.00422218
Iteration 5730, loss = 0.00422173
Iteration 5731, loss = 0.00422018
Iteration 5732, loss = 0.00421940
Iteration 5733, loss = 0.00421807
Iteration 5734, loss = 0.00421705
Iteration 5735, loss = 0.00421599
Iteration 5736, loss = 0.00421484
Iteration 5737, loss = 0.00421389
Iteration 5738, loss = 0.00421286
Iteration 5739, loss = 0.00421184
Iteration 5740, loss = 0.00421098
Iteration 5741, loss = 0.00421001
Iteration 5742, loss = 0.00420910
Iteration 5743, loss = 0.00420827
Iteration 5744, loss = 0.00420753
Iteration 5745, loss = 0.00420642
Iteration 5746, loss = 0.00420664
Iteration 5747, loss = 0.00420479
Iteration 5748, loss = 0.00420355
Iteration 5749, loss = 0.00420269
Iteration 5750, loss = 0.00420156
Iteration 5751, loss = 0.00420063
Iteration 5752, loss = 0.00419968
Iteration 5753, loss = 0.00419867
Iteration 5754, loss = 0.00419783
Iteration 5755, loss = 0.00419693
Iteration 5756, loss = 0.00419584
Iteration 5757, loss = 0.00419499
Iteration 5758, loss = 0.00419398
Iteration 5759, loss = 0.00419324
Iteration 5760, loss = 0.00419171
Iteration 5761, loss = 0.00419056
Iteration 5762, loss = 0.00418942
Iteration 5763, loss = 0.00418834
Iteration 5764, loss = 0.00418740
Iteration 5765, loss = 0.00418621
Iteration 5766, loss = 0.00418517
Iteration 5767, loss = 0.00418414
Iteration 5768, loss = 0.00418312
Iteration 5769, loss = 0.00418197
Iteration 5770, loss = 0.00418118
Iteration 5771, loss = 0.00417997
Iteration 5772, loss = 0.00417901
Iteration 5773, loss = 0.00417800
Iteration 5774, loss = 0.00417708
Iteration 5775, loss = 0.00417625
Iteration 5776, loss = 0.00417496
Iteration 5777, loss = 0.00417405
Iteration 5778, loss = 0.00417310
Iteration 5779, loss = 0.00417199
Iteration 5780, loss = 0.00417088
Iteration 5781, loss = 0.00417038
Iteration 5782, loss = 0.00416898
Iteration 5783, loss = 0.00416830
Iteration 5784, loss = 0.00416690
Iteration 5785, loss = 0.00416588
Iteration 5786, loss = 0.00416485
Iteration 5787, loss = 0.00416375
Iteration 5788, loss = 0.00416262
Iteration 5789, loss = 0.00416159
Iteration 5790, loss = 0.00416043
Iteration 5791, loss = 0.00415957
Iteration 5792, loss = 0.00415849
Iteration 5793, loss = 0.00415759
Iteration 5794, loss = 0.00415641
Iteration 5795, loss = 0.00415553
Iteration 5796, loss = 0.00415456
Iteration 5797, loss = 0.00415355
Iteration 5798, loss = 0.00415262
Iteration 5799, loss = 0.00415209
Iteration 5800, loss = 0.00415118
Iteration 5801, loss = 0.00414971
Iteration 5802, loss = 0.00414870
Iteration 5803, loss = 0.00414780
Iteration 5804, loss = 0.00414666
Iteration 5805, loss = 0.00414566
Iteration 5806, loss = 0.00414475
Iteration 5807, loss = 0.00414379
Iteration 5808, loss = 0.00414270
Iteration 5809, loss = 0.00414190
Iteration 5810, loss = 0.00414095
Iteration 5811, loss = 0.00413987
Iteration 5812, loss = 0.00413884
Iteration 5813, loss = 0.00413826
Iteration 5814, loss = 0.00413693
Iteration 5815, loss = 0.00413623
Iteration 5816, loss = 0.00413506
Iteration 5817, loss = 0.00413416
Iteration 5818, loss = 0.00413317
Iteration 5819, loss = 0.00413223
Iteration 5820, loss = 0.00413168
Iteration 5821, loss = 0.00413055
Iteration 5822, loss = 0.00412972
Iteration 5823, loss = 0.00412888
Iteration 5824, loss = 0.00412812
Iteration 5825, loss = 0.00412687
Iteration 5826, loss = 0.00412603
Iteration 5827, loss = 0.00412495
Iteration 5828, loss = 0.00412406
Iteration 5829, loss = 0.00412322
Iteration 5830, loss = 0.00412216
Iteration 5831, loss = 0.00412119
Iteration 5832, loss = 0.00412025
Iteration 5833, loss = 0.00411942
Iteration 5834, loss = 0.00411858
Iteration 5835, loss = 0.00411762
Iteration 5836, loss = 0.00411708
Iteration 5837, loss = 0.00411588
Iteration 5838, loss = 0.00411506
Iteration 5839, loss = 0.00411436
Iteration 5840, loss = 0.00411284
Iteration 5841, loss = 0.00411200
Iteration 5842, loss = 0.00411100
Iteration 5843, loss = 0.00410966
Iteration 5844, loss = 0.00410857
Iteration 5845, loss = 0.00410740
Iteration 5846, loss = 0.00410670
Iteration 5847, loss = 0.00410575
Iteration 5848, loss = 0.00410461
Iteration 5849, loss = 0.00410356
Iteration 5850, loss = 0.00410269
Iteration 5851, loss = 0.00410185
Iteration 5852, loss = 0.00410079
Iteration 5853, loss = 0.00409974
Iteration 5854, loss = 0.00409870
Iteration 5855, loss = 0.00409767
Iteration 5856, loss = 0.00409663
Iteration 5857, loss = 0.00409544
Iteration 5858, loss = 0.00409441
Iteration 5859, loss = 0.00409321
Iteration 5860, loss = 0.00409264
Iteration 5861, loss = 0.00409140
Iteration 5862, loss = 0.00409067
Iteration 5863, loss = 0.00408981
Iteration 5864, loss = 0.00408872
Iteration 5865, loss = 0.00408787
Iteration 5866, loss = 0.00408685
Iteration 5867, loss = 0.00408591
Iteration 5868, loss = 0.00408511
Iteration 5869, loss = 0.00408409
Iteration 5870, loss = 0.00408313
Iteration 5871, loss = 0.00408230
Iteration 5872, loss = 0.00408127
Iteration 5873, loss = 0.00408047
Iteration 5874, loss = 0.00407932
Iteration 5875, loss = 0.00407829
Iteration 5876, loss = 0.00407773
Iteration 5877, loss = 0.00407632
Iteration 5878, loss = 0.00407525
Iteration 5879, loss = 0.00407465
Iteration 5880, loss = 0.00407335
Iteration 5881, loss = 0.00407255
Iteration 5882, loss = 0.00407161
Iteration 5883, loss = 0.00407064
Iteration 5884, loss = 0.00406959
Iteration 5885, loss = 0.00406869
Iteration 5886, loss = 0.00406781
Iteration 5887, loss = 0.00406676
Iteration 5888, loss = 0.00406593
Iteration 5889, loss = 0.00406508
Iteration 5890, loss = 0.00406401
Iteration 5891, loss = 0.00406305
Iteration 5892, loss = 0.00406213
Iteration 5893, loss = 0.00406128
Iteration 5894, loss = 0.00406026
Iteration 5895, loss = 0.00405931
Iteration 5896, loss = 0.00405839
Iteration 5897, loss = 0.00405749
Iteration 5898, loss = 0.00405674
Iteration 5899, loss = 0.00405572
Iteration 5900, loss = 0.00405465
Iteration 5901, loss = 0.00405414
Iteration 5902, loss = 0.00405279
Iteration 5903, loss = 0.00405186
Iteration 5904, loss = 0.00405077
Iteration 5905, loss = 0.00404991
Iteration 5906, loss = 0.00404878
Iteration 5907, loss = 0.00404780
Iteration 5908, loss = 0.00404676
Iteration 5909, loss = 0.00404602
Iteration 5910, loss = 0.00404501
Iteration 5911, loss = 0.00404397
Iteration 5912, loss = 0.00404296
Iteration 5913, loss = 0.00404203
Iteration 5914, loss = 0.00404101
Iteration 5915, loss = 0.00403988
Iteration 5916, loss = 0.00403920
Iteration 5917, loss = 0.00403797
Iteration 5918, loss = 0.00403708
Iteration 5919, loss = 0.00403592
Iteration 5920, loss = 0.00403494
Iteration 5921, loss = 0.00403395
Iteration 5922, loss = 0.00403295
Iteration 5923, loss = 0.00403239
Iteration 5924, loss = 0.00403119
Iteration 5925, loss = 0.00403044
Iteration 5926, loss = 0.00402955
Iteration 5927, loss = 0.00402859
Iteration 5928, loss = 0.00402770
Iteration 5929, loss = 0.00402689
Iteration 5930, loss = 0.00402685
Iteration 5931, loss = 0.00402538
Iteration 5932, loss = 0.00402456
Iteration 5933, loss = 0.00402384
Iteration 5934, loss = 0.00402290
Iteration 5935, loss = 0.00402204
Iteration 5936, loss = 0.00402138
Iteration 5937, loss = 0.00402019
Iteration 5938, loss = 0.00401925
Iteration 5939, loss = 0.00401843
Iteration 5940, loss = 0.00401725
Iteration 5941, loss = 0.00401622
Iteration 5942, loss = 0.00401561
Iteration 5943, loss = 0.00401423
Iteration 5944, loss = 0.00401330
Iteration 5945, loss = 0.00401252
Iteration 5946, loss = 0.00401168
Iteration 5947, loss = 0.00401059
Iteration 5948, loss = 0.00400962
Iteration 5949, loss = 0.00400876
Iteration 5950, loss = 0.00400809
Iteration 5951, loss = 0.00400704
Iteration 5952, loss = 0.00400611
Iteration 5953, loss = 0.00400505
Iteration 5954, loss = 0.00400458
Iteration 5955, loss = 0.00400345
Iteration 5956, loss = 0.00400249
Iteration 5957, loss = 0.00400211
Iteration 5958, loss = 0.00400144
Iteration 5959, loss = 0.00400003
Iteration 5960, loss = 0.00399911
Iteration 5961, loss = 0.00399819
Iteration 5962, loss = 0.00399743
Iteration 5963, loss = 0.00399637
Iteration 5964, loss = 0.00399527
Iteration 5965, loss = 0.00399437
Iteration 5966, loss = 0.00399346
Iteration 5967, loss = 0.00399227
Iteration 5968, loss = 0.00399147
Iteration 5969, loss = 0.00399034
Iteration 5970, loss = 0.00398956
Iteration 5971, loss = 0.00398850
Iteration 5972, loss = 0.00398764
Iteration 5973, loss = 0.00398669
Iteration 5974, loss = 0.00398582
Iteration 5975, loss = 0.00398503
Iteration 5976, loss = 0.00398429
Iteration 5977, loss = 0.00398350
Iteration 5978, loss = 0.00398217
Iteration 5979, loss = 0.00398130
Iteration 5980, loss = 0.00398037
Iteration 5981, loss = 0.00397956
Iteration 5982, loss = 0.00397859
Iteration 5983, loss = 0.00397849
Iteration 5984, loss = 0.00397711
Iteration 5985, loss = 0.00397598
Iteration 5986, loss = 0.00397490
Iteration 5987, loss = 0.00397396
Iteration 5988, loss = 0.00397302
Iteration 5989, loss = 0.00397192
Iteration 5990, loss = 0.00397094
Iteration 5991, loss = 0.00397009
Iteration 5992, loss = 0.00396906
Iteration 5993, loss = 0.00396847
Iteration 5994, loss = 0.00396720
Iteration 5995, loss = 0.00396656
Iteration 5996, loss = 0.00396539
Iteration 5997, loss = 0.00396455
Iteration 5998, loss = 0.00396381
Iteration 5999, loss = 0.00396279
Iteration 6000, loss = 0.00396189
Iteration 6001, loss = 0.00396105
Iteration 6002, loss = 0.00396021
Iteration 6003, loss = 0.00395933
Iteration 6004, loss = 0.00395889
Iteration 6005, loss = 0.00395777
Iteration 6006, loss = 0.00395684
Iteration 6007, loss = 0.00395586
Iteration 6008, loss = 0.00395491
Iteration 6009, loss = 0.00395409
Iteration 6010, loss = 0.00395300
Iteration 6011, loss = 0.00395219
Iteration 6012, loss = 0.00395110
Iteration 6013, loss = 0.00395029
Iteration 6014, loss = 0.00394928
Iteration 6015, loss = 0.00394837
Iteration 6016, loss = 0.00394805
Iteration 6017, loss = 0.00394661
Iteration 6018, loss = 0.00394569
Iteration 6019, loss = 0.00394457
Iteration 6020, loss = 0.00394384
Iteration 6021, loss = 0.00394268
Iteration 6022, loss = 0.00394153
Iteration 6023, loss = 0.00394067
Iteration 6024, loss = 0.00393966
Iteration 6025, loss = 0.00393861
Iteration 6026, loss = 0.00393762
Iteration 6027, loss = 0.00393656
Iteration 6028, loss = 0.00393582
Iteration 6029, loss = 0.00393512
Iteration 6030, loss = 0.00393410
Iteration 6031, loss = 0.00393295
Iteration 6032, loss = 0.00393227
Iteration 6033, loss = 0.00393137
Iteration 6034, loss = 0.00393055
Iteration 6035, loss = 0.00392929
Iteration 6036, loss = 0.00392825
Iteration 6037, loss = 0.00392751
Iteration 6038, loss = 0.00392681
Iteration 6039, loss = 0.00392589
Iteration 6040, loss = 0.00392490
Iteration 6041, loss = 0.00392410
Iteration 6042, loss = 0.00392324
Iteration 6043, loss = 0.00392243
Iteration 6044, loss = 0.00392155
Iteration 6045, loss = 0.00392071
Iteration 6046, loss = 0.00391981
Iteration 6047, loss = 0.00391894
Iteration 6048, loss = 0.00391805
Iteration 6049, loss = 0.00391717
Iteration 6050, loss = 0.00391619
Iteration 6051, loss = 0.00391592
Iteration 6052, loss = 0.00391451
Iteration 6053, loss = 0.00391363
Iteration 6054, loss = 0.00391276
Iteration 6055, loss = 0.00391194
Iteration 6056, loss = 0.00391117
Iteration 6057, loss = 0.00391018
Iteration 6058, loss = 0.00390920
Iteration 6059, loss = 0.00390842
Iteration 6060, loss = 0.00390760
Iteration 6061, loss = 0.00390675
Iteration 6062, loss = 0.00390586
Iteration 6063, loss = 0.00390504
Iteration 6064, loss = 0.00390429
Iteration 6065, loss = 0.00390336
Iteration 6066, loss = 0.00390252
Iteration 6067, loss = 0.00390175
Iteration 6068, loss = 0.00390085
Iteration 6069, loss = 0.00390003
Iteration 6070, loss = 0.00389911
Iteration 6071, loss = 0.00389825
Iteration 6072, loss = 0.00389730
Iteration 6073, loss = 0.00389664
Iteration 6074, loss = 0.00389565
Iteration 6075, loss = 0.00389484
Iteration 6076, loss = 0.00389394
Iteration 6077, loss = 0.00389314
Iteration 6078, loss = 0.00389221
Iteration 6079, loss = 0.00389129
Iteration 6080, loss = 0.00389043
Iteration 6081, loss = 0.00388963
Iteration 6082, loss = 0.00388885
Iteration 6083, loss = 0.00388799
Iteration 6084, loss = 0.00388708
Iteration 6085, loss = 0.00388634
Iteration 6086, loss = 0.00388542
Iteration 6087, loss = 0.00388471
Iteration 6088, loss = 0.00388379
Iteration 6089, loss = 0.00388318
Iteration 6090, loss = 0.00388234
Iteration 6091, loss = 0.00388143
Iteration 6092, loss = 0.00388080
Iteration 6093, loss = 0.00387963
Iteration 6094, loss = 0.00387880
Iteration 6095, loss = 0.00387795
Iteration 6096, loss = 0.00387713
Iteration 6097, loss = 0.00387633
Iteration 6098, loss = 0.00387543
Iteration 6099, loss = 0.00387447
Iteration 6100, loss = 0.00387351
Iteration 6101, loss = 0.00387267
Iteration 6102, loss = 0.00387168
Iteration 6103, loss = 0.00387071
Iteration 6104, loss = 0.00386983
Iteration 6105, loss = 0.00386911
Iteration 6106, loss = 0.00386817
Iteration 6107, loss = 0.00386714
Iteration 6108, loss = 0.00386704
Iteration 6109, loss = 0.00386541
Iteration 6110, loss = 0.00386466
Iteration 6111, loss = 0.00386372
Iteration 6112, loss = 0.00386298
Iteration 6113, loss = 0.00386187
Iteration 6114, loss = 0.00386115
Iteration 6115, loss = 0.00386015
Iteration 6116, loss = 0.00385928
Iteration 6117, loss = 0.00385836
Iteration 6118, loss = 0.00385769
Iteration 6119, loss = 0.00385692
Iteration 6120, loss = 0.00385628
Iteration 6121, loss = 0.00385563
Iteration 6122, loss = 0.00385468
Iteration 6123, loss = 0.00385386
Iteration 6124, loss = 0.00385288
Iteration 6125, loss = 0.00385200
Iteration 6126, loss = 0.00385130
Iteration 6127, loss = 0.00385031
Iteration 6128, loss = 0.00384934
Iteration 6129, loss = 0.00384836
Iteration 6130, loss = 0.00384742
Iteration 6131, loss = 0.00384649
Iteration 6132, loss = 0.00384536
Iteration 6133, loss = 0.00384477
Iteration 6134, loss = 0.00384386
Iteration 6135, loss = 0.00384266
Iteration 6136, loss = 0.00384223
Iteration 6137, loss = 0.00384098
Iteration 6138, loss = 0.00384031
Iteration 6139, loss = 0.00383940
Iteration 6140, loss = 0.00383846
Iteration 6141, loss = 0.00383760
Iteration 6142, loss = 0.00383718
Iteration 6143, loss = 0.00383631
Iteration 6144, loss = 0.00383556
Iteration 6145, loss = 0.00383488
Iteration 6146, loss = 0.00383360
Iteration 6147, loss = 0.00383308
Iteration 6148, loss = 0.00383186
Iteration 6149, loss = 0.00383109
Iteration 6150, loss = 0.00383013
Iteration 6151, loss = 0.00382918
Iteration 6152, loss = 0.00382838
Iteration 6153, loss = 0.00382722
Iteration 6154, loss = 0.00382626
Iteration 6155, loss = 0.00382531
Iteration 6156, loss = 0.00382431
Iteration 6157, loss = 0.00382345
Iteration 6158, loss = 0.00382252
Iteration 6159, loss = 0.00382149
Iteration 6160, loss = 0.00382066
Iteration 6161, loss = 0.00381978
Iteration 6162, loss = 0.00381900
Iteration 6163, loss = 0.00381805
Iteration 6164, loss = 0.00381737
Iteration 6165, loss = 0.00381625
Iteration 6166, loss = 0.00381538
Iteration 6167, loss = 0.00381454
Iteration 6168, loss = 0.00381370
Iteration 6169, loss = 0.00381295
Iteration 6170, loss = 0.00381188
Iteration 6171, loss = 0.00381112
Iteration 6172, loss = 0.00381045
Iteration 6173, loss = 0.00380924
Iteration 6174, loss = 0.00380848
Iteration 6175, loss = 0.00380754
Iteration 6176, loss = 0.00380669
Iteration 6177, loss = 0.00380598
Iteration 6178, loss = 0.00380484
Iteration 6179, loss = 0.00380391
Iteration 6180, loss = 0.00380312
Iteration 6181, loss = 0.00380245
Iteration 6182, loss = 0.00380156
Iteration 6183, loss = 0.00380070
Iteration 6184, loss = 0.00379983
Iteration 6185, loss = 0.00379909
Iteration 6186, loss = 0.00379819
Iteration 6187, loss = 0.00379743
Iteration 6188, loss = 0.00379655
Iteration 6189, loss = 0.00379571
Iteration 6190, loss = 0.00379498
Iteration 6191, loss = 0.00379419
Iteration 6192, loss = 0.00379335
Iteration 6193, loss = 0.00379254
Iteration 6194, loss = 0.00379161
Iteration 6195, loss = 0.00379088
Iteration 6196, loss = 0.00378988
Iteration 6197, loss = 0.00378938
Iteration 6198, loss = 0.00378821
Iteration 6199, loss = 0.00378744
Iteration 6200, loss = 0.00378679
Iteration 6201, loss = 0.00378564
Iteration 6202, loss = 0.00378478
Iteration 6203, loss = 0.00378401
Iteration 6204, loss = 0.00378335
Iteration 6205, loss = 0.00378225
Iteration 6206, loss = 0.00378181
Iteration 6207, loss = 0.00378063
Iteration 6208, loss = 0.00377983
Iteration 6209, loss = 0.00377922
Iteration 6210, loss = 0.00377819
Iteration 6211, loss = 0.00377731
Iteration 6212, loss = 0.00377638
Iteration 6213, loss = 0.00377571
Iteration 6214, loss = 0.00377476
Iteration 6215, loss = 0.00377392
Iteration 6216, loss = 0.00377321
Iteration 6217, loss = 0.00377259
Iteration 6218, loss = 0.00377160
Iteration 6219, loss = 0.00377101
Iteration 6220, loss = 0.00377007
Iteration 6221, loss = 0.00376930
Iteration 6222, loss = 0.00376842
Iteration 6223, loss = 0.00376774
Iteration 6224, loss = 0.00376688
Iteration 6225, loss = 0.00376601
Iteration 6226, loss = 0.00376525
Iteration 6227, loss = 0.00376422
Iteration 6228, loss = 0.00376340
Iteration 6229, loss = 0.00376277
Iteration 6230, loss = 0.00376185
Iteration 6231, loss = 0.00376142
Iteration 6232, loss = 0.00376033
Iteration 6233, loss = 0.00375972
Iteration 6234, loss = 0.00375887
Iteration 6235, loss = 0.00375799
Iteration 6236, loss = 0.00375724
Iteration 6237, loss = 0.00375646
Iteration 6238, loss = 0.00375559
Iteration 6239, loss = 0.00375499
Iteration 6240, loss = 0.00375407
Iteration 6241, loss = 0.00375318
Iteration 6242, loss = 0.00375253
Iteration 6243, loss = 0.00375171
Iteration 6244, loss = 0.00375110
Iteration 6245, loss = 0.00375026
Iteration 6246, loss = 0.00374947
Iteration 6247, loss = 0.00374862
Iteration 6248, loss = 0.00374776
Iteration 6249, loss = 0.00374683
Iteration 6250, loss = 0.00374590
Iteration 6251, loss = 0.00374519
Iteration 6252, loss = 0.00374435
Iteration 6253, loss = 0.00374373
Iteration 6254, loss = 0.00374271
Iteration 6255, loss = 0.00374199
Iteration 6256, loss = 0.00374110
Iteration 6257, loss = 0.00374036
Iteration 6258, loss = 0.00373942
Iteration 6259, loss = 0.00373857
Iteration 6260, loss = 0.00373771
Iteration 6261, loss = 0.00373710
Iteration 6262, loss = 0.00373627
Iteration 6263, loss = 0.00373571
Iteration 6264, loss = 0.00373484
Iteration 6265, loss = 0.00373442
Iteration 6266, loss = 0.00373345
Iteration 6267, loss = 0.00373282
Iteration 6268, loss = 0.00373203
Iteration 6269, loss = 0.00373134
Iteration 6270, loss = 0.00373070
Iteration 6271, loss = 0.00372988
Iteration 6272, loss = 0.00372916
Iteration 6273, loss = 0.00372826
Iteration 6274, loss = 0.00372744
Iteration 6275, loss = 0.00372657
Iteration 6276, loss = 0.00372584
Iteration 6277, loss = 0.00372550
Iteration 6278, loss = 0.00372426
Iteration 6279, loss = 0.00372337
Iteration 6280, loss = 0.00372282
Iteration 6281, loss = 0.00372174
Iteration 6282, loss = 0.00372090
Iteration 6283, loss = 0.00372029
Iteration 6284, loss = 0.00371938
Iteration 6285, loss = 0.00371859
Iteration 6286, loss = 0.00371777
Iteration 6287, loss = 0.00371691
Iteration 6288, loss = 0.00371611
Iteration 6289, loss = 0.00371528
Iteration 6290, loss = 0.00371432
Iteration 6291, loss = 0.00371394
Iteration 6292, loss = 0.00371276
Iteration 6293, loss = 0.00371283
Iteration 6294, loss = 0.00371143
Iteration 6295, loss = 0.00371055
Iteration 6296, loss = 0.00370966
Iteration 6297, loss = 0.00370884
Iteration 6298, loss = 0.00370807
Iteration 6299, loss = 0.00370742
Iteration 6300, loss = 0.00370665
Iteration 6301, loss = 0.00370585
Iteration 6302, loss = 0.00370533
Iteration 6303, loss = 0.00370446
Iteration 6304, loss = 0.00370397
Iteration 6305, loss = 0.00370323
Iteration 6306, loss = 0.00370233
Iteration 6307, loss = 0.00370164
Iteration 6308, loss = 0.00370074
Iteration 6309, loss = 0.00370020
Iteration 6310, loss = 0.00369930
Iteration 6311, loss = 0.00369865
Iteration 6312, loss = 0.00369823
Iteration 6313, loss = 0.00369741
Iteration 6314, loss = 0.00369669
Iteration 6315, loss = 0.00369595
Iteration 6316, loss = 0.00369563
Iteration 6317, loss = 0.00369460
Iteration 6318, loss = 0.00369382
Iteration 6319, loss = 0.00369316
Iteration 6320, loss = 0.00369224
Iteration 6321, loss = 0.00369159
Iteration 6322, loss = 0.00369109
Iteration 6323, loss = 0.00369063
Iteration 6324, loss = 0.00368994
Iteration 6325, loss = 0.00368919
Iteration 6326, loss = 0.00368865
Iteration 6327, loss = 0.00368856
Iteration 6328, loss = 0.00368761
Iteration 6329, loss = 0.00368712
Iteration 6330, loss = 0.00368625
Iteration 6331, loss = 0.00368561
Iteration 6332, loss = 0.00368476
Iteration 6333, loss = 0.00368412
Iteration 6334, loss = 0.00368321
Iteration 6335, loss = 0.00368263
Iteration 6336, loss = 0.00368177
Iteration 6337, loss = 0.00368096
Iteration 6338, loss = 0.00368021
Iteration 6339, loss = 0.00367936
Iteration 6340, loss = 0.00367894
Iteration 6341, loss = 0.00367900
Iteration 6342, loss = 0.00367816
Iteration 6343, loss = 0.00367764
Iteration 6344, loss = 0.00367683
Iteration 6345, loss = 0.00367615
Iteration 6346, loss = 0.00367542
Iteration 6347, loss = 0.00367468
Iteration 6348, loss = 0.00367408
Iteration 6349, loss = 0.00367354
Iteration 6350, loss = 0.00367271
Iteration 6351, loss = 0.00367158
Iteration 6352, loss = 0.00367035
Iteration 6353, loss = 0.00366932
Iteration 6354, loss = 0.00366811
Iteration 6355, loss = 0.00366772
Iteration 6356, loss = 0.00366612
Iteration 6357, loss = 0.00366504
Iteration 6358, loss = 0.00366452
Iteration 6359, loss = 0.00366319
Iteration 6360, loss = 0.00366211
Iteration 6361, loss = 0.00366104
Iteration 6362, loss = 0.00366034
Iteration 6363, loss = 0.00365915
Iteration 6364, loss = 0.00365822
Iteration 6365, loss = 0.00365764
Iteration 6366, loss = 0.00365647
Iteration 6367, loss = 0.00365570
Iteration 6368, loss = 0.00365495
Iteration 6369, loss = 0.00365413
Iteration 6370, loss = 0.00365341
Iteration 6371, loss = 0.00365273
Iteration 6372, loss = 0.00365213
Iteration 6373, loss = 0.00365152
Iteration 6374, loss = 0.00365062
Iteration 6375, loss = 0.00364996
Iteration 6376, loss = 0.00364911
Iteration 6377, loss = 0.00364844
Iteration 6378, loss = 0.00364749
Iteration 6379, loss = 0.00364676
Iteration 6380, loss = 0.00364609
Iteration 6381, loss = 0.00364519
Iteration 6382, loss = 0.00364452
Iteration 6383, loss = 0.00364352
Iteration 6384, loss = 0.00364290
Iteration 6385, loss = 0.00364188
Iteration 6386, loss = 0.00364101
Iteration 6387, loss = 0.00364021
Iteration 6388, loss = 0.00363947
Iteration 6389, loss = 0.00363883
Iteration 6390, loss = 0.00363784
Iteration 6391, loss = 0.00363694
Iteration 6392, loss = 0.00363638
Iteration 6393, loss = 0.00363543
Iteration 6394, loss = 0.00363443
Iteration 6395, loss = 0.00363395
Iteration 6396, loss = 0.00363289
Iteration 6397, loss = 0.00363197
Iteration 6398, loss = 0.00363115
Iteration 6399, loss = 0.00363050
Iteration 6400, loss = 0.00362930
Iteration 6401, loss = 0.00362827
Iteration 6402, loss = 0.00362745
Iteration 6403, loss = 0.00362629
Iteration 6404, loss = 0.00362519
Iteration 6405, loss = 0.00362440
Iteration 6406, loss = 0.00362361
Iteration 6407, loss = 0.00362271
Iteration 6408, loss = 0.00362165
Iteration 6409, loss = 0.00362094
Iteration 6410, loss = 0.00362019
Iteration 6411, loss = 0.00361933
Iteration 6412, loss = 0.00361859
Iteration 6413, loss = 0.00361781
Iteration 6414, loss = 0.00361699
Iteration 6415, loss = 0.00361611
Iteration 6416, loss = 0.00361519
Iteration 6417, loss = 0.00361442
Iteration 6418, loss = 0.00361351
Iteration 6419, loss = 0.00361251
Iteration 6420, loss = 0.00361161
Iteration 6421, loss = 0.00361090
Iteration 6422, loss = 0.00361001
Iteration 6423, loss = 0.00360943
Iteration 6424, loss = 0.00360830
Iteration 6425, loss = 0.00360763
Iteration 6426, loss = 0.00360687
Iteration 6427, loss = 0.00360606
Iteration 6428, loss = 0.00360532
Iteration 6429, loss = 0.00360456
Iteration 6430, loss = 0.00360383
Iteration 6431, loss = 0.00360313
Iteration 6432, loss = 0.00360237
Iteration 6433, loss = 0.00360156
Iteration 6434, loss = 0.00360099
Iteration 6435, loss = 0.00360008
Iteration 6436, loss = 0.00359929
Iteration 6437, loss = 0.00359843
Iteration 6438, loss = 0.00359768
Iteration 6439, loss = 0.00359678
Iteration 6440, loss = 0.00359613
Iteration 6441, loss = 0.00359545
Iteration 6442, loss = 0.00359483
Iteration 6443, loss = 0.00359411
Iteration 6444, loss = 0.00359356
Iteration 6445, loss = 0.00359285
Iteration 6446, loss = 0.00359232
Iteration 6447, loss = 0.00359167
Iteration 6448, loss = 0.00359055
Iteration 6449, loss = 0.00358961
Iteration 6450, loss = 0.00358875
Iteration 6451, loss = 0.00358776
Iteration 6452, loss = 0.00358691
Iteration 6453, loss = 0.00358608
Iteration 6454, loss = 0.00358525
Iteration 6455, loss = 0.00358445
Iteration 6456, loss = 0.00358355
Iteration 6457, loss = 0.00358269
Iteration 6458, loss = 0.00358200
Iteration 6459, loss = 0.00358142
Iteration 6460, loss = 0.00358052
Iteration 6461, loss = 0.00357971
Iteration 6462, loss = 0.00357912
Iteration 6463, loss = 0.00357819
Iteration 6464, loss = 0.00357742
Iteration 6465, loss = 0.00357666
Iteration 6466, loss = 0.00357590
Iteration 6467, loss = 0.00357511
Iteration 6468, loss = 0.00357438
Iteration 6469, loss = 0.00357345
Iteration 6470, loss = 0.00357263
Iteration 6471, loss = 0.00357188
Iteration 6472, loss = 0.00357093
Iteration 6473, loss = 0.00357011
Iteration 6474, loss = 0.00356922
Iteration 6475, loss = 0.00356895
Iteration 6476, loss = 0.00356823
Iteration 6477, loss = 0.00356772
Iteration 6478, loss = 0.00356656
Iteration 6479, loss = 0.00356577
Iteration 6480, loss = 0.00356503
Iteration 6481, loss = 0.00356432
Iteration 6482, loss = 0.00356357
Iteration 6483, loss = 0.00356294
Iteration 6484, loss = 0.00356206
Iteration 6485, loss = 0.00356137
Iteration 6486, loss = 0.00356062
Iteration 6487, loss = 0.00355991
Iteration 6488, loss = 0.00355928
Iteration 6489, loss = 0.00355850
Iteration 6490, loss = 0.00355768
Iteration 6491, loss = 0.00355682
Iteration 6492, loss = 0.00355667
Iteration 6493, loss = 0.00355566
Iteration 6494, loss = 0.00355469
Iteration 6495, loss = 0.00355387
Iteration 6496, loss = 0.00355327
Iteration 6497, loss = 0.00355265
Iteration 6498, loss = 0.00355161
Iteration 6499, loss = 0.00355085
Iteration 6500, loss = 0.00355011
Iteration 6501, loss = 0.00354949
Iteration 6502, loss = 0.00354881
Iteration 6503, loss = 0.00354804
Iteration 6504, loss = 0.00354720
Iteration 6505, loss = 0.00354638
Iteration 6506, loss = 0.00354569
Iteration 6507, loss = 0.00354499
Iteration 6508, loss = 0.00354432
Iteration 6509, loss = 0.00354361
Iteration 6510, loss = 0.00354276
Iteration 6511, loss = 0.00354202
Iteration 6512, loss = 0.00354140
Iteration 6513, loss = 0.00354053
Iteration 6514, loss = 0.00353990
Iteration 6515, loss = 0.00353902
Iteration 6516, loss = 0.00353829
Iteration 6517, loss = 0.00353761
Iteration 6518, loss = 0.00353678
Iteration 6519, loss = 0.00353618
Iteration 6520, loss = 0.00353583
Iteration 6521, loss = 0.00353470
Iteration 6522, loss = 0.00353401
Iteration 6523, loss = 0.00353331
Iteration 6524, loss = 0.00353243
Iteration 6525, loss = 0.00353162
Iteration 6526, loss = 0.00353078
Iteration 6527, loss = 0.00353012
Iteration 6528, loss = 0.00352924
Iteration 6529, loss = 0.00352859
Iteration 6530, loss = 0.00352777
Iteration 6531, loss = 0.00352694
Iteration 6532, loss = 0.00352617
Iteration 6533, loss = 0.00352546
Iteration 6534, loss = 0.00352466
Iteration 6535, loss = 0.00352385
Iteration 6536, loss = 0.00352335
Iteration 6537, loss = 0.00352251
Iteration 6538, loss = 0.00352173
Iteration 6539, loss = 0.00352099
Iteration 6540, loss = 0.00352033
Iteration 6541, loss = 0.00351967
Iteration 6542, loss = 0.00351900
Iteration 6543, loss = 0.00351831
Iteration 6544, loss = 0.00351750
Iteration 6545, loss = 0.00351688
Iteration 6546, loss = 0.00351612
Iteration 6547, loss = 0.00351535
Iteration 6548, loss = 0.00351469
Iteration 6549, loss = 0.00351401
Iteration 6550, loss = 0.00351334
Iteration 6551, loss = 0.00351248
Iteration 6552, loss = 0.00351165
Iteration 6553, loss = 0.00351099
Iteration 6554, loss = 0.00351032
Iteration 6555, loss = 0.00350942
Iteration 6556, loss = 0.00350859
Iteration 6557, loss = 0.00350795
Iteration 6558, loss = 0.00350709
Iteration 6559, loss = 0.00350649
Iteration 6560, loss = 0.00350592
Iteration 6561, loss = 0.00350477
Iteration 6562, loss = 0.00350429
Iteration 6563, loss = 0.00350314
Iteration 6564, loss = 0.00350238
Iteration 6565, loss = 0.00350162
Iteration 6566, loss = 0.00350085
Iteration 6567, loss = 0.00350029
Iteration 6568, loss = 0.00349950
Iteration 6569, loss = 0.00349858
Iteration 6570, loss = 0.00349780
Iteration 6571, loss = 0.00349709
Iteration 6572, loss = 0.00349634
Iteration 6573, loss = 0.00349572
Iteration 6574, loss = 0.00349505
Iteration 6575, loss = 0.00349428
Iteration 6576, loss = 0.00349349
Iteration 6577, loss = 0.00349277
Iteration 6578, loss = 0.00349226
Iteration 6579, loss = 0.00349141
Iteration 6580, loss = 0.00349063
Iteration 6581, loss = 0.00348996
Iteration 6582, loss = 0.00348912
Iteration 6583, loss = 0.00348839
Iteration 6584, loss = 0.00348770
Iteration 6585, loss = 0.00348698
Iteration 6586, loss = 0.00348624
Iteration 6587, loss = 0.00348551
Iteration 6588, loss = 0.00348491
Iteration 6589, loss = 0.00348385
Iteration 6590, loss = 0.00348305
Iteration 6591, loss = 0.00348234
Iteration 6592, loss = 0.00348150
Iteration 6593, loss = 0.00348079
Iteration 6594, loss = 0.00348008
Iteration 6595, loss = 0.00347956
Iteration 6596, loss = 0.00347895
Iteration 6597, loss = 0.00347789
Iteration 6598, loss = 0.00347717
Iteration 6599, loss = 0.00347642
Iteration 6600, loss = 0.00347562
Iteration 6601, loss = 0.00347490
Iteration 6602, loss = 0.00347432
Iteration 6603, loss = 0.00347363
Iteration 6604, loss = 0.00347289
Iteration 6605, loss = 0.00347208
Iteration 6606, loss = 0.00347138
Iteration 6607, loss = 0.00347086
Iteration 6608, loss = 0.00347004
Iteration 6609, loss = 0.00346931
Iteration 6610, loss = 0.00346865
Iteration 6611, loss = 0.00346798
Iteration 6612, loss = 0.00346732
Iteration 6613, loss = 0.00346671
Iteration 6614, loss = 0.00346598
Iteration 6615, loss = 0.00346538
Iteration 6616, loss = 0.00346468
Iteration 6617, loss = 0.00346394
Iteration 6618, loss = 0.00346327
Iteration 6619, loss = 0.00346266
Iteration 6620, loss = 0.00346216
Iteration 6621, loss = 0.00346168
Iteration 6622, loss = 0.00346066
Iteration 6623, loss = 0.00345994
Iteration 6624, loss = 0.00345939
Iteration 6625, loss = 0.00345863
Iteration 6626, loss = 0.00345798
Iteration 6627, loss = 0.00345732
Iteration 6628, loss = 0.00345664
Iteration 6629, loss = 0.00345600
Iteration 6630, loss = 0.00345532
Iteration 6631, loss = 0.00345450
Iteration 6632, loss = 0.00345377
Iteration 6633, loss = 0.00345298
Iteration 6634, loss = 0.00345241
Iteration 6635, loss = 0.00345185
Iteration 6636, loss = 0.00345109
Iteration 6637, loss = 0.00345035
Iteration 6638, loss = 0.00344965
Iteration 6639, loss = 0.00344901
Iteration 6640, loss = 0.00344827
Iteration 6641, loss = 0.00344793
Iteration 6642, loss = 0.00344703
Iteration 6643, loss = 0.00344634
Iteration 6644, loss = 0.00344560
Iteration 6645, loss = 0.00344488
Iteration 6646, loss = 0.00344423
Iteration 6647, loss = 0.00344372
Iteration 6648, loss = 0.00344325
Iteration 6649, loss = 0.00344251
Iteration 6650, loss = 0.00344169
Iteration 6651, loss = 0.00344095
Iteration 6652, loss = 0.00344063
Iteration 6653, loss = 0.00343971
Iteration 6654, loss = 0.00343904
Iteration 6655, loss = 0.00343837
Iteration 6656, loss = 0.00343772
Iteration 6657, loss = 0.00343707
Iteration 6658, loss = 0.00343655
Iteration 6659, loss = 0.00343583
Iteration 6660, loss = 0.00343531
Iteration 6661, loss = 0.00343464
Iteration 6662, loss = 0.00343393
Iteration 6663, loss = 0.00343344
Iteration 6664, loss = 0.00343265
Iteration 6665, loss = 0.00343193
Iteration 6666, loss = 0.00343196
Iteration 6667, loss = 0.00343055
Iteration 6668, loss = 0.00342998
Iteration 6669, loss = 0.00342916
Iteration 6670, loss = 0.00342850
Iteration 6671, loss = 0.00342782
Iteration 6672, loss = 0.00342720
Iteration 6673, loss = 0.00342655
Iteration 6674, loss = 0.00342581
Iteration 6675, loss = 0.00342529
Iteration 6676, loss = 0.00342437
Iteration 6677, loss = 0.00342379
Iteration 6678, loss = 0.00342300
Iteration 6679, loss = 0.00342212
Iteration 6680, loss = 0.00342124
Iteration 6681, loss = 0.00342050
Iteration 6682, loss = 0.00341979
Iteration 6683, loss = 0.00341923
Iteration 6684, loss = 0.00341829
Iteration 6685, loss = 0.00341757
Iteration 6686, loss = 0.00341697
Iteration 6687, loss = 0.00341607
Iteration 6688, loss = 0.00341561
Iteration 6689, loss = 0.00341466
Iteration 6690, loss = 0.00341393
Iteration 6691, loss = 0.00341334
Iteration 6692, loss = 0.00341270
Iteration 6693, loss = 0.00341179
Iteration 6694, loss = 0.00341105
Iteration 6695, loss = 0.00341044
Iteration 6696, loss = 0.00340968
Iteration 6697, loss = 0.00340897
Iteration 6698, loss = 0.00340834
Iteration 6699, loss = 0.00340815
Iteration 6700, loss = 0.00340695
Iteration 6701, loss = 0.00340634
Iteration 6702, loss = 0.00340539
Iteration 6703, loss = 0.00340481
Iteration 6704, loss = 0.00340392
Iteration 6705, loss = 0.00340300
Iteration 6706, loss = 0.00340221
Iteration 6707, loss = 0.00340175
Iteration 6708, loss = 0.00340081
Iteration 6709, loss = 0.00340025
Iteration 6710, loss = 0.00339981
Iteration 6711, loss = 0.00339865
Iteration 6712, loss = 0.00339779
Iteration 6713, loss = 0.00339699
Iteration 6714, loss = 0.00339633
Iteration 6715, loss = 0.00339551
Iteration 6716, loss = 0.00339493
Iteration 6717, loss = 0.00339399
Iteration 6718, loss = 0.00339329
Iteration 6719, loss = 0.00339257
Iteration 6720, loss = 0.00339162
Iteration 6721, loss = 0.00339088
Iteration 6722, loss = 0.00339042
Iteration 6723, loss = 0.00338976
Iteration 6724, loss = 0.00338883
Iteration 6725, loss = 0.00338806
Iteration 6726, loss = 0.00338749
Iteration 6727, loss = 0.00338647
Iteration 6728, loss = 0.00338611
Iteration 6729, loss = 0.00338506
Iteration 6730, loss = 0.00338448
Iteration 6731, loss = 0.00338357
Iteration 6732, loss = 0.00338293
Iteration 6733, loss = 0.00338207
Iteration 6734, loss = 0.00338120
Iteration 6735, loss = 0.00338058
Iteration 6736, loss = 0.00337988
Iteration 6737, loss = 0.00337933
Iteration 6738, loss = 0.00337845
Iteration 6739, loss = 0.00337773
Iteration 6740, loss = 0.00337706
Iteration 6741, loss = 0.00337634
Iteration 6742, loss = 0.00337576
Iteration 6743, loss = 0.00337518
Iteration 6744, loss = 0.00337443
Iteration 6745, loss = 0.00337404
Iteration 6746, loss = 0.00337320
Iteration 6747, loss = 0.00337259
Iteration 6748, loss = 0.00337202
Iteration 6749, loss = 0.00337136
Iteration 6750, loss = 0.00337069
Iteration 6751, loss = 0.00337001
Iteration 6752, loss = 0.00336931
Iteration 6753, loss = 0.00336858
Iteration 6754, loss = 0.00336803
Iteration 6755, loss = 0.00336729
Iteration 6756, loss = 0.00336666
Iteration 6757, loss = 0.00336602
Iteration 6758, loss = 0.00336544
Iteration 6759, loss = 0.00336484
Iteration 6760, loss = 0.00336425
Iteration 6761, loss = 0.00336341
Iteration 6762, loss = 0.00336297
Iteration 6763, loss = 0.00336199
Iteration 6764, loss = 0.00336145
Iteration 6765, loss = 0.00336092
Iteration 6766, loss = 0.00335999
Iteration 6767, loss = 0.00335935
Iteration 6768, loss = 0.00335874
Iteration 6769, loss = 0.00335814
Iteration 6770, loss = 0.00335748
Iteration 6771, loss = 0.00335676
Iteration 6772, loss = 0.00335608
Iteration 6773, loss = 0.00335539
Iteration 6774, loss = 0.00335470
Iteration 6775, loss = 0.00335379
Iteration 6776, loss = 0.00335321
Iteration 6777, loss = 0.00335251
Iteration 6778, loss = 0.00335206
Iteration 6779, loss = 0.00335104
Iteration 6780, loss = 0.00335047
Iteration 6781, loss = 0.00334985
Iteration 6782, loss = 0.00334918
Iteration 6783, loss = 0.00334879
Iteration 6784, loss = 0.00334795
Iteration 6785, loss = 0.00334726
Iteration 6786, loss = 0.00334650
Iteration 6787, loss = 0.00334564
Iteration 6788, loss = 0.00334496
Iteration 6789, loss = 0.00334426
Iteration 6790, loss = 0.00334351
Iteration 6791, loss = 0.00334283
Iteration 6792, loss = 0.00334229
Iteration 6793, loss = 0.00334142
Iteration 6794, loss = 0.00334100
Iteration 6795, loss = 0.00334001
Iteration 6796, loss = 0.00333953
Iteration 6797, loss = 0.00333869
Iteration 6798, loss = 0.00333793
Iteration 6799, loss = 0.00333718
Iteration 6800, loss = 0.00333655
Iteration 6801, loss = 0.00333593
Iteration 6802, loss = 0.00333523
Iteration 6803, loss = 0.00333447
Iteration 6804, loss = 0.00333388
Iteration 6805, loss = 0.00333315
Iteration 6806, loss = 0.00333250
Iteration 6807, loss = 0.00333188
Iteration 6808, loss = 0.00333128
Iteration 6809, loss = 0.00333052
Iteration 6810, loss = 0.00332986
Iteration 6811, loss = 0.00332925
Iteration 6812, loss = 0.00332863
Iteration 6813, loss = 0.00332838
Iteration 6814, loss = 0.00332745
Iteration 6815, loss = 0.00332691
Iteration 6816, loss = 0.00332634
Iteration 6817, loss = 0.00332558
Iteration 6818, loss = 0.00332495
Iteration 6819, loss = 0.00332426
Iteration 6820, loss = 0.00332356
Iteration 6821, loss = 0.00332292
Iteration 6822, loss = 0.00332228
Iteration 6823, loss = 0.00332187
Iteration 6824, loss = 0.00332107
Iteration 6825, loss = 0.00332052
Iteration 6826, loss = 0.00331974
Iteration 6827, loss = 0.00331917
Iteration 6828, loss = 0.00331845
Iteration 6829, loss = 0.00331785
Iteration 6830, loss = 0.00331714
Iteration 6831, loss = 0.00331647
Iteration 6832, loss = 0.00331589
Iteration 6833, loss = 0.00331525
Iteration 6834, loss = 0.00331460
Iteration 6835, loss = 0.00331385
Iteration 6836, loss = 0.00331309
Iteration 6837, loss = 0.00331236
Iteration 6838, loss = 0.00331201
Iteration 6839, loss = 0.00331104
Iteration 6840, loss = 0.00331035
Iteration 6841, loss = 0.00330991
Iteration 6842, loss = 0.00330915
Iteration 6843, loss = 0.00330858
Iteration 6844, loss = 0.00330787
Iteration 6845, loss = 0.00330713
Iteration 6846, loss = 0.00330642
Iteration 6847, loss = 0.00330571
Iteration 6848, loss = 0.00330506
Iteration 6849, loss = 0.00330435
Iteration 6850, loss = 0.00330382
Iteration 6851, loss = 0.00330312
Iteration 6852, loss = 0.00330242
Iteration 6853, loss = 0.00330171
Iteration 6854, loss = 0.00330108
Iteration 6855, loss = 0.00330035
Iteration 6856, loss = 0.00329980
Iteration 6857, loss = 0.00329905
Iteration 6858, loss = 0.00329822
Iteration 6859, loss = 0.00329761
Iteration 6860, loss = 0.00329692
Iteration 6861, loss = 0.00329616
Iteration 6862, loss = 0.00329545
Iteration 6863, loss = 0.00329481
Iteration 6864, loss = 0.00329403
Iteration 6865, loss = 0.00329338
Iteration 6866, loss = 0.00329261
Iteration 6867, loss = 0.00329181
Iteration 6868, loss = 0.00329120
Iteration 6869, loss = 0.00329072
Iteration 6870, loss = 0.00328990
Iteration 6871, loss = 0.00328926
Iteration 6872, loss = 0.00328862
Iteration 6873, loss = 0.00328820
Iteration 6874, loss = 0.00328734
Iteration 6875, loss = 0.00328685
Iteration 6876, loss = 0.00328602
Iteration 6877, loss = 0.00328547
Iteration 6878, loss = 0.00328489
Iteration 6879, loss = 0.00328445
Iteration 6880, loss = 0.00328372
Iteration 6881, loss = 0.00328289
Iteration 6882, loss = 0.00328217
Iteration 6883, loss = 0.00328158
Iteration 6884, loss = 0.00328082
Iteration 6885, loss = 0.00328015
Iteration 6886, loss = 0.00327934
Iteration 6887, loss = 0.00327884
Iteration 6888, loss = 0.00327805
Iteration 6889, loss = 0.00327765
Iteration 6890, loss = 0.00327677
Iteration 6891, loss = 0.00327616
Iteration 6892, loss = 0.00327548
Iteration 6893, loss = 0.00327488
Iteration 6894, loss = 0.00327427
Iteration 6895, loss = 0.00327391
Iteration 6896, loss = 0.00327299
Iteration 6897, loss = 0.00327235
Iteration 6898, loss = 0.00327173
Iteration 6899, loss = 0.00327109
Iteration 6900, loss = 0.00327038
Iteration 6901, loss = 0.00326968
Iteration 6902, loss = 0.00326902
Iteration 6903, loss = 0.00326834
Iteration 6904, loss = 0.00326760
Iteration 6905, loss = 0.00326706
Iteration 6906, loss = 0.00326617
Iteration 6907, loss = 0.00326575
Iteration 6908, loss = 0.00326485
Iteration 6909, loss = 0.00326423
Iteration 6910, loss = 0.00326346
Iteration 6911, loss = 0.00326273
Iteration 6912, loss = 0.00326196
Iteration 6913, loss = 0.00326173
Iteration 6914, loss = 0.00326069
Iteration 6915, loss = 0.00325990
Iteration 6916, loss = 0.00325918
Iteration 6917, loss = 0.00325855
Iteration 6918, loss = 0.00325780
Iteration 6919, loss = 0.00325718
Iteration 6920, loss = 0.00325633
Iteration 6921, loss = 0.00325571
Iteration 6922, loss = 0.00325552
Iteration 6923, loss = 0.00325428
Iteration 6924, loss = 0.00325392
Iteration 6925, loss = 0.00325296
Iteration 6926, loss = 0.00325243
Iteration 6927, loss = 0.00325164
Iteration 6928, loss = 0.00325091
Iteration 6929, loss = 0.00325026
Iteration 6930, loss = 0.00324959
Iteration 6931, loss = 0.00324904
Iteration 6932, loss = 0.00324829
Iteration 6933, loss = 0.00324757
Iteration 6934, loss = 0.00324691
Iteration 6935, loss = 0.00324628
Iteration 6936, loss = 0.00324560
Iteration 6937, loss = 0.00324495
Iteration 6938, loss = 0.00324434
Iteration 6939, loss = 0.00324373
Iteration 6940, loss = 0.00324306
Iteration 6941, loss = 0.00324245
Iteration 6942, loss = 0.00324186
Iteration 6943, loss = 0.00324098
Iteration 6944, loss = 0.00324027
Iteration 6945, loss = 0.00323963
Iteration 6946, loss = 0.00323896
Iteration 6947, loss = 0.00323827
Iteration 6948, loss = 0.00323761
Iteration 6949, loss = 0.00323685
Iteration 6950, loss = 0.00323601
Iteration 6951, loss = 0.00323565
Iteration 6952, loss = 0.00323531
Iteration 6953, loss = 0.00323420
Iteration 6954, loss = 0.00323359
Iteration 6955, loss = 0.00323306
Iteration 6956, loss = 0.00323231
Iteration 6957, loss = 0.00323184
Iteration 6958, loss = 0.00323101
Iteration 6959, loss = 0.00323040
Iteration 6960, loss = 0.00322978
Iteration 6961, loss = 0.00322912
Iteration 6962, loss = 0.00322866
Iteration 6963, loss = 0.00322786
Iteration 6964, loss = 0.00322754
Iteration 6965, loss = 0.00322668
Iteration 6966, loss = 0.00322607
Iteration 6967, loss = 0.00322541
Iteration 6968, loss = 0.00322483
Iteration 6969, loss = 0.00322419
Iteration 6970, loss = 0.00322357
Iteration 6971, loss = 0.00322301
Iteration 6972, loss = 0.00322246
Iteration 6973, loss = 0.00322185
Iteration 6974, loss = 0.00322174
Iteration 6975, loss = 0.00322060
Iteration 6976, loss = 0.00321987
Iteration 6977, loss = 0.00321951
Iteration 6978, loss = 0.00321866
Iteration 6979, loss = 0.00321829
Iteration 6980, loss = 0.00321740
Iteration 6981, loss = 0.00321685
Iteration 6982, loss = 0.00321618
Iteration 6983, loss = 0.00321551
Iteration 6984, loss = 0.00321499
Iteration 6985, loss = 0.00321422
Iteration 6986, loss = 0.00321365
Iteration 6987, loss = 0.00321310
Iteration 6988, loss = 0.00321237
Iteration 6989, loss = 0.00321163
Iteration 6990, loss = 0.00321102
Iteration 6991, loss = 0.00321036
Iteration 6992, loss = 0.00320986
Iteration 6993, loss = 0.00320916
Iteration 6994, loss = 0.00320863
Iteration 6995, loss = 0.00320821
Iteration 6996, loss = 0.00320733
Iteration 6997, loss = 0.00320692
Iteration 6998, loss = 0.00320615
Iteration 6999, loss = 0.00320557
Iteration 7000, loss = 0.00320498
Iteration 7001, loss = 0.00320446
Iteration 7002, loss = 0.00320375
Iteration 7003, loss = 0.00320313
Iteration 7004, loss = 0.00320273
Iteration 7005, loss = 0.00320196
Iteration 7006, loss = 0.00320128
Iteration 7007, loss = 0.00320072
Iteration 7008, loss = 0.00320020
Iteration 7009, loss = 0.00319945
Iteration 7010, loss = 0.00319870
Iteration 7011, loss = 0.00319851
Iteration 7012, loss = 0.00319745
Iteration 7013, loss = 0.00319677
Iteration 7014, loss = 0.00319621
Iteration 7015, loss = 0.00319547
Iteration 7016, loss = 0.00319477
Iteration 7017, loss = 0.00319413
Iteration 7018, loss = 0.00319336
Iteration 7019, loss = 0.00319281
Iteration 7020, loss = 0.00319201
Iteration 7021, loss = 0.00319136
Iteration 7022, loss = 0.00319082
Iteration 7023, loss = 0.00319013
Iteration 7024, loss = 0.00318949
Iteration 7025, loss = 0.00318894
Iteration 7026, loss = 0.00318822
Iteration 7027, loss = 0.00318761
Iteration 7028, loss = 0.00318714
Iteration 7029, loss = 0.00318654
Iteration 7030, loss = 0.00318578
Iteration 7031, loss = 0.00318525
Iteration 7032, loss = 0.00318457
Iteration 7033, loss = 0.00318398
Iteration 7034, loss = 0.00318364
Iteration 7035, loss = 0.00318288
Iteration 7036, loss = 0.00318237
Iteration 7037, loss = 0.00318160
Iteration 7038, loss = 0.00318101
Iteration 7039, loss = 0.00318042
Iteration 7040, loss = 0.00317988
Iteration 7041, loss = 0.00317932
Iteration 7042, loss = 0.00317873
Iteration 7043, loss = 0.00317804
Iteration 7044, loss = 0.00317752
Iteration 7045, loss = 0.00317699
Iteration 7046, loss = 0.00317608
Iteration 7047, loss = 0.00317551
Iteration 7048, loss = 0.00317527
Iteration 7049, loss = 0.00317432
Iteration 7050, loss = 0.00317341
Iteration 7051, loss = 0.00317283
Iteration 7052, loss = 0.00317271
Iteration 7053, loss = 0.00317192
Iteration 7054, loss = 0.00317079
Iteration 7055, loss = 0.00317028
Iteration 7056, loss = 0.00316955
Iteration 7057, loss = 0.00316905
Iteration 7058, loss = 0.00316828
Iteration 7059, loss = 0.00316766
Iteration 7060, loss = 0.00316716
Iteration 7061, loss = 0.00316656
Iteration 7062, loss = 0.00316587
Iteration 7063, loss = 0.00316530
Iteration 7064, loss = 0.00316476
Iteration 7065, loss = 0.00316425
Iteration 7066, loss = 0.00316355
Iteration 7067, loss = 0.00316302
Iteration 7068, loss = 0.00316243
Iteration 7069, loss = 0.00316186
Iteration 7070, loss = 0.00316137
Iteration 7071, loss = 0.00316072
Iteration 7072, loss = 0.00316005
Iteration 7073, loss = 0.00315941
Iteration 7074, loss = 0.00315912
Iteration 7075, loss = 0.00315822
Iteration 7076, loss = 0.00315758
Iteration 7077, loss = 0.00315700
Iteration 7078, loss = 0.00315633
Iteration 7079, loss = 0.00315566
Iteration 7080, loss = 0.00315495
Iteration 7081, loss = 0.00315456
Iteration 7082, loss = 0.00315380
Iteration 7083, loss = 0.00315307
Iteration 7084, loss = 0.00315261
Iteration 7085, loss = 0.00315191
Iteration 7086, loss = 0.00315146
Iteration 7087, loss = 0.00315083
Iteration 7088, loss = 0.00315010
Iteration 7089, loss = 0.00314947
Iteration 7090, loss = 0.00314929
Iteration 7091, loss = 0.00314836
Iteration 7092, loss = 0.00314772
Iteration 7093, loss = 0.00314734
Iteration 7094, loss = 0.00314652
Iteration 7095, loss = 0.00314598
Iteration 7096, loss = 0.00314551
Iteration 7097, loss = 0.00314492
Iteration 7098, loss = 0.00314443
Iteration 7099, loss = 0.00314369
Iteration 7100, loss = 0.00314309
Iteration 7101, loss = 0.00314248
Iteration 7102, loss = 0.00314192
Iteration 7103, loss = 0.00314136
Iteration 7104, loss = 0.00314080
Iteration 7105, loss = 0.00314036
Iteration 7106, loss = 0.00313970
Iteration 7107, loss = 0.00313914
Iteration 7108, loss = 0.00313858
Iteration 7109, loss = 0.00313806
Iteration 7110, loss = 0.00313759
Iteration 7111, loss = 0.00313691
Iteration 7112, loss = 0.00313639
Iteration 7113, loss = 0.00313596
Iteration 7114, loss = 0.00313526
Iteration 7115, loss = 0.00313470
Iteration 7116, loss = 0.00313407
Iteration 7117, loss = 0.00313387
Iteration 7118, loss = 0.00313307
Iteration 7119, loss = 0.00313234
Iteration 7120, loss = 0.00313181
Iteration 7121, loss = 0.00313125
Iteration 7122, loss = 0.00313059
Iteration 7123, loss = 0.00313012
Iteration 7124, loss = 0.00312953
Iteration 7125, loss = 0.00312896
Iteration 7126, loss = 0.00312844
Iteration 7127, loss = 0.00312801
Iteration 7128, loss = 0.00312743
Iteration 7129, loss = 0.00312667
Iteration 7130, loss = 0.00312631
Iteration 7131, loss = 0.00312553
Iteration 7132, loss = 0.00312499
Iteration 7133, loss = 0.00312428
Iteration 7134, loss = 0.00312363
Iteration 7135, loss = 0.00312299
Iteration 7136, loss = 0.00312229
Iteration 7137, loss = 0.00312180
Iteration 7138, loss = 0.00312133
Iteration 7139, loss = 0.00312055
Iteration 7140, loss = 0.00311999
Iteration 7141, loss = 0.00311943
Iteration 7142, loss = 0.00311909
Iteration 7143, loss = 0.00311834
Iteration 7144, loss = 0.00311784
Iteration 7145, loss = 0.00311713
Iteration 7146, loss = 0.00311637
Iteration 7147, loss = 0.00311577
Iteration 7148, loss = 0.00311520
Iteration 7149, loss = 0.00311479
Iteration 7150, loss = 0.00311405
Iteration 7151, loss = 0.00311364
Iteration 7152, loss = 0.00311286
Iteration 7153, loss = 0.00311256
Iteration 7154, loss = 0.00311168
Iteration 7155, loss = 0.00311105
Iteration 7156, loss = 0.00311050
Iteration 7157, loss = 0.00311002
Iteration 7158, loss = 0.00310933
Iteration 7159, loss = 0.00310880
Iteration 7160, loss = 0.00310814
Iteration 7161, loss = 0.00310766
Iteration 7162, loss = 0.00310694
Iteration 7163, loss = 0.00310633
Iteration 7164, loss = 0.00310593
Iteration 7165, loss = 0.00310511
Iteration 7166, loss = 0.00310454
Iteration 7167, loss = 0.00310389
Iteration 7168, loss = 0.00310379
Iteration 7169, loss = 0.00310277
Iteration 7170, loss = 0.00310240
Iteration 7171, loss = 0.00310158
Iteration 7172, loss = 0.00310104
Iteration 7173, loss = 0.00310049
Iteration 7174, loss = 0.00309985
Iteration 7175, loss = 0.00309919
Iteration 7176, loss = 0.00309860
Iteration 7177, loss = 0.00309853
Iteration 7178, loss = 0.00309763
Iteration 7179, loss = 0.00309703
Iteration 7180, loss = 0.00309648
Iteration 7181, loss = 0.00309584
Iteration 7182, loss = 0.00309522
Iteration 7183, loss = 0.00309466
Iteration 7184, loss = 0.00309401
Iteration 7185, loss = 0.00309337
Iteration 7186, loss = 0.00309278
Iteration 7187, loss = 0.00309223
Iteration 7188, loss = 0.00309175
Iteration 7189, loss = 0.00309101
Iteration 7190, loss = 0.00309046
Iteration 7191, loss = 0.00308999
Iteration 7192, loss = 0.00308928
Iteration 7193, loss = 0.00308864
Iteration 7194, loss = 0.00308805
Iteration 7195, loss = 0.00308753
Iteration 7196, loss = 0.00308692
Iteration 7197, loss = 0.00308650
Iteration 7198, loss = 0.00308578
Iteration 7199, loss = 0.00308517
Iteration 7200, loss = 0.00308461
Iteration 7201, loss = 0.00308415
Iteration 7202, loss = 0.00308366
Iteration 7203, loss = 0.00308312
Iteration 7204, loss = 0.00308242
Iteration 7205, loss = 0.00308187
Iteration 7206, loss = 0.00308139
Iteration 7207, loss = 0.00308097
Iteration 7208, loss = 0.00308019
Iteration 7209, loss = 0.00307980
Iteration 7210, loss = 0.00307924
Iteration 7211, loss = 0.00307882
Iteration 7212, loss = 0.00307817
Iteration 7213, loss = 0.00307761
Iteration 7214, loss = 0.00307691
Iteration 7215, loss = 0.00307629
Iteration 7216, loss = 0.00307599
Iteration 7217, loss = 0.00307517
Iteration 7218, loss = 0.00307439
Iteration 7219, loss = 0.00307386
Iteration 7220, loss = 0.00307317
Iteration 7221, loss = 0.00307264
Iteration 7222, loss = 0.00307208
Iteration 7223, loss = 0.00307148
Iteration 7224, loss = 0.00307092
Iteration 7225, loss = 0.00307046
Iteration 7226, loss = 0.00307005
Iteration 7227, loss = 0.00306935
Iteration 7228, loss = 0.00306885
Iteration 7229, loss = 0.00306833
Iteration 7230, loss = 0.00306781
Iteration 7231, loss = 0.00306730
Iteration 7232, loss = 0.00306667
Iteration 7233, loss = 0.00306607
Iteration 7234, loss = 0.00306553
Iteration 7235, loss = 0.00306494
Iteration 7236, loss = 0.00306446
Iteration 7237, loss = 0.00306408
Iteration 7238, loss = 0.00306344
Iteration 7239, loss = 0.00306286
Iteration 7240, loss = 0.00306235
Iteration 7241, loss = 0.00306177
Iteration 7242, loss = 0.00306134
Iteration 7243, loss = 0.00306074
Iteration 7244, loss = 0.00306009
Iteration 7245, loss = 0.00305952
Iteration 7246, loss = 0.00305896
Iteration 7247, loss = 0.00305833
Iteration 7248, loss = 0.00305782
Iteration 7249, loss = 0.00305734
Iteration 7250, loss = 0.00305658
Iteration 7251, loss = 0.00305605
Iteration 7252, loss = 0.00305550
Iteration 7253, loss = 0.00305502
Iteration 7254, loss = 0.00305450
Iteration 7255, loss = 0.00305388
Iteration 7256, loss = 0.00305340
Iteration 7257, loss = 0.00305284
Iteration 7258, loss = 0.00305210
Iteration 7259, loss = 0.00305163
Iteration 7260, loss = 0.00305128
Iteration 7261, loss = 0.00305064
Iteration 7262, loss = 0.00305016
Iteration 7263, loss = 0.00304954
Iteration 7264, loss = 0.00304900
Iteration 7265, loss = 0.00304847
Iteration 7266, loss = 0.00304800
Iteration 7267, loss = 0.00304754
Iteration 7268, loss = 0.00304710
Iteration 7269, loss = 0.00304643
Iteration 7270, loss = 0.00304599
Iteration 7271, loss = 0.00304557
Iteration 7272, loss = 0.00304487
Iteration 7273, loss = 0.00304445
Iteration 7274, loss = 0.00304376
Iteration 7275, loss = 0.00304313
Iteration 7276, loss = 0.00304261
Iteration 7277, loss = 0.00304196
Iteration 7278, loss = 0.00304138
Iteration 7279, loss = 0.00304099
Iteration 7280, loss = 0.00304029
Iteration 7281, loss = 0.00303975
Iteration 7282, loss = 0.00303914
Iteration 7283, loss = 0.00303853
Iteration 7284, loss = 0.00303803
Iteration 7285, loss = 0.00303745
Iteration 7286, loss = 0.00303690
Iteration 7287, loss = 0.00303653
Iteration 7288, loss = 0.00303582
Iteration 7289, loss = 0.00303520
Iteration 7290, loss = 0.00303451
Iteration 7291, loss = 0.00303395
Iteration 7292, loss = 0.00303339
Iteration 7293, loss = 0.00303266
Iteration 7294, loss = 0.00303227
Iteration 7295, loss = 0.00303149
Iteration 7296, loss = 0.00303084
Iteration 7297, loss = 0.00303033
Iteration 7298, loss = 0.00302975
Iteration 7299, loss = 0.00302915
Iteration 7300, loss = 0.00302862
Iteration 7301, loss = 0.00302799
Iteration 7302, loss = 0.00302748
Iteration 7303, loss = 0.00302704
Iteration 7304, loss = 0.00302642
Iteration 7305, loss = 0.00302603
Iteration 7306, loss = 0.00302534
Iteration 7307, loss = 0.00302488
Iteration 7308, loss = 0.00302432
Iteration 7309, loss = 0.00302375
Iteration 7310, loss = 0.00302313
Iteration 7311, loss = 0.00302261
Iteration 7312, loss = 0.00302217
Iteration 7313, loss = 0.00302142
Iteration 7314, loss = 0.00302098
Iteration 7315, loss = 0.00302022
Iteration 7316, loss = 0.00301971
Iteration 7317, loss = 0.00301911
Iteration 7318, loss = 0.00301848
Iteration 7319, loss = 0.00301789
Iteration 7320, loss = 0.00301740
Iteration 7321, loss = 0.00301683
Iteration 7322, loss = 0.00301622
Iteration 7323, loss = 0.00301563
Iteration 7324, loss = 0.00301506
Iteration 7325, loss = 0.00301447
Iteration 7326, loss = 0.00301410
Iteration 7327, loss = 0.00301345
Iteration 7328, loss = 0.00301295
Iteration 7329, loss = 0.00301243
Iteration 7330, loss = 0.00301177
Iteration 7331, loss = 0.00301135
Iteration 7332, loss = 0.00301066
Iteration 7333, loss = 0.00301000
Iteration 7334, loss = 0.00300938
Iteration 7335, loss = 0.00300894
Iteration 7336, loss = 0.00300830
Iteration 7337, loss = 0.00300774
Iteration 7338, loss = 0.00300727
Iteration 7339, loss = 0.00300669
Iteration 7340, loss = 0.00300610
Iteration 7341, loss = 0.00300564
Iteration 7342, loss = 0.00300516
Iteration 7343, loss = 0.00300463
Iteration 7344, loss = 0.00300411
Iteration 7345, loss = 0.00300380
Iteration 7346, loss = 0.00300306
Iteration 7347, loss = 0.00300271
Iteration 7348, loss = 0.00300199
Iteration 7349, loss = 0.00300149
Iteration 7350, loss = 0.00300080
Iteration 7351, loss = 0.00300045
Iteration 7352, loss = 0.00299987
Iteration 7353, loss = 0.00299941
Iteration 7354, loss = 0.00299884
Iteration 7355, loss = 0.00299827
Iteration 7356, loss = 0.00299778
Iteration 7357, loss = 0.00299728
Iteration 7358, loss = 0.00299668
Iteration 7359, loss = 0.00299620
Iteration 7360, loss = 0.00299584
Iteration 7361, loss = 0.00299510
Iteration 7362, loss = 0.00299460
Iteration 7363, loss = 0.00299399
Iteration 7364, loss = 0.00299342
Iteration 7365, loss = 0.00299272
Iteration 7366, loss = 0.00299231
Iteration 7367, loss = 0.00299155
Iteration 7368, loss = 0.00299122
Iteration 7369, loss = 0.00299072
Iteration 7370, loss = 0.00299012
Iteration 7371, loss = 0.00298958
Iteration 7372, loss = 0.00298901
Iteration 7373, loss = 0.00298863
Iteration 7374, loss = 0.00298787
Iteration 7375, loss = 0.00298731
Iteration 7376, loss = 0.00298679
Iteration 7377, loss = 0.00298619
Iteration 7378, loss = 0.00298563
Iteration 7379, loss = 0.00298500
Iteration 7380, loss = 0.00298444
Iteration 7381, loss = 0.00298389
Iteration 7382, loss = 0.00298315
Iteration 7383, loss = 0.00298249
Iteration 7384, loss = 0.00298196
Iteration 7385, loss = 0.00298122
Iteration 7386, loss = 0.00298064
Iteration 7387, loss = 0.00298015
Iteration 7388, loss = 0.00297956
Iteration 7389, loss = 0.00297902
Iteration 7390, loss = 0.00297845
Iteration 7391, loss = 0.00297802
Iteration 7392, loss = 0.00297752
Iteration 7393, loss = 0.00297684
Iteration 7394, loss = 0.00297631
Iteration 7395, loss = 0.00297569
Iteration 7396, loss = 0.00297534
Iteration 7397, loss = 0.00297469
Iteration 7398, loss = 0.00297478
Iteration 7399, loss = 0.00297366
Iteration 7400, loss = 0.00297300
Iteration 7401, loss = 0.00297240
Iteration 7402, loss = 0.00297188
Iteration 7403, loss = 0.00297149
Iteration 7404, loss = 0.00297075
Iteration 7405, loss = 0.00297019
Iteration 7406, loss = 0.00296964
Iteration 7407, loss = 0.00296920
Iteration 7408, loss = 0.00296871
Iteration 7409, loss = 0.00296833
Iteration 7410, loss = 0.00296772
Iteration 7411, loss = 0.00296733
Iteration 7412, loss = 0.00296672
Iteration 7413, loss = 0.00296619
Iteration 7414, loss = 0.00296566
Iteration 7415, loss = 0.00296521
Iteration 7416, loss = 0.00296469
Iteration 7417, loss = 0.00296425
Iteration 7418, loss = 0.00296371
Iteration 7419, loss = 0.00296328
Iteration 7420, loss = 0.00296297
Iteration 7421, loss = 0.00296237
Iteration 7422, loss = 0.00296185
Iteration 7423, loss = 0.00296141
Iteration 7424, loss = 0.00296075
Iteration 7425, loss = 0.00296020
Iteration 7426, loss = 0.00295968
Iteration 7427, loss = 0.00295910
Iteration 7428, loss = 0.00295854
Iteration 7429, loss = 0.00295796
Iteration 7430, loss = 0.00295752
Iteration 7431, loss = 0.00295712
Iteration 7432, loss = 0.00295646
Iteration 7433, loss = 0.00295591
Iteration 7434, loss = 0.00295535
Iteration 7435, loss = 0.00295491
Iteration 7436, loss = 0.00295439
Iteration 7437, loss = 0.00295367
Iteration 7438, loss = 0.00295325
Iteration 7439, loss = 0.00295261
Iteration 7440, loss = 0.00295201
Iteration 7441, loss = 0.00295157
Iteration 7442, loss = 0.00295093
Iteration 7443, loss = 0.00295036
Iteration 7444, loss = 0.00294971
Iteration 7445, loss = 0.00294941
Iteration 7446, loss = 0.00294876
Iteration 7447, loss = 0.00294822
Iteration 7448, loss = 0.00294788
Iteration 7449, loss = 0.00294727
Iteration 7450, loss = 0.00294679
Iteration 7451, loss = 0.00294626
Iteration 7452, loss = 0.00294575
Iteration 7453, loss = 0.00294532
Iteration 7454, loss = 0.00294486
Iteration 7455, loss = 0.00294437
Iteration 7456, loss = 0.00294384
Iteration 7457, loss = 0.00294390
Iteration 7458, loss = 0.00294285
Iteration 7459, loss = 0.00294228
Iteration 7460, loss = 0.00294173
Iteration 7461, loss = 0.00294115
Iteration 7462, loss = 0.00294074
Iteration 7463, loss = 0.00294015
Iteration 7464, loss = 0.00293961
Iteration 7465, loss = 0.00293909
Iteration 7466, loss = 0.00293851
Iteration 7467, loss = 0.00293808
Iteration 7468, loss = 0.00293765
Iteration 7469, loss = 0.00293697
Iteration 7470, loss = 0.00293635
Iteration 7471, loss = 0.00293575
Iteration 7472, loss = 0.00293510
Iteration 7473, loss = 0.00293465
Iteration 7474, loss = 0.00293403
Iteration 7475, loss = 0.00293348
Iteration 7476, loss = 0.00293284
Iteration 7477, loss = 0.00293232
Iteration 7478, loss = 0.00293177
Iteration 7479, loss = 0.00293139
Iteration 7480, loss = 0.00293069
Iteration 7481, loss = 0.00293016
Iteration 7482, loss = 0.00292951
Iteration 7483, loss = 0.00292901
Iteration 7484, loss = 0.00292846
Iteration 7485, loss = 0.00292774
Iteration 7486, loss = 0.00292714
Iteration 7487, loss = 0.00292655
Iteration 7488, loss = 0.00292590
Iteration 7489, loss = 0.00292532
Iteration 7490, loss = 0.00292493
Iteration 7491, loss = 0.00292436
Iteration 7492, loss = 0.00292390
Iteration 7493, loss = 0.00292325
Iteration 7494, loss = 0.00292262
Iteration 7495, loss = 0.00292197
Iteration 7496, loss = 0.00292151
Iteration 7497, loss = 0.00292080
Iteration 7498, loss = 0.00292016
Iteration 7499, loss = 0.00291967
Iteration 7500, loss = 0.00291894
Iteration 7501, loss = 0.00291851
Iteration 7502, loss = 0.00291772
Iteration 7503, loss = 0.00291703
Iteration 7504, loss = 0.00291647
Iteration 7505, loss = 0.00291581
Iteration 7506, loss = 0.00291520
Iteration 7507, loss = 0.00291490
Iteration 7508, loss = 0.00291396
Iteration 7509, loss = 0.00291342
Iteration 7510, loss = 0.00291328
Iteration 7511, loss = 0.00291214
Iteration 7512, loss = 0.00291147
Iteration 7513, loss = 0.00291072
Iteration 7514, loss = 0.00291005
Iteration 7515, loss = 0.00290956
Iteration 7516, loss = 0.00290894
Iteration 7517, loss = 0.00290825
Iteration 7518, loss = 0.00290771
Iteration 7519, loss = 0.00290714
Iteration 7520, loss = 0.00290665
Iteration 7521, loss = 0.00290620
Iteration 7522, loss = 0.00290553
Iteration 7523, loss = 0.00290500
Iteration 7524, loss = 0.00290436
Iteration 7525, loss = 0.00290386
Iteration 7526, loss = 0.00290332
Iteration 7527, loss = 0.00290280
Iteration 7528, loss = 0.00290228
Iteration 7529, loss = 0.00290177
Iteration 7530, loss = 0.00290121
Iteration 7531, loss = 0.00290069
Iteration 7532, loss = 0.00290025
Iteration 7533, loss = 0.00289976
Iteration 7534, loss = 0.00289907
Iteration 7535, loss = 0.00289853
Iteration 7536, loss = 0.00289813
Iteration 7537, loss = 0.00289765
Iteration 7538, loss = 0.00289693
Iteration 7539, loss = 0.00289643
Iteration 7540, loss = 0.00289589
Iteration 7541, loss = 0.00289534
Iteration 7542, loss = 0.00289489
Iteration 7543, loss = 0.00289428
Iteration 7544, loss = 0.00289372
Iteration 7545, loss = 0.00289313
Iteration 7546, loss = 0.00289257
Iteration 7547, loss = 0.00289217
Iteration 7548, loss = 0.00289164
Iteration 7549, loss = 0.00289092
Iteration 7550, loss = 0.00289045
Iteration 7551, loss = 0.00288987
Iteration 7552, loss = 0.00288929
Iteration 7553, loss = 0.00288890
Iteration 7554, loss = 0.00288824
Iteration 7555, loss = 0.00288757
Iteration 7556, loss = 0.00288700
Iteration 7557, loss = 0.00288638
Iteration 7558, loss = 0.00288593
Iteration 7559, loss = 0.00288534
Iteration 7560, loss = 0.00288499
Iteration 7561, loss = 0.00288425
Iteration 7562, loss = 0.00288368
Iteration 7563, loss = 0.00288313
Iteration 7564, loss = 0.00288256
Iteration 7565, loss = 0.00288194
Iteration 7566, loss = 0.00288169
Iteration 7567, loss = 0.00288097
Iteration 7568, loss = 0.00288039
Iteration 7569, loss = 0.00287977
Iteration 7570, loss = 0.00287921
Iteration 7571, loss = 0.00287869
Iteration 7572, loss = 0.00287808
Iteration 7573, loss = 0.00287777
Iteration 7574, loss = 0.00287708
Iteration 7575, loss = 0.00287650
Iteration 7576, loss = 0.00287605
Iteration 7577, loss = 0.00287551
Iteration 7578, loss = 0.00287498
Iteration 7579, loss = 0.00287440
Iteration 7580, loss = 0.00287392
Iteration 7581, loss = 0.00287344
Iteration 7582, loss = 0.00287265
Iteration 7583, loss = 0.00287217
Iteration 7584, loss = 0.00287149
Iteration 7585, loss = 0.00287082
Iteration 7586, loss = 0.00287023
Iteration 7587, loss = 0.00286981
Iteration 7588, loss = 0.00286913
Iteration 7589, loss = 0.00286848
Iteration 7590, loss = 0.00286793
Iteration 7591, loss = 0.00286738
Iteration 7592, loss = 0.00286675
Iteration 7593, loss = 0.00286611
Iteration 7594, loss = 0.00286562
Iteration 7595, loss = 0.00286510
Iteration 7596, loss = 0.00286450
Iteration 7597, loss = 0.00286393
Iteration 7598, loss = 0.00286340
Iteration 7599, loss = 0.00286283
Iteration 7600, loss = 0.00286231
Iteration 7601, loss = 0.00286177
Iteration 7602, loss = 0.00286124
Iteration 7603, loss = 0.00286064
Iteration 7604, loss = 0.00286023
Iteration 7605, loss = 0.00285970
Iteration 7606, loss = 0.00285906
Iteration 7607, loss = 0.00285855
Iteration 7608, loss = 0.00285803
Iteration 7609, loss = 0.00285758
Iteration 7610, loss = 0.00285685
Iteration 7611, loss = 0.00285623
Iteration 7612, loss = 0.00285582
Iteration 7613, loss = 0.00285527
Iteration 7614, loss = 0.00285474
Iteration 7615, loss = 0.00285417
Iteration 7616, loss = 0.00285358
Iteration 7617, loss = 0.00285323
Iteration 7618, loss = 0.00285263
Iteration 7619, loss = 0.00285207
Iteration 7620, loss = 0.00285148
Iteration 7621, loss = 0.00285096
Iteration 7622, loss = 0.00285042
Iteration 7623, loss = 0.00284987
Iteration 7624, loss = 0.00284920
Iteration 7625, loss = 0.00284897
Iteration 7626, loss = 0.00284865
Iteration 7627, loss = 0.00284778
Iteration 7628, loss = 0.00284722
Iteration 7629, loss = 0.00284681
Iteration 7630, loss = 0.00284617
Iteration 7631, loss = 0.00284560
Iteration 7632, loss = 0.00284511
Iteration 7633, loss = 0.00284441
Iteration 7634, loss = 0.00284385
Iteration 7635, loss = 0.00284327
Iteration 7636, loss = 0.00284317
Iteration 7637, loss = 0.00284228
Iteration 7638, loss = 0.00284174
Iteration 7639, loss = 0.00284119
Iteration 7640, loss = 0.00284063
Iteration 7641, loss = 0.00284015
Iteration 7642, loss = 0.00283966
Iteration 7643, loss = 0.00283922
Iteration 7644, loss = 0.00283868
Iteration 7645, loss = 0.00283820
Iteration 7646, loss = 0.00283771
Iteration 7647, loss = 0.00283738
Iteration 7648, loss = 0.00283676
Iteration 7649, loss = 0.00283618
Iteration 7650, loss = 0.00283556
Iteration 7651, loss = 0.00283517
Iteration 7652, loss = 0.00283444
Iteration 7653, loss = 0.00283404
Iteration 7654, loss = 0.00283335
Iteration 7655, loss = 0.00283283
Iteration 7656, loss = 0.00283228
Iteration 7657, loss = 0.00283196
Iteration 7658, loss = 0.00283127
Iteration 7659, loss = 0.00283075
Iteration 7660, loss = 0.00283025
Iteration 7661, loss = 0.00282972
Iteration 7662, loss = 0.00282923
Iteration 7663, loss = 0.00282869
Iteration 7664, loss = 0.00282819
Iteration 7665, loss = 0.00282769
Iteration 7666, loss = 0.00282722
Iteration 7667, loss = 0.00282666
Iteration 7668, loss = 0.00282642
Iteration 7669, loss = 0.00282578
Iteration 7670, loss = 0.00282531
Iteration 7671, loss = 0.00282485
Iteration 7672, loss = 0.00282436
Iteration 7673, loss = 0.00282381
Iteration 7674, loss = 0.00282341
Iteration 7675, loss = 0.00282301
Iteration 7676, loss = 0.00282233
Iteration 7677, loss = 0.00282175
Iteration 7678, loss = 0.00282128
Iteration 7679, loss = 0.00282080
Iteration 7680, loss = 0.00282018
Iteration 7681, loss = 0.00281965
Iteration 7682, loss = 0.00281931
Iteration 7683, loss = 0.00281856
Iteration 7684, loss = 0.00281811
Iteration 7685, loss = 0.00281752
Iteration 7686, loss = 0.00281702
Iteration 7687, loss = 0.00281650
Iteration 7688, loss = 0.00281577
Iteration 7689, loss = 0.00281504
Iteration 7690, loss = 0.00281467
Iteration 7691, loss = 0.00281419
Iteration 7692, loss = 0.00281363
Iteration 7693, loss = 0.00281289
Iteration 7694, loss = 0.00281234
Iteration 7695, loss = 0.00281182
Iteration 7696, loss = 0.00281123
Iteration 7697, loss = 0.00281072
Iteration 7698, loss = 0.00281029
Iteration 7699, loss = 0.00280972
Iteration 7700, loss = 0.00280915
Iteration 7701, loss = 0.00280854
Iteration 7702, loss = 0.00280814
Iteration 7703, loss = 0.00280756
Iteration 7704, loss = 0.00280692
Iteration 7705, loss = 0.00280629
Iteration 7706, loss = 0.00280572
Iteration 7707, loss = 0.00280536
Iteration 7708, loss = 0.00280463
Iteration 7709, loss = 0.00280407
Iteration 7710, loss = 0.00280355
Iteration 7711, loss = 0.00280301
Iteration 7712, loss = 0.00280246
Iteration 7713, loss = 0.00280204
Iteration 7714, loss = 0.00280147
Iteration 7715, loss = 0.00280111
Iteration 7716, loss = 0.00280057
Iteration 7717, loss = 0.00280006
Iteration 7718, loss = 0.00279956
Iteration 7719, loss = 0.00279889
Iteration 7720, loss = 0.00279823
Iteration 7721, loss = 0.00279777
Iteration 7722, loss = 0.00279735
Iteration 7723, loss = 0.00279672
Iteration 7724, loss = 0.00279628
Iteration 7725, loss = 0.00279563
Iteration 7726, loss = 0.00279527
Iteration 7727, loss = 0.00279458
Iteration 7728, loss = 0.00279417
Iteration 7729, loss = 0.00279366
Iteration 7730, loss = 0.00279278
Iteration 7731, loss = 0.00279241
Iteration 7732, loss = 0.00279175
Iteration 7733, loss = 0.00279119
Iteration 7734, loss = 0.00279062
Iteration 7735, loss = 0.00279006
Iteration 7736, loss = 0.00278945
Iteration 7737, loss = 0.00278892
Iteration 7738, loss = 0.00278845
Iteration 7739, loss = 0.00278784
Iteration 7740, loss = 0.00278731
Iteration 7741, loss = 0.00278693
Iteration 7742, loss = 0.00278647
Iteration 7743, loss = 0.00278582
Iteration 7744, loss = 0.00278548
Iteration 7745, loss = 0.00278487
Iteration 7746, loss = 0.00278431
Iteration 7747, loss = 0.00278376
Iteration 7748, loss = 0.00278316
Iteration 7749, loss = 0.00278255
Iteration 7750, loss = 0.00278201
Iteration 7751, loss = 0.00278158
Iteration 7752, loss = 0.00278103
Iteration 7753, loss = 0.00278035
Iteration 7754, loss = 0.00277988
Iteration 7755, loss = 0.00277926
Iteration 7756, loss = 0.00277873
Iteration 7757, loss = 0.00277834
Iteration 7758, loss = 0.00277763
Iteration 7759, loss = 0.00277731
Iteration 7760, loss = 0.00277671
Iteration 7761, loss = 0.00277600
Iteration 7762, loss = 0.00277580
Iteration 7763, loss = 0.00277485
Iteration 7764, loss = 0.00277431
Iteration 7765, loss = 0.00277375
Iteration 7766, loss = 0.00277325
Iteration 7767, loss = 0.00277261
Iteration 7768, loss = 0.00277208
Iteration 7769, loss = 0.00277151
Iteration 7770, loss = 0.00277116
Iteration 7771, loss = 0.00277038
Iteration 7772, loss = 0.00276978
Iteration 7773, loss = 0.00276919
Iteration 7774, loss = 0.00276870
Iteration 7775, loss = 0.00276804
Iteration 7776, loss = 0.00276749
Iteration 7777, loss = 0.00276690
Iteration 7778, loss = 0.00276642
Iteration 7779, loss = 0.00276588
Iteration 7780, loss = 0.00276529
Iteration 7781, loss = 0.00276493
Iteration 7782, loss = 0.00276429
Iteration 7783, loss = 0.00276379
Iteration 7784, loss = 0.00276330
Iteration 7785, loss = 0.00276271
Iteration 7786, loss = 0.00276222
Iteration 7787, loss = 0.00276185
Iteration 7788, loss = 0.00276150
Iteration 7789, loss = 0.00276089
Iteration 7790, loss = 0.00276037
Iteration 7791, loss = 0.00275988
Iteration 7792, loss = 0.00275932
Iteration 7793, loss = 0.00275883
Iteration 7794, loss = 0.00275832
Iteration 7795, loss = 0.00275788
Iteration 7796, loss = 0.00275740
Iteration 7797, loss = 0.00275693
Iteration 7798, loss = 0.00275645
Iteration 7799, loss = 0.00275591
Iteration 7800, loss = 0.00275555
Iteration 7801, loss = 0.00275504
Iteration 7802, loss = 0.00275463
Iteration 7803, loss = 0.00275404
Iteration 7804, loss = 0.00275357
Iteration 7805, loss = 0.00275315
Iteration 7806, loss = 0.00275269
Iteration 7807, loss = 0.00275218
Iteration 7808, loss = 0.00275179
Iteration 7809, loss = 0.00275147
Iteration 7810, loss = 0.00275081
Iteration 7811, loss = 0.00275032
Iteration 7812, loss = 0.00275011
Iteration 7813, loss = 0.00274944
Iteration 7814, loss = 0.00274889
Iteration 7815, loss = 0.00274859
Iteration 7816, loss = 0.00274787
Iteration 7817, loss = 0.00274734
Iteration 7818, loss = 0.00274679
Iteration 7819, loss = 0.00274658
Iteration 7820, loss = 0.00274572
Iteration 7821, loss = 0.00274528
Iteration 7822, loss = 0.00274452
Iteration 7823, loss = 0.00274398
Iteration 7824, loss = 0.00274356
Iteration 7825, loss = 0.00274284
Iteration 7826, loss = 0.00274238
Iteration 7827, loss = 0.00274180
Iteration 7828, loss = 0.00274136
Iteration 7829, loss = 0.00274082
Iteration 7830, loss = 0.00274045
Iteration 7831, loss = 0.00273965
Iteration 7832, loss = 0.00273905
Iteration 7833, loss = 0.00273847
Iteration 7834, loss = 0.00273788
Iteration 7835, loss = 0.00273734
Iteration 7836, loss = 0.00273683
Iteration 7837, loss = 0.00273618
Iteration 7838, loss = 0.00273569
Iteration 7839, loss = 0.00273519
Iteration 7840, loss = 0.00273465
Iteration 7841, loss = 0.00273403
Iteration 7842, loss = 0.00273354
Iteration 7843, loss = 0.00273299
Iteration 7844, loss = 0.00273251
Iteration 7845, loss = 0.00273207
Iteration 7846, loss = 0.00273152
Iteration 7847, loss = 0.00273100
Iteration 7848, loss = 0.00273060
Iteration 7849, loss = 0.00273004
Iteration 7850, loss = 0.00272946
Iteration 7851, loss = 0.00272893
Iteration 7852, loss = 0.00272842
Iteration 7853, loss = 0.00272788
Iteration 7854, loss = 0.00272739
Iteration 7855, loss = 0.00272687
Iteration 7856, loss = 0.00272640
Iteration 7857, loss = 0.00272590
Iteration 7858, loss = 0.00272538
Iteration 7859, loss = 0.00272489
Iteration 7860, loss = 0.00272445
Iteration 7861, loss = 0.00272413
Iteration 7862, loss = 0.00272368
Iteration 7863, loss = 0.00272312
Iteration 7864, loss = 0.00272261
Iteration 7865, loss = 0.00272222
Iteration 7866, loss = 0.00272155
Iteration 7867, loss = 0.00272095
Iteration 7868, loss = 0.00272059
Iteration 7869, loss = 0.00271988
Iteration 7870, loss = 0.00271934
Iteration 7871, loss = 0.00271909
Iteration 7872, loss = 0.00271830
Iteration 7873, loss = 0.00271768
Iteration 7874, loss = 0.00271725
Iteration 7875, loss = 0.00271669
Iteration 7876, loss = 0.00271620
Iteration 7877, loss = 0.00271557
Iteration 7878, loss = 0.00271525
Iteration 7879, loss = 0.00271466
Iteration 7880, loss = 0.00271421
Iteration 7881, loss = 0.00271382
Iteration 7882, loss = 0.00271334
Iteration 7883, loss = 0.00271296
Iteration 7884, loss = 0.00271254
Iteration 7885, loss = 0.00271183
Iteration 7886, loss = 0.00271138
Iteration 7887, loss = 0.00271085
Iteration 7888, loss = 0.00271027
Iteration 7889, loss = 0.00270978
Iteration 7890, loss = 0.00270926
Iteration 7891, loss = 0.00270876
Iteration 7892, loss = 0.00270832
Iteration 7893, loss = 0.00270769
Iteration 7894, loss = 0.00270730
Iteration 7895, loss = 0.00270667
Iteration 7896, loss = 0.00270620
Iteration 7897, loss = 0.00270568
Iteration 7898, loss = 0.00270559
Iteration 7899, loss = 0.00270470
Iteration 7900, loss = 0.00270418
Iteration 7901, loss = 0.00270367
Iteration 7902, loss = 0.00270314
Iteration 7903, loss = 0.00270258
Iteration 7904, loss = 0.00270221
Iteration 7905, loss = 0.00270168
Iteration 7906, loss = 0.00270112
Iteration 7907, loss = 0.00270059
Iteration 7908, loss = 0.00270041
Iteration 7909, loss = 0.00269972
Iteration 7910, loss = 0.00269939
Iteration 7911, loss = 0.00269871
Iteration 7912, loss = 0.00269838
Iteration 7913, loss = 0.00269771
Iteration 7914, loss = 0.00269726
Iteration 7915, loss = 0.00269673
Iteration 7916, loss = 0.00269622
Iteration 7917, loss = 0.00269581
Iteration 7918, loss = 0.00269525
Iteration 7919, loss = 0.00269474
Iteration 7920, loss = 0.00269440
Iteration 7921, loss = 0.00269379
Iteration 7922, loss = 0.00269342
Iteration 7923, loss = 0.00269309
Iteration 7924, loss = 0.00269251
Iteration 7925, loss = 0.00269219
Iteration 7926, loss = 0.00269141
Iteration 7927, loss = 0.00269098
Iteration 7928, loss = 0.00269061
Iteration 7929, loss = 0.00268998
Iteration 7930, loss = 0.00268944
Iteration 7931, loss = 0.00268892
Iteration 7932, loss = 0.00268846
Iteration 7933, loss = 0.00268792
Iteration 7934, loss = 0.00268744
Iteration 7935, loss = 0.00268702
Iteration 7936, loss = 0.00268659
Iteration 7937, loss = 0.00268607
Iteration 7938, loss = 0.00268561
Iteration 7939, loss = 0.00268518
Iteration 7940, loss = 0.00268470
Iteration 7941, loss = 0.00268466
Iteration 7942, loss = 0.00268377
Iteration 7943, loss = 0.00268331
Iteration 7944, loss = 0.00268286
Iteration 7945, loss = 0.00268229
Iteration 7946, loss = 0.00268193
Iteration 7947, loss = 0.00268135
Iteration 7948, loss = 0.00268097
Iteration 7949, loss = 0.00268052
Iteration 7950, loss = 0.00268001
Iteration 7951, loss = 0.00267948
Iteration 7952, loss = 0.00267904
Iteration 7953, loss = 0.00267857
Iteration 7954, loss = 0.00267830
Iteration 7955, loss = 0.00267764
Iteration 7956, loss = 0.00267712
Iteration 7957, loss = 0.00267668
Iteration 7958, loss = 0.00267617
Iteration 7959, loss = 0.00267573
Iteration 7960, loss = 0.00267522
Iteration 7961, loss = 0.00267470
Iteration 7962, loss = 0.00267439
Iteration 7963, loss = 0.00267378
Iteration 7964, loss = 0.00267322
Iteration 7965, loss = 0.00267309
Iteration 7966, loss = 0.00267230
Iteration 7967, loss = 0.00267168
Iteration 7968, loss = 0.00267132
Iteration 7969, loss = 0.00267070
Iteration 7970, loss = 0.00267035
Iteration 7971, loss = 0.00266968
Iteration 7972, loss = 0.00266916
Iteration 7973, loss = 0.00266861
Iteration 7974, loss = 0.00266817
Iteration 7975, loss = 0.00266765
Iteration 7976, loss = 0.00266716
Iteration 7977, loss = 0.00266661
Iteration 7978, loss = 0.00266625
Iteration 7979, loss = 0.00266567
Iteration 7980, loss = 0.00266502
Iteration 7981, loss = 0.00266463
Iteration 7982, loss = 0.00266406
Iteration 7983, loss = 0.00266373
Iteration 7984, loss = 0.00266343
Iteration 7985, loss = 0.00266276
Iteration 7986, loss = 0.00266226
Iteration 7987, loss = 0.00266184
Iteration 7988, loss = 0.00266133
Iteration 7989, loss = 0.00266090
Iteration 7990, loss = 0.00266040
Iteration 7991, loss = 0.00265991
Iteration 7992, loss = 0.00265947
Iteration 7993, loss = 0.00265901
Iteration 7994, loss = 0.00265847
Iteration 7995, loss = 0.00265804
Iteration 7996, loss = 0.00265741
Iteration 7997, loss = 0.00265718
Iteration 7998, loss = 0.00265651
Iteration 7999, loss = 0.00265615
Iteration 8000, loss = 0.00265577
Iteration 1, loss = 1.03656897
Iteration 2, loss = 1.03327855
Iteration 3, loss = 1.02816807
Iteration 4, loss = 1.02179414
Iteration 5, loss = 1.01412463
Iteration 6, loss = 1.00596533
Iteration 7, loss = 0.99700394
Iteration 8, loss = 0.98769013
Iteration 9, loss = 0.97802004
Iteration 10, loss = 0.96849862
Iteration 11, loss = 0.95872698
Iteration 12, loss = 0.94911888
Iteration 13, loss = 0.93944542
Iteration 14, loss = 0.93013511
Iteration 15, loss = 0.92072018
Iteration 16, loss = 0.91168244
Iteration 17, loss = 0.90273407
Iteration 18, loss = 0.89427913
Iteration 19, loss = 0.88578080
Iteration 20, loss = 0.87780730
Iteration 21, loss = 0.86980361
Iteration 22, loss = 0.86218884
Iteration 23, loss = 0.85485576
Iteration 24, loss = 0.84731777
Iteration 25, loss = 0.84032692
Iteration 26, loss = 0.83316136
Iteration 27, loss = 0.82656556
Iteration 28, loss = 0.81970470
Iteration 29, loss = 0.81357867
Iteration 30, loss = 0.80721357
Iteration 31, loss = 0.80116490
Iteration 32, loss = 0.79547899
Iteration 33, loss = 0.78967431
Iteration 34, loss = 0.78425313
Iteration 35, loss = 0.77878638
Iteration 36, loss = 0.77374628
Iteration 37, loss = 0.76850900
Iteration 38, loss = 0.76376326
Iteration 39, loss = 0.75894980
Iteration 40, loss = 0.75426976
Iteration 41, loss = 0.74968734
Iteration 42, loss = 0.74530492
Iteration 43, loss = 0.74087707
Iteration 44, loss = 0.73663820
Iteration 45, loss = 0.73245069
Iteration 46, loss = 0.72838216
Iteration 47, loss = 0.72435012
Iteration 48, loss = 0.72053012
Iteration 49, loss = 0.71668025
Iteration 50, loss = 0.71295144
Iteration 51, loss = 0.70939135
Iteration 52, loss = 0.70574215
Iteration 53, loss = 0.70241531
Iteration 54, loss = 0.69892785
Iteration 55, loss = 0.69555294
Iteration 56, loss = 0.69227598
Iteration 57, loss = 0.68906685
Iteration 58, loss = 0.68568696
Iteration 59, loss = 0.68259318
Iteration 60, loss = 0.67945556
Iteration 61, loss = 0.67637632
Iteration 62, loss = 0.67342233
Iteration 63, loss = 0.67038080
Iteration 64, loss = 0.66755208
Iteration 65, loss = 0.66472737
Iteration 66, loss = 0.66194788
Iteration 67, loss = 0.65915127
Iteration 68, loss = 0.65643763
Iteration 69, loss = 0.65372928
Iteration 70, loss = 0.65109116
Iteration 71, loss = 0.64833976
Iteration 72, loss = 0.64575606
Iteration 73, loss = 0.64306256
Iteration 74, loss = 0.64038412
Iteration 75, loss = 0.63765358
Iteration 76, loss = 0.63502639
Iteration 77, loss = 0.63233940
Iteration 78, loss = 0.62967396
Iteration 79, loss = 0.62700715
Iteration 80, loss = 0.62446500
Iteration 81, loss = 0.62184320
Iteration 82, loss = 0.61929664
Iteration 83, loss = 0.61677284
Iteration 84, loss = 0.61422295
Iteration 85, loss = 0.61167840
Iteration 86, loss = 0.60923501
Iteration 87, loss = 0.60665893
Iteration 88, loss = 0.60418681
Iteration 89, loss = 0.60168544
Iteration 90, loss = 0.59915640
Iteration 91, loss = 0.59669759
Iteration 92, loss = 0.59421737
Iteration 93, loss = 0.59175294
Iteration 94, loss = 0.58928984
Iteration 95, loss = 0.58683833
Iteration 96, loss = 0.58441168
Iteration 97, loss = 0.58196506
Iteration 98, loss = 0.57952457
Iteration 99, loss = 0.57714859
Iteration 100, loss = 0.57474190
Iteration 101, loss = 0.57227412
Iteration 102, loss = 0.56987883
Iteration 103, loss = 0.56745150
Iteration 104, loss = 0.56510446
Iteration 105, loss = 0.56267995
Iteration 106, loss = 0.56037221
Iteration 107, loss = 0.55801787
Iteration 108, loss = 0.55571338
Iteration 109, loss = 0.55341184
Iteration 110, loss = 0.55114685
Iteration 111, loss = 0.54889039
Iteration 112, loss = 0.54660299
Iteration 113, loss = 0.54437478
Iteration 114, loss = 0.54211161
Iteration 115, loss = 0.53986333
Iteration 116, loss = 0.53761869
Iteration 117, loss = 0.53538636
Iteration 118, loss = 0.53316478
Iteration 119, loss = 0.53087888
Iteration 120, loss = 0.52868636
Iteration 121, loss = 0.52644691
Iteration 122, loss = 0.52423201
Iteration 123, loss = 0.52197806
Iteration 124, loss = 0.51977598
Iteration 125, loss = 0.51755752
Iteration 126, loss = 0.51534514
Iteration 127, loss = 0.51312710
Iteration 128, loss = 0.51096145
Iteration 129, loss = 0.50876167
Iteration 130, loss = 0.50663334
Iteration 131, loss = 0.50450376
Iteration 132, loss = 0.50236477
Iteration 133, loss = 0.50025591
Iteration 134, loss = 0.49814417
Iteration 135, loss = 0.49607183
Iteration 136, loss = 0.49394530
Iteration 137, loss = 0.49193151
Iteration 138, loss = 0.48985742
Iteration 139, loss = 0.48780232
Iteration 140, loss = 0.48576265
Iteration 141, loss = 0.48372453
Iteration 142, loss = 0.48167375
Iteration 143, loss = 0.47960676
Iteration 144, loss = 0.47758329
Iteration 145, loss = 0.47553118
Iteration 146, loss = 0.47350590
Iteration 147, loss = 0.47145901
Iteration 148, loss = 0.46945943
Iteration 149, loss = 0.46740718
Iteration 150, loss = 0.46537592
Iteration 151, loss = 0.46335495
Iteration 152, loss = 0.46130152
Iteration 153, loss = 0.45924826
Iteration 154, loss = 0.45720648
Iteration 155, loss = 0.45516185
Iteration 156, loss = 0.45317780
Iteration 157, loss = 0.45110441
Iteration 158, loss = 0.44910558
Iteration 159, loss = 0.44712111
Iteration 160, loss = 0.44510663
Iteration 161, loss = 0.44312772
Iteration 162, loss = 0.44111939
Iteration 163, loss = 0.43911970
Iteration 164, loss = 0.43710670
Iteration 165, loss = 0.43508901
Iteration 166, loss = 0.43306495
Iteration 167, loss = 0.43101732
Iteration 168, loss = 0.42898266
Iteration 169, loss = 0.42692157
Iteration 170, loss = 0.42489324
Iteration 171, loss = 0.42286070
Iteration 172, loss = 0.42083297
Iteration 173, loss = 0.41881568
Iteration 174, loss = 0.41682504
Iteration 175, loss = 0.41482641
Iteration 176, loss = 0.41281500
Iteration 177, loss = 0.41081797
Iteration 178, loss = 0.40879039
Iteration 179, loss = 0.40678486
Iteration 180, loss = 0.40478345
Iteration 181, loss = 0.40278185
Iteration 182, loss = 0.40076746
Iteration 183, loss = 0.39876587
Iteration 184, loss = 0.39674743
Iteration 185, loss = 0.39477726
Iteration 186, loss = 0.39273803
Iteration 187, loss = 0.39073863
Iteration 188, loss = 0.38877041
Iteration 189, loss = 0.38677605
Iteration 190, loss = 0.38479879
Iteration 191, loss = 0.38283553
Iteration 192, loss = 0.38086774
Iteration 193, loss = 0.37892293
Iteration 194, loss = 0.37694381
Iteration 195, loss = 0.37499792
Iteration 196, loss = 0.37302506
Iteration 197, loss = 0.37107027
Iteration 198, loss = 0.36910821
Iteration 199, loss = 0.36714012
Iteration 200, loss = 0.36518267
Iteration 201, loss = 0.36322566
Iteration 202, loss = 0.36127760
Iteration 203, loss = 0.35930589
Iteration 204, loss = 0.35736258
Iteration 205, loss = 0.35541322
Iteration 206, loss = 0.35346797
Iteration 207, loss = 0.35156013
Iteration 208, loss = 0.34960173
Iteration 209, loss = 0.34766806
Iteration 210, loss = 0.34575567
Iteration 211, loss = 0.34381768
Iteration 212, loss = 0.34190567
Iteration 213, loss = 0.34000364
Iteration 214, loss = 0.33808364
Iteration 215, loss = 0.33620869
Iteration 216, loss = 0.33429753
Iteration 217, loss = 0.33243955
Iteration 218, loss = 0.33054778
Iteration 219, loss = 0.32869512
Iteration 220, loss = 0.32684369
Iteration 221, loss = 0.32498803
Iteration 222, loss = 0.32312524
Iteration 223, loss = 0.32129633
Iteration 224, loss = 0.31943839
Iteration 225, loss = 0.31759896
Iteration 226, loss = 0.31576928
Iteration 227, loss = 0.31393070
Iteration 228, loss = 0.31208836
Iteration 229, loss = 0.31026723
Iteration 230, loss = 0.30845216
Iteration 231, loss = 0.30661575
Iteration 232, loss = 0.30482277
Iteration 233, loss = 0.30300615
Iteration 234, loss = 0.30123273
Iteration 235, loss = 0.29943223
Iteration 236, loss = 0.29766171
Iteration 237, loss = 0.29591698
Iteration 238, loss = 0.29415716
Iteration 239, loss = 0.29241200
Iteration 240, loss = 0.29069325
Iteration 241, loss = 0.28895137
Iteration 242, loss = 0.28724700
Iteration 243, loss = 0.28553460
Iteration 244, loss = 0.28383975
Iteration 245, loss = 0.28216683
Iteration 246, loss = 0.28048255
Iteration 247, loss = 0.27883661
Iteration 248, loss = 0.27716934
Iteration 249, loss = 0.27551268
Iteration 250, loss = 0.27389528
Iteration 251, loss = 0.27223627
Iteration 252, loss = 0.27061992
Iteration 253, loss = 0.26900831
Iteration 254, loss = 0.26740248
Iteration 255, loss = 0.26581111
Iteration 256, loss = 0.26423701
Iteration 257, loss = 0.26267272
Iteration 258, loss = 0.26112696
Iteration 259, loss = 0.25955766
Iteration 260, loss = 0.25800797
Iteration 261, loss = 0.25648375
Iteration 262, loss = 0.25494390
Iteration 263, loss = 0.25341636
Iteration 264, loss = 0.25189885
Iteration 265, loss = 0.25040290
Iteration 266, loss = 0.24888882
Iteration 267, loss = 0.24739933
Iteration 268, loss = 0.24591305
Iteration 269, loss = 0.24445178
Iteration 270, loss = 0.24296983
Iteration 271, loss = 0.24154153
Iteration 272, loss = 0.24011120
Iteration 273, loss = 0.23867145
Iteration 274, loss = 0.23727042
Iteration 275, loss = 0.23584789
Iteration 276, loss = 0.23444962
Iteration 277, loss = 0.23305460
Iteration 278, loss = 0.23168716
Iteration 279, loss = 0.23028960
Iteration 280, loss = 0.22895049
Iteration 281, loss = 0.22760918
Iteration 282, loss = 0.22627440
Iteration 283, loss = 0.22494876
Iteration 284, loss = 0.22363295
Iteration 285, loss = 0.22232827
Iteration 286, loss = 0.22103246
Iteration 287, loss = 0.21972927
Iteration 288, loss = 0.21844964
Iteration 289, loss = 0.21716705
Iteration 290, loss = 0.21590330
Iteration 291, loss = 0.21463834
Iteration 292, loss = 0.21338268
Iteration 293, loss = 0.21214181
Iteration 294, loss = 0.21089862
Iteration 295, loss = 0.20966759
Iteration 296, loss = 0.20845964
Iteration 297, loss = 0.20724516
Iteration 298, loss = 0.20604549
Iteration 299, loss = 0.20485656
Iteration 300, loss = 0.20369192
Iteration 301, loss = 0.20252077
Iteration 302, loss = 0.20136095
Iteration 303, loss = 0.20021945
Iteration 304, loss = 0.19908350
Iteration 305, loss = 0.19795163
Iteration 306, loss = 0.19684284
Iteration 307, loss = 0.19573193
Iteration 308, loss = 0.19463810
Iteration 309, loss = 0.19354695
Iteration 310, loss = 0.19247105
Iteration 311, loss = 0.19141044
Iteration 312, loss = 0.19034266
Iteration 313, loss = 0.18930010
Iteration 314, loss = 0.18826277
Iteration 315, loss = 0.18721776
Iteration 316, loss = 0.18619150
Iteration 317, loss = 0.18517303
Iteration 318, loss = 0.18415729
Iteration 319, loss = 0.18314796
Iteration 320, loss = 0.18214172
Iteration 321, loss = 0.18115054
Iteration 322, loss = 0.18015816
Iteration 323, loss = 0.17917095
Iteration 324, loss = 0.17820153
Iteration 325, loss = 0.17723250
Iteration 326, loss = 0.17628545
Iteration 327, loss = 0.17531992
Iteration 328, loss = 0.17437351
Iteration 329, loss = 0.17344246
Iteration 330, loss = 0.17251898
Iteration 331, loss = 0.17159442
Iteration 332, loss = 0.17067756
Iteration 333, loss = 0.16978689
Iteration 334, loss = 0.16889516
Iteration 335, loss = 0.16801044
Iteration 336, loss = 0.16713773
Iteration 337, loss = 0.16627218
Iteration 338, loss = 0.16541372
Iteration 339, loss = 0.16455897
Iteration 340, loss = 0.16370645
Iteration 341, loss = 0.16286750
Iteration 342, loss = 0.16202789
Iteration 343, loss = 0.16120280
Iteration 344, loss = 0.16037793
Iteration 345, loss = 0.15955087
Iteration 346, loss = 0.15873767
Iteration 347, loss = 0.15793193
Iteration 348, loss = 0.15713714
Iteration 349, loss = 0.15634286
Iteration 350, loss = 0.15556518
Iteration 351, loss = 0.15478174
Iteration 352, loss = 0.15400947
Iteration 353, loss = 0.15323728
Iteration 354, loss = 0.15247223
Iteration 355, loss = 0.15170477
Iteration 356, loss = 0.15094653
Iteration 357, loss = 0.15019220
Iteration 358, loss = 0.14944448
Iteration 359, loss = 0.14870603
Iteration 360, loss = 0.14796952
Iteration 361, loss = 0.14724172
Iteration 362, loss = 0.14651033
Iteration 363, loss = 0.14578490
Iteration 364, loss = 0.14507802
Iteration 365, loss = 0.14437312
Iteration 366, loss = 0.14366485
Iteration 367, loss = 0.14297396
Iteration 368, loss = 0.14228535
Iteration 369, loss = 0.14160679
Iteration 370, loss = 0.14093627
Iteration 371, loss = 0.14027445
Iteration 372, loss = 0.13961459
Iteration 373, loss = 0.13896822
Iteration 374, loss = 0.13832795
Iteration 375, loss = 0.13768648
Iteration 376, loss = 0.13705338
Iteration 377, loss = 0.13643338
Iteration 378, loss = 0.13581109
Iteration 379, loss = 0.13519197
Iteration 380, loss = 0.13457500
Iteration 381, loss = 0.13396450
Iteration 382, loss = 0.13335792
Iteration 383, loss = 0.13275155
Iteration 384, loss = 0.13216145
Iteration 385, loss = 0.13156649
Iteration 386, loss = 0.13098068
Iteration 387, loss = 0.13040307
Iteration 388, loss = 0.12982493
Iteration 389, loss = 0.12925641
Iteration 390, loss = 0.12869191
Iteration 391, loss = 0.12812527
Iteration 392, loss = 0.12757408
Iteration 393, loss = 0.12701763
Iteration 394, loss = 0.12646917
Iteration 395, loss = 0.12592566
Iteration 396, loss = 0.12538518
Iteration 397, loss = 0.12485272
Iteration 398, loss = 0.12431869
Iteration 399, loss = 0.12378777
Iteration 400, loss = 0.12326535
Iteration 401, loss = 0.12275563
Iteration 402, loss = 0.12223750
Iteration 403, loss = 0.12173800
Iteration 404, loss = 0.12122965
Iteration 405, loss = 0.12073658
Iteration 406, loss = 0.12023321
Iteration 407, loss = 0.11974987
Iteration 408, loss = 0.11925609
Iteration 409, loss = 0.11877239
Iteration 410, loss = 0.11829156
Iteration 411, loss = 0.11781808
Iteration 412, loss = 0.11734831
Iteration 413, loss = 0.11687807
Iteration 414, loss = 0.11640995
Iteration 415, loss = 0.11594233
Iteration 416, loss = 0.11548893
Iteration 417, loss = 0.11503433
Iteration 418, loss = 0.11458228
Iteration 419, loss = 0.11413642
Iteration 420, loss = 0.11369646
Iteration 421, loss = 0.11326194
Iteration 422, loss = 0.11281771
Iteration 423, loss = 0.11238376
Iteration 424, loss = 0.11195137
Iteration 425, loss = 0.11149914
Iteration 426, loss = 0.11107127
Iteration 427, loss = 0.11063427
Iteration 428, loss = 0.11019362
Iteration 429, loss = 0.10977385
Iteration 430, loss = 0.10935335
Iteration 431, loss = 0.10892507
Iteration 432, loss = 0.10850801
Iteration 433, loss = 0.10809728
Iteration 434, loss = 0.10768575
Iteration 435, loss = 0.10728542
Iteration 436, loss = 0.10688273
Iteration 437, loss = 0.10648427
Iteration 438, loss = 0.10609121
Iteration 439, loss = 0.10570141
Iteration 440, loss = 0.10530977
Iteration 441, loss = 0.10492693
Iteration 442, loss = 0.10454158
Iteration 443, loss = 0.10416048
Iteration 444, loss = 0.10378044
Iteration 445, loss = 0.10340118
Iteration 446, loss = 0.10302800
Iteration 447, loss = 0.10265551
Iteration 448, loss = 0.10228677
Iteration 449, loss = 0.10192459
Iteration 450, loss = 0.10155984
Iteration 451, loss = 0.10119638
Iteration 452, loss = 0.10083797
Iteration 453, loss = 0.10048767
Iteration 454, loss = 0.10013217
Iteration 455, loss = 0.09978491
Iteration 456, loss = 0.09943867
Iteration 457, loss = 0.09909374
Iteration 458, loss = 0.09874572
Iteration 459, loss = 0.09840973
Iteration 460, loss = 0.09805388
Iteration 461, loss = 0.09770996
Iteration 462, loss = 0.09737784
Iteration 463, loss = 0.09704122
Iteration 464, loss = 0.09670530
Iteration 465, loss = 0.09636634
Iteration 466, loss = 0.09603757
Iteration 467, loss = 0.09571293
Iteration 468, loss = 0.09538551
Iteration 469, loss = 0.09506441
Iteration 470, loss = 0.09474636
Iteration 471, loss = 0.09442865
Iteration 472, loss = 0.09411593
Iteration 473, loss = 0.09380359
Iteration 474, loss = 0.09349776
Iteration 475, loss = 0.09318553
Iteration 476, loss = 0.09288295
Iteration 477, loss = 0.09258536
Iteration 478, loss = 0.09228768
Iteration 479, loss = 0.09199130
Iteration 480, loss = 0.09169450
Iteration 481, loss = 0.09140343
Iteration 482, loss = 0.09110460
Iteration 483, loss = 0.09081092
Iteration 484, loss = 0.09052250
Iteration 485, loss = 0.09023009
Iteration 486, loss = 0.08993951
Iteration 487, loss = 0.08964706
Iteration 488, loss = 0.08935833
Iteration 489, loss = 0.08906734
Iteration 490, loss = 0.08878446
Iteration 491, loss = 0.08849997
Iteration 492, loss = 0.08822987
Iteration 493, loss = 0.08794920
Iteration 494, loss = 0.08767910
Iteration 495, loss = 0.08741020
Iteration 496, loss = 0.08714333
Iteration 497, loss = 0.08688658
Iteration 498, loss = 0.08662384
Iteration 499, loss = 0.08636881
Iteration 500, loss = 0.08612075
Iteration 501, loss = 0.08586517
Iteration 502, loss = 0.08560533
Iteration 503, loss = 0.08536052
Iteration 504, loss = 0.08510781
Iteration 505, loss = 0.08486016
Iteration 506, loss = 0.08462850
Iteration 507, loss = 0.08438328
Iteration 508, loss = 0.08414153
Iteration 509, loss = 0.08390461
Iteration 510, loss = 0.08366464
Iteration 511, loss = 0.08342650
Iteration 512, loss = 0.08318871
Iteration 513, loss = 0.08295255
Iteration 514, loss = 0.08272040
Iteration 515, loss = 0.08248310
Iteration 516, loss = 0.08225173
Iteration 517, loss = 0.08201596
Iteration 518, loss = 0.08178841
Iteration 519, loss = 0.08155546
Iteration 520, loss = 0.08132867
Iteration 521, loss = 0.08110591
Iteration 522, loss = 0.08087712
Iteration 523, loss = 0.08065662
Iteration 524, loss = 0.08043488
Iteration 525, loss = 0.08021913
Iteration 526, loss = 0.07999614
Iteration 527, loss = 0.07978441
Iteration 528, loss = 0.07957114
Iteration 529, loss = 0.07935006
Iteration 530, loss = 0.07914614
Iteration 531, loss = 0.07892777
Iteration 532, loss = 0.07871926
Iteration 533, loss = 0.07851148
Iteration 534, loss = 0.07830360
Iteration 535, loss = 0.07810134
Iteration 536, loss = 0.07789098
Iteration 537, loss = 0.07768712
Iteration 538, loss = 0.07747962
Iteration 539, loss = 0.07727449
Iteration 540, loss = 0.07707393
Iteration 541, loss = 0.07686996
Iteration 542, loss = 0.07667672
Iteration 543, loss = 0.07647635
Iteration 544, loss = 0.07627835
Iteration 545, loss = 0.07608239
Iteration 546, loss = 0.07588462
Iteration 547, loss = 0.07569320
Iteration 548, loss = 0.07549638
Iteration 549, loss = 0.07530673
Iteration 550, loss = 0.07511786
Iteration 551, loss = 0.07492568
Iteration 552, loss = 0.07473735
Iteration 553, loss = 0.07454966
Iteration 554, loss = 0.07436581
Iteration 555, loss = 0.07417766
Iteration 556, loss = 0.07399384
Iteration 557, loss = 0.07380954
Iteration 558, loss = 0.07363369
Iteration 559, loss = 0.07345372
Iteration 560, loss = 0.07327530
Iteration 561, loss = 0.07309768
Iteration 562, loss = 0.07292263
Iteration 563, loss = 0.07275291
Iteration 564, loss = 0.07257315
Iteration 565, loss = 0.07241072
Iteration 566, loss = 0.07222973
Iteration 567, loss = 0.07205332
Iteration 568, loss = 0.07188551
Iteration 569, loss = 0.07172209
Iteration 570, loss = 0.07154186
Iteration 571, loss = 0.07137234
Iteration 572, loss = 0.07120270
Iteration 573, loss = 0.07103596
Iteration 574, loss = 0.07087213
Iteration 575, loss = 0.07070348
Iteration 576, loss = 0.07054088
Iteration 577, loss = 0.07037735
Iteration 578, loss = 0.07021301
Iteration 579, loss = 0.07005250
Iteration 580, loss = 0.06989026
Iteration 581, loss = 0.06972585
Iteration 582, loss = 0.06956644
Iteration 583, loss = 0.06940687
Iteration 584, loss = 0.06924766
Iteration 585, loss = 0.06909215
Iteration 586, loss = 0.06894198
Iteration 587, loss = 0.06878263
Iteration 588, loss = 0.06863048
Iteration 589, loss = 0.06847174
Iteration 590, loss = 0.06831620
Iteration 591, loss = 0.06816239
Iteration 592, loss = 0.06800443
Iteration 593, loss = 0.06785313
Iteration 594, loss = 0.06770257
Iteration 595, loss = 0.06754636
Iteration 596, loss = 0.06739603
Iteration 597, loss = 0.06724413
Iteration 598, loss = 0.06709556
Iteration 599, loss = 0.06694101
Iteration 600, loss = 0.06680142
Iteration 601, loss = 0.06665075
Iteration 602, loss = 0.06650325
Iteration 603, loss = 0.06635801
Iteration 604, loss = 0.06621268
Iteration 605, loss = 0.06606868
Iteration 606, loss = 0.06592639
Iteration 607, loss = 0.06579149
Iteration 608, loss = 0.06565085
Iteration 609, loss = 0.06552638
Iteration 610, loss = 0.06537854
Iteration 611, loss = 0.06523626
Iteration 612, loss = 0.06509423
Iteration 613, loss = 0.06496010
Iteration 614, loss = 0.06482275
Iteration 615, loss = 0.06468283
Iteration 616, loss = 0.06454417
Iteration 617, loss = 0.06441061
Iteration 618, loss = 0.06427592
Iteration 619, loss = 0.06414245
Iteration 620, loss = 0.06401079
Iteration 621, loss = 0.06388261
Iteration 622, loss = 0.06375259
Iteration 623, loss = 0.06362230
Iteration 624, loss = 0.06349617
Iteration 625, loss = 0.06336654
Iteration 626, loss = 0.06324590
Iteration 627, loss = 0.06311167
Iteration 628, loss = 0.06298443
Iteration 629, loss = 0.06285826
Iteration 630, loss = 0.06272866
Iteration 631, loss = 0.06260013
Iteration 632, loss = 0.06247354
Iteration 633, loss = 0.06234305
Iteration 634, loss = 0.06221624
Iteration 635, loss = 0.06208805
Iteration 636, loss = 0.06196207
Iteration 637, loss = 0.06183518
Iteration 638, loss = 0.06171390
Iteration 639, loss = 0.06158629
Iteration 640, loss = 0.06146629
Iteration 641, loss = 0.06134407
Iteration 642, loss = 0.06122227
Iteration 643, loss = 0.06110819
Iteration 644, loss = 0.06098878
Iteration 645, loss = 0.06087393
Iteration 646, loss = 0.06075977
Iteration 647, loss = 0.06065248
Iteration 648, loss = 0.06053147
Iteration 649, loss = 0.06041829
Iteration 650, loss = 0.06030431
Iteration 651, loss = 0.06018911
Iteration 652, loss = 0.06007307
Iteration 653, loss = 0.05995827
Iteration 654, loss = 0.05984643
Iteration 655, loss = 0.05973196
Iteration 656, loss = 0.05961579
Iteration 657, loss = 0.05950235
Iteration 658, loss = 0.05938996
Iteration 659, loss = 0.05927861
Iteration 660, loss = 0.05916733
Iteration 661, loss = 0.05905642
Iteration 662, loss = 0.05894400
Iteration 663, loss = 0.05883200
Iteration 664, loss = 0.05871945
Iteration 665, loss = 0.05860390
Iteration 666, loss = 0.05849293
Iteration 667, loss = 0.05837764
Iteration 668, loss = 0.05826919
Iteration 669, loss = 0.05815817
Iteration 670, loss = 0.05804499
Iteration 671, loss = 0.05793718
Iteration 672, loss = 0.05782812
Iteration 673, loss = 0.05772109
Iteration 674, loss = 0.05761655
Iteration 675, loss = 0.05750911
Iteration 676, loss = 0.05740364
Iteration 677, loss = 0.05730618
Iteration 678, loss = 0.05720219
Iteration 679, loss = 0.05708928
Iteration 680, loss = 0.05699003
Iteration 681, loss = 0.05688239
Iteration 682, loss = 0.05678694
Iteration 683, loss = 0.05668069
Iteration 684, loss = 0.05657710
Iteration 685, loss = 0.05647948
Iteration 686, loss = 0.05637768
Iteration 687, loss = 0.05627847
Iteration 688, loss = 0.05617530
Iteration 689, loss = 0.05608141
Iteration 690, loss = 0.05597992
Iteration 691, loss = 0.05588166
Iteration 692, loss = 0.05578381
Iteration 693, loss = 0.05569144
Iteration 694, loss = 0.05558911
Iteration 695, loss = 0.05549215
Iteration 696, loss = 0.05539319
Iteration 697, loss = 0.05530021
Iteration 698, loss = 0.05520415
Iteration 699, loss = 0.05511138
Iteration 700, loss = 0.05501410
Iteration 701, loss = 0.05491956
Iteration 702, loss = 0.05482817
Iteration 703, loss = 0.05473481
Iteration 704, loss = 0.05464847
Iteration 705, loss = 0.05455097
Iteration 706, loss = 0.05445745
Iteration 707, loss = 0.05436481
Iteration 708, loss = 0.05426923
Iteration 709, loss = 0.05418144
Iteration 710, loss = 0.05408723
Iteration 711, loss = 0.05399298
Iteration 712, loss = 0.05390428
Iteration 713, loss = 0.05381341
Iteration 714, loss = 0.05372305
Iteration 715, loss = 0.05363145
Iteration 716, loss = 0.05354120
Iteration 717, loss = 0.05345107
Iteration 718, loss = 0.05336346
Iteration 719, loss = 0.05327566
Iteration 720, loss = 0.05318805
Iteration 721, loss = 0.05310296
Iteration 722, loss = 0.05301693
Iteration 723, loss = 0.05292738
Iteration 724, loss = 0.05284260
Iteration 725, loss = 0.05276142
Iteration 726, loss = 0.05267066
Iteration 727, loss = 0.05258526
Iteration 728, loss = 0.05250150
Iteration 729, loss = 0.05241468
Iteration 730, loss = 0.05232811
Iteration 731, loss = 0.05224065
Iteration 732, loss = 0.05215254
Iteration 733, loss = 0.05206364
Iteration 734, loss = 0.05197606
Iteration 735, loss = 0.05189405
Iteration 736, loss = 0.05180512
Iteration 737, loss = 0.05172310
Iteration 738, loss = 0.05163996
Iteration 739, loss = 0.05155821
Iteration 740, loss = 0.05147655
Iteration 741, loss = 0.05139573
Iteration 742, loss = 0.05131518
Iteration 743, loss = 0.05123682
Iteration 744, loss = 0.05115923
Iteration 745, loss = 0.05107687
Iteration 746, loss = 0.05099669
Iteration 747, loss = 0.05091513
Iteration 748, loss = 0.05083231
Iteration 749, loss = 0.05075245
Iteration 750, loss = 0.05066829
Iteration 751, loss = 0.05058709
Iteration 752, loss = 0.05050598
Iteration 753, loss = 0.05042800
Iteration 754, loss = 0.05034899
Iteration 755, loss = 0.05027129
Iteration 756, loss = 0.05019480
Iteration 757, loss = 0.05011495
Iteration 758, loss = 0.05003898
Iteration 759, loss = 0.04996252
Iteration 760, loss = 0.04988776
Iteration 761, loss = 0.04980472
Iteration 762, loss = 0.04973137
Iteration 763, loss = 0.04965375
Iteration 764, loss = 0.04956821
Iteration 765, loss = 0.04949439
Iteration 766, loss = 0.04941898
Iteration 767, loss = 0.04934029
Iteration 768, loss = 0.04926291
Iteration 769, loss = 0.04918609
Iteration 770, loss = 0.04911162
Iteration 771, loss = 0.04903389
Iteration 772, loss = 0.04895976
Iteration 773, loss = 0.04888546
Iteration 774, loss = 0.04881072
Iteration 775, loss = 0.04873876
Iteration 776, loss = 0.04866239
Iteration 777, loss = 0.04858463
Iteration 778, loss = 0.04851527
Iteration 779, loss = 0.04843891
Iteration 780, loss = 0.04836222
Iteration 781, loss = 0.04828670
Iteration 782, loss = 0.04821518
Iteration 783, loss = 0.04814128
Iteration 784, loss = 0.04807215
Iteration 785, loss = 0.04800586
Iteration 786, loss = 0.04793256
Iteration 787, loss = 0.04786676
Iteration 788, loss = 0.04779542
Iteration 789, loss = 0.04772780
Iteration 790, loss = 0.04765795
Iteration 791, loss = 0.04758818
Iteration 792, loss = 0.04751802
Iteration 793, loss = 0.04744533
Iteration 794, loss = 0.04737366
Iteration 795, loss = 0.04730351
Iteration 796, loss = 0.04723149
Iteration 797, loss = 0.04716511
Iteration 798, loss = 0.04708965
Iteration 799, loss = 0.04702285
Iteration 800, loss = 0.04695684
Iteration 801, loss = 0.04688102
Iteration 802, loss = 0.04681255
Iteration 803, loss = 0.04674711
Iteration 804, loss = 0.04667727
Iteration 805, loss = 0.04660837
Iteration 806, loss = 0.04654191
Iteration 807, loss = 0.04647153
Iteration 808, loss = 0.04640688
Iteration 809, loss = 0.04634166
Iteration 810, loss = 0.04627641
Iteration 811, loss = 0.04621098
Iteration 812, loss = 0.04614643
Iteration 813, loss = 0.04608119
Iteration 814, loss = 0.04601828
Iteration 815, loss = 0.04595557
Iteration 816, loss = 0.04589033
Iteration 817, loss = 0.04582722
Iteration 818, loss = 0.04575964
Iteration 819, loss = 0.04569148
Iteration 820, loss = 0.04562646
Iteration 821, loss = 0.04556111
Iteration 822, loss = 0.04549598
Iteration 823, loss = 0.04542862
Iteration 824, loss = 0.04536482
Iteration 825, loss = 0.04529954
Iteration 826, loss = 0.04523418
Iteration 827, loss = 0.04517100
Iteration 828, loss = 0.04510570
Iteration 829, loss = 0.04504441
Iteration 830, loss = 0.04498528
Iteration 831, loss = 0.04491659
Iteration 832, loss = 0.04485348
Iteration 833, loss = 0.04478819
Iteration 834, loss = 0.04472832
Iteration 835, loss = 0.04466381
Iteration 836, loss = 0.04460120
Iteration 837, loss = 0.04453627
Iteration 838, loss = 0.04447377
Iteration 839, loss = 0.04441199
Iteration 840, loss = 0.04435063
Iteration 841, loss = 0.04429073
Iteration 842, loss = 0.04423107
Iteration 843, loss = 0.04417497
Iteration 844, loss = 0.04411362
Iteration 845, loss = 0.04405498
Iteration 846, loss = 0.04399555
Iteration 847, loss = 0.04393533
Iteration 848, loss = 0.04387684
Iteration 849, loss = 0.04381669
Iteration 850, loss = 0.04375340
Iteration 851, loss = 0.04369636
Iteration 852, loss = 0.04363405
Iteration 853, loss = 0.04357662
Iteration 854, loss = 0.04351525
Iteration 855, loss = 0.04345606
Iteration 856, loss = 0.04339775
Iteration 857, loss = 0.04334414
Iteration 858, loss = 0.04328214
Iteration 859, loss = 0.04322494
Iteration 860, loss = 0.04316515
Iteration 861, loss = 0.04310679
Iteration 862, loss = 0.04304876
Iteration 863, loss = 0.04299071
Iteration 864, loss = 0.04293267
Iteration 865, loss = 0.04286967
Iteration 866, loss = 0.04281340
Iteration 867, loss = 0.04275351
Iteration 868, loss = 0.04270126
Iteration 869, loss = 0.04263646
Iteration 870, loss = 0.04257961
Iteration 871, loss = 0.04252036
Iteration 872, loss = 0.04245950
Iteration 873, loss = 0.04240328
Iteration 874, loss = 0.04234728
Iteration 875, loss = 0.04229469
Iteration 876, loss = 0.04224274
Iteration 877, loss = 0.04218682
Iteration 878, loss = 0.04213586
Iteration 879, loss = 0.04208716
Iteration 880, loss = 0.04202833
Iteration 881, loss = 0.04197639
Iteration 882, loss = 0.04192479
Iteration 883, loss = 0.04187621
Iteration 884, loss = 0.04182353
Iteration 885, loss = 0.04177575
Iteration 886, loss = 0.04172226
Iteration 887, loss = 0.04166837
Iteration 888, loss = 0.04161723
Iteration 889, loss = 0.04156629
Iteration 890, loss = 0.04151566
Iteration 891, loss = 0.04146710
Iteration 892, loss = 0.04141880
Iteration 893, loss = 0.04136967
Iteration 894, loss = 0.04132271
Iteration 895, loss = 0.04127164
Iteration 896, loss = 0.04122562
Iteration 897, loss = 0.04117276
Iteration 898, loss = 0.04112357
Iteration 899, loss = 0.04107288
Iteration 900, loss = 0.04102515
Iteration 901, loss = 0.04097468
Iteration 902, loss = 0.04092533
Iteration 903, loss = 0.04087247
Iteration 904, loss = 0.04082455
Iteration 905, loss = 0.04077367
Iteration 906, loss = 0.04072307
Iteration 907, loss = 0.04067441
Iteration 908, loss = 0.04062355
Iteration 909, loss = 0.04057436
Iteration 910, loss = 0.04052363
Iteration 911, loss = 0.04047912
Iteration 912, loss = 0.04042700
Iteration 913, loss = 0.04038989
Iteration 914, loss = 0.04033110
Iteration 915, loss = 0.04028809
Iteration 916, loss = 0.04023713
Iteration 917, loss = 0.04019249
Iteration 918, loss = 0.04014270
Iteration 919, loss = 0.04009500
Iteration 920, loss = 0.04004867
Iteration 921, loss = 0.04000022
Iteration 922, loss = 0.03995526
Iteration 923, loss = 0.03990783
Iteration 924, loss = 0.03986068
Iteration 925, loss = 0.03981504
Iteration 926, loss = 0.03977022
Iteration 927, loss = 0.03972477
Iteration 928, loss = 0.03967935
Iteration 929, loss = 0.03963538
Iteration 930, loss = 0.03958988
Iteration 931, loss = 0.03954832
Iteration 932, loss = 0.03949959
Iteration 933, loss = 0.03945190
Iteration 934, loss = 0.03940573
Iteration 935, loss = 0.03936295
Iteration 936, loss = 0.03931702
Iteration 937, loss = 0.03927314
Iteration 938, loss = 0.03922898
Iteration 939, loss = 0.03918571
Iteration 940, loss = 0.03913901
Iteration 941, loss = 0.03909620
Iteration 942, loss = 0.03904735
Iteration 943, loss = 0.03900136
Iteration 944, loss = 0.03895536
Iteration 945, loss = 0.03890793
Iteration 946, loss = 0.03886433
Iteration 947, loss = 0.03881844
Iteration 948, loss = 0.03877220
Iteration 949, loss = 0.03872751
Iteration 950, loss = 0.03868530
Iteration 951, loss = 0.03863947
Iteration 952, loss = 0.03859225
Iteration 953, loss = 0.03855687
Iteration 954, loss = 0.03850848
Iteration 955, loss = 0.03846303
Iteration 956, loss = 0.03842093
Iteration 957, loss = 0.03837588
Iteration 958, loss = 0.03833278
Iteration 959, loss = 0.03828890
Iteration 960, loss = 0.03824763
Iteration 961, loss = 0.03820252
Iteration 962, loss = 0.03815822
Iteration 963, loss = 0.03811619
Iteration 964, loss = 0.03807219
Iteration 965, loss = 0.03803007
Iteration 966, loss = 0.03798566
Iteration 967, loss = 0.03794411
Iteration 968, loss = 0.03790202
Iteration 969, loss = 0.03786035
Iteration 970, loss = 0.03781978
Iteration 971, loss = 0.03778012
Iteration 972, loss = 0.03774183
Iteration 973, loss = 0.03769876
Iteration 974, loss = 0.03765733
Iteration 975, loss = 0.03761778
Iteration 976, loss = 0.03757574
Iteration 977, loss = 0.03753763
Iteration 978, loss = 0.03749681
Iteration 979, loss = 0.03745737
Iteration 980, loss = 0.03741660
Iteration 981, loss = 0.03737907
Iteration 982, loss = 0.03733832
Iteration 983, loss = 0.03729922
Iteration 984, loss = 0.03726046
Iteration 985, loss = 0.03721990
Iteration 986, loss = 0.03717773
Iteration 987, loss = 0.03713753
Iteration 988, loss = 0.03709528
Iteration 989, loss = 0.03705660
Iteration 990, loss = 0.03701598
Iteration 991, loss = 0.03697713
Iteration 992, loss = 0.03693592
Iteration 993, loss = 0.03689609
Iteration 994, loss = 0.03685685
Iteration 995, loss = 0.03681517
Iteration 996, loss = 0.03677576
Iteration 997, loss = 0.03674275
Iteration 998, loss = 0.03669691
Iteration 999, loss = 0.03665734
Iteration 1000, loss = 0.03661964
Iteration 1001, loss = 0.03657931
Iteration 1002, loss = 0.03654002
Iteration 1003, loss = 0.03649965
Iteration 1004, loss = 0.03646106
Iteration 1005, loss = 0.03642482
Iteration 1006, loss = 0.03638579
Iteration 1007, loss = 0.03634461
Iteration 1008, loss = 0.03630852
Iteration 1009, loss = 0.03626558
Iteration 1010, loss = 0.03622899
Iteration 1011, loss = 0.03618775
Iteration 1012, loss = 0.03614938
Iteration 1013, loss = 0.03611127
Iteration 1014, loss = 0.03607362
Iteration 1015, loss = 0.03603689
Iteration 1016, loss = 0.03599958
Iteration 1017, loss = 0.03596197
Iteration 1018, loss = 0.03592424
Iteration 1019, loss = 0.03588363
Iteration 1020, loss = 0.03584554
Iteration 1021, loss = 0.03580623
Iteration 1022, loss = 0.03576700
Iteration 1023, loss = 0.03572584
Iteration 1024, loss = 0.03568879
Iteration 1025, loss = 0.03565102
Iteration 1026, loss = 0.03561154
Iteration 1027, loss = 0.03557139
Iteration 1028, loss = 0.03553799
Iteration 1029, loss = 0.03549656
Iteration 1030, loss = 0.03545888
Iteration 1031, loss = 0.03542306
Iteration 1032, loss = 0.03538462
Iteration 1033, loss = 0.03534716
Iteration 1034, loss = 0.03531006
Iteration 1035, loss = 0.03527484
Iteration 1036, loss = 0.03523920
Iteration 1037, loss = 0.03520641
Iteration 1038, loss = 0.03516739
Iteration 1039, loss = 0.03513097
Iteration 1040, loss = 0.03509346
Iteration 1041, loss = 0.03505722
Iteration 1042, loss = 0.03502050
Iteration 1043, loss = 0.03498481
Iteration 1044, loss = 0.03494962
Iteration 1045, loss = 0.03491506
Iteration 1046, loss = 0.03488264
Iteration 1047, loss = 0.03484535
Iteration 1048, loss = 0.03481089
Iteration 1049, loss = 0.03477440
Iteration 1050, loss = 0.03474071
Iteration 1051, loss = 0.03470577
Iteration 1052, loss = 0.03466943
Iteration 1053, loss = 0.03463527
Iteration 1054, loss = 0.03459913
Iteration 1055, loss = 0.03456475
Iteration 1056, loss = 0.03452928
Iteration 1057, loss = 0.03449568
Iteration 1058, loss = 0.03445833
Iteration 1059, loss = 0.03442786
Iteration 1060, loss = 0.03439034
Iteration 1061, loss = 0.03435597
Iteration 1062, loss = 0.03431942
Iteration 1063, loss = 0.03428755
Iteration 1064, loss = 0.03425180
Iteration 1065, loss = 0.03421913
Iteration 1066, loss = 0.03418765
Iteration 1067, loss = 0.03415486
Iteration 1068, loss = 0.03412589
Iteration 1069, loss = 0.03408956
Iteration 1070, loss = 0.03405473
Iteration 1071, loss = 0.03402151
Iteration 1072, loss = 0.03397884
Iteration 1073, loss = 0.03394445
Iteration 1074, loss = 0.03390968
Iteration 1075, loss = 0.03386953
Iteration 1076, loss = 0.03384008
Iteration 1077, loss = 0.03380250
Iteration 1078, loss = 0.03376503
Iteration 1079, loss = 0.03373479
Iteration 1080, loss = 0.03369711
Iteration 1081, loss = 0.03366788
Iteration 1082, loss = 0.03363064
Iteration 1083, loss = 0.03359998
Iteration 1084, loss = 0.03356374
Iteration 1085, loss = 0.03353029
Iteration 1086, loss = 0.03349496
Iteration 1087, loss = 0.03345991
Iteration 1088, loss = 0.03342820
Iteration 1089, loss = 0.03339744
Iteration 1090, loss = 0.03336233
Iteration 1091, loss = 0.03332941
Iteration 1092, loss = 0.03329968
Iteration 1093, loss = 0.03326566
Iteration 1094, loss = 0.03323591
Iteration 1095, loss = 0.03320323
Iteration 1096, loss = 0.03317244
Iteration 1097, loss = 0.03313720
Iteration 1098, loss = 0.03310531
Iteration 1099, loss = 0.03307234
Iteration 1100, loss = 0.03304168
Iteration 1101, loss = 0.03300852
Iteration 1102, loss = 0.03297282
Iteration 1103, loss = 0.03293972
Iteration 1104, loss = 0.03290706
Iteration 1105, loss = 0.03287295
Iteration 1106, loss = 0.03284226
Iteration 1107, loss = 0.03280806
Iteration 1108, loss = 0.03277628
Iteration 1109, loss = 0.03274434
Iteration 1110, loss = 0.03271440
Iteration 1111, loss = 0.03268056
Iteration 1112, loss = 0.03264818
Iteration 1113, loss = 0.03261730
Iteration 1114, loss = 0.03258609
Iteration 1115, loss = 0.03255417
Iteration 1116, loss = 0.03252064
Iteration 1117, loss = 0.03248844
Iteration 1118, loss = 0.03245762
Iteration 1119, loss = 0.03242394
Iteration 1120, loss = 0.03239566
Iteration 1121, loss = 0.03236040
Iteration 1122, loss = 0.03233418
Iteration 1123, loss = 0.03230328
Iteration 1124, loss = 0.03226900
Iteration 1125, loss = 0.03223722
Iteration 1126, loss = 0.03220660
Iteration 1127, loss = 0.03217535
Iteration 1128, loss = 0.03214325
Iteration 1129, loss = 0.03211563
Iteration 1130, loss = 0.03208332
Iteration 1131, loss = 0.03204995
Iteration 1132, loss = 0.03201663
Iteration 1133, loss = 0.03198496
Iteration 1134, loss = 0.03195743
Iteration 1135, loss = 0.03192531
Iteration 1136, loss = 0.03189113
Iteration 1137, loss = 0.03185876
Iteration 1138, loss = 0.03182728
Iteration 1139, loss = 0.03179509
Iteration 1140, loss = 0.03176564
Iteration 1141, loss = 0.03173430
Iteration 1142, loss = 0.03170288
Iteration 1143, loss = 0.03167507
Iteration 1144, loss = 0.03164350
Iteration 1145, loss = 0.03161551
Iteration 1146, loss = 0.03158429
Iteration 1147, loss = 0.03155498
Iteration 1148, loss = 0.03152552
Iteration 1149, loss = 0.03149732
Iteration 1150, loss = 0.03146804
Iteration 1151, loss = 0.03143960
Iteration 1152, loss = 0.03141342
Iteration 1153, loss = 0.03138563
Iteration 1154, loss = 0.03135774
Iteration 1155, loss = 0.03132982
Iteration 1156, loss = 0.03130037
Iteration 1157, loss = 0.03127175
Iteration 1158, loss = 0.03124319
Iteration 1159, loss = 0.03121411
Iteration 1160, loss = 0.03118488
Iteration 1161, loss = 0.03115598
Iteration 1162, loss = 0.03112666
Iteration 1163, loss = 0.03109870
Iteration 1164, loss = 0.03107192
Iteration 1165, loss = 0.03104589
Iteration 1166, loss = 0.03101951
Iteration 1167, loss = 0.03099371
Iteration 1168, loss = 0.03096639
Iteration 1169, loss = 0.03093744
Iteration 1170, loss = 0.03090892
Iteration 1171, loss = 0.03088394
Iteration 1172, loss = 0.03085504
Iteration 1173, loss = 0.03082686
Iteration 1174, loss = 0.03080340
Iteration 1175, loss = 0.03077634
Iteration 1176, loss = 0.03075024
Iteration 1177, loss = 0.03072682
Iteration 1178, loss = 0.03070575
Iteration 1179, loss = 0.03067731
Iteration 1180, loss = 0.03065432
Iteration 1181, loss = 0.03062267
Iteration 1182, loss = 0.03059518
Iteration 1183, loss = 0.03056641
Iteration 1184, loss = 0.03053778
Iteration 1185, loss = 0.03051038
Iteration 1186, loss = 0.03048191
Iteration 1187, loss = 0.03045487
Iteration 1188, loss = 0.03042726
Iteration 1189, loss = 0.03040299
Iteration 1190, loss = 0.03037744
Iteration 1191, loss = 0.03034961
Iteration 1192, loss = 0.03032303
Iteration 1193, loss = 0.03029501
Iteration 1194, loss = 0.03026649
Iteration 1195, loss = 0.03024247
Iteration 1196, loss = 0.03021183
Iteration 1197, loss = 0.03018592
Iteration 1198, loss = 0.03015465
Iteration 1199, loss = 0.03013046
Iteration 1200, loss = 0.03010035
Iteration 1201, loss = 0.03007437
Iteration 1202, loss = 0.03004828
Iteration 1203, loss = 0.03002184
Iteration 1204, loss = 0.02999485
Iteration 1205, loss = 0.02997044
Iteration 1206, loss = 0.02994442
Iteration 1207, loss = 0.02991946
Iteration 1208, loss = 0.02989523
Iteration 1209, loss = 0.02987265
Iteration 1210, loss = 0.02984834
Iteration 1211, loss = 0.02982631
Iteration 1212, loss = 0.02980109
Iteration 1213, loss = 0.02977517
Iteration 1214, loss = 0.02975172
Iteration 1215, loss = 0.02972771
Iteration 1216, loss = 0.02970359
Iteration 1217, loss = 0.02967916
Iteration 1218, loss = 0.02965367
Iteration 1219, loss = 0.02962740
Iteration 1220, loss = 0.02960062
Iteration 1221, loss = 0.02957646
Iteration 1222, loss = 0.02954753
Iteration 1223, loss = 0.02951959
Iteration 1224, loss = 0.02949592
Iteration 1225, loss = 0.02947397
Iteration 1226, loss = 0.02944509
Iteration 1227, loss = 0.02941649
Iteration 1228, loss = 0.02939341
Iteration 1229, loss = 0.02936513
Iteration 1230, loss = 0.02933890
Iteration 1231, loss = 0.02931151
Iteration 1232, loss = 0.02928137
Iteration 1233, loss = 0.02925426
Iteration 1234, loss = 0.02923092
Iteration 1235, loss = 0.02920100
Iteration 1236, loss = 0.02917627
Iteration 1237, loss = 0.02914963
Iteration 1238, loss = 0.02912432
Iteration 1239, loss = 0.02909496
Iteration 1240, loss = 0.02907554
Iteration 1241, loss = 0.02904417
Iteration 1242, loss = 0.02902007
Iteration 1243, loss = 0.02899629
Iteration 1244, loss = 0.02896970
Iteration 1245, loss = 0.02894248
Iteration 1246, loss = 0.02891706
Iteration 1247, loss = 0.02889273
Iteration 1248, loss = 0.02886876
Iteration 1249, loss = 0.02884462
Iteration 1250, loss = 0.02882129
Iteration 1251, loss = 0.02879485
Iteration 1252, loss = 0.02876967
Iteration 1253, loss = 0.02874503
Iteration 1254, loss = 0.02871894
Iteration 1255, loss = 0.02869318
Iteration 1256, loss = 0.02866867
Iteration 1257, loss = 0.02864184
Iteration 1258, loss = 0.02861620
Iteration 1259, loss = 0.02858908
Iteration 1260, loss = 0.02856644
Iteration 1261, loss = 0.02854014
Iteration 1262, loss = 0.02851343
Iteration 1263, loss = 0.02848775
Iteration 1264, loss = 0.02846619
Iteration 1265, loss = 0.02843926
Iteration 1266, loss = 0.02841505
Iteration 1267, loss = 0.02839175
Iteration 1268, loss = 0.02836911
Iteration 1269, loss = 0.02834499
Iteration 1270, loss = 0.02831815
Iteration 1271, loss = 0.02829427
Iteration 1272, loss = 0.02826975
Iteration 1273, loss = 0.02824500
Iteration 1274, loss = 0.02822469
Iteration 1275, loss = 0.02819575
Iteration 1276, loss = 0.02817290
Iteration 1277, loss = 0.02814725
Iteration 1278, loss = 0.02812248
Iteration 1279, loss = 0.02809892
Iteration 1280, loss = 0.02807437
Iteration 1281, loss = 0.02804876
Iteration 1282, loss = 0.02802734
Iteration 1283, loss = 0.02800204
Iteration 1284, loss = 0.02797867
Iteration 1285, loss = 0.02795634
Iteration 1286, loss = 0.02793477
Iteration 1287, loss = 0.02791020
Iteration 1288, loss = 0.02788730
Iteration 1289, loss = 0.02786416
Iteration 1290, loss = 0.02784231
Iteration 1291, loss = 0.02781930
Iteration 1292, loss = 0.02779623
Iteration 1293, loss = 0.02777342
Iteration 1294, loss = 0.02775156
Iteration 1295, loss = 0.02772759
Iteration 1296, loss = 0.02770520
Iteration 1297, loss = 0.02768303
Iteration 1298, loss = 0.02766018
Iteration 1299, loss = 0.02763802
Iteration 1300, loss = 0.02761455
Iteration 1301, loss = 0.02759377
Iteration 1302, loss = 0.02757093
Iteration 1303, loss = 0.02754915
Iteration 1304, loss = 0.02752524
Iteration 1305, loss = 0.02750549
Iteration 1306, loss = 0.02748201
Iteration 1307, loss = 0.02746107
Iteration 1308, loss = 0.02744097
Iteration 1309, loss = 0.02741594
Iteration 1310, loss = 0.02739291
Iteration 1311, loss = 0.02736545
Iteration 1312, loss = 0.02734087
Iteration 1313, loss = 0.02731712
Iteration 1314, loss = 0.02729459
Iteration 1315, loss = 0.02727320
Iteration 1316, loss = 0.02724719
Iteration 1317, loss = 0.02722424
Iteration 1318, loss = 0.02720327
Iteration 1319, loss = 0.02717927
Iteration 1320, loss = 0.02715751
Iteration 1321, loss = 0.02713357
Iteration 1322, loss = 0.02711251
Iteration 1323, loss = 0.02708802
Iteration 1324, loss = 0.02707036
Iteration 1325, loss = 0.02704455
Iteration 1326, loss = 0.02702382
Iteration 1327, loss = 0.02700055
Iteration 1328, loss = 0.02697998
Iteration 1329, loss = 0.02695797
Iteration 1330, loss = 0.02693679
Iteration 1331, loss = 0.02691417
Iteration 1332, loss = 0.02689315
Iteration 1333, loss = 0.02687030
Iteration 1334, loss = 0.02685187
Iteration 1335, loss = 0.02682850
Iteration 1336, loss = 0.02680794
Iteration 1337, loss = 0.02678662
Iteration 1338, loss = 0.02676549
Iteration 1339, loss = 0.02674449
Iteration 1340, loss = 0.02672168
Iteration 1341, loss = 0.02670151
Iteration 1342, loss = 0.02667861
Iteration 1343, loss = 0.02665793
Iteration 1344, loss = 0.02663651
Iteration 1345, loss = 0.02661688
Iteration 1346, loss = 0.02659681
Iteration 1347, loss = 0.02657487
Iteration 1348, loss = 0.02655428
Iteration 1349, loss = 0.02653338
Iteration 1350, loss = 0.02651337
Iteration 1351, loss = 0.02649235
Iteration 1352, loss = 0.02647036
Iteration 1353, loss = 0.02644829
Iteration 1354, loss = 0.02642599
Iteration 1355, loss = 0.02640626
Iteration 1356, loss = 0.02638541
Iteration 1357, loss = 0.02636786
Iteration 1358, loss = 0.02634526
Iteration 1359, loss = 0.02632319
Iteration 1360, loss = 0.02630241
Iteration 1361, loss = 0.02628231
Iteration 1362, loss = 0.02626209
Iteration 1363, loss = 0.02624111
Iteration 1364, loss = 0.02622126
Iteration 1365, loss = 0.02620034
Iteration 1366, loss = 0.02617964
Iteration 1367, loss = 0.02616081
Iteration 1368, loss = 0.02614076
Iteration 1369, loss = 0.02612261
Iteration 1370, loss = 0.02610270
Iteration 1371, loss = 0.02608531
Iteration 1372, loss = 0.02606562
Iteration 1373, loss = 0.02604859
Iteration 1374, loss = 0.02603010
Iteration 1375, loss = 0.02601123
Iteration 1376, loss = 0.02599399
Iteration 1377, loss = 0.02597639
Iteration 1378, loss = 0.02595491
Iteration 1379, loss = 0.02593548
Iteration 1380, loss = 0.02591738
Iteration 1381, loss = 0.02589771
Iteration 1382, loss = 0.02587818
Iteration 1383, loss = 0.02585921
Iteration 1384, loss = 0.02584021
Iteration 1385, loss = 0.02582082
Iteration 1386, loss = 0.02580105
Iteration 1387, loss = 0.02578234
Iteration 1388, loss = 0.02576344
Iteration 1389, loss = 0.02573925
Iteration 1390, loss = 0.02572094
Iteration 1391, loss = 0.02569811
Iteration 1392, loss = 0.02567726
Iteration 1393, loss = 0.02565762
Iteration 1394, loss = 0.02563712
Iteration 1395, loss = 0.02562251
Iteration 1396, loss = 0.02560138
Iteration 1397, loss = 0.02558061
Iteration 1398, loss = 0.02556283
Iteration 1399, loss = 0.02554148
Iteration 1400, loss = 0.02552425
Iteration 1401, loss = 0.02550258
Iteration 1402, loss = 0.02548254
Iteration 1403, loss = 0.02546361
Iteration 1404, loss = 0.02544389
Iteration 1405, loss = 0.02542567
Iteration 1406, loss = 0.02540528
Iteration 1407, loss = 0.02538859
Iteration 1408, loss = 0.02536476
Iteration 1409, loss = 0.02534543
Iteration 1410, loss = 0.02532142
Iteration 1411, loss = 0.02530400
Iteration 1412, loss = 0.02528297
Iteration 1413, loss = 0.02526350
Iteration 1414, loss = 0.02524338
Iteration 1415, loss = 0.02522398
Iteration 1416, loss = 0.02520452
Iteration 1417, loss = 0.02518590
Iteration 1418, loss = 0.02516929
Iteration 1419, loss = 0.02514900
Iteration 1420, loss = 0.02512685
Iteration 1421, loss = 0.02510903
Iteration 1422, loss = 0.02508845
Iteration 1423, loss = 0.02506821
Iteration 1424, loss = 0.02504732
Iteration 1425, loss = 0.02502814
Iteration 1426, loss = 0.02500892
Iteration 1427, loss = 0.02498950
Iteration 1428, loss = 0.02497172
Iteration 1429, loss = 0.02495192
Iteration 1430, loss = 0.02493258
Iteration 1431, loss = 0.02491332
Iteration 1432, loss = 0.02489546
Iteration 1433, loss = 0.02487609
Iteration 1434, loss = 0.02485828
Iteration 1435, loss = 0.02483852
Iteration 1436, loss = 0.02482049
Iteration 1437, loss = 0.02480147
Iteration 1438, loss = 0.02478150
Iteration 1439, loss = 0.02476435
Iteration 1440, loss = 0.02474444
Iteration 1441, loss = 0.02472411
Iteration 1442, loss = 0.02470491
Iteration 1443, loss = 0.02468696
Iteration 1444, loss = 0.02466752
Iteration 1445, loss = 0.02464828
Iteration 1446, loss = 0.02463103
Iteration 1447, loss = 0.02461222
Iteration 1448, loss = 0.02459370
Iteration 1449, loss = 0.02457891
Iteration 1450, loss = 0.02455982
Iteration 1451, loss = 0.02454237
Iteration 1452, loss = 0.02452524
Iteration 1453, loss = 0.02450657
Iteration 1454, loss = 0.02448588
Iteration 1455, loss = 0.02446552
Iteration 1456, loss = 0.02444798
Iteration 1457, loss = 0.02442824
Iteration 1458, loss = 0.02440736
Iteration 1459, loss = 0.02439819
Iteration 1460, loss = 0.02437414
Iteration 1461, loss = 0.02435538
Iteration 1462, loss = 0.02433598
Iteration 1463, loss = 0.02431897
Iteration 1464, loss = 0.02430037
Iteration 1465, loss = 0.02428218
Iteration 1466, loss = 0.02426516
Iteration 1467, loss = 0.02425116
Iteration 1468, loss = 0.02423306
Iteration 1469, loss = 0.02421592
Iteration 1470, loss = 0.02419772
Iteration 1471, loss = 0.02418078
Iteration 1472, loss = 0.02416269
Iteration 1473, loss = 0.02414479
Iteration 1474, loss = 0.02412695
Iteration 1475, loss = 0.02410746
Iteration 1476, loss = 0.02408983
Iteration 1477, loss = 0.02407073
Iteration 1478, loss = 0.02405192
Iteration 1479, loss = 0.02403308
Iteration 1480, loss = 0.02401691
Iteration 1481, loss = 0.02399670
Iteration 1482, loss = 0.02398108
Iteration 1483, loss = 0.02396253
Iteration 1484, loss = 0.02394563
Iteration 1485, loss = 0.02392758
Iteration 1486, loss = 0.02391034
Iteration 1487, loss = 0.02389285
Iteration 1488, loss = 0.02387526
Iteration 1489, loss = 0.02385616
Iteration 1490, loss = 0.02384124
Iteration 1491, loss = 0.02382218
Iteration 1492, loss = 0.02380275
Iteration 1493, loss = 0.02378494
Iteration 1494, loss = 0.02376600
Iteration 1495, loss = 0.02374972
Iteration 1496, loss = 0.02372951
Iteration 1497, loss = 0.02371102
Iteration 1498, loss = 0.02369557
Iteration 1499, loss = 0.02367669
Iteration 1500, loss = 0.02365841
Iteration 1501, loss = 0.02364136
Iteration 1502, loss = 0.02362368
Iteration 1503, loss = 0.02360815
Iteration 1504, loss = 0.02358974
Iteration 1505, loss = 0.02357294
Iteration 1506, loss = 0.02355771
Iteration 1507, loss = 0.02353972
Iteration 1508, loss = 0.02352183
Iteration 1509, loss = 0.02350475
Iteration 1510, loss = 0.02348873
Iteration 1511, loss = 0.02347088
Iteration 1512, loss = 0.02345517
Iteration 1513, loss = 0.02343615
Iteration 1514, loss = 0.02341938
Iteration 1515, loss = 0.02340267
Iteration 1516, loss = 0.02338429
Iteration 1517, loss = 0.02336661
Iteration 1518, loss = 0.02334921
Iteration 1519, loss = 0.02333300
Iteration 1520, loss = 0.02331704
Iteration 1521, loss = 0.02330110
Iteration 1522, loss = 0.02328419
Iteration 1523, loss = 0.02327042
Iteration 1524, loss = 0.02325328
Iteration 1525, loss = 0.02323674
Iteration 1526, loss = 0.02322106
Iteration 1527, loss = 0.02320364
Iteration 1528, loss = 0.02318775
Iteration 1529, loss = 0.02317119
Iteration 1530, loss = 0.02315483
Iteration 1531, loss = 0.02313765
Iteration 1532, loss = 0.02312238
Iteration 1533, loss = 0.02310586
Iteration 1534, loss = 0.02308900
Iteration 1535, loss = 0.02307241
Iteration 1536, loss = 0.02305623
Iteration 1537, loss = 0.02303905
Iteration 1538, loss = 0.02302473
Iteration 1539, loss = 0.02300730
Iteration 1540, loss = 0.02299046
Iteration 1541, loss = 0.02297320
Iteration 1542, loss = 0.02295656
Iteration 1543, loss = 0.02294169
Iteration 1544, loss = 0.02292592
Iteration 1545, loss = 0.02290875
Iteration 1546, loss = 0.02289150
Iteration 1547, loss = 0.02287470
Iteration 1548, loss = 0.02286065
Iteration 1549, loss = 0.02284229
Iteration 1550, loss = 0.02282681
Iteration 1551, loss = 0.02280850
Iteration 1552, loss = 0.02279112
Iteration 1553, loss = 0.02277620
Iteration 1554, loss = 0.02275766
Iteration 1555, loss = 0.02274131
Iteration 1556, loss = 0.02272539
Iteration 1557, loss = 0.02270782
Iteration 1558, loss = 0.02269257
Iteration 1559, loss = 0.02267665
Iteration 1560, loss = 0.02265983
Iteration 1561, loss = 0.02264283
Iteration 1562, loss = 0.02262588
Iteration 1563, loss = 0.02260968
Iteration 1564, loss = 0.02259230
Iteration 1565, loss = 0.02257478
Iteration 1566, loss = 0.02255962
Iteration 1567, loss = 0.02254190
Iteration 1568, loss = 0.02252574
Iteration 1569, loss = 0.02251191
Iteration 1570, loss = 0.02249372
Iteration 1571, loss = 0.02247706
Iteration 1572, loss = 0.02245977
Iteration 1573, loss = 0.02244250
Iteration 1574, loss = 0.02242579
Iteration 1575, loss = 0.02241050
Iteration 1576, loss = 0.02239342
Iteration 1577, loss = 0.02237534
Iteration 1578, loss = 0.02235869
Iteration 1579, loss = 0.02234201
Iteration 1580, loss = 0.02232545
Iteration 1581, loss = 0.02230880
Iteration 1582, loss = 0.02229389
Iteration 1583, loss = 0.02227946
Iteration 1584, loss = 0.02226401
Iteration 1585, loss = 0.02224805
Iteration 1586, loss = 0.02223319
Iteration 1587, loss = 0.02221394
Iteration 1588, loss = 0.02220088
Iteration 1589, loss = 0.02218290
Iteration 1590, loss = 0.02216573
Iteration 1591, loss = 0.02215011
Iteration 1592, loss = 0.02213567
Iteration 1593, loss = 0.02212105
Iteration 1594, loss = 0.02210515
Iteration 1595, loss = 0.02208770
Iteration 1596, loss = 0.02207107
Iteration 1597, loss = 0.02205672
Iteration 1598, loss = 0.02203963
Iteration 1599, loss = 0.02202356
Iteration 1600, loss = 0.02200926
Iteration 1601, loss = 0.02199077
Iteration 1602, loss = 0.02197495
Iteration 1603, loss = 0.02195939
Iteration 1604, loss = 0.02194251
Iteration 1605, loss = 0.02192740
Iteration 1606, loss = 0.02191149
Iteration 1607, loss = 0.02189391
Iteration 1608, loss = 0.02187731
Iteration 1609, loss = 0.02186524
Iteration 1610, loss = 0.02184686
Iteration 1611, loss = 0.02183007
Iteration 1612, loss = 0.02181712
Iteration 1613, loss = 0.02179990
Iteration 1614, loss = 0.02178344
Iteration 1615, loss = 0.02176888
Iteration 1616, loss = 0.02175267
Iteration 1617, loss = 0.02173631
Iteration 1618, loss = 0.02172066
Iteration 1619, loss = 0.02170492
Iteration 1620, loss = 0.02168886
Iteration 1621, loss = 0.02167273
Iteration 1622, loss = 0.02165893
Iteration 1623, loss = 0.02164091
Iteration 1624, loss = 0.02162555
Iteration 1625, loss = 0.02160916
Iteration 1626, loss = 0.02159364
Iteration 1627, loss = 0.02157867
Iteration 1628, loss = 0.02156448
Iteration 1629, loss = 0.02154957
Iteration 1630, loss = 0.02153404
Iteration 1631, loss = 0.02151829
Iteration 1632, loss = 0.02150591
Iteration 1633, loss = 0.02149124
Iteration 1634, loss = 0.02147488
Iteration 1635, loss = 0.02145923
Iteration 1636, loss = 0.02144445
Iteration 1637, loss = 0.02143114
Iteration 1638, loss = 0.02141243
Iteration 1639, loss = 0.02139733
Iteration 1640, loss = 0.02138542
Iteration 1641, loss = 0.02136854
Iteration 1642, loss = 0.02135614
Iteration 1643, loss = 0.02133884
Iteration 1644, loss = 0.02132365
Iteration 1645, loss = 0.02131036
Iteration 1646, loss = 0.02129423
Iteration 1647, loss = 0.02127898
Iteration 1648, loss = 0.02126515
Iteration 1649, loss = 0.02124919
Iteration 1650, loss = 0.02123549
Iteration 1651, loss = 0.02122072
Iteration 1652, loss = 0.02120654
Iteration 1653, loss = 0.02119325
Iteration 1654, loss = 0.02117851
Iteration 1655, loss = 0.02116483
Iteration 1656, loss = 0.02115326
Iteration 1657, loss = 0.02113844
Iteration 1658, loss = 0.02112604
Iteration 1659, loss = 0.02111092
Iteration 1660, loss = 0.02109739
Iteration 1661, loss = 0.02108290
Iteration 1662, loss = 0.02106809
Iteration 1663, loss = 0.02105424
Iteration 1664, loss = 0.02103969
Iteration 1665, loss = 0.02102570
Iteration 1666, loss = 0.02101165
Iteration 1667, loss = 0.02099685
Iteration 1668, loss = 0.02098258
Iteration 1669, loss = 0.02097119
Iteration 1670, loss = 0.02095479
Iteration 1671, loss = 0.02094252
Iteration 1672, loss = 0.02092692
Iteration 1673, loss = 0.02091308
Iteration 1674, loss = 0.02090149
Iteration 1675, loss = 0.02088440
Iteration 1676, loss = 0.02087058
Iteration 1677, loss = 0.02085573
Iteration 1678, loss = 0.02084163
Iteration 1679, loss = 0.02082822
Iteration 1680, loss = 0.02081766
Iteration 1681, loss = 0.02080154
Iteration 1682, loss = 0.02078834
Iteration 1683, loss = 0.02077409
Iteration 1684, loss = 0.02075986
Iteration 1685, loss = 0.02074828
Iteration 1686, loss = 0.02073358
Iteration 1687, loss = 0.02071881
Iteration 1688, loss = 0.02070511
Iteration 1689, loss = 0.02069224
Iteration 1690, loss = 0.02067705
Iteration 1691, loss = 0.02066554
Iteration 1692, loss = 0.02065123
Iteration 1693, loss = 0.02063590
Iteration 1694, loss = 0.02062067
Iteration 1695, loss = 0.02060746
Iteration 1696, loss = 0.02059806
Iteration 1697, loss = 0.02058319
Iteration 1698, loss = 0.02056913
Iteration 1699, loss = 0.02055563
Iteration 1700, loss = 0.02054185
Iteration 1701, loss = 0.02052921
Iteration 1702, loss = 0.02051634
Iteration 1703, loss = 0.02050311
Iteration 1704, loss = 0.02049147
Iteration 1705, loss = 0.02047652
Iteration 1706, loss = 0.02046442
Iteration 1707, loss = 0.02045006
Iteration 1708, loss = 0.02043609
Iteration 1709, loss = 0.02042279
Iteration 1710, loss = 0.02040944
Iteration 1711, loss = 0.02039671
Iteration 1712, loss = 0.02038526
Iteration 1713, loss = 0.02036905
Iteration 1714, loss = 0.02035553
Iteration 1715, loss = 0.02034115
Iteration 1716, loss = 0.02032692
Iteration 1717, loss = 0.02031648
Iteration 1718, loss = 0.02030043
Iteration 1719, loss = 0.02028512
Iteration 1720, loss = 0.02027017
Iteration 1721, loss = 0.02025678
Iteration 1722, loss = 0.02024210
Iteration 1723, loss = 0.02023089
Iteration 1724, loss = 0.02021558
Iteration 1725, loss = 0.02020180
Iteration 1726, loss = 0.02018860
Iteration 1727, loss = 0.02017617
Iteration 1728, loss = 0.02016304
Iteration 1729, loss = 0.02014974
Iteration 1730, loss = 0.02013505
Iteration 1731, loss = 0.02012475
Iteration 1732, loss = 0.02011073
Iteration 1733, loss = 0.02009635
Iteration 1734, loss = 0.02008262
Iteration 1735, loss = 0.02006880
Iteration 1736, loss = 0.02005652
Iteration 1737, loss = 0.02004360
Iteration 1738, loss = 0.02003078
Iteration 1739, loss = 0.02001701
Iteration 1740, loss = 0.02000340
Iteration 1741, loss = 0.01999022
Iteration 1742, loss = 0.01997605
Iteration 1743, loss = 0.01996330
Iteration 1744, loss = 0.01995032
Iteration 1745, loss = 0.01993860
Iteration 1746, loss = 0.01992450
Iteration 1747, loss = 0.01991231
Iteration 1748, loss = 0.01989818
Iteration 1749, loss = 0.01988456
Iteration 1750, loss = 0.01987161
Iteration 1751, loss = 0.01985714
Iteration 1752, loss = 0.01984759
Iteration 1753, loss = 0.01983244
Iteration 1754, loss = 0.01982082
Iteration 1755, loss = 0.01980752
Iteration 1756, loss = 0.01979535
Iteration 1757, loss = 0.01978247
Iteration 1758, loss = 0.01976830
Iteration 1759, loss = 0.01975506
Iteration 1760, loss = 0.01974319
Iteration 1761, loss = 0.01972844
Iteration 1762, loss = 0.01971500
Iteration 1763, loss = 0.01970275
Iteration 1764, loss = 0.01969038
Iteration 1765, loss = 0.01968003
Iteration 1766, loss = 0.01966664
Iteration 1767, loss = 0.01965474
Iteration 1768, loss = 0.01964274
Iteration 1769, loss = 0.01963134
Iteration 1770, loss = 0.01961913
Iteration 1771, loss = 0.01960817
Iteration 1772, loss = 0.01959539
Iteration 1773, loss = 0.01958361
Iteration 1774, loss = 0.01956986
Iteration 1775, loss = 0.01955854
Iteration 1776, loss = 0.01954896
Iteration 1777, loss = 0.01953300
Iteration 1778, loss = 0.01952042
Iteration 1779, loss = 0.01950797
Iteration 1780, loss = 0.01949389
Iteration 1781, loss = 0.01948110
Iteration 1782, loss = 0.01946888
Iteration 1783, loss = 0.01945442
Iteration 1784, loss = 0.01944180
Iteration 1785, loss = 0.01943002
Iteration 1786, loss = 0.01941540
Iteration 1787, loss = 0.01940138
Iteration 1788, loss = 0.01938829
Iteration 1789, loss = 0.01937647
Iteration 1790, loss = 0.01935994
Iteration 1791, loss = 0.01934614
Iteration 1792, loss = 0.01933246
Iteration 1793, loss = 0.01931795
Iteration 1794, loss = 0.01930458
Iteration 1795, loss = 0.01929164
Iteration 1796, loss = 0.01928057
Iteration 1797, loss = 0.01926632
Iteration 1798, loss = 0.01925451
Iteration 1799, loss = 0.01924245
Iteration 1800, loss = 0.01922996
Iteration 1801, loss = 0.01921869
Iteration 1802, loss = 0.01920649
Iteration 1803, loss = 0.01919318
Iteration 1804, loss = 0.01918216
Iteration 1805, loss = 0.01917317
Iteration 1806, loss = 0.01915795
Iteration 1807, loss = 0.01914554
Iteration 1808, loss = 0.01913123
Iteration 1809, loss = 0.01911812
Iteration 1810, loss = 0.01910858
Iteration 1811, loss = 0.01909216
Iteration 1812, loss = 0.01908001
Iteration 1813, loss = 0.01906990
Iteration 1814, loss = 0.01905575
Iteration 1815, loss = 0.01904398
Iteration 1816, loss = 0.01903088
Iteration 1817, loss = 0.01901928
Iteration 1818, loss = 0.01900794
Iteration 1819, loss = 0.01899294
Iteration 1820, loss = 0.01898049
Iteration 1821, loss = 0.01896748
Iteration 1822, loss = 0.01895569
Iteration 1823, loss = 0.01894197
Iteration 1824, loss = 0.01892880
Iteration 1825, loss = 0.01891663
Iteration 1826, loss = 0.01890642
Iteration 1827, loss = 0.01889270
Iteration 1828, loss = 0.01887956
Iteration 1829, loss = 0.01886804
Iteration 1830, loss = 0.01885603
Iteration 1831, loss = 0.01884385
Iteration 1832, loss = 0.01883174
Iteration 1833, loss = 0.01881903
Iteration 1834, loss = 0.01880668
Iteration 1835, loss = 0.01879558
Iteration 1836, loss = 0.01878513
Iteration 1837, loss = 0.01877108
Iteration 1838, loss = 0.01875986
Iteration 1839, loss = 0.01874756
Iteration 1840, loss = 0.01873544
Iteration 1841, loss = 0.01872418
Iteration 1842, loss = 0.01871202
Iteration 1843, loss = 0.01869996
Iteration 1844, loss = 0.01868852
Iteration 1845, loss = 0.01867796
Iteration 1846, loss = 0.01866556
Iteration 1847, loss = 0.01865377
Iteration 1848, loss = 0.01864204
Iteration 1849, loss = 0.01863090
Iteration 1850, loss = 0.01862060
Iteration 1851, loss = 0.01860772
Iteration 1852, loss = 0.01859544
Iteration 1853, loss = 0.01858325
Iteration 1854, loss = 0.01857202
Iteration 1855, loss = 0.01856303
Iteration 1856, loss = 0.01855024
Iteration 1857, loss = 0.01853887
Iteration 1858, loss = 0.01852728
Iteration 1859, loss = 0.01851553
Iteration 1860, loss = 0.01850358
Iteration 1861, loss = 0.01849239
Iteration 1862, loss = 0.01848076
Iteration 1863, loss = 0.01846967
Iteration 1864, loss = 0.01845894
Iteration 1865, loss = 0.01844788
Iteration 1866, loss = 0.01843621
Iteration 1867, loss = 0.01842474
Iteration 1868, loss = 0.01841416
Iteration 1869, loss = 0.01840259
Iteration 1870, loss = 0.01839139
Iteration 1871, loss = 0.01838083
Iteration 1872, loss = 0.01836960
Iteration 1873, loss = 0.01835841
Iteration 1874, loss = 0.01834771
Iteration 1875, loss = 0.01833696
Iteration 1876, loss = 0.01832542
Iteration 1877, loss = 0.01831380
Iteration 1878, loss = 0.01830262
Iteration 1879, loss = 0.01829284
Iteration 1880, loss = 0.01828389
Iteration 1881, loss = 0.01827047
Iteration 1882, loss = 0.01825874
Iteration 1883, loss = 0.01824492
Iteration 1884, loss = 0.01823464
Iteration 1885, loss = 0.01822028
Iteration 1886, loss = 0.01820914
Iteration 1887, loss = 0.01819748
Iteration 1888, loss = 0.01818571
Iteration 1889, loss = 0.01817409
Iteration 1890, loss = 0.01816310
Iteration 1891, loss = 0.01815172
Iteration 1892, loss = 0.01813911
Iteration 1893, loss = 0.01812857
Iteration 1894, loss = 0.01811773
Iteration 1895, loss = 0.01810560
Iteration 1896, loss = 0.01809403
Iteration 1897, loss = 0.01808300
Iteration 1898, loss = 0.01807130
Iteration 1899, loss = 0.01806165
Iteration 1900, loss = 0.01804774
Iteration 1901, loss = 0.01803589
Iteration 1902, loss = 0.01802564
Iteration 1903, loss = 0.01801147
Iteration 1904, loss = 0.01800177
Iteration 1905, loss = 0.01798955
Iteration 1906, loss = 0.01797795
Iteration 1907, loss = 0.01796685
Iteration 1908, loss = 0.01795522
Iteration 1909, loss = 0.01794666
Iteration 1910, loss = 0.01793377
Iteration 1911, loss = 0.01792244
Iteration 1912, loss = 0.01791123
Iteration 1913, loss = 0.01790039
Iteration 1914, loss = 0.01788958
Iteration 1915, loss = 0.01788050
Iteration 1916, loss = 0.01786947
Iteration 1917, loss = 0.01785930
Iteration 1918, loss = 0.01784768
Iteration 1919, loss = 0.01783734
Iteration 1920, loss = 0.01782665
Iteration 1921, loss = 0.01781598
Iteration 1922, loss = 0.01780523
Iteration 1923, loss = 0.01779486
Iteration 1924, loss = 0.01778502
Iteration 1925, loss = 0.01777543
Iteration 1926, loss = 0.01776486
Iteration 1927, loss = 0.01775352
Iteration 1928, loss = 0.01774354
Iteration 1929, loss = 0.01773349
Iteration 1930, loss = 0.01772372
Iteration 1931, loss = 0.01771416
Iteration 1932, loss = 0.01770517
Iteration 1933, loss = 0.01769755
Iteration 1934, loss = 0.01768615
Iteration 1935, loss = 0.01767630
Iteration 1936, loss = 0.01766691
Iteration 1937, loss = 0.01765628
Iteration 1938, loss = 0.01764596
Iteration 1939, loss = 0.01763524
Iteration 1940, loss = 0.01762509
Iteration 1941, loss = 0.01761322
Iteration 1942, loss = 0.01760211
Iteration 1943, loss = 0.01759181
Iteration 1944, loss = 0.01757957
Iteration 1945, loss = 0.01756794
Iteration 1946, loss = 0.01755553
Iteration 1947, loss = 0.01754469
Iteration 1948, loss = 0.01753400
Iteration 1949, loss = 0.01752274
Iteration 1950, loss = 0.01751167
Iteration 1951, loss = 0.01750062
Iteration 1952, loss = 0.01749031
Iteration 1953, loss = 0.01747990
Iteration 1954, loss = 0.01746930
Iteration 1955, loss = 0.01745867
Iteration 1956, loss = 0.01744938
Iteration 1957, loss = 0.01743914
Iteration 1958, loss = 0.01742832
Iteration 1959, loss = 0.01741854
Iteration 1960, loss = 0.01740907
Iteration 1961, loss = 0.01739948
Iteration 1962, loss = 0.01738983
Iteration 1963, loss = 0.01738032
Iteration 1964, loss = 0.01737146
Iteration 1965, loss = 0.01736019
Iteration 1966, loss = 0.01735130
Iteration 1967, loss = 0.01734216
Iteration 1968, loss = 0.01733045
Iteration 1969, loss = 0.01732071
Iteration 1970, loss = 0.01730885
Iteration 1971, loss = 0.01729892
Iteration 1972, loss = 0.01728906
Iteration 1973, loss = 0.01728170
Iteration 1974, loss = 0.01726999
Iteration 1975, loss = 0.01725923
Iteration 1976, loss = 0.01725158
Iteration 1977, loss = 0.01724154
Iteration 1978, loss = 0.01723162
Iteration 1979, loss = 0.01722264
Iteration 1980, loss = 0.01721372
Iteration 1981, loss = 0.01720263
Iteration 1982, loss = 0.01719447
Iteration 1983, loss = 0.01718360
Iteration 1984, loss = 0.01717286
Iteration 1985, loss = 0.01716296
Iteration 1986, loss = 0.01715382
Iteration 1987, loss = 0.01714451
Iteration 1988, loss = 0.01713468
Iteration 1989, loss = 0.01712803
Iteration 1990, loss = 0.01711568
Iteration 1991, loss = 0.01710575
Iteration 1992, loss = 0.01709601
Iteration 1993, loss = 0.01708694
Iteration 1994, loss = 0.01707751
Iteration 1995, loss = 0.01706768
Iteration 1996, loss = 0.01705823
Iteration 1997, loss = 0.01704898
Iteration 1998, loss = 0.01703977
Iteration 1999, loss = 0.01703054
Iteration 2000, loss = 0.01702059
Iteration 2001, loss = 0.01701120
Iteration 2002, loss = 0.01700302
Iteration 2003, loss = 0.01699219
Iteration 2004, loss = 0.01698301
Iteration 2005, loss = 0.01697319
Iteration 2006, loss = 0.01696373
Iteration 2007, loss = 0.01695453
Iteration 2008, loss = 0.01694401
Iteration 2009, loss = 0.01693464
Iteration 2010, loss = 0.01692535
Iteration 2011, loss = 0.01691564
Iteration 2012, loss = 0.01690679
Iteration 2013, loss = 0.01689837
Iteration 2014, loss = 0.01688889
Iteration 2015, loss = 0.01688061
Iteration 2016, loss = 0.01687251
Iteration 2017, loss = 0.01686025
Iteration 2018, loss = 0.01684950
Iteration 2019, loss = 0.01683884
Iteration 2020, loss = 0.01682839
Iteration 2021, loss = 0.01681733
Iteration 2022, loss = 0.01680926
Iteration 2023, loss = 0.01680010
Iteration 2024, loss = 0.01679089
Iteration 2025, loss = 0.01678082
Iteration 2026, loss = 0.01677509
Iteration 2027, loss = 0.01676528
Iteration 2028, loss = 0.01675517
Iteration 2029, loss = 0.01674609
Iteration 2030, loss = 0.01673490
Iteration 2031, loss = 0.01672591
Iteration 2032, loss = 0.01671463
Iteration 2033, loss = 0.01670445
Iteration 2034, loss = 0.01669557
Iteration 2035, loss = 0.01668495
Iteration 2036, loss = 0.01667490
Iteration 2037, loss = 0.01666453
Iteration 2038, loss = 0.01665591
Iteration 2039, loss = 0.01664761
Iteration 2040, loss = 0.01663673
Iteration 2041, loss = 0.01662617
Iteration 2042, loss = 0.01661550
Iteration 2043, loss = 0.01660392
Iteration 2044, loss = 0.01659303
Iteration 2045, loss = 0.01658250
Iteration 2046, loss = 0.01657104
Iteration 2047, loss = 0.01656202
Iteration 2048, loss = 0.01655021
Iteration 2049, loss = 0.01654175
Iteration 2050, loss = 0.01652966
Iteration 2051, loss = 0.01651904
Iteration 2052, loss = 0.01651095
Iteration 2053, loss = 0.01650007
Iteration 2054, loss = 0.01649113
Iteration 2055, loss = 0.01648012
Iteration 2056, loss = 0.01647168
Iteration 2057, loss = 0.01646066
Iteration 2058, loss = 0.01645250
Iteration 2059, loss = 0.01644204
Iteration 2060, loss = 0.01643266
Iteration 2061, loss = 0.01642298
Iteration 2062, loss = 0.01641395
Iteration 2063, loss = 0.01640331
Iteration 2064, loss = 0.01639395
Iteration 2065, loss = 0.01638310
Iteration 2066, loss = 0.01637332
Iteration 2067, loss = 0.01636311
Iteration 2068, loss = 0.01635318
Iteration 2069, loss = 0.01634356
Iteration 2070, loss = 0.01633436
Iteration 2071, loss = 0.01632534
Iteration 2072, loss = 0.01631667
Iteration 2073, loss = 0.01630901
Iteration 2074, loss = 0.01629760
Iteration 2075, loss = 0.01628883
Iteration 2076, loss = 0.01627852
Iteration 2077, loss = 0.01626893
Iteration 2078, loss = 0.01625952
Iteration 2079, loss = 0.01624949
Iteration 2080, loss = 0.01624066
Iteration 2081, loss = 0.01623264
Iteration 2082, loss = 0.01622281
Iteration 2083, loss = 0.01621463
Iteration 2084, loss = 0.01620437
Iteration 2085, loss = 0.01619461
Iteration 2086, loss = 0.01618590
Iteration 2087, loss = 0.01617708
Iteration 2088, loss = 0.01616781
Iteration 2089, loss = 0.01616102
Iteration 2090, loss = 0.01615017
Iteration 2091, loss = 0.01614289
Iteration 2092, loss = 0.01613319
Iteration 2093, loss = 0.01612454
Iteration 2094, loss = 0.01611527
Iteration 2095, loss = 0.01610694
Iteration 2096, loss = 0.01609876
Iteration 2097, loss = 0.01608855
Iteration 2098, loss = 0.01608002
Iteration 2099, loss = 0.01606997
Iteration 2100, loss = 0.01606262
Iteration 2101, loss = 0.01605213
Iteration 2102, loss = 0.01604262
Iteration 2103, loss = 0.01603448
Iteration 2104, loss = 0.01602546
Iteration 2105, loss = 0.01601727
Iteration 2106, loss = 0.01600904
Iteration 2107, loss = 0.01599975
Iteration 2108, loss = 0.01599152
Iteration 2109, loss = 0.01598201
Iteration 2110, loss = 0.01597259
Iteration 2111, loss = 0.01596394
Iteration 2112, loss = 0.01595459
Iteration 2113, loss = 0.01594565
Iteration 2114, loss = 0.01593771
Iteration 2115, loss = 0.01592891
Iteration 2116, loss = 0.01592452
Iteration 2117, loss = 0.01591266
Iteration 2118, loss = 0.01590440
Iteration 2119, loss = 0.01589455
Iteration 2120, loss = 0.01588461
Iteration 2121, loss = 0.01587671
Iteration 2122, loss = 0.01586689
Iteration 2123, loss = 0.01585716
Iteration 2124, loss = 0.01584993
Iteration 2125, loss = 0.01584109
Iteration 2126, loss = 0.01583308
Iteration 2127, loss = 0.01582144
Iteration 2128, loss = 0.01581057
Iteration 2129, loss = 0.01579938
Iteration 2130, loss = 0.01579208
Iteration 2131, loss = 0.01578161
Iteration 2132, loss = 0.01577240
Iteration 2133, loss = 0.01576306
Iteration 2134, loss = 0.01575199
Iteration 2135, loss = 0.01574580
Iteration 2136, loss = 0.01573539
Iteration 2137, loss = 0.01572517
Iteration 2138, loss = 0.01571621
Iteration 2139, loss = 0.01570694
Iteration 2140, loss = 0.01569799
Iteration 2141, loss = 0.01568855
Iteration 2142, loss = 0.01567730
Iteration 2143, loss = 0.01567071
Iteration 2144, loss = 0.01565917
Iteration 2145, loss = 0.01565180
Iteration 2146, loss = 0.01564193
Iteration 2147, loss = 0.01563552
Iteration 2148, loss = 0.01562491
Iteration 2149, loss = 0.01561611
Iteration 2150, loss = 0.01560850
Iteration 2151, loss = 0.01560031
Iteration 2152, loss = 0.01559189
Iteration 2153, loss = 0.01558387
Iteration 2154, loss = 0.01557482
Iteration 2155, loss = 0.01556663
Iteration 2156, loss = 0.01555732
Iteration 2157, loss = 0.01554773
Iteration 2158, loss = 0.01553852
Iteration 2159, loss = 0.01552910
Iteration 2160, loss = 0.01552097
Iteration 2161, loss = 0.01551080
Iteration 2162, loss = 0.01550507
Iteration 2163, loss = 0.01549343
Iteration 2164, loss = 0.01548498
Iteration 2165, loss = 0.01547527
Iteration 2166, loss = 0.01546733
Iteration 2167, loss = 0.01545765
Iteration 2168, loss = 0.01544867
Iteration 2169, loss = 0.01544072
Iteration 2170, loss = 0.01543220
Iteration 2171, loss = 0.01542434
Iteration 2172, loss = 0.01541572
Iteration 2173, loss = 0.01540706
Iteration 2174, loss = 0.01539826
Iteration 2175, loss = 0.01539310
Iteration 2176, loss = 0.01538154
Iteration 2177, loss = 0.01537415
Iteration 2178, loss = 0.01536411
Iteration 2179, loss = 0.01535760
Iteration 2180, loss = 0.01534944
Iteration 2181, loss = 0.01534084
Iteration 2182, loss = 0.01533245
Iteration 2183, loss = 0.01532325
Iteration 2184, loss = 0.01531585
Iteration 2185, loss = 0.01530653
Iteration 2186, loss = 0.01530042
Iteration 2187, loss = 0.01529342
Iteration 2188, loss = 0.01528498
Iteration 2189, loss = 0.01527633
Iteration 2190, loss = 0.01526787
Iteration 2191, loss = 0.01525958
Iteration 2192, loss = 0.01525101
Iteration 2193, loss = 0.01524092
Iteration 2194, loss = 0.01523181
Iteration 2195, loss = 0.01522153
Iteration 2196, loss = 0.01521267
Iteration 2197, loss = 0.01520402
Iteration 2198, loss = 0.01519539
Iteration 2199, loss = 0.01518585
Iteration 2200, loss = 0.01517788
Iteration 2201, loss = 0.01516953
Iteration 2202, loss = 0.01516166
Iteration 2203, loss = 0.01515368
Iteration 2204, loss = 0.01514673
Iteration 2205, loss = 0.01513803
Iteration 2206, loss = 0.01513110
Iteration 2207, loss = 0.01512437
Iteration 2208, loss = 0.01511673
Iteration 2209, loss = 0.01510758
Iteration 2210, loss = 0.01509887
Iteration 2211, loss = 0.01509131
Iteration 2212, loss = 0.01508438
Iteration 2213, loss = 0.01507391
Iteration 2214, loss = 0.01506728
Iteration 2215, loss = 0.01505688
Iteration 2216, loss = 0.01504854
Iteration 2217, loss = 0.01503969
Iteration 2218, loss = 0.01503236
Iteration 2219, loss = 0.01502448
Iteration 2220, loss = 0.01501549
Iteration 2221, loss = 0.01500909
Iteration 2222, loss = 0.01499892
Iteration 2223, loss = 0.01499495
Iteration 2224, loss = 0.01498475
Iteration 2225, loss = 0.01497544
Iteration 2226, loss = 0.01496730
Iteration 2227, loss = 0.01495990
Iteration 2228, loss = 0.01495203
Iteration 2229, loss = 0.01494469
Iteration 2230, loss = 0.01493726
Iteration 2231, loss = 0.01492961
Iteration 2232, loss = 0.01492273
Iteration 2233, loss = 0.01491404
Iteration 2234, loss = 0.01490658
Iteration 2235, loss = 0.01489903
Iteration 2236, loss = 0.01489090
Iteration 2237, loss = 0.01488355
Iteration 2238, loss = 0.01487482
Iteration 2239, loss = 0.01486684
Iteration 2240, loss = 0.01485896
Iteration 2241, loss = 0.01485026
Iteration 2242, loss = 0.01484090
Iteration 2243, loss = 0.01483141
Iteration 2244, loss = 0.01482430
Iteration 2245, loss = 0.01481650
Iteration 2246, loss = 0.01480724
Iteration 2247, loss = 0.01479841
Iteration 2248, loss = 0.01479140
Iteration 2249, loss = 0.01478348
Iteration 2250, loss = 0.01477553
Iteration 2251, loss = 0.01477023
Iteration 2252, loss = 0.01476184
Iteration 2253, loss = 0.01475506
Iteration 2254, loss = 0.01474509
Iteration 2255, loss = 0.01473776
Iteration 2256, loss = 0.01472857
Iteration 2257, loss = 0.01472066
Iteration 2258, loss = 0.01471257
Iteration 2259, loss = 0.01470430
Iteration 2260, loss = 0.01469608
Iteration 2261, loss = 0.01468803
Iteration 2262, loss = 0.01467822
Iteration 2263, loss = 0.01467010
Iteration 2264, loss = 0.01466210
Iteration 2265, loss = 0.01465350
Iteration 2266, loss = 0.01464614
Iteration 2267, loss = 0.01463840
Iteration 2268, loss = 0.01463091
Iteration 2269, loss = 0.01462348
Iteration 2270, loss = 0.01461721
Iteration 2271, loss = 0.01460852
Iteration 2272, loss = 0.01460064
Iteration 2273, loss = 0.01459324
Iteration 2274, loss = 0.01458457
Iteration 2275, loss = 0.01457592
Iteration 2276, loss = 0.01456874
Iteration 2277, loss = 0.01456083
Iteration 2278, loss = 0.01455231
Iteration 2279, loss = 0.01454340
Iteration 2280, loss = 0.01453486
Iteration 2281, loss = 0.01452761
Iteration 2282, loss = 0.01451946
Iteration 2283, loss = 0.01451096
Iteration 2284, loss = 0.01450284
Iteration 2285, loss = 0.01449495
Iteration 2286, loss = 0.01448701
Iteration 2287, loss = 0.01447905
Iteration 2288, loss = 0.01447111
Iteration 2289, loss = 0.01446343
Iteration 2290, loss = 0.01445551
Iteration 2291, loss = 0.01444661
Iteration 2292, loss = 0.01443978
Iteration 2293, loss = 0.01443154
Iteration 2294, loss = 0.01442437
Iteration 2295, loss = 0.01441758
Iteration 2296, loss = 0.01441100
Iteration 2297, loss = 0.01440347
Iteration 2298, loss = 0.01439858
Iteration 2299, loss = 0.01438975
Iteration 2300, loss = 0.01438345
Iteration 2301, loss = 0.01437813
Iteration 2302, loss = 0.01436917
Iteration 2303, loss = 0.01436081
Iteration 2304, loss = 0.01435235
Iteration 2305, loss = 0.01434547
Iteration 2306, loss = 0.01433690
Iteration 2307, loss = 0.01433048
Iteration 2308, loss = 0.01432340
Iteration 2309, loss = 0.01431452
Iteration 2310, loss = 0.01430728
Iteration 2311, loss = 0.01429996
Iteration 2312, loss = 0.01429252
Iteration 2313, loss = 0.01428514
Iteration 2314, loss = 0.01427802
Iteration 2315, loss = 0.01427010
Iteration 2316, loss = 0.01426384
Iteration 2317, loss = 0.01425546
Iteration 2318, loss = 0.01424898
Iteration 2319, loss = 0.01424165
Iteration 2320, loss = 0.01423505
Iteration 2321, loss = 0.01422800
Iteration 2322, loss = 0.01422007
Iteration 2323, loss = 0.01421204
Iteration 2324, loss = 0.01420555
Iteration 2325, loss = 0.01419733
Iteration 2326, loss = 0.01418948
Iteration 2327, loss = 0.01418164
Iteration 2328, loss = 0.01417278
Iteration 2329, loss = 0.01416343
Iteration 2330, loss = 0.01415634
Iteration 2331, loss = 0.01414875
Iteration 2332, loss = 0.01413937
Iteration 2333, loss = 0.01413128
Iteration 2334, loss = 0.01412593
Iteration 2335, loss = 0.01411623
Iteration 2336, loss = 0.01411061
Iteration 2337, loss = 0.01410016
Iteration 2338, loss = 0.01409221
Iteration 2339, loss = 0.01408465
Iteration 2340, loss = 0.01407675
Iteration 2341, loss = 0.01406924
Iteration 2342, loss = 0.01406010
Iteration 2343, loss = 0.01405325
Iteration 2344, loss = 0.01404518
Iteration 2345, loss = 0.01403705
Iteration 2346, loss = 0.01403013
Iteration 2347, loss = 0.01402330
Iteration 2348, loss = 0.01401365
Iteration 2349, loss = 0.01400599
Iteration 2350, loss = 0.01399807
Iteration 2351, loss = 0.01399032
Iteration 2352, loss = 0.01398272
Iteration 2353, loss = 0.01397493
Iteration 2354, loss = 0.01397053
Iteration 2355, loss = 0.01396030
Iteration 2356, loss = 0.01395356
Iteration 2357, loss = 0.01394493
Iteration 2358, loss = 0.01393747
Iteration 2359, loss = 0.01393025
Iteration 2360, loss = 0.01392280
Iteration 2361, loss = 0.01391569
Iteration 2362, loss = 0.01390794
Iteration 2363, loss = 0.01390040
Iteration 2364, loss = 0.01389309
Iteration 2365, loss = 0.01388590
Iteration 2366, loss = 0.01387996
Iteration 2367, loss = 0.01387198
Iteration 2368, loss = 0.01386365
Iteration 2369, loss = 0.01385541
Iteration 2370, loss = 0.01384847
Iteration 2371, loss = 0.01384151
Iteration 2372, loss = 0.01383465
Iteration 2373, loss = 0.01382530
Iteration 2374, loss = 0.01381798
Iteration 2375, loss = 0.01381057
Iteration 2376, loss = 0.01380254
Iteration 2377, loss = 0.01379458
Iteration 2378, loss = 0.01378764
Iteration 2379, loss = 0.01378018
Iteration 2380, loss = 0.01377167
Iteration 2381, loss = 0.01376429
Iteration 2382, loss = 0.01375723
Iteration 2383, loss = 0.01375179
Iteration 2384, loss = 0.01374343
Iteration 2385, loss = 0.01373728
Iteration 2386, loss = 0.01373012
Iteration 2387, loss = 0.01372354
Iteration 2388, loss = 0.01371679
Iteration 2389, loss = 0.01371082
Iteration 2390, loss = 0.01370285
Iteration 2391, loss = 0.01369687
Iteration 2392, loss = 0.01368836
Iteration 2393, loss = 0.01368069
Iteration 2394, loss = 0.01367431
Iteration 2395, loss = 0.01366595
Iteration 2396, loss = 0.01365869
Iteration 2397, loss = 0.01365068
Iteration 2398, loss = 0.01364487
Iteration 2399, loss = 0.01363636
Iteration 2400, loss = 0.01362936
Iteration 2401, loss = 0.01362216
Iteration 2402, loss = 0.01361459
Iteration 2403, loss = 0.01360731
Iteration 2404, loss = 0.01359988
Iteration 2405, loss = 0.01359352
Iteration 2406, loss = 0.01358616
Iteration 2407, loss = 0.01357850
Iteration 2408, loss = 0.01357174
Iteration 2409, loss = 0.01356604
Iteration 2410, loss = 0.01355857
Iteration 2411, loss = 0.01355138
Iteration 2412, loss = 0.01354524
Iteration 2413, loss = 0.01353629
Iteration 2414, loss = 0.01352903
Iteration 2415, loss = 0.01352167
Iteration 2416, loss = 0.01351444
Iteration 2417, loss = 0.01350595
Iteration 2418, loss = 0.01350105
Iteration 2419, loss = 0.01349338
Iteration 2420, loss = 0.01348499
Iteration 2421, loss = 0.01347791
Iteration 2422, loss = 0.01347039
Iteration 2423, loss = 0.01346363
Iteration 2424, loss = 0.01345655
Iteration 2425, loss = 0.01345034
Iteration 2426, loss = 0.01344263
Iteration 2427, loss = 0.01343660
Iteration 2428, loss = 0.01343017
Iteration 2429, loss = 0.01342355
Iteration 2430, loss = 0.01341746
Iteration 2431, loss = 0.01341073
Iteration 2432, loss = 0.01340475
Iteration 2433, loss = 0.01340024
Iteration 2434, loss = 0.01339298
Iteration 2435, loss = 0.01338678
Iteration 2436, loss = 0.01338226
Iteration 2437, loss = 0.01337513
Iteration 2438, loss = 0.01337004
Iteration 2439, loss = 0.01336418
Iteration 2440, loss = 0.01335616
Iteration 2441, loss = 0.01335012
Iteration 2442, loss = 0.01334272
Iteration 2443, loss = 0.01333590
Iteration 2444, loss = 0.01332872
Iteration 2445, loss = 0.01332144
Iteration 2446, loss = 0.01331359
Iteration 2447, loss = 0.01330762
Iteration 2448, loss = 0.01329955
Iteration 2449, loss = 0.01329269
Iteration 2450, loss = 0.01328485
Iteration 2451, loss = 0.01327945
Iteration 2452, loss = 0.01327098
Iteration 2453, loss = 0.01326500
Iteration 2454, loss = 0.01325879
Iteration 2455, loss = 0.01325256
Iteration 2456, loss = 0.01324654
Iteration 2457, loss = 0.01323942
Iteration 2458, loss = 0.01323277
Iteration 2459, loss = 0.01322706
Iteration 2460, loss = 0.01321976
Iteration 2461, loss = 0.01321295
Iteration 2462, loss = 0.01320621
Iteration 2463, loss = 0.01320045
Iteration 2464, loss = 0.01319335
Iteration 2465, loss = 0.01318381
Iteration 2466, loss = 0.01317795
Iteration 2467, loss = 0.01316916
Iteration 2468, loss = 0.01316224
Iteration 2469, loss = 0.01315584
Iteration 2470, loss = 0.01314820
Iteration 2471, loss = 0.01314181
Iteration 2472, loss = 0.01313399
Iteration 2473, loss = 0.01312917
Iteration 2474, loss = 0.01312102
Iteration 2475, loss = 0.01311516
Iteration 2476, loss = 0.01310767
Iteration 2477, loss = 0.01310169
Iteration 2478, loss = 0.01309500
Iteration 2479, loss = 0.01308850
Iteration 2480, loss = 0.01308223
Iteration 2481, loss = 0.01307608
Iteration 2482, loss = 0.01307012
Iteration 2483, loss = 0.01306409
Iteration 2484, loss = 0.01305886
Iteration 2485, loss = 0.01305276
Iteration 2486, loss = 0.01304676
Iteration 2487, loss = 0.01304062
Iteration 2488, loss = 0.01303485
Iteration 2489, loss = 0.01302925
Iteration 2490, loss = 0.01302415
Iteration 2491, loss = 0.01301866
Iteration 2492, loss = 0.01301328
Iteration 2493, loss = 0.01300952
Iteration 2494, loss = 0.01300245
Iteration 2495, loss = 0.01299756
Iteration 2496, loss = 0.01299063
Iteration 2497, loss = 0.01298475
Iteration 2498, loss = 0.01298026
Iteration 2499, loss = 0.01297424
Iteration 2500, loss = 0.01296902
Iteration 2501, loss = 0.01296250
Iteration 2502, loss = 0.01295606
Iteration 2503, loss = 0.01294908
Iteration 2504, loss = 0.01294278
Iteration 2505, loss = 0.01293594
Iteration 2506, loss = 0.01292962
Iteration 2507, loss = 0.01292359
Iteration 2508, loss = 0.01291630
Iteration 2509, loss = 0.01290888
Iteration 2510, loss = 0.01290261
Iteration 2511, loss = 0.01289663
Iteration 2512, loss = 0.01289031
Iteration 2513, loss = 0.01288429
Iteration 2514, loss = 0.01287839
Iteration 2515, loss = 0.01287271
Iteration 2516, loss = 0.01286659
Iteration 2517, loss = 0.01286091
Iteration 2518, loss = 0.01285632
Iteration 2519, loss = 0.01284862
Iteration 2520, loss = 0.01284289
Iteration 2521, loss = 0.01283565
Iteration 2522, loss = 0.01282904
Iteration 2523, loss = 0.01282313
Iteration 2524, loss = 0.01281596
Iteration 2525, loss = 0.01280907
Iteration 2526, loss = 0.01280244
Iteration 2527, loss = 0.01279492
Iteration 2528, loss = 0.01278938
Iteration 2529, loss = 0.01278284
Iteration 2530, loss = 0.01277638
Iteration 2531, loss = 0.01276928
Iteration 2532, loss = 0.01276344
Iteration 2533, loss = 0.01275675
Iteration 2534, loss = 0.01275071
Iteration 2535, loss = 0.01274510
Iteration 2536, loss = 0.01273901
Iteration 2537, loss = 0.01273162
Iteration 2538, loss = 0.01272673
Iteration 2539, loss = 0.01271886
Iteration 2540, loss = 0.01271241
Iteration 2541, loss = 0.01270563
Iteration 2542, loss = 0.01270065
Iteration 2543, loss = 0.01269311
Iteration 2544, loss = 0.01268749
Iteration 2545, loss = 0.01268138
Iteration 2546, loss = 0.01267417
Iteration 2547, loss = 0.01266728
Iteration 2548, loss = 0.01266007
Iteration 2549, loss = 0.01265220
Iteration 2550, loss = 0.01264502
Iteration 2551, loss = 0.01263827
Iteration 2552, loss = 0.01262999
Iteration 2553, loss = 0.01262398
Iteration 2554, loss = 0.01261766
Iteration 2555, loss = 0.01261122
Iteration 2556, loss = 0.01260414
Iteration 2557, loss = 0.01259762
Iteration 2558, loss = 0.01259317
Iteration 2559, loss = 0.01258571
Iteration 2560, loss = 0.01257958
Iteration 2561, loss = 0.01257594
Iteration 2562, loss = 0.01256760
Iteration 2563, loss = 0.01256083
Iteration 2564, loss = 0.01255450
Iteration 2565, loss = 0.01254736
Iteration 2566, loss = 0.01254208
Iteration 2567, loss = 0.01253483
Iteration 2568, loss = 0.01252818
Iteration 2569, loss = 0.01252118
Iteration 2570, loss = 0.01251469
Iteration 2571, loss = 0.01250980
Iteration 2572, loss = 0.01250137
Iteration 2573, loss = 0.01249504
Iteration 2574, loss = 0.01248992
Iteration 2575, loss = 0.01248249
Iteration 2576, loss = 0.01247682
Iteration 2577, loss = 0.01246940
Iteration 2578, loss = 0.01246301
Iteration 2579, loss = 0.01245546
Iteration 2580, loss = 0.01244965
Iteration 2581, loss = 0.01244358
Iteration 2582, loss = 0.01243639
Iteration 2583, loss = 0.01243190
Iteration 2584, loss = 0.01242459
Iteration 2585, loss = 0.01241838
Iteration 2586, loss = 0.01241219
Iteration 2587, loss = 0.01240676
Iteration 2588, loss = 0.01239974
Iteration 2589, loss = 0.01239435
Iteration 2590, loss = 0.01238800
Iteration 2591, loss = 0.01238231
Iteration 2592, loss = 0.01237605
Iteration 2593, loss = 0.01237221
Iteration 2594, loss = 0.01236538
Iteration 2595, loss = 0.01235987
Iteration 2596, loss = 0.01235581
Iteration 2597, loss = 0.01234911
Iteration 2598, loss = 0.01234336
Iteration 2599, loss = 0.01233766
Iteration 2600, loss = 0.01233175
Iteration 2601, loss = 0.01232581
Iteration 2602, loss = 0.01232163
Iteration 2603, loss = 0.01231346
Iteration 2604, loss = 0.01230777
Iteration 2605, loss = 0.01230152
Iteration 2606, loss = 0.01229549
Iteration 2607, loss = 0.01229112
Iteration 2608, loss = 0.01228453
Iteration 2609, loss = 0.01227958
Iteration 2610, loss = 0.01227243
Iteration 2611, loss = 0.01226716
Iteration 2612, loss = 0.01226126
Iteration 2613, loss = 0.01225532
Iteration 2614, loss = 0.01224957
Iteration 2615, loss = 0.01224281
Iteration 2616, loss = 0.01223759
Iteration 2617, loss = 0.01223184
Iteration 2618, loss = 0.01222704
Iteration 2619, loss = 0.01222046
Iteration 2620, loss = 0.01221484
Iteration 2621, loss = 0.01220965
Iteration 2622, loss = 0.01220422
Iteration 2623, loss = 0.01219999
Iteration 2624, loss = 0.01219615
Iteration 2625, loss = 0.01219003
Iteration 2626, loss = 0.01218567
Iteration 2627, loss = 0.01218134
Iteration 2628, loss = 0.01217639
Iteration 2629, loss = 0.01217114
Iteration 2630, loss = 0.01216571
Iteration 2631, loss = 0.01216041
Iteration 2632, loss = 0.01215473
Iteration 2633, loss = 0.01214951
Iteration 2634, loss = 0.01214399
Iteration 2635, loss = 0.01213846
Iteration 2636, loss = 0.01213207
Iteration 2637, loss = 0.01212696
Iteration 2638, loss = 0.01212080
Iteration 2639, loss = 0.01211381
Iteration 2640, loss = 0.01210810
Iteration 2641, loss = 0.01210297
Iteration 2642, loss = 0.01209623
Iteration 2643, loss = 0.01209065
Iteration 2644, loss = 0.01208574
Iteration 2645, loss = 0.01207919
Iteration 2646, loss = 0.01207476
Iteration 2647, loss = 0.01206904
Iteration 2648, loss = 0.01206280
Iteration 2649, loss = 0.01205775
Iteration 2650, loss = 0.01205266
Iteration 2651, loss = 0.01204692
Iteration 2652, loss = 0.01204097
Iteration 2653, loss = 0.01203633
Iteration 2654, loss = 0.01203033
Iteration 2655, loss = 0.01202494
Iteration 2656, loss = 0.01201965
Iteration 2657, loss = 0.01201463
Iteration 2658, loss = 0.01200870
Iteration 2659, loss = 0.01200212
Iteration 2660, loss = 0.01199503
Iteration 2661, loss = 0.01198866
Iteration 2662, loss = 0.01198232
Iteration 2663, loss = 0.01197687
Iteration 2664, loss = 0.01197005
Iteration 2665, loss = 0.01196643
Iteration 2666, loss = 0.01195835
Iteration 2667, loss = 0.01195249
Iteration 2668, loss = 0.01194695
Iteration 2669, loss = 0.01194125
Iteration 2670, loss = 0.01193564
Iteration 2671, loss = 0.01193104
Iteration 2672, loss = 0.01192281
Iteration 2673, loss = 0.01191632
Iteration 2674, loss = 0.01191054
Iteration 2675, loss = 0.01190359
Iteration 2676, loss = 0.01189950
Iteration 2677, loss = 0.01189152
Iteration 2678, loss = 0.01188611
Iteration 2679, loss = 0.01188029
Iteration 2680, loss = 0.01187430
Iteration 2681, loss = 0.01187074
Iteration 2682, loss = 0.01186265
Iteration 2683, loss = 0.01185712
Iteration 2684, loss = 0.01185119
Iteration 2685, loss = 0.01184487
Iteration 2686, loss = 0.01183892
Iteration 2687, loss = 0.01183212
Iteration 2688, loss = 0.01182863
Iteration 2689, loss = 0.01182125
Iteration 2690, loss = 0.01181700
Iteration 2691, loss = 0.01181016
Iteration 2692, loss = 0.01180467
Iteration 2693, loss = 0.01179852
Iteration 2694, loss = 0.01179319
Iteration 2695, loss = 0.01178798
Iteration 2696, loss = 0.01178200
Iteration 2697, loss = 0.01177639
Iteration 2698, loss = 0.01177005
Iteration 2699, loss = 0.01176477
Iteration 2700, loss = 0.01175819
Iteration 2701, loss = 0.01175490
Iteration 2702, loss = 0.01174766
Iteration 2703, loss = 0.01174521
Iteration 2704, loss = 0.01173965
Iteration 2705, loss = 0.01173459
Iteration 2706, loss = 0.01172942
Iteration 2707, loss = 0.01172410
Iteration 2708, loss = 0.01171976
Iteration 2709, loss = 0.01171362
Iteration 2710, loss = 0.01170826
Iteration 2711, loss = 0.01170252
Iteration 2712, loss = 0.01169795
Iteration 2713, loss = 0.01169320
Iteration 2714, loss = 0.01168733
Iteration 2715, loss = 0.01168152
Iteration 2716, loss = 0.01167757
Iteration 2717, loss = 0.01167110
Iteration 2718, loss = 0.01166568
Iteration 2719, loss = 0.01166121
Iteration 2720, loss = 0.01165499
Iteration 2721, loss = 0.01164979
Iteration 2722, loss = 0.01164460
Iteration 2723, loss = 0.01163941
Iteration 2724, loss = 0.01163367
Iteration 2725, loss = 0.01162867
Iteration 2726, loss = 0.01162292
Iteration 2727, loss = 0.01161791
Iteration 2728, loss = 0.01161220
Iteration 2729, loss = 0.01160633
Iteration 2730, loss = 0.01160048
Iteration 2731, loss = 0.01159392
Iteration 2732, loss = 0.01158935
Iteration 2733, loss = 0.01158292
Iteration 2734, loss = 0.01157722
Iteration 2735, loss = 0.01157062
Iteration 2736, loss = 0.01156556
Iteration 2737, loss = 0.01155971
Iteration 2738, loss = 0.01155426
Iteration 2739, loss = 0.01154818
Iteration 2740, loss = 0.01154289
Iteration 2741, loss = 0.01153802
Iteration 2742, loss = 0.01153227
Iteration 2743, loss = 0.01152777
Iteration 2744, loss = 0.01152188
Iteration 2745, loss = 0.01151625
Iteration 2746, loss = 0.01151233
Iteration 2747, loss = 0.01150590
Iteration 2748, loss = 0.01149918
Iteration 2749, loss = 0.01149275
Iteration 2750, loss = 0.01148848
Iteration 2751, loss = 0.01148299
Iteration 2752, loss = 0.01147760
Iteration 2753, loss = 0.01147211
Iteration 2754, loss = 0.01146668
Iteration 2755, loss = 0.01146146
Iteration 2756, loss = 0.01145539
Iteration 2757, loss = 0.01145079
Iteration 2758, loss = 0.01144375
Iteration 2759, loss = 0.01143827
Iteration 2760, loss = 0.01143309
Iteration 2761, loss = 0.01142709
Iteration 2762, loss = 0.01142121
Iteration 2763, loss = 0.01141572
Iteration 2764, loss = 0.01141046
Iteration 2765, loss = 0.01140494
Iteration 2766, loss = 0.01139960
Iteration 2767, loss = 0.01139543
Iteration 2768, loss = 0.01138904
Iteration 2769, loss = 0.01138376
Iteration 2770, loss = 0.01138067
Iteration 2771, loss = 0.01137448
Iteration 2772, loss = 0.01136949
Iteration 2773, loss = 0.01136348
Iteration 2774, loss = 0.01135832
Iteration 2775, loss = 0.01135364
Iteration 2776, loss = 0.01134840
Iteration 2777, loss = 0.01134264
Iteration 2778, loss = 0.01133663
Iteration 2779, loss = 0.01133249
Iteration 2780, loss = 0.01132562
Iteration 2781, loss = 0.01132336
Iteration 2782, loss = 0.01131586
Iteration 2783, loss = 0.01130931
Iteration 2784, loss = 0.01130483
Iteration 2785, loss = 0.01129937
Iteration 2786, loss = 0.01129432
Iteration 2787, loss = 0.01128853
Iteration 2788, loss = 0.01128338
Iteration 2789, loss = 0.01127873
Iteration 2790, loss = 0.01127723
Iteration 2791, loss = 0.01127015
Iteration 2792, loss = 0.01126543
Iteration 2793, loss = 0.01126033
Iteration 2794, loss = 0.01125545
Iteration 2795, loss = 0.01125115
Iteration 2796, loss = 0.01124600
Iteration 2797, loss = 0.01124155
Iteration 2798, loss = 0.01123634
Iteration 2799, loss = 0.01123146
Iteration 2800, loss = 0.01122580
Iteration 2801, loss = 0.01122087
Iteration 2802, loss = 0.01121578
Iteration 2803, loss = 0.01121063
Iteration 2804, loss = 0.01120705
Iteration 2805, loss = 0.01120186
Iteration 2806, loss = 0.01119642
Iteration 2807, loss = 0.01119114
Iteration 2808, loss = 0.01118580
Iteration 2809, loss = 0.01118048
Iteration 2810, loss = 0.01117537
Iteration 2811, loss = 0.01117004
Iteration 2812, loss = 0.01116586
Iteration 2813, loss = 0.01116033
Iteration 2814, loss = 0.01115624
Iteration 2815, loss = 0.01115036
Iteration 2816, loss = 0.01114494
Iteration 2817, loss = 0.01113878
Iteration 2818, loss = 0.01113328
Iteration 2819, loss = 0.01112778
Iteration 2820, loss = 0.01112209
Iteration 2821, loss = 0.01111712
Iteration 2822, loss = 0.01111101
Iteration 2823, loss = 0.01110553
Iteration 2824, loss = 0.01110036
Iteration 2825, loss = 0.01109485
Iteration 2826, loss = 0.01109024
Iteration 2827, loss = 0.01108448
Iteration 2828, loss = 0.01107882
Iteration 2829, loss = 0.01107445
Iteration 2830, loss = 0.01106900
Iteration 2831, loss = 0.01106424
Iteration 2832, loss = 0.01105858
Iteration 2833, loss = 0.01105298
Iteration 2834, loss = 0.01104740
Iteration 2835, loss = 0.01104185
Iteration 2836, loss = 0.01103739
Iteration 2837, loss = 0.01103244
Iteration 2838, loss = 0.01102668
Iteration 2839, loss = 0.01102087
Iteration 2840, loss = 0.01101561
Iteration 2841, loss = 0.01100979
Iteration 2842, loss = 0.01100407
Iteration 2843, loss = 0.01099809
Iteration 2844, loss = 0.01099140
Iteration 2845, loss = 0.01098580
Iteration 2846, loss = 0.01097873
Iteration 2847, loss = 0.01097360
Iteration 2848, loss = 0.01096625
Iteration 2849, loss = 0.01096201
Iteration 2850, loss = 0.01095771
Iteration 2851, loss = 0.01095069
Iteration 2852, loss = 0.01094482
Iteration 2853, loss = 0.01094001
Iteration 2854, loss = 0.01093465
Iteration 2855, loss = 0.01093076
Iteration 2856, loss = 0.01092430
Iteration 2857, loss = 0.01091856
Iteration 2858, loss = 0.01091471
Iteration 2859, loss = 0.01090862
Iteration 2860, loss = 0.01090286
Iteration 2861, loss = 0.01089768
Iteration 2862, loss = 0.01089254
Iteration 2863, loss = 0.01088688
Iteration 2864, loss = 0.01088178
Iteration 2865, loss = 0.01087658
Iteration 2866, loss = 0.01087187
Iteration 2867, loss = 0.01086614
Iteration 2868, loss = 0.01086056
Iteration 2869, loss = 0.01085502
Iteration 2870, loss = 0.01084911
Iteration 2871, loss = 0.01084402
Iteration 2872, loss = 0.01083836
Iteration 2873, loss = 0.01083353
Iteration 2874, loss = 0.01082829
Iteration 2875, loss = 0.01082309
Iteration 2876, loss = 0.01081855
Iteration 2877, loss = 0.01081377
Iteration 2878, loss = 0.01080851
Iteration 2879, loss = 0.01080398
Iteration 2880, loss = 0.01080058
Iteration 2881, loss = 0.01079389
Iteration 2882, loss = 0.01078941
Iteration 2883, loss = 0.01078476
Iteration 2884, loss = 0.01077976
Iteration 2885, loss = 0.01077474
Iteration 2886, loss = 0.01077044
Iteration 2887, loss = 0.01076523
Iteration 2888, loss = 0.01076081
Iteration 2889, loss = 0.01075611
Iteration 2890, loss = 0.01075190
Iteration 2891, loss = 0.01074792
Iteration 2892, loss = 0.01074319
Iteration 2893, loss = 0.01073697
Iteration 2894, loss = 0.01073196
Iteration 2895, loss = 0.01072755
Iteration 2896, loss = 0.01072208
Iteration 2897, loss = 0.01071814
Iteration 2898, loss = 0.01071169
Iteration 2899, loss = 0.01070664
Iteration 2900, loss = 0.01070120
Iteration 2901, loss = 0.01069627
Iteration 2902, loss = 0.01069080
Iteration 2903, loss = 0.01068588
Iteration 2904, loss = 0.01068338
Iteration 2905, loss = 0.01067613
Iteration 2906, loss = 0.01067073
Iteration 2907, loss = 0.01066561
Iteration 2908, loss = 0.01066123
Iteration 2909, loss = 0.01065592
Iteration 2910, loss = 0.01065034
Iteration 2911, loss = 0.01064647
Iteration 2912, loss = 0.01064056
Iteration 2913, loss = 0.01063590
Iteration 2914, loss = 0.01063016
Iteration 2915, loss = 0.01062533
Iteration 2916, loss = 0.01062025
Iteration 2917, loss = 0.01061663
Iteration 2918, loss = 0.01061085
Iteration 2919, loss = 0.01060609
Iteration 2920, loss = 0.01060147
Iteration 2921, loss = 0.01059673
Iteration 2922, loss = 0.01059202
Iteration 2923, loss = 0.01058742
Iteration 2924, loss = 0.01058313
Iteration 2925, loss = 0.01057794
Iteration 2926, loss = 0.01057321
Iteration 2927, loss = 0.01056917
Iteration 2928, loss = 0.01056436
Iteration 2929, loss = 0.01055899
Iteration 2930, loss = 0.01055429
Iteration 2931, loss = 0.01054931
Iteration 2932, loss = 0.01054473
Iteration 2933, loss = 0.01054077
Iteration 2934, loss = 0.01053678
Iteration 2935, loss = 0.01053091
Iteration 2936, loss = 0.01052767
Iteration 2937, loss = 0.01052192
Iteration 2938, loss = 0.01051731
Iteration 2939, loss = 0.01051247
Iteration 2940, loss = 0.01050863
Iteration 2941, loss = 0.01050269
Iteration 2942, loss = 0.01049966
Iteration 2943, loss = 0.01049313
Iteration 2944, loss = 0.01048944
Iteration 2945, loss = 0.01048351
Iteration 2946, loss = 0.01047773
Iteration 2947, loss = 0.01047425
Iteration 2948, loss = 0.01046788
Iteration 2949, loss = 0.01046278
Iteration 2950, loss = 0.01045732
Iteration 2951, loss = 0.01045191
Iteration 2952, loss = 0.01044788
Iteration 2953, loss = 0.01044292
Iteration 2954, loss = 0.01043811
Iteration 2955, loss = 0.01043355
Iteration 2956, loss = 0.01042864
Iteration 2957, loss = 0.01042459
Iteration 2958, loss = 0.01041971
Iteration 2959, loss = 0.01041539
Iteration 2960, loss = 0.01041127
Iteration 2961, loss = 0.01040673
Iteration 2962, loss = 0.01040247
Iteration 2963, loss = 0.01039774
Iteration 2964, loss = 0.01039310
Iteration 2965, loss = 0.01038842
Iteration 2966, loss = 0.01038413
Iteration 2967, loss = 0.01037862
Iteration 2968, loss = 0.01037377
Iteration 2969, loss = 0.01036904
Iteration 2970, loss = 0.01036413
Iteration 2971, loss = 0.01035916
Iteration 2972, loss = 0.01035412
Iteration 2973, loss = 0.01034923
Iteration 2974, loss = 0.01034502
Iteration 2975, loss = 0.01033999
Iteration 2976, loss = 0.01033582
Iteration 2977, loss = 0.01032990
Iteration 2978, loss = 0.01032572
Iteration 2979, loss = 0.01032056
Iteration 2980, loss = 0.01031588
Iteration 2981, loss = 0.01031161
Iteration 2982, loss = 0.01030634
Iteration 2983, loss = 0.01030189
Iteration 2984, loss = 0.01029664
Iteration 2985, loss = 0.01029158
Iteration 2986, loss = 0.01028677
Iteration 2987, loss = 0.01028363
Iteration 2988, loss = 0.01027871
Iteration 2989, loss = 0.01027487
Iteration 2990, loss = 0.01027004
Iteration 2991, loss = 0.01026550
Iteration 2992, loss = 0.01026087
Iteration 2993, loss = 0.01025650
Iteration 2994, loss = 0.01025174
Iteration 2995, loss = 0.01024715
Iteration 2996, loss = 0.01024407
Iteration 2997, loss = 0.01023913
Iteration 2998, loss = 0.01023547
Iteration 2999, loss = 0.01023026
Iteration 3000, loss = 0.01022668
Iteration 3001, loss = 0.01022229
Iteration 3002, loss = 0.01021785
Iteration 3003, loss = 0.01021308
Iteration 3004, loss = 0.01020869
Iteration 3005, loss = 0.01020435
Iteration 3006, loss = 0.01019978
Iteration 3007, loss = 0.01019638
Iteration 3008, loss = 0.01019168
Iteration 3009, loss = 0.01018768
Iteration 3010, loss = 0.01018427
Iteration 3011, loss = 0.01017878
Iteration 3012, loss = 0.01017425
Iteration 3013, loss = 0.01016945
Iteration 3014, loss = 0.01016551
Iteration 3015, loss = 0.01016117
Iteration 3016, loss = 0.01015648
Iteration 3017, loss = 0.01015198
Iteration 3018, loss = 0.01014678
Iteration 3019, loss = 0.01014123
Iteration 3020, loss = 0.01013631
Iteration 3021, loss = 0.01013335
Iteration 3022, loss = 0.01012737
Iteration 3023, loss = 0.01012263
Iteration 3024, loss = 0.01011804
Iteration 3025, loss = 0.01011348
Iteration 3026, loss = 0.01010941
Iteration 3027, loss = 0.01010544
Iteration 3028, loss = 0.01010227
Iteration 3029, loss = 0.01009732
Iteration 3030, loss = 0.01009336
Iteration 3031, loss = 0.01008849
Iteration 3032, loss = 0.01008431
Iteration 3033, loss = 0.01008129
Iteration 3034, loss = 0.01007628
Iteration 3035, loss = 0.01007202
Iteration 3036, loss = 0.01006842
Iteration 3037, loss = 0.01006392
Iteration 3038, loss = 0.01005945
Iteration 3039, loss = 0.01005524
Iteration 3040, loss = 0.01005064
Iteration 3041, loss = 0.01004636
Iteration 3042, loss = 0.01004271
Iteration 3043, loss = 0.01003877
Iteration 3044, loss = 0.01003440
Iteration 3045, loss = 0.01003148
Iteration 3046, loss = 0.01002680
Iteration 3047, loss = 0.01002305
Iteration 3048, loss = 0.01001832
Iteration 3049, loss = 0.01001469
Iteration 3050, loss = 0.01000930
Iteration 3051, loss = 0.01000383
Iteration 3052, loss = 0.00999897
Iteration 3053, loss = 0.00999370
Iteration 3054, loss = 0.00998801
Iteration 3055, loss = 0.00998557
Iteration 3056, loss = 0.00997946
Iteration 3057, loss = 0.00997662
Iteration 3058, loss = 0.00997051
Iteration 3059, loss = 0.00996594
Iteration 3060, loss = 0.00996309
Iteration 3061, loss = 0.00995809
Iteration 3062, loss = 0.00995417
Iteration 3063, loss = 0.00995015
Iteration 3064, loss = 0.00994588
Iteration 3065, loss = 0.00994141
Iteration 3066, loss = 0.00993734
Iteration 3067, loss = 0.00993230
Iteration 3068, loss = 0.00992781
Iteration 3069, loss = 0.00992461
Iteration 3070, loss = 0.00991895
Iteration 3071, loss = 0.00991477
Iteration 3072, loss = 0.00990995
Iteration 3073, loss = 0.00990472
Iteration 3074, loss = 0.00990054
Iteration 3075, loss = 0.00989537
Iteration 3076, loss = 0.00989121
Iteration 3077, loss = 0.00988678
Iteration 3078, loss = 0.00988231
Iteration 3079, loss = 0.00987801
Iteration 3080, loss = 0.00987381
Iteration 3081, loss = 0.00986927
Iteration 3082, loss = 0.00986508
Iteration 3083, loss = 0.00986086
Iteration 3084, loss = 0.00985670
Iteration 3085, loss = 0.00985240
Iteration 3086, loss = 0.00984877
Iteration 3087, loss = 0.00984416
Iteration 3088, loss = 0.00984070
Iteration 3089, loss = 0.00983730
Iteration 3090, loss = 0.00983264
Iteration 3091, loss = 0.00982851
Iteration 3092, loss = 0.00982459
Iteration 3093, loss = 0.00982082
Iteration 3094, loss = 0.00981693
Iteration 3095, loss = 0.00981269
Iteration 3096, loss = 0.00980952
Iteration 3097, loss = 0.00980468
Iteration 3098, loss = 0.00980042
Iteration 3099, loss = 0.00979576
Iteration 3100, loss = 0.00979125
Iteration 3101, loss = 0.00978712
Iteration 3102, loss = 0.00978301
Iteration 3103, loss = 0.00977903
Iteration 3104, loss = 0.00977481
Iteration 3105, loss = 0.00977046
Iteration 3106, loss = 0.00976633
Iteration 3107, loss = 0.00976208
Iteration 3108, loss = 0.00975812
Iteration 3109, loss = 0.00975381
Iteration 3110, loss = 0.00974945
Iteration 3111, loss = 0.00974583
Iteration 3112, loss = 0.00974150
Iteration 3113, loss = 0.00973763
Iteration 3114, loss = 0.00973409
Iteration 3115, loss = 0.00972919
Iteration 3116, loss = 0.00972549
Iteration 3117, loss = 0.00972157
Iteration 3118, loss = 0.00971672
Iteration 3119, loss = 0.00971276
Iteration 3120, loss = 0.00970898
Iteration 3121, loss = 0.00970482
Iteration 3122, loss = 0.00970087
Iteration 3123, loss = 0.00969702
Iteration 3124, loss = 0.00969349
Iteration 3125, loss = 0.00968875
Iteration 3126, loss = 0.00968516
Iteration 3127, loss = 0.00968080
Iteration 3128, loss = 0.00967735
Iteration 3129, loss = 0.00967292
Iteration 3130, loss = 0.00966919
Iteration 3131, loss = 0.00966535
Iteration 3132, loss = 0.00966027
Iteration 3133, loss = 0.00965673
Iteration 3134, loss = 0.00965159
Iteration 3135, loss = 0.00964844
Iteration 3136, loss = 0.00964323
Iteration 3137, loss = 0.00963925
Iteration 3138, loss = 0.00963528
Iteration 3139, loss = 0.00963136
Iteration 3140, loss = 0.00962749
Iteration 3141, loss = 0.00962408
Iteration 3142, loss = 0.00962020
Iteration 3143, loss = 0.00961645
Iteration 3144, loss = 0.00961341
Iteration 3145, loss = 0.00960968
Iteration 3146, loss = 0.00960608
Iteration 3147, loss = 0.00960264
Iteration 3148, loss = 0.00959893
Iteration 3149, loss = 0.00959439
Iteration 3150, loss = 0.00959093
Iteration 3151, loss = 0.00958718
Iteration 3152, loss = 0.00958388
Iteration 3153, loss = 0.00958010
Iteration 3154, loss = 0.00957715
Iteration 3155, loss = 0.00957340
Iteration 3156, loss = 0.00957036
Iteration 3157, loss = 0.00956514
Iteration 3158, loss = 0.00956003
Iteration 3159, loss = 0.00955636
Iteration 3160, loss = 0.00955145
Iteration 3161, loss = 0.00954711
Iteration 3162, loss = 0.00954286
Iteration 3163, loss = 0.00953901
Iteration 3164, loss = 0.00953487
Iteration 3165, loss = 0.00953085
Iteration 3166, loss = 0.00952626
Iteration 3167, loss = 0.00952238
Iteration 3168, loss = 0.00951689
Iteration 3169, loss = 0.00951238
Iteration 3170, loss = 0.00950788
Iteration 3171, loss = 0.00950402
Iteration 3172, loss = 0.00949892
Iteration 3173, loss = 0.00949493
Iteration 3174, loss = 0.00949072
Iteration 3175, loss = 0.00948648
Iteration 3176, loss = 0.00948247
Iteration 3177, loss = 0.00947840
Iteration 3178, loss = 0.00947479
Iteration 3179, loss = 0.00947149
Iteration 3180, loss = 0.00946833
Iteration 3181, loss = 0.00946340
Iteration 3182, loss = 0.00945969
Iteration 3183, loss = 0.00945497
Iteration 3184, loss = 0.00945225
Iteration 3185, loss = 0.00944767
Iteration 3186, loss = 0.00944282
Iteration 3187, loss = 0.00943852
Iteration 3188, loss = 0.00943498
Iteration 3189, loss = 0.00943072
Iteration 3190, loss = 0.00942691
Iteration 3191, loss = 0.00942283
Iteration 3192, loss = 0.00941885
Iteration 3193, loss = 0.00941431
Iteration 3194, loss = 0.00941045
Iteration 3195, loss = 0.00940628
Iteration 3196, loss = 0.00940193
Iteration 3197, loss = 0.00939890
Iteration 3198, loss = 0.00939419
Iteration 3199, loss = 0.00939013
Iteration 3200, loss = 0.00938689
Iteration 3201, loss = 0.00938247
Iteration 3202, loss = 0.00937915
Iteration 3203, loss = 0.00937500
Iteration 3204, loss = 0.00937212
Iteration 3205, loss = 0.00936770
Iteration 3206, loss = 0.00936322
Iteration 3207, loss = 0.00935900
Iteration 3208, loss = 0.00935445
Iteration 3209, loss = 0.00935059
Iteration 3210, loss = 0.00934537
Iteration 3211, loss = 0.00934158
Iteration 3212, loss = 0.00933692
Iteration 3213, loss = 0.00933336
Iteration 3214, loss = 0.00932866
Iteration 3215, loss = 0.00932452
Iteration 3216, loss = 0.00932038
Iteration 3217, loss = 0.00931692
Iteration 3218, loss = 0.00931271
Iteration 3219, loss = 0.00930848
Iteration 3220, loss = 0.00930470
Iteration 3221, loss = 0.00930124
Iteration 3222, loss = 0.00929773
Iteration 3223, loss = 0.00929428
Iteration 3224, loss = 0.00929094
Iteration 3225, loss = 0.00928717
Iteration 3226, loss = 0.00928363
Iteration 3227, loss = 0.00928021
Iteration 3228, loss = 0.00927630
Iteration 3229, loss = 0.00927387
Iteration 3230, loss = 0.00926997
Iteration 3231, loss = 0.00926626
Iteration 3232, loss = 0.00926264
Iteration 3233, loss = 0.00926007
Iteration 3234, loss = 0.00925546
Iteration 3235, loss = 0.00925209
Iteration 3236, loss = 0.00924792
Iteration 3237, loss = 0.00924440
Iteration 3238, loss = 0.00924099
Iteration 3239, loss = 0.00923737
Iteration 3240, loss = 0.00923408
Iteration 3241, loss = 0.00923069
Iteration 3242, loss = 0.00922793
Iteration 3243, loss = 0.00922511
Iteration 3244, loss = 0.00922165
Iteration 3245, loss = 0.00921726
Iteration 3246, loss = 0.00921333
Iteration 3247, loss = 0.00920909
Iteration 3248, loss = 0.00920575
Iteration 3249, loss = 0.00920136
Iteration 3250, loss = 0.00919670
Iteration 3251, loss = 0.00919355
Iteration 3252, loss = 0.00918773
Iteration 3253, loss = 0.00918305
Iteration 3254, loss = 0.00917938
Iteration 3255, loss = 0.00917405
Iteration 3256, loss = 0.00917062
Iteration 3257, loss = 0.00916799
Iteration 3258, loss = 0.00916217
Iteration 3259, loss = 0.00915882
Iteration 3260, loss = 0.00915493
Iteration 3261, loss = 0.00915127
Iteration 3262, loss = 0.00914742
Iteration 3263, loss = 0.00914369
Iteration 3264, loss = 0.00914002
Iteration 3265, loss = 0.00913635
Iteration 3266, loss = 0.00913250
Iteration 3267, loss = 0.00912896
Iteration 3268, loss = 0.00912548
Iteration 3269, loss = 0.00912153
Iteration 3270, loss = 0.00911848
Iteration 3271, loss = 0.00911494
Iteration 3272, loss = 0.00911095
Iteration 3273, loss = 0.00910773
Iteration 3274, loss = 0.00910404
Iteration 3275, loss = 0.00910007
Iteration 3276, loss = 0.00909660
Iteration 3277, loss = 0.00909311
Iteration 3278, loss = 0.00909005
Iteration 3279, loss = 0.00908635
Iteration 3280, loss = 0.00908284
Iteration 3281, loss = 0.00907897
Iteration 3282, loss = 0.00907538
Iteration 3283, loss = 0.00907115
Iteration 3284, loss = 0.00906744
Iteration 3285, loss = 0.00906321
Iteration 3286, loss = 0.00906070
Iteration 3287, loss = 0.00905610
Iteration 3288, loss = 0.00905189
Iteration 3289, loss = 0.00904831
Iteration 3290, loss = 0.00904455
Iteration 3291, loss = 0.00904150
Iteration 3292, loss = 0.00903809
Iteration 3293, loss = 0.00903294
Iteration 3294, loss = 0.00902905
Iteration 3295, loss = 0.00902500
Iteration 3296, loss = 0.00902181
Iteration 3297, loss = 0.00901896
Iteration 3298, loss = 0.00901360
Iteration 3299, loss = 0.00901034
Iteration 3300, loss = 0.00900579
Iteration 3301, loss = 0.00900099
Iteration 3302, loss = 0.00899720
Iteration 3303, loss = 0.00899261
Iteration 3304, loss = 0.00898865
Iteration 3305, loss = 0.00898417
Iteration 3306, loss = 0.00897960
Iteration 3307, loss = 0.00897613
Iteration 3308, loss = 0.00897189
Iteration 3309, loss = 0.00896853
Iteration 3310, loss = 0.00896474
Iteration 3311, loss = 0.00896067
Iteration 3312, loss = 0.00895814
Iteration 3313, loss = 0.00895332
Iteration 3314, loss = 0.00894978
Iteration 3315, loss = 0.00894578
Iteration 3316, loss = 0.00894188
Iteration 3317, loss = 0.00893798
Iteration 3318, loss = 0.00893475
Iteration 3319, loss = 0.00893077
Iteration 3320, loss = 0.00892740
Iteration 3321, loss = 0.00892420
Iteration 3322, loss = 0.00892205
Iteration 3323, loss = 0.00891776
Iteration 3324, loss = 0.00891413
Iteration 3325, loss = 0.00891094
Iteration 3326, loss = 0.00890724
Iteration 3327, loss = 0.00890378
Iteration 3328, loss = 0.00890075
Iteration 3329, loss = 0.00889696
Iteration 3330, loss = 0.00889318
Iteration 3331, loss = 0.00888970
Iteration 3332, loss = 0.00888624
Iteration 3333, loss = 0.00888299
Iteration 3334, loss = 0.00887907
Iteration 3335, loss = 0.00887511
Iteration 3336, loss = 0.00887111
Iteration 3337, loss = 0.00886721
Iteration 3338, loss = 0.00886354
Iteration 3339, loss = 0.00885964
Iteration 3340, loss = 0.00885610
Iteration 3341, loss = 0.00885261
Iteration 3342, loss = 0.00884896
Iteration 3343, loss = 0.00884556
Iteration 3344, loss = 0.00884224
Iteration 3345, loss = 0.00883882
Iteration 3346, loss = 0.00883506
Iteration 3347, loss = 0.00883159
Iteration 3348, loss = 0.00882794
Iteration 3349, loss = 0.00882503
Iteration 3350, loss = 0.00882194
Iteration 3351, loss = 0.00881846
Iteration 3352, loss = 0.00881425
Iteration 3353, loss = 0.00881089
Iteration 3354, loss = 0.00880742
Iteration 3355, loss = 0.00880356
Iteration 3356, loss = 0.00880001
Iteration 3357, loss = 0.00879688
Iteration 3358, loss = 0.00879311
Iteration 3359, loss = 0.00878961
Iteration 3360, loss = 0.00878650
Iteration 3361, loss = 0.00878279
Iteration 3362, loss = 0.00878023
Iteration 3363, loss = 0.00877497
Iteration 3364, loss = 0.00877093
Iteration 3365, loss = 0.00876664
Iteration 3366, loss = 0.00876401
Iteration 3367, loss = 0.00876088
Iteration 3368, loss = 0.00875592
Iteration 3369, loss = 0.00875211
Iteration 3370, loss = 0.00874880
Iteration 3371, loss = 0.00874514
Iteration 3372, loss = 0.00874123
Iteration 3373, loss = 0.00873819
Iteration 3374, loss = 0.00873417
Iteration 3375, loss = 0.00873048
Iteration 3376, loss = 0.00872693
Iteration 3377, loss = 0.00872246
Iteration 3378, loss = 0.00871859
Iteration 3379, loss = 0.00871565
Iteration 3380, loss = 0.00871105
Iteration 3381, loss = 0.00870744
Iteration 3382, loss = 0.00870404
Iteration 3383, loss = 0.00869989
Iteration 3384, loss = 0.00869557
Iteration 3385, loss = 0.00869283
Iteration 3386, loss = 0.00868886
Iteration 3387, loss = 0.00868496
Iteration 3388, loss = 0.00868161
Iteration 3389, loss = 0.00867757
Iteration 3390, loss = 0.00867429
Iteration 3391, loss = 0.00867061
Iteration 3392, loss = 0.00866740
Iteration 3393, loss = 0.00866422
Iteration 3394, loss = 0.00866005
Iteration 3395, loss = 0.00865664
Iteration 3396, loss = 0.00865357
Iteration 3397, loss = 0.00864985
Iteration 3398, loss = 0.00864669
Iteration 3399, loss = 0.00864271
Iteration 3400, loss = 0.00863971
Iteration 3401, loss = 0.00863616
Iteration 3402, loss = 0.00863315
Iteration 3403, loss = 0.00862907
Iteration 3404, loss = 0.00862550
Iteration 3405, loss = 0.00862217
Iteration 3406, loss = 0.00861921
Iteration 3407, loss = 0.00861581
Iteration 3408, loss = 0.00861229
Iteration 3409, loss = 0.00860891
Iteration 3410, loss = 0.00860650
Iteration 3411, loss = 0.00860259
Iteration 3412, loss = 0.00859922
Iteration 3413, loss = 0.00859622
Iteration 3414, loss = 0.00859278
Iteration 3415, loss = 0.00858943
Iteration 3416, loss = 0.00858670
Iteration 3417, loss = 0.00858279
Iteration 3418, loss = 0.00857974
Iteration 3419, loss = 0.00857604
Iteration 3420, loss = 0.00857274
Iteration 3421, loss = 0.00856942
Iteration 3422, loss = 0.00856625
Iteration 3423, loss = 0.00856342
Iteration 3424, loss = 0.00855953
Iteration 3425, loss = 0.00855646
Iteration 3426, loss = 0.00855326
Iteration 3427, loss = 0.00855060
Iteration 3428, loss = 0.00854668
Iteration 3429, loss = 0.00854392
Iteration 3430, loss = 0.00853981
Iteration 3431, loss = 0.00853639
Iteration 3432, loss = 0.00853329
Iteration 3433, loss = 0.00853044
Iteration 3434, loss = 0.00852607
Iteration 3435, loss = 0.00852253
Iteration 3436, loss = 0.00851876
Iteration 3437, loss = 0.00851568
Iteration 3438, loss = 0.00851179
Iteration 3439, loss = 0.00850849
Iteration 3440, loss = 0.00850505
Iteration 3441, loss = 0.00850168
Iteration 3442, loss = 0.00849868
Iteration 3443, loss = 0.00849537
Iteration 3444, loss = 0.00849236
Iteration 3445, loss = 0.00848842
Iteration 3446, loss = 0.00848484
Iteration 3447, loss = 0.00848170
Iteration 3448, loss = 0.00847822
Iteration 3449, loss = 0.00847482
Iteration 3450, loss = 0.00847144
Iteration 3451, loss = 0.00846991
Iteration 3452, loss = 0.00846494
Iteration 3453, loss = 0.00846123
Iteration 3454, loss = 0.00845842
Iteration 3455, loss = 0.00845468
Iteration 3456, loss = 0.00845159
Iteration 3457, loss = 0.00844809
Iteration 3458, loss = 0.00844434
Iteration 3459, loss = 0.00844090
Iteration 3460, loss = 0.00843770
Iteration 3461, loss = 0.00843444
Iteration 3462, loss = 0.00843146
Iteration 3463, loss = 0.00842796
Iteration 3464, loss = 0.00842465
Iteration 3465, loss = 0.00842209
Iteration 3466, loss = 0.00841846
Iteration 3467, loss = 0.00841524
Iteration 3468, loss = 0.00841217
Iteration 3469, loss = 0.00840890
Iteration 3470, loss = 0.00840624
Iteration 3471, loss = 0.00840260
Iteration 3472, loss = 0.00839994
Iteration 3473, loss = 0.00839572
Iteration 3474, loss = 0.00839246
Iteration 3475, loss = 0.00838845
Iteration 3476, loss = 0.00838498
Iteration 3477, loss = 0.00838172
Iteration 3478, loss = 0.00837821
Iteration 3479, loss = 0.00837430
Iteration 3480, loss = 0.00837119
Iteration 3481, loss = 0.00836761
Iteration 3482, loss = 0.00836476
Iteration 3483, loss = 0.00836106
Iteration 3484, loss = 0.00835805
Iteration 3485, loss = 0.00835483
Iteration 3486, loss = 0.00835168
Iteration 3487, loss = 0.00834875
Iteration 3488, loss = 0.00834518
Iteration 3489, loss = 0.00834297
Iteration 3490, loss = 0.00833927
Iteration 3491, loss = 0.00833568
Iteration 3492, loss = 0.00833281
Iteration 3493, loss = 0.00832899
Iteration 3494, loss = 0.00832637
Iteration 3495, loss = 0.00832293
Iteration 3496, loss = 0.00831965
Iteration 3497, loss = 0.00831667
Iteration 3498, loss = 0.00831300
Iteration 3499, loss = 0.00831055
Iteration 3500, loss = 0.00830742
Iteration 3501, loss = 0.00830363
Iteration 3502, loss = 0.00830053
Iteration 3503, loss = 0.00829717
Iteration 3504, loss = 0.00829417
Iteration 3505, loss = 0.00829078
Iteration 3506, loss = 0.00828725
Iteration 3507, loss = 0.00828633
Iteration 3508, loss = 0.00828183
Iteration 3509, loss = 0.00827849
Iteration 3510, loss = 0.00827519
Iteration 3511, loss = 0.00827159
Iteration 3512, loss = 0.00826904
Iteration 3513, loss = 0.00826570
Iteration 3514, loss = 0.00826373
Iteration 3515, loss = 0.00825981
Iteration 3516, loss = 0.00825669
Iteration 3517, loss = 0.00825455
Iteration 3518, loss = 0.00825072
Iteration 3519, loss = 0.00824771
Iteration 3520, loss = 0.00824445
Iteration 3521, loss = 0.00824144
Iteration 3522, loss = 0.00823810
Iteration 3523, loss = 0.00823498
Iteration 3524, loss = 0.00823160
Iteration 3525, loss = 0.00822912
Iteration 3526, loss = 0.00822688
Iteration 3527, loss = 0.00822191
Iteration 3528, loss = 0.00821889
Iteration 3529, loss = 0.00821524
Iteration 3530, loss = 0.00821227
Iteration 3531, loss = 0.00820949
Iteration 3532, loss = 0.00820503
Iteration 3533, loss = 0.00820177
Iteration 3534, loss = 0.00819809
Iteration 3535, loss = 0.00819498
Iteration 3536, loss = 0.00819152
Iteration 3537, loss = 0.00818827
Iteration 3538, loss = 0.00818507
Iteration 3539, loss = 0.00818293
Iteration 3540, loss = 0.00817905
Iteration 3541, loss = 0.00817565
Iteration 3542, loss = 0.00817281
Iteration 3543, loss = 0.00816998
Iteration 3544, loss = 0.00816679
Iteration 3545, loss = 0.00816405
Iteration 3546, loss = 0.00816111
Iteration 3547, loss = 0.00815802
Iteration 3548, loss = 0.00815472
Iteration 3549, loss = 0.00815195
Iteration 3550, loss = 0.00814829
Iteration 3551, loss = 0.00814521
Iteration 3552, loss = 0.00814202
Iteration 3553, loss = 0.00813877
Iteration 3554, loss = 0.00813579
Iteration 3555, loss = 0.00813211
Iteration 3556, loss = 0.00812941
Iteration 3557, loss = 0.00812607
Iteration 3558, loss = 0.00812242
Iteration 3559, loss = 0.00811986
Iteration 3560, loss = 0.00811641
Iteration 3561, loss = 0.00811375
Iteration 3562, loss = 0.00811049
Iteration 3563, loss = 0.00810725
Iteration 3564, loss = 0.00810468
Iteration 3565, loss = 0.00810131
Iteration 3566, loss = 0.00809833
Iteration 3567, loss = 0.00809549
Iteration 3568, loss = 0.00809239
Iteration 3569, loss = 0.00809041
Iteration 3570, loss = 0.00808520
Iteration 3571, loss = 0.00808239
Iteration 3572, loss = 0.00807855
Iteration 3573, loss = 0.00807500
Iteration 3574, loss = 0.00807242
Iteration 3575, loss = 0.00806846
Iteration 3576, loss = 0.00806464
Iteration 3577, loss = 0.00806086
Iteration 3578, loss = 0.00805774
Iteration 3579, loss = 0.00805458
Iteration 3580, loss = 0.00805178
Iteration 3581, loss = 0.00804850
Iteration 3582, loss = 0.00804549
Iteration 3583, loss = 0.00804254
Iteration 3584, loss = 0.00803925
Iteration 3585, loss = 0.00803608
Iteration 3586, loss = 0.00803284
Iteration 3587, loss = 0.00803030
Iteration 3588, loss = 0.00802724
Iteration 3589, loss = 0.00802448
Iteration 3590, loss = 0.00802136
Iteration 3591, loss = 0.00801852
Iteration 3592, loss = 0.00801549
Iteration 3593, loss = 0.00801244
Iteration 3594, loss = 0.00800989
Iteration 3595, loss = 0.00800584
Iteration 3596, loss = 0.00800310
Iteration 3597, loss = 0.00800003
Iteration 3598, loss = 0.00799711
Iteration 3599, loss = 0.00799374
Iteration 3600, loss = 0.00799102
Iteration 3601, loss = 0.00798792
Iteration 3602, loss = 0.00798517
Iteration 3603, loss = 0.00798194
Iteration 3604, loss = 0.00797921
Iteration 3605, loss = 0.00797670
Iteration 3606, loss = 0.00797346
Iteration 3607, loss = 0.00797051
Iteration 3608, loss = 0.00796757
Iteration 3609, loss = 0.00796477
Iteration 3610, loss = 0.00796176
Iteration 3611, loss = 0.00795920
Iteration 3612, loss = 0.00795651
Iteration 3613, loss = 0.00795382
Iteration 3614, loss = 0.00795124
Iteration 3615, loss = 0.00794963
Iteration 3616, loss = 0.00794679
Iteration 3617, loss = 0.00794467
Iteration 3618, loss = 0.00794253
Iteration 3619, loss = 0.00793954
Iteration 3620, loss = 0.00793686
Iteration 3621, loss = 0.00793442
Iteration 3622, loss = 0.00793133
Iteration 3623, loss = 0.00792837
Iteration 3624, loss = 0.00792580
Iteration 3625, loss = 0.00792296
Iteration 3626, loss = 0.00792003
Iteration 3627, loss = 0.00791736
Iteration 3628, loss = 0.00791457
Iteration 3629, loss = 0.00791179
Iteration 3630, loss = 0.00790883
Iteration 3631, loss = 0.00790571
Iteration 3632, loss = 0.00790299
Iteration 3633, loss = 0.00790021
Iteration 3634, loss = 0.00789739
Iteration 3635, loss = 0.00789519
Iteration 3636, loss = 0.00789301
Iteration 3637, loss = 0.00788961
Iteration 3638, loss = 0.00788674
Iteration 3639, loss = 0.00788449
Iteration 3640, loss = 0.00788127
Iteration 3641, loss = 0.00787755
Iteration 3642, loss = 0.00787396
Iteration 3643, loss = 0.00787077
Iteration 3644, loss = 0.00786742
Iteration 3645, loss = 0.00786494
Iteration 3646, loss = 0.00786215
Iteration 3647, loss = 0.00785786
Iteration 3648, loss = 0.00785487
Iteration 3649, loss = 0.00785199
Iteration 3650, loss = 0.00784877
Iteration 3651, loss = 0.00784632
Iteration 3652, loss = 0.00784240
Iteration 3653, loss = 0.00783904
Iteration 3654, loss = 0.00783585
Iteration 3655, loss = 0.00783285
Iteration 3656, loss = 0.00783006
Iteration 3657, loss = 0.00782730
Iteration 3658, loss = 0.00782397
Iteration 3659, loss = 0.00782090
Iteration 3660, loss = 0.00781821
Iteration 3661, loss = 0.00781418
Iteration 3662, loss = 0.00781055
Iteration 3663, loss = 0.00780841
Iteration 3664, loss = 0.00780513
Iteration 3665, loss = 0.00780131
Iteration 3666, loss = 0.00779836
Iteration 3667, loss = 0.00779514
Iteration 3668, loss = 0.00779228
Iteration 3669, loss = 0.00778949
Iteration 3670, loss = 0.00778665
Iteration 3671, loss = 0.00778381
Iteration 3672, loss = 0.00778116
Iteration 3673, loss = 0.00777899
Iteration 3674, loss = 0.00777615
Iteration 3675, loss = 0.00777337
Iteration 3676, loss = 0.00777039
Iteration 3677, loss = 0.00776728
Iteration 3678, loss = 0.00776511
Iteration 3679, loss = 0.00776214
Iteration 3680, loss = 0.00776026
Iteration 3681, loss = 0.00775764
Iteration 3682, loss = 0.00775536
Iteration 3683, loss = 0.00775465
Iteration 3684, loss = 0.00775047
Iteration 3685, loss = 0.00774753
Iteration 3686, loss = 0.00774468
Iteration 3687, loss = 0.00774214
Iteration 3688, loss = 0.00773909
Iteration 3689, loss = 0.00773669
Iteration 3690, loss = 0.00773384
Iteration 3691, loss = 0.00773122
Iteration 3692, loss = 0.00772871
Iteration 3693, loss = 0.00772641
Iteration 3694, loss = 0.00772407
Iteration 3695, loss = 0.00772173
Iteration 3696, loss = 0.00771918
Iteration 3697, loss = 0.00771670
Iteration 3698, loss = 0.00771452
Iteration 3699, loss = 0.00771128
Iteration 3700, loss = 0.00770800
Iteration 3701, loss = 0.00770648
Iteration 3702, loss = 0.00770222
Iteration 3703, loss = 0.00769912
Iteration 3704, loss = 0.00769618
Iteration 3705, loss = 0.00769294
Iteration 3706, loss = 0.00768995
Iteration 3707, loss = 0.00768681
Iteration 3708, loss = 0.00768436
Iteration 3709, loss = 0.00768156
Iteration 3710, loss = 0.00767885
Iteration 3711, loss = 0.00767620
Iteration 3712, loss = 0.00767366
Iteration 3713, loss = 0.00767114
Iteration 3714, loss = 0.00766891
Iteration 3715, loss = 0.00766616
Iteration 3716, loss = 0.00766400
Iteration 3717, loss = 0.00766156
Iteration 3718, loss = 0.00765945
Iteration 3719, loss = 0.00765610
Iteration 3720, loss = 0.00765341
Iteration 3721, loss = 0.00765017
Iteration 3722, loss = 0.00764837
Iteration 3723, loss = 0.00764570
Iteration 3724, loss = 0.00764247
Iteration 3725, loss = 0.00764013
Iteration 3726, loss = 0.00763718
Iteration 3727, loss = 0.00763471
Iteration 3728, loss = 0.00763235
Iteration 3729, loss = 0.00763127
Iteration 3730, loss = 0.00762697
Iteration 3731, loss = 0.00762396
Iteration 3732, loss = 0.00762052
Iteration 3733, loss = 0.00761776
Iteration 3734, loss = 0.00761490
Iteration 3735, loss = 0.00761147
Iteration 3736, loss = 0.00760903
Iteration 3737, loss = 0.00760566
Iteration 3738, loss = 0.00760260
Iteration 3739, loss = 0.00759888
Iteration 3740, loss = 0.00759606
Iteration 3741, loss = 0.00759360
Iteration 3742, loss = 0.00758990
Iteration 3743, loss = 0.00758753
Iteration 3744, loss = 0.00758486
Iteration 3745, loss = 0.00758121
Iteration 3746, loss = 0.00757880
Iteration 3747, loss = 0.00757599
Iteration 3748, loss = 0.00757365
Iteration 3749, loss = 0.00757085
Iteration 3750, loss = 0.00756872
Iteration 3751, loss = 0.00756664
Iteration 3752, loss = 0.00756366
Iteration 3753, loss = 0.00756219
Iteration 3754, loss = 0.00755856
Iteration 3755, loss = 0.00755586
Iteration 3756, loss = 0.00755320
Iteration 3757, loss = 0.00755013
Iteration 3758, loss = 0.00754781
Iteration 3759, loss = 0.00754470
Iteration 3760, loss = 0.00754148
Iteration 3761, loss = 0.00753832
Iteration 3762, loss = 0.00753494
Iteration 3763, loss = 0.00753255
Iteration 3764, loss = 0.00752895
Iteration 3765, loss = 0.00752594
Iteration 3766, loss = 0.00752346
Iteration 3767, loss = 0.00752052
Iteration 3768, loss = 0.00751763
Iteration 3769, loss = 0.00751483
Iteration 3770, loss = 0.00751220
Iteration 3771, loss = 0.00750994
Iteration 3772, loss = 0.00750726
Iteration 3773, loss = 0.00750448
Iteration 3774, loss = 0.00750144
Iteration 3775, loss = 0.00749902
Iteration 3776, loss = 0.00749690
Iteration 3777, loss = 0.00749394
Iteration 3778, loss = 0.00749093
Iteration 3779, loss = 0.00748823
Iteration 3780, loss = 0.00748584
Iteration 3781, loss = 0.00748374
Iteration 3782, loss = 0.00748063
Iteration 3783, loss = 0.00747799
Iteration 3784, loss = 0.00747541
Iteration 3785, loss = 0.00747292
Iteration 3786, loss = 0.00747044
Iteration 3787, loss = 0.00746796
Iteration 3788, loss = 0.00746605
Iteration 3789, loss = 0.00746403
Iteration 3790, loss = 0.00746077
Iteration 3791, loss = 0.00745819
Iteration 3792, loss = 0.00745576
Iteration 3793, loss = 0.00745334
Iteration 3794, loss = 0.00745091
Iteration 3795, loss = 0.00744871
Iteration 3796, loss = 0.00744642
Iteration 3797, loss = 0.00744420
Iteration 3798, loss = 0.00744207
Iteration 3799, loss = 0.00743984
Iteration 3800, loss = 0.00743704
Iteration 3801, loss = 0.00743402
Iteration 3802, loss = 0.00743146
Iteration 3803, loss = 0.00742869
Iteration 3804, loss = 0.00742621
Iteration 3805, loss = 0.00742321
Iteration 3806, loss = 0.00742073
Iteration 3807, loss = 0.00741773
Iteration 3808, loss = 0.00741566
Iteration 3809, loss = 0.00741250
Iteration 3810, loss = 0.00741004
Iteration 3811, loss = 0.00740756
Iteration 3812, loss = 0.00740496
Iteration 3813, loss = 0.00740219
Iteration 3814, loss = 0.00739977
Iteration 3815, loss = 0.00739714
Iteration 3816, loss = 0.00739458
Iteration 3817, loss = 0.00739291
Iteration 3818, loss = 0.00738974
Iteration 3819, loss = 0.00738755
Iteration 3820, loss = 0.00738501
Iteration 3821, loss = 0.00738277
Iteration 3822, loss = 0.00738042
Iteration 3823, loss = 0.00737812
Iteration 3824, loss = 0.00737556
Iteration 3825, loss = 0.00737394
Iteration 3826, loss = 0.00737207
Iteration 3827, loss = 0.00736984
Iteration 3828, loss = 0.00736792
Iteration 3829, loss = 0.00736586
Iteration 3830, loss = 0.00736426
Iteration 3831, loss = 0.00736218
Iteration 3832, loss = 0.00736040
Iteration 3833, loss = 0.00735812
Iteration 3834, loss = 0.00735559
Iteration 3835, loss = 0.00735331
Iteration 3836, loss = 0.00734955
Iteration 3837, loss = 0.00734684
Iteration 3838, loss = 0.00734396
Iteration 3839, loss = 0.00734214
Iteration 3840, loss = 0.00733802
Iteration 3841, loss = 0.00733546
Iteration 3842, loss = 0.00733258
Iteration 3843, loss = 0.00733012
Iteration 3844, loss = 0.00732796
Iteration 3845, loss = 0.00732495
Iteration 3846, loss = 0.00732210
Iteration 3847, loss = 0.00731957
Iteration 3848, loss = 0.00731663
Iteration 3849, loss = 0.00731408
Iteration 3850, loss = 0.00731140
Iteration 3851, loss = 0.00730926
Iteration 3852, loss = 0.00730656
Iteration 3853, loss = 0.00730388
Iteration 3854, loss = 0.00730139
Iteration 3855, loss = 0.00729853
Iteration 3856, loss = 0.00729620
Iteration 3857, loss = 0.00729435
Iteration 3858, loss = 0.00729041
Iteration 3859, loss = 0.00728876
Iteration 3860, loss = 0.00728556
Iteration 3861, loss = 0.00728294
Iteration 3862, loss = 0.00728072
Iteration 3863, loss = 0.00727824
Iteration 3864, loss = 0.00727585
Iteration 3865, loss = 0.00727407
Iteration 3866, loss = 0.00727076
Iteration 3867, loss = 0.00726813
Iteration 3868, loss = 0.00726580
Iteration 3869, loss = 0.00726308
Iteration 3870, loss = 0.00726063
Iteration 3871, loss = 0.00725870
Iteration 3872, loss = 0.00725679
Iteration 3873, loss = 0.00725407
Iteration 3874, loss = 0.00725151
Iteration 3875, loss = 0.00724895
Iteration 3876, loss = 0.00724638
Iteration 3877, loss = 0.00724365
Iteration 3878, loss = 0.00724147
Iteration 3879, loss = 0.00723860
Iteration 3880, loss = 0.00723631
Iteration 3881, loss = 0.00723346
Iteration 3882, loss = 0.00723150
Iteration 3883, loss = 0.00722865
Iteration 3884, loss = 0.00722586
Iteration 3885, loss = 0.00722303
Iteration 3886, loss = 0.00722057
Iteration 3887, loss = 0.00721765
Iteration 3888, loss = 0.00721527
Iteration 3889, loss = 0.00721324
Iteration 3890, loss = 0.00721047
Iteration 3891, loss = 0.00720788
Iteration 3892, loss = 0.00720571
Iteration 3893, loss = 0.00720341
Iteration 3894, loss = 0.00720090
Iteration 3895, loss = 0.00719868
Iteration 3896, loss = 0.00719671
Iteration 3897, loss = 0.00719374
Iteration 3898, loss = 0.00719095
Iteration 3899, loss = 0.00718828
Iteration 3900, loss = 0.00718627
Iteration 3901, loss = 0.00718313
Iteration 3902, loss = 0.00718079
Iteration 3903, loss = 0.00717906
Iteration 3904, loss = 0.00717674
Iteration 3905, loss = 0.00717393
Iteration 3906, loss = 0.00717201
Iteration 3907, loss = 0.00716946
Iteration 3908, loss = 0.00716744
Iteration 3909, loss = 0.00716527
Iteration 3910, loss = 0.00716275
Iteration 3911, loss = 0.00716041
Iteration 3912, loss = 0.00715865
Iteration 3913, loss = 0.00715560
Iteration 3914, loss = 0.00715351
Iteration 3915, loss = 0.00715008
Iteration 3916, loss = 0.00714741
Iteration 3917, loss = 0.00714316
Iteration 3918, loss = 0.00714141
Iteration 3919, loss = 0.00713757
Iteration 3920, loss = 0.00713433
Iteration 3921, loss = 0.00713145
Iteration 3922, loss = 0.00712997
Iteration 3923, loss = 0.00712657
Iteration 3924, loss = 0.00712405
Iteration 3925, loss = 0.00712069
Iteration 3926, loss = 0.00711751
Iteration 3927, loss = 0.00711415
Iteration 3928, loss = 0.00711168
Iteration 3929, loss = 0.00710799
Iteration 3930, loss = 0.00710466
Iteration 3931, loss = 0.00710077
Iteration 3932, loss = 0.00709785
Iteration 3933, loss = 0.00709667
Iteration 3934, loss = 0.00709408
Iteration 3935, loss = 0.00709006
Iteration 3936, loss = 0.00708741
Iteration 3937, loss = 0.00708470
Iteration 3938, loss = 0.00708180
Iteration 3939, loss = 0.00707900
Iteration 3940, loss = 0.00707712
Iteration 3941, loss = 0.00707385
Iteration 3942, loss = 0.00707113
Iteration 3943, loss = 0.00706792
Iteration 3944, loss = 0.00706575
Iteration 3945, loss = 0.00706346
Iteration 3946, loss = 0.00706037
Iteration 3947, loss = 0.00705772
Iteration 3948, loss = 0.00705511
Iteration 3949, loss = 0.00705283
Iteration 3950, loss = 0.00705042
Iteration 3951, loss = 0.00704811
Iteration 3952, loss = 0.00704568
Iteration 3953, loss = 0.00704328
Iteration 3954, loss = 0.00704118
Iteration 3955, loss = 0.00703855
Iteration 3956, loss = 0.00703622
Iteration 3957, loss = 0.00703405
Iteration 3958, loss = 0.00703189
Iteration 3959, loss = 0.00702959
Iteration 3960, loss = 0.00702760
Iteration 3961, loss = 0.00702518
Iteration 3962, loss = 0.00702293
Iteration 3963, loss = 0.00702055
Iteration 3964, loss = 0.00701755
Iteration 3965, loss = 0.00701565
Iteration 3966, loss = 0.00701314
Iteration 3967, loss = 0.00701060
Iteration 3968, loss = 0.00700777
Iteration 3969, loss = 0.00700556
Iteration 3970, loss = 0.00700301
Iteration 3971, loss = 0.00700067
Iteration 3972, loss = 0.00699791
Iteration 3973, loss = 0.00699542
Iteration 3974, loss = 0.00699242
Iteration 3975, loss = 0.00699008
Iteration 3976, loss = 0.00698814
Iteration 3977, loss = 0.00698499
Iteration 3978, loss = 0.00698232
Iteration 3979, loss = 0.00698074
Iteration 3980, loss = 0.00697747
Iteration 3981, loss = 0.00697577
Iteration 3982, loss = 0.00697304
Iteration 3983, loss = 0.00697199
Iteration 3984, loss = 0.00696854
Iteration 3985, loss = 0.00696613
Iteration 3986, loss = 0.00696381
Iteration 3987, loss = 0.00696155
Iteration 3988, loss = 0.00695886
Iteration 3989, loss = 0.00695641
Iteration 3990, loss = 0.00695428
Iteration 3991, loss = 0.00695143
Iteration 3992, loss = 0.00694942
Iteration 3993, loss = 0.00694659
Iteration 3994, loss = 0.00694386
Iteration 3995, loss = 0.00694249
Iteration 3996, loss = 0.00693936
Iteration 3997, loss = 0.00693690
Iteration 3998, loss = 0.00693454
Iteration 3999, loss = 0.00693216
Iteration 4000, loss = 0.00693088
Iteration 4001, loss = 0.00692752
Iteration 4002, loss = 0.00692529
Iteration 4003, loss = 0.00692295
Iteration 4004, loss = 0.00692051
Iteration 4005, loss = 0.00691861
Iteration 4006, loss = 0.00691562
Iteration 4007, loss = 0.00691367
Iteration 4008, loss = 0.00691058
Iteration 4009, loss = 0.00690819
Iteration 4010, loss = 0.00690580
Iteration 4011, loss = 0.00690304
Iteration 4012, loss = 0.00690057
Iteration 4013, loss = 0.00689828
Iteration 4014, loss = 0.00689590
Iteration 4015, loss = 0.00689370
Iteration 4016, loss = 0.00689082
Iteration 4017, loss = 0.00688836
Iteration 4018, loss = 0.00688577
Iteration 4019, loss = 0.00688340
Iteration 4020, loss = 0.00688105
Iteration 4021, loss = 0.00687862
Iteration 4022, loss = 0.00687661
Iteration 4023, loss = 0.00687474
Iteration 4024, loss = 0.00687225
Iteration 4025, loss = 0.00687009
Iteration 4026, loss = 0.00686838
Iteration 4027, loss = 0.00686602
Iteration 4028, loss = 0.00686373
Iteration 4029, loss = 0.00686155
Iteration 4030, loss = 0.00685949
Iteration 4031, loss = 0.00685727
Iteration 4032, loss = 0.00685492
Iteration 4033, loss = 0.00685348
Iteration 4034, loss = 0.00685127
Iteration 4035, loss = 0.00684865
Iteration 4036, loss = 0.00684599
Iteration 4037, loss = 0.00684325
Iteration 4038, loss = 0.00684120
Iteration 4039, loss = 0.00683918
Iteration 4040, loss = 0.00683614
Iteration 4041, loss = 0.00683371
Iteration 4042, loss = 0.00683136
Iteration 4043, loss = 0.00682957
Iteration 4044, loss = 0.00682680
Iteration 4045, loss = 0.00682432
Iteration 4046, loss = 0.00682217
Iteration 4047, loss = 0.00681993
Iteration 4048, loss = 0.00681784
Iteration 4049, loss = 0.00681557
Iteration 4050, loss = 0.00681332
Iteration 4051, loss = 0.00681106
Iteration 4052, loss = 0.00680867
Iteration 4053, loss = 0.00680650
Iteration 4054, loss = 0.00680426
Iteration 4055, loss = 0.00680177
Iteration 4056, loss = 0.00679968
Iteration 4057, loss = 0.00679742
Iteration 4058, loss = 0.00679525
Iteration 4059, loss = 0.00679359
Iteration 4060, loss = 0.00679087
Iteration 4061, loss = 0.00678930
Iteration 4062, loss = 0.00678644
Iteration 4063, loss = 0.00678498
Iteration 4064, loss = 0.00678271
Iteration 4065, loss = 0.00677963
Iteration 4066, loss = 0.00677726
Iteration 4067, loss = 0.00677555
Iteration 4068, loss = 0.00677276
Iteration 4069, loss = 0.00677021
Iteration 4070, loss = 0.00676801
Iteration 4071, loss = 0.00676615
Iteration 4072, loss = 0.00676368
Iteration 4073, loss = 0.00676125
Iteration 4074, loss = 0.00675927
Iteration 4075, loss = 0.00675708
Iteration 4076, loss = 0.00675461
Iteration 4077, loss = 0.00675211
Iteration 4078, loss = 0.00674981
Iteration 4079, loss = 0.00674780
Iteration 4080, loss = 0.00674530
Iteration 4081, loss = 0.00674302
Iteration 4082, loss = 0.00674093
Iteration 4083, loss = 0.00673892
Iteration 4084, loss = 0.00673704
Iteration 4085, loss = 0.00673465
Iteration 4086, loss = 0.00673242
Iteration 4087, loss = 0.00673007
Iteration 4088, loss = 0.00672779
Iteration 4089, loss = 0.00672569
Iteration 4090, loss = 0.00672296
Iteration 4091, loss = 0.00672082
Iteration 4092, loss = 0.00671825
Iteration 4093, loss = 0.00671640
Iteration 4094, loss = 0.00671444
Iteration 4095, loss = 0.00671220
Iteration 4096, loss = 0.00671069
Iteration 4097, loss = 0.00670928
Iteration 4098, loss = 0.00670687
Iteration 4099, loss = 0.00670489
Iteration 4100, loss = 0.00670360
Iteration 4101, loss = 0.00670149
Iteration 4102, loss = 0.00669944
Iteration 4103, loss = 0.00669735
Iteration 4104, loss = 0.00669548
Iteration 4105, loss = 0.00669366
Iteration 4106, loss = 0.00669173
Iteration 4107, loss = 0.00668982
Iteration 4108, loss = 0.00668839
Iteration 4109, loss = 0.00668590
Iteration 4110, loss = 0.00668359
Iteration 4111, loss = 0.00668133
Iteration 4112, loss = 0.00667935
Iteration 4113, loss = 0.00667700
Iteration 4114, loss = 0.00667484
Iteration 4115, loss = 0.00667247
Iteration 4116, loss = 0.00667024
Iteration 4117, loss = 0.00666829
Iteration 4118, loss = 0.00666549
Iteration 4119, loss = 0.00666333
Iteration 4120, loss = 0.00666102
Iteration 4121, loss = 0.00665892
Iteration 4122, loss = 0.00665682
Iteration 4123, loss = 0.00665470
Iteration 4124, loss = 0.00665238
Iteration 4125, loss = 0.00665014
Iteration 4126, loss = 0.00664794
Iteration 4127, loss = 0.00664556
Iteration 4128, loss = 0.00664371
Iteration 4129, loss = 0.00664138
Iteration 4130, loss = 0.00663928
Iteration 4131, loss = 0.00663738
Iteration 4132, loss = 0.00663534
Iteration 4133, loss = 0.00663351
Iteration 4134, loss = 0.00663113
Iteration 4135, loss = 0.00662918
Iteration 4136, loss = 0.00662667
Iteration 4137, loss = 0.00662451
Iteration 4138, loss = 0.00662222
Iteration 4139, loss = 0.00662086
Iteration 4140, loss = 0.00661859
Iteration 4141, loss = 0.00661709
Iteration 4142, loss = 0.00661491
Iteration 4143, loss = 0.00661302
Iteration 4144, loss = 0.00661147
Iteration 4145, loss = 0.00660888
Iteration 4146, loss = 0.00660652
Iteration 4147, loss = 0.00660389
Iteration 4148, loss = 0.00660158
Iteration 4149, loss = 0.00659896
Iteration 4150, loss = 0.00659536
Iteration 4151, loss = 0.00659272
Iteration 4152, loss = 0.00658989
Iteration 4153, loss = 0.00658658
Iteration 4154, loss = 0.00658454
Iteration 4155, loss = 0.00658106
Iteration 4156, loss = 0.00657917
Iteration 4157, loss = 0.00657667
Iteration 4158, loss = 0.00657376
Iteration 4159, loss = 0.00657112
Iteration 4160, loss = 0.00656859
Iteration 4161, loss = 0.00656668
Iteration 4162, loss = 0.00656348
Iteration 4163, loss = 0.00656090
Iteration 4164, loss = 0.00655844
Iteration 4165, loss = 0.00655603
Iteration 4166, loss = 0.00655419
Iteration 4167, loss = 0.00655164
Iteration 4168, loss = 0.00654961
Iteration 4169, loss = 0.00654687
Iteration 4170, loss = 0.00654396
Iteration 4171, loss = 0.00654199
Iteration 4172, loss = 0.00653921
Iteration 4173, loss = 0.00653715
Iteration 4174, loss = 0.00653486
Iteration 4175, loss = 0.00653241
Iteration 4176, loss = 0.00653052
Iteration 4177, loss = 0.00652805
Iteration 4178, loss = 0.00652583
Iteration 4179, loss = 0.00652343
Iteration 4180, loss = 0.00652153
Iteration 4181, loss = 0.00651939
Iteration 4182, loss = 0.00651711
Iteration 4183, loss = 0.00651480
Iteration 4184, loss = 0.00651265
Iteration 4185, loss = 0.00651103
Iteration 4186, loss = 0.00650853
Iteration 4187, loss = 0.00650604
Iteration 4188, loss = 0.00650421
Iteration 4189, loss = 0.00650214
Iteration 4190, loss = 0.00649997
Iteration 4191, loss = 0.00649825
Iteration 4192, loss = 0.00649592
Iteration 4193, loss = 0.00649404
Iteration 4194, loss = 0.00649188
Iteration 4195, loss = 0.00648991
Iteration 4196, loss = 0.00648745
Iteration 4197, loss = 0.00648506
Iteration 4198, loss = 0.00648298
Iteration 4199, loss = 0.00648084
Iteration 4200, loss = 0.00647824
Iteration 4201, loss = 0.00647660
Iteration 4202, loss = 0.00647418
Iteration 4203, loss = 0.00647219
Iteration 4204, loss = 0.00646985
Iteration 4205, loss = 0.00646766
Iteration 4206, loss = 0.00646572
Iteration 4207, loss = 0.00646378
Iteration 4208, loss = 0.00646135
Iteration 4209, loss = 0.00645936
Iteration 4210, loss = 0.00645705
Iteration 4211, loss = 0.00645596
Iteration 4212, loss = 0.00645292
Iteration 4213, loss = 0.00645091
Iteration 4214, loss = 0.00644870
Iteration 4215, loss = 0.00644729
Iteration 4216, loss = 0.00644472
Iteration 4217, loss = 0.00644262
Iteration 4218, loss = 0.00644091
Iteration 4219, loss = 0.00643900
Iteration 4220, loss = 0.00643651
Iteration 4221, loss = 0.00643436
Iteration 4222, loss = 0.00643235
Iteration 4223, loss = 0.00643094
Iteration 4224, loss = 0.00642823
Iteration 4225, loss = 0.00642627
Iteration 4226, loss = 0.00642398
Iteration 4227, loss = 0.00642201
Iteration 4228, loss = 0.00642005
Iteration 4229, loss = 0.00641829
Iteration 4230, loss = 0.00641561
Iteration 4231, loss = 0.00641359
Iteration 4232, loss = 0.00641143
Iteration 4233, loss = 0.00640980
Iteration 4234, loss = 0.00640719
Iteration 4235, loss = 0.00640553
Iteration 4236, loss = 0.00640301
Iteration 4237, loss = 0.00640107
Iteration 4238, loss = 0.00639846
Iteration 4239, loss = 0.00639663
Iteration 4240, loss = 0.00639403
Iteration 4241, loss = 0.00639198
Iteration 4242, loss = 0.00638969
Iteration 4243, loss = 0.00638744
Iteration 4244, loss = 0.00638549
Iteration 4245, loss = 0.00638323
Iteration 4246, loss = 0.00638128
Iteration 4247, loss = 0.00637908
Iteration 4248, loss = 0.00637687
Iteration 4249, loss = 0.00637523
Iteration 4250, loss = 0.00637325
Iteration 4251, loss = 0.00637124
Iteration 4252, loss = 0.00636930
Iteration 4253, loss = 0.00636729
Iteration 4254, loss = 0.00636544
Iteration 4255, loss = 0.00636378
Iteration 4256, loss = 0.00636179
Iteration 4257, loss = 0.00636042
Iteration 4258, loss = 0.00635801
Iteration 4259, loss = 0.00635613
Iteration 4260, loss = 0.00635315
Iteration 4261, loss = 0.00635112
Iteration 4262, loss = 0.00634939
Iteration 4263, loss = 0.00634709
Iteration 4264, loss = 0.00634484
Iteration 4265, loss = 0.00634251
Iteration 4266, loss = 0.00634120
Iteration 4267, loss = 0.00633905
Iteration 4268, loss = 0.00633665
Iteration 4269, loss = 0.00633467
Iteration 4270, loss = 0.00633229
Iteration 4271, loss = 0.00633035
Iteration 4272, loss = 0.00632818
Iteration 4273, loss = 0.00632630
Iteration 4274, loss = 0.00632408
Iteration 4275, loss = 0.00632159
Iteration 4276, loss = 0.00631996
Iteration 4277, loss = 0.00631729
Iteration 4278, loss = 0.00631488
Iteration 4279, loss = 0.00631247
Iteration 4280, loss = 0.00631025
Iteration 4281, loss = 0.00630821
Iteration 4282, loss = 0.00630613
Iteration 4283, loss = 0.00630399
Iteration 4284, loss = 0.00630152
Iteration 4285, loss = 0.00629943
Iteration 4286, loss = 0.00629811
Iteration 4287, loss = 0.00629542
Iteration 4288, loss = 0.00629312
Iteration 4289, loss = 0.00629165
Iteration 4290, loss = 0.00628953
Iteration 4291, loss = 0.00628754
Iteration 4292, loss = 0.00628544
Iteration 4293, loss = 0.00628356
Iteration 4294, loss = 0.00628147
Iteration 4295, loss = 0.00627928
Iteration 4296, loss = 0.00627738
Iteration 4297, loss = 0.00627557
Iteration 4298, loss = 0.00627312
Iteration 4299, loss = 0.00627150
Iteration 4300, loss = 0.00626945
Iteration 4301, loss = 0.00626720
Iteration 4302, loss = 0.00626521
Iteration 4303, loss = 0.00626318
Iteration 4304, loss = 0.00626134
Iteration 4305, loss = 0.00625926
Iteration 4306, loss = 0.00625726
Iteration 4307, loss = 0.00625570
Iteration 4308, loss = 0.00625336
Iteration 4309, loss = 0.00625160
Iteration 4310, loss = 0.00624953
Iteration 4311, loss = 0.00624752
Iteration 4312, loss = 0.00624560
Iteration 4313, loss = 0.00624341
Iteration 4314, loss = 0.00624134
Iteration 4315, loss = 0.00623944
Iteration 4316, loss = 0.00623722
Iteration 4317, loss = 0.00623511
Iteration 4318, loss = 0.00623284
Iteration 4319, loss = 0.00623090
Iteration 4320, loss = 0.00622898
Iteration 4321, loss = 0.00622679
Iteration 4322, loss = 0.00622493
Iteration 4323, loss = 0.00622304
Iteration 4324, loss = 0.00622071
Iteration 4325, loss = 0.00621831
Iteration 4326, loss = 0.00621598
Iteration 4327, loss = 0.00621348
Iteration 4328, loss = 0.00621151
Iteration 4329, loss = 0.00620894
Iteration 4330, loss = 0.00620698
Iteration 4331, loss = 0.00620548
Iteration 4332, loss = 0.00620308
Iteration 4333, loss = 0.00620080
Iteration 4334, loss = 0.00619904
Iteration 4335, loss = 0.00619732
Iteration 4336, loss = 0.00619662
Iteration 4337, loss = 0.00619402
Iteration 4338, loss = 0.00619192
Iteration 4339, loss = 0.00618899
Iteration 4340, loss = 0.00618653
Iteration 4341, loss = 0.00618435
Iteration 4342, loss = 0.00618326
Iteration 4343, loss = 0.00618053
Iteration 4344, loss = 0.00617788
Iteration 4345, loss = 0.00617627
Iteration 4346, loss = 0.00617462
Iteration 4347, loss = 0.00617218
Iteration 4348, loss = 0.00617018
Iteration 4349, loss = 0.00616808
Iteration 4350, loss = 0.00616602
Iteration 4351, loss = 0.00616405
Iteration 4352, loss = 0.00616287
Iteration 4353, loss = 0.00616051
Iteration 4354, loss = 0.00615867
Iteration 4355, loss = 0.00615640
Iteration 4356, loss = 0.00615481
Iteration 4357, loss = 0.00615281
Iteration 4358, loss = 0.00615096
Iteration 4359, loss = 0.00614937
Iteration 4360, loss = 0.00614712
Iteration 4361, loss = 0.00614537
Iteration 4362, loss = 0.00614332
Iteration 4363, loss = 0.00614192
Iteration 4364, loss = 0.00613947
Iteration 4365, loss = 0.00613755
Iteration 4366, loss = 0.00613569
Iteration 4367, loss = 0.00613362
Iteration 4368, loss = 0.00613183
Iteration 4369, loss = 0.00612976
Iteration 4370, loss = 0.00612789
Iteration 4371, loss = 0.00612589
Iteration 4372, loss = 0.00612425
Iteration 4373, loss = 0.00612204
Iteration 4374, loss = 0.00612012
Iteration 4375, loss = 0.00611843
Iteration 4376, loss = 0.00611643
Iteration 4377, loss = 0.00611474
Iteration 4378, loss = 0.00611265
Iteration 4379, loss = 0.00611107
Iteration 4380, loss = 0.00610875
Iteration 4381, loss = 0.00610695
Iteration 4382, loss = 0.00610540
Iteration 4383, loss = 0.00610343
Iteration 4384, loss = 0.00610151
Iteration 4385, loss = 0.00609960
Iteration 4386, loss = 0.00609815
Iteration 4387, loss = 0.00609599
Iteration 4388, loss = 0.00609458
Iteration 4389, loss = 0.00609224
Iteration 4390, loss = 0.00609038
Iteration 4391, loss = 0.00608849
Iteration 4392, loss = 0.00608661
Iteration 4393, loss = 0.00608465
Iteration 4394, loss = 0.00608263
Iteration 4395, loss = 0.00608118
Iteration 4396, loss = 0.00607868
Iteration 4397, loss = 0.00607689
Iteration 4398, loss = 0.00607488
Iteration 4399, loss = 0.00607295
Iteration 4400, loss = 0.00607095
Iteration 4401, loss = 0.00606898
Iteration 4402, loss = 0.00606778
Iteration 4403, loss = 0.00606529
Iteration 4404, loss = 0.00606384
Iteration 4405, loss = 0.00606143
Iteration 4406, loss = 0.00605975
Iteration 4407, loss = 0.00605768
Iteration 4408, loss = 0.00605575
Iteration 4409, loss = 0.00605385
Iteration 4410, loss = 0.00605224
Iteration 4411, loss = 0.00605042
Iteration 4412, loss = 0.00604843
Iteration 4413, loss = 0.00604701
Iteration 4414, loss = 0.00604499
Iteration 4415, loss = 0.00604357
Iteration 4416, loss = 0.00604136
Iteration 4417, loss = 0.00603970
Iteration 4418, loss = 0.00603785
Iteration 4419, loss = 0.00603603
Iteration 4420, loss = 0.00603438
Iteration 4421, loss = 0.00603249
Iteration 4422, loss = 0.00603038
Iteration 4423, loss = 0.00602898
Iteration 4424, loss = 0.00602704
Iteration 4425, loss = 0.00602524
Iteration 4426, loss = 0.00602342
Iteration 4427, loss = 0.00602163
Iteration 4428, loss = 0.00601992
Iteration 4429, loss = 0.00601822
Iteration 4430, loss = 0.00601676
Iteration 4431, loss = 0.00601517
Iteration 4432, loss = 0.00601368
Iteration 4433, loss = 0.00601216
Iteration 4434, loss = 0.00601057
Iteration 4435, loss = 0.00600841
Iteration 4436, loss = 0.00600660
Iteration 4437, loss = 0.00600608
Iteration 4438, loss = 0.00600363
Iteration 4439, loss = 0.00600193
Iteration 4440, loss = 0.00600056
Iteration 4441, loss = 0.00599878
Iteration 4442, loss = 0.00599671
Iteration 4443, loss = 0.00599525
Iteration 4444, loss = 0.00599312
Iteration 4445, loss = 0.00599121
Iteration 4446, loss = 0.00598925
Iteration 4447, loss = 0.00598780
Iteration 4448, loss = 0.00598546
Iteration 4449, loss = 0.00598383
Iteration 4450, loss = 0.00598159
Iteration 4451, loss = 0.00597993
Iteration 4452, loss = 0.00597775
Iteration 4453, loss = 0.00597580
Iteration 4454, loss = 0.00597396
Iteration 4455, loss = 0.00597214
Iteration 4456, loss = 0.00597025
Iteration 4457, loss = 0.00596892
Iteration 4458, loss = 0.00596677
Iteration 4459, loss = 0.00596546
Iteration 4460, loss = 0.00596342
Iteration 4461, loss = 0.00596148
Iteration 4462, loss = 0.00595982
Iteration 4463, loss = 0.00595825
Iteration 4464, loss = 0.00595648
Iteration 4465, loss = 0.00595490
Iteration 4466, loss = 0.00595305
Iteration 4467, loss = 0.00595162
Iteration 4468, loss = 0.00594983
Iteration 4469, loss = 0.00594871
Iteration 4470, loss = 0.00594681
Iteration 4471, loss = 0.00594533
Iteration 4472, loss = 0.00594385
Iteration 4473, loss = 0.00594169
Iteration 4474, loss = 0.00594005
Iteration 4475, loss = 0.00593829
Iteration 4476, loss = 0.00593656
Iteration 4477, loss = 0.00593461
Iteration 4478, loss = 0.00593271
Iteration 4479, loss = 0.00593154
Iteration 4480, loss = 0.00592968
Iteration 4481, loss = 0.00592831
Iteration 4482, loss = 0.00592621
Iteration 4483, loss = 0.00592482
Iteration 4484, loss = 0.00592296
Iteration 4485, loss = 0.00592155
Iteration 4486, loss = 0.00591911
Iteration 4487, loss = 0.00591761
Iteration 4488, loss = 0.00591569
Iteration 4489, loss = 0.00591387
Iteration 4490, loss = 0.00591184
Iteration 4491, loss = 0.00591056
Iteration 4492, loss = 0.00590790
Iteration 4493, loss = 0.00590620
Iteration 4494, loss = 0.00590427
Iteration 4495, loss = 0.00590254
Iteration 4496, loss = 0.00590059
Iteration 4497, loss = 0.00589866
Iteration 4498, loss = 0.00589689
Iteration 4499, loss = 0.00589504
Iteration 4500, loss = 0.00589330
Iteration 4501, loss = 0.00589136
Iteration 4502, loss = 0.00588953
Iteration 4503, loss = 0.00588772
Iteration 4504, loss = 0.00588606
Iteration 4505, loss = 0.00588398
Iteration 4506, loss = 0.00588271
Iteration 4507, loss = 0.00588034
Iteration 4508, loss = 0.00587851
Iteration 4509, loss = 0.00587711
Iteration 4510, loss = 0.00587491
Iteration 4511, loss = 0.00587297
Iteration 4512, loss = 0.00587152
Iteration 4513, loss = 0.00586946
Iteration 4514, loss = 0.00586883
Iteration 4515, loss = 0.00586603
Iteration 4516, loss = 0.00586420
Iteration 4517, loss = 0.00586227
Iteration 4518, loss = 0.00586051
Iteration 4519, loss = 0.00585871
Iteration 4520, loss = 0.00585796
Iteration 4521, loss = 0.00585583
Iteration 4522, loss = 0.00585363
Iteration 4523, loss = 0.00585195
Iteration 4524, loss = 0.00584993
Iteration 4525, loss = 0.00584776
Iteration 4526, loss = 0.00584653
Iteration 4527, loss = 0.00584400
Iteration 4528, loss = 0.00584225
Iteration 4529, loss = 0.00584024
Iteration 4530, loss = 0.00583839
Iteration 4531, loss = 0.00583642
Iteration 4532, loss = 0.00583457
Iteration 4533, loss = 0.00583264
Iteration 4534, loss = 0.00583096
Iteration 4535, loss = 0.00582924
Iteration 4536, loss = 0.00582742
Iteration 4537, loss = 0.00582529
Iteration 4538, loss = 0.00582370
Iteration 4539, loss = 0.00582169
Iteration 4540, loss = 0.00582012
Iteration 4541, loss = 0.00581842
Iteration 4542, loss = 0.00581660
Iteration 4543, loss = 0.00581556
Iteration 4544, loss = 0.00581290
Iteration 4545, loss = 0.00581101
Iteration 4546, loss = 0.00580911
Iteration 4547, loss = 0.00580791
Iteration 4548, loss = 0.00580571
Iteration 4549, loss = 0.00580412
Iteration 4550, loss = 0.00580208
Iteration 4551, loss = 0.00580032
Iteration 4552, loss = 0.00579860
Iteration 4553, loss = 0.00579681
Iteration 4554, loss = 0.00579468
Iteration 4555, loss = 0.00579313
Iteration 4556, loss = 0.00579124
Iteration 4557, loss = 0.00578954
Iteration 4558, loss = 0.00578752
Iteration 4559, loss = 0.00578765
Iteration 4560, loss = 0.00578442
Iteration 4561, loss = 0.00578281
Iteration 4562, loss = 0.00578072
Iteration 4563, loss = 0.00577892
Iteration 4564, loss = 0.00577677
Iteration 4565, loss = 0.00577481
Iteration 4566, loss = 0.00577345
Iteration 4567, loss = 0.00577141
Iteration 4568, loss = 0.00576916
Iteration 4569, loss = 0.00576722
Iteration 4570, loss = 0.00576541
Iteration 4571, loss = 0.00576393
Iteration 4572, loss = 0.00576182
Iteration 4573, loss = 0.00576021
Iteration 4574, loss = 0.00575803
Iteration 4575, loss = 0.00575631
Iteration 4576, loss = 0.00575463
Iteration 4577, loss = 0.00575351
Iteration 4578, loss = 0.00575184
Iteration 4579, loss = 0.00575041
Iteration 4580, loss = 0.00574771
Iteration 4581, loss = 0.00574689
Iteration 4582, loss = 0.00574457
Iteration 4583, loss = 0.00574275
Iteration 4584, loss = 0.00574107
Iteration 4585, loss = 0.00573951
Iteration 4586, loss = 0.00573791
Iteration 4587, loss = 0.00573617
Iteration 4588, loss = 0.00573428
Iteration 4589, loss = 0.00573256
Iteration 4590, loss = 0.00573075
Iteration 4591, loss = 0.00572886
Iteration 4592, loss = 0.00572725
Iteration 4593, loss = 0.00572553
Iteration 4594, loss = 0.00572374
Iteration 4595, loss = 0.00572292
Iteration 4596, loss = 0.00572031
Iteration 4597, loss = 0.00571870
Iteration 4598, loss = 0.00571664
Iteration 4599, loss = 0.00571475
Iteration 4600, loss = 0.00571261
Iteration 4601, loss = 0.00571089
Iteration 4602, loss = 0.00570886
Iteration 4603, loss = 0.00570686
Iteration 4604, loss = 0.00570506
Iteration 4605, loss = 0.00570316
Iteration 4606, loss = 0.00570120
Iteration 4607, loss = 0.00569948
Iteration 4608, loss = 0.00569801
Iteration 4609, loss = 0.00569592
Iteration 4610, loss = 0.00569407
Iteration 4611, loss = 0.00569215
Iteration 4612, loss = 0.00568997
Iteration 4613, loss = 0.00568833
Iteration 4614, loss = 0.00568734
Iteration 4615, loss = 0.00568496
Iteration 4616, loss = 0.00568281
Iteration 4617, loss = 0.00568094
Iteration 4618, loss = 0.00567908
Iteration 4619, loss = 0.00567734
Iteration 4620, loss = 0.00567573
Iteration 4621, loss = 0.00567372
Iteration 4622, loss = 0.00567164
Iteration 4623, loss = 0.00566993
Iteration 4624, loss = 0.00566809
Iteration 4625, loss = 0.00566658
Iteration 4626, loss = 0.00566486
Iteration 4627, loss = 0.00566304
Iteration 4628, loss = 0.00566142
Iteration 4629, loss = 0.00565978
Iteration 4630, loss = 0.00565833
Iteration 4631, loss = 0.00565618
Iteration 4632, loss = 0.00565477
Iteration 4633, loss = 0.00565330
Iteration 4634, loss = 0.00565171
Iteration 4635, loss = 0.00565013
Iteration 4636, loss = 0.00564818
Iteration 4637, loss = 0.00564640
Iteration 4638, loss = 0.00564454
Iteration 4639, loss = 0.00564306
Iteration 4640, loss = 0.00564136
Iteration 4641, loss = 0.00563999
Iteration 4642, loss = 0.00563817
Iteration 4643, loss = 0.00563621
Iteration 4644, loss = 0.00563467
Iteration 4645, loss = 0.00563314
Iteration 4646, loss = 0.00563088
Iteration 4647, loss = 0.00562909
Iteration 4648, loss = 0.00562734
Iteration 4649, loss = 0.00562546
Iteration 4650, loss = 0.00562407
Iteration 4651, loss = 0.00562202
Iteration 4652, loss = 0.00562040
Iteration 4653, loss = 0.00561872
Iteration 4654, loss = 0.00561695
Iteration 4655, loss = 0.00561541
Iteration 4656, loss = 0.00561356
Iteration 4657, loss = 0.00561196
Iteration 4658, loss = 0.00561040
Iteration 4659, loss = 0.00560872
Iteration 4660, loss = 0.00560665
Iteration 4661, loss = 0.00560506
Iteration 4662, loss = 0.00560399
Iteration 4663, loss = 0.00560143
Iteration 4664, loss = 0.00559988
Iteration 4665, loss = 0.00559788
Iteration 4666, loss = 0.00559637
Iteration 4667, loss = 0.00559476
Iteration 4668, loss = 0.00559319
Iteration 4669, loss = 0.00559142
Iteration 4670, loss = 0.00558982
Iteration 4671, loss = 0.00558853
Iteration 4672, loss = 0.00558710
Iteration 4673, loss = 0.00558511
Iteration 4674, loss = 0.00558348
Iteration 4675, loss = 0.00558163
Iteration 4676, loss = 0.00557993
Iteration 4677, loss = 0.00557836
Iteration 4678, loss = 0.00557698
Iteration 4679, loss = 0.00557517
Iteration 4680, loss = 0.00557332
Iteration 4681, loss = 0.00557163
Iteration 4682, loss = 0.00557052
Iteration 4683, loss = 0.00556850
Iteration 4684, loss = 0.00556714
Iteration 4685, loss = 0.00556532
Iteration 4686, loss = 0.00556395
Iteration 4687, loss = 0.00556199
Iteration 4688, loss = 0.00556038
Iteration 4689, loss = 0.00555886
Iteration 4690, loss = 0.00555719
Iteration 4691, loss = 0.00555555
Iteration 4692, loss = 0.00555389
Iteration 4693, loss = 0.00555249
Iteration 4694, loss = 0.00555100
Iteration 4695, loss = 0.00554934
Iteration 4696, loss = 0.00554767
Iteration 4697, loss = 0.00554655
Iteration 4698, loss = 0.00554478
Iteration 4699, loss = 0.00554372
Iteration 4700, loss = 0.00554170
Iteration 4701, loss = 0.00554012
Iteration 4702, loss = 0.00553858
Iteration 4703, loss = 0.00553713
Iteration 4704, loss = 0.00553554
Iteration 4705, loss = 0.00553392
Iteration 4706, loss = 0.00553245
Iteration 4707, loss = 0.00553101
Iteration 4708, loss = 0.00552934
Iteration 4709, loss = 0.00552777
Iteration 4710, loss = 0.00552627
Iteration 4711, loss = 0.00552457
Iteration 4712, loss = 0.00552336
Iteration 4713, loss = 0.00552169
Iteration 4714, loss = 0.00552002
Iteration 4715, loss = 0.00551860
Iteration 4716, loss = 0.00551710
Iteration 4717, loss = 0.00551586
Iteration 4718, loss = 0.00551435
Iteration 4719, loss = 0.00551262
Iteration 4720, loss = 0.00551100
Iteration 4721, loss = 0.00550916
Iteration 4722, loss = 0.00550741
Iteration 4723, loss = 0.00550605
Iteration 4724, loss = 0.00550406
Iteration 4725, loss = 0.00550216
Iteration 4726, loss = 0.00550058
Iteration 4727, loss = 0.00549885
Iteration 4728, loss = 0.00549770
Iteration 4729, loss = 0.00549579
Iteration 4730, loss = 0.00549431
Iteration 4731, loss = 0.00549312
Iteration 4732, loss = 0.00549154
Iteration 4733, loss = 0.00549017
Iteration 4734, loss = 0.00548865
Iteration 4735, loss = 0.00548715
Iteration 4736, loss = 0.00548582
Iteration 4737, loss = 0.00548436
Iteration 4738, loss = 0.00548278
Iteration 4739, loss = 0.00548183
Iteration 4740, loss = 0.00547963
Iteration 4741, loss = 0.00547822
Iteration 4742, loss = 0.00547659
Iteration 4743, loss = 0.00547504
Iteration 4744, loss = 0.00547344
Iteration 4745, loss = 0.00547200
Iteration 4746, loss = 0.00547044
Iteration 4747, loss = 0.00546908
Iteration 4748, loss = 0.00546765
Iteration 4749, loss = 0.00546617
Iteration 4750, loss = 0.00546436
Iteration 4751, loss = 0.00546307
Iteration 4752, loss = 0.00546128
Iteration 4753, loss = 0.00545902
Iteration 4754, loss = 0.00545751
Iteration 4755, loss = 0.00545584
Iteration 4756, loss = 0.00545399
Iteration 4757, loss = 0.00545231
Iteration 4758, loss = 0.00545153
Iteration 4759, loss = 0.00544942
Iteration 4760, loss = 0.00544792
Iteration 4761, loss = 0.00544697
Iteration 4762, loss = 0.00544492
Iteration 4763, loss = 0.00544337
Iteration 4764, loss = 0.00544188
Iteration 4765, loss = 0.00544023
Iteration 4766, loss = 0.00543856
Iteration 4767, loss = 0.00543707
Iteration 4768, loss = 0.00543543
Iteration 4769, loss = 0.00543377
Iteration 4770, loss = 0.00543221
Iteration 4771, loss = 0.00543065
Iteration 4772, loss = 0.00542907
Iteration 4773, loss = 0.00542748
Iteration 4774, loss = 0.00542594
Iteration 4775, loss = 0.00542436
Iteration 4776, loss = 0.00542281
Iteration 4777, loss = 0.00542128
Iteration 4778, loss = 0.00541960
Iteration 4779, loss = 0.00541837
Iteration 4780, loss = 0.00541688
Iteration 4781, loss = 0.00541510
Iteration 4782, loss = 0.00541352
Iteration 4783, loss = 0.00541222
Iteration 4784, loss = 0.00541085
Iteration 4785, loss = 0.00540902
Iteration 4786, loss = 0.00540777
Iteration 4787, loss = 0.00540685
Iteration 4788, loss = 0.00540424
Iteration 4789, loss = 0.00540283
Iteration 4790, loss = 0.00540093
Iteration 4791, loss = 0.00539931
Iteration 4792, loss = 0.00539760
Iteration 4793, loss = 0.00539627
Iteration 4794, loss = 0.00539477
Iteration 4795, loss = 0.00539269
Iteration 4796, loss = 0.00539113
Iteration 4797, loss = 0.00538944
Iteration 4798, loss = 0.00538775
Iteration 4799, loss = 0.00538660
Iteration 4800, loss = 0.00538460
Iteration 4801, loss = 0.00538308
Iteration 4802, loss = 0.00538161
Iteration 4803, loss = 0.00538121
Iteration 4804, loss = 0.00537862
Iteration 4805, loss = 0.00537706
Iteration 4806, loss = 0.00537629
Iteration 4807, loss = 0.00537374
Iteration 4808, loss = 0.00537216
Iteration 4809, loss = 0.00537105
Iteration 4810, loss = 0.00536919
Iteration 4811, loss = 0.00536754
Iteration 4812, loss = 0.00536586
Iteration 4813, loss = 0.00536453
Iteration 4814, loss = 0.00536299
Iteration 4815, loss = 0.00536163
Iteration 4816, loss = 0.00535968
Iteration 4817, loss = 0.00535807
Iteration 4818, loss = 0.00535630
Iteration 4819, loss = 0.00535451
Iteration 4820, loss = 0.00535371
Iteration 4821, loss = 0.00535173
Iteration 4822, loss = 0.00535038
Iteration 4823, loss = 0.00534864
Iteration 4824, loss = 0.00534699
Iteration 4825, loss = 0.00534540
Iteration 4826, loss = 0.00534411
Iteration 4827, loss = 0.00534243
Iteration 4828, loss = 0.00534094
Iteration 4829, loss = 0.00533869
Iteration 4830, loss = 0.00533699
Iteration 4831, loss = 0.00533553
Iteration 4832, loss = 0.00533358
Iteration 4833, loss = 0.00533177
Iteration 4834, loss = 0.00533110
Iteration 4835, loss = 0.00532857
Iteration 4836, loss = 0.00532730
Iteration 4837, loss = 0.00532533
Iteration 4838, loss = 0.00532347
Iteration 4839, loss = 0.00532234
Iteration 4840, loss = 0.00532065
Iteration 4841, loss = 0.00531885
Iteration 4842, loss = 0.00531744
Iteration 4843, loss = 0.00531586
Iteration 4844, loss = 0.00531435
Iteration 4845, loss = 0.00531300
Iteration 4846, loss = 0.00531152
Iteration 4847, loss = 0.00530998
Iteration 4848, loss = 0.00530837
Iteration 4849, loss = 0.00530691
Iteration 4850, loss = 0.00530559
Iteration 4851, loss = 0.00530416
Iteration 4852, loss = 0.00530260
Iteration 4853, loss = 0.00530090
Iteration 4854, loss = 0.00530007
Iteration 4855, loss = 0.00529804
Iteration 4856, loss = 0.00529618
Iteration 4857, loss = 0.00529477
Iteration 4858, loss = 0.00529320
Iteration 4859, loss = 0.00529136
Iteration 4860, loss = 0.00529004
Iteration 4861, loss = 0.00528833
Iteration 4862, loss = 0.00528678
Iteration 4863, loss = 0.00528541
Iteration 4864, loss = 0.00528379
Iteration 4865, loss = 0.00528237
Iteration 4866, loss = 0.00528086
Iteration 4867, loss = 0.00527920
Iteration 4868, loss = 0.00527808
Iteration 4869, loss = 0.00527694
Iteration 4870, loss = 0.00527583
Iteration 4871, loss = 0.00527417
Iteration 4872, loss = 0.00527406
Iteration 4873, loss = 0.00527164
Iteration 4874, loss = 0.00527009
Iteration 4875, loss = 0.00526854
Iteration 4876, loss = 0.00526726
Iteration 4877, loss = 0.00526547
Iteration 4878, loss = 0.00526371
Iteration 4879, loss = 0.00526239
Iteration 4880, loss = 0.00526105
Iteration 4881, loss = 0.00525920
Iteration 4882, loss = 0.00525761
Iteration 4883, loss = 0.00525599
Iteration 4884, loss = 0.00525455
Iteration 4885, loss = 0.00525300
Iteration 4886, loss = 0.00525193
Iteration 4887, loss = 0.00524949
Iteration 4888, loss = 0.00524821
Iteration 4889, loss = 0.00524640
Iteration 4890, loss = 0.00524456
Iteration 4891, loss = 0.00524294
Iteration 4892, loss = 0.00524124
Iteration 4893, loss = 0.00523987
Iteration 4894, loss = 0.00523819
Iteration 4895, loss = 0.00523687
Iteration 4896, loss = 0.00523510
Iteration 4897, loss = 0.00523408
Iteration 4898, loss = 0.00523214
Iteration 4899, loss = 0.00523124
Iteration 4900, loss = 0.00522992
Iteration 4901, loss = 0.00522795
Iteration 4902, loss = 0.00522647
Iteration 4903, loss = 0.00522507
Iteration 4904, loss = 0.00522341
Iteration 4905, loss = 0.00522208
Iteration 4906, loss = 0.00522069
Iteration 4907, loss = 0.00521899
Iteration 4908, loss = 0.00521747
Iteration 4909, loss = 0.00521601
Iteration 4910, loss = 0.00521426
Iteration 4911, loss = 0.00521303
Iteration 4912, loss = 0.00521106
Iteration 4913, loss = 0.00520965
Iteration 4914, loss = 0.00520854
Iteration 4915, loss = 0.00520718
Iteration 4916, loss = 0.00520525
Iteration 4917, loss = 0.00520363
Iteration 4918, loss = 0.00520192
Iteration 4919, loss = 0.00520048
Iteration 4920, loss = 0.00519859
Iteration 4921, loss = 0.00519715
Iteration 4922, loss = 0.00519532
Iteration 4923, loss = 0.00519383
Iteration 4924, loss = 0.00519218
Iteration 4925, loss = 0.00519070
Iteration 4926, loss = 0.00518924
Iteration 4927, loss = 0.00518793
Iteration 4928, loss = 0.00518652
Iteration 4929, loss = 0.00518481
Iteration 4930, loss = 0.00518380
Iteration 4931, loss = 0.00518189
Iteration 4932, loss = 0.00518027
Iteration 4933, loss = 0.00517906
Iteration 4934, loss = 0.00517748
Iteration 4935, loss = 0.00517610
Iteration 4936, loss = 0.00517446
Iteration 4937, loss = 0.00517323
Iteration 4938, loss = 0.00517141
Iteration 4939, loss = 0.00516988
Iteration 4940, loss = 0.00516817
Iteration 4941, loss = 0.00516693
Iteration 4942, loss = 0.00516562
Iteration 4943, loss = 0.00516381
Iteration 4944, loss = 0.00516235
Iteration 4945, loss = 0.00516062
Iteration 4946, loss = 0.00515948
Iteration 4947, loss = 0.00515775
Iteration 4948, loss = 0.00515647
Iteration 4949, loss = 0.00515508
Iteration 4950, loss = 0.00515389
Iteration 4951, loss = 0.00515232
Iteration 4952, loss = 0.00515079
Iteration 4953, loss = 0.00514934
Iteration 4954, loss = 0.00514831
Iteration 4955, loss = 0.00514699
Iteration 4956, loss = 0.00514498
Iteration 4957, loss = 0.00514341
Iteration 4958, loss = 0.00514207
Iteration 4959, loss = 0.00514051
Iteration 4960, loss = 0.00513910
Iteration 4961, loss = 0.00513776
Iteration 4962, loss = 0.00513623
Iteration 4963, loss = 0.00513497
Iteration 4964, loss = 0.00513340
Iteration 4965, loss = 0.00513195
Iteration 4966, loss = 0.00513044
Iteration 4967, loss = 0.00512922
Iteration 4968, loss = 0.00512752
Iteration 4969, loss = 0.00512601
Iteration 4970, loss = 0.00512465
Iteration 4971, loss = 0.00512350
Iteration 4972, loss = 0.00512162
Iteration 4973, loss = 0.00512017
Iteration 4974, loss = 0.00511883
Iteration 4975, loss = 0.00511753
Iteration 4976, loss = 0.00511572
Iteration 4977, loss = 0.00511435
Iteration 4978, loss = 0.00511307
Iteration 4979, loss = 0.00511169
Iteration 4980, loss = 0.00511025
Iteration 4981, loss = 0.00510887
Iteration 4982, loss = 0.00510754
Iteration 4983, loss = 0.00510615
Iteration 4984, loss = 0.00510477
Iteration 4985, loss = 0.00510397
Iteration 4986, loss = 0.00510224
Iteration 4987, loss = 0.00510096
Iteration 4988, loss = 0.00509989
Iteration 4989, loss = 0.00509823
Iteration 4990, loss = 0.00509659
Iteration 4991, loss = 0.00509504
Iteration 4992, loss = 0.00509353
Iteration 4993, loss = 0.00509199
Iteration 4994, loss = 0.00509044
Iteration 4995, loss = 0.00508893
Iteration 4996, loss = 0.00508750
Iteration 4997, loss = 0.00508610
Iteration 4998, loss = 0.00508471
Iteration 4999, loss = 0.00508349
Iteration 5000, loss = 0.00508202
Iteration 5001, loss = 0.00508062
Iteration 5002, loss = 0.00507930
Iteration 5003, loss = 0.00507804
Iteration 5004, loss = 0.00507679
Iteration 5005, loss = 0.00507563
Iteration 5006, loss = 0.00507421
Iteration 5007, loss = 0.00507331
Iteration 5008, loss = 0.00507155
Iteration 5009, loss = 0.00507010
Iteration 5010, loss = 0.00506903
Iteration 5011, loss = 0.00506712
Iteration 5012, loss = 0.00506577
Iteration 5013, loss = 0.00506460
Iteration 5014, loss = 0.00506291
Iteration 5015, loss = 0.00506125
Iteration 5016, loss = 0.00506006
Iteration 5017, loss = 0.00505839
Iteration 5018, loss = 0.00505692
Iteration 5019, loss = 0.00505552
Iteration 5020, loss = 0.00505412
Iteration 5021, loss = 0.00505288
Iteration 5022, loss = 0.00505156
Iteration 5023, loss = 0.00505029
Iteration 5024, loss = 0.00504891
Iteration 5025, loss = 0.00504762
Iteration 5026, loss = 0.00504601
Iteration 5027, loss = 0.00504490
Iteration 5028, loss = 0.00504480
Iteration 5029, loss = 0.00504313
Iteration 5030, loss = 0.00504132
Iteration 5031, loss = 0.00504007
Iteration 5032, loss = 0.00503909
Iteration 5033, loss = 0.00503757
Iteration 5034, loss = 0.00503675
Iteration 5035, loss = 0.00503501
Iteration 5036, loss = 0.00503351
Iteration 5037, loss = 0.00503246
Iteration 5038, loss = 0.00503094
Iteration 5039, loss = 0.00502983
Iteration 5040, loss = 0.00502837
Iteration 5041, loss = 0.00502711
Iteration 5042, loss = 0.00502579
Iteration 5043, loss = 0.00502450
Iteration 5044, loss = 0.00502324
Iteration 5045, loss = 0.00502204
Iteration 5046, loss = 0.00502073
Iteration 5047, loss = 0.00501955
Iteration 5048, loss = 0.00501838
Iteration 5049, loss = 0.00501707
Iteration 5050, loss = 0.00501571
Iteration 5051, loss = 0.00501487
Iteration 5052, loss = 0.00501325
Iteration 5053, loss = 0.00501192
Iteration 5054, loss = 0.00501062
Iteration 5055, loss = 0.00500932
Iteration 5056, loss = 0.00500805
Iteration 5057, loss = 0.00500680
Iteration 5058, loss = 0.00500538
Iteration 5059, loss = 0.00500412
Iteration 5060, loss = 0.00500299
Iteration 5061, loss = 0.00500147
Iteration 5062, loss = 0.00499998
Iteration 5063, loss = 0.00499882
Iteration 5064, loss = 0.00499764
Iteration 5065, loss = 0.00499643
Iteration 5066, loss = 0.00499505
Iteration 5067, loss = 0.00499413
Iteration 5068, loss = 0.00499301
Iteration 5069, loss = 0.00499138
Iteration 5070, loss = 0.00499019
Iteration 5071, loss = 0.00498880
Iteration 5072, loss = 0.00498744
Iteration 5073, loss = 0.00498603
Iteration 5074, loss = 0.00498485
Iteration 5075, loss = 0.00498353
Iteration 5076, loss = 0.00498233
Iteration 5077, loss = 0.00498112
Iteration 5078, loss = 0.00498017
Iteration 5079, loss = 0.00497825
Iteration 5080, loss = 0.00497664
Iteration 5081, loss = 0.00497509
Iteration 5082, loss = 0.00497397
Iteration 5083, loss = 0.00497241
Iteration 5084, loss = 0.00497117
Iteration 5085, loss = 0.00496930
Iteration 5086, loss = 0.00496776
Iteration 5087, loss = 0.00496663
Iteration 5088, loss = 0.00496503
Iteration 5089, loss = 0.00496365
Iteration 5090, loss = 0.00496201
Iteration 5091, loss = 0.00496119
Iteration 5092, loss = 0.00495935
Iteration 5093, loss = 0.00495790
Iteration 5094, loss = 0.00495674
Iteration 5095, loss = 0.00495499
Iteration 5096, loss = 0.00495414
Iteration 5097, loss = 0.00495281
Iteration 5098, loss = 0.00495163
Iteration 5099, loss = 0.00495023
Iteration 5100, loss = 0.00494918
Iteration 5101, loss = 0.00494773
Iteration 5102, loss = 0.00494628
Iteration 5103, loss = 0.00494533
Iteration 5104, loss = 0.00494378
Iteration 5105, loss = 0.00494255
Iteration 5106, loss = 0.00494127
Iteration 5107, loss = 0.00493995
Iteration 5108, loss = 0.00493868
Iteration 5109, loss = 0.00493734
Iteration 5110, loss = 0.00493623
Iteration 5111, loss = 0.00493513
Iteration 5112, loss = 0.00493363
Iteration 5113, loss = 0.00493240
Iteration 5114, loss = 0.00493074
Iteration 5115, loss = 0.00492944
Iteration 5116, loss = 0.00492814
Iteration 5117, loss = 0.00492680
Iteration 5118, loss = 0.00492516
Iteration 5119, loss = 0.00492390
Iteration 5120, loss = 0.00492253
Iteration 5121, loss = 0.00492098
Iteration 5122, loss = 0.00491971
Iteration 5123, loss = 0.00491881
Iteration 5124, loss = 0.00491678
Iteration 5125, loss = 0.00491539
Iteration 5126, loss = 0.00491426
Iteration 5127, loss = 0.00491285
Iteration 5128, loss = 0.00491171
Iteration 5129, loss = 0.00491025
Iteration 5130, loss = 0.00490909
Iteration 5131, loss = 0.00490725
Iteration 5132, loss = 0.00490601
Iteration 5133, loss = 0.00490430
Iteration 5134, loss = 0.00490291
Iteration 5135, loss = 0.00490130
Iteration 5136, loss = 0.00489974
Iteration 5137, loss = 0.00489839
Iteration 5138, loss = 0.00489699
Iteration 5139, loss = 0.00489552
Iteration 5140, loss = 0.00489424
Iteration 5141, loss = 0.00489289
Iteration 5142, loss = 0.00489148
Iteration 5143, loss = 0.00489007
Iteration 5144, loss = 0.00488900
Iteration 5145, loss = 0.00488733
Iteration 5146, loss = 0.00488576
Iteration 5147, loss = 0.00488449
Iteration 5148, loss = 0.00488304
Iteration 5149, loss = 0.00488162
Iteration 5150, loss = 0.00488006
Iteration 5151, loss = 0.00487884
Iteration 5152, loss = 0.00487761
Iteration 5153, loss = 0.00487624
Iteration 5154, loss = 0.00487466
Iteration 5155, loss = 0.00487367
Iteration 5156, loss = 0.00487243
Iteration 5157, loss = 0.00487096
Iteration 5158, loss = 0.00486978
Iteration 5159, loss = 0.00486850
Iteration 5160, loss = 0.00486723
Iteration 5161, loss = 0.00486608
Iteration 5162, loss = 0.00486467
Iteration 5163, loss = 0.00486356
Iteration 5164, loss = 0.00486220
Iteration 5165, loss = 0.00486109
Iteration 5166, loss = 0.00485970
Iteration 5167, loss = 0.00485852
Iteration 5168, loss = 0.00485729
Iteration 5169, loss = 0.00485620
Iteration 5170, loss = 0.00485493
Iteration 5171, loss = 0.00485452
Iteration 5172, loss = 0.00485247
Iteration 5173, loss = 0.00485119
Iteration 5174, loss = 0.00484993
Iteration 5175, loss = 0.00484873
Iteration 5176, loss = 0.00484717
Iteration 5177, loss = 0.00484564
Iteration 5178, loss = 0.00484445
Iteration 5179, loss = 0.00484303
Iteration 5180, loss = 0.00484177
Iteration 5181, loss = 0.00484101
Iteration 5182, loss = 0.00483920
Iteration 5183, loss = 0.00483820
Iteration 5184, loss = 0.00483661
Iteration 5185, loss = 0.00483524
Iteration 5186, loss = 0.00483386
Iteration 5187, loss = 0.00483265
Iteration 5188, loss = 0.00483110
Iteration 5189, loss = 0.00482971
Iteration 5190, loss = 0.00482881
Iteration 5191, loss = 0.00482752
Iteration 5192, loss = 0.00482592
Iteration 5193, loss = 0.00482514
Iteration 5194, loss = 0.00482326
Iteration 5195, loss = 0.00482211
Iteration 5196, loss = 0.00482061
Iteration 5197, loss = 0.00481945
Iteration 5198, loss = 0.00481826
Iteration 5199, loss = 0.00481699
Iteration 5200, loss = 0.00481575
Iteration 5201, loss = 0.00481459
Iteration 5202, loss = 0.00481327
Iteration 5203, loss = 0.00481222
Iteration 5204, loss = 0.00481066
Iteration 5205, loss = 0.00480967
Iteration 5206, loss = 0.00480835
Iteration 5207, loss = 0.00480700
Iteration 5208, loss = 0.00480582
Iteration 5209, loss = 0.00480445
Iteration 5210, loss = 0.00480313
Iteration 5211, loss = 0.00480189
Iteration 5212, loss = 0.00480074
Iteration 5213, loss = 0.00479934
Iteration 5214, loss = 0.00479859
Iteration 5215, loss = 0.00479721
Iteration 5216, loss = 0.00479609
Iteration 5217, loss = 0.00479492
Iteration 5218, loss = 0.00479367
Iteration 5219, loss = 0.00479246
Iteration 5220, loss = 0.00479136
Iteration 5221, loss = 0.00478991
Iteration 5222, loss = 0.00478904
Iteration 5223, loss = 0.00478795
Iteration 5224, loss = 0.00478627
Iteration 5225, loss = 0.00478498
Iteration 5226, loss = 0.00478375
Iteration 5227, loss = 0.00478250
Iteration 5228, loss = 0.00478142
Iteration 5229, loss = 0.00478010
Iteration 5230, loss = 0.00477892
Iteration 5231, loss = 0.00477757
Iteration 5232, loss = 0.00477652
Iteration 5233, loss = 0.00477527
Iteration 5234, loss = 0.00477438
Iteration 5235, loss = 0.00477311
Iteration 5236, loss = 0.00477186
Iteration 5237, loss = 0.00477050
Iteration 5238, loss = 0.00476903
Iteration 5239, loss = 0.00476767
Iteration 5240, loss = 0.00476638
Iteration 5241, loss = 0.00476473
Iteration 5242, loss = 0.00476410
Iteration 5243, loss = 0.00476223
Iteration 5244, loss = 0.00476145
Iteration 5245, loss = 0.00476049
Iteration 5246, loss = 0.00475889
Iteration 5247, loss = 0.00475831
Iteration 5248, loss = 0.00475659
Iteration 5249, loss = 0.00475530
Iteration 5250, loss = 0.00475454
Iteration 5251, loss = 0.00475298
Iteration 5252, loss = 0.00475181
Iteration 5253, loss = 0.00475056
Iteration 5254, loss = 0.00474944
Iteration 5255, loss = 0.00474821
Iteration 5256, loss = 0.00474657
Iteration 5257, loss = 0.00474505
Iteration 5258, loss = 0.00474362
Iteration 5259, loss = 0.00474254
Iteration 5260, loss = 0.00474119
Iteration 5261, loss = 0.00473978
Iteration 5262, loss = 0.00473846
Iteration 5263, loss = 0.00473710
Iteration 5264, loss = 0.00473608
Iteration 5265, loss = 0.00473452
Iteration 5266, loss = 0.00473368
Iteration 5267, loss = 0.00473196
Iteration 5268, loss = 0.00473068
Iteration 5269, loss = 0.00472923
Iteration 5270, loss = 0.00472790
Iteration 5271, loss = 0.00472673
Iteration 5272, loss = 0.00472563
Iteration 5273, loss = 0.00472420
Iteration 5274, loss = 0.00472279
Iteration 5275, loss = 0.00472172
Iteration 5276, loss = 0.00472097
Iteration 5277, loss = 0.00471937
Iteration 5278, loss = 0.00471817
Iteration 5279, loss = 0.00471699
Iteration 5280, loss = 0.00471588
Iteration 5281, loss = 0.00471483
Iteration 5282, loss = 0.00471365
Iteration 5283, loss = 0.00471264
Iteration 5284, loss = 0.00471137
Iteration 5285, loss = 0.00471013
Iteration 5286, loss = 0.00470892
Iteration 5287, loss = 0.00470760
Iteration 5288, loss = 0.00470623
Iteration 5289, loss = 0.00470498
Iteration 5290, loss = 0.00470377
Iteration 5291, loss = 0.00470250
Iteration 5292, loss = 0.00470128
Iteration 5293, loss = 0.00470012
Iteration 5294, loss = 0.00469890
Iteration 5295, loss = 0.00469777
Iteration 5296, loss = 0.00469640
Iteration 5297, loss = 0.00469521
Iteration 5298, loss = 0.00469392
Iteration 5299, loss = 0.00469271
Iteration 5300, loss = 0.00469166
Iteration 5301, loss = 0.00469034
Iteration 5302, loss = 0.00468947
Iteration 5303, loss = 0.00468802
Iteration 5304, loss = 0.00468669
Iteration 5305, loss = 0.00468534
Iteration 5306, loss = 0.00468397
Iteration 5307, loss = 0.00468271
Iteration 5308, loss = 0.00468204
Iteration 5309, loss = 0.00468025
Iteration 5310, loss = 0.00467907
Iteration 5311, loss = 0.00467777
Iteration 5312, loss = 0.00467628
Iteration 5313, loss = 0.00467527
Iteration 5314, loss = 0.00467387
Iteration 5315, loss = 0.00467260
Iteration 5316, loss = 0.00467148
Iteration 5317, loss = 0.00467103
Iteration 5318, loss = 0.00466912
Iteration 5319, loss = 0.00466744
Iteration 5320, loss = 0.00466654
Iteration 5321, loss = 0.00466504
Iteration 5322, loss = 0.00466373
Iteration 5323, loss = 0.00466262
Iteration 5324, loss = 0.00466129
Iteration 5325, loss = 0.00465999
Iteration 5326, loss = 0.00465865
Iteration 5327, loss = 0.00465728
Iteration 5328, loss = 0.00465616
Iteration 5329, loss = 0.00465523
Iteration 5330, loss = 0.00465358
Iteration 5331, loss = 0.00465251
Iteration 5332, loss = 0.00465103
Iteration 5333, loss = 0.00464978
Iteration 5334, loss = 0.00464843
Iteration 5335, loss = 0.00464719
Iteration 5336, loss = 0.00464598
Iteration 5337, loss = 0.00464496
Iteration 5338, loss = 0.00464347
Iteration 5339, loss = 0.00464225
Iteration 5340, loss = 0.00464111
Iteration 5341, loss = 0.00463985
Iteration 5342, loss = 0.00463879
Iteration 5343, loss = 0.00463742
Iteration 5344, loss = 0.00463637
Iteration 5345, loss = 0.00463499
Iteration 5346, loss = 0.00463373
Iteration 5347, loss = 0.00463291
Iteration 5348, loss = 0.00463152
Iteration 5349, loss = 0.00463033
Iteration 5350, loss = 0.00462919
Iteration 5351, loss = 0.00462818
Iteration 5352, loss = 0.00462685
Iteration 5353, loss = 0.00462578
Iteration 5354, loss = 0.00462463
Iteration 5355, loss = 0.00462336
Iteration 5356, loss = 0.00462204
Iteration 5357, loss = 0.00462069
Iteration 5358, loss = 0.00461965
Iteration 5359, loss = 0.00461935
Iteration 5360, loss = 0.00461731
Iteration 5361, loss = 0.00461631
Iteration 5362, loss = 0.00461530
Iteration 5363, loss = 0.00461379
Iteration 5364, loss = 0.00461270
Iteration 5365, loss = 0.00461164
Iteration 5366, loss = 0.00461091
Iteration 5367, loss = 0.00460884
Iteration 5368, loss = 0.00460774
Iteration 5369, loss = 0.00460657
Iteration 5370, loss = 0.00460529
Iteration 5371, loss = 0.00460458
Iteration 5372, loss = 0.00460295
Iteration 5373, loss = 0.00460207
Iteration 5374, loss = 0.00460096
Iteration 5375, loss = 0.00459993
Iteration 5376, loss = 0.00459867
Iteration 5377, loss = 0.00459747
Iteration 5378, loss = 0.00459684
Iteration 5379, loss = 0.00459446
Iteration 5380, loss = 0.00459349
Iteration 5381, loss = 0.00459270
Iteration 5382, loss = 0.00459099
Iteration 5383, loss = 0.00458976
Iteration 5384, loss = 0.00458889
Iteration 5385, loss = 0.00458745
Iteration 5386, loss = 0.00458646
Iteration 5387, loss = 0.00458535
Iteration 5388, loss = 0.00458411
Iteration 5389, loss = 0.00458298
Iteration 5390, loss = 0.00458182
Iteration 5391, loss = 0.00458055
Iteration 5392, loss = 0.00457948
Iteration 5393, loss = 0.00457809
Iteration 5394, loss = 0.00457697
Iteration 5395, loss = 0.00457596
Iteration 5396, loss = 0.00457480
Iteration 5397, loss = 0.00457386
Iteration 5398, loss = 0.00457228
Iteration 5399, loss = 0.00457124
Iteration 5400, loss = 0.00456999
Iteration 5401, loss = 0.00456883
Iteration 5402, loss = 0.00456756
Iteration 5403, loss = 0.00456638
Iteration 5404, loss = 0.00456545
Iteration 5405, loss = 0.00456428
Iteration 5406, loss = 0.00456292
Iteration 5407, loss = 0.00456210
Iteration 5408, loss = 0.00456054
Iteration 5409, loss = 0.00455935
Iteration 5410, loss = 0.00455803
Iteration 5411, loss = 0.00455702
Iteration 5412, loss = 0.00455578
Iteration 5413, loss = 0.00455461
Iteration 5414, loss = 0.00455334
Iteration 5415, loss = 0.00455175
Iteration 5416, loss = 0.00455063
Iteration 5417, loss = 0.00454934
Iteration 5418, loss = 0.00454800
Iteration 5419, loss = 0.00454680
Iteration 5420, loss = 0.00454539
Iteration 5421, loss = 0.00454470
Iteration 5422, loss = 0.00454301
Iteration 5423, loss = 0.00454149
Iteration 5424, loss = 0.00454036
Iteration 5425, loss = 0.00453884
Iteration 5426, loss = 0.00453769
Iteration 5427, loss = 0.00453634
Iteration 5428, loss = 0.00453510
Iteration 5429, loss = 0.00453394
Iteration 5430, loss = 0.00453261
Iteration 5431, loss = 0.00453149
Iteration 5432, loss = 0.00453030
Iteration 5433, loss = 0.00452915
Iteration 5434, loss = 0.00452794
Iteration 5435, loss = 0.00452679
Iteration 5436, loss = 0.00452557
Iteration 5437, loss = 0.00452454
Iteration 5438, loss = 0.00452338
Iteration 5439, loss = 0.00452221
Iteration 5440, loss = 0.00452123
Iteration 5441, loss = 0.00451990
Iteration 5442, loss = 0.00451879
Iteration 5443, loss = 0.00451758
Iteration 5444, loss = 0.00451726
Iteration 5445, loss = 0.00451534
Iteration 5446, loss = 0.00451419
Iteration 5447, loss = 0.00451286
Iteration 5448, loss = 0.00451158
Iteration 5449, loss = 0.00451074
Iteration 5450, loss = 0.00450941
Iteration 5451, loss = 0.00450830
Iteration 5452, loss = 0.00450715
Iteration 5453, loss = 0.00450587
Iteration 5454, loss = 0.00450494
Iteration 5455, loss = 0.00450364
Iteration 5456, loss = 0.00450245
Iteration 5457, loss = 0.00450135
Iteration 5458, loss = 0.00450019
Iteration 5459, loss = 0.00449921
Iteration 5460, loss = 0.00449903
Iteration 5461, loss = 0.00449720
Iteration 5462, loss = 0.00449605
Iteration 5463, loss = 0.00449498
Iteration 5464, loss = 0.00449384
Iteration 5465, loss = 0.00449288
Iteration 5466, loss = 0.00449165
Iteration 5467, loss = 0.00449054
Iteration 5468, loss = 0.00448936
Iteration 5469, loss = 0.00448841
Iteration 5470, loss = 0.00448707
Iteration 5471, loss = 0.00448614
Iteration 5472, loss = 0.00448476
Iteration 5473, loss = 0.00448376
Iteration 5474, loss = 0.00448241
Iteration 5475, loss = 0.00448168
Iteration 5476, loss = 0.00448032
Iteration 5477, loss = 0.00447930
Iteration 5478, loss = 0.00447818
Iteration 5479, loss = 0.00447709
Iteration 5480, loss = 0.00447589
Iteration 5481, loss = 0.00447475
Iteration 5482, loss = 0.00447368
Iteration 5483, loss = 0.00447261
Iteration 5484, loss = 0.00447203
Iteration 5485, loss = 0.00447040
Iteration 5486, loss = 0.00446929
Iteration 5487, loss = 0.00446830
Iteration 5488, loss = 0.00446708
Iteration 5489, loss = 0.00446597
Iteration 5490, loss = 0.00446483
Iteration 5491, loss = 0.00446386
Iteration 5492, loss = 0.00446282
Iteration 5493, loss = 0.00446177
Iteration 5494, loss = 0.00446096
Iteration 5495, loss = 0.00445984
Iteration 5496, loss = 0.00445856
Iteration 5497, loss = 0.00445738
Iteration 5498, loss = 0.00445602
Iteration 5499, loss = 0.00445542
Iteration 5500, loss = 0.00445365
Iteration 5501, loss = 0.00445313
Iteration 5502, loss = 0.00445169
Iteration 5503, loss = 0.00445048
Iteration 5504, loss = 0.00444923
Iteration 5505, loss = 0.00444823
Iteration 5506, loss = 0.00444708
Iteration 5507, loss = 0.00444590
Iteration 5508, loss = 0.00444468
Iteration 5509, loss = 0.00444375
Iteration 5510, loss = 0.00444274
Iteration 5511, loss = 0.00444161
Iteration 5512, loss = 0.00444053
Iteration 5513, loss = 0.00443963
Iteration 5514, loss = 0.00443867
Iteration 5515, loss = 0.00443740
Iteration 5516, loss = 0.00443641
Iteration 5517, loss = 0.00443538
Iteration 5518, loss = 0.00443411
Iteration 5519, loss = 0.00443286
Iteration 5520, loss = 0.00443215
Iteration 5521, loss = 0.00443161
Iteration 5522, loss = 0.00443012
Iteration 5523, loss = 0.00442882
Iteration 5524, loss = 0.00442781
Iteration 5525, loss = 0.00442657
Iteration 5526, loss = 0.00442545
Iteration 5527, loss = 0.00442450
Iteration 5528, loss = 0.00442317
Iteration 5529, loss = 0.00442246
Iteration 5530, loss = 0.00442096
Iteration 5531, loss = 0.00441978
Iteration 5532, loss = 0.00441909
Iteration 5533, loss = 0.00441733
Iteration 5534, loss = 0.00441624
Iteration 5535, loss = 0.00441499
Iteration 5536, loss = 0.00441372
Iteration 5537, loss = 0.00441283
Iteration 5538, loss = 0.00441159
Iteration 5539, loss = 0.00441065
Iteration 5540, loss = 0.00440933
Iteration 5541, loss = 0.00440786
Iteration 5542, loss = 0.00440679
Iteration 5543, loss = 0.00440566
Iteration 5544, loss = 0.00440441
Iteration 5545, loss = 0.00440333
Iteration 5546, loss = 0.00440209
Iteration 5547, loss = 0.00440096
Iteration 5548, loss = 0.00439984
Iteration 5549, loss = 0.00439846
Iteration 5550, loss = 0.00439757
Iteration 5551, loss = 0.00439636
Iteration 5552, loss = 0.00439503
Iteration 5553, loss = 0.00439402
Iteration 5554, loss = 0.00439304
Iteration 5555, loss = 0.00439139
Iteration 5556, loss = 0.00439052
Iteration 5557, loss = 0.00438897
Iteration 5558, loss = 0.00438799
Iteration 5559, loss = 0.00438692
Iteration 5560, loss = 0.00438558
Iteration 5561, loss = 0.00438463
Iteration 5562, loss = 0.00438391
Iteration 5563, loss = 0.00438242
Iteration 5564, loss = 0.00438121
Iteration 5565, loss = 0.00438066
Iteration 5566, loss = 0.00437903
Iteration 5567, loss = 0.00437805
Iteration 5568, loss = 0.00437681
Iteration 5569, loss = 0.00437567
Iteration 5570, loss = 0.00437462
Iteration 5571, loss = 0.00437351
Iteration 5572, loss = 0.00437274
Iteration 5573, loss = 0.00437150
Iteration 5574, loss = 0.00437044
Iteration 5575, loss = 0.00436908
Iteration 5576, loss = 0.00436795
Iteration 5577, loss = 0.00436687
Iteration 5578, loss = 0.00436552
Iteration 5579, loss = 0.00436466
Iteration 5580, loss = 0.00436313
Iteration 5581, loss = 0.00436205
Iteration 5582, loss = 0.00436090
Iteration 5583, loss = 0.00435981
Iteration 5584, loss = 0.00435876
Iteration 5585, loss = 0.00435782
Iteration 5586, loss = 0.00435685
Iteration 5587, loss = 0.00435601
Iteration 5588, loss = 0.00435508
Iteration 5589, loss = 0.00435404
Iteration 5590, loss = 0.00435304
Iteration 5591, loss = 0.00435212
Iteration 5592, loss = 0.00435108
Iteration 5593, loss = 0.00435002
Iteration 5594, loss = 0.00434900
Iteration 5595, loss = 0.00434826
Iteration 5596, loss = 0.00434704
Iteration 5597, loss = 0.00434612
Iteration 5598, loss = 0.00434517
Iteration 5599, loss = 0.00434434
Iteration 5600, loss = 0.00434248
Iteration 5601, loss = 0.00434188
Iteration 5602, loss = 0.00434037
Iteration 5603, loss = 0.00433978
Iteration 5604, loss = 0.00433833
Iteration 5605, loss = 0.00433738
Iteration 5606, loss = 0.00433635
Iteration 5607, loss = 0.00433511
Iteration 5608, loss = 0.00433414
Iteration 5609, loss = 0.00433352
Iteration 5610, loss = 0.00433211
Iteration 5611, loss = 0.00433088
Iteration 5612, loss = 0.00432997
Iteration 5613, loss = 0.00432851
Iteration 5614, loss = 0.00432735
Iteration 5615, loss = 0.00432595
Iteration 5616, loss = 0.00432483
Iteration 5617, loss = 0.00432345
Iteration 5618, loss = 0.00432241
Iteration 5619, loss = 0.00432112
Iteration 5620, loss = 0.00432005
Iteration 5621, loss = 0.00431869
Iteration 5622, loss = 0.00431766
Iteration 5623, loss = 0.00431621
Iteration 5624, loss = 0.00431530
Iteration 5625, loss = 0.00431408
Iteration 5626, loss = 0.00431342
Iteration 5627, loss = 0.00431196
Iteration 5628, loss = 0.00431075
Iteration 5629, loss = 0.00430972
Iteration 5630, loss = 0.00430869
Iteration 5631, loss = 0.00430797
Iteration 5632, loss = 0.00430699
Iteration 5633, loss = 0.00430570
Iteration 5634, loss = 0.00430463
Iteration 5635, loss = 0.00430353
Iteration 5636, loss = 0.00430258
Iteration 5637, loss = 0.00430148
Iteration 5638, loss = 0.00430044
Iteration 5639, loss = 0.00429932
Iteration 5640, loss = 0.00429831
Iteration 5641, loss = 0.00429747
Iteration 5642, loss = 0.00429638
Iteration 5643, loss = 0.00429571
Iteration 5644, loss = 0.00429411
Iteration 5645, loss = 0.00429314
Iteration 5646, loss = 0.00429214
Iteration 5647, loss = 0.00429104
Iteration 5648, loss = 0.00429006
Iteration 5649, loss = 0.00428886
Iteration 5650, loss = 0.00428799
Iteration 5651, loss = 0.00428675
Iteration 5652, loss = 0.00428565
Iteration 5653, loss = 0.00428469
Iteration 5654, loss = 0.00428376
Iteration 5655, loss = 0.00428321
Iteration 5656, loss = 0.00428171
Iteration 5657, loss = 0.00428077
Iteration 5658, loss = 0.00427972
Iteration 5659, loss = 0.00427882
Iteration 5660, loss = 0.00427774
Iteration 5661, loss = 0.00427670
Iteration 5662, loss = 0.00427585
Iteration 5663, loss = 0.00427479
Iteration 5664, loss = 0.00427374
Iteration 5665, loss = 0.00427277
Iteration 5666, loss = 0.00427192
Iteration 5667, loss = 0.00427109
Iteration 5668, loss = 0.00427017
Iteration 5669, loss = 0.00426897
Iteration 5670, loss = 0.00426795
Iteration 5671, loss = 0.00426698
Iteration 5672, loss = 0.00426599
Iteration 5673, loss = 0.00426506
Iteration 5674, loss = 0.00426377
Iteration 5675, loss = 0.00426265
Iteration 5676, loss = 0.00426178
Iteration 5677, loss = 0.00426061
Iteration 5678, loss = 0.00425951
Iteration 5679, loss = 0.00425859
Iteration 5680, loss = 0.00425752
Iteration 5681, loss = 0.00425659
Iteration 5682, loss = 0.00425539
Iteration 5683, loss = 0.00425434
Iteration 5684, loss = 0.00425365
Iteration 5685, loss = 0.00425252
Iteration 5686, loss = 0.00425146
Iteration 5687, loss = 0.00425035
Iteration 5688, loss = 0.00424937
Iteration 5689, loss = 0.00424833
Iteration 5690, loss = 0.00424749
Iteration 5691, loss = 0.00424649
Iteration 5692, loss = 0.00424575
Iteration 5693, loss = 0.00424460
Iteration 5694, loss = 0.00424379
Iteration 5695, loss = 0.00424236
Iteration 5696, loss = 0.00424129
Iteration 5697, loss = 0.00424016
Iteration 5698, loss = 0.00423901
Iteration 5699, loss = 0.00423827
Iteration 5700, loss = 0.00423689
Iteration 5701, loss = 0.00423582
Iteration 5702, loss = 0.00423473
Iteration 5703, loss = 0.00423371
Iteration 5704, loss = 0.00423286
Iteration 5705, loss = 0.00423163
Iteration 5706, loss = 0.00423059
Iteration 5707, loss = 0.00422953
Iteration 5708, loss = 0.00422865
Iteration 5709, loss = 0.00422773
Iteration 5710, loss = 0.00422734
Iteration 5711, loss = 0.00422555
Iteration 5712, loss = 0.00422477
Iteration 5713, loss = 0.00422379
Iteration 5714, loss = 0.00422261
Iteration 5715, loss = 0.00422138
Iteration 5716, loss = 0.00422035
Iteration 5717, loss = 0.00421922
Iteration 5718, loss = 0.00421810
Iteration 5719, loss = 0.00421721
Iteration 5720, loss = 0.00421599
Iteration 5721, loss = 0.00421515
Iteration 5722, loss = 0.00421405
Iteration 5723, loss = 0.00421298
Iteration 5724, loss = 0.00421184
Iteration 5725, loss = 0.00421072
Iteration 5726, loss = 0.00420980
Iteration 5727, loss = 0.00420883
Iteration 5728, loss = 0.00420799
Iteration 5729, loss = 0.00420701
Iteration 5730, loss = 0.00420641
Iteration 5731, loss = 0.00420514
Iteration 5732, loss = 0.00420428
Iteration 5733, loss = 0.00420291
Iteration 5734, loss = 0.00420187
Iteration 5735, loss = 0.00420085
Iteration 5736, loss = 0.00419970
Iteration 5737, loss = 0.00419882
Iteration 5738, loss = 0.00419763
Iteration 5739, loss = 0.00419666
Iteration 5740, loss = 0.00419573
Iteration 5741, loss = 0.00419474
Iteration 5742, loss = 0.00419378
Iteration 5743, loss = 0.00419293
Iteration 5744, loss = 0.00419211
Iteration 5745, loss = 0.00419103
Iteration 5746, loss = 0.00419137
Iteration 5747, loss = 0.00418938
Iteration 5748, loss = 0.00418815
Iteration 5749, loss = 0.00418722
Iteration 5750, loss = 0.00418606
Iteration 5751, loss = 0.00418509
Iteration 5752, loss = 0.00418414
Iteration 5753, loss = 0.00418312
Iteration 5754, loss = 0.00418217
Iteration 5755, loss = 0.00418138
Iteration 5756, loss = 0.00418017
Iteration 5757, loss = 0.00417925
Iteration 5758, loss = 0.00417835
Iteration 5759, loss = 0.00417757
Iteration 5760, loss = 0.00417582
Iteration 5761, loss = 0.00417465
Iteration 5762, loss = 0.00417363
Iteration 5763, loss = 0.00417241
Iteration 5764, loss = 0.00417134
Iteration 5765, loss = 0.00417017
Iteration 5766, loss = 0.00416909
Iteration 5767, loss = 0.00416804
Iteration 5768, loss = 0.00416695
Iteration 5769, loss = 0.00416571
Iteration 5770, loss = 0.00416489
Iteration 5771, loss = 0.00416355
Iteration 5772, loss = 0.00416261
Iteration 5773, loss = 0.00416157
Iteration 5774, loss = 0.00416051
Iteration 5775, loss = 0.00415969
Iteration 5776, loss = 0.00415833
Iteration 5777, loss = 0.00415736
Iteration 5778, loss = 0.00415642
Iteration 5779, loss = 0.00415525
Iteration 5780, loss = 0.00415417
Iteration 5781, loss = 0.00415343
Iteration 5782, loss = 0.00415229
Iteration 5783, loss = 0.00415158
Iteration 5784, loss = 0.00415024
Iteration 5785, loss = 0.00414918
Iteration 5786, loss = 0.00414816
Iteration 5787, loss = 0.00414712
Iteration 5788, loss = 0.00414598
Iteration 5789, loss = 0.00414493
Iteration 5790, loss = 0.00414381
Iteration 5791, loss = 0.00414277
Iteration 5792, loss = 0.00414162
Iteration 5793, loss = 0.00414074
Iteration 5794, loss = 0.00413960
Iteration 5795, loss = 0.00413870
Iteration 5796, loss = 0.00413774
Iteration 5797, loss = 0.00413671
Iteration 5798, loss = 0.00413578
Iteration 5799, loss = 0.00413526
Iteration 5800, loss = 0.00413440
Iteration 5801, loss = 0.00413288
Iteration 5802, loss = 0.00413181
Iteration 5803, loss = 0.00413090
Iteration 5804, loss = 0.00412978
Iteration 5805, loss = 0.00412885
Iteration 5806, loss = 0.00412782
Iteration 5807, loss = 0.00412695
Iteration 5808, loss = 0.00412596
Iteration 5809, loss = 0.00412498
Iteration 5810, loss = 0.00412423
Iteration 5811, loss = 0.00412309
Iteration 5812, loss = 0.00412217
Iteration 5813, loss = 0.00412182
Iteration 5814, loss = 0.00412033
Iteration 5815, loss = 0.00411966
Iteration 5816, loss = 0.00411849
Iteration 5817, loss = 0.00411755
Iteration 5818, loss = 0.00411657
Iteration 5819, loss = 0.00411562
Iteration 5820, loss = 0.00411512
Iteration 5821, loss = 0.00411388
Iteration 5822, loss = 0.00411305
Iteration 5823, loss = 0.00411204
Iteration 5824, loss = 0.00411136
Iteration 5825, loss = 0.00411025
Iteration 5826, loss = 0.00410933
Iteration 5827, loss = 0.00410829
Iteration 5828, loss = 0.00410740
Iteration 5829, loss = 0.00410653
Iteration 5830, loss = 0.00410542
Iteration 5831, loss = 0.00410467
Iteration 5832, loss = 0.00410363
Iteration 5833, loss = 0.00410268
Iteration 5834, loss = 0.00410206
Iteration 5835, loss = 0.00410095
Iteration 5836, loss = 0.00410039
Iteration 5837, loss = 0.00409921
Iteration 5838, loss = 0.00409814
Iteration 5839, loss = 0.00409747
Iteration 5840, loss = 0.00409605
Iteration 5841, loss = 0.00409516
Iteration 5842, loss = 0.00409399
Iteration 5843, loss = 0.00409259
Iteration 5844, loss = 0.00409147
Iteration 5845, loss = 0.00409036
Iteration 5846, loss = 0.00408964
Iteration 5847, loss = 0.00408856
Iteration 5848, loss = 0.00408744
Iteration 5849, loss = 0.00408637
Iteration 5850, loss = 0.00408545
Iteration 5851, loss = 0.00408456
Iteration 5852, loss = 0.00408352
Iteration 5853, loss = 0.00408277
Iteration 5854, loss = 0.00408156
Iteration 5855, loss = 0.00408048
Iteration 5856, loss = 0.00407943
Iteration 5857, loss = 0.00407818
Iteration 5858, loss = 0.00407705
Iteration 5859, loss = 0.00407585
Iteration 5860, loss = 0.00407529
Iteration 5861, loss = 0.00407396
Iteration 5862, loss = 0.00407321
Iteration 5863, loss = 0.00407232
Iteration 5864, loss = 0.00407120
Iteration 5865, loss = 0.00407032
Iteration 5866, loss = 0.00406941
Iteration 5867, loss = 0.00406839
Iteration 5868, loss = 0.00406760
Iteration 5869, loss = 0.00406657
Iteration 5870, loss = 0.00406559
Iteration 5871, loss = 0.00406472
Iteration 5872, loss = 0.00406378
Iteration 5873, loss = 0.00406288
Iteration 5874, loss = 0.00406180
Iteration 5875, loss = 0.00406083
Iteration 5876, loss = 0.00406025
Iteration 5877, loss = 0.00405866
Iteration 5878, loss = 0.00405758
Iteration 5879, loss = 0.00405695
Iteration 5880, loss = 0.00405564
Iteration 5881, loss = 0.00405467
Iteration 5882, loss = 0.00405376
Iteration 5883, loss = 0.00405277
Iteration 5884, loss = 0.00405190
Iteration 5885, loss = 0.00405093
Iteration 5886, loss = 0.00405014
Iteration 5887, loss = 0.00404907
Iteration 5888, loss = 0.00404826
Iteration 5889, loss = 0.00404742
Iteration 5890, loss = 0.00404644
Iteration 5891, loss = 0.00404549
Iteration 5892, loss = 0.00404454
Iteration 5893, loss = 0.00404365
Iteration 5894, loss = 0.00404274
Iteration 5895, loss = 0.00404183
Iteration 5896, loss = 0.00404082
Iteration 5897, loss = 0.00403999
Iteration 5898, loss = 0.00403915
Iteration 5899, loss = 0.00403809
Iteration 5900, loss = 0.00403714
Iteration 5901, loss = 0.00403669
Iteration 5902, loss = 0.00403532
Iteration 5903, loss = 0.00403441
Iteration 5904, loss = 0.00403332
Iteration 5905, loss = 0.00403259
Iteration 5906, loss = 0.00403136
Iteration 5907, loss = 0.00403037
Iteration 5908, loss = 0.00402934
Iteration 5909, loss = 0.00402865
Iteration 5910, loss = 0.00402774
Iteration 5911, loss = 0.00402660
Iteration 5912, loss = 0.00402557
Iteration 5913, loss = 0.00402460
Iteration 5914, loss = 0.00402363
Iteration 5915, loss = 0.00402250
Iteration 5916, loss = 0.00402179
Iteration 5917, loss = 0.00402066
Iteration 5918, loss = 0.00401976
Iteration 5919, loss = 0.00401840
Iteration 5920, loss = 0.00401746
Iteration 5921, loss = 0.00401641
Iteration 5922, loss = 0.00401538
Iteration 5923, loss = 0.00401490
Iteration 5924, loss = 0.00401354
Iteration 5925, loss = 0.00401271
Iteration 5926, loss = 0.00401175
Iteration 5927, loss = 0.00401081
Iteration 5928, loss = 0.00400980
Iteration 5929, loss = 0.00400902
Iteration 5930, loss = 0.00400884
Iteration 5931, loss = 0.00400734
Iteration 5932, loss = 0.00400648
Iteration 5933, loss = 0.00400567
Iteration 5934, loss = 0.00400478
Iteration 5935, loss = 0.00400381
Iteration 5936, loss = 0.00400316
Iteration 5937, loss = 0.00400200
Iteration 5938, loss = 0.00400106
Iteration 5939, loss = 0.00400013
Iteration 5940, loss = 0.00399905
Iteration 5941, loss = 0.00399807
Iteration 5942, loss = 0.00399749
Iteration 5943, loss = 0.00399625
Iteration 5944, loss = 0.00399523
Iteration 5945, loss = 0.00399440
Iteration 5946, loss = 0.00399342
Iteration 5947, loss = 0.00399244
Iteration 5948, loss = 0.00399151
Iteration 5949, loss = 0.00399061
Iteration 5950, loss = 0.00398988
Iteration 5951, loss = 0.00398880
Iteration 5952, loss = 0.00398791
Iteration 5953, loss = 0.00398692
Iteration 5954, loss = 0.00398625
Iteration 5955, loss = 0.00398516
Iteration 5956, loss = 0.00398416
Iteration 5957, loss = 0.00398373
Iteration 5958, loss = 0.00398303
Iteration 5959, loss = 0.00398164
Iteration 5960, loss = 0.00398067
Iteration 5961, loss = 0.00397989
Iteration 5962, loss = 0.00397902
Iteration 5963, loss = 0.00397799
Iteration 5964, loss = 0.00397691
Iteration 5965, loss = 0.00397595
Iteration 5966, loss = 0.00397509
Iteration 5967, loss = 0.00397387
Iteration 5968, loss = 0.00397299
Iteration 5969, loss = 0.00397189
Iteration 5970, loss = 0.00397105
Iteration 5971, loss = 0.00397004
Iteration 5972, loss = 0.00396910
Iteration 5973, loss = 0.00396804
Iteration 5974, loss = 0.00396712
Iteration 5975, loss = 0.00396624
Iteration 5976, loss = 0.00396553
Iteration 5977, loss = 0.00396467
Iteration 5978, loss = 0.00396313
Iteration 5979, loss = 0.00396224
Iteration 5980, loss = 0.00396128
Iteration 5981, loss = 0.00396043
Iteration 5982, loss = 0.00395937
Iteration 5983, loss = 0.00395925
Iteration 5984, loss = 0.00395769
Iteration 5985, loss = 0.00395661
Iteration 5986, loss = 0.00395551
Iteration 5987, loss = 0.00395459
Iteration 5988, loss = 0.00395370
Iteration 5989, loss = 0.00395254
Iteration 5990, loss = 0.00395159
Iteration 5991, loss = 0.00395074
Iteration 5992, loss = 0.00394975
Iteration 5993, loss = 0.00394915
Iteration 5994, loss = 0.00394782
Iteration 5995, loss = 0.00394703
Iteration 5996, loss = 0.00394595
Iteration 5997, loss = 0.00394498
Iteration 5998, loss = 0.00394440
Iteration 5999, loss = 0.00394322
Iteration 6000, loss = 0.00394224
Iteration 6001, loss = 0.00394145
Iteration 6002, loss = 0.00394055
Iteration 6003, loss = 0.00393965
Iteration 6004, loss = 0.00393915
Iteration 6005, loss = 0.00393807
Iteration 6006, loss = 0.00393708
Iteration 6007, loss = 0.00393615
Iteration 6008, loss = 0.00393524
Iteration 6009, loss = 0.00393452
Iteration 6010, loss = 0.00393345
Iteration 6011, loss = 0.00393252
Iteration 6012, loss = 0.00393157
Iteration 6013, loss = 0.00393074
Iteration 6014, loss = 0.00392979
Iteration 6015, loss = 0.00392891
Iteration 6016, loss = 0.00392856
Iteration 6017, loss = 0.00392711
Iteration 6018, loss = 0.00392630
Iteration 6019, loss = 0.00392532
Iteration 6020, loss = 0.00392444
Iteration 6021, loss = 0.00392366
Iteration 6022, loss = 0.00392239
Iteration 6023, loss = 0.00392166
Iteration 6024, loss = 0.00392061
Iteration 6025, loss = 0.00391970
Iteration 6026, loss = 0.00391873
Iteration 6027, loss = 0.00391785
Iteration 6028, loss = 0.00391718
Iteration 6029, loss = 0.00391627
Iteration 6030, loss = 0.00391559
Iteration 6031, loss = 0.00391430
Iteration 6032, loss = 0.00391372
Iteration 6033, loss = 0.00391278
Iteration 6034, loss = 0.00391189
Iteration 6035, loss = 0.00391078
Iteration 6036, loss = 0.00390974
Iteration 6037, loss = 0.00390897
Iteration 6038, loss = 0.00390826
Iteration 6039, loss = 0.00390726
Iteration 6040, loss = 0.00390631
Iteration 6041, loss = 0.00390553
Iteration 6042, loss = 0.00390467
Iteration 6043, loss = 0.00390372
Iteration 6044, loss = 0.00390286
Iteration 6045, loss = 0.00390200
Iteration 6046, loss = 0.00390108
Iteration 6047, loss = 0.00390031
Iteration 6048, loss = 0.00389940
Iteration 6049, loss = 0.00389855
Iteration 6050, loss = 0.00389771
Iteration 6051, loss = 0.00389708
Iteration 6052, loss = 0.00389596
Iteration 6053, loss = 0.00389504
Iteration 6054, loss = 0.00389425
Iteration 6055, loss = 0.00389348
Iteration 6056, loss = 0.00389269
Iteration 6057, loss = 0.00389171
Iteration 6058, loss = 0.00389072
Iteration 6059, loss = 0.00388994
Iteration 6060, loss = 0.00388911
Iteration 6061, loss = 0.00388824
Iteration 6062, loss = 0.00388733
Iteration 6063, loss = 0.00388649
Iteration 6064, loss = 0.00388571
Iteration 6065, loss = 0.00388473
Iteration 6066, loss = 0.00388398
Iteration 6067, loss = 0.00388318
Iteration 6068, loss = 0.00388210
Iteration 6069, loss = 0.00388122
Iteration 6070, loss = 0.00388035
Iteration 6071, loss = 0.00387950
Iteration 6072, loss = 0.00387841
Iteration 6073, loss = 0.00387778
Iteration 6074, loss = 0.00387673
Iteration 6075, loss = 0.00387591
Iteration 6076, loss = 0.00387494
Iteration 6077, loss = 0.00387410
Iteration 6078, loss = 0.00387328
Iteration 6079, loss = 0.00387231
Iteration 6080, loss = 0.00387148
Iteration 6081, loss = 0.00387068
Iteration 6082, loss = 0.00386981
Iteration 6083, loss = 0.00386905
Iteration 6084, loss = 0.00386810
Iteration 6085, loss = 0.00386733
Iteration 6086, loss = 0.00386640
Iteration 6087, loss = 0.00386567
Iteration 6088, loss = 0.00386474
Iteration 6089, loss = 0.00386410
Iteration 6090, loss = 0.00386327
Iteration 6091, loss = 0.00386236
Iteration 6092, loss = 0.00386155
Iteration 6093, loss = 0.00386055
Iteration 6094, loss = 0.00385971
Iteration 6095, loss = 0.00385889
Iteration 6096, loss = 0.00385803
Iteration 6097, loss = 0.00385730
Iteration 6098, loss = 0.00385632
Iteration 6099, loss = 0.00385540
Iteration 6100, loss = 0.00385441
Iteration 6101, loss = 0.00385368
Iteration 6102, loss = 0.00385265
Iteration 6103, loss = 0.00385169
Iteration 6104, loss = 0.00385078
Iteration 6105, loss = 0.00385010
Iteration 6106, loss = 0.00384932
Iteration 6107, loss = 0.00384820
Iteration 6108, loss = 0.00384814
Iteration 6109, loss = 0.00384663
Iteration 6110, loss = 0.00384580
Iteration 6111, loss = 0.00384492
Iteration 6112, loss = 0.00384417
Iteration 6113, loss = 0.00384318
Iteration 6114, loss = 0.00384239
Iteration 6115, loss = 0.00384143
Iteration 6116, loss = 0.00384053
Iteration 6117, loss = 0.00383992
Iteration 6118, loss = 0.00383905
Iteration 6119, loss = 0.00383825
Iteration 6120, loss = 0.00383761
Iteration 6121, loss = 0.00383693
Iteration 6122, loss = 0.00383608
Iteration 6123, loss = 0.00383528
Iteration 6124, loss = 0.00383432
Iteration 6125, loss = 0.00383346
Iteration 6126, loss = 0.00383270
Iteration 6127, loss = 0.00383172
Iteration 6128, loss = 0.00383066
Iteration 6129, loss = 0.00382969
Iteration 6130, loss = 0.00382871
Iteration 6131, loss = 0.00382778
Iteration 6132, loss = 0.00382650
Iteration 6133, loss = 0.00382589
Iteration 6134, loss = 0.00382510
Iteration 6135, loss = 0.00382371
Iteration 6136, loss = 0.00382335
Iteration 6137, loss = 0.00382203
Iteration 6138, loss = 0.00382124
Iteration 6139, loss = 0.00382038
Iteration 6140, loss = 0.00381945
Iteration 6141, loss = 0.00381860
Iteration 6142, loss = 0.00381794
Iteration 6143, loss = 0.00381715
Iteration 6144, loss = 0.00381639
Iteration 6145, loss = 0.00381586
Iteration 6146, loss = 0.00381472
Iteration 6147, loss = 0.00381395
Iteration 6148, loss = 0.00381282
Iteration 6149, loss = 0.00381196
Iteration 6150, loss = 0.00381102
Iteration 6151, loss = 0.00381005
Iteration 6152, loss = 0.00380932
Iteration 6153, loss = 0.00380813
Iteration 6154, loss = 0.00380725
Iteration 6155, loss = 0.00380617
Iteration 6156, loss = 0.00380526
Iteration 6157, loss = 0.00380442
Iteration 6158, loss = 0.00380349
Iteration 6159, loss = 0.00380259
Iteration 6160, loss = 0.00380173
Iteration 6161, loss = 0.00380089
Iteration 6162, loss = 0.00380008
Iteration 6163, loss = 0.00379906
Iteration 6164, loss = 0.00379830
Iteration 6165, loss = 0.00379722
Iteration 6166, loss = 0.00379637
Iteration 6167, loss = 0.00379541
Iteration 6168, loss = 0.00379469
Iteration 6169, loss = 0.00379384
Iteration 6170, loss = 0.00379288
Iteration 6171, loss = 0.00379196
Iteration 6172, loss = 0.00379148
Iteration 6173, loss = 0.00379020
Iteration 6174, loss = 0.00378939
Iteration 6175, loss = 0.00378854
Iteration 6176, loss = 0.00378771
Iteration 6177, loss = 0.00378712
Iteration 6178, loss = 0.00378602
Iteration 6179, loss = 0.00378511
Iteration 6180, loss = 0.00378430
Iteration 6181, loss = 0.00378369
Iteration 6182, loss = 0.00378287
Iteration 6183, loss = 0.00378195
Iteration 6184, loss = 0.00378107
Iteration 6185, loss = 0.00378039
Iteration 6186, loss = 0.00377949
Iteration 6187, loss = 0.00377878
Iteration 6188, loss = 0.00377786
Iteration 6189, loss = 0.00377711
Iteration 6190, loss = 0.00377625
Iteration 6191, loss = 0.00377545
Iteration 6192, loss = 0.00377467
Iteration 6193, loss = 0.00377383
Iteration 6194, loss = 0.00377292
Iteration 6195, loss = 0.00377226
Iteration 6196, loss = 0.00377115
Iteration 6197, loss = 0.00377076
Iteration 6198, loss = 0.00376949
Iteration 6199, loss = 0.00376869
Iteration 6200, loss = 0.00376809
Iteration 6201, loss = 0.00376695
Iteration 6202, loss = 0.00376609
Iteration 6203, loss = 0.00376525
Iteration 6204, loss = 0.00376472
Iteration 6205, loss = 0.00376356
Iteration 6206, loss = 0.00376290
Iteration 6207, loss = 0.00376187
Iteration 6208, loss = 0.00376105
Iteration 6209, loss = 0.00376043
Iteration 6210, loss = 0.00375943
Iteration 6211, loss = 0.00375858
Iteration 6212, loss = 0.00375763
Iteration 6213, loss = 0.00375689
Iteration 6214, loss = 0.00375602
Iteration 6215, loss = 0.00375511
Iteration 6216, loss = 0.00375433
Iteration 6217, loss = 0.00375369
Iteration 6218, loss = 0.00375274
Iteration 6219, loss = 0.00375231
Iteration 6220, loss = 0.00375130
Iteration 6221, loss = 0.00375036
Iteration 6222, loss = 0.00374960
Iteration 6223, loss = 0.00374897
Iteration 6224, loss = 0.00374802
Iteration 6225, loss = 0.00374710
Iteration 6226, loss = 0.00374641
Iteration 6227, loss = 0.00374545
Iteration 6228, loss = 0.00374455
Iteration 6229, loss = 0.00374379
Iteration 6230, loss = 0.00374290
Iteration 6231, loss = 0.00374241
Iteration 6232, loss = 0.00374135
Iteration 6233, loss = 0.00374054
Iteration 6234, loss = 0.00373973
Iteration 6235, loss = 0.00373896
Iteration 6236, loss = 0.00373799
Iteration 6237, loss = 0.00373721
Iteration 6238, loss = 0.00373631
Iteration 6239, loss = 0.00373564
Iteration 6240, loss = 0.00373467
Iteration 6241, loss = 0.00373382
Iteration 6242, loss = 0.00373310
Iteration 6243, loss = 0.00373220
Iteration 6244, loss = 0.00373153
Iteration 6245, loss = 0.00373068
Iteration 6246, loss = 0.00372985
Iteration 6247, loss = 0.00372884
Iteration 6248, loss = 0.00372802
Iteration 6249, loss = 0.00372711
Iteration 6250, loss = 0.00372620
Iteration 6251, loss = 0.00372554
Iteration 6252, loss = 0.00372457
Iteration 6253, loss = 0.00372384
Iteration 6254, loss = 0.00372297
Iteration 6255, loss = 0.00372227
Iteration 6256, loss = 0.00372135
Iteration 6257, loss = 0.00372054
Iteration 6258, loss = 0.00371970
Iteration 6259, loss = 0.00371886
Iteration 6260, loss = 0.00371806
Iteration 6261, loss = 0.00371726
Iteration 6262, loss = 0.00371647
Iteration 6263, loss = 0.00371589
Iteration 6264, loss = 0.00371497
Iteration 6265, loss = 0.00371454
Iteration 6266, loss = 0.00371354
Iteration 6267, loss = 0.00371293
Iteration 6268, loss = 0.00371209
Iteration 6269, loss = 0.00371138
Iteration 6270, loss = 0.00371082
Iteration 6271, loss = 0.00370992
Iteration 6272, loss = 0.00370920
Iteration 6273, loss = 0.00370837
Iteration 6274, loss = 0.00370762
Iteration 6275, loss = 0.00370683
Iteration 6276, loss = 0.00370614
Iteration 6277, loss = 0.00370572
Iteration 6278, loss = 0.00370459
Iteration 6279, loss = 0.00370380
Iteration 6280, loss = 0.00370322
Iteration 6281, loss = 0.00370230
Iteration 6282, loss = 0.00370149
Iteration 6283, loss = 0.00370088
Iteration 6284, loss = 0.00370002
Iteration 6285, loss = 0.00369921
Iteration 6286, loss = 0.00369847
Iteration 6287, loss = 0.00369760
Iteration 6288, loss = 0.00369683
Iteration 6289, loss = 0.00369596
Iteration 6290, loss = 0.00369498
Iteration 6291, loss = 0.00369456
Iteration 6292, loss = 0.00369347
Iteration 6293, loss = 0.00369347
Iteration 6294, loss = 0.00369210
Iteration 6295, loss = 0.00369121
Iteration 6296, loss = 0.00369029
Iteration 6297, loss = 0.00368946
Iteration 6298, loss = 0.00368870
Iteration 6299, loss = 0.00368811
Iteration 6300, loss = 0.00368731
Iteration 6301, loss = 0.00368653
Iteration 6302, loss = 0.00368596
Iteration 6303, loss = 0.00368515
Iteration 6304, loss = 0.00368476
Iteration 6305, loss = 0.00368376
Iteration 6306, loss = 0.00368297
Iteration 6307, loss = 0.00368220
Iteration 6308, loss = 0.00368139
Iteration 6309, loss = 0.00368082
Iteration 6310, loss = 0.00368001
Iteration 6311, loss = 0.00367928
Iteration 6312, loss = 0.00367893
Iteration 6313, loss = 0.00367807
Iteration 6314, loss = 0.00367734
Iteration 6315, loss = 0.00367655
Iteration 6316, loss = 0.00367619
Iteration 6317, loss = 0.00367531
Iteration 6318, loss = 0.00367451
Iteration 6319, loss = 0.00367390
Iteration 6320, loss = 0.00367288
Iteration 6321, loss = 0.00367229
Iteration 6322, loss = 0.00367172
Iteration 6323, loss = 0.00367123
Iteration 6324, loss = 0.00367060
Iteration 6325, loss = 0.00366985
Iteration 6326, loss = 0.00366922
Iteration 6327, loss = 0.00366903
Iteration 6328, loss = 0.00366807
Iteration 6329, loss = 0.00366764
Iteration 6330, loss = 0.00366671
Iteration 6331, loss = 0.00366605
Iteration 6332, loss = 0.00366512
Iteration 6333, loss = 0.00366445
Iteration 6334, loss = 0.00366351
Iteration 6335, loss = 0.00366275
Iteration 6336, loss = 0.00366188
Iteration 6337, loss = 0.00366115
Iteration 6338, loss = 0.00366037
Iteration 6339, loss = 0.00365951
Iteration 6340, loss = 0.00365915
Iteration 6341, loss = 0.00365893
Iteration 6342, loss = 0.00365801
Iteration 6343, loss = 0.00365780
Iteration 6344, loss = 0.00365670
Iteration 6345, loss = 0.00365606
Iteration 6346, loss = 0.00365524
Iteration 6347, loss = 0.00365448
Iteration 6348, loss = 0.00365382
Iteration 6349, loss = 0.00365314
Iteration 6350, loss = 0.00365245
Iteration 6351, loss = 0.00365128
Iteration 6352, loss = 0.00365006
Iteration 6353, loss = 0.00364897
Iteration 6354, loss = 0.00364787
Iteration 6355, loss = 0.00364744
Iteration 6356, loss = 0.00364593
Iteration 6357, loss = 0.00364489
Iteration 6358, loss = 0.00364440
Iteration 6359, loss = 0.00364308
Iteration 6360, loss = 0.00364208
Iteration 6361, loss = 0.00364102
Iteration 6362, loss = 0.00364024
Iteration 6363, loss = 0.00363912
Iteration 6364, loss = 0.00363812
Iteration 6365, loss = 0.00363754
Iteration 6366, loss = 0.00363635
Iteration 6367, loss = 0.00363542
Iteration 6368, loss = 0.00363476
Iteration 6369, loss = 0.00363390
Iteration 6370, loss = 0.00363312
Iteration 6371, loss = 0.00363245
Iteration 6372, loss = 0.00363190
Iteration 6373, loss = 0.00363105
Iteration 6374, loss = 0.00363038
Iteration 6375, loss = 0.00362965
Iteration 6376, loss = 0.00362883
Iteration 6377, loss = 0.00362823
Iteration 6378, loss = 0.00362718
Iteration 6379, loss = 0.00362648
Iteration 6380, loss = 0.00362581
Iteration 6381, loss = 0.00362489
Iteration 6382, loss = 0.00362432
Iteration 6383, loss = 0.00362332
Iteration 6384, loss = 0.00362277
Iteration 6385, loss = 0.00362162
Iteration 6386, loss = 0.00362081
Iteration 6387, loss = 0.00361996
Iteration 6388, loss = 0.00361925
Iteration 6389, loss = 0.00361843
Iteration 6390, loss = 0.00361758
Iteration 6391, loss = 0.00361662
Iteration 6392, loss = 0.00361599
Iteration 6393, loss = 0.00361509
Iteration 6394, loss = 0.00361412
Iteration 6395, loss = 0.00361372
Iteration 6396, loss = 0.00361256
Iteration 6397, loss = 0.00361168
Iteration 6398, loss = 0.00361091
Iteration 6399, loss = 0.00361045
Iteration 6400, loss = 0.00360918
Iteration 6401, loss = 0.00360810
Iteration 6402, loss = 0.00360739
Iteration 6403, loss = 0.00360614
Iteration 6404, loss = 0.00360510
Iteration 6405, loss = 0.00360431
Iteration 6406, loss = 0.00360347
Iteration 6407, loss = 0.00360253
Iteration 6408, loss = 0.00360153
Iteration 6409, loss = 0.00360084
Iteration 6410, loss = 0.00360005
Iteration 6411, loss = 0.00359924
Iteration 6412, loss = 0.00359843
Iteration 6413, loss = 0.00359771
Iteration 6414, loss = 0.00359691
Iteration 6415, loss = 0.00359604
Iteration 6416, loss = 0.00359513
Iteration 6417, loss = 0.00359442
Iteration 6418, loss = 0.00359336
Iteration 6419, loss = 0.00359251
Iteration 6420, loss = 0.00359167
Iteration 6421, loss = 0.00359092
Iteration 6422, loss = 0.00359007
Iteration 6423, loss = 0.00358946
Iteration 6424, loss = 0.00358836
Iteration 6425, loss = 0.00358762
Iteration 6426, loss = 0.00358690
Iteration 6427, loss = 0.00358610
Iteration 6428, loss = 0.00358546
Iteration 6429, loss = 0.00358463
Iteration 6430, loss = 0.00358392
Iteration 6431, loss = 0.00358323
Iteration 6432, loss = 0.00358247
Iteration 6433, loss = 0.00358163
Iteration 6434, loss = 0.00358100
Iteration 6435, loss = 0.00358003
Iteration 6436, loss = 0.00357929
Iteration 6437, loss = 0.00357849
Iteration 6438, loss = 0.00357770
Iteration 6439, loss = 0.00357676
Iteration 6440, loss = 0.00357606
Iteration 6441, loss = 0.00357533
Iteration 6442, loss = 0.00357473
Iteration 6443, loss = 0.00357401
Iteration 6444, loss = 0.00357339
Iteration 6445, loss = 0.00357268
Iteration 6446, loss = 0.00357213
Iteration 6447, loss = 0.00357154
Iteration 6448, loss = 0.00357046
Iteration 6449, loss = 0.00356955
Iteration 6450, loss = 0.00356866
Iteration 6451, loss = 0.00356779
Iteration 6452, loss = 0.00356690
Iteration 6453, loss = 0.00356594
Iteration 6454, loss = 0.00356515
Iteration 6455, loss = 0.00356422
Iteration 6456, loss = 0.00356361
Iteration 6457, loss = 0.00356250
Iteration 6458, loss = 0.00356172
Iteration 6459, loss = 0.00356127
Iteration 6460, loss = 0.00356029
Iteration 6461, loss = 0.00355953
Iteration 6462, loss = 0.00355893
Iteration 6463, loss = 0.00355798
Iteration 6464, loss = 0.00355715
Iteration 6465, loss = 0.00355644
Iteration 6466, loss = 0.00355558
Iteration 6467, loss = 0.00355477
Iteration 6468, loss = 0.00355388
Iteration 6469, loss = 0.00355304
Iteration 6470, loss = 0.00355222
Iteration 6471, loss = 0.00355146
Iteration 6472, loss = 0.00355049
Iteration 6473, loss = 0.00354956
Iteration 6474, loss = 0.00354867
Iteration 6475, loss = 0.00354840
Iteration 6476, loss = 0.00354769
Iteration 6477, loss = 0.00354723
Iteration 6478, loss = 0.00354589
Iteration 6479, loss = 0.00354520
Iteration 6480, loss = 0.00354440
Iteration 6481, loss = 0.00354376
Iteration 6482, loss = 0.00354292
Iteration 6483, loss = 0.00354211
Iteration 6484, loss = 0.00354137
Iteration 6485, loss = 0.00354072
Iteration 6486, loss = 0.00353989
Iteration 6487, loss = 0.00353915
Iteration 6488, loss = 0.00353859
Iteration 6489, loss = 0.00353778
Iteration 6490, loss = 0.00353698
Iteration 6491, loss = 0.00353614
Iteration 6492, loss = 0.00353601
Iteration 6493, loss = 0.00353484
Iteration 6494, loss = 0.00353395
Iteration 6495, loss = 0.00353313
Iteration 6496, loss = 0.00353231
Iteration 6497, loss = 0.00353191
Iteration 6498, loss = 0.00353090
Iteration 6499, loss = 0.00353021
Iteration 6500, loss = 0.00352948
Iteration 6501, loss = 0.00352864
Iteration 6502, loss = 0.00352799
Iteration 6503, loss = 0.00352735
Iteration 6504, loss = 0.00352645
Iteration 6505, loss = 0.00352560
Iteration 6506, loss = 0.00352479
Iteration 6507, loss = 0.00352411
Iteration 6508, loss = 0.00352353
Iteration 6509, loss = 0.00352283
Iteration 6510, loss = 0.00352190
Iteration 6511, loss = 0.00352118
Iteration 6512, loss = 0.00352059
Iteration 6513, loss = 0.00351963
Iteration 6514, loss = 0.00351897
Iteration 6515, loss = 0.00351809
Iteration 6516, loss = 0.00351730
Iteration 6517, loss = 0.00351661
Iteration 6518, loss = 0.00351566
Iteration 6519, loss = 0.00351494
Iteration 6520, loss = 0.00351454
Iteration 6521, loss = 0.00351350
Iteration 6522, loss = 0.00351287
Iteration 6523, loss = 0.00351212
Iteration 6524, loss = 0.00351116
Iteration 6525, loss = 0.00351037
Iteration 6526, loss = 0.00350952
Iteration 6527, loss = 0.00350882
Iteration 6528, loss = 0.00350797
Iteration 6529, loss = 0.00350724
Iteration 6530, loss = 0.00350642
Iteration 6531, loss = 0.00350568
Iteration 6532, loss = 0.00350485
Iteration 6533, loss = 0.00350424
Iteration 6534, loss = 0.00350342
Iteration 6535, loss = 0.00350261
Iteration 6536, loss = 0.00350192
Iteration 6537, loss = 0.00350118
Iteration 6538, loss = 0.00350037
Iteration 6539, loss = 0.00349964
Iteration 6540, loss = 0.00349897
Iteration 6541, loss = 0.00349831
Iteration 6542, loss = 0.00349764
Iteration 6543, loss = 0.00349693
Iteration 6544, loss = 0.00349611
Iteration 6545, loss = 0.00349554
Iteration 6546, loss = 0.00349472
Iteration 6547, loss = 0.00349394
Iteration 6548, loss = 0.00349331
Iteration 6549, loss = 0.00349256
Iteration 6550, loss = 0.00349183
Iteration 6551, loss = 0.00349103
Iteration 6552, loss = 0.00349015
Iteration 6553, loss = 0.00348943
Iteration 6554, loss = 0.00348884
Iteration 6555, loss = 0.00348802
Iteration 6556, loss = 0.00348719
Iteration 6557, loss = 0.00348652
Iteration 6558, loss = 0.00348555
Iteration 6559, loss = 0.00348494
Iteration 6560, loss = 0.00348433
Iteration 6561, loss = 0.00348320
Iteration 6562, loss = 0.00348265
Iteration 6563, loss = 0.00348151
Iteration 6564, loss = 0.00348073
Iteration 6565, loss = 0.00347996
Iteration 6566, loss = 0.00347918
Iteration 6567, loss = 0.00347858
Iteration 6568, loss = 0.00347786
Iteration 6569, loss = 0.00347692
Iteration 6570, loss = 0.00347611
Iteration 6571, loss = 0.00347538
Iteration 6572, loss = 0.00347463
Iteration 6573, loss = 0.00347401
Iteration 6574, loss = 0.00347336
Iteration 6575, loss = 0.00347266
Iteration 6576, loss = 0.00347184
Iteration 6577, loss = 0.00347108
Iteration 6578, loss = 0.00347059
Iteration 6579, loss = 0.00346956
Iteration 6580, loss = 0.00346883
Iteration 6581, loss = 0.00346817
Iteration 6582, loss = 0.00346732
Iteration 6583, loss = 0.00346658
Iteration 6584, loss = 0.00346581
Iteration 6585, loss = 0.00346505
Iteration 6586, loss = 0.00346453
Iteration 6587, loss = 0.00346375
Iteration 6588, loss = 0.00346304
Iteration 6589, loss = 0.00346201
Iteration 6590, loss = 0.00346126
Iteration 6591, loss = 0.00346057
Iteration 6592, loss = 0.00345973
Iteration 6593, loss = 0.00345907
Iteration 6594, loss = 0.00345836
Iteration 6595, loss = 0.00345769
Iteration 6596, loss = 0.00345721
Iteration 6597, loss = 0.00345608
Iteration 6598, loss = 0.00345532
Iteration 6599, loss = 0.00345458
Iteration 6600, loss = 0.00345376
Iteration 6601, loss = 0.00345300
Iteration 6602, loss = 0.00345243
Iteration 6603, loss = 0.00345175
Iteration 6604, loss = 0.00345101
Iteration 6605, loss = 0.00345022
Iteration 6606, loss = 0.00344953
Iteration 6607, loss = 0.00344898
Iteration 6608, loss = 0.00344815
Iteration 6609, loss = 0.00344745
Iteration 6610, loss = 0.00344679
Iteration 6611, loss = 0.00344613
Iteration 6612, loss = 0.00344543
Iteration 6613, loss = 0.00344479
Iteration 6614, loss = 0.00344410
Iteration 6615, loss = 0.00344342
Iteration 6616, loss = 0.00344284
Iteration 6617, loss = 0.00344201
Iteration 6618, loss = 0.00344145
Iteration 6619, loss = 0.00344075
Iteration 6620, loss = 0.00344031
Iteration 6621, loss = 0.00343956
Iteration 6622, loss = 0.00343877
Iteration 6623, loss = 0.00343802
Iteration 6624, loss = 0.00343746
Iteration 6625, loss = 0.00343670
Iteration 6626, loss = 0.00343604
Iteration 6627, loss = 0.00343535
Iteration 6628, loss = 0.00343465
Iteration 6629, loss = 0.00343392
Iteration 6630, loss = 0.00343322
Iteration 6631, loss = 0.00343237
Iteration 6632, loss = 0.00343161
Iteration 6633, loss = 0.00343082
Iteration 6634, loss = 0.00343029
Iteration 6635, loss = 0.00342970
Iteration 6636, loss = 0.00342896
Iteration 6637, loss = 0.00342823
Iteration 6638, loss = 0.00342755
Iteration 6639, loss = 0.00342689
Iteration 6640, loss = 0.00342622
Iteration 6641, loss = 0.00342582
Iteration 6642, loss = 0.00342497
Iteration 6643, loss = 0.00342429
Iteration 6644, loss = 0.00342356
Iteration 6645, loss = 0.00342292
Iteration 6646, loss = 0.00342224
Iteration 6647, loss = 0.00342171
Iteration 6648, loss = 0.00342115
Iteration 6649, loss = 0.00342060
Iteration 6650, loss = 0.00341963
Iteration 6651, loss = 0.00341903
Iteration 6652, loss = 0.00341854
Iteration 6653, loss = 0.00341766
Iteration 6654, loss = 0.00341698
Iteration 6655, loss = 0.00341630
Iteration 6656, loss = 0.00341560
Iteration 6657, loss = 0.00341495
Iteration 6658, loss = 0.00341448
Iteration 6659, loss = 0.00341365
Iteration 6660, loss = 0.00341316
Iteration 6661, loss = 0.00341246
Iteration 6662, loss = 0.00341181
Iteration 6663, loss = 0.00341122
Iteration 6664, loss = 0.00341054
Iteration 6665, loss = 0.00340987
Iteration 6666, loss = 0.00340984
Iteration 6667, loss = 0.00340848
Iteration 6668, loss = 0.00340795
Iteration 6669, loss = 0.00340705
Iteration 6670, loss = 0.00340633
Iteration 6671, loss = 0.00340564
Iteration 6672, loss = 0.00340492
Iteration 6673, loss = 0.00340425
Iteration 6674, loss = 0.00340345
Iteration 6675, loss = 0.00340303
Iteration 6676, loss = 0.00340200
Iteration 6677, loss = 0.00340150
Iteration 6678, loss = 0.00340072
Iteration 6679, loss = 0.00339975
Iteration 6680, loss = 0.00339896
Iteration 6681, loss = 0.00339825
Iteration 6682, loss = 0.00339750
Iteration 6683, loss = 0.00339701
Iteration 6684, loss = 0.00339606
Iteration 6685, loss = 0.00339537
Iteration 6686, loss = 0.00339486
Iteration 6687, loss = 0.00339399
Iteration 6688, loss = 0.00339357
Iteration 6689, loss = 0.00339261
Iteration 6690, loss = 0.00339184
Iteration 6691, loss = 0.00339127
Iteration 6692, loss = 0.00339052
Iteration 6693, loss = 0.00338978
Iteration 6694, loss = 0.00338905
Iteration 6695, loss = 0.00338842
Iteration 6696, loss = 0.00338765
Iteration 6697, loss = 0.00338696
Iteration 6698, loss = 0.00338633
Iteration 6699, loss = 0.00338610
Iteration 6700, loss = 0.00338498
Iteration 6701, loss = 0.00338447
Iteration 6702, loss = 0.00338361
Iteration 6703, loss = 0.00338293
Iteration 6704, loss = 0.00338215
Iteration 6705, loss = 0.00338131
Iteration 6706, loss = 0.00338059
Iteration 6707, loss = 0.00337986
Iteration 6708, loss = 0.00337915
Iteration 6709, loss = 0.00337836
Iteration 6710, loss = 0.00337806
Iteration 6711, loss = 0.00337691
Iteration 6712, loss = 0.00337604
Iteration 6713, loss = 0.00337522
Iteration 6714, loss = 0.00337454
Iteration 6715, loss = 0.00337376
Iteration 6716, loss = 0.00337324
Iteration 6717, loss = 0.00337225
Iteration 6718, loss = 0.00337144
Iteration 6719, loss = 0.00337075
Iteration 6720, loss = 0.00336981
Iteration 6721, loss = 0.00336912
Iteration 6722, loss = 0.00336872
Iteration 6723, loss = 0.00336797
Iteration 6724, loss = 0.00336705
Iteration 6725, loss = 0.00336621
Iteration 6726, loss = 0.00336565
Iteration 6727, loss = 0.00336484
Iteration 6728, loss = 0.00336449
Iteration 6729, loss = 0.00336333
Iteration 6730, loss = 0.00336281
Iteration 6731, loss = 0.00336197
Iteration 6732, loss = 0.00336130
Iteration 6733, loss = 0.00336051
Iteration 6734, loss = 0.00335963
Iteration 6735, loss = 0.00335901
Iteration 6736, loss = 0.00335829
Iteration 6737, loss = 0.00335781
Iteration 6738, loss = 0.00335692
Iteration 6739, loss = 0.00335622
Iteration 6740, loss = 0.00335557
Iteration 6741, loss = 0.00335482
Iteration 6742, loss = 0.00335422
Iteration 6743, loss = 0.00335370
Iteration 6744, loss = 0.00335296
Iteration 6745, loss = 0.00335263
Iteration 6746, loss = 0.00335174
Iteration 6747, loss = 0.00335116
Iteration 6748, loss = 0.00335059
Iteration 6749, loss = 0.00334998
Iteration 6750, loss = 0.00334929
Iteration 6751, loss = 0.00334866
Iteration 6752, loss = 0.00334802
Iteration 6753, loss = 0.00334736
Iteration 6754, loss = 0.00334675
Iteration 6755, loss = 0.00334620
Iteration 6756, loss = 0.00334546
Iteration 6757, loss = 0.00334484
Iteration 6758, loss = 0.00334430
Iteration 6759, loss = 0.00334363
Iteration 6760, loss = 0.00334301
Iteration 6761, loss = 0.00334222
Iteration 6762, loss = 0.00334198
Iteration 6763, loss = 0.00334082
Iteration 6764, loss = 0.00334019
Iteration 6765, loss = 0.00333970
Iteration 6766, loss = 0.00333878
Iteration 6767, loss = 0.00333814
Iteration 6768, loss = 0.00333749
Iteration 6769, loss = 0.00333678
Iteration 6770, loss = 0.00333618
Iteration 6771, loss = 0.00333551
Iteration 6772, loss = 0.00333483
Iteration 6773, loss = 0.00333416
Iteration 6774, loss = 0.00333345
Iteration 6775, loss = 0.00333259
Iteration 6776, loss = 0.00333202
Iteration 6777, loss = 0.00333132
Iteration 6778, loss = 0.00333079
Iteration 6779, loss = 0.00332984
Iteration 6780, loss = 0.00332919
Iteration 6781, loss = 0.00332864
Iteration 6782, loss = 0.00332793
Iteration 6783, loss = 0.00332743
Iteration 6784, loss = 0.00332670
Iteration 6785, loss = 0.00332600
Iteration 6786, loss = 0.00332515
Iteration 6787, loss = 0.00332444
Iteration 6788, loss = 0.00332375
Iteration 6789, loss = 0.00332302
Iteration 6790, loss = 0.00332229
Iteration 6791, loss = 0.00332161
Iteration 6792, loss = 0.00332108
Iteration 6793, loss = 0.00332013
Iteration 6794, loss = 0.00331977
Iteration 6795, loss = 0.00331874
Iteration 6796, loss = 0.00331817
Iteration 6797, loss = 0.00331738
Iteration 6798, loss = 0.00331665
Iteration 6799, loss = 0.00331584
Iteration 6800, loss = 0.00331519
Iteration 6801, loss = 0.00331456
Iteration 6802, loss = 0.00331386
Iteration 6803, loss = 0.00331302
Iteration 6804, loss = 0.00331236
Iteration 6805, loss = 0.00331167
Iteration 6806, loss = 0.00331098
Iteration 6807, loss = 0.00331030
Iteration 6808, loss = 0.00330965
Iteration 6809, loss = 0.00330889
Iteration 6810, loss = 0.00330820
Iteration 6811, loss = 0.00330750
Iteration 6812, loss = 0.00330697
Iteration 6813, loss = 0.00330658
Iteration 6814, loss = 0.00330573
Iteration 6815, loss = 0.00330525
Iteration 6816, loss = 0.00330465
Iteration 6817, loss = 0.00330393
Iteration 6818, loss = 0.00330325
Iteration 6819, loss = 0.00330262
Iteration 6820, loss = 0.00330193
Iteration 6821, loss = 0.00330125
Iteration 6822, loss = 0.00330061
Iteration 6823, loss = 0.00330026
Iteration 6824, loss = 0.00329940
Iteration 6825, loss = 0.00329879
Iteration 6826, loss = 0.00329808
Iteration 6827, loss = 0.00329754
Iteration 6828, loss = 0.00329684
Iteration 6829, loss = 0.00329625
Iteration 6830, loss = 0.00329554
Iteration 6831, loss = 0.00329488
Iteration 6832, loss = 0.00329433
Iteration 6833, loss = 0.00329380
Iteration 6834, loss = 0.00329309
Iteration 6835, loss = 0.00329231
Iteration 6836, loss = 0.00329163
Iteration 6837, loss = 0.00329088
Iteration 6838, loss = 0.00329037
Iteration 6839, loss = 0.00328965
Iteration 6840, loss = 0.00328891
Iteration 6841, loss = 0.00328845
Iteration 6842, loss = 0.00328781
Iteration 6843, loss = 0.00328720
Iteration 6844, loss = 0.00328640
Iteration 6845, loss = 0.00328576
Iteration 6846, loss = 0.00328502
Iteration 6847, loss = 0.00328433
Iteration 6848, loss = 0.00328371
Iteration 6849, loss = 0.00328297
Iteration 6850, loss = 0.00328245
Iteration 6851, loss = 0.00328171
Iteration 6852, loss = 0.00328095
Iteration 6853, loss = 0.00328022
Iteration 6854, loss = 0.00327948
Iteration 6855, loss = 0.00327875
Iteration 6856, loss = 0.00327812
Iteration 6857, loss = 0.00327738
Iteration 6858, loss = 0.00327653
Iteration 6859, loss = 0.00327594
Iteration 6860, loss = 0.00327522
Iteration 6861, loss = 0.00327442
Iteration 6862, loss = 0.00327369
Iteration 6863, loss = 0.00327295
Iteration 6864, loss = 0.00327221
Iteration 6865, loss = 0.00327160
Iteration 6866, loss = 0.00327086
Iteration 6867, loss = 0.00327005
Iteration 6868, loss = 0.00326943
Iteration 6869, loss = 0.00326890
Iteration 6870, loss = 0.00326812
Iteration 6871, loss = 0.00326746
Iteration 6872, loss = 0.00326680
Iteration 6873, loss = 0.00326637
Iteration 6874, loss = 0.00326542
Iteration 6875, loss = 0.00326503
Iteration 6876, loss = 0.00326421
Iteration 6877, loss = 0.00326364
Iteration 6878, loss = 0.00326303
Iteration 6879, loss = 0.00326267
Iteration 6880, loss = 0.00326180
Iteration 6881, loss = 0.00326111
Iteration 6882, loss = 0.00326035
Iteration 6883, loss = 0.00325968
Iteration 6884, loss = 0.00325902
Iteration 6885, loss = 0.00325839
Iteration 6886, loss = 0.00325744
Iteration 6887, loss = 0.00325688
Iteration 6888, loss = 0.00325611
Iteration 6889, loss = 0.00325573
Iteration 6890, loss = 0.00325484
Iteration 6891, loss = 0.00325417
Iteration 6892, loss = 0.00325353
Iteration 6893, loss = 0.00325295
Iteration 6894, loss = 0.00325238
Iteration 6895, loss = 0.00325189
Iteration 6896, loss = 0.00325101
Iteration 6897, loss = 0.00325041
Iteration 6898, loss = 0.00324986
Iteration 6899, loss = 0.00324908
Iteration 6900, loss = 0.00324839
Iteration 6901, loss = 0.00324772
Iteration 6902, loss = 0.00324705
Iteration 6903, loss = 0.00324633
Iteration 6904, loss = 0.00324559
Iteration 6905, loss = 0.00324503
Iteration 6906, loss = 0.00324413
Iteration 6907, loss = 0.00324378
Iteration 6908, loss = 0.00324282
Iteration 6909, loss = 0.00324220
Iteration 6910, loss = 0.00324139
Iteration 6911, loss = 0.00324074
Iteration 6912, loss = 0.00323985
Iteration 6913, loss = 0.00323946
Iteration 6914, loss = 0.00323847
Iteration 6915, loss = 0.00323771
Iteration 6916, loss = 0.00323700
Iteration 6917, loss = 0.00323633
Iteration 6918, loss = 0.00323560
Iteration 6919, loss = 0.00323496
Iteration 6920, loss = 0.00323419
Iteration 6921, loss = 0.00323352
Iteration 6922, loss = 0.00323325
Iteration 6923, loss = 0.00323206
Iteration 6924, loss = 0.00323180
Iteration 6925, loss = 0.00323077
Iteration 6926, loss = 0.00323017
Iteration 6927, loss = 0.00322949
Iteration 6928, loss = 0.00322877
Iteration 6929, loss = 0.00322811
Iteration 6930, loss = 0.00322758
Iteration 6931, loss = 0.00322688
Iteration 6932, loss = 0.00322620
Iteration 6933, loss = 0.00322544
Iteration 6934, loss = 0.00322477
Iteration 6935, loss = 0.00322412
Iteration 6936, loss = 0.00322342
Iteration 6937, loss = 0.00322277
Iteration 6938, loss = 0.00322211
Iteration 6939, loss = 0.00322150
Iteration 6940, loss = 0.00322073
Iteration 6941, loss = 0.00322019
Iteration 6942, loss = 0.00321948
Iteration 6943, loss = 0.00321861
Iteration 6944, loss = 0.00321798
Iteration 6945, loss = 0.00321732
Iteration 6946, loss = 0.00321668
Iteration 6947, loss = 0.00321599
Iteration 6948, loss = 0.00321524
Iteration 6949, loss = 0.00321457
Iteration 6950, loss = 0.00321373
Iteration 6951, loss = 0.00321327
Iteration 6952, loss = 0.00321291
Iteration 6953, loss = 0.00321192
Iteration 6954, loss = 0.00321132
Iteration 6955, loss = 0.00321076
Iteration 6956, loss = 0.00321001
Iteration 6957, loss = 0.00320951
Iteration 6958, loss = 0.00320876
Iteration 6959, loss = 0.00320813
Iteration 6960, loss = 0.00320753
Iteration 6961, loss = 0.00320687
Iteration 6962, loss = 0.00320629
Iteration 6963, loss = 0.00320559
Iteration 6964, loss = 0.00320533
Iteration 6965, loss = 0.00320442
Iteration 6966, loss = 0.00320384
Iteration 6967, loss = 0.00320322
Iteration 6968, loss = 0.00320260
Iteration 6969, loss = 0.00320201
Iteration 6970, loss = 0.00320140
Iteration 6971, loss = 0.00320086
Iteration 6972, loss = 0.00320026
Iteration 6973, loss = 0.00319967
Iteration 6974, loss = 0.00319977
Iteration 6975, loss = 0.00319849
Iteration 6976, loss = 0.00319773
Iteration 6977, loss = 0.00319730
Iteration 6978, loss = 0.00319652
Iteration 6979, loss = 0.00319609
Iteration 6980, loss = 0.00319527
Iteration 6981, loss = 0.00319473
Iteration 6982, loss = 0.00319406
Iteration 6983, loss = 0.00319339
Iteration 6984, loss = 0.00319284
Iteration 6985, loss = 0.00319216
Iteration 6986, loss = 0.00319162
Iteration 6987, loss = 0.00319098
Iteration 6988, loss = 0.00319027
Iteration 6989, loss = 0.00318963
Iteration 6990, loss = 0.00318901
Iteration 6991, loss = 0.00318835
Iteration 6992, loss = 0.00318785
Iteration 6993, loss = 0.00318719
Iteration 6994, loss = 0.00318670
Iteration 6995, loss = 0.00318633
Iteration 6996, loss = 0.00318543
Iteration 6997, loss = 0.00318494
Iteration 6998, loss = 0.00318432
Iteration 6999, loss = 0.00318378
Iteration 7000, loss = 0.00318317
Iteration 7001, loss = 0.00318268
Iteration 7002, loss = 0.00318198
Iteration 7003, loss = 0.00318133
Iteration 7004, loss = 0.00318093
Iteration 7005, loss = 0.00318011
Iteration 7006, loss = 0.00317951
Iteration 7007, loss = 0.00317891
Iteration 7008, loss = 0.00317836
Iteration 7009, loss = 0.00317754
Iteration 7010, loss = 0.00317687
Iteration 7011, loss = 0.00317665
Iteration 7012, loss = 0.00317562
Iteration 7013, loss = 0.00317492
Iteration 7014, loss = 0.00317437
Iteration 7015, loss = 0.00317366
Iteration 7016, loss = 0.00317285
Iteration 7017, loss = 0.00317217
Iteration 7018, loss = 0.00317142
Iteration 7019, loss = 0.00317093
Iteration 7020, loss = 0.00317005
Iteration 7021, loss = 0.00316936
Iteration 7022, loss = 0.00316883
Iteration 7023, loss = 0.00316817
Iteration 7024, loss = 0.00316751
Iteration 7025, loss = 0.00316700
Iteration 7026, loss = 0.00316624
Iteration 7027, loss = 0.00316558
Iteration 7028, loss = 0.00316510
Iteration 7029, loss = 0.00316440
Iteration 7030, loss = 0.00316371
Iteration 7031, loss = 0.00316317
Iteration 7032, loss = 0.00316247
Iteration 7033, loss = 0.00316189
Iteration 7034, loss = 0.00316155
Iteration 7035, loss = 0.00316072
Iteration 7036, loss = 0.00316028
Iteration 7037, loss = 0.00315944
Iteration 7038, loss = 0.00315878
Iteration 7039, loss = 0.00315827
Iteration 7040, loss = 0.00315758
Iteration 7041, loss = 0.00315699
Iteration 7042, loss = 0.00315642
Iteration 7043, loss = 0.00315577
Iteration 7044, loss = 0.00315517
Iteration 7045, loss = 0.00315463
Iteration 7046, loss = 0.00315382
Iteration 7047, loss = 0.00315327
Iteration 7048, loss = 0.00315291
Iteration 7049, loss = 0.00315215
Iteration 7050, loss = 0.00315123
Iteration 7051, loss = 0.00315063
Iteration 7052, loss = 0.00315052
Iteration 7053, loss = 0.00314970
Iteration 7054, loss = 0.00314860
Iteration 7055, loss = 0.00314802
Iteration 7056, loss = 0.00314738
Iteration 7057, loss = 0.00314688
Iteration 7058, loss = 0.00314614
Iteration 7059, loss = 0.00314553
Iteration 7060, loss = 0.00314503
Iteration 7061, loss = 0.00314446
Iteration 7062, loss = 0.00314377
Iteration 7063, loss = 0.00314316
Iteration 7064, loss = 0.00314272
Iteration 7065, loss = 0.00314204
Iteration 7066, loss = 0.00314142
Iteration 7067, loss = 0.00314087
Iteration 7068, loss = 0.00314020
Iteration 7069, loss = 0.00313959
Iteration 7070, loss = 0.00313913
Iteration 7071, loss = 0.00313842
Iteration 7072, loss = 0.00313774
Iteration 7073, loss = 0.00313707
Iteration 7074, loss = 0.00313653
Iteration 7075, loss = 0.00313589
Iteration 7076, loss = 0.00313526
Iteration 7077, loss = 0.00313466
Iteration 7078, loss = 0.00313403
Iteration 7079, loss = 0.00313333
Iteration 7080, loss = 0.00313255
Iteration 7081, loss = 0.00313217
Iteration 7082, loss = 0.00313129
Iteration 7083, loss = 0.00313069
Iteration 7084, loss = 0.00313014
Iteration 7085, loss = 0.00312941
Iteration 7086, loss = 0.00312890
Iteration 7087, loss = 0.00312834
Iteration 7088, loss = 0.00312758
Iteration 7089, loss = 0.00312691
Iteration 7090, loss = 0.00312661
Iteration 7091, loss = 0.00312580
Iteration 7092, loss = 0.00312507
Iteration 7093, loss = 0.00312468
Iteration 7094, loss = 0.00312383
Iteration 7095, loss = 0.00312336
Iteration 7096, loss = 0.00312289
Iteration 7097, loss = 0.00312223
Iteration 7098, loss = 0.00312183
Iteration 7099, loss = 0.00312124
Iteration 7100, loss = 0.00312051
Iteration 7101, loss = 0.00311989
Iteration 7102, loss = 0.00311935
Iteration 7103, loss = 0.00311879
Iteration 7104, loss = 0.00311820
Iteration 7105, loss = 0.00311774
Iteration 7106, loss = 0.00311714
Iteration 7107, loss = 0.00311667
Iteration 7108, loss = 0.00311604
Iteration 7109, loss = 0.00311553
Iteration 7110, loss = 0.00311505
Iteration 7111, loss = 0.00311439
Iteration 7112, loss = 0.00311396
Iteration 7113, loss = 0.00311342
Iteration 7114, loss = 0.00311276
Iteration 7115, loss = 0.00311219
Iteration 7116, loss = 0.00311156
Iteration 7117, loss = 0.00311134
Iteration 7118, loss = 0.00311044
Iteration 7119, loss = 0.00310983
Iteration 7120, loss = 0.00310929
Iteration 7121, loss = 0.00310870
Iteration 7122, loss = 0.00310812
Iteration 7123, loss = 0.00310757
Iteration 7124, loss = 0.00310698
Iteration 7125, loss = 0.00310639
Iteration 7126, loss = 0.00310585
Iteration 7127, loss = 0.00310548
Iteration 7128, loss = 0.00310474
Iteration 7129, loss = 0.00310412
Iteration 7130, loss = 0.00310377
Iteration 7131, loss = 0.00310299
Iteration 7132, loss = 0.00310243
Iteration 7133, loss = 0.00310171
Iteration 7134, loss = 0.00310110
Iteration 7135, loss = 0.00310048
Iteration 7136, loss = 0.00309990
Iteration 7137, loss = 0.00309933
Iteration 7138, loss = 0.00309893
Iteration 7139, loss = 0.00309813
Iteration 7140, loss = 0.00309759
Iteration 7141, loss = 0.00309704
Iteration 7142, loss = 0.00309659
Iteration 7143, loss = 0.00309603
Iteration 7144, loss = 0.00309548
Iteration 7145, loss = 0.00309491
Iteration 7146, loss = 0.00309409
Iteration 7147, loss = 0.00309352
Iteration 7148, loss = 0.00309295
Iteration 7149, loss = 0.00309262
Iteration 7150, loss = 0.00309188
Iteration 7151, loss = 0.00309148
Iteration 7152, loss = 0.00309072
Iteration 7153, loss = 0.00309046
Iteration 7154, loss = 0.00308965
Iteration 7155, loss = 0.00308900
Iteration 7156, loss = 0.00308845
Iteration 7157, loss = 0.00308794
Iteration 7158, loss = 0.00308726
Iteration 7159, loss = 0.00308669
Iteration 7160, loss = 0.00308606
Iteration 7161, loss = 0.00308552
Iteration 7162, loss = 0.00308482
Iteration 7163, loss = 0.00308413
Iteration 7164, loss = 0.00308374
Iteration 7165, loss = 0.00308291
Iteration 7166, loss = 0.00308236
Iteration 7167, loss = 0.00308165
Iteration 7168, loss = 0.00308158
Iteration 7169, loss = 0.00308063
Iteration 7170, loss = 0.00308013
Iteration 7171, loss = 0.00307933
Iteration 7172, loss = 0.00307882
Iteration 7173, loss = 0.00307818
Iteration 7174, loss = 0.00307760
Iteration 7175, loss = 0.00307706
Iteration 7176, loss = 0.00307635
Iteration 7177, loss = 0.00307624
Iteration 7178, loss = 0.00307534
Iteration 7179, loss = 0.00307478
Iteration 7180, loss = 0.00307417
Iteration 7181, loss = 0.00307361
Iteration 7182, loss = 0.00307310
Iteration 7183, loss = 0.00307238
Iteration 7184, loss = 0.00307179
Iteration 7185, loss = 0.00307123
Iteration 7186, loss = 0.00307062
Iteration 7187, loss = 0.00307004
Iteration 7188, loss = 0.00306948
Iteration 7189, loss = 0.00306880
Iteration 7190, loss = 0.00306822
Iteration 7191, loss = 0.00306782
Iteration 7192, loss = 0.00306709
Iteration 7193, loss = 0.00306642
Iteration 7194, loss = 0.00306583
Iteration 7195, loss = 0.00306533
Iteration 7196, loss = 0.00306467
Iteration 7197, loss = 0.00306417
Iteration 7198, loss = 0.00306349
Iteration 7199, loss = 0.00306292
Iteration 7200, loss = 0.00306230
Iteration 7201, loss = 0.00306187
Iteration 7202, loss = 0.00306138
Iteration 7203, loss = 0.00306079
Iteration 7204, loss = 0.00306008
Iteration 7205, loss = 0.00305954
Iteration 7206, loss = 0.00305899
Iteration 7207, loss = 0.00305843
Iteration 7208, loss = 0.00305790
Iteration 7209, loss = 0.00305738
Iteration 7210, loss = 0.00305684
Iteration 7211, loss = 0.00305659
Iteration 7212, loss = 0.00305573
Iteration 7213, loss = 0.00305515
Iteration 7214, loss = 0.00305449
Iteration 7215, loss = 0.00305386
Iteration 7216, loss = 0.00305353
Iteration 7217, loss = 0.00305277
Iteration 7218, loss = 0.00305197
Iteration 7219, loss = 0.00305143
Iteration 7220, loss = 0.00305075
Iteration 7221, loss = 0.00305025
Iteration 7222, loss = 0.00304970
Iteration 7223, loss = 0.00304909
Iteration 7224, loss = 0.00304851
Iteration 7225, loss = 0.00304805
Iteration 7226, loss = 0.00304760
Iteration 7227, loss = 0.00304688
Iteration 7228, loss = 0.00304637
Iteration 7229, loss = 0.00304580
Iteration 7230, loss = 0.00304520
Iteration 7231, loss = 0.00304472
Iteration 7232, loss = 0.00304412
Iteration 7233, loss = 0.00304358
Iteration 7234, loss = 0.00304296
Iteration 7235, loss = 0.00304239
Iteration 7236, loss = 0.00304191
Iteration 7237, loss = 0.00304156
Iteration 7238, loss = 0.00304092
Iteration 7239, loss = 0.00304029
Iteration 7240, loss = 0.00303977
Iteration 7241, loss = 0.00303920
Iteration 7242, loss = 0.00303876
Iteration 7243, loss = 0.00303817
Iteration 7244, loss = 0.00303755
Iteration 7245, loss = 0.00303696
Iteration 7246, loss = 0.00303641
Iteration 7247, loss = 0.00303582
Iteration 7248, loss = 0.00303522
Iteration 7249, loss = 0.00303472
Iteration 7250, loss = 0.00303409
Iteration 7251, loss = 0.00303343
Iteration 7252, loss = 0.00303286
Iteration 7253, loss = 0.00303235
Iteration 7254, loss = 0.00303178
Iteration 7255, loss = 0.00303119
Iteration 7256, loss = 0.00303078
Iteration 7257, loss = 0.00303008
Iteration 7258, loss = 0.00302937
Iteration 7259, loss = 0.00302889
Iteration 7260, loss = 0.00302849
Iteration 7261, loss = 0.00302790
Iteration 7262, loss = 0.00302739
Iteration 7263, loss = 0.00302676
Iteration 7264, loss = 0.00302621
Iteration 7265, loss = 0.00302568
Iteration 7266, loss = 0.00302519
Iteration 7267, loss = 0.00302468
Iteration 7268, loss = 0.00302425
Iteration 7269, loss = 0.00302364
Iteration 7270, loss = 0.00302311
Iteration 7271, loss = 0.00302265
Iteration 7272, loss = 0.00302192
Iteration 7273, loss = 0.00302137
Iteration 7274, loss = 0.00302082
Iteration 7275, loss = 0.00302023
Iteration 7276, loss = 0.00301971
Iteration 7277, loss = 0.00301910
Iteration 7278, loss = 0.00301857
Iteration 7279, loss = 0.00301807
Iteration 7280, loss = 0.00301750
Iteration 7281, loss = 0.00301707
Iteration 7282, loss = 0.00301639
Iteration 7283, loss = 0.00301581
Iteration 7284, loss = 0.00301535
Iteration 7285, loss = 0.00301473
Iteration 7286, loss = 0.00301423
Iteration 7287, loss = 0.00301369
Iteration 7288, loss = 0.00301315
Iteration 7289, loss = 0.00301253
Iteration 7290, loss = 0.00301189
Iteration 7291, loss = 0.00301140
Iteration 7292, loss = 0.00301072
Iteration 7293, loss = 0.00301013
Iteration 7294, loss = 0.00300962
Iteration 7295, loss = 0.00300887
Iteration 7296, loss = 0.00300825
Iteration 7297, loss = 0.00300779
Iteration 7298, loss = 0.00300720
Iteration 7299, loss = 0.00300653
Iteration 7300, loss = 0.00300602
Iteration 7301, loss = 0.00300530
Iteration 7302, loss = 0.00300471
Iteration 7303, loss = 0.00300466
Iteration 7304, loss = 0.00300374
Iteration 7305, loss = 0.00300332
Iteration 7306, loss = 0.00300265
Iteration 7307, loss = 0.00300213
Iteration 7308, loss = 0.00300160
Iteration 7309, loss = 0.00300106
Iteration 7310, loss = 0.00300040
Iteration 7311, loss = 0.00299993
Iteration 7312, loss = 0.00299941
Iteration 7313, loss = 0.00299874
Iteration 7314, loss = 0.00299836
Iteration 7315, loss = 0.00299756
Iteration 7316, loss = 0.00299701
Iteration 7317, loss = 0.00299646
Iteration 7318, loss = 0.00299585
Iteration 7319, loss = 0.00299525
Iteration 7320, loss = 0.00299480
Iteration 7321, loss = 0.00299409
Iteration 7322, loss = 0.00299356
Iteration 7323, loss = 0.00299296
Iteration 7324, loss = 0.00299243
Iteration 7325, loss = 0.00299187
Iteration 7326, loss = 0.00299133
Iteration 7327, loss = 0.00299084
Iteration 7328, loss = 0.00299031
Iteration 7329, loss = 0.00298984
Iteration 7330, loss = 0.00298921
Iteration 7331, loss = 0.00298860
Iteration 7332, loss = 0.00298807
Iteration 7333, loss = 0.00298752
Iteration 7334, loss = 0.00298688
Iteration 7335, loss = 0.00298649
Iteration 7336, loss = 0.00298584
Iteration 7337, loss = 0.00298529
Iteration 7338, loss = 0.00298485
Iteration 7339, loss = 0.00298423
Iteration 7340, loss = 0.00298367
Iteration 7341, loss = 0.00298321
Iteration 7342, loss = 0.00298271
Iteration 7343, loss = 0.00298220
Iteration 7344, loss = 0.00298159
Iteration 7345, loss = 0.00298141
Iteration 7346, loss = 0.00298064
Iteration 7347, loss = 0.00298020
Iteration 7348, loss = 0.00297946
Iteration 7349, loss = 0.00297898
Iteration 7350, loss = 0.00297825
Iteration 7351, loss = 0.00297789
Iteration 7352, loss = 0.00297728
Iteration 7353, loss = 0.00297685
Iteration 7354, loss = 0.00297621
Iteration 7355, loss = 0.00297560
Iteration 7356, loss = 0.00297501
Iteration 7357, loss = 0.00297462
Iteration 7358, loss = 0.00297397
Iteration 7359, loss = 0.00297347
Iteration 7360, loss = 0.00297308
Iteration 7361, loss = 0.00297238
Iteration 7362, loss = 0.00297187
Iteration 7363, loss = 0.00297135
Iteration 7364, loss = 0.00297064
Iteration 7365, loss = 0.00296999
Iteration 7366, loss = 0.00296963
Iteration 7367, loss = 0.00296881
Iteration 7368, loss = 0.00296858
Iteration 7369, loss = 0.00296795
Iteration 7370, loss = 0.00296739
Iteration 7371, loss = 0.00296684
Iteration 7372, loss = 0.00296622
Iteration 7373, loss = 0.00296592
Iteration 7374, loss = 0.00296511
Iteration 7375, loss = 0.00296453
Iteration 7376, loss = 0.00296394
Iteration 7377, loss = 0.00296340
Iteration 7378, loss = 0.00296287
Iteration 7379, loss = 0.00296225
Iteration 7380, loss = 0.00296166
Iteration 7381, loss = 0.00296121
Iteration 7382, loss = 0.00296038
Iteration 7383, loss = 0.00295977
Iteration 7384, loss = 0.00295920
Iteration 7385, loss = 0.00295855
Iteration 7386, loss = 0.00295797
Iteration 7387, loss = 0.00295743
Iteration 7388, loss = 0.00295688
Iteration 7389, loss = 0.00295637
Iteration 7390, loss = 0.00295583
Iteration 7391, loss = 0.00295543
Iteration 7392, loss = 0.00295490
Iteration 7393, loss = 0.00295430
Iteration 7394, loss = 0.00295382
Iteration 7395, loss = 0.00295317
Iteration 7396, loss = 0.00295280
Iteration 7397, loss = 0.00295222
Iteration 7398, loss = 0.00295233
Iteration 7399, loss = 0.00295122
Iteration 7400, loss = 0.00295062
Iteration 7401, loss = 0.00295007
Iteration 7402, loss = 0.00294953
Iteration 7403, loss = 0.00294912
Iteration 7404, loss = 0.00294842
Iteration 7405, loss = 0.00294782
Iteration 7406, loss = 0.00294727
Iteration 7407, loss = 0.00294686
Iteration 7408, loss = 0.00294635
Iteration 7409, loss = 0.00294600
Iteration 7410, loss = 0.00294537
Iteration 7411, loss = 0.00294499
Iteration 7412, loss = 0.00294434
Iteration 7413, loss = 0.00294383
Iteration 7414, loss = 0.00294331
Iteration 7415, loss = 0.00294285
Iteration 7416, loss = 0.00294232
Iteration 7417, loss = 0.00294189
Iteration 7418, loss = 0.00294134
Iteration 7419, loss = 0.00294096
Iteration 7420, loss = 0.00294056
Iteration 7421, loss = 0.00294000
Iteration 7422, loss = 0.00293943
Iteration 7423, loss = 0.00293903
Iteration 7424, loss = 0.00293834
Iteration 7425, loss = 0.00293771
Iteration 7426, loss = 0.00293727
Iteration 7427, loss = 0.00293666
Iteration 7428, loss = 0.00293613
Iteration 7429, loss = 0.00293560
Iteration 7430, loss = 0.00293509
Iteration 7431, loss = 0.00293481
Iteration 7432, loss = 0.00293415
Iteration 7433, loss = 0.00293360
Iteration 7434, loss = 0.00293300
Iteration 7435, loss = 0.00293261
Iteration 7436, loss = 0.00293211
Iteration 7437, loss = 0.00293134
Iteration 7438, loss = 0.00293093
Iteration 7439, loss = 0.00293022
Iteration 7440, loss = 0.00292963
Iteration 7441, loss = 0.00292916
Iteration 7442, loss = 0.00292858
Iteration 7443, loss = 0.00292798
Iteration 7444, loss = 0.00292733
Iteration 7445, loss = 0.00292703
Iteration 7446, loss = 0.00292635
Iteration 7447, loss = 0.00292581
Iteration 7448, loss = 0.00292535
Iteration 7449, loss = 0.00292475
Iteration 7450, loss = 0.00292420
Iteration 7451, loss = 0.00292370
Iteration 7452, loss = 0.00292310
Iteration 7453, loss = 0.00292269
Iteration 7454, loss = 0.00292214
Iteration 7455, loss = 0.00292158
Iteration 7456, loss = 0.00292107
Iteration 7457, loss = 0.00292096
Iteration 7458, loss = 0.00292005
Iteration 7459, loss = 0.00291952
Iteration 7460, loss = 0.00291903
Iteration 7461, loss = 0.00291843
Iteration 7462, loss = 0.00291794
Iteration 7463, loss = 0.00291737
Iteration 7464, loss = 0.00291681
Iteration 7465, loss = 0.00291632
Iteration 7466, loss = 0.00291575
Iteration 7467, loss = 0.00291537
Iteration 7468, loss = 0.00291497
Iteration 7469, loss = 0.00291430
Iteration 7470, loss = 0.00291377
Iteration 7471, loss = 0.00291321
Iteration 7472, loss = 0.00291260
Iteration 7473, loss = 0.00291217
Iteration 7474, loss = 0.00291162
Iteration 7475, loss = 0.00291115
Iteration 7476, loss = 0.00291053
Iteration 7477, loss = 0.00291004
Iteration 7478, loss = 0.00290955
Iteration 7479, loss = 0.00290925
Iteration 7480, loss = 0.00290855
Iteration 7481, loss = 0.00290803
Iteration 7482, loss = 0.00290755
Iteration 7483, loss = 0.00290708
Iteration 7484, loss = 0.00290653
Iteration 7485, loss = 0.00290587
Iteration 7486, loss = 0.00290535
Iteration 7487, loss = 0.00290476
Iteration 7488, loss = 0.00290418
Iteration 7489, loss = 0.00290362
Iteration 7490, loss = 0.00290326
Iteration 7491, loss = 0.00290274
Iteration 7492, loss = 0.00290232
Iteration 7493, loss = 0.00290167
Iteration 7494, loss = 0.00290107
Iteration 7495, loss = 0.00290048
Iteration 7496, loss = 0.00290001
Iteration 7497, loss = 0.00289935
Iteration 7498, loss = 0.00289872
Iteration 7499, loss = 0.00289832
Iteration 7500, loss = 0.00289761
Iteration 7501, loss = 0.00289709
Iteration 7502, loss = 0.00289646
Iteration 7503, loss = 0.00289586
Iteration 7504, loss = 0.00289534
Iteration 7505, loss = 0.00289472
Iteration 7506, loss = 0.00289414
Iteration 7507, loss = 0.00289395
Iteration 7508, loss = 0.00289299
Iteration 7509, loss = 0.00289245
Iteration 7510, loss = 0.00289247
Iteration 7511, loss = 0.00289124
Iteration 7512, loss = 0.00289066
Iteration 7513, loss = 0.00289001
Iteration 7514, loss = 0.00288945
Iteration 7515, loss = 0.00288894
Iteration 7516, loss = 0.00288828
Iteration 7517, loss = 0.00288771
Iteration 7518, loss = 0.00288722
Iteration 7519, loss = 0.00288669
Iteration 7520, loss = 0.00288618
Iteration 7521, loss = 0.00288574
Iteration 7522, loss = 0.00288511
Iteration 7523, loss = 0.00288468
Iteration 7524, loss = 0.00288405
Iteration 7525, loss = 0.00288364
Iteration 7526, loss = 0.00288306
Iteration 7527, loss = 0.00288255
Iteration 7528, loss = 0.00288204
Iteration 7529, loss = 0.00288159
Iteration 7530, loss = 0.00288103
Iteration 7531, loss = 0.00288054
Iteration 7532, loss = 0.00288014
Iteration 7533, loss = 0.00287967
Iteration 7534, loss = 0.00287901
Iteration 7535, loss = 0.00287848
Iteration 7536, loss = 0.00287818
Iteration 7537, loss = 0.00287762
Iteration 7538, loss = 0.00287697
Iteration 7539, loss = 0.00287655
Iteration 7540, loss = 0.00287599
Iteration 7541, loss = 0.00287549
Iteration 7542, loss = 0.00287500
Iteration 7543, loss = 0.00287440
Iteration 7544, loss = 0.00287386
Iteration 7545, loss = 0.00287330
Iteration 7546, loss = 0.00287276
Iteration 7547, loss = 0.00287240
Iteration 7548, loss = 0.00287194
Iteration 7549, loss = 0.00287125
Iteration 7550, loss = 0.00287074
Iteration 7551, loss = 0.00287023
Iteration 7552, loss = 0.00286972
Iteration 7553, loss = 0.00286924
Iteration 7554, loss = 0.00286875
Iteration 7555, loss = 0.00286812
Iteration 7556, loss = 0.00286760
Iteration 7557, loss = 0.00286705
Iteration 7558, loss = 0.00286671
Iteration 7559, loss = 0.00286622
Iteration 7560, loss = 0.00286572
Iteration 7561, loss = 0.00286514
Iteration 7562, loss = 0.00286468
Iteration 7563, loss = 0.00286412
Iteration 7564, loss = 0.00286362
Iteration 7565, loss = 0.00286314
Iteration 7566, loss = 0.00286286
Iteration 7567, loss = 0.00286221
Iteration 7568, loss = 0.00286160
Iteration 7569, loss = 0.00286102
Iteration 7570, loss = 0.00286051
Iteration 7571, loss = 0.00286001
Iteration 7572, loss = 0.00285945
Iteration 7573, loss = 0.00285907
Iteration 7574, loss = 0.00285850
Iteration 7575, loss = 0.00285803
Iteration 7576, loss = 0.00285759
Iteration 7577, loss = 0.00285701
Iteration 7578, loss = 0.00285658
Iteration 7579, loss = 0.00285601
Iteration 7580, loss = 0.00285560
Iteration 7581, loss = 0.00285503
Iteration 7582, loss = 0.00285442
Iteration 7583, loss = 0.00285403
Iteration 7584, loss = 0.00285341
Iteration 7585, loss = 0.00285281
Iteration 7586, loss = 0.00285222
Iteration 7587, loss = 0.00285183
Iteration 7588, loss = 0.00285119
Iteration 7589, loss = 0.00285061
Iteration 7590, loss = 0.00285010
Iteration 7591, loss = 0.00284963
Iteration 7592, loss = 0.00284907
Iteration 7593, loss = 0.00284854
Iteration 7594, loss = 0.00284805
Iteration 7595, loss = 0.00284768
Iteration 7596, loss = 0.00284707
Iteration 7597, loss = 0.00284652
Iteration 7598, loss = 0.00284602
Iteration 7599, loss = 0.00284550
Iteration 7600, loss = 0.00284504
Iteration 7601, loss = 0.00284455
Iteration 7602, loss = 0.00284406
Iteration 7603, loss = 0.00284349
Iteration 7604, loss = 0.00284313
Iteration 7605, loss = 0.00284265
Iteration 7606, loss = 0.00284210
Iteration 7607, loss = 0.00284163
Iteration 7608, loss = 0.00284118
Iteration 7609, loss = 0.00284073
Iteration 7610, loss = 0.00284016
Iteration 7611, loss = 0.00283964
Iteration 7612, loss = 0.00283925
Iteration 7613, loss = 0.00283878
Iteration 7614, loss = 0.00283834
Iteration 7615, loss = 0.00283780
Iteration 7616, loss = 0.00283728
Iteration 7617, loss = 0.00283689
Iteration 7618, loss = 0.00283640
Iteration 7619, loss = 0.00283593
Iteration 7620, loss = 0.00283539
Iteration 7621, loss = 0.00283492
Iteration 7622, loss = 0.00283452
Iteration 7623, loss = 0.00283393
Iteration 7624, loss = 0.00283333
Iteration 7625, loss = 0.00283308
Iteration 7626, loss = 0.00283282
Iteration 7627, loss = 0.00283203
Iteration 7628, loss = 0.00283155
Iteration 7629, loss = 0.00283115
Iteration 7630, loss = 0.00283054
Iteration 7631, loss = 0.00283004
Iteration 7632, loss = 0.00282951
Iteration 7633, loss = 0.00282895
Iteration 7634, loss = 0.00282842
Iteration 7635, loss = 0.00282789
Iteration 7636, loss = 0.00282769
Iteration 7637, loss = 0.00282696
Iteration 7638, loss = 0.00282650
Iteration 7639, loss = 0.00282594
Iteration 7640, loss = 0.00282540
Iteration 7641, loss = 0.00282495
Iteration 7642, loss = 0.00282447
Iteration 7643, loss = 0.00282409
Iteration 7644, loss = 0.00282355
Iteration 7645, loss = 0.00282311
Iteration 7646, loss = 0.00282267
Iteration 7647, loss = 0.00282231
Iteration 7648, loss = 0.00282175
Iteration 7649, loss = 0.00282120
Iteration 7650, loss = 0.00282065
Iteration 7651, loss = 0.00282041
Iteration 7652, loss = 0.00281962
Iteration 7653, loss = 0.00281917
Iteration 7654, loss = 0.00281856
Iteration 7655, loss = 0.00281810
Iteration 7656, loss = 0.00281763
Iteration 7657, loss = 0.00281727
Iteration 7658, loss = 0.00281668
Iteration 7659, loss = 0.00281616
Iteration 7660, loss = 0.00281566
Iteration 7661, loss = 0.00281517
Iteration 7662, loss = 0.00281468
Iteration 7663, loss = 0.00281420
Iteration 7664, loss = 0.00281382
Iteration 7665, loss = 0.00281331
Iteration 7666, loss = 0.00281284
Iteration 7667, loss = 0.00281233
Iteration 7668, loss = 0.00281199
Iteration 7669, loss = 0.00281151
Iteration 7670, loss = 0.00281103
Iteration 7671, loss = 0.00281061
Iteration 7672, loss = 0.00281013
Iteration 7673, loss = 0.00280961
Iteration 7674, loss = 0.00280920
Iteration 7675, loss = 0.00280874
Iteration 7676, loss = 0.00280814
Iteration 7677, loss = 0.00280752
Iteration 7678, loss = 0.00280702
Iteration 7679, loss = 0.00280660
Iteration 7680, loss = 0.00280593
Iteration 7681, loss = 0.00280542
Iteration 7682, loss = 0.00280511
Iteration 7683, loss = 0.00280436
Iteration 7684, loss = 0.00280394
Iteration 7685, loss = 0.00280338
Iteration 7686, loss = 0.00280280
Iteration 7687, loss = 0.00280236
Iteration 7688, loss = 0.00280164
Iteration 7689, loss = 0.00280102
Iteration 7690, loss = 0.00280072
Iteration 7691, loss = 0.00280027
Iteration 7692, loss = 0.00279964
Iteration 7693, loss = 0.00279906
Iteration 7694, loss = 0.00279850
Iteration 7695, loss = 0.00279811
Iteration 7696, loss = 0.00279747
Iteration 7697, loss = 0.00279699
Iteration 7698, loss = 0.00279659
Iteration 7699, loss = 0.00279604
Iteration 7700, loss = 0.00279545
Iteration 7701, loss = 0.00279494
Iteration 7702, loss = 0.00279461
Iteration 7703, loss = 0.00279395
Iteration 7704, loss = 0.00279338
Iteration 7705, loss = 0.00279279
Iteration 7706, loss = 0.00279233
Iteration 7707, loss = 0.00279186
Iteration 7708, loss = 0.00279137
Iteration 7709, loss = 0.00279079
Iteration 7710, loss = 0.00279031
Iteration 7711, loss = 0.00278990
Iteration 7712, loss = 0.00278940
Iteration 7713, loss = 0.00278894
Iteration 7714, loss = 0.00278840
Iteration 7715, loss = 0.00278814
Iteration 7716, loss = 0.00278753
Iteration 7717, loss = 0.00278706
Iteration 7718, loss = 0.00278650
Iteration 7719, loss = 0.00278602
Iteration 7720, loss = 0.00278540
Iteration 7721, loss = 0.00278489
Iteration 7722, loss = 0.00278450
Iteration 7723, loss = 0.00278398
Iteration 7724, loss = 0.00278354
Iteration 7725, loss = 0.00278301
Iteration 7726, loss = 0.00278262
Iteration 7727, loss = 0.00278207
Iteration 7728, loss = 0.00278170
Iteration 7729, loss = 0.00278122
Iteration 7730, loss = 0.00278049
Iteration 7731, loss = 0.00278007
Iteration 7732, loss = 0.00277946
Iteration 7733, loss = 0.00277894
Iteration 7734, loss = 0.00277838
Iteration 7735, loss = 0.00277785
Iteration 7736, loss = 0.00277730
Iteration 7737, loss = 0.00277680
Iteration 7738, loss = 0.00277631
Iteration 7739, loss = 0.00277579
Iteration 7740, loss = 0.00277530
Iteration 7741, loss = 0.00277492
Iteration 7742, loss = 0.00277455
Iteration 7743, loss = 0.00277395
Iteration 7744, loss = 0.00277360
Iteration 7745, loss = 0.00277293
Iteration 7746, loss = 0.00277247
Iteration 7747, loss = 0.00277194
Iteration 7748, loss = 0.00277137
Iteration 7749, loss = 0.00277080
Iteration 7750, loss = 0.00277032
Iteration 7751, loss = 0.00276988
Iteration 7752, loss = 0.00276939
Iteration 7753, loss = 0.00276871
Iteration 7754, loss = 0.00276829
Iteration 7755, loss = 0.00276771
Iteration 7756, loss = 0.00276722
Iteration 7757, loss = 0.00276676
Iteration 7758, loss = 0.00276619
Iteration 7759, loss = 0.00276584
Iteration 7760, loss = 0.00276528
Iteration 7761, loss = 0.00276465
Iteration 7762, loss = 0.00276441
Iteration 7763, loss = 0.00276356
Iteration 7764, loss = 0.00276303
Iteration 7765, loss = 0.00276251
Iteration 7766, loss = 0.00276204
Iteration 7767, loss = 0.00276144
Iteration 7768, loss = 0.00276091
Iteration 7769, loss = 0.00276037
Iteration 7770, loss = 0.00275999
Iteration 7771, loss = 0.00275941
Iteration 7772, loss = 0.00275874
Iteration 7773, loss = 0.00275818
Iteration 7774, loss = 0.00275775
Iteration 7775, loss = 0.00275710
Iteration 7776, loss = 0.00275663
Iteration 7777, loss = 0.00275608
Iteration 7778, loss = 0.00275565
Iteration 7779, loss = 0.00275525
Iteration 7780, loss = 0.00275462
Iteration 7781, loss = 0.00275430
Iteration 7782, loss = 0.00275370
Iteration 7783, loss = 0.00275324
Iteration 7784, loss = 0.00275280
Iteration 7785, loss = 0.00275227
Iteration 7786, loss = 0.00275179
Iteration 7787, loss = 0.00275145
Iteration 7788, loss = 0.00275102
Iteration 7789, loss = 0.00275050
Iteration 7790, loss = 0.00275003
Iteration 7791, loss = 0.00274955
Iteration 7792, loss = 0.00274904
Iteration 7793, loss = 0.00274857
Iteration 7794, loss = 0.00274810
Iteration 7795, loss = 0.00274768
Iteration 7796, loss = 0.00274722
Iteration 7797, loss = 0.00274680
Iteration 7798, loss = 0.00274637
Iteration 7799, loss = 0.00274585
Iteration 7800, loss = 0.00274546
Iteration 7801, loss = 0.00274503
Iteration 7802, loss = 0.00274457
Iteration 7803, loss = 0.00274414
Iteration 7804, loss = 0.00274368
Iteration 7805, loss = 0.00274324
Iteration 7806, loss = 0.00274286
Iteration 7807, loss = 0.00274234
Iteration 7808, loss = 0.00274196
Iteration 7809, loss = 0.00274161
Iteration 7810, loss = 0.00274101
Iteration 7811, loss = 0.00274052
Iteration 7812, loss = 0.00274033
Iteration 7813, loss = 0.00273967
Iteration 7814, loss = 0.00273923
Iteration 7815, loss = 0.00273892
Iteration 7816, loss = 0.00273825
Iteration 7817, loss = 0.00273772
Iteration 7818, loss = 0.00273725
Iteration 7819, loss = 0.00273683
Iteration 7820, loss = 0.00273609
Iteration 7821, loss = 0.00273577
Iteration 7822, loss = 0.00273496
Iteration 7823, loss = 0.00273444
Iteration 7824, loss = 0.00273405
Iteration 7825, loss = 0.00273337
Iteration 7826, loss = 0.00273287
Iteration 7827, loss = 0.00273237
Iteration 7828, loss = 0.00273197
Iteration 7829, loss = 0.00273146
Iteration 7830, loss = 0.00273116
Iteration 7831, loss = 0.00273047
Iteration 7832, loss = 0.00272980
Iteration 7833, loss = 0.00272928
Iteration 7834, loss = 0.00272874
Iteration 7835, loss = 0.00272828
Iteration 7836, loss = 0.00272777
Iteration 7837, loss = 0.00272713
Iteration 7838, loss = 0.00272663
Iteration 7839, loss = 0.00272624
Iteration 7840, loss = 0.00272569
Iteration 7841, loss = 0.00272513
Iteration 7842, loss = 0.00272466
Iteration 7843, loss = 0.00272417
Iteration 7844, loss = 0.00272370
Iteration 7845, loss = 0.00272328
Iteration 7846, loss = 0.00272281
Iteration 7847, loss = 0.00272232
Iteration 7848, loss = 0.00272188
Iteration 7849, loss = 0.00272140
Iteration 7850, loss = 0.00272086
Iteration 7851, loss = 0.00272029
Iteration 7852, loss = 0.00271981
Iteration 7853, loss = 0.00271930
Iteration 7854, loss = 0.00271878
Iteration 7855, loss = 0.00271830
Iteration 7856, loss = 0.00271789
Iteration 7857, loss = 0.00271736
Iteration 7858, loss = 0.00271691
Iteration 7859, loss = 0.00271645
Iteration 7860, loss = 0.00271610
Iteration 7861, loss = 0.00271570
Iteration 7862, loss = 0.00271515
Iteration 7863, loss = 0.00271475
Iteration 7864, loss = 0.00271421
Iteration 7865, loss = 0.00271382
Iteration 7866, loss = 0.00271319
Iteration 7867, loss = 0.00271261
Iteration 7868, loss = 0.00271239
Iteration 7869, loss = 0.00271160
Iteration 7870, loss = 0.00271104
Iteration 7871, loss = 0.00271063
Iteration 7872, loss = 0.00270998
Iteration 7873, loss = 0.00270942
Iteration 7874, loss = 0.00270905
Iteration 7875, loss = 0.00270848
Iteration 7876, loss = 0.00270796
Iteration 7877, loss = 0.00270747
Iteration 7878, loss = 0.00270717
Iteration 7879, loss = 0.00270665
Iteration 7880, loss = 0.00270618
Iteration 7881, loss = 0.00270588
Iteration 7882, loss = 0.00270543
Iteration 7883, loss = 0.00270508
Iteration 7884, loss = 0.00270445
Iteration 7885, loss = 0.00270400
Iteration 7886, loss = 0.00270365
Iteration 7887, loss = 0.00270306
Iteration 7888, loss = 0.00270253
Iteration 7889, loss = 0.00270210
Iteration 7890, loss = 0.00270156
Iteration 7891, loss = 0.00270107
Iteration 7892, loss = 0.00270067
Iteration 7893, loss = 0.00270001
Iteration 7894, loss = 0.00269959
Iteration 7895, loss = 0.00269899
Iteration 7896, loss = 0.00269854
Iteration 7897, loss = 0.00269808
Iteration 7898, loss = 0.00269796
Iteration 7899, loss = 0.00269708
Iteration 7900, loss = 0.00269660
Iteration 7901, loss = 0.00269607
Iteration 7902, loss = 0.00269562
Iteration 7903, loss = 0.00269511
Iteration 7904, loss = 0.00269474
Iteration 7905, loss = 0.00269425
Iteration 7906, loss = 0.00269371
Iteration 7907, loss = 0.00269323
Iteration 7908, loss = 0.00269296
Iteration 7909, loss = 0.00269235
Iteration 7910, loss = 0.00269204
Iteration 7911, loss = 0.00269141
Iteration 7912, loss = 0.00269112
Iteration 7913, loss = 0.00269046
Iteration 7914, loss = 0.00269008
Iteration 7915, loss = 0.00268955
Iteration 7916, loss = 0.00268905
Iteration 7917, loss = 0.00268869
Iteration 7918, loss = 0.00268816
Iteration 7919, loss = 0.00268767
Iteration 7920, loss = 0.00268738
Iteration 7921, loss = 0.00268683
Iteration 7922, loss = 0.00268652
Iteration 7923, loss = 0.00268616
Iteration 7924, loss = 0.00268571
Iteration 7925, loss = 0.00268528
Iteration 7926, loss = 0.00268465
Iteration 7927, loss = 0.00268423
Iteration 7928, loss = 0.00268383
Iteration 7929, loss = 0.00268333
Iteration 7930, loss = 0.00268277
Iteration 7931, loss = 0.00268225
Iteration 7932, loss = 0.00268185
Iteration 7933, loss = 0.00268137
Iteration 7934, loss = 0.00268087
Iteration 7935, loss = 0.00268047
Iteration 7936, loss = 0.00268003
Iteration 7937, loss = 0.00267955
Iteration 7938, loss = 0.00267908
Iteration 7939, loss = 0.00267872
Iteration 7940, loss = 0.00267823
Iteration 7941, loss = 0.00267822
Iteration 7942, loss = 0.00267728
Iteration 7943, loss = 0.00267686
Iteration 7944, loss = 0.00267644
Iteration 7945, loss = 0.00267593
Iteration 7946, loss = 0.00267553
Iteration 7947, loss = 0.00267498
Iteration 7948, loss = 0.00267469
Iteration 7949, loss = 0.00267420
Iteration 7950, loss = 0.00267370
Iteration 7951, loss = 0.00267321
Iteration 7952, loss = 0.00267275
Iteration 7953, loss = 0.00267233
Iteration 7954, loss = 0.00267206
Iteration 7955, loss = 0.00267141
Iteration 7956, loss = 0.00267096
Iteration 7957, loss = 0.00267046
Iteration 7958, loss = 0.00267001
Iteration 7959, loss = 0.00266954
Iteration 7960, loss = 0.00266905
Iteration 7961, loss = 0.00266854
Iteration 7962, loss = 0.00266827
Iteration 7963, loss = 0.00266759
Iteration 7964, loss = 0.00266713
Iteration 7965, loss = 0.00266703
Iteration 7966, loss = 0.00266623
Iteration 7967, loss = 0.00266566
Iteration 7968, loss = 0.00266522
Iteration 7969, loss = 0.00266476
Iteration 7970, loss = 0.00266438
Iteration 7971, loss = 0.00266380
Iteration 7972, loss = 0.00266325
Iteration 7973, loss = 0.00266272
Iteration 7974, loss = 0.00266232
Iteration 7975, loss = 0.00266184
Iteration 7976, loss = 0.00266140
Iteration 7977, loss = 0.00266092
Iteration 7978, loss = 0.00266053
Iteration 7979, loss = 0.00266003
Iteration 7980, loss = 0.00265940
Iteration 7981, loss = 0.00265899
Iteration 7982, loss = 0.00265848
Iteration 7983, loss = 0.00265816
Iteration 7984, loss = 0.00265794
Iteration 7985, loss = 0.00265720
Iteration 7986, loss = 0.00265674
Iteration 7987, loss = 0.00265626
Iteration 7988, loss = 0.00265585
Iteration 7989, loss = 0.00265543
Iteration 7990, loss = 0.00265495
Iteration 7991, loss = 0.00265449
Iteration 7992, loss = 0.00265408
Iteration 7993, loss = 0.00265365
Iteration 7994, loss = 0.00265305
Iteration 7995, loss = 0.00265277
Iteration 7996, loss = 0.00265212
Iteration 7997, loss = 0.00265191
Iteration 7998, loss = 0.00265126
Iteration 7999, loss = 0.00265093
Iteration 8000, loss = 0.00265054
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[105]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Accuracies:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span><span class="n">multi_accuracies</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Mean Accuracy: &quot;</span><span class="p">,</span><span class="n">multi_accuracies</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Accuracies:
 [1.         1.         1.         1.         1.         1.
 0.92592593 1.         1.         1.        ]
Mean Accuracy:  0.9925925925925926
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[106]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">multi_predicted</span> <span class="o">=</span> <span class="n">multi_classifier</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[107]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span><span class="n">multi_predicted</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[107]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>1.0</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[108]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Confusion Matrix For MLPClassifier&quot;</span><span class="p">)</span>
<span class="n">cm</span><span class="o">=</span><span class="n">metrics</span><span class="o">.</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span><span class="n">multi_predicted</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>

<span class="n">df_cm</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">cm</span><span class="p">,</span> <span class="n">index</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">]],</span>
                  <span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;Predict 0&quot;</span><span class="p">,</span><span class="s2">&quot;Predict 1&quot;</span><span class="p">]])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">7</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">df_cm</span><span class="p">,</span> <span class="n">annot</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Confusion Matrix For MLPClassifier
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>





<div id="1f3f9153-424d-4531-ac77-e1911bf7e151"></div>
<div class="output_subarea output_javascript ">
<script type="text/javascript">
var element = $('#1f3f9153-424d-4531-ac77-e1911bf7e151');

        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns'); }
    
</script>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>





<div id="8d9575db-9a28-48cf-8984-9136f1133b93"></div>
<div class="output_subarea output_javascript ">
<script type="text/javascript">
var element = $('#8d9575db-9a28-48cf-8984-9136f1133b93');

        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns'); }
    
</script>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>





<div id="65bbfa75-298a-4850-8cc8-568fc4e188c1"></div>
<div class="output_subarea output_javascript ">
<script type="text/javascript">
var element = $('#65bbfa75-298a-4850-8cc8-568fc4e188c1');

        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns'); }
    
</script>
</div>

</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[108]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&lt;matplotlib.axes._subplots.AxesSubplot at 0x12718aa20&gt;</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>




<div class="output_png output_subarea ">
<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAZMAAAEvCAYAAACAFCxvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAXzUlEQVR4nO3deZhcdZno8e/b3dlYQlgkOwQh7JKAGUS5KAgCKvuMLM9FgzK2I+CFq+MIF5SRbUAgDjxs00oIKAbjmgioZBgRGUXIYGRJQMLeIRJAMGzpTnf97h9ViU3odCf160qfSn8/POfprnNOnfNWqK633vd3lkgpIUlSjob+DkCSVP9MJpKkbCYTSVI2k4kkKZvJRJKUzWQiScrWVOsdrHjpSY891nozbMx+/R2CBpiO9sXRV9uq9vNy0Fbv7rMYqmVlIknKVvPKRJK0lkqd/R1B1UwmklQUqdTfEVTNZCJJRVEymUiSMiUrE0lSNisTSVK2Oq5MPDRYkoqi1Fnd1IuImB4RSyPi4S7z/jUiFkfE/Mr0sS7LzoqIRRHxWEQcsjahW5lIUlHUrjKZAVwF3LTa/G+mlC7rOiMidgWOB3YDxgD/GRE7ppR6zFpWJpJUFKVSdVMvUkp3A39ZyyiOBG5JKbWllJ4CFgF79/Ykk4kkFURKpaqmDKdFxIOVNtjmlXljgee6rNNamdcjk4kkFUWVlUlENEfEvC5T81rs7Vpge2AysAS4vDK/u+t89XrNMMdMJKkoqqwyUkotQMs6PueFlb9HxLeAWysPW4HxXVYdBzzf2/asTCSpKGp0NFd3ImJ0l4dHAyuP9JoDHB8RQyJiO2AicF9v27MykaSiqNHRXBExE9gf2CoiWoFzgf0jYjLlFtbTwOcAUkqPRMQsYAHQAZza25FcAJFSbW834v1MtD55PxOtb315P5O2R+6s6vNyyG4H9vv9TKxMJKkoPANekjSQWZlIUlF4oUdJUq61GOcuLJOJJBVFHY+ZmEwkqShsc0mSslmZSJKyVXk2exGYTCSpKKxMJEnZHDORJGWzMpEkZbMykSRlM5lIknJ5BrwkKZ+ViSQpmwPwkqRsViaSpGx1XJl4cyxJUjYrE0kqCttckqRsddzmMplIUlFYmUiSsplMJEnZbHNJkrJZmUiSslmZSJKyWZlIkrJZmUiSslmZSJKymUwkSdlS6u8IqmYykaSisDKRJGUzmUiSsnk0lyQpWx1XJt4cS5KUzcpEkorCo7kkSdnquM1lMpGkojCZSJKyeTSXJClXKjlmIknKZZtLkpStjttcnmciSUVRStVNvYiI6RGxNCIe7jLv0oh4NCIejIifRMSILsvOiohFEfFYRByyNqGbTCSpKEql6qbezQAOXW3eXGD3lNIewJ+AswAiYlfgeGC3ynOuiYjG3nZgMpGkoqhRMkkp3Q38ZbV5d6SUOioP7wXGVX4/ErglpdSWUnoKWATs3ds+HDPpI+dcNI27//s+tth8BD/97nXdrnPfAw9yyRX/QUdHB5uPGM6Mqy/N2md7eztnnX85Cx57nBGbDeey885i7OiR/Pa+B/j3625gxYoOBg1q4kunnsz73js5a1/acB1y8P5Mm3YejQ0NTL9hJt+49Or+Dmng6r8z4D8DfL/y+1jKyWWl1sq8HlmZ9JGjPvYRrpt2wRqXL3vtdS64/CquuuRcZt/8H1x+wdlrve3FS17gpNP+5R3zf3zrHQzfdBN+Pms6nzzuKKZdMx2AzUcM56pL/pWffOdaLjznS5x13mXr/oI0IDQ0NHDlFRdy2OEn8p5JB3DccUexyy4T+zusgavKyiQimiNiXpepeW13GRFnAx3AzStndbNar1mu18okInamXPaMrWzweWBOSmnh2gY7EEyZ/B4WL3lhjctvn3sXB31oX0aP2hqALTdfNdbFz375X9z8g9msWNHBHrvtxDlfOpXGxl5blPzXb37HKSefCMDB++/HRdOuJaXELjvusGqdHbbblrb2dtrb2xk8eHC1L08bqL3/bk+eeOJpnnrqWQBmzZrNEYcfwsKFj/dzZANUleeZpJRagJZ1fV5ETAUOAw5MaVVZ1AqM77LaOMqf+z3qsTKJiK8At1DOVPcB91d+nxkRZ65r4APZ08+2suy11znptH/h2M98gdk//08Annj6WX5x56/5znWX86Mbr6ahoYFb7/jVWm1z6YsvM2rrrQBoampkk4034tW/LnvbOnPvuodddtzeRKJujRk7iuda//Y50bp4CWPGjOrHiAa4VKpuqkJEHAp8BTgipfRml0VzgOMjYkhEbAdMpPz536PeKpOTgd1SSitWC2Ia8Ahw8boEP5B1dpZY8OjjfPvKi2lra+N/f+6LTNptZ34/bz4LHl3E8SefDkBbWxtbVKqW/3PWeSx+/gVWdKxgyQsv8vdTTwXgxGOP5OiPH0zqpr8a8bcKddGTzzDtmum0fPPC9fAKVY+6vl9W6u59pfWkRmfAR8RMYH9gq4hoBc6lfPTWEGBu5X1wb0rpn1JKj0TELGAB5fbXqSmlzt720VsyKQFjgGdWmz+6smxNgTcDzQDXXH4B//ipE3qLY4M3cuutGDFiOBsNG8pGw4by3sm789iip0gpccRHD+L/fv7T73jOlf/2NaA8ZnL2hZcz46pvvGObf176EqO2fhcdHZ28/sabbDZ8UwD+vPRFTv9/53PRV/+ZbcaNqf0LVF1a3LqE8V3eH+PGjmZJD+1a1Vaq0RnwKaXuPoSv72H9C4F1+hba2wD8GcCdEfHziGipTL8A7gRO7yGQlpTSlJTSFBNJ2QH77cMDf3yYjo5O3lq+nIceeYx3TxjPPlMmM/eue3j5lVcB+Ouy13j+z2v3x3zA/9qH2beX22V33PUb3vfeSUQEy157nVO+fC5nfO4k9tpjt5q9JtW/++fNZ4cdtmPChPEMGjSIY489kp/dekd/h6U61GNlklL6RUTsSPkY47GUx0tagfvXpuwZSL587sXc/4cHefXVZRx41ImccvIn6egoH8J93NEfZ/sJ27Dv+6ZwzNTP0xAN/P3hhzDx3RMA+MJnP0XzGWdTSiUGNTVx9hdPYcyokb3u85jDDuGs8y/lo8d+hs2Gb8qlXy8PY8380c94rvV5rpsxk+tmzASg5d8vfNugvwTQ2dnJ6Wecw+23fY/GhgZm3Ph9Fiz4U3+HNXDV8YUeo9b90RUvPVm//zqqO8PG7NffIWiA6Whf3N2htFV544ITq/q83Pic7/ZZDNXypEVJKoo6rkxMJpJUFF6CXpKUzcpEkpStju9nYjKRpKKwMpEk5arVSYvrg8lEkorCykSSlM1kIknK5gC8JCmblYkkKVcymUiSsplMJEnZPDRYkpTNykSSlK2Ok0lvd1qUJKlXViaSVBC1vllhLZlMJKko6rjNZTKRpKIwmUiScnnSoiQpn8lEkpStfs9ZNJlIUlHY5pIk5TOZSJKy2eaSJOWyzSVJymdlIknKZWUiScpnZSJJypVMJpKkbCYTSVKueq5MvDmWJCmblYkkFUUdVyYmE0kqiHpuc5lMJKkgTCaSpGwmE0lSvhT9HUHVTCaSVBBWJpKkbKlUv5WJ55lIUkGkUnVTbyLi9Ih4OCIeiYgzKvO2iIi5EfF45efmObGbTCSpIFKKqqaeRMTuwGeBvYFJwGERMRE4E7gzpTQRuLPyuGomE0kqiBpVJrsA96aU3kwpdQC/Bo4GjgRurKxzI3BUTuwmE0kqiFSKqqZePAx8MCK2jIiNgI8B44GRKaUlAJWfW+fE7gC8JBVEqvLeWBHRDDR3mdWSUmopbzMtjIhLgLnA68AfgY68SN/JZCJJBVHt0VyVxNHSw/LrgesBIuIioBV4ISJGp5SWRMRoYGlVO6+wzSVJBVGjNhcRsXXl5zbAMcBMYA4wtbLKVGB2TuxWJpJUENW2udbCjyJiS2AFcGpK6ZWIuBiYFREnA88Cn8jZgclEkgqiVictppT262bey8CBfbUP21ySpGxWJpJUEL2dgFhkJhNJKggv9ChJylayMpEk5bLNJUnKVs+XoDeZSFJB1PA8k5ozmUhSQViZSJKyOQAvScrmALwkKZtjJpKkbLa5JEnZbHNJkrLZ5urBsDHvuPKxVDPLzj+4v0OQqmabS5KUzTaXJClbPVcm3hxLkpTNykSSCqKOx99NJpJUFPXc5jKZSFJBOAAvScpWx3ftNZlIUlEkrEwkSZlKdTwCbzKRpIIoWZlIknLZ5pIkZXMAXpKUzcpEkpTNykSSlM1kIknKZptLkpStVL+5xGQiSUXheSaSpGx1fAK8N8eSJOWzMpGkgvBoLklStlI4ZiJJylTPYyYmE0kqCNtckqRsnmciScrmeSaSpGyOmUiSstVzm8uTFiWpIEpVTmsjIkZExA8j4tGIWBgR74+ILSJibkQ8Xvm5ebWxm0wkqSBSldNaugL4RUppZ2ASsBA4E7gzpTQRuLPyuComE0kqiFJUN/UmIoYDHwSuB0gptaeUXgWOBG6srHYjcFS1sZtMJKkgatjmejfwInBDRPwhIr4dERsDI1NKSwAqP7euNnaTiSQVRLXJJCKaI2Jel6l5tU03AXsB16aU9gTeIKOl1R2P5pKkgkhVHs2VUmoBWnpYpRVoTSn9vvL4h5STyQsRMTqltCQiRgNLq4vAykSSCqNWba6U0p+B5yJip8qsA4EFwBxgamXeVGB2tbFbmUhSQdT42lxfAG6OiMHAk8CnKRcUsyLiZOBZ4BPVbtxkIkkFUcsz4FNK84Ep3Sw6sC+2b5tLkpTNykSSCqKeL6diMpGkgvB+JpKkbCYTSVI2L0EvScrmmIkkKZttLklSNttckqRspTpOJyYTSSoI21ySpGz1W5eYTCSpMKxMJEnZPDRYkpTNAXhJUrb6TSUmE0kqDMdMJEnZ6rnN5c2xJEnZrEwkqSDqty4xmUhSYThmIknKVs9jJiYTSSqI+k0lJhNJKgzbXJKkbKmOaxOTiSQVhJWJJCmbA/DqU4ccvD/Tpp1HY0MD02+YyTcuvbq/Q1LBDP7oZ2jcfhLpzWUsn/7Vdyxv3HUfBr3vYwCkFW20//Im0ovP5e20sYnBH/8sDaO2Jb31Ou2zryUte5mGCbsy+EOfgMYm6Oyg/VezKD27MG9fA1T9phLPgC+choYGrrziQg47/ETeM+kAjjvuKHbZZWJ/h6WC6XjoHpb/YNoal6e/vsTy713M8hu+xorfzmHwoVPXetsxfEuGnPCVd8xv2mM/0vI3WN5yJh3z7mDQ/seW9/Xm67T96AqWT/8qbbd9m8GHfXbdX5CAcmVSzVQEViYFs/ff7ckTTzzNU089C8CsWbM54vBDWLjw8X6OTEVSav0TMXzLNS9fvKjL708Qm26x6nHjru+n6b0HEY1NdC55khV33ASp9w+kxol7seKenwLQ+eg8Bh90IgBp6bOr1kkvLSaaBq2qUrRu6nnMpOrKJCI+3ZeBqGzM2FE81/r8qseti5cwZsyofoxI9a5p0gcpPfkQALHlaJp22Zu2my9i+YxzoVSicdf3r9V2YpMRpNf+Un6QSqS2t2DYJm9bp3GnKZReeMZEUqVU5X9FkFOZfB24oa8CUVnEO2+1ltbiW6PUnYZtdqZpj/1Y/t2LAGjcdldi5LYM/dTXyis0DYI3l9EJDD76NBo2exc0NhLDt2ToSV8HYMX/zKXzoXugm/dm14omthrDoA99grZZl9X6ZW2w6rky6TGZRMSDa1oEjOzhec1AM0A0bkZDw8ZVBzjQLG5dwvhxY1Y9Hjd2NEuWvNCPEalexbvGMfjQT9P2g2mw/I1V8zsf/i0r7v7hO9Zv/8lV5ecN35LBH/9H2mZe8rbl6bVXiE23IL32CkQDMWTYqu3Gppsz5Ogv0H7bt0ivvljDV7VhK0qVUY3e2lwjgU8Bh3czvbymJ6WUWlJKU1JKU0wk6+b+efPZYYftmDBhPIMGDeLYY4/kZ7fe0d9hqc7Eplsw5OjTyh/ur/zty0jnMwtp3GkKbLRpecbQjXsce+mq8/E/0Lj7vgA07jyFzpVHbA0ZxpB/OIMVv/7h28ZqtO5KVU5F0Fub61Zgk5TS/NUXRMRdNYlogOvs7OT0M87h9tu+R2NDAzNu/D4LFvypv8NSwQw+/HM0brMzDNuEoadczop7fko0NALQMf8uBu17JDFsEwZ/5JMApFInbTedR3r5eVb85scMPfafy22rUiftc79DWrbG74ardDx4N4MPa2Zo88Wkt96gfc51ADTtdRAxYiSDPnAEgz5wBADLZ10Gb75Wo1e/4SrVcUs7at2Pbxo8tn7/dVR3lp1/cH+HoAFmo6/c0M1gUnU+ue0xVX1efueZH/dZDNXy0GBJKoh6/uZtMpGkgijKCYjVMJlIUkHU89FcJhNJKoiiHJlVDZOJJBWEbS5JUjbbXJKkbLa5JEnZ6vk6fN7PRJIKolb3M4mIoRFxX0T8MSIeiYivV+ZvFxG/j4jHI+L7ETG42thNJpJUEDW8Nlcb8OGU0iRgMnBoROwDXAJ8M6U0EXgFOLna2E0mklQQtbqfSSp7vfJwUGVKwIeBlZeQvhE4qtrYTSaSVBC1vG1vRDRGxHxgKTAXeAJ4NaW08k5mrcDYamM3mUhSQaSUqpoiojki5nWZmrvZdmdKaTIwDtgb2KW7EKqN3aO5JKkgqj00OKXUArSs5bqvVm4hsg8wIiKaKtXJOOD5Hp/cAysTSSqIWo2ZRMS7ImJE5fdhwEHAQuBXwD9UVpsKzK42disTSSqIGl5OZTRwY0Q0Ui4iZqWUbo2IBcAtEXEB8Afg+mp3YDKRpA1cSulBYM9u5j9Jefwkm8lEkgqins+AN5lIUkF41WBJUjavGixJylayzSVJylW/qcRkIkmF4ZiJJCmbyUSSlM1DgyVJ2axMJEnZPDRYkpTNNpckKZttLklSNisTSVI2KxNJUjYH4CVJ2er52lzetleSlM3KRJIKwjaXJClbPbe5TCaSVBBWJpKkbFYmkqRsViaSpGxWJpKkbFYmkqRsKZX6O4SqmUwkqSC8NpckKZtXDZYkZbMykSRlszKRJGXz0GBJUjYPDZYkZbPNJUnK5gC8JClbPVcm3mlRkpTNykSSCsKjuSRJ2eq5zWUykaSCcABekpTNykSSlM0xE0lSNs+AlyRlszKRJGWr5zETT1qUpIJIVf7Xm4g4NCIei4hFEXFmLWK3MpGkgqhFZRIRjcDVwEeAVuD+iJiTUlrQl/sxmUhSQdSozbU3sCil9CRARNwCHAn0aTKxzSVJBZGqnHoxFniuy+PWyrw+VfPKpKN9cdR6HxuiiGhOKbX0dxwaOHzP9b9qPy8johlo7jKrpcv/y+622eclkJVJcTX3vorUp3zP1amUUktKaUqXqeuXglZgfJfH44Dn+zoGk4kkbdjuByZGxHYRMRg4HpjT1ztxAF6SNmAppY6IOA34JdAITE8pPdLX+zGZFJe9a61vvuc2UCml24Hba7mPqOczLiVJxeCYiSQpm8mkD0REZ0TMj4iHI+IHEbFRxrb2j4hbK78f0dOlDyJiRESc0sPyml9CQetfgd9v0yNiaUQ8XG08ql8mk77xVkppckppd6Ad+KeuC6Nsnf+tU0pzUkoX97DKCKDbP+4ul1D4KLArcEJE7LquMaiQCvd+q5gBHLqu+9WGwWTS934D7BAREyJiYURcAzwAjI+IgyPidxHxQOUb5SawqoJ4NCLuAY5ZuaGIOCkirqr8PjIifhIRf6xMHwAuBravfEu9dLU4Vl1CIaXUDqy8hII2LEV5v5FSuhv4y3p4zSogk0kfiogmypXAQ5VZOwE3pZT2BN4AzgEOSintBcwDvhgRQ4FvAYcD+wGj1rD5K4Ffp5QmAXsBjwBnAk9UvqV+ebX118slFNR/CvZ+0wBnMukbwyJiPuU/2GeB6yvzn0kp3Vv5fR/K7ab/rqw7FdgW2Bl4KqX0eCofWvfdNezjw8C1ACmlzpTSX3uJab1cQkH9oojvNw1wnmfSN95KKU3uOiMioPztcNUsYG5K6YTV1ptMbT7k18slFNQvivh+0wBnZbL+3AvsGxE7AETERhGxI/AosF1EbF9Z74Q1PP9O4POV5zZGxHDgNWDTNay/Xi6hoMJa3+83DXAmk/UkpfQicBIwMyIepPzHvnNKaTnlC+zdVhkQfWYNmzgdOCAiHgL+B9gtpfQy5TbGw6sPiKaUOoCVl1BYCMyqxSUUVEzr+/0GEBEzgd8BO0VEa0Sc3OcvTIXlGfCSpGxWJpKkbCYTSVI2k4kkKZvJRJKUzWQiScpmMpEkZTOZSJKymUwkSdn+P+tovTEhwPxQAAAAAElFTkSuQmCC
"
>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span> 
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Printing-each-Algorithm-and-the-accuracy-score">Printing each Algorithm and the accuracy score<a class="anchor-link" href="#Printing-each-Algorithm-and-the-accuracy-score">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[109]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;LogisticRegression:&quot;</span><span class="p">,</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span><span class="n">y_test_pred</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Support Vector Machine (using kernel=linear):&quot;</span><span class="p">,</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span><span class="n">svm_pred</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Support Vector Machine (using kernel=rbf):&quot;</span><span class="p">,</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span><span class="n">svm_rbf_pred</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;RandomForestClassifier:&quot;</span><span class="p">,</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span><span class="n">rdf_pred</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;KNeighborsClassifier:&quot;</span><span class="p">,</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span><span class="n">KNN_predicted</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;MLPClassifier:&quot;</span><span class="p">,</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span><span class="n">multi_predicted</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>LogisticRegression: 0.9745454545454545
Support Vector Machine (using kernel=linear): 0.9818181818181818
Support Vector Machine (using kernel=rbf): 1.0
RandomForestClassifier: 0.9963636363636363
KNeighborsClassifier: 1.0
MLPClassifier: 1.0
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>It can be seen that Support Vector Machine (using kernel=rbf), KNeighborsClassifier: 1.0 and MLPClassifier: 1.0 are having hightest accuracy score of 100% and RandomForestClassifier is also doing very great with accuracy score of 99%</p>
<p>These can also be verified from the confusion matrix</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Accuracy of 100% is quite weired and I suggest you try different approach to verify this such instead of 80:20, try 70:30 splitting and also try tuning the parameters of the different algorithms to verfify you results</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>logistic regression documentation: <a href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html">https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html</a></p>
<p>SVM documentation: <a href="https://scikit-learn.org/stable/modules/svm.html">https://scikit-learn.org/stable/modules/svm.html</a></p>
<p>GridSearchCV: <a href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html">https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html</a></p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span> 
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span> 
</pre></div>

    </div>
</div>
</div>

</div>
    </div>
  </div>
</body>

 


</html>
